index,text
26465,multiple dilemmas confound social ecological modelling this review paper focuses on two a modeller s dilemma associated with determining appropriate levels of model simplification and a dilemma of decision making relating to the use of models that were never designed to predict we analyse approaches for addressing these dilemmas as they relate to shallow coastal systems and conclude that wicked problems cannot be adequately addressed using traditional disciplinary or systems engineering modelling simplified inter and trans disciplinary models have the potential to identify directions of system change challenge thinking in disciplinary silos and ultimately confront the dilemmas of social ecological modelling keywords wicked problems agent based modelling post normal science social ecological systems shallow coastal systems 1 introduction this paper examines two dilemmas prevalent in environmental research a modeller s dilemma and a dilemma of decision making modellers face many dilemmas but a central issue relates to tradeoffs between simplifications that are necessary to represent certain characteristics of a system and the need also to represent intricacies within the system in sufficient detail in order to produce outputs that are useful in some way this dilemma is particularly challenging in the case of social ecological systems which have interacting physical ecological and social components how should these components be treated within models a related dilemma confounds environmental management models not intended for decision support have nevertheless become a crutch on which decision making often relies with insufficient critical consideration of model limitations in the planning process and application of models in ways that modellers may not have intended groeneveld et al 2017 kelly et al 2013 improved environmental planning requires progress in resolving these related dilemmas this paper reviews literature with an aim of identifying approaches of addressing and minimising these two dilemmas confronting modellers and decision makers the dilemmas are recognisable across much environmental research but we focus on shallow coastal systems particularly estuaries which are highly valued for providing essential ecosystem services and contributing to wider marine ecosystem function but are also vulnerable due to their physical properties e g shallow water depths and processes such as increasing population urbanisation and changes in climate and land use mcnamara and werner 2008a ipcc 2014 box 1 sets out some of the key concepts used in this review paper the approach has involved critiquing literature from diverse fields pertaining to social ecological modelling wicked problems trans and interdisciplinary research abm estuarine modelling and estuarine management the review is concerned with determining appropriate methods for approaching uncertainty in complex social ecological systems and selecting suitable techniques for modelling feedbacks between and interactions within these systems as set out in schlüter et al 2012 but with a specific focus on how the two dilemmas impact upon model form function and use systems engineering models differ from the other definitions in box 1 as they represent a single discipline way of approaching a problem this type of model represents a traditional approach to environmental management as opposed to a holistic post normal science approach schlüter et al 2012 set out the main differences between traditional and social ecological systems approaches to the management of human environment systems chief among which is that traditional methods utilise a command and control technique whereas social ecological systems management aim to enhance system resilience the three other concepts are fundamentally intertwined the post normal science approach is a methodology that often incorporates transdisciplinarity when attempting to address wicked problems in complex social ecological systems this review was undertaken using a post normal science approach reviewing literature from the fields of social ecological modelling wicked problems trans and interdisciplinary research agent based modelling abm estuarine modelling and estuarine management our review is concerned with determining appropriate methods for approaching uncertainty in complex social ecological systems and selecting suitable techniques for modelling feedbacks between and interactions within these systems as set out in schlüter et al 2012 but with a specific focus on how the two dilemmas impact upon model form function and use the review paper focuses on shallow coastal areas that occur at the downstream end of terrestrial drainage systems and are highly exposed to anthropogenically derived pollution davies 2015 millennium ecosystem assessment 2005a worldwide shallow coastal ecosystems are undergoing rapid changes creating a research imperative to understand the complex interrelationships between ecological physical and social processes that drive environmental change e g mcgranahan et al 2007 moser et al 2012 nicholls et al 2011 small and nicholls 2003 rapid urbanisation and increasing population in coastal areas can stress the existing social ecological systems while climate change is making these areas increasingly less suitable to sustain human populations crossett et al 2004 moser et al 2012 the consequences of sea level rise are already being felt in some of the least developed countries such as bangladesh where some 46 of the population lived within 10 m of mean sea level in 2007 mcgranahan et al 2007 however sea level rise is a global problem with 10 of world population concentrated in only 2 of the land area mcgranahan et al 2007 and 2 4 of global population at risk of displacement by sea level rise by the end of the 21st century nicholls et al 2011 anthropogenic alteration of natural systems makes natural processes e g rainfall flooding storm surge more complex by introducing runoff channelisation water treatment and discharge interfering with natural flow regulation in particular urbanised systems experience exacerbated impacts of relatively common events due to a combination of expanded impervious surfaces and channelised drainage networks baird 2009 schiff and benoit 2007 computational models can help understand these complexities and should therefore be an important resource for decision makers in avoiding or mitigating impacts that reduce environmental ecological social and economic resilience however progress has been limited by the two dilemmas modellers are confronted with the challenge of how to adequately represent the physical ecological and social dimensions of shallow coastal systems and decision makers are challenged by how to utilise models that are designed for social learning or developing system understanding when a predictive model is desired for decision making purposes our aim in this paper is to reconcile the two dilemmas by identifying optimum modelling approach es for fully integrated consideration of social ecological and geophysical systems in a single model to accomplish this we review literature so as to explore the potential for post normal science transdisciplinarity and particularly abm to understand complex environmental problems and suggest a way forward the review paper is structured as follows first the nature of the two dilemmas are elaborated and environmental problems are categorised as tame complicated and wicked see box 2 second literature relevant to modelling shallow coastal social ecological systems is reviewed providing a foundation for the third and final section that outlines a path forward for modelling 2 a modeller s dilemma the phrase modeller s dilemma was used by singh and mishra 2008 in relation to conflict resolution among various model averaging techniques used in groundwater modelling a different modeller s dilemma as discussed here concerns the struggle to determine the appropriate level of simplification and imitation of reality necessary to produce useful model outcomes while preserving the necessary particulars of the system to be studied in selecting an approach to model complex social ecological systems it is necessary to first determine the purpose of the modelling endeavour as discussed by kelly et al 2013 and then decide upon an appropriate level of model complicatedness murray 2007 sun et al 2016 following sun et al 2016 our use of the term complicatedness pertains to model structure whereas complexity is used to describe model outputs the choice between high and low model complicatedness is determined by multiple factors but the existing level of system understanding is perhaps most important murray 2007 points out that highly complicated models offer limited explanatory insight whereas highly simple models are unable to make numerically reliable predictions sun et al 2016 note that increasing the complicatedness of a model can result in a decrease in the complexity of model outputs reducing model complicatedness can be achieved by omitting or approximating poorly understood components and components that are believed to have minimal systemic effect but these types of simplifications may also reduce the ability of the model to achieve research goals by altering model complexity all models are by definition abstract representations simplifications of reality and no model can be considered correct but the degree of simplification employed in different models varies enormously murray 2007 2013 o sullivan et al 2012 simandan 2010 sun et al 2016 determining the appropriate level of simplification is especially pertinent for a social ecological model being developed with the intention of investigating social ecological change and the interactions between physical ecological and social components at various scales as these systems are inherently highly complex yet poorly understood and notoriously difficult to manage using a traditional command and control approach voinov et al 2016 in such poorly understood social ecological systems having a predictive or forecasting focus is difficult due to the presence of unknown system variables kelly et al 2013 a more realistic goal is to improve system understanding by developing a very simple model that is useful even if its assumptions and workings are not strictly correct o sullivan et al 2012 murray 2013 such simple models also go some way to mitigate a dilemma that faces decision makers 2 1 a dilemma of decision making computational models have come to occupy a position that they were never designed for treated as infallible by those who rely on them but not by their creators meadows and robinson 2002 an increasing reliance on models to guide decision making e g carnavale et al 2012 oxley et al 2004 suggests that decision makers prefer a predictive tool policy makers have historically had difficulty in comprehending and counteracting wicked problems davies 2015 head 2014 stirling 2010 exemplified by the detachment between the time of decision making and the subsequent effects being observed rammer and seidl 2015 in this context model results provide a decision making crutch models can make decisions for decision makers devolution of responsibility from decision maker to model can be traced to a number of factors including the search for simple solutions by decision makers that thwarts the longer term perspective necessary to approach wicked problems head 2014 as well as ignoring the unintended consequences of wicked problems there is frequent miscommunication about the role of both science lave 2015 and modelling schneider 1997 in decision making and policy development the purpose and practical limitations of a model must always be made clear to end users and decision makers schneider 1997 in turn decision makers have a responsibility to understand the practical limitations of a model and to avoid using it in ways and for reasons that it is incapable additionally while scientists may openly express the subjective elements of their work in professional discussions morgan and keith 1995 they should also do so in relation to decision making wright 2015 research suggests that including stakeholders and decision makers in the development and testing of models is a valuable way of improving their understanding of model purpose bousquet and le page 2004 schneider 1997 seidl 2015 voinov and bousquet 2010 yearley 2006 seidl 2015 discusses various methods of participation and potential benefits from participatory modelling in this regard 3 dilemmas in practice chesapeake bay modelling system shallow coastal areas are increasingly becoming the subject of modelling exercises aimed at deciphering potential impacts and ways to mitigate or avoid them dilemmas facing both modellers and decision makers are accompanying these efforts e g lloyd et al 2015 malzone et al 2009 one notable example of a major social ecological coastal modelling project is the chesapeake bay modelling system cbms developed by the chesapeake bay program it uses an ecosystem based management approach to simulate social ecological system function and the impacts of change at the catchment scale using a coupled component model boesch and goldman 2009 paolisso et al 2015 calibrated through direct comparison with observed condition the model was initially used to assist voluntary restoration projects but is increasingly guiding official watershed implementation plans that aim to reduce human impacts on the chesapeake bay ecosystem paolisso et al 2015 the modelling endeavour has expanded since its establishment in 1983 and now encompasses airshed watershed and a model of the shallow coastal portions of chesapeake bay itself e g cerco et al 2013 keisman and shenk 2013 linker et al 2013 the cbms program was not successful in achieving some of its early management goals however a more holistic and integrated management approach was implemented once managers recognised the interrelated nature of the issues facing the bay boesch and goldman 2009 similar management schemes based on the principles of post normal science ecosystem based management and transdisciplinary research are increasingly viewed as superior to traditional command and control management at addressing wicked problems biggs et al 2010 davies 2015 funtowicz and ravetz 1993 since its inception the cbms has become increasingly complicated as the airshed and watershed models have been linked to the original bay model paolisso et al 2015 the creation of the present coupled component model highlights the aforementioned modeller s dilemma of determining an appropriate level of model simplicity vs complicatedness and the dilemma of decision making concerning changing use of the model s over time the increasing complicatedness of the cbms highlights a major issue facing modellers a modeller s dilemma and impacting on decision makers a decision maker s dilemma when attempting to address wicked problems 4 categorising problems rittel and webber 1973 noted that scientific practices were failing to address issues characterised by uncertainty plurality interdependence and a lack of agreement over what the problem actually was they coined the term wicked problems as a means of conveying the inherent complexity of the joint system problem and showed that conventional methods of addressing comparatively tame relatively simple and solvable problems were inadequate when applied to more complex problems balint et al 2011 added complicated problems as a middle ground between tame and wicked and suggested that the three major features distinguishing wicked from tame and complicated problems are values risk and uncertainty we use complicated to refer to problems that are not necessarily simple or solvable tame but where research is able to gain greater traction and deliver more useful prediction and forecasting of system attributes than research addressing wicked problems use of the term wicked implies difficulty in understanding and addressing complex problems almost all problems in social ecological systems can be considered wicked in large part because human interventions intended or not add risk uncertainty and multiple values creating a challenging environment for coping with this complex reality box 2 illustrates some of the ways in which tame complicated and wicked problems can be approached through disciplinary interdisciplinary and transdisciplinary research tame problems are generally tackled by a single academic discipline whereas complicated problems are best addressed through interdisciplinary research folke 2006 and transdisciplinarity is emerging as an important approach for tackling wicked problems brown et al 2010 participatory modelling is an important transdisciplinary post normal science method of approaching wicked problems that has become increasingly important during recent years robson 2014 seidl 2015 5 modelling 5 1 revisiting modelling according to kelly et al 2013 the five potential purposes of modelling are developing system understanding facilitating social learning predicting the behavior of variables when other variables are known forecasting the behavior of variables when other variables are not known and management and decision making under uncertainty sun et al 2016 set out six similar purposes for modelling prediction theory building decision making case specific analysis to illuminate core dynamics and education social ecological models can be developed and subsequently used for any of these purposes or a combination thereof model developers and end users may view and utilise the same model in different ways schneider 1997 creating the potential for a dilemma of decision making to emerge many approaches to integrated inter and transdisciplinary social ecological modelling exist bayesian networks system dynamics modelling abm knowledge based modelling and coupled component modelling among others have diverse strengths and weaknesses and are subsequently suited to achieving different modelling aims gilbert et al 2008 kelly et al 2013 no approach to environmental modelling is applicable in all situations the principal consideration when selecting a modelling technique and level of complicatedness is determining the purpose of the research kelly et al 2013 sun et al 2016 for instance if the investigation is focused on developing greater system understanding or facilitating social learning or in research with a significant spatial component then abm is a suitable approach kelly et al 2013 however system dynamics modelling may be a better option in cases without major spatial constituents voinov and bousquet 2010 as a way of accommodating the strengths and avoiding the weaknesses of the available techniques coupled component modelling attempts to bring the best of each system together to facilitate interdisciplinary modelling albeit it in a highly complex manner kelly et al 2013 while coupled component modelling increases model complicatedness it can facilitate understanding of both individual interactions and their aggregate effects this is useful when attempting to improve understanding of the system coupled components models may however exacerbate a modeller s dilemma as the combination of existing models can easily result in the development of a highly complicated model when a simpler original model would be better suited to address the issues facing the system while system dynamics and abms are both well suited to developing system understanding and facilitating social learning the spatial properties of abm means that it is generally superior for social ecological applications bousquet and le page 2004 kelly et al 2013 sun et al 2016 voinov and bousquet 2010 abms tend to be more complicated than system dynamics models but are more revealing of the interactions between individual variables and agents clifford 2008 o sullivan et al 2012 the approach selected should be determined by whether the research project is more interested in these individual interactions or only aggregate effects kelly et al 2013 a typical aim of modelling is to achieve a level of consistency between model components particularly scale as it is simpler to investigate interactions between the constituent parts when they are similarly scaled murray et al 2009 explicit numerical reductionism involves modelling on the smallest and fastest scales whereas top down exploratory modelling operates on the largest and slowest scales murray et al 2009 as different components may act and interact at vastly different scales utilising only a single scale risks oversimplification of some components if top down modelling is used or over complication of model structure if numerical reductionism is applied dealing with this requires use of a scale appropriate for the system under consideration a scale that captures the requisite level of complexity needed to address the problem being investigated o sullivan et al 2012 our literature review suggests that key to social ecological modelling endeavours are four actions coming to know the system under consideration identifying the constituent components of the system identifying the connections between these components and reconciling both component scale and disciplinarity attempts at modelling for the purpose of developing system understanding tend to limit the number of components included in the model or reduce their scale or other attributes e g becu et al 2003 huang et al 2014 whereas attempts at quantifying the nature of interactions between components tend to have increased complicatedness in many situations where some facets of system form and function are not well understood the inclusion of poorly understood components will reduce numerical precision and the robustness of model outputs some of these unknown quantities can be approximated gonzalez et al 2008 or proxies used drobinski et al 2012 mcgranahan et al 2007 but when they cannot limiting the number of model components can both increase model accuracy and enhance system understanding 5 2 modelling shallow coastal systems when developing a model to investigate changes in shallow coastal systems the developers should be explicit as to whether it is designed to investigate the mean values of system change or the extreme conditions caused by these changes mean values drive an average condition and are widely used in models operating over decadal or longer time scales e g holgate 2007 nicholls et al 2008 incremental stressors occurring over a longer timeframe can trigger state changes in shallow coastal social ecological systems hughes et al 2017 for example the impacts of rising water temperatures on coral reefs or a gradual long term increase in nitrogen in estuarine systems however investigating the incremental changes that produce average system conditions do not shed light on the extreme events that might provide the impetus for sudden state changes in a system in local and regional scale investigations of climate change impacts on coastal areas the extreme values constitute the greatest risk to people and property subsequently they are among the best studied facets of climate change e g chini and stansby 2012 kirwin et al 2008 nicholls et al 2011 modelling the impacts of environmental change on shallow coastal social ecological systems occupies a position near point 3 in fig 1 the problem is wicked and multiple disciplines need to cooperate and contribute toward addressing it berkes 2010 learmonth et al 2011 utilising simple computational modelling for shallow coastal systems research allows for development of understanding of system form and function while avoiding unnecessary complicatedness in model design testing and operation modelling specific components of the social ecological aspect of coastal catchments can allow researchers to develop understanding of the potential directions of climate change environmental change and changes in collective human behavior on the shallow coastal areas of the system such a model may be intended for use in forecasting or predicting system responses but there are significant challenges associated with this aim local scale research is much more likely to achieve success if it has alternate purposes such as facilitating social learning among stakeholders or to assist but not drive decision making under uncertainty in the future if such a model is to be used in decision making it is vital to explain to the decision makers the reasons a model was constructed what its limitations are and that model intent may not be forecasting or prediction schneider 1997 rather that it can demonstrate the potential for non linear and complex responses to the wicked problem of climate change such a model could be used to guide decision making by encouraging the fostering of resilience within the social ecological system under consideration murray et al 2009 5 3 what models suit in a recent review of participatory modelling ventures seidl 2015 found participatory abm to be the most commonly used participatory modelling approach and simon and etienne 2010 concluded that abm is the most appropriate modelling approach to facilitate stakeholder participation in the literature abm stands out as the technique most suited to investigating dynamic human environmental interactions in a shallow coastal social ecological system due to its explicit focus on investigating interactions between individuals other techniques are more concerned with analysis of the aggregated effects of such interactions kelly et al 2013 schlüter et al 2012 however abm approaches often produce more complicated models than other approaches due to the large numbers of model inputs sun et al 2016 exacerbating the modeller s dilemma of significance to the intricacy of the model are simulation of the interactions between inputs a continually changing spatial setting and potentially changing boundary conditions bousquet and le page 2004 kelly et al 2013 o sullivan et al 2012 abms can expand researcher and stakeholder understanding of complex social ecological systems by simulating interactions between autonomous entities within the system making this approach particularly appealing for modelling the interaction between social and ecological agents in coastal systems research e g luo et al 2012 mcnamara and keeler 2013 however depending on the level of model simplification desired complicated model structure can be considered a weakness of an abm approach when addressing the modeller s dilemma kelly et al 2013 o sullivan et al 2012 sun et al 2016 hence there is a trade off when using an abm approach between the strength of simulating agent interactions and the potential weakness of high model complicatedness sun et al 2016 the inability of abms to accurately predict outcomes without making the model overly complicated due to the inclusion of poorly understood system components is a limitation kelly et al 2013 sun et al 2016 as stated this can be remedied by reducing model complicatedness but in doing so the modeller runs the risk of also reducing model complexity which may adversely impact on research outcomes while the intricacy of abm makes it a complicated and time consuming approach its significant strength in developing system understanding can often justify these factors o sullivan et al 2012 if prediction of system behavior is the purpose of modelling more suitable approaches than abm are available such as system dynamics and potentially coupled component modelling when developed in conjunction with stakeholders and or end users an abm can help mitigate the dilemma of decision making by explicitly demonstrating model limitations to end users dereynier et al 2010 robson 2014 this kind of end user participation in model development can also mitigate the modeller s dilemma as all parties collaboratively decide upon an appropriate level of complicatedness rather than just the modeller determining this agent behavior and interactions are fundamental concerns in developing understanding and modelling coastal social ecological system structure bousquet and le page 2004 abms provide a well founded framework aimed at incorporating this integration of behavior and interactions as well as stakeholder knowledge and perspectives within a numerical model berger 2001 elsawah et al 2015 fulton et al 2015 kelly et al 2013 voinov and bousquet 2010 voinov et al 2016 their ability to handle spatial data and dynamics gives abms an advantage over other approaches to modelling kelly et al 2013 sun et al 2016 abm has been used to model various social ecological systems at the catchment scale e g barreteau et al 2001 barthel et al 2009 becu et al 2003 and is particularly useful when investigating human settlement and other social ecological systems o sullivan et al 2012 sun et al 2016 modelling of shallow coastal environments using an abm approach is also becoming increasingly common e g brush and nixon 2010 canal vergés et al 2014 zhang and gorelick 2014 6 reintroducing social elements wicked problems are ubiquitous within interconnected social ecological systems balint et al 2011 brown et al 2010 turnpenny et al 2009 shallow coastal social ecological systems are highly interconnected and often produce non linear emergent responses to a change in one system component resulting in changes across scales and affecting multiple system attributes mcnamara and werner 2008a moser et al 2012 williams et al 2013 hence the human element must be meaningfully embraced in shallow coastal social ecological modelling which requires a multifaceted approach historically when disciplinary research programmes have attempted to grapple with wicked problems that transcend disciplinary boundaries one discipline tends to dominate the discourse and research agenda with the result that either human or non human system attributes are poorly incorporated or oversimplified to the point of irrelevance davies 2015 lave et al 2014 turner ii et al 2016 previous work on resilience in social ecological systems has tended to either disconnect the social components of systems from the whole brown gaddis et al 2010 reduce them to economic factors or simple demographics cote and nightingale 2012 or represent the connections between the subsystems as unidirectional filatova et al 2013 while failing to acknowledge the singular complex and intertwined entity that is a social ecological system berkes 2007 this pitfall can be avoided by investigating the nature of relevant human variables from the outset of research particularly through application of a post normal science participatory modelling approach funtowicz and ravetz 1993 turnpenny et al 2009 voinov et al 2016 stakeholder participation provides the opportunity to learn about concealed characteristics of the system voinov and brown gaddis 2008 such as how resident and non residents utilise and interact with a shallow coastal system social ecological research can use stakeholder participation to make visible the range of values held davies 2015 balint et al 2011 and to build a shared understanding of a system and the issues facing it both for social learning purposes and to link findings to decision making processes fulton et al 2015 yearley 2006 mitigating the dilemma of decision making the knowledge derived from stakeholders participants and end users can be used by modellers to develop a richer understanding of the system so that the model under development can more accurately represent the social characteristics of the system and assist in developing ways to address the wicked problems afflicting it an analysis of integrated coastal management in new zealand found that increased collaboration across the science policy interface facilitates the production of higher quality science and better management outcomes for coastal zones bremer and glavovic 2013 when studying a wicked problem separate handling of the social components could easily result in unrealistic representation of system functions subsequent production of imprecise model outputs and an exacerbation of the modeller s dilemma through inclusion of unnecessary variables or oversimplification of the social system cote and nightingale 2012 noted that work on resilience in social ecological systems has proceeded in remarkable isolation from human geography and other social sciences despite the notable commonalities in research foci a holistic broad scale envisioning of the system using a post normal science approach is desirable when researching and modelling social ecological impacts of climate change on shallow coastal systems viewing shallow coasts as comprised of separate social geophysical ecological economic political etc subsystems is commonplace in the anglophone world as a way of making sense of complexity castree 2014 in practice there is considerable difference between understanding a system as the sum of its parts and dealing with system complexity in a way that does not recognise artificial conceptual boundaries between subsystems in developing simple models that aim to grow understanding of an entire shallow coastal social ecological system there is little point in treating perceived subsystems as distinct entities the components of any system are not solely responsible for its behavior rather the interactions between components create system form and function castree 2014 thrift 1996 in simandan 2010 393 and those components need not belong to any one category or subsystem simandan 2010 391 writing on contingency and necessity within human belief systems highlights a major issue with a non holistic research approach binary distinctions yield artificial borders and as soon as one faces borders one faces the quandary of border cases and the ensuing temptation to fudge them so as to fit neatly into one box or the other true transdisciplinary environmental research ought to accept that boundaries between social ecological and geophysical systems are socially constructed and that their use may lead to potentially inadequate representations of any system as a whole traditional disciplinary understandings and representations of subsystems are not obsolete epistemic communities remain vital to disciplinary and interdisciplinary knowledge production but the different disciplinary viewpoints need to be proactively discussed and blended in the early stages of a research project turner ii et al 2016 this review paper indicates that the best path is to 1 identify those variables in a system whose interactions have the greatest influence on whatever is of interest and 2 model their interrelations lynam et al 2007 and effects on overall system form and function regardless of which subsystem they are perceived to occupy such a holistic treatment of the overall social ecological system can mitigate the modeller s dilemma as the inclusion of only the necessary variables reduces model complicatedness in turn simpler models can mitigate the dilemma of decision making as the model can be easier to comprehend and limitations of the model will be more obvious 7 a way forward participatory abm can help to mitigate the dilemma of decision making by ensuring that stakeholders and decision makers are engaged in the development of model form and function and so understand when it is and is not appropriate to use a model to assist with the decision making process by encouraging end user participation the modeller s dilemma can be lessened as the modeller no longer needs to give as much concern to misuse of the model and has more leeway to determine how complicated model structure should be so as to appropriately model the system in question shallow coastal ecosystems have unknown variables and myriad complex interactions across human and biophysical domains hence social ecological models are more suited to producing information on the likely direction of environmental changes through developing system understanding than to making accurate predictions of exactly what change will occur models may be heuristic imperfect representations of reality but they can serve to achieve research and environmental management goals murray 2007 in social ecological systems not all system components need to be modeled in order to investigate outcomes of interactions between other system components in a transdisciplinary setting developing a model allows for improving researcher and stakeholder understanding of the system in question which in turn helps in addressing the problems affecting the system high numerical precision of outputs might be achieved through increasing model complicatedness but this is less important in this type of work than the robustness of results pertaining to the directions of change the need for balance between model simplification and complicatedness is mirrored in efforts to achieve parity between the various disciplines involved wicked problems in social ecological systems cannot be adequately addressed using traditional disciplinary or systems engineering modelling due to the interplay of social variables wu et al 2015 instead use of interdisciplinary and transdisciplinary modelling enables a holistic systems view this is a prerequisite for grappling with wicked problems in shallow coastal social ecological systems anthropogenically induced changes to shallow coastal systems are present worldwide yet the changes that are occurring are often poorly understood these changes do not occur in isolation but impact upon other facets of these systems understanding how these changes occur and spread is vital to avoiding or reducing the impacts of human actions simple models developed for the purpose of identifying directions of system change under various stressors are a valuable tool in achieving this inter or transdisciplinary research that considers the relevant factors in system form function and change can help challenge the thinking in disciplinary silos where knowledge has historically been produced and can help societies confront wicked environmental problems a post normal science approach particularly participatory modelling facilitates the development of understanding of complex systems voinov et al 2016 and provides a valuable tool to help address the issues faced by social ecological systems in a holistic transdisciplinary manner acknowledgements funding for this research comes through the niwa hamilton phd scholarship to aefa under coms1402 ecosystem based management of coasts and estuaries med received funding from the mbie natural hazards research platform contract x05x0907 climate change impacts on weather related hazards and the mbie under the resilience to nature s challenges national science challenge living at the edge programme 
26465,multiple dilemmas confound social ecological modelling this review paper focuses on two a modeller s dilemma associated with determining appropriate levels of model simplification and a dilemma of decision making relating to the use of models that were never designed to predict we analyse approaches for addressing these dilemmas as they relate to shallow coastal systems and conclude that wicked problems cannot be adequately addressed using traditional disciplinary or systems engineering modelling simplified inter and trans disciplinary models have the potential to identify directions of system change challenge thinking in disciplinary silos and ultimately confront the dilemmas of social ecological modelling keywords wicked problems agent based modelling post normal science social ecological systems shallow coastal systems 1 introduction this paper examines two dilemmas prevalent in environmental research a modeller s dilemma and a dilemma of decision making modellers face many dilemmas but a central issue relates to tradeoffs between simplifications that are necessary to represent certain characteristics of a system and the need also to represent intricacies within the system in sufficient detail in order to produce outputs that are useful in some way this dilemma is particularly challenging in the case of social ecological systems which have interacting physical ecological and social components how should these components be treated within models a related dilemma confounds environmental management models not intended for decision support have nevertheless become a crutch on which decision making often relies with insufficient critical consideration of model limitations in the planning process and application of models in ways that modellers may not have intended groeneveld et al 2017 kelly et al 2013 improved environmental planning requires progress in resolving these related dilemmas this paper reviews literature with an aim of identifying approaches of addressing and minimising these two dilemmas confronting modellers and decision makers the dilemmas are recognisable across much environmental research but we focus on shallow coastal systems particularly estuaries which are highly valued for providing essential ecosystem services and contributing to wider marine ecosystem function but are also vulnerable due to their physical properties e g shallow water depths and processes such as increasing population urbanisation and changes in climate and land use mcnamara and werner 2008a ipcc 2014 box 1 sets out some of the key concepts used in this review paper the approach has involved critiquing literature from diverse fields pertaining to social ecological modelling wicked problems trans and interdisciplinary research abm estuarine modelling and estuarine management the review is concerned with determining appropriate methods for approaching uncertainty in complex social ecological systems and selecting suitable techniques for modelling feedbacks between and interactions within these systems as set out in schlüter et al 2012 but with a specific focus on how the two dilemmas impact upon model form function and use systems engineering models differ from the other definitions in box 1 as they represent a single discipline way of approaching a problem this type of model represents a traditional approach to environmental management as opposed to a holistic post normal science approach schlüter et al 2012 set out the main differences between traditional and social ecological systems approaches to the management of human environment systems chief among which is that traditional methods utilise a command and control technique whereas social ecological systems management aim to enhance system resilience the three other concepts are fundamentally intertwined the post normal science approach is a methodology that often incorporates transdisciplinarity when attempting to address wicked problems in complex social ecological systems this review was undertaken using a post normal science approach reviewing literature from the fields of social ecological modelling wicked problems trans and interdisciplinary research agent based modelling abm estuarine modelling and estuarine management our review is concerned with determining appropriate methods for approaching uncertainty in complex social ecological systems and selecting suitable techniques for modelling feedbacks between and interactions within these systems as set out in schlüter et al 2012 but with a specific focus on how the two dilemmas impact upon model form function and use the review paper focuses on shallow coastal areas that occur at the downstream end of terrestrial drainage systems and are highly exposed to anthropogenically derived pollution davies 2015 millennium ecosystem assessment 2005a worldwide shallow coastal ecosystems are undergoing rapid changes creating a research imperative to understand the complex interrelationships between ecological physical and social processes that drive environmental change e g mcgranahan et al 2007 moser et al 2012 nicholls et al 2011 small and nicholls 2003 rapid urbanisation and increasing population in coastal areas can stress the existing social ecological systems while climate change is making these areas increasingly less suitable to sustain human populations crossett et al 2004 moser et al 2012 the consequences of sea level rise are already being felt in some of the least developed countries such as bangladesh where some 46 of the population lived within 10 m of mean sea level in 2007 mcgranahan et al 2007 however sea level rise is a global problem with 10 of world population concentrated in only 2 of the land area mcgranahan et al 2007 and 2 4 of global population at risk of displacement by sea level rise by the end of the 21st century nicholls et al 2011 anthropogenic alteration of natural systems makes natural processes e g rainfall flooding storm surge more complex by introducing runoff channelisation water treatment and discharge interfering with natural flow regulation in particular urbanised systems experience exacerbated impacts of relatively common events due to a combination of expanded impervious surfaces and channelised drainage networks baird 2009 schiff and benoit 2007 computational models can help understand these complexities and should therefore be an important resource for decision makers in avoiding or mitigating impacts that reduce environmental ecological social and economic resilience however progress has been limited by the two dilemmas modellers are confronted with the challenge of how to adequately represent the physical ecological and social dimensions of shallow coastal systems and decision makers are challenged by how to utilise models that are designed for social learning or developing system understanding when a predictive model is desired for decision making purposes our aim in this paper is to reconcile the two dilemmas by identifying optimum modelling approach es for fully integrated consideration of social ecological and geophysical systems in a single model to accomplish this we review literature so as to explore the potential for post normal science transdisciplinarity and particularly abm to understand complex environmental problems and suggest a way forward the review paper is structured as follows first the nature of the two dilemmas are elaborated and environmental problems are categorised as tame complicated and wicked see box 2 second literature relevant to modelling shallow coastal social ecological systems is reviewed providing a foundation for the third and final section that outlines a path forward for modelling 2 a modeller s dilemma the phrase modeller s dilemma was used by singh and mishra 2008 in relation to conflict resolution among various model averaging techniques used in groundwater modelling a different modeller s dilemma as discussed here concerns the struggle to determine the appropriate level of simplification and imitation of reality necessary to produce useful model outcomes while preserving the necessary particulars of the system to be studied in selecting an approach to model complex social ecological systems it is necessary to first determine the purpose of the modelling endeavour as discussed by kelly et al 2013 and then decide upon an appropriate level of model complicatedness murray 2007 sun et al 2016 following sun et al 2016 our use of the term complicatedness pertains to model structure whereas complexity is used to describe model outputs the choice between high and low model complicatedness is determined by multiple factors but the existing level of system understanding is perhaps most important murray 2007 points out that highly complicated models offer limited explanatory insight whereas highly simple models are unable to make numerically reliable predictions sun et al 2016 note that increasing the complicatedness of a model can result in a decrease in the complexity of model outputs reducing model complicatedness can be achieved by omitting or approximating poorly understood components and components that are believed to have minimal systemic effect but these types of simplifications may also reduce the ability of the model to achieve research goals by altering model complexity all models are by definition abstract representations simplifications of reality and no model can be considered correct but the degree of simplification employed in different models varies enormously murray 2007 2013 o sullivan et al 2012 simandan 2010 sun et al 2016 determining the appropriate level of simplification is especially pertinent for a social ecological model being developed with the intention of investigating social ecological change and the interactions between physical ecological and social components at various scales as these systems are inherently highly complex yet poorly understood and notoriously difficult to manage using a traditional command and control approach voinov et al 2016 in such poorly understood social ecological systems having a predictive or forecasting focus is difficult due to the presence of unknown system variables kelly et al 2013 a more realistic goal is to improve system understanding by developing a very simple model that is useful even if its assumptions and workings are not strictly correct o sullivan et al 2012 murray 2013 such simple models also go some way to mitigate a dilemma that faces decision makers 2 1 a dilemma of decision making computational models have come to occupy a position that they were never designed for treated as infallible by those who rely on them but not by their creators meadows and robinson 2002 an increasing reliance on models to guide decision making e g carnavale et al 2012 oxley et al 2004 suggests that decision makers prefer a predictive tool policy makers have historically had difficulty in comprehending and counteracting wicked problems davies 2015 head 2014 stirling 2010 exemplified by the detachment between the time of decision making and the subsequent effects being observed rammer and seidl 2015 in this context model results provide a decision making crutch models can make decisions for decision makers devolution of responsibility from decision maker to model can be traced to a number of factors including the search for simple solutions by decision makers that thwarts the longer term perspective necessary to approach wicked problems head 2014 as well as ignoring the unintended consequences of wicked problems there is frequent miscommunication about the role of both science lave 2015 and modelling schneider 1997 in decision making and policy development the purpose and practical limitations of a model must always be made clear to end users and decision makers schneider 1997 in turn decision makers have a responsibility to understand the practical limitations of a model and to avoid using it in ways and for reasons that it is incapable additionally while scientists may openly express the subjective elements of their work in professional discussions morgan and keith 1995 they should also do so in relation to decision making wright 2015 research suggests that including stakeholders and decision makers in the development and testing of models is a valuable way of improving their understanding of model purpose bousquet and le page 2004 schneider 1997 seidl 2015 voinov and bousquet 2010 yearley 2006 seidl 2015 discusses various methods of participation and potential benefits from participatory modelling in this regard 3 dilemmas in practice chesapeake bay modelling system shallow coastal areas are increasingly becoming the subject of modelling exercises aimed at deciphering potential impacts and ways to mitigate or avoid them dilemmas facing both modellers and decision makers are accompanying these efforts e g lloyd et al 2015 malzone et al 2009 one notable example of a major social ecological coastal modelling project is the chesapeake bay modelling system cbms developed by the chesapeake bay program it uses an ecosystem based management approach to simulate social ecological system function and the impacts of change at the catchment scale using a coupled component model boesch and goldman 2009 paolisso et al 2015 calibrated through direct comparison with observed condition the model was initially used to assist voluntary restoration projects but is increasingly guiding official watershed implementation plans that aim to reduce human impacts on the chesapeake bay ecosystem paolisso et al 2015 the modelling endeavour has expanded since its establishment in 1983 and now encompasses airshed watershed and a model of the shallow coastal portions of chesapeake bay itself e g cerco et al 2013 keisman and shenk 2013 linker et al 2013 the cbms program was not successful in achieving some of its early management goals however a more holistic and integrated management approach was implemented once managers recognised the interrelated nature of the issues facing the bay boesch and goldman 2009 similar management schemes based on the principles of post normal science ecosystem based management and transdisciplinary research are increasingly viewed as superior to traditional command and control management at addressing wicked problems biggs et al 2010 davies 2015 funtowicz and ravetz 1993 since its inception the cbms has become increasingly complicated as the airshed and watershed models have been linked to the original bay model paolisso et al 2015 the creation of the present coupled component model highlights the aforementioned modeller s dilemma of determining an appropriate level of model simplicity vs complicatedness and the dilemma of decision making concerning changing use of the model s over time the increasing complicatedness of the cbms highlights a major issue facing modellers a modeller s dilemma and impacting on decision makers a decision maker s dilemma when attempting to address wicked problems 4 categorising problems rittel and webber 1973 noted that scientific practices were failing to address issues characterised by uncertainty plurality interdependence and a lack of agreement over what the problem actually was they coined the term wicked problems as a means of conveying the inherent complexity of the joint system problem and showed that conventional methods of addressing comparatively tame relatively simple and solvable problems were inadequate when applied to more complex problems balint et al 2011 added complicated problems as a middle ground between tame and wicked and suggested that the three major features distinguishing wicked from tame and complicated problems are values risk and uncertainty we use complicated to refer to problems that are not necessarily simple or solvable tame but where research is able to gain greater traction and deliver more useful prediction and forecasting of system attributes than research addressing wicked problems use of the term wicked implies difficulty in understanding and addressing complex problems almost all problems in social ecological systems can be considered wicked in large part because human interventions intended or not add risk uncertainty and multiple values creating a challenging environment for coping with this complex reality box 2 illustrates some of the ways in which tame complicated and wicked problems can be approached through disciplinary interdisciplinary and transdisciplinary research tame problems are generally tackled by a single academic discipline whereas complicated problems are best addressed through interdisciplinary research folke 2006 and transdisciplinarity is emerging as an important approach for tackling wicked problems brown et al 2010 participatory modelling is an important transdisciplinary post normal science method of approaching wicked problems that has become increasingly important during recent years robson 2014 seidl 2015 5 modelling 5 1 revisiting modelling according to kelly et al 2013 the five potential purposes of modelling are developing system understanding facilitating social learning predicting the behavior of variables when other variables are known forecasting the behavior of variables when other variables are not known and management and decision making under uncertainty sun et al 2016 set out six similar purposes for modelling prediction theory building decision making case specific analysis to illuminate core dynamics and education social ecological models can be developed and subsequently used for any of these purposes or a combination thereof model developers and end users may view and utilise the same model in different ways schneider 1997 creating the potential for a dilemma of decision making to emerge many approaches to integrated inter and transdisciplinary social ecological modelling exist bayesian networks system dynamics modelling abm knowledge based modelling and coupled component modelling among others have diverse strengths and weaknesses and are subsequently suited to achieving different modelling aims gilbert et al 2008 kelly et al 2013 no approach to environmental modelling is applicable in all situations the principal consideration when selecting a modelling technique and level of complicatedness is determining the purpose of the research kelly et al 2013 sun et al 2016 for instance if the investigation is focused on developing greater system understanding or facilitating social learning or in research with a significant spatial component then abm is a suitable approach kelly et al 2013 however system dynamics modelling may be a better option in cases without major spatial constituents voinov and bousquet 2010 as a way of accommodating the strengths and avoiding the weaknesses of the available techniques coupled component modelling attempts to bring the best of each system together to facilitate interdisciplinary modelling albeit it in a highly complex manner kelly et al 2013 while coupled component modelling increases model complicatedness it can facilitate understanding of both individual interactions and their aggregate effects this is useful when attempting to improve understanding of the system coupled components models may however exacerbate a modeller s dilemma as the combination of existing models can easily result in the development of a highly complicated model when a simpler original model would be better suited to address the issues facing the system while system dynamics and abms are both well suited to developing system understanding and facilitating social learning the spatial properties of abm means that it is generally superior for social ecological applications bousquet and le page 2004 kelly et al 2013 sun et al 2016 voinov and bousquet 2010 abms tend to be more complicated than system dynamics models but are more revealing of the interactions between individual variables and agents clifford 2008 o sullivan et al 2012 the approach selected should be determined by whether the research project is more interested in these individual interactions or only aggregate effects kelly et al 2013 a typical aim of modelling is to achieve a level of consistency between model components particularly scale as it is simpler to investigate interactions between the constituent parts when they are similarly scaled murray et al 2009 explicit numerical reductionism involves modelling on the smallest and fastest scales whereas top down exploratory modelling operates on the largest and slowest scales murray et al 2009 as different components may act and interact at vastly different scales utilising only a single scale risks oversimplification of some components if top down modelling is used or over complication of model structure if numerical reductionism is applied dealing with this requires use of a scale appropriate for the system under consideration a scale that captures the requisite level of complexity needed to address the problem being investigated o sullivan et al 2012 our literature review suggests that key to social ecological modelling endeavours are four actions coming to know the system under consideration identifying the constituent components of the system identifying the connections between these components and reconciling both component scale and disciplinarity attempts at modelling for the purpose of developing system understanding tend to limit the number of components included in the model or reduce their scale or other attributes e g becu et al 2003 huang et al 2014 whereas attempts at quantifying the nature of interactions between components tend to have increased complicatedness in many situations where some facets of system form and function are not well understood the inclusion of poorly understood components will reduce numerical precision and the robustness of model outputs some of these unknown quantities can be approximated gonzalez et al 2008 or proxies used drobinski et al 2012 mcgranahan et al 2007 but when they cannot limiting the number of model components can both increase model accuracy and enhance system understanding 5 2 modelling shallow coastal systems when developing a model to investigate changes in shallow coastal systems the developers should be explicit as to whether it is designed to investigate the mean values of system change or the extreme conditions caused by these changes mean values drive an average condition and are widely used in models operating over decadal or longer time scales e g holgate 2007 nicholls et al 2008 incremental stressors occurring over a longer timeframe can trigger state changes in shallow coastal social ecological systems hughes et al 2017 for example the impacts of rising water temperatures on coral reefs or a gradual long term increase in nitrogen in estuarine systems however investigating the incremental changes that produce average system conditions do not shed light on the extreme events that might provide the impetus for sudden state changes in a system in local and regional scale investigations of climate change impacts on coastal areas the extreme values constitute the greatest risk to people and property subsequently they are among the best studied facets of climate change e g chini and stansby 2012 kirwin et al 2008 nicholls et al 2011 modelling the impacts of environmental change on shallow coastal social ecological systems occupies a position near point 3 in fig 1 the problem is wicked and multiple disciplines need to cooperate and contribute toward addressing it berkes 2010 learmonth et al 2011 utilising simple computational modelling for shallow coastal systems research allows for development of understanding of system form and function while avoiding unnecessary complicatedness in model design testing and operation modelling specific components of the social ecological aspect of coastal catchments can allow researchers to develop understanding of the potential directions of climate change environmental change and changes in collective human behavior on the shallow coastal areas of the system such a model may be intended for use in forecasting or predicting system responses but there are significant challenges associated with this aim local scale research is much more likely to achieve success if it has alternate purposes such as facilitating social learning among stakeholders or to assist but not drive decision making under uncertainty in the future if such a model is to be used in decision making it is vital to explain to the decision makers the reasons a model was constructed what its limitations are and that model intent may not be forecasting or prediction schneider 1997 rather that it can demonstrate the potential for non linear and complex responses to the wicked problem of climate change such a model could be used to guide decision making by encouraging the fostering of resilience within the social ecological system under consideration murray et al 2009 5 3 what models suit in a recent review of participatory modelling ventures seidl 2015 found participatory abm to be the most commonly used participatory modelling approach and simon and etienne 2010 concluded that abm is the most appropriate modelling approach to facilitate stakeholder participation in the literature abm stands out as the technique most suited to investigating dynamic human environmental interactions in a shallow coastal social ecological system due to its explicit focus on investigating interactions between individuals other techniques are more concerned with analysis of the aggregated effects of such interactions kelly et al 2013 schlüter et al 2012 however abm approaches often produce more complicated models than other approaches due to the large numbers of model inputs sun et al 2016 exacerbating the modeller s dilemma of significance to the intricacy of the model are simulation of the interactions between inputs a continually changing spatial setting and potentially changing boundary conditions bousquet and le page 2004 kelly et al 2013 o sullivan et al 2012 abms can expand researcher and stakeholder understanding of complex social ecological systems by simulating interactions between autonomous entities within the system making this approach particularly appealing for modelling the interaction between social and ecological agents in coastal systems research e g luo et al 2012 mcnamara and keeler 2013 however depending on the level of model simplification desired complicated model structure can be considered a weakness of an abm approach when addressing the modeller s dilemma kelly et al 2013 o sullivan et al 2012 sun et al 2016 hence there is a trade off when using an abm approach between the strength of simulating agent interactions and the potential weakness of high model complicatedness sun et al 2016 the inability of abms to accurately predict outcomes without making the model overly complicated due to the inclusion of poorly understood system components is a limitation kelly et al 2013 sun et al 2016 as stated this can be remedied by reducing model complicatedness but in doing so the modeller runs the risk of also reducing model complexity which may adversely impact on research outcomes while the intricacy of abm makes it a complicated and time consuming approach its significant strength in developing system understanding can often justify these factors o sullivan et al 2012 if prediction of system behavior is the purpose of modelling more suitable approaches than abm are available such as system dynamics and potentially coupled component modelling when developed in conjunction with stakeholders and or end users an abm can help mitigate the dilemma of decision making by explicitly demonstrating model limitations to end users dereynier et al 2010 robson 2014 this kind of end user participation in model development can also mitigate the modeller s dilemma as all parties collaboratively decide upon an appropriate level of complicatedness rather than just the modeller determining this agent behavior and interactions are fundamental concerns in developing understanding and modelling coastal social ecological system structure bousquet and le page 2004 abms provide a well founded framework aimed at incorporating this integration of behavior and interactions as well as stakeholder knowledge and perspectives within a numerical model berger 2001 elsawah et al 2015 fulton et al 2015 kelly et al 2013 voinov and bousquet 2010 voinov et al 2016 their ability to handle spatial data and dynamics gives abms an advantage over other approaches to modelling kelly et al 2013 sun et al 2016 abm has been used to model various social ecological systems at the catchment scale e g barreteau et al 2001 barthel et al 2009 becu et al 2003 and is particularly useful when investigating human settlement and other social ecological systems o sullivan et al 2012 sun et al 2016 modelling of shallow coastal environments using an abm approach is also becoming increasingly common e g brush and nixon 2010 canal vergés et al 2014 zhang and gorelick 2014 6 reintroducing social elements wicked problems are ubiquitous within interconnected social ecological systems balint et al 2011 brown et al 2010 turnpenny et al 2009 shallow coastal social ecological systems are highly interconnected and often produce non linear emergent responses to a change in one system component resulting in changes across scales and affecting multiple system attributes mcnamara and werner 2008a moser et al 2012 williams et al 2013 hence the human element must be meaningfully embraced in shallow coastal social ecological modelling which requires a multifaceted approach historically when disciplinary research programmes have attempted to grapple with wicked problems that transcend disciplinary boundaries one discipline tends to dominate the discourse and research agenda with the result that either human or non human system attributes are poorly incorporated or oversimplified to the point of irrelevance davies 2015 lave et al 2014 turner ii et al 2016 previous work on resilience in social ecological systems has tended to either disconnect the social components of systems from the whole brown gaddis et al 2010 reduce them to economic factors or simple demographics cote and nightingale 2012 or represent the connections between the subsystems as unidirectional filatova et al 2013 while failing to acknowledge the singular complex and intertwined entity that is a social ecological system berkes 2007 this pitfall can be avoided by investigating the nature of relevant human variables from the outset of research particularly through application of a post normal science participatory modelling approach funtowicz and ravetz 1993 turnpenny et al 2009 voinov et al 2016 stakeholder participation provides the opportunity to learn about concealed characteristics of the system voinov and brown gaddis 2008 such as how resident and non residents utilise and interact with a shallow coastal system social ecological research can use stakeholder participation to make visible the range of values held davies 2015 balint et al 2011 and to build a shared understanding of a system and the issues facing it both for social learning purposes and to link findings to decision making processes fulton et al 2015 yearley 2006 mitigating the dilemma of decision making the knowledge derived from stakeholders participants and end users can be used by modellers to develop a richer understanding of the system so that the model under development can more accurately represent the social characteristics of the system and assist in developing ways to address the wicked problems afflicting it an analysis of integrated coastal management in new zealand found that increased collaboration across the science policy interface facilitates the production of higher quality science and better management outcomes for coastal zones bremer and glavovic 2013 when studying a wicked problem separate handling of the social components could easily result in unrealistic representation of system functions subsequent production of imprecise model outputs and an exacerbation of the modeller s dilemma through inclusion of unnecessary variables or oversimplification of the social system cote and nightingale 2012 noted that work on resilience in social ecological systems has proceeded in remarkable isolation from human geography and other social sciences despite the notable commonalities in research foci a holistic broad scale envisioning of the system using a post normal science approach is desirable when researching and modelling social ecological impacts of climate change on shallow coastal systems viewing shallow coasts as comprised of separate social geophysical ecological economic political etc subsystems is commonplace in the anglophone world as a way of making sense of complexity castree 2014 in practice there is considerable difference between understanding a system as the sum of its parts and dealing with system complexity in a way that does not recognise artificial conceptual boundaries between subsystems in developing simple models that aim to grow understanding of an entire shallow coastal social ecological system there is little point in treating perceived subsystems as distinct entities the components of any system are not solely responsible for its behavior rather the interactions between components create system form and function castree 2014 thrift 1996 in simandan 2010 393 and those components need not belong to any one category or subsystem simandan 2010 391 writing on contingency and necessity within human belief systems highlights a major issue with a non holistic research approach binary distinctions yield artificial borders and as soon as one faces borders one faces the quandary of border cases and the ensuing temptation to fudge them so as to fit neatly into one box or the other true transdisciplinary environmental research ought to accept that boundaries between social ecological and geophysical systems are socially constructed and that their use may lead to potentially inadequate representations of any system as a whole traditional disciplinary understandings and representations of subsystems are not obsolete epistemic communities remain vital to disciplinary and interdisciplinary knowledge production but the different disciplinary viewpoints need to be proactively discussed and blended in the early stages of a research project turner ii et al 2016 this review paper indicates that the best path is to 1 identify those variables in a system whose interactions have the greatest influence on whatever is of interest and 2 model their interrelations lynam et al 2007 and effects on overall system form and function regardless of which subsystem they are perceived to occupy such a holistic treatment of the overall social ecological system can mitigate the modeller s dilemma as the inclusion of only the necessary variables reduces model complicatedness in turn simpler models can mitigate the dilemma of decision making as the model can be easier to comprehend and limitations of the model will be more obvious 7 a way forward participatory abm can help to mitigate the dilemma of decision making by ensuring that stakeholders and decision makers are engaged in the development of model form and function and so understand when it is and is not appropriate to use a model to assist with the decision making process by encouraging end user participation the modeller s dilemma can be lessened as the modeller no longer needs to give as much concern to misuse of the model and has more leeway to determine how complicated model structure should be so as to appropriately model the system in question shallow coastal ecosystems have unknown variables and myriad complex interactions across human and biophysical domains hence social ecological models are more suited to producing information on the likely direction of environmental changes through developing system understanding than to making accurate predictions of exactly what change will occur models may be heuristic imperfect representations of reality but they can serve to achieve research and environmental management goals murray 2007 in social ecological systems not all system components need to be modeled in order to investigate outcomes of interactions between other system components in a transdisciplinary setting developing a model allows for improving researcher and stakeholder understanding of the system in question which in turn helps in addressing the problems affecting the system high numerical precision of outputs might be achieved through increasing model complicatedness but this is less important in this type of work than the robustness of results pertaining to the directions of change the need for balance between model simplification and complicatedness is mirrored in efforts to achieve parity between the various disciplines involved wicked problems in social ecological systems cannot be adequately addressed using traditional disciplinary or systems engineering modelling due to the interplay of social variables wu et al 2015 instead use of interdisciplinary and transdisciplinary modelling enables a holistic systems view this is a prerequisite for grappling with wicked problems in shallow coastal social ecological systems anthropogenically induced changes to shallow coastal systems are present worldwide yet the changes that are occurring are often poorly understood these changes do not occur in isolation but impact upon other facets of these systems understanding how these changes occur and spread is vital to avoiding or reducing the impacts of human actions simple models developed for the purpose of identifying directions of system change under various stressors are a valuable tool in achieving this inter or transdisciplinary research that considers the relevant factors in system form function and change can help challenge the thinking in disciplinary silos where knowledge has historically been produced and can help societies confront wicked environmental problems a post normal science approach particularly participatory modelling facilitates the development of understanding of complex systems voinov et al 2016 and provides a valuable tool to help address the issues faced by social ecological systems in a holistic transdisciplinary manner acknowledgements funding for this research comes through the niwa hamilton phd scholarship to aefa under coms1402 ecosystem based management of coasts and estuaries med received funding from the mbie natural hazards research platform contract x05x0907 climate change impacts on weather related hazards and the mbie under the resilience to nature s challenges national science challenge living at the edge programme 
26466,high resolution raster data for land cover mapping or change analysis are normally acquired through satellite or aerial imagery apart from the incurred costs the available files might not have the required temporal resolution moreover cloud cover and atmospheric absorptions may limit the applicability of existing algorithms or reduce their accuracy this paper presents a novel technique that is capable of mapping garrigue and or phrygana vegetation as well as karst or ground armour terrain in photos captured by a digital camera by including a reference pattern in every frame the automated method estimates the total area covered by each land type pixel based classification is performed by supervised decision tree methods although the intention is not to replace traditional surface cover analysis the proposed technique allows accurate land cover mapping with quantitative estimates to be obtained since no expensive hardware or specialised personnel are required vegetation monitoring of local sites can be carried out cheaply and frequently the developed proof of concept is tested on photos taken in thirteen different sites across the maltese islands keywords machine learning pattern recognition land cover mapping decision trees 1 introduction quantitative vegetation cover estimates over an area of interest are normally obtained through satellite or aerial imagery although high resolution raster sets can be acquired the data collection processes can be very expensive moreover sampling might not be carried out at the required frequency or time of year remote sensing of the ground from a high altitude may be hindered by clouds or distortions introduced by atmospheric absorptions despite all these challenges a lot of ground breaking and pioneering research to automatically cluster different types of land or to detect cover change from multi spectral data have been made apart from the scientific applications this information is of value to stakeholders as well as policy and decision makers for environmental and resource management lim et al 2009 punia et al 2011 this work presents a novel land cover mapping technique that is capable of determining the total area covered by garrigue and or phrygana type vegetation regions in images captured around the maltese islands non vegetated regions composed of karstic terrain or areas with predominant ground armour terrain are also detected data over the region of interest is acquired at regular intervals by a digital single lens reflex dslr camera mounted perpendicular to the ground while such an approach may not contribute to global analysis it allows for an investigation of local vegetation variation the results may also be correlated to other measurements such as for instance bird sightings the presented method is fully automated does not involve a lot of heavy computation and can be run on a desktop computer with average specifications processing hundreds of photos only require a few minutes to obtain spatial dimensions from the pixel representations a small reference pattern is photographed in each image after the detection and masking of the corresponding region the remaining pixels are categorised into different classes by a supervised classification algorithm the total surface area covered by vegetation is then computed the use of inexpensive hardware for land cover estimation have already been tried and tested lim et al 2009 in the work presented by chan and paelinckx 2008 a hyperspectra imagery sensor is used to classify ecotopes although different methodologies have been proposed the techniques almost always require the sensor to be fixed with an aircraft flying at a constant altitude so that the pixel size remains constant data captured over non flat terrain might require the application of transforms in the pre processing stage studies by waske and braun 2009 and rodriguez galiano et al 2012 use synthetic aperture radar sar and landsat data respectively while the information by sar can be used in almost any weather conditions this is frequently contaminated by noise moreover the revisit time and spatial resolution might not be adequate when small areas are to be studied the adopted classification process categorises regions based on the red green and blue pixel values other methods that adopt a feature or object based approach have been suggested rego and koch 2003 yoon et al 2005 syed et al 2005 however a simple rule based system that is fast can handle big data and can differentiate well between just two classes is implemented the applicability and accuracy of decision trees for the classification of similar datasets have already been demonstrated punia et al 2011 hansen et al 1996 schneider et al 2010 studies by chan and paelinckx 2008 rodriguez galiano et al 2012 and stumpf and kerle 2011 investigated the use of random forests which involve the construction of a number of trees a good overview and comparative study of the various machine learning techniques that can be applied is given in vatsavai et al 2011 waske et al 2012 also present a tool that is capable of classifying remotely sensed images this supports various image types and classification models however no details are given with respect to the spatial area coverage details on the adopted methodology for the generation of the dataset and the contrast enhancement performed on each image are discussed in section 2 the image capturing process and how the overlapping of frames was avoided are also described the processes involved for the automatic detection of the reference pattern are then presented in section 3 the training samples used the classification method and the obtained results are put forward in section 4 this is followed by a brief discussion and planned future work in section 5 2 data collection and enhancement the main goal of this work is to compute accurate estimates of land areas covered by garrigue and or phrygana and non vegetated regions from a large number of images in this study photos captured from thirteen different sites across the maltese islands are processed fig 1 shows a map of the locations while table 1 presents the respective number of photos taken at each site the camera was set at nadir angle although photos captured by this method have a small field of view fov the site to be studied can easily be covered by taking more images at each location data was recorded at regular intervals in a grid pattern and at a height of about two meters after determining the fov of the camera at its widest angle the spatial distance between each photo was determined this was set such as not to have overlapping frames the extent of each frame was also verified manually to ensure that no region was photographed more than once by the central limit theorem the capturing of images in this way allowed for accurate and statistically significant classification results to be obtained the presented algorithm can process images captured by any camera unlike most of the commonly applied vegetation classification methods the infra red channel is not required this makes possible the use of sensors that are just sensitive to the red green and blue wavelengths the parameters are not site specific and hardware calibration is not required for this study images were captured using a canon powershot s3 is that houses a digic ii 6 2 mp ccd sensor the attached lens had a focal length of 36 mm 432 mm with very low distortion as demonstrated in fig 2 at wide angle mode this optical system introduces a 1 1 barrel distortion while telephoto images have no noticeable pincushion effect joinson 2016 the pixels at the edges of the captured image were only marginally effected and affine transformation methods to correct for this were not applied cells at nadir and at the edges of the raster set were considered to be of the same dimensions the reference pattern used to calculate the spatial size of each pixel was randomly positioned in each frame therefore small errors introduced through lens distortion averaged out to maximize the fov the sensor was attached to an extended monopod and positioned so as to face the ground in a perpendicular manner use of the timer was made to release the shutter automatically the camera was set on the auto program mode to automatically adjust the shutter speed and aperture width images were captured in good lightning conditions and such settings always gave optimum results auto focusing was carried out through the lens ttl mode and in group point so that all parts of the images were sharp sensor noise was negligible the first step involves contrast enhancement through software to augment and normalise colour variation across the dataset as described in section 4 2 classification is based on the red green and blue channels improving the visual separation between vegetated and non vegetated zones in colour space allow better results to be obtained rgb data is projected onto the lab model in which the l channel represents the luminance the a channel shows the variation from green to red while the b channel shows the variation from blue to yellow in particular the l channel is equalised such that one percent of the pixels attain extreme values at both high and low ends of the scale the data is converted back and saved as rgb fig 3 shows part of an image and the corresponding lab channels before and after the luminance boost operation 3 reference pattern detection extraction of length information is made possible through the chequered pattern shown in fig 4 in particular this was scaled such as to fit onto an a3 paper 297 mm 420 mm the next step of the algorithm is to detect and extract information from this grid this is assumed to be over a minimum of p pixels for this study a minimum of 150 150 pixels was considered and p was set to 22 500 3 1 pattern localisation detection of the pattern is performed on a binary image derived from the greyscale composite different threshold levels from 0 9 down to 0 1 are automatically tested until the total number of white pixels exceeds the predetermined limit of p 5 that is 112 500 the pixels that define the perimeters of the resulting regions in the binary image are then identified touching or very close boundaries are joined to form complete constructions polygons enclosing less than p pixels are assumed not to represent the reference pattern and are not considered any further in all experiments such regions were all true negatives and encoded small patches of vegetation through colonization by garrigue and or phrygana biotopes or assemblages exposed bare rock or areas characterized by ground armour p should be proportional to the number of pixels that cover the pattern and to the height from which the images are captured if this is too small an incorrect area might be selected and the grid lines identification process will fail if the number is too large then the actual pattern area might cover less pixels than the set threshold and is not selected the perimeter associated with the chequered pattern is expected to have a rectangular shape this is identified by selecting the object found to have the least difference between the area enclosed by the polygon and the corresponding convex hull area the matching pixels over the selected region are extracted from the greyscale version and are binary thresholded at 75 the maximum value a mask with the same dimensions as the input image that encodes the position of the pixels of the pattern is then created the extracted region is processed by a canny edge detector to highlight the outline of each grid cell in fig 5 the identified pattern region the corresponding extracted pattern and the output from the edge detector for four different images are shown extensive tests prove that the pattern is accurately detected irrespective of its position orientation and angle in the image 3 2 formalisation of the grid pattern the next step involves parameterisation of the detected lines this is achieved through the application of hough transformation as demonstrated in fig 6 the coordinates of the high intensity points within the accumulator space are determined and the corresponding line equations are obtained in this study projection was applied between 90 and 90 at one degree resolution contributions from random noise and edge artefact made insignificant contributions to the accumulator space and did not influence line detection lines with a steep gradient and which make an angle of less than 30 to the normal are considered as vertical segments with a small gradient and with angles greater than 60 to the normal are taken to have a horizontal orientation the points of intersection between horizontal and vertical pairs are then computed extra peaks considered from the accumulator space will result in nearly parallel lines over the same grid boundary this is accounted for by grouping all intersecting points within a small radius of each other in this study points within a radius of 10 pixels were grouped together such a value should be set according to the sharpness of the edges of the reference pattern if these are blurry then a larger number might be required to obtain single line edges the line segments and the corresponding intersection points extracted from the hough projection shown in fig 6 are presented in fig 7 the accumulator space the detected lines and the points of intersection for the four images shown in fig 5 are put forward in fig 8 the mean perpendicular distance between each pair of points is computed in terms of numbers of pixels this result is taken to represent the real length of each grid cell in the reference pattern and allows for the actual dimensions of the picture elements to be determined 3 3 pixel to real space conversion the 2413 photos considered in this work had a resolution of 2816 2112 pixels detection of the chequered pattern by the method described above was found to be successful 99 047 of the time the 24 photos for which the method failed had the pattern covered by the shadow of tall vegetation the average surface area captured by each photo in the dataset was found to be 3 7396 m2 fig 9 presents a summary of the processes involved to transform pixel dimensions into real length measurements 4 classification method following pattern detection and the elimination of the corresponding elements the remaining pixels are divided into two groups according to whether they show a vegetated or a non vegetated region such classification is performed through a model which is trained to make predictions based on the red green and blue channel intensities use of a supervised decision tree learning algorithm is adopted samples are classified after traversing the branches from the root to a leaf node according to the met conditions the tree is learnt by splitting the provided labelled examples into subsets according to the attribute value various branches are built by recursively repeating this process until all elements in each group have the same target value or when splitting the data no longer increases the prediction accuracy mitchell 1997 a number of decision tree learning algorithms are available some methods allow for inequality tests and can work on noisy and incomplete information provided that the training set represents a full description of the classes to be modelled the constructed tree can be used as a rule set for predicting the category of unknown samples 4 1 generation of training dataset in this study separate training sets were generated for each location five to ten photos from each site were selected and vegetated and non vegetated areas were manually marked by using photo editing software in particular the paintbrush tool was used to indicate garrigue and or phrygana pixels with pure green red 0 green 255 blue 0 and karstic or ground armour sections with pure blue red 0 green 0 blue 255 such images were saved as lossless bitmap files to retain the exact given intensities a script that reads the masked training files and extracts the locations of the marked pixels was then implemented the corresponding rgb channel intensities were obtained from the original photos this method allowed a good and significant training set to be easily generated some examples of the defined training masks are shown in fig 10 4 2 model generation and validation once the training and target vectors are provided the algorithm randomises the entries and proceeds to construct the classification model from 70 of the samples the remaining examples are used for testing although classification is done across two groups the model is trained to output real values between 0 0 and 1 0 predictions close to 0 0 are taken to represent vegetation while pixels assigned a value close to 1 0 are considered to be garrigue and or phrygana to maintain a strong confidence in the classifier only values below the 0 25 or above the 0 75 thresholds are considered pixels with values outside this range are left as unclassified this to ensure that only cells classified with a high degree of accuracy are assigned to the respective class such an approach also allows for the tracking of incorrectly classified pixels the outputs of the test vectors are then compared to the actual target value this allows for a classification confidence to be computed for each class at each site considered table 2 presents the percentages of correctly classified pixels over the testing set used the percentage of unclassified pixels and the pearson correlation coefficient between the actual and the predicted classes are also shown as can be seen from the last column of this table a high correlation between the predicted and the target values was obtained for all sites the confidence of each model can also be confirmed from the low percentage of pixels that could not be classified 4 3 cluster results after convergence the classifier is used on other photos captured from the same site land mapping is followed by area estimation the number of elements assigned within each class is multiplied by the pixel surface area computed from the reference pattern to obtain estimates of the total garrigue and or phrygana coverage and the total of karstic or ground armour terrain in square meters samples of original photos and the corresponding classification results are presented in fig 11 the proposed method does not restrict the height of the camera above ground level although the reference pattern might scale over a different number of pixels across images the surface area it covers in m2 should always approach the same constant since the printed pattern had dimensions of 0 297 m 0 420 m in this case the expected value was of 0 12474 m2 as shown by the histogram in fig 12 the computed spatial surface area covered by the pattern was very close to the expected value 5 discussion and future work in this study a tool for land cover mapping that computes an estimate for the surface area coverage was presented actual pixel sizes are obtained through the use of a reference pattern which is photographed in all images although vegetation percentage coverage can be carried out by an expert such a task is very time consuming and sometimes subjective the proposed technique provides a quick quantitative alternative that can be carried out with cheap resources while vegetation cover is normally computed through the use of satellite and aerial images the resolution provided by such methods is not always adequate especially when very small regions are to be studied moreover commonly used vegetation indices such as the normalised difference vegetation index ndvi and the enhanced vegetation index evi make use of the thermal infra red band this is not always available at the same resolution as the other channels although traditional land cover analysis cannot be fully replaced the proposed method proved to provide encouraging results in a gis environment as discussed in section 2 seasonable variability can be investigated through the re capturing and processing of images during the winter months remotely sensed satellite images are contaminated by clouds fig 13 demonstrates the ndvi computed from landsat 7 after the scan line correlator slc problem from landsat 8 and from sentinel 2 these missions have a resolution of 30 m and 10 m respectively results from data captured on a typical winter day are also presented although these bands encode the highest resolution available the regions of interest cover a small amount of grid cells this restrict studies that target to investigate the short term vegetation cover change over small regions the proposed technique allows any region to be studied throughout the year conventional vegetation indices assign a normalised value to each pixel these are commonly followed by supervised or unsupervised machine learning classification methods to categorise each element with a particular land type the presented method combines these two steps by automatically classifying each pixel with the closest group defined in the training set the correlation values presented in table 2 indicate a very strong agreement between the manual and automatic classifications as demonstrated in section 3 3 the reference pattern was detected in the majority of the images planned future work include the use of mosaicking techniques that automatically stitch images together this will drastically improve image acquisition time and eliminates problems associated with the avoidance of overlapping regions the use of a higher end camera model that automatically geo tags the captured images will also help the applicability of other classification models such as neural networks support vector machines and fuzzy logic can also be investigated such classifiers can be trained to distinguish between other classes such as for instance water forests or different types of agriculture the model will be able to learn the colour components of different land cover types specified in the training samples this study can also be easily adapted to images captured by a down facing camera at higher altitudes to test such an approach the presented pattern matching algorithm was applied on frames taken by a dji phantom 4 drone data was acquired from 10 0 m 12 5 m 15 0 m 17 5 m and 20 0 m as shown in fig 14 the pattern in photos captured from an altitude of less than 20 0 m was detected and the dimensions of each pixel could be calculated however as the distance from the ground increased the pattern became too small and extended over very few pixels moreover in such cases the geometrical distortions due to non flat terrains cannot be ignored while drones are fast becoming a source of aerial data the provided telemetry is normally with respect to the point from which the aircraft lifted off and the actual distance to ground might vary in such cases the use of a reference pattern for calibration will still be required 6 software availability the developed toolbox can be requested from the corresponding author by email and will be provided free of charge all functions were written in matlab version 2015a which is required to run the provided m and library files no special hardware is necessary all tests presented in this study were run on a macbook pro with an intel core i5 processor 2 9 ghz and 8 gb of ram the full or a subset of the image dataset can also be provided as jpeg files all files are available as from 2017 
26466,high resolution raster data for land cover mapping or change analysis are normally acquired through satellite or aerial imagery apart from the incurred costs the available files might not have the required temporal resolution moreover cloud cover and atmospheric absorptions may limit the applicability of existing algorithms or reduce their accuracy this paper presents a novel technique that is capable of mapping garrigue and or phrygana vegetation as well as karst or ground armour terrain in photos captured by a digital camera by including a reference pattern in every frame the automated method estimates the total area covered by each land type pixel based classification is performed by supervised decision tree methods although the intention is not to replace traditional surface cover analysis the proposed technique allows accurate land cover mapping with quantitative estimates to be obtained since no expensive hardware or specialised personnel are required vegetation monitoring of local sites can be carried out cheaply and frequently the developed proof of concept is tested on photos taken in thirteen different sites across the maltese islands keywords machine learning pattern recognition land cover mapping decision trees 1 introduction quantitative vegetation cover estimates over an area of interest are normally obtained through satellite or aerial imagery although high resolution raster sets can be acquired the data collection processes can be very expensive moreover sampling might not be carried out at the required frequency or time of year remote sensing of the ground from a high altitude may be hindered by clouds or distortions introduced by atmospheric absorptions despite all these challenges a lot of ground breaking and pioneering research to automatically cluster different types of land or to detect cover change from multi spectral data have been made apart from the scientific applications this information is of value to stakeholders as well as policy and decision makers for environmental and resource management lim et al 2009 punia et al 2011 this work presents a novel land cover mapping technique that is capable of determining the total area covered by garrigue and or phrygana type vegetation regions in images captured around the maltese islands non vegetated regions composed of karstic terrain or areas with predominant ground armour terrain are also detected data over the region of interest is acquired at regular intervals by a digital single lens reflex dslr camera mounted perpendicular to the ground while such an approach may not contribute to global analysis it allows for an investigation of local vegetation variation the results may also be correlated to other measurements such as for instance bird sightings the presented method is fully automated does not involve a lot of heavy computation and can be run on a desktop computer with average specifications processing hundreds of photos only require a few minutes to obtain spatial dimensions from the pixel representations a small reference pattern is photographed in each image after the detection and masking of the corresponding region the remaining pixels are categorised into different classes by a supervised classification algorithm the total surface area covered by vegetation is then computed the use of inexpensive hardware for land cover estimation have already been tried and tested lim et al 2009 in the work presented by chan and paelinckx 2008 a hyperspectra imagery sensor is used to classify ecotopes although different methodologies have been proposed the techniques almost always require the sensor to be fixed with an aircraft flying at a constant altitude so that the pixel size remains constant data captured over non flat terrain might require the application of transforms in the pre processing stage studies by waske and braun 2009 and rodriguez galiano et al 2012 use synthetic aperture radar sar and landsat data respectively while the information by sar can be used in almost any weather conditions this is frequently contaminated by noise moreover the revisit time and spatial resolution might not be adequate when small areas are to be studied the adopted classification process categorises regions based on the red green and blue pixel values other methods that adopt a feature or object based approach have been suggested rego and koch 2003 yoon et al 2005 syed et al 2005 however a simple rule based system that is fast can handle big data and can differentiate well between just two classes is implemented the applicability and accuracy of decision trees for the classification of similar datasets have already been demonstrated punia et al 2011 hansen et al 1996 schneider et al 2010 studies by chan and paelinckx 2008 rodriguez galiano et al 2012 and stumpf and kerle 2011 investigated the use of random forests which involve the construction of a number of trees a good overview and comparative study of the various machine learning techniques that can be applied is given in vatsavai et al 2011 waske et al 2012 also present a tool that is capable of classifying remotely sensed images this supports various image types and classification models however no details are given with respect to the spatial area coverage details on the adopted methodology for the generation of the dataset and the contrast enhancement performed on each image are discussed in section 2 the image capturing process and how the overlapping of frames was avoided are also described the processes involved for the automatic detection of the reference pattern are then presented in section 3 the training samples used the classification method and the obtained results are put forward in section 4 this is followed by a brief discussion and planned future work in section 5 2 data collection and enhancement the main goal of this work is to compute accurate estimates of land areas covered by garrigue and or phrygana and non vegetated regions from a large number of images in this study photos captured from thirteen different sites across the maltese islands are processed fig 1 shows a map of the locations while table 1 presents the respective number of photos taken at each site the camera was set at nadir angle although photos captured by this method have a small field of view fov the site to be studied can easily be covered by taking more images at each location data was recorded at regular intervals in a grid pattern and at a height of about two meters after determining the fov of the camera at its widest angle the spatial distance between each photo was determined this was set such as not to have overlapping frames the extent of each frame was also verified manually to ensure that no region was photographed more than once by the central limit theorem the capturing of images in this way allowed for accurate and statistically significant classification results to be obtained the presented algorithm can process images captured by any camera unlike most of the commonly applied vegetation classification methods the infra red channel is not required this makes possible the use of sensors that are just sensitive to the red green and blue wavelengths the parameters are not site specific and hardware calibration is not required for this study images were captured using a canon powershot s3 is that houses a digic ii 6 2 mp ccd sensor the attached lens had a focal length of 36 mm 432 mm with very low distortion as demonstrated in fig 2 at wide angle mode this optical system introduces a 1 1 barrel distortion while telephoto images have no noticeable pincushion effect joinson 2016 the pixels at the edges of the captured image were only marginally effected and affine transformation methods to correct for this were not applied cells at nadir and at the edges of the raster set were considered to be of the same dimensions the reference pattern used to calculate the spatial size of each pixel was randomly positioned in each frame therefore small errors introduced through lens distortion averaged out to maximize the fov the sensor was attached to an extended monopod and positioned so as to face the ground in a perpendicular manner use of the timer was made to release the shutter automatically the camera was set on the auto program mode to automatically adjust the shutter speed and aperture width images were captured in good lightning conditions and such settings always gave optimum results auto focusing was carried out through the lens ttl mode and in group point so that all parts of the images were sharp sensor noise was negligible the first step involves contrast enhancement through software to augment and normalise colour variation across the dataset as described in section 4 2 classification is based on the red green and blue channels improving the visual separation between vegetated and non vegetated zones in colour space allow better results to be obtained rgb data is projected onto the lab model in which the l channel represents the luminance the a channel shows the variation from green to red while the b channel shows the variation from blue to yellow in particular the l channel is equalised such that one percent of the pixels attain extreme values at both high and low ends of the scale the data is converted back and saved as rgb fig 3 shows part of an image and the corresponding lab channels before and after the luminance boost operation 3 reference pattern detection extraction of length information is made possible through the chequered pattern shown in fig 4 in particular this was scaled such as to fit onto an a3 paper 297 mm 420 mm the next step of the algorithm is to detect and extract information from this grid this is assumed to be over a minimum of p pixels for this study a minimum of 150 150 pixels was considered and p was set to 22 500 3 1 pattern localisation detection of the pattern is performed on a binary image derived from the greyscale composite different threshold levels from 0 9 down to 0 1 are automatically tested until the total number of white pixels exceeds the predetermined limit of p 5 that is 112 500 the pixels that define the perimeters of the resulting regions in the binary image are then identified touching or very close boundaries are joined to form complete constructions polygons enclosing less than p pixels are assumed not to represent the reference pattern and are not considered any further in all experiments such regions were all true negatives and encoded small patches of vegetation through colonization by garrigue and or phrygana biotopes or assemblages exposed bare rock or areas characterized by ground armour p should be proportional to the number of pixels that cover the pattern and to the height from which the images are captured if this is too small an incorrect area might be selected and the grid lines identification process will fail if the number is too large then the actual pattern area might cover less pixels than the set threshold and is not selected the perimeter associated with the chequered pattern is expected to have a rectangular shape this is identified by selecting the object found to have the least difference between the area enclosed by the polygon and the corresponding convex hull area the matching pixels over the selected region are extracted from the greyscale version and are binary thresholded at 75 the maximum value a mask with the same dimensions as the input image that encodes the position of the pixels of the pattern is then created the extracted region is processed by a canny edge detector to highlight the outline of each grid cell in fig 5 the identified pattern region the corresponding extracted pattern and the output from the edge detector for four different images are shown extensive tests prove that the pattern is accurately detected irrespective of its position orientation and angle in the image 3 2 formalisation of the grid pattern the next step involves parameterisation of the detected lines this is achieved through the application of hough transformation as demonstrated in fig 6 the coordinates of the high intensity points within the accumulator space are determined and the corresponding line equations are obtained in this study projection was applied between 90 and 90 at one degree resolution contributions from random noise and edge artefact made insignificant contributions to the accumulator space and did not influence line detection lines with a steep gradient and which make an angle of less than 30 to the normal are considered as vertical segments with a small gradient and with angles greater than 60 to the normal are taken to have a horizontal orientation the points of intersection between horizontal and vertical pairs are then computed extra peaks considered from the accumulator space will result in nearly parallel lines over the same grid boundary this is accounted for by grouping all intersecting points within a small radius of each other in this study points within a radius of 10 pixels were grouped together such a value should be set according to the sharpness of the edges of the reference pattern if these are blurry then a larger number might be required to obtain single line edges the line segments and the corresponding intersection points extracted from the hough projection shown in fig 6 are presented in fig 7 the accumulator space the detected lines and the points of intersection for the four images shown in fig 5 are put forward in fig 8 the mean perpendicular distance between each pair of points is computed in terms of numbers of pixels this result is taken to represent the real length of each grid cell in the reference pattern and allows for the actual dimensions of the picture elements to be determined 3 3 pixel to real space conversion the 2413 photos considered in this work had a resolution of 2816 2112 pixels detection of the chequered pattern by the method described above was found to be successful 99 047 of the time the 24 photos for which the method failed had the pattern covered by the shadow of tall vegetation the average surface area captured by each photo in the dataset was found to be 3 7396 m2 fig 9 presents a summary of the processes involved to transform pixel dimensions into real length measurements 4 classification method following pattern detection and the elimination of the corresponding elements the remaining pixels are divided into two groups according to whether they show a vegetated or a non vegetated region such classification is performed through a model which is trained to make predictions based on the red green and blue channel intensities use of a supervised decision tree learning algorithm is adopted samples are classified after traversing the branches from the root to a leaf node according to the met conditions the tree is learnt by splitting the provided labelled examples into subsets according to the attribute value various branches are built by recursively repeating this process until all elements in each group have the same target value or when splitting the data no longer increases the prediction accuracy mitchell 1997 a number of decision tree learning algorithms are available some methods allow for inequality tests and can work on noisy and incomplete information provided that the training set represents a full description of the classes to be modelled the constructed tree can be used as a rule set for predicting the category of unknown samples 4 1 generation of training dataset in this study separate training sets were generated for each location five to ten photos from each site were selected and vegetated and non vegetated areas were manually marked by using photo editing software in particular the paintbrush tool was used to indicate garrigue and or phrygana pixels with pure green red 0 green 255 blue 0 and karstic or ground armour sections with pure blue red 0 green 0 blue 255 such images were saved as lossless bitmap files to retain the exact given intensities a script that reads the masked training files and extracts the locations of the marked pixels was then implemented the corresponding rgb channel intensities were obtained from the original photos this method allowed a good and significant training set to be easily generated some examples of the defined training masks are shown in fig 10 4 2 model generation and validation once the training and target vectors are provided the algorithm randomises the entries and proceeds to construct the classification model from 70 of the samples the remaining examples are used for testing although classification is done across two groups the model is trained to output real values between 0 0 and 1 0 predictions close to 0 0 are taken to represent vegetation while pixels assigned a value close to 1 0 are considered to be garrigue and or phrygana to maintain a strong confidence in the classifier only values below the 0 25 or above the 0 75 thresholds are considered pixels with values outside this range are left as unclassified this to ensure that only cells classified with a high degree of accuracy are assigned to the respective class such an approach also allows for the tracking of incorrectly classified pixels the outputs of the test vectors are then compared to the actual target value this allows for a classification confidence to be computed for each class at each site considered table 2 presents the percentages of correctly classified pixels over the testing set used the percentage of unclassified pixels and the pearson correlation coefficient between the actual and the predicted classes are also shown as can be seen from the last column of this table a high correlation between the predicted and the target values was obtained for all sites the confidence of each model can also be confirmed from the low percentage of pixels that could not be classified 4 3 cluster results after convergence the classifier is used on other photos captured from the same site land mapping is followed by area estimation the number of elements assigned within each class is multiplied by the pixel surface area computed from the reference pattern to obtain estimates of the total garrigue and or phrygana coverage and the total of karstic or ground armour terrain in square meters samples of original photos and the corresponding classification results are presented in fig 11 the proposed method does not restrict the height of the camera above ground level although the reference pattern might scale over a different number of pixels across images the surface area it covers in m2 should always approach the same constant since the printed pattern had dimensions of 0 297 m 0 420 m in this case the expected value was of 0 12474 m2 as shown by the histogram in fig 12 the computed spatial surface area covered by the pattern was very close to the expected value 5 discussion and future work in this study a tool for land cover mapping that computes an estimate for the surface area coverage was presented actual pixel sizes are obtained through the use of a reference pattern which is photographed in all images although vegetation percentage coverage can be carried out by an expert such a task is very time consuming and sometimes subjective the proposed technique provides a quick quantitative alternative that can be carried out with cheap resources while vegetation cover is normally computed through the use of satellite and aerial images the resolution provided by such methods is not always adequate especially when very small regions are to be studied moreover commonly used vegetation indices such as the normalised difference vegetation index ndvi and the enhanced vegetation index evi make use of the thermal infra red band this is not always available at the same resolution as the other channels although traditional land cover analysis cannot be fully replaced the proposed method proved to provide encouraging results in a gis environment as discussed in section 2 seasonable variability can be investigated through the re capturing and processing of images during the winter months remotely sensed satellite images are contaminated by clouds fig 13 demonstrates the ndvi computed from landsat 7 after the scan line correlator slc problem from landsat 8 and from sentinel 2 these missions have a resolution of 30 m and 10 m respectively results from data captured on a typical winter day are also presented although these bands encode the highest resolution available the regions of interest cover a small amount of grid cells this restrict studies that target to investigate the short term vegetation cover change over small regions the proposed technique allows any region to be studied throughout the year conventional vegetation indices assign a normalised value to each pixel these are commonly followed by supervised or unsupervised machine learning classification methods to categorise each element with a particular land type the presented method combines these two steps by automatically classifying each pixel with the closest group defined in the training set the correlation values presented in table 2 indicate a very strong agreement between the manual and automatic classifications as demonstrated in section 3 3 the reference pattern was detected in the majority of the images planned future work include the use of mosaicking techniques that automatically stitch images together this will drastically improve image acquisition time and eliminates problems associated with the avoidance of overlapping regions the use of a higher end camera model that automatically geo tags the captured images will also help the applicability of other classification models such as neural networks support vector machines and fuzzy logic can also be investigated such classifiers can be trained to distinguish between other classes such as for instance water forests or different types of agriculture the model will be able to learn the colour components of different land cover types specified in the training samples this study can also be easily adapted to images captured by a down facing camera at higher altitudes to test such an approach the presented pattern matching algorithm was applied on frames taken by a dji phantom 4 drone data was acquired from 10 0 m 12 5 m 15 0 m 17 5 m and 20 0 m as shown in fig 14 the pattern in photos captured from an altitude of less than 20 0 m was detected and the dimensions of each pixel could be calculated however as the distance from the ground increased the pattern became too small and extended over very few pixels moreover in such cases the geometrical distortions due to non flat terrains cannot be ignored while drones are fast becoming a source of aerial data the provided telemetry is normally with respect to the point from which the aircraft lifted off and the actual distance to ground might vary in such cases the use of a reference pattern for calibration will still be required 6 software availability the developed toolbox can be requested from the corresponding author by email and will be provided free of charge all functions were written in matlab version 2015a which is required to run the provided m and library files no special hardware is necessary all tests presented in this study were run on a macbook pro with an intel core i5 processor 2 9 ghz and 8 gb of ram the full or a subset of the image dataset can also be provided as jpeg files all files are available as from 2017 
26467,decreasing groundwater availability in the texas high plains has resulted in the widespread adoption of management allowed depletion mad irrigation scheduling modeling of such practices and their effects on water balance components can be a cost effective and time saving alternative to field based research however studies have identified deficiencies in the auto irrigation algorithms in the soil and water assessment tool swat including the continuation of irrigation during the non growing season and an inability to simulate growth stage specific irrigation consequently new and representative auto irrigation algorithms were developed using 1 a uniform single season mad and 2 a growth stage specific mad with options for seasonal growth stage partitioning based on scheduled date and accumulated heat units comparisons with observed data from an irrigated lysimeter field showed improved model performance for simulations of irrigation amount and frequency and actual evapotranspiration minimal differences in leaf area index and yield were observed with the non water stressed management keywords actual evapotranspiration et crop leaf area index lai heat units auto irrigation soil water deficit management allowed depletion mad software availability model algorithm name swat mad irrigation algorithm description this algorithm simulates management allowed depletion mad irrigation scheduling by incorporating an allowable depletion percentage of plant available water paw determined by crop specific maximum rooting depth into an irrigation trigger the algorithm also suspends irrigation events following harvest developed by y chen yongchen neo tamu edu and g w marek gary marek ars usda gov ecosystem science and management texas a m university college station texas and usda ars conservation and production research laboratory bushland texas respectively year available 2017 availability contact developers cost no cost and open source language fortran 1 introduction irrigated agriculture provides an enormous contribution toward global food supply and security by producing approximately 40 of food and agricultural commodities on only 17 of cultivated lands food and agriculture organization fao 2002 supplemental irrigation in the semi arid texas high plains thp has made it one of the most productive agricultural regions in the united states the discovery of the vast ogallala aquifer early in the 20th century provided a seemingly inexhaustible source of groundwater for irrigation within the region hornbeck and keskin 2012 irrigation development began in the 1950 s with both irrigated area and volume pumped peaking in 1974 before steadily declining from 1974 to 1989 colaizzi et al 2009 the development and proliferation of center pivot and other associated irrigation management technologies greatly contributed to the rapid expansion of mechanized systems of agricultural irrigation in the thp decades of intensive irrigation pumping coupled with minimal natural recharge has resulted in significant decline of ogallala aquifer groundwater levels and subsequently irrigation well capacities thus decreasing groundwater availability has placed an emphasis on more sustainable agricultural irrigation management practices in the region texas water development board twdb 2006 2011 2016 decreasing well capacities have also resulted in the adoption of limited irrigation strategies systems designed to increase application and production efficiencies by reducing evaporative losses while minimizing overwatering these technologies include but are not limited to low energy precision application lepa sprinkler drops low elevation spray application lesa drops subsurface drip irrigation sdi and most recently variable rate irrigation vri and precision mobile drip irrigation pmdi however irrespective of system application efficiency irrigation scheduling ultimately dictates seasonal irrigation events and therefore plays a significant role in water resources management in this respect water losses from excess irrigation may dwarf relative losses associated with system application efficiencies conversely insufficient irrigation generally results in reduced yields or even crop failure as such irrigation timing and magnitude optimized for localized crop soil topography and climate parameters are critical for effective irrigation management and agricultural crop production computer simulation models are powerful evaluation tools and their water use outputs are commonly used in regional water planning and policy efforts however these models require adequate calibration and testing against measured field data to both validate model performance and reinforce user confidence in model outputs the considerable investment required for field based studies has led to the increased use of crop and hydrologic modeling software packages for simulating and evaluating different agricultural irrigation management strategies as such they serve as a time and cost efficient alternative for evaluating sustainable irrigation management practices li et al 2014 however accurate simulation of irrigation events particularly irrigation magnitude and frequency is critical for meaningful evaluation of irrigation management strategies as plant growth development is greatly affected by these variables commonly used simulation models are the soil and water assessment tool swat watershed scale model the agricultural policy environmental extender apex small watershed field scale model the decision support system for agrotechnology transfer dssat crop model root zone water quality model rzwqm field scale model and modflow groundwater model among these swat apex and rzwqm include an auto irrigation function to simulate irrigation in associated fields or watersheds dssat and modflow only allow for the manual input of irrigation data the rzwqm includes an auto irrigation function based on soil water depletion the auto irrigation function in swat and apex is based on a water stress identifier of either 1 plant water demand or 2 soil water content the plant water demand option applies irrigation water whenever a user defined decrease in plant growth occurs due to water stress alternatively the soil water content option triggers irrigation when a user defined soil water deficit threshold calculated as the difference between field capacity and soil water content is exceeded recently swat was used for assessing the impacts of agricultural irrigation management on water use and hydrologic process at both watershed and field scales marek et al 2017 reported that simulated seasonal irrigation approximated that of actual irrigation totals typical of thp crops by adjusting the parameters of the auto irrigation function however they also concluded the limitations of the soil water content method could prevent representative simulation of irrigation from reduced system capacities due to irrigation frequency limitations related to center pivot travel times chen et al 2017b also found that although the swat default auto irrigation triggered by soil water content method provided reasonable simulation of actual evapotranspiration et the irrigation amounts varied greatly from actual irrigation amounts observed in the field in most cases the swat default auto irrigation functions over irrigated crops as compared to actual practiced irrigation levels some studies further reported that the swat default auto irrigation function was unable to appropriately represent the hydrological process in intensively irrigated study areas akhavan et al 2010 chen et al 2017a dechmi et al 2012 panagopoulos et al 2014a b for instance when the soil water content method was used irrigation events were not suspended even after the crop harvest marek et al 2017 chen et al 2017b also documented that the water stress trigger auto wstrs is used in both water stress identifier options however according to the user manual and source code this value is read as a percentage expressed as a decimal value between 0 and 1 under the plant water demand option wstrs id 1 and as mm of soil water deficit under the soil water content option wstrs id 2 this distinction is not readily recognized and can easily be overlooked furthermore the mouse over comment for the soil water content trigger value in the arcswat interface calls for a value between 0 and 1 identical to that of the plant water demand option this is incorrect and can easily mislead users accessing the arcswat interface to setup auto irrigation management researchers have also suggested growth stage specific irrigation levels for effective use of water and to create favorable conditions for crop growth guo 1997 xie and cui 2011 this approach could be especially useful for production regions with limited water resources three major growth stages of crop development initial growth stage stage 1 mid season stage stage 2 and late season stage stage 3 are commonly recognized and used by the research community allen et al 1998 recently a continuous relatively long term 2000 2010 lysimeter dataset from the u s department of agriculture agricultural research service usda ars conservation and production research laboratory cprl at bushland texas was used for an evaluation of crop et flux in swat under irrigated conditions marek et al 2016 these research grade water balance data included lysimeter measured et research grade meteorological measurements and detailed agronomy records provided a quality dataset for model calibration and validation irrigation data from these long term observed data also provided a unique opportunity for the development and testing of alternative auto irrigation algorithms the swat default auto irrigation functions using the soil water content option trigger irrigation s when the water content in the soil profile falls below field capacity by a user defined soil water deficit threshold mm however in practice producers may be willing to allow a maximum percentage of plant available water paw depletion before irrigation is triggered this concept is known as management allowed depletion mad a common framework for irrigation management as outlined by merriam 1966 the mad irrigation management has been commonly used in semi arid arid regions such as u s states of texas kansas arizona etc and iran callison 2012 evett et al 2011 gheysari et al 2009 lamm et al 1996 merriam 1966 suarez rey et al 2000 for most crop production a 50 mad level represents a nominal and reasonable overall value for avoiding significant plant water stress callison 2012 u s department of the interior bureau of reclamation 2017 usda nrcs 2017 as for sensitive high value shallow rooted crops or heavily compacted soils a smaller range of depletion may be required 30 50 mad regarding stress tolerant crops deep root zones or well structured soils a larger range of depletion can be used 50 70 mad fig 1 furthermore many crops have explicit important growth stages each having various sensitivity to water stress for instance cereal grain initial growth and late season stages are generally less sensitive to water deficits however sufficient irrigation is crucial for the mid season stage typical of the pollination period for water sensitive crops such as vegetables fruits or nuts too large of a mad can lead to production quality issues if specific stages are not adequately irrigated therefore crop growth stage specific mad values fao mad are required to address relative irrigation requirements the current default auto irrigation function in swat or any other model for that matter as far as we know is unable to simulate mad irrigation management explicitly however irrigation scheduling based on the mad concept is becoming widely used marek et al 2005 2009 2011 evett et al 2011 hao et al 2015 vories et al 2017 as such the addition of mad based options for the auto irrigation algorithms in swat is needed for accurate simulation of actual irrigation practices however adequate testing and validation are required before these amendments to the auto irrigation function can be incorporated into the distributed swat model in this study irrigation and crop et data of considerable breadth 2000 2010 and quality from an irrigated lysimeter field at the usda ars cprl at bushland texas were used for assessing the newly developed mad auto irrigation algorithms regarding the irrigation and et simulations the objectives of this study were to 1 create and incorporate a mad based auto irrigation algorithm into swat using fortran programming language 2 develop and present a logical procedure for the development of fao mad values based on plant development scheduling of specific date and heat unit accumulations and 3 evaluate the newly developed mad auto irrigation algorithms for simulation of irrigation and crop et by comparing model outputs to results from swat default auto irrigation scenarios and observed data 2 materials and methods 2 1 study field data used in this study were collected from a 4 7 ha lysimeter research field located at the usda ars cprl bushland texas 35 2 n 102 1 w 1170 m above mean sea level daily et values were collected from a precision large weighing lysimeter located in the center of the field the dominant soil is well drained pullman clay loam fine mixed superactive thermic torrertic paleustoll unger and pringle 1981 the study area topography is essentially flat with a slope 0 3 the regional climate is classified as semi arid with an average temperature and precipitation 2000 2010 of 14 1 c and 488 mm respectively weather data were obtained from an adjacent research grade weather station maintained to asce ewri specifications asce 2005 agronomic and et data were collected for irrigated crops grown on the lysimeter field from 2000 to 2010 crops grown during the study period included cotton gossypium hirsutum l in 2000 2002 2008 and 2010 soybean glycine max l in 2003 and 2004 grain and forage sorghum sorghum bicolor l moench in 2005 and 2007 forage corn zea mays l in 2006 and sunflower helianthus annuus l in 2009 table 1 the field was irrigated by a linear move irrigation system equipped with low elevation sprinkler application drops in general irrigations were scheduled to avoid plant water stress a mad of 40 60 in the top 1 5 m of the soil profile as determined by weekly neutron probe measurements of soil water the actual source of irrigation water in the texas high plains is the ogallala aquifer however the irrigation source was set to an unlimited source outside of the watershed in order to eliminate the influence of the groundwater capacity on irrigation simulations and model code development daily application rates of 25 32 mm are representative of production agriculture in the region details about specific crop planting and management practices are provided by chen et al 2017b 2 2 climate data collection and processing climate data 15 min output obtained from the adjacent weather station were compiled into daily values and formatted for model input quality assurance and quality control qa qc procedures were used to ensure that measured precipitation air temperature wind speed solar radiation and relatively humidity values were within acceptable ranges also all climate data were compared to data collected from a collocated weather station of the texas high plains et network marek et al 2005 correlations between the two datasets were used to gap fill climatic data of the weather station 2 3 lysimeter data the lysimeter contains an undisturbed in situ soil monolith weighing 45 mg including the container lysimeter surface dimensions are approximately 3 m 3 m 9 m2 with a depth of 2 3 m voltage outputs from load cells sm 50 interface inc scottsdale ariz with 22 kg full range capacity were measured and recorded by data loggers cr 7x campbell scientific logan utah at 0 5 hz 2 s frequency lysimeter mass kg is converted to a mass equivalent lysimeter storage value mm of water by dividing it by the effective surface area of the lysimeter 9 m2 and the density of water taken as 1000 kg m 3 data logger resolution is better than 0 001 mm when converted to equivalent depth of water however lysimeter accuracy is dependent upon root mean square error rmse of calibration and has ranged from 0 05 mm howell et al 1995 to 0 01 mm evett et al 2012 load cell voltage outputs reported as 5 min means serve as the base dataset for subsequent processing periods howell et al 1995 initial lysimeter design and management are described by marek et al 1988 and a comprehensive history of the lysimeter et measurements at the cprl is provided by evett et al 2016 experienced scientists and technicians are responsible for routine lysimeter maintenance and ensuring representativeness of the surrounding field daily et mm calculations were performed using the following soil water balance equation 1 et r p i δsw f where r is the sum of runon and runoff taken as zero due to furrow diking to minimize runoff in this study p is precipitation i is irrigation δsw is the change in soil moisture and f is flux into or out of the volume taken as positive when entering the control volume the lysimeter was equipped with vacuum drainage system that collected any drainage into tanks suspended from the lysimeter soil tank such that drainage did not alter the lysimeter mass as such f was assigned as zero other mass changing events were flagged and accounted for according to data processing and data qa qc procedures provided by marek et al 2014 missing or unusable lysimeter et data resulting from lysimeter calibrations maintenance power outages and agronomic activities were not used crop leaf area index lai was measured periodically during the growing season throughout the 10 year period 2 4 swat model description and setup swat is a continuous time semi distributed process based and river basin scale model arnold et al 1998 a large number of input parameters are required for swat to evaluate the effects of best management practices on hydrology swat is widely used and accepted as a feasible tool to simulate the effects of best management practices on water balance in many watersheds gassman et al 2014 primary model inputs include hydrography terrain soil land use tile drainage weather and management practices srinivasan et al 2010 management scheduling inputs in swat allows the users to schedule agronomic practices by specific date for example users can manually assign dates for planting tillage fertilization irrigation harvest etc alternatively using a heat units basis the swat model will schedule management practices according to the heat unit accumulations calculated from the temperature data inputs for instance the model may schedule irrigation to start once 0 15 heat units have accumulated a specialized approach using the arcswat interface was used to create a field scale project by delineating a very small watershed around the lysimeter field marek et al 2016 a single sub basin with the longest reach was chosen to be representative of the slope and aspect of the field all other sub basins and associated outlets were removed this resulted in a project consisting of a single sub basin a single reach and a single hydrologic response unit hru after inputting land use soil slope and climate data all other data inputs were performed using swat input text files according to the actual management data all the hypothetical scenarios were designed by modifying the input management text files in swat in this study swat 2012 version 2012 10 2 19 revision 664 was used as the initial code for alterations and subsequent evaluations a well calibrated swat model from chen et al 2017b for et lai and crop yield with manual inputs of all actual management operations was used in this study the penman monteith method was used to estimate daily potential et the entire simulation period was from 2000 to 2010 with the first year 2000 being used as the model warmup period the calibration and validation periods were 2001 2005 and 2006 to 2010 respectively 2 5 swat code modification and model evaluation approach the swat model is coded in the fortran 90 programming language however unlike many models swat is an open source model and access to the source code is not restricted to a limited group of developers holzworth et al 2015 the source code of swat 2012 revision 664 was obtained from http swat tamu edu according to the source code the swat default auto irrigation triggered by soil water content method will initiate an irrigation of a user specified amount irr mx when the total soil water content falls below field capacity by more than the user defined soil water deficit threshold sol sumfc sol sw auto wstr 2 where sol sumfc is the one dimensional amount of water held in the soil profile at field capacity mm sol sw is the amount of water stored in soil profile on any given day mm and auto wstr is water stress threshold that triggers irrigation mm in this study the swat code was modified to incorporate a mad irrigation management approach into the auto irrigation function physical soil properties such as soil water calculations in swat are based on individual soil layers for example soil available water by layer sol awc layer is defined as the total water content of the soil layer minus the water content of the layer at permanent wilting point 1 5 mpa arnold et al 2012 plant available water paw for plant uptake is determined by the summation of sol awc by soil layer up to a depth of the crop specific maximum rooting depth rdmx value assigned in the plant database file as such water contained in soil layers below the plant rooting depth is unavailable for plant uptake code alterations for mad irrigation scheduling also referenced the paw by layer calculations and crop specific maximum root depth values however the trigger for initiating irrigations was changed to a percentage of paw depletion mad rather than the difference between field capacity mm and soil water content mm additional modifications included coding to suspend irrigation events after crop harvest the newly developed auto irrigation algorithms simulate mad based irrigation management using the following expression 3 sol sumfc sol sw paw mad where paw is plant available water determined by both soil specific hydrology and plant specific maximum rooting depth mm and mad is the management allowed depletion percentage expressed as a decimal value ranging from 0 to 1 mad values approaching zero indicate management that allows relatively less depletion of soil water before initiating irrigation resulting in decreased plant water stress conversely values approaching 1 allow for more depletion of soil water before irrigations resulting in increased plant water stress code alteration included options for the addition of 1 a single constant mad value applied throughout the growing season and 2 growth stage specific mad values fao mad however categorizing plant growth into appropriate growth stages generally presents a challenge within the modeling environment users having detailed field scale crop growth data may manually divide the growing season into appropriate stages by specific date alternatively many users working with large watershed projects may not have adequate data or not be interested in manually categorizing crop growth stages in these cases crop growth stages can be constructed automatically by the partitioning of seasonal heat units generated in the swat plant growth model this flexibility allows users the option to choose whichever method is most appropriate based on available data and modeling goals a flowchart based model development procedure was used for development and testing of the alternative auto irrigation algorithms in this study fig 2 initially a constant mad value of 0 5 commonly used for fully irrigated cereal crops allen et al 1998 was used to evaluate the model performance in irrigation and et simulations under both crop growth schedule methods of 1 schedule by date and 2 schedule by heat units furthermore fao mads were also developed under both growth schedule methods initial fao mad values of 0 50 0 40 and 0 50 were used for the initial growth stage stage 1 mid season stage stage 2 and late season stage stage 3 respectively crop growth stage separation points were estimated from calibrated lai values using the schedule by date option fig 3 the initial growth stage separation points of 0 35 and 0 75 of seasonal heat units to bring a plant to maturity were used for the fao mad schedule by heat units the performance of fao mads on simulated irrigation and actual et was evaluated by comparison with actual irrigation and et values as well as the outputs from swat default auto irrigation scenarios finally fao mad values for cotton were further adjusted and evaluated separately due to the indeterminate nature of cotton and associated alternative mad values in the literature the amount of irrigation applied per event irr mx was set to 25 4 mm 1 inch an amount representative of system capacity at the cprl and surrounding regions 2 6 auto irrigation management scenario development and assessment in total six auto irrigation management scenarios were evaluated including the swat default auto irrigation single mad auto irrigation and fao mad auto irrigation using both the 1 schedule by date and 2 heat units approach in all years the auto irrigation function was initiated at the time of planting in the management input file therefore no irrigation events were simulated prior to crop planting in order to ensure unbiased comparisons of seasonal auto irrigation functions with actual irrigations occasional preseason irrigations to promote germination were not considered in the comparisons for the schedule by date simulations division of the growing season into growth stage specific periods was achieved by visual analysis of simulated lai data following model calibration fig 3 growth stage separation points initial growth end date and late season start date for crops in all years are listed in table 1 these specific dates were used as inputs in the swat management file mgt initial mad values of 0 50 0 40 and 0 50 for initial growth mid season and late season stages respectively were used for all crops excluding cotton mad values for cotton were adjusted within the range of 0 30 0 70 regarding the management method of schedule by heat units mad values of 0 50 0 40 and 0 50 for initial growth stage mid season stage and late season stage and growth stage separation points of 0 35 and 0 75 of heat units to maturity were hard coded into the execution command in the model fig 2 the swat model performance for simulating et and irrigation amount was evaluated using percent bias pbias and nash sutcliffe efficiency nse nash and sutcliffe 1970 statistics nse values range from to 1 with an nse value equal to 1 indicates perfect model performance the optimal pbias is 0 0 a negative value indicates a model bias toward underestimation whereas a positive value denotes a bias toward overestimation gupta et al 1999 intel parallel studio xe composer edition and microsoft visual studio 2013 were used to modify and compile the swat source code statistical analyses were performed using the statistical package for social science software spss 22 0 inc chicago il usa analysis of variance was used to test the difference with the significance level of p 0 05 microsoft excel 2016 was used for other data analysis 3 results and discussion 3 1 swat model performance for et and lai simulations the nse and pbias values for daily et simulations were 0 85 and 0 2 respectively during the calibration period 2001 2005 and 0 80 and 1 9 respectively during the validation period 2006 2010 under the baseline scenario table 2 the model performance for both periods demonstrated a very good agreement between the simulated and observed et according to moriasi et al 2007 criteria under the baseline scenario the simulated average annual 2001 2010 potential et pet based on the penman monteith method was 1786 mm fig 4 there was limited average annual runoff 0 91 mm and percolation 4 03 mm chen et al 2016 simulated an average annual 1994 2009 surface runoff of 3 4 mm under the irrigated cotton land use in the thp using swat in this study furrow diking in the irrigated lysimeter field minimized runoff rosenberg et al 1999 simulated a similar value of recharge to the ogallala aquifer 6 mm yr 1 as to the 4 03 mm in this study using the hydrologic unit model for the united states humus approximately 99 of the water from precipitation 496 0 mm and irrigation 380 7 mm was converted to et 872 6 mm due to the much higher pet demand 1786 mm than the total water input 876 7 mm hao et al 2014 also reported that more than 90 of the growing season precipitation was used as growing season et in biomass sorghum fields in the thp in semi arid regions et is easily the largest component of the water balance a graphical comparison showed that swat simulated lai after calibration matched the observed data well fig 3 a good fit of simulated lai is beneficial for achieving reasonable partitioning of transpiration and evaporation which in turn contribute to the accurate simulations of both the hydrologic cycle and plant growth yimam et al 2015 in this study it is of primary importance to obtain good lai simulation agreement due to the development of fao mads for the schedule by date option the constant mad auto irrigation scheduled by date showed similar model performance for et as compared to the swat default auto irrigation with nse values of 0 70 and 0 66 during calibration and validation periods respectively table 2 the fao mad auto irrigation schedule by date achieved a slightly improved et simulation for the calibration and validation periods nse of 0 75 and 0 68 respectively as compared to the swat default auto irrigation and constant mad auto irrigation schedule by date table 2 the swat default auto irrigation schedule by heat units failed to achieve a satisfactory nse value 0 48 for et during 2006 2010 table 3 however the constant mad auto irrigation schedule by heat units showed satisfactory model performance during calibration nse of 0 61 and validation nse of 0 51 periods table 3 the nse value was further improved to 0 64 under the fao mad auto irrigation schedule by heat units during the calibration period table 3 it is worth noting that in general the management method of schedule by date simulated a much better approximation of et than the management method of schedule by heat units the scheduling by heat units method is typically used in large complex watersheds for which users have little to no detailed information about the management scheduling jager et al 2015 wang et al 2016 in the absence of such information confidence in simulation results are less as compared to studies with more detailed management information inputs such as field scale studies 3 2 comparison of seasonal irrigation schedule by date in order to build new tools algorithms for existing models existing functions need to be evaluated and compared papajorgji and shatar 2004 when compared to the actual irrigations the nse and pbias values achieved for the simulation of annual irrigation amount during the entire simulation period from 2001 to 2010 were 4 05 and 46 3 respectively under the swat default auto irrigation schedule by specific date fig 5 a the irrigation amount for the swat default auto irrigation schedule by specific date was significantly higher than the actual irrigation amount p 0 013 0 05 simulations using the constant mad auto irrigation schedule by date option still resulted in an unsatisfactory performance although nse and pbias values improved to 1 64 and 21 7 respectively fig 5b however the relative increase in nse was substantial at 2 41 and pbias was reduced by 24 6 as compared to those of the swat default auto irrigation scenario no significant difference was found between irrigation amounts from the simulated constant mad and the actual irrigation p 0 19 0 05 using the fao mad auto irrigation schedule by date resulted in satisfactory model performance nse and pbias of 0 54 and 5 2 respectively for irrigation amount fig 5c in this study the unlimited irrigation source was used rather than the deep aquifer option to eliminate the influence of aquifer capacity on model code development the simplified representation aquifers in swat is largely unrealistic in reality an irrigation of a particular depth does not necessarily correlate to a corresponding change in depth of aquifer below as groundwater movement also has a horizontal component as such well capacity which can be adequately represented using the daily maximum irrigation amount is a much more realistic mechanism for simulating actual regional irrigation capacities using the unlimited source option allowed for simulated irrigations to occur based on the auto irrigation algorithms resulting in an overall overestimation of irrigation amount compared to the actual irrigation as described above in reality users are allowed to set the irrigation source to reach reservoir shallow aquifer deep aquifer or unlimited source outside watershed according to their demand due to the soft coding of the mad auto irrigation function users should be aware that using the aquifer source options may limit irrigation as aquifer depletion may be artificially accelerated due to the oversimplified representation of aquifer volume in swat some large inter annual variabilities in pbias were found for the 2001 cotton 55 2 2005 grain sorghum 18 5 2006 forage corn 25 9 and 2008 cotton 25 6 limited irrigation was performed in 2001 cotton based on the management record which may account for the large variation as for the 2005 grain sorghum only four measured lai values were available which may have led to an unreliable lai calibration especially when no senescence point was measured fig 3 there was a large variation in the measured lai for 2006 forage corn which was likely attributable to damage from an undetermined plant virus or herbicide the long tail of simulated lai for the 2008 cotton during the late season stage may have resulted in larger simulated et values relative to observed et resulting in the triggering of more irrigation events as compared to actual irrigation events 3 3 comparison of seasonal irrigation schedule by heat units in watershed scale studies model users may not know the management information by specific date and elect to schedule auto irrigation by heat units the nse and pbias values were 6 44 and 57 respectively for simulation of annual irrigation amount under the swat default auto irrigation schedule by heat units as compared to the actual irrigation fig 6 a similar to results for scheduling by date the irrigation amount under the swat default auto irrigation schedule by heat units was significantly higher than the actual irrigation amount p 0 008 0 05 resulting nse and pbias values were 4 69 and 37 3 respectively under the constant mad auto irrigation schedule by heat units fig 6b the improvement of nse and pbias was 1 75 and 19 7 respectively relative to the swat default auto irrigation scenario in addition there was no significant difference between simulated irrigation and observed data at p 0 05 level p 0 07 a further improvement in nse and pbias to 3 52 and 29 9 respectively was found for the fao mad auto irrigation schedule by heat units fig 6c all of the auto irrigation scenarios using schedule by heat units resulted in a low nse value however the mad auto irrigation algorithms suggested a significant improvement in irrigation simulation reduced pbias values as compared to the swat default auto irrigation schedule by heat units excluding cotton improved model performance was achieved in the simulation of irrigation amount nse and pbias 0 26 and 2 under the fao mad auto irrigation schedule by heat units fig 6d cotton is essentially a perennial shrub that is cultivated as an annual crop ton 2004 vegetative growth will continue under well watered conditions under full irrigation conditions the model auto irrigation tends to supply adequate water for crop growth however thp producers suspend irrigation for cotton during the cotton late growing season to promote boll set and opening the nse values of simulated irrigation amounts using the schedule by heat units option were much lower than those of the schedule by date option the best simulation performance for et and irrigation resulted from using the fao mad auto irrigation schedule by specific date the availability of the observed lai data was essential for this mad auto irrigation development therefore the measurement of lai is important given the model calibration and improvement of simulations for et and irrigation scheduling duchemin et al 2008 also concluded the collection of lai information is critical for accurate crop modeling furthermore many non destructive techniques are available for lai estimation including hand held radiometers and remote sensing from ground space gow et al 2016 it is worth noting that even though the irrigation simulations under the schedule by heat units method exhibited a large bias the nse values for the et simulations were within the satisfactory range this is an example of what modelers commonly refer to as getting a right answer for the wrong reason swat is typically calibrated for hydrologic parameters such as streamflow surface runoff with considerably fewer studies using soil water content and et wellen et al 2015 also limited studies have compared irrigation simulations due to the lack of the actual irrigation scheduling for such comparisons tian et al 2015 in this study the key reason for a satisfactory et simulation but with apparently biased irrigation output from the swat default auto irrigation scenarios was due to the relatively low number of irrigation events in each year 20 per year for the actual irrigations compared to 345 days of non irrigation conditions 3 4 comparison of monthly irrigation irrigation scheduling the monthly swat default auto irrigation of schedule by date and heat units showed more frequent irrigation of relatively smaller amounts as compared to the actual irrigation figs 7a and 8 a also the swat default auto irrigation applied irrigation water during the crop non growing season for example the swat default auto irrigation triggered irrigation events in january of 2009 and 2010 figs 7a and 8a a significantly higher irrigation amount was also found under the swat default auto irrigation schedule by heat units compared to the actual irrigation p 0 03 0 05 although the constant mad auto irrigation suspended the non growing season irrigation more than a 20 bias was still observed figs 7b and 8b the monthly irrigation comparisons indicated the fao mad auto irrigation schedule by date resulted in irrigation scheduling much more representative of the actual irrigation with nse and pbias values of 0 61 and 5 2 respectively fig 7c the fao mad auto irrigation schedule by heat units also exhibited a more reasonable irrigation frequency relative to the swat default auto irrigation schedule by heat units fig 8c however differences in daily comparisons of simulated and actual irrigation frequency did exist data not shown irrespective of mad calibration as the occurrence of actual irrigations may shift as a result of on farm irrigation scheduling with other irrigated research or production fields the fao mad auto irrigation schedule by heat units also suggested excessive irrigation pbias of 29 9 as compared to actual irrigation a more reasonable match nse and pbias 0 46 and 2 0 was observed for the fao mad auto irrigation schedule by heat units when the cotton years were not considered fig 8d the statistical performance for monthly irrigation results was much better than that of annual results a major contributing factor for this was the occurrence of months without irrigation additionally the monthly comparisons not only indicated a comparison of the irrigation amount but also included an irrigation frequency comparison 3 5 comparison of crop growth response crop lai and yield simulated crop yields under multiple auto irrigation scenarios swat default constant mad growth stage specific mad using both schedule by specific date and heat units varied only minimally from observed yields fig s1 in the swat model the water stress factor can be used to correct the simulated biomass throughout the growing season and the crop specific harvest index determines yield from the final biomass value in this study the full irrigation was scheduled to avoid plant water stress and the same crop database values were used for all scenarios irrigation was managed so that all crops experienced negligible water stress under all the scenarios this explains the observance of only minimal changes in simulated crop yield as compared to the observed data as for the lai values no significant changes were observed for the auto irrigation scenarios scheduled by specific data when compared to the measured lai values figs s2 s5 negligible water stress contributed to the minimal differences in lai between the simulated and measured values however differences between simulated and observed lai values were apparent for the 2005 grain sorghum and 2006 forage corn schedule by heat units figs s6 s8 this is primarily due to the replanting of the two crops following early season hail damage and undetermined plant virus damage in 2005 and 2006 respectively the heat unit accumulation growth model used to determine crop maturity is unable to represent the replanting of a crop this is the fundamental reason for the distinct leftward shift of the simulated lai curve early planting for 2005 grain sorghum and 2006 forage corn relative to the observed data a similar shift in simulated lai was observed for the 2009 sunflower crop due to the scheduled planting to occur once 0 15 heat units had accumulated which resulted in an earlier planting than the actual planting date 4 conclusions irrigation has enabled the texas high plains to be one of the most productive agricultural regions for supplying food and fiber in the united states however the decreasing availability of groundwater for irrigation has become a catalyst for the development and implementation of alternative cropping strategies and irrigation management in the region swat is an open source hydrologic model that not only allows users to simulate targeted scenarios but also offers opportunity to improve model representativeness through modification of the source code in this study mad auto irrigation algorithms were developed and evaluated using field data from an irrigated lysimeter at the usda ars cprl in bushland texas results indicated that the swat default auto irrigation functions simulated reasonable values for et nse 0 5 however simulated irrigation was significantly larger 50 than actual irrigation p 0 05 although use of the constant mad auto irrigation algorithms improved model et simulation slightly as compared to the swat default auto irrigation scenarios the simulation of seasonal irrigation was greatly improved nse increased more than 1 7 results from the fao mad auto irrigation algorithms not only demonstrated further improvements in et simulation but also indicated an improvement in the simulation of irrigation magnitude and frequency the fao mad auto irrigation schedule by date which was developed using calibrated lai exhibited the best fit for both et nse calibration and validation 0 75 and 0 68 and irrigation nse and pbias 0 54 and 5 2 among all the auto irrigation management scenarios this result highlighted the importance of detailed management information for minimizing uncertainty in model simulations in addition adequate periodic measurements of lai are pivotal for identifying growth stage separation points for use with the fao mad auto irrigation schedule by date option however modeling of large and or complex watersheds will likely require use of scheduling by heat units option results from this study showed less robust model performance for et and irrigation simulations under the schedule by heat units relative to those of the schedule by date option however use of the fao mad auto irrigation schedule by heat units option resulted in improved simulation of both et and irrigation as compared to the swat default auto irrigation schedule by heat units the mad algorithms were evaluated using cprl field data for crop irrigation management designed to avoid water stress conditions future model testing of the mad algorithms using limited irrigation datasets will provide additional measures of model performance in water limited scenarios which is prevalent in current thp and other production environments additionally testing in other climatic regions and soil types will further assess the efficacy of the mad based auto irrigation algorithms acknowledgments this research was supported in part by the ogallala aquifer program a consortium between usda agricultural research service kansas state university texas a m agrilife research texas a m agrilife extension service texas tech university and west texas a m university we gratefully thank the three anonymous reviewers for their valuable suggestions for improving this paper appendix a supplementary data the following is the supplementary data related to this article supplementary data supplementary data appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2017 09 013 
26467,decreasing groundwater availability in the texas high plains has resulted in the widespread adoption of management allowed depletion mad irrigation scheduling modeling of such practices and their effects on water balance components can be a cost effective and time saving alternative to field based research however studies have identified deficiencies in the auto irrigation algorithms in the soil and water assessment tool swat including the continuation of irrigation during the non growing season and an inability to simulate growth stage specific irrigation consequently new and representative auto irrigation algorithms were developed using 1 a uniform single season mad and 2 a growth stage specific mad with options for seasonal growth stage partitioning based on scheduled date and accumulated heat units comparisons with observed data from an irrigated lysimeter field showed improved model performance for simulations of irrigation amount and frequency and actual evapotranspiration minimal differences in leaf area index and yield were observed with the non water stressed management keywords actual evapotranspiration et crop leaf area index lai heat units auto irrigation soil water deficit management allowed depletion mad software availability model algorithm name swat mad irrigation algorithm description this algorithm simulates management allowed depletion mad irrigation scheduling by incorporating an allowable depletion percentage of plant available water paw determined by crop specific maximum rooting depth into an irrigation trigger the algorithm also suspends irrigation events following harvest developed by y chen yongchen neo tamu edu and g w marek gary marek ars usda gov ecosystem science and management texas a m university college station texas and usda ars conservation and production research laboratory bushland texas respectively year available 2017 availability contact developers cost no cost and open source language fortran 1 introduction irrigated agriculture provides an enormous contribution toward global food supply and security by producing approximately 40 of food and agricultural commodities on only 17 of cultivated lands food and agriculture organization fao 2002 supplemental irrigation in the semi arid texas high plains thp has made it one of the most productive agricultural regions in the united states the discovery of the vast ogallala aquifer early in the 20th century provided a seemingly inexhaustible source of groundwater for irrigation within the region hornbeck and keskin 2012 irrigation development began in the 1950 s with both irrigated area and volume pumped peaking in 1974 before steadily declining from 1974 to 1989 colaizzi et al 2009 the development and proliferation of center pivot and other associated irrigation management technologies greatly contributed to the rapid expansion of mechanized systems of agricultural irrigation in the thp decades of intensive irrigation pumping coupled with minimal natural recharge has resulted in significant decline of ogallala aquifer groundwater levels and subsequently irrigation well capacities thus decreasing groundwater availability has placed an emphasis on more sustainable agricultural irrigation management practices in the region texas water development board twdb 2006 2011 2016 decreasing well capacities have also resulted in the adoption of limited irrigation strategies systems designed to increase application and production efficiencies by reducing evaporative losses while minimizing overwatering these technologies include but are not limited to low energy precision application lepa sprinkler drops low elevation spray application lesa drops subsurface drip irrigation sdi and most recently variable rate irrigation vri and precision mobile drip irrigation pmdi however irrespective of system application efficiency irrigation scheduling ultimately dictates seasonal irrigation events and therefore plays a significant role in water resources management in this respect water losses from excess irrigation may dwarf relative losses associated with system application efficiencies conversely insufficient irrigation generally results in reduced yields or even crop failure as such irrigation timing and magnitude optimized for localized crop soil topography and climate parameters are critical for effective irrigation management and agricultural crop production computer simulation models are powerful evaluation tools and their water use outputs are commonly used in regional water planning and policy efforts however these models require adequate calibration and testing against measured field data to both validate model performance and reinforce user confidence in model outputs the considerable investment required for field based studies has led to the increased use of crop and hydrologic modeling software packages for simulating and evaluating different agricultural irrigation management strategies as such they serve as a time and cost efficient alternative for evaluating sustainable irrigation management practices li et al 2014 however accurate simulation of irrigation events particularly irrigation magnitude and frequency is critical for meaningful evaluation of irrigation management strategies as plant growth development is greatly affected by these variables commonly used simulation models are the soil and water assessment tool swat watershed scale model the agricultural policy environmental extender apex small watershed field scale model the decision support system for agrotechnology transfer dssat crop model root zone water quality model rzwqm field scale model and modflow groundwater model among these swat apex and rzwqm include an auto irrigation function to simulate irrigation in associated fields or watersheds dssat and modflow only allow for the manual input of irrigation data the rzwqm includes an auto irrigation function based on soil water depletion the auto irrigation function in swat and apex is based on a water stress identifier of either 1 plant water demand or 2 soil water content the plant water demand option applies irrigation water whenever a user defined decrease in plant growth occurs due to water stress alternatively the soil water content option triggers irrigation when a user defined soil water deficit threshold calculated as the difference between field capacity and soil water content is exceeded recently swat was used for assessing the impacts of agricultural irrigation management on water use and hydrologic process at both watershed and field scales marek et al 2017 reported that simulated seasonal irrigation approximated that of actual irrigation totals typical of thp crops by adjusting the parameters of the auto irrigation function however they also concluded the limitations of the soil water content method could prevent representative simulation of irrigation from reduced system capacities due to irrigation frequency limitations related to center pivot travel times chen et al 2017b also found that although the swat default auto irrigation triggered by soil water content method provided reasonable simulation of actual evapotranspiration et the irrigation amounts varied greatly from actual irrigation amounts observed in the field in most cases the swat default auto irrigation functions over irrigated crops as compared to actual practiced irrigation levels some studies further reported that the swat default auto irrigation function was unable to appropriately represent the hydrological process in intensively irrigated study areas akhavan et al 2010 chen et al 2017a dechmi et al 2012 panagopoulos et al 2014a b for instance when the soil water content method was used irrigation events were not suspended even after the crop harvest marek et al 2017 chen et al 2017b also documented that the water stress trigger auto wstrs is used in both water stress identifier options however according to the user manual and source code this value is read as a percentage expressed as a decimal value between 0 and 1 under the plant water demand option wstrs id 1 and as mm of soil water deficit under the soil water content option wstrs id 2 this distinction is not readily recognized and can easily be overlooked furthermore the mouse over comment for the soil water content trigger value in the arcswat interface calls for a value between 0 and 1 identical to that of the plant water demand option this is incorrect and can easily mislead users accessing the arcswat interface to setup auto irrigation management researchers have also suggested growth stage specific irrigation levels for effective use of water and to create favorable conditions for crop growth guo 1997 xie and cui 2011 this approach could be especially useful for production regions with limited water resources three major growth stages of crop development initial growth stage stage 1 mid season stage stage 2 and late season stage stage 3 are commonly recognized and used by the research community allen et al 1998 recently a continuous relatively long term 2000 2010 lysimeter dataset from the u s department of agriculture agricultural research service usda ars conservation and production research laboratory cprl at bushland texas was used for an evaluation of crop et flux in swat under irrigated conditions marek et al 2016 these research grade water balance data included lysimeter measured et research grade meteorological measurements and detailed agronomy records provided a quality dataset for model calibration and validation irrigation data from these long term observed data also provided a unique opportunity for the development and testing of alternative auto irrigation algorithms the swat default auto irrigation functions using the soil water content option trigger irrigation s when the water content in the soil profile falls below field capacity by a user defined soil water deficit threshold mm however in practice producers may be willing to allow a maximum percentage of plant available water paw depletion before irrigation is triggered this concept is known as management allowed depletion mad a common framework for irrigation management as outlined by merriam 1966 the mad irrigation management has been commonly used in semi arid arid regions such as u s states of texas kansas arizona etc and iran callison 2012 evett et al 2011 gheysari et al 2009 lamm et al 1996 merriam 1966 suarez rey et al 2000 for most crop production a 50 mad level represents a nominal and reasonable overall value for avoiding significant plant water stress callison 2012 u s department of the interior bureau of reclamation 2017 usda nrcs 2017 as for sensitive high value shallow rooted crops or heavily compacted soils a smaller range of depletion may be required 30 50 mad regarding stress tolerant crops deep root zones or well structured soils a larger range of depletion can be used 50 70 mad fig 1 furthermore many crops have explicit important growth stages each having various sensitivity to water stress for instance cereal grain initial growth and late season stages are generally less sensitive to water deficits however sufficient irrigation is crucial for the mid season stage typical of the pollination period for water sensitive crops such as vegetables fruits or nuts too large of a mad can lead to production quality issues if specific stages are not adequately irrigated therefore crop growth stage specific mad values fao mad are required to address relative irrigation requirements the current default auto irrigation function in swat or any other model for that matter as far as we know is unable to simulate mad irrigation management explicitly however irrigation scheduling based on the mad concept is becoming widely used marek et al 2005 2009 2011 evett et al 2011 hao et al 2015 vories et al 2017 as such the addition of mad based options for the auto irrigation algorithms in swat is needed for accurate simulation of actual irrigation practices however adequate testing and validation are required before these amendments to the auto irrigation function can be incorporated into the distributed swat model in this study irrigation and crop et data of considerable breadth 2000 2010 and quality from an irrigated lysimeter field at the usda ars cprl at bushland texas were used for assessing the newly developed mad auto irrigation algorithms regarding the irrigation and et simulations the objectives of this study were to 1 create and incorporate a mad based auto irrigation algorithm into swat using fortran programming language 2 develop and present a logical procedure for the development of fao mad values based on plant development scheduling of specific date and heat unit accumulations and 3 evaluate the newly developed mad auto irrigation algorithms for simulation of irrigation and crop et by comparing model outputs to results from swat default auto irrigation scenarios and observed data 2 materials and methods 2 1 study field data used in this study were collected from a 4 7 ha lysimeter research field located at the usda ars cprl bushland texas 35 2 n 102 1 w 1170 m above mean sea level daily et values were collected from a precision large weighing lysimeter located in the center of the field the dominant soil is well drained pullman clay loam fine mixed superactive thermic torrertic paleustoll unger and pringle 1981 the study area topography is essentially flat with a slope 0 3 the regional climate is classified as semi arid with an average temperature and precipitation 2000 2010 of 14 1 c and 488 mm respectively weather data were obtained from an adjacent research grade weather station maintained to asce ewri specifications asce 2005 agronomic and et data were collected for irrigated crops grown on the lysimeter field from 2000 to 2010 crops grown during the study period included cotton gossypium hirsutum l in 2000 2002 2008 and 2010 soybean glycine max l in 2003 and 2004 grain and forage sorghum sorghum bicolor l moench in 2005 and 2007 forage corn zea mays l in 2006 and sunflower helianthus annuus l in 2009 table 1 the field was irrigated by a linear move irrigation system equipped with low elevation sprinkler application drops in general irrigations were scheduled to avoid plant water stress a mad of 40 60 in the top 1 5 m of the soil profile as determined by weekly neutron probe measurements of soil water the actual source of irrigation water in the texas high plains is the ogallala aquifer however the irrigation source was set to an unlimited source outside of the watershed in order to eliminate the influence of the groundwater capacity on irrigation simulations and model code development daily application rates of 25 32 mm are representative of production agriculture in the region details about specific crop planting and management practices are provided by chen et al 2017b 2 2 climate data collection and processing climate data 15 min output obtained from the adjacent weather station were compiled into daily values and formatted for model input quality assurance and quality control qa qc procedures were used to ensure that measured precipitation air temperature wind speed solar radiation and relatively humidity values were within acceptable ranges also all climate data were compared to data collected from a collocated weather station of the texas high plains et network marek et al 2005 correlations between the two datasets were used to gap fill climatic data of the weather station 2 3 lysimeter data the lysimeter contains an undisturbed in situ soil monolith weighing 45 mg including the container lysimeter surface dimensions are approximately 3 m 3 m 9 m2 with a depth of 2 3 m voltage outputs from load cells sm 50 interface inc scottsdale ariz with 22 kg full range capacity were measured and recorded by data loggers cr 7x campbell scientific logan utah at 0 5 hz 2 s frequency lysimeter mass kg is converted to a mass equivalent lysimeter storage value mm of water by dividing it by the effective surface area of the lysimeter 9 m2 and the density of water taken as 1000 kg m 3 data logger resolution is better than 0 001 mm when converted to equivalent depth of water however lysimeter accuracy is dependent upon root mean square error rmse of calibration and has ranged from 0 05 mm howell et al 1995 to 0 01 mm evett et al 2012 load cell voltage outputs reported as 5 min means serve as the base dataset for subsequent processing periods howell et al 1995 initial lysimeter design and management are described by marek et al 1988 and a comprehensive history of the lysimeter et measurements at the cprl is provided by evett et al 2016 experienced scientists and technicians are responsible for routine lysimeter maintenance and ensuring representativeness of the surrounding field daily et mm calculations were performed using the following soil water balance equation 1 et r p i δsw f where r is the sum of runon and runoff taken as zero due to furrow diking to minimize runoff in this study p is precipitation i is irrigation δsw is the change in soil moisture and f is flux into or out of the volume taken as positive when entering the control volume the lysimeter was equipped with vacuum drainage system that collected any drainage into tanks suspended from the lysimeter soil tank such that drainage did not alter the lysimeter mass as such f was assigned as zero other mass changing events were flagged and accounted for according to data processing and data qa qc procedures provided by marek et al 2014 missing or unusable lysimeter et data resulting from lysimeter calibrations maintenance power outages and agronomic activities were not used crop leaf area index lai was measured periodically during the growing season throughout the 10 year period 2 4 swat model description and setup swat is a continuous time semi distributed process based and river basin scale model arnold et al 1998 a large number of input parameters are required for swat to evaluate the effects of best management practices on hydrology swat is widely used and accepted as a feasible tool to simulate the effects of best management practices on water balance in many watersheds gassman et al 2014 primary model inputs include hydrography terrain soil land use tile drainage weather and management practices srinivasan et al 2010 management scheduling inputs in swat allows the users to schedule agronomic practices by specific date for example users can manually assign dates for planting tillage fertilization irrigation harvest etc alternatively using a heat units basis the swat model will schedule management practices according to the heat unit accumulations calculated from the temperature data inputs for instance the model may schedule irrigation to start once 0 15 heat units have accumulated a specialized approach using the arcswat interface was used to create a field scale project by delineating a very small watershed around the lysimeter field marek et al 2016 a single sub basin with the longest reach was chosen to be representative of the slope and aspect of the field all other sub basins and associated outlets were removed this resulted in a project consisting of a single sub basin a single reach and a single hydrologic response unit hru after inputting land use soil slope and climate data all other data inputs were performed using swat input text files according to the actual management data all the hypothetical scenarios were designed by modifying the input management text files in swat in this study swat 2012 version 2012 10 2 19 revision 664 was used as the initial code for alterations and subsequent evaluations a well calibrated swat model from chen et al 2017b for et lai and crop yield with manual inputs of all actual management operations was used in this study the penman monteith method was used to estimate daily potential et the entire simulation period was from 2000 to 2010 with the first year 2000 being used as the model warmup period the calibration and validation periods were 2001 2005 and 2006 to 2010 respectively 2 5 swat code modification and model evaluation approach the swat model is coded in the fortran 90 programming language however unlike many models swat is an open source model and access to the source code is not restricted to a limited group of developers holzworth et al 2015 the source code of swat 2012 revision 664 was obtained from http swat tamu edu according to the source code the swat default auto irrigation triggered by soil water content method will initiate an irrigation of a user specified amount irr mx when the total soil water content falls below field capacity by more than the user defined soil water deficit threshold sol sumfc sol sw auto wstr 2 where sol sumfc is the one dimensional amount of water held in the soil profile at field capacity mm sol sw is the amount of water stored in soil profile on any given day mm and auto wstr is water stress threshold that triggers irrigation mm in this study the swat code was modified to incorporate a mad irrigation management approach into the auto irrigation function physical soil properties such as soil water calculations in swat are based on individual soil layers for example soil available water by layer sol awc layer is defined as the total water content of the soil layer minus the water content of the layer at permanent wilting point 1 5 mpa arnold et al 2012 plant available water paw for plant uptake is determined by the summation of sol awc by soil layer up to a depth of the crop specific maximum rooting depth rdmx value assigned in the plant database file as such water contained in soil layers below the plant rooting depth is unavailable for plant uptake code alterations for mad irrigation scheduling also referenced the paw by layer calculations and crop specific maximum root depth values however the trigger for initiating irrigations was changed to a percentage of paw depletion mad rather than the difference between field capacity mm and soil water content mm additional modifications included coding to suspend irrigation events after crop harvest the newly developed auto irrigation algorithms simulate mad based irrigation management using the following expression 3 sol sumfc sol sw paw mad where paw is plant available water determined by both soil specific hydrology and plant specific maximum rooting depth mm and mad is the management allowed depletion percentage expressed as a decimal value ranging from 0 to 1 mad values approaching zero indicate management that allows relatively less depletion of soil water before initiating irrigation resulting in decreased plant water stress conversely values approaching 1 allow for more depletion of soil water before irrigations resulting in increased plant water stress code alteration included options for the addition of 1 a single constant mad value applied throughout the growing season and 2 growth stage specific mad values fao mad however categorizing plant growth into appropriate growth stages generally presents a challenge within the modeling environment users having detailed field scale crop growth data may manually divide the growing season into appropriate stages by specific date alternatively many users working with large watershed projects may not have adequate data or not be interested in manually categorizing crop growth stages in these cases crop growth stages can be constructed automatically by the partitioning of seasonal heat units generated in the swat plant growth model this flexibility allows users the option to choose whichever method is most appropriate based on available data and modeling goals a flowchart based model development procedure was used for development and testing of the alternative auto irrigation algorithms in this study fig 2 initially a constant mad value of 0 5 commonly used for fully irrigated cereal crops allen et al 1998 was used to evaluate the model performance in irrigation and et simulations under both crop growth schedule methods of 1 schedule by date and 2 schedule by heat units furthermore fao mads were also developed under both growth schedule methods initial fao mad values of 0 50 0 40 and 0 50 were used for the initial growth stage stage 1 mid season stage stage 2 and late season stage stage 3 respectively crop growth stage separation points were estimated from calibrated lai values using the schedule by date option fig 3 the initial growth stage separation points of 0 35 and 0 75 of seasonal heat units to bring a plant to maturity were used for the fao mad schedule by heat units the performance of fao mads on simulated irrigation and actual et was evaluated by comparison with actual irrigation and et values as well as the outputs from swat default auto irrigation scenarios finally fao mad values for cotton were further adjusted and evaluated separately due to the indeterminate nature of cotton and associated alternative mad values in the literature the amount of irrigation applied per event irr mx was set to 25 4 mm 1 inch an amount representative of system capacity at the cprl and surrounding regions 2 6 auto irrigation management scenario development and assessment in total six auto irrigation management scenarios were evaluated including the swat default auto irrigation single mad auto irrigation and fao mad auto irrigation using both the 1 schedule by date and 2 heat units approach in all years the auto irrigation function was initiated at the time of planting in the management input file therefore no irrigation events were simulated prior to crop planting in order to ensure unbiased comparisons of seasonal auto irrigation functions with actual irrigations occasional preseason irrigations to promote germination were not considered in the comparisons for the schedule by date simulations division of the growing season into growth stage specific periods was achieved by visual analysis of simulated lai data following model calibration fig 3 growth stage separation points initial growth end date and late season start date for crops in all years are listed in table 1 these specific dates were used as inputs in the swat management file mgt initial mad values of 0 50 0 40 and 0 50 for initial growth mid season and late season stages respectively were used for all crops excluding cotton mad values for cotton were adjusted within the range of 0 30 0 70 regarding the management method of schedule by heat units mad values of 0 50 0 40 and 0 50 for initial growth stage mid season stage and late season stage and growth stage separation points of 0 35 and 0 75 of heat units to maturity were hard coded into the execution command in the model fig 2 the swat model performance for simulating et and irrigation amount was evaluated using percent bias pbias and nash sutcliffe efficiency nse nash and sutcliffe 1970 statistics nse values range from to 1 with an nse value equal to 1 indicates perfect model performance the optimal pbias is 0 0 a negative value indicates a model bias toward underestimation whereas a positive value denotes a bias toward overestimation gupta et al 1999 intel parallel studio xe composer edition and microsoft visual studio 2013 were used to modify and compile the swat source code statistical analyses were performed using the statistical package for social science software spss 22 0 inc chicago il usa analysis of variance was used to test the difference with the significance level of p 0 05 microsoft excel 2016 was used for other data analysis 3 results and discussion 3 1 swat model performance for et and lai simulations the nse and pbias values for daily et simulations were 0 85 and 0 2 respectively during the calibration period 2001 2005 and 0 80 and 1 9 respectively during the validation period 2006 2010 under the baseline scenario table 2 the model performance for both periods demonstrated a very good agreement between the simulated and observed et according to moriasi et al 2007 criteria under the baseline scenario the simulated average annual 2001 2010 potential et pet based on the penman monteith method was 1786 mm fig 4 there was limited average annual runoff 0 91 mm and percolation 4 03 mm chen et al 2016 simulated an average annual 1994 2009 surface runoff of 3 4 mm under the irrigated cotton land use in the thp using swat in this study furrow diking in the irrigated lysimeter field minimized runoff rosenberg et al 1999 simulated a similar value of recharge to the ogallala aquifer 6 mm yr 1 as to the 4 03 mm in this study using the hydrologic unit model for the united states humus approximately 99 of the water from precipitation 496 0 mm and irrigation 380 7 mm was converted to et 872 6 mm due to the much higher pet demand 1786 mm than the total water input 876 7 mm hao et al 2014 also reported that more than 90 of the growing season precipitation was used as growing season et in biomass sorghum fields in the thp in semi arid regions et is easily the largest component of the water balance a graphical comparison showed that swat simulated lai after calibration matched the observed data well fig 3 a good fit of simulated lai is beneficial for achieving reasonable partitioning of transpiration and evaporation which in turn contribute to the accurate simulations of both the hydrologic cycle and plant growth yimam et al 2015 in this study it is of primary importance to obtain good lai simulation agreement due to the development of fao mads for the schedule by date option the constant mad auto irrigation scheduled by date showed similar model performance for et as compared to the swat default auto irrigation with nse values of 0 70 and 0 66 during calibration and validation periods respectively table 2 the fao mad auto irrigation schedule by date achieved a slightly improved et simulation for the calibration and validation periods nse of 0 75 and 0 68 respectively as compared to the swat default auto irrigation and constant mad auto irrigation schedule by date table 2 the swat default auto irrigation schedule by heat units failed to achieve a satisfactory nse value 0 48 for et during 2006 2010 table 3 however the constant mad auto irrigation schedule by heat units showed satisfactory model performance during calibration nse of 0 61 and validation nse of 0 51 periods table 3 the nse value was further improved to 0 64 under the fao mad auto irrigation schedule by heat units during the calibration period table 3 it is worth noting that in general the management method of schedule by date simulated a much better approximation of et than the management method of schedule by heat units the scheduling by heat units method is typically used in large complex watersheds for which users have little to no detailed information about the management scheduling jager et al 2015 wang et al 2016 in the absence of such information confidence in simulation results are less as compared to studies with more detailed management information inputs such as field scale studies 3 2 comparison of seasonal irrigation schedule by date in order to build new tools algorithms for existing models existing functions need to be evaluated and compared papajorgji and shatar 2004 when compared to the actual irrigations the nse and pbias values achieved for the simulation of annual irrigation amount during the entire simulation period from 2001 to 2010 were 4 05 and 46 3 respectively under the swat default auto irrigation schedule by specific date fig 5 a the irrigation amount for the swat default auto irrigation schedule by specific date was significantly higher than the actual irrigation amount p 0 013 0 05 simulations using the constant mad auto irrigation schedule by date option still resulted in an unsatisfactory performance although nse and pbias values improved to 1 64 and 21 7 respectively fig 5b however the relative increase in nse was substantial at 2 41 and pbias was reduced by 24 6 as compared to those of the swat default auto irrigation scenario no significant difference was found between irrigation amounts from the simulated constant mad and the actual irrigation p 0 19 0 05 using the fao mad auto irrigation schedule by date resulted in satisfactory model performance nse and pbias of 0 54 and 5 2 respectively for irrigation amount fig 5c in this study the unlimited irrigation source was used rather than the deep aquifer option to eliminate the influence of aquifer capacity on model code development the simplified representation aquifers in swat is largely unrealistic in reality an irrigation of a particular depth does not necessarily correlate to a corresponding change in depth of aquifer below as groundwater movement also has a horizontal component as such well capacity which can be adequately represented using the daily maximum irrigation amount is a much more realistic mechanism for simulating actual regional irrigation capacities using the unlimited source option allowed for simulated irrigations to occur based on the auto irrigation algorithms resulting in an overall overestimation of irrigation amount compared to the actual irrigation as described above in reality users are allowed to set the irrigation source to reach reservoir shallow aquifer deep aquifer or unlimited source outside watershed according to their demand due to the soft coding of the mad auto irrigation function users should be aware that using the aquifer source options may limit irrigation as aquifer depletion may be artificially accelerated due to the oversimplified representation of aquifer volume in swat some large inter annual variabilities in pbias were found for the 2001 cotton 55 2 2005 grain sorghum 18 5 2006 forage corn 25 9 and 2008 cotton 25 6 limited irrigation was performed in 2001 cotton based on the management record which may account for the large variation as for the 2005 grain sorghum only four measured lai values were available which may have led to an unreliable lai calibration especially when no senescence point was measured fig 3 there was a large variation in the measured lai for 2006 forage corn which was likely attributable to damage from an undetermined plant virus or herbicide the long tail of simulated lai for the 2008 cotton during the late season stage may have resulted in larger simulated et values relative to observed et resulting in the triggering of more irrigation events as compared to actual irrigation events 3 3 comparison of seasonal irrigation schedule by heat units in watershed scale studies model users may not know the management information by specific date and elect to schedule auto irrigation by heat units the nse and pbias values were 6 44 and 57 respectively for simulation of annual irrigation amount under the swat default auto irrigation schedule by heat units as compared to the actual irrigation fig 6 a similar to results for scheduling by date the irrigation amount under the swat default auto irrigation schedule by heat units was significantly higher than the actual irrigation amount p 0 008 0 05 resulting nse and pbias values were 4 69 and 37 3 respectively under the constant mad auto irrigation schedule by heat units fig 6b the improvement of nse and pbias was 1 75 and 19 7 respectively relative to the swat default auto irrigation scenario in addition there was no significant difference between simulated irrigation and observed data at p 0 05 level p 0 07 a further improvement in nse and pbias to 3 52 and 29 9 respectively was found for the fao mad auto irrigation schedule by heat units fig 6c all of the auto irrigation scenarios using schedule by heat units resulted in a low nse value however the mad auto irrigation algorithms suggested a significant improvement in irrigation simulation reduced pbias values as compared to the swat default auto irrigation schedule by heat units excluding cotton improved model performance was achieved in the simulation of irrigation amount nse and pbias 0 26 and 2 under the fao mad auto irrigation schedule by heat units fig 6d cotton is essentially a perennial shrub that is cultivated as an annual crop ton 2004 vegetative growth will continue under well watered conditions under full irrigation conditions the model auto irrigation tends to supply adequate water for crop growth however thp producers suspend irrigation for cotton during the cotton late growing season to promote boll set and opening the nse values of simulated irrigation amounts using the schedule by heat units option were much lower than those of the schedule by date option the best simulation performance for et and irrigation resulted from using the fao mad auto irrigation schedule by specific date the availability of the observed lai data was essential for this mad auto irrigation development therefore the measurement of lai is important given the model calibration and improvement of simulations for et and irrigation scheduling duchemin et al 2008 also concluded the collection of lai information is critical for accurate crop modeling furthermore many non destructive techniques are available for lai estimation including hand held radiometers and remote sensing from ground space gow et al 2016 it is worth noting that even though the irrigation simulations under the schedule by heat units method exhibited a large bias the nse values for the et simulations were within the satisfactory range this is an example of what modelers commonly refer to as getting a right answer for the wrong reason swat is typically calibrated for hydrologic parameters such as streamflow surface runoff with considerably fewer studies using soil water content and et wellen et al 2015 also limited studies have compared irrigation simulations due to the lack of the actual irrigation scheduling for such comparisons tian et al 2015 in this study the key reason for a satisfactory et simulation but with apparently biased irrigation output from the swat default auto irrigation scenarios was due to the relatively low number of irrigation events in each year 20 per year for the actual irrigations compared to 345 days of non irrigation conditions 3 4 comparison of monthly irrigation irrigation scheduling the monthly swat default auto irrigation of schedule by date and heat units showed more frequent irrigation of relatively smaller amounts as compared to the actual irrigation figs 7a and 8 a also the swat default auto irrigation applied irrigation water during the crop non growing season for example the swat default auto irrigation triggered irrigation events in january of 2009 and 2010 figs 7a and 8a a significantly higher irrigation amount was also found under the swat default auto irrigation schedule by heat units compared to the actual irrigation p 0 03 0 05 although the constant mad auto irrigation suspended the non growing season irrigation more than a 20 bias was still observed figs 7b and 8b the monthly irrigation comparisons indicated the fao mad auto irrigation schedule by date resulted in irrigation scheduling much more representative of the actual irrigation with nse and pbias values of 0 61 and 5 2 respectively fig 7c the fao mad auto irrigation schedule by heat units also exhibited a more reasonable irrigation frequency relative to the swat default auto irrigation schedule by heat units fig 8c however differences in daily comparisons of simulated and actual irrigation frequency did exist data not shown irrespective of mad calibration as the occurrence of actual irrigations may shift as a result of on farm irrigation scheduling with other irrigated research or production fields the fao mad auto irrigation schedule by heat units also suggested excessive irrigation pbias of 29 9 as compared to actual irrigation a more reasonable match nse and pbias 0 46 and 2 0 was observed for the fao mad auto irrigation schedule by heat units when the cotton years were not considered fig 8d the statistical performance for monthly irrigation results was much better than that of annual results a major contributing factor for this was the occurrence of months without irrigation additionally the monthly comparisons not only indicated a comparison of the irrigation amount but also included an irrigation frequency comparison 3 5 comparison of crop growth response crop lai and yield simulated crop yields under multiple auto irrigation scenarios swat default constant mad growth stage specific mad using both schedule by specific date and heat units varied only minimally from observed yields fig s1 in the swat model the water stress factor can be used to correct the simulated biomass throughout the growing season and the crop specific harvest index determines yield from the final biomass value in this study the full irrigation was scheduled to avoid plant water stress and the same crop database values were used for all scenarios irrigation was managed so that all crops experienced negligible water stress under all the scenarios this explains the observance of only minimal changes in simulated crop yield as compared to the observed data as for the lai values no significant changes were observed for the auto irrigation scenarios scheduled by specific data when compared to the measured lai values figs s2 s5 negligible water stress contributed to the minimal differences in lai between the simulated and measured values however differences between simulated and observed lai values were apparent for the 2005 grain sorghum and 2006 forage corn schedule by heat units figs s6 s8 this is primarily due to the replanting of the two crops following early season hail damage and undetermined plant virus damage in 2005 and 2006 respectively the heat unit accumulation growth model used to determine crop maturity is unable to represent the replanting of a crop this is the fundamental reason for the distinct leftward shift of the simulated lai curve early planting for 2005 grain sorghum and 2006 forage corn relative to the observed data a similar shift in simulated lai was observed for the 2009 sunflower crop due to the scheduled planting to occur once 0 15 heat units had accumulated which resulted in an earlier planting than the actual planting date 4 conclusions irrigation has enabled the texas high plains to be one of the most productive agricultural regions for supplying food and fiber in the united states however the decreasing availability of groundwater for irrigation has become a catalyst for the development and implementation of alternative cropping strategies and irrigation management in the region swat is an open source hydrologic model that not only allows users to simulate targeted scenarios but also offers opportunity to improve model representativeness through modification of the source code in this study mad auto irrigation algorithms were developed and evaluated using field data from an irrigated lysimeter at the usda ars cprl in bushland texas results indicated that the swat default auto irrigation functions simulated reasonable values for et nse 0 5 however simulated irrigation was significantly larger 50 than actual irrigation p 0 05 although use of the constant mad auto irrigation algorithms improved model et simulation slightly as compared to the swat default auto irrigation scenarios the simulation of seasonal irrigation was greatly improved nse increased more than 1 7 results from the fao mad auto irrigation algorithms not only demonstrated further improvements in et simulation but also indicated an improvement in the simulation of irrigation magnitude and frequency the fao mad auto irrigation schedule by date which was developed using calibrated lai exhibited the best fit for both et nse calibration and validation 0 75 and 0 68 and irrigation nse and pbias 0 54 and 5 2 among all the auto irrigation management scenarios this result highlighted the importance of detailed management information for minimizing uncertainty in model simulations in addition adequate periodic measurements of lai are pivotal for identifying growth stage separation points for use with the fao mad auto irrigation schedule by date option however modeling of large and or complex watersheds will likely require use of scheduling by heat units option results from this study showed less robust model performance for et and irrigation simulations under the schedule by heat units relative to those of the schedule by date option however use of the fao mad auto irrigation schedule by heat units option resulted in improved simulation of both et and irrigation as compared to the swat default auto irrigation schedule by heat units the mad algorithms were evaluated using cprl field data for crop irrigation management designed to avoid water stress conditions future model testing of the mad algorithms using limited irrigation datasets will provide additional measures of model performance in water limited scenarios which is prevalent in current thp and other production environments additionally testing in other climatic regions and soil types will further assess the efficacy of the mad based auto irrigation algorithms acknowledgments this research was supported in part by the ogallala aquifer program a consortium between usda agricultural research service kansas state university texas a m agrilife research texas a m agrilife extension service texas tech university and west texas a m university we gratefully thank the three anonymous reviewers for their valuable suggestions for improving this paper appendix a supplementary data the following is the supplementary data related to this article supplementary data supplementary data appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2017 09 013 
26468,water resources systems face irreducible uncertainty in supply and demand requiring policies to respond to changing conditions on multiple timescales for both short term operation and long term adaptation thresholds or decision triggers where a policy links observed indicators to actions have featured prominently in recent studies there remains a need for a general method to conceptualize threshold based policies in an easily interpretable structure and a corresponding search algorithm to design them here we propose a conceptual and computational framework where policies are formulated as binary trees using a simulation optimization approach folsom reservoir california serves as an illustrative case study where policies define the thresholds triggering flood control and conservation actions candidate operating rules are generated across an ensemble of climate scenarios incorporating indicator variables describing longer term climate shifts to investigate opportunities for adaptation policy tree optimization and corresponding open source software provide a generalizable interpretable approach to policy design under uncertainty 1 introduction control policies for water and environmental systems must be designed at timescales for which projections of exogenous variables remain highly uncertain pahl wostl 2007 this challenge is primarily driven by nonstationary climate but is amplified by uncertainties in hydrologic and human systems hallegatte 2009 brown et al 2015 the resulting cascade of uncertainty wilby and dessai 2010 inhibits traditional planning methods and has prompted the development of non probabilistic approaches to vulnerability assessment and policy design dessai and hulme 2004 kwakkel et al 2016 much of the work in this area has focused on long term adaptation measures such as infrastructure sequencing mortazavi naeini et al 2014 beh et al 2015 zeff et al 2016 however changes in short term management policies such as reservoir operations urban water conservation and agricultural practices have also been explored as alternative or complementary adaptation measures giuliani et al 2016c culley et al 2016 the role of operating policies in adaptation is increasingly recognized as the performance of a system is often driven by the accumulation of short term decisions moreover the extreme events for which policies are designed are often the most difficult to project with certainty requiring robust policies able to withstand unanticipated conditions walker et al 2001 lempert 2002 herman et al 2015 giuliani and castelletti 2016 a common theme among studies of both long term adaptation and short term management policies has been the use of thresholds or decision triggers where a system changes course in response to observations the long term adaptation problem is perhaps best framed by haasnoot et al 2013 as a choice from a set of candidate pathways in the water resources field this most commonly refers to climate adaptation the response to observed or expected changes in climatic stimuli adger et al 2005 implying decadal timescales or greater by contrast in the socio environmental systems field adaptation may refer to any action taken to manage a system including responses to short timescale stimuli walker et al 2004 folke et al 2010 most reservoir operating policies adapt to short term observations via feedback control loops which explicitly condition management decisions on the system state castelletti et al 2008 embedding long term adaptation mechanisms in operating policies remains an open issue regardless of timescale designing decision thresholds relies on the concept of tipping points which define the conditions under which a current or planned policy will cease to meet its objectives kwadijk et al 2010 these tipping points may then be translated to a scenario dependent ending date for each policy haasnoot et al 2012 in a nonstationary climate this adaptive mechanism allows the management policy to respond to new information as it becomes available while remaining robust to unexpected change hall et al 2014 computational methods to generate adaptive pathways have included evolutionary algorithms with mixed integer formulations to explore the combinatorial problem of sequencing actions on a fixed time interval kwakkel et al 2015 for shorter operational timescales policies with decisions triggered by observations are fundamental in water resources e g young 1967 reservoir operating rules often involve discrete thresholds leading to a release decision shih and revelle 1995 either for water supply or flood control similarly in urban water management studies decision triggers have been used to implement conservation measures or activate alternative supplies mortazavi et al 2012 zeff et al 2014 mortazavi naeini et al 2015 borgomeo et al 2016 these studies in particular have used simulation optimization approaches where the structure of the decision rule is fixed and threshold values are searched as continuous decision variables the design of short term policies can play an important role in long term adaptation which might involve redefining policies more suitable to projected climate scenarios giuliani et al 2016a or the inclusion of longer timescale information in the policy itself the concept of decision triggers holds promise for control problems across multiple timescales to generalize a threshold based policy combines a set of candidate actions with a set of trigger conditions defined by indicator variables and their threshold values several important challenges have been recognized including the design and selection of indicators in cases where multiple observed variables are expected to influence the decision groves et al 2015 haasnoot et al 2015 giuliani et al 2015 accounting for this challenge requires a method in which the structure of the rule can be searched in addition to the threshold values there remains a need to generalize the design of threshold based policies without prespecifying the threshold values sequence or timing of actions in other words to optimize the set of conditions under which certain actions are taken rather than the actions themselves in this paper we frame the design of management policies over multiple timescales as a simulation optimization problem in which the policy is represented as a binary tree the tree structure allows actions to be conditioned on multiple indicator variables characterizing current system conditions as well as longer term climatological variables this combination of short and long term information improves the ability of the resulting solutions to adapt across a range of uncertain futures in addition this approach facilitates the interpretation of the optimized policies by decision makers because the logical rules triggering a specific action can be easily visualized this study focuses on triggering reversible actions such as flood control and hedging operations rather than irreversible ones such as infrastructure investment although precedent exists for the latter statistical concerns arise for actions only triggered once a topic for future study we demonstrate the policy tree optimization method using folsom reservoir california as an illustrative case study first we test the algorithmic performance under historical conditions against solutions designed with traditional control methods the result serves as the baseline policy without any long term adaptation measures we then use the method to develop policy trees capable of navigating a wide range of plausible climate change scenarios the resulting policies suggest how operating rules and thresholds might be adapted in the future despite highly divergent projections of water supply risk due to nonstationary climate 2 methods 2 1 problem statement managed water systems can be modeled with the state transition equation 1 s t 1 f s t u t q t 1 t 0 h where s u and q are vectors of state decision and disturbance variables and h is the evaluation horizon the naming convention reflects a standard reservoir management problem where these are storage release decision and inflow vectors respectively though the approach can be applied to other types of policy design problems with different control variables the time subscript of each variable denotes the time instant at which it assumes a deterministic value the reservoir storage is measured at time t and thus is denoted as s t while inflow in the interval t t 1 is denoted as q t 1 because it can be known only at the end of the time interval the goal is to choose the sequence of release decisions u t for t 0 h 1 that minimizes a cost function j s 0 u 0 h 1 q 1 h for the initial condition s 0 and a particular inflow series q 1 h subject to the state transition equation 1 a common approach to determine the optimal sequence of release decisions is to define an operating policy as a parametric function p θ that provides the release decisions at each timestep t given the current system conditions x t i e state variables along with additional indicator variables in the literature a number of operating rules based on storage and inflow have been proposed e g oliveira and loucks 1997 lund and guzman 1999 an alternative to these rules is represented by the use of nonlinear approximating networks e g raman and chandramouli 1996 busoniu et al 2011 giuliani et al 2014 which provide more flexibility to the operating policy given the selected parameterization of the operating policy p θ the exploration of the parameter space θ θ leads to the policy that optimizes the cost function j 2 θ arg min θ j s 0 p θ q 1 h this direct policy search approach originated in the artificial intelligence field rosenstein and barto 2001 and has been adopted in water resources as parameterization simulation optimization koutsoyiannis and economou 2003 recently extended for multi objective operations problems giuliani et al 2016b 2017 quinn et al 2017 the choice of the parameterized function family may be connected to the choice of the policy input variables policy search is both an information selection problem hejazi et al 2008 giuliani et al 2015 as well as a real valued optimization problem e g zatarain salazar et al 2016 2 2 policy trees in this study we represent policies as binary trees replacing the real valued optimization problem in equation 2 with a search for a set of hierarchical rules to select decisions at each timestep from a discrete set of actions a i a fig 1 each action can be thought of as a different operating mode e g flood control water supply hedging selected according to the current system conditions x t we would like to search for the optimal policy tree t such that the sequence of actions a t t x t minimizes the cost function subject to the dynamics of the system i e 3 t arg min t j s 0 t q 1 h specifically given the set of policy inputs x x hereafter indicator variables and actions a the goal is to partition the indicator space into an arbitrary number of regions r i x defined by constant thresholds k 4 r i x x 1 k 1 x 2 k 2 where each region r i corresponds to an action a i a in other words at time t in the simulation model a t a i if x t r i the number of regions does not necessarily equal the number of candidate actions it may be lower if some actions are not included in the partitioning or higher if some actions appear in more than one region of the indicator space the union of all r i covers the full indicator space i e i 1 n r i x and the regions are mutually exclusive r i r j i j where i j tree structured operating policies offer several advantages the first and perhaps most important is interpretability space partitioning methods such as prim friedman and fisher 1999 and cart breiman et al 1984 have seen widespread application in scenario discovery as well as historical policy fitting in water resources applications bessler et al 2003 yang et al 2016 in part because their results are readily interpretable in high dimensional indicator spaces the method proposed in this paper follows a similar approach but assigns actions rather than outcomes to the regions of the indicator space it explicitly optimizes the tree based policy with respect to an objective function rather than fitting a tree to historical observations this means that the performance of the tree based policy must be evaluated using a simulation model where the tree is used to make decisions at each timestep policy design is therefore a simulation optimization problem rather than a regression problem second this approach directly answers the question under what conditions should certain actions be taken which makes the resulting policies transferable to other forcing scenarios finally the concept of state action rules applies equally to long term adaptation with its focus on signposts and tipping points and short term operation where many policy search methods have originated a policy tree may combine indicators and actions across both timescales 2 3 algorithm the optimization problem in equation 3 may be noisy multimodal or discontinuous making it intractable for gradient based techniques heuristic methods such as evolutionary algorithms have been widely used for such problems as they are able to find approximate solutions despite these difficulties nicklow et al 2010 reed et al 2013 maier et al 2014 evolutionary algorithms are most often applied to real valued problems where decision variables are optimized on a continuous bounded domain in this respect equation 3 is unusual because the decision variable t is a tree structure heuristic optimization of tree structures is the domain of genetic programming koza 1992 a subfield of evolutionary computation concerned with the automated design of computer programs i e hierarchical sets of instructions genetic programming requires the user to specify the set of functions to be used for the internal nodes of the tree the candidate values for terminal nodes and the objective function poli et al 2008 a common application of genetic programming is symbolic regression where the function set includes mathematical operations such as arithmetic or trigonometric functions and the terminals are variables and constants e g bongard and lipson 2007 a similar type of genetic programming has been developed for reservoir operations fallah mehdipour et al 2012 ashofteh et al 2015 where complex nonlinear functions compute releases as a function of inflow and storage similar to a neural network the computational approach developed for this study is a variant of genetic programming customized for binary trees including a discrete set of actions on the terminal nodes fig 1 the internal indicator nodes of the tree perform logical comparisons between an indicator variable and a threshold value returning a boolean value the terminal action nodes are strings representing actions to be taken mathematical details of the actions corresponding to each string must be defined in the simulation model as in any evolutionary algorithm a population of solutions is maintained and updated by combining elements of the most promising solutions the basic structure of this algorithm is a μ λ evolution strategy where the best μ solutions from a population of size λ are chosen as parents for the next generation the child solutions are only accepted if they outperform the parents an elitist strategy which guarantees monotonically improving objective function values bäck and schwefel 1993 multiple random trials are used to avoid convergence to a local optimum the algorithm must perform several operations initialization crossover and mutation all trees are represented as lists in a depth first order to facilitate these operations to generate a random initial population the algorithm uses a grow procedure for each solution koza 1992 beginning with an empty list the grow procedure appends indicator nodes using randomly chosen variables and thresholds with probability p t a terminal node will be added instead using a randomly chosen action this process continues until a user specified maximum depth d max has been reached after which only terminal nodes are added until the tree is complete trees created by this procedure are not always full i e where all branches extend to the maximum depth however we can use the special case of full trees to estimate the size of the search space a full tree with depth d will have 2 d 1 indicator nodes and 2 d action nodes if there are n i indicator variables and n a actions to choose from the number of possible full tree structures scales as n i 2 d 1 n a 2 d the double exponential scaling shows that the depth d drives the difficulty of the search making it very unlikely for the random initialization procedure to generate a near optimal policy crossover and mutation operations are illustrated in fig 2 crossover fig 2a is performed on each member of the population with probability p c and simply swaps subtrees from two parents chosen randomly without replacement from the set of μ to generate a child tree this subtree crossover procedure was inspired by the deap library distributed evolutionary algorithms in python fortin et al 2012 and adapted for the specific case of binary trees crossover will occasionally increase the depth of the child trees a phenomenon known as bloat when left unchecked koza 1992 to avoid this crossover is repeated until the maximum depth requirement is satisfied child trees not generated from crossover with probability 1 p c are replaced with a randomly generated tree using the initialization procedure to encourage exploration of the solution space and avoid premature convergence mutation fig 2b is then performed on all members of the new population each node in the tree is mutated with probability p m for indicator nodes a truncated gaussian mutation is performed on the threshold value following the standard approach for evolution strategy methods bäck and schwefel 1993 and the indicator variable itself is unchanged the threshold value is normalized to 0 1 before the mutation with σ 0 1 to avoid scaling issues with different indicator variables to mutate action nodes a random sample is taken from the discrete set of candidate actions with replacement finally a pruning step fig 2c must be performed to simplify undesirable subtrees created by crossover and mutation where both true and false branches point to the same action blue or the logical relationships between thresholds create unreachable branches red source code for the algorithm is available on github https github com jdherman ptreeopt all code and data from this paper is included in the paper branch the master branch is intended for general use 3 case study experiment 3 1 folsom reservoir folsom reservoir is the primary water supply and flood control reservoir on the american river in northern california fig 3 a b with an active capacity of 966 thousand acre feet taf or 1 19 km3 completed in 1955 as part of the central valley project cvp the reservoir provides agricultural and municipal water supply hydropower environmental flows and flood protection for the city of sacramento the american river basin covers an area of 1850 mi2 with most precipitation historically falling as snow at elevations above 5000 ft carpenter and georgakakos 2001 fig 3c shows the exceedance curves for daily inflow to folsom with one curve per year over the period 1955 2016 inflows for the period 1955 1995 are included to show historical variability but are not used in the model for this study these were reconstructed from two gages maintained by the united states geological survey american river at fair oaks 11446500 available since 1904 and north fork american river 11427000 available since 1941 inflow data for 1995 2016 is provided by the u s bureau of reclamation along with daily storage and release data through the california data exchange center cdec http cdec water ca gov fig 3d shows average daily releases over the year averaged over the period 1995 2016 which serve as a proxy for daily water demand d t in this study the averages exclude flood control releases which are defined as releases exceeding 12 taf day a 25 day centered moving average is applied to smooth daily variability in reality water demands from folsom are far more complicated since the reservoir is operated in coordination with other cvp reservoirs to meet statewide urban agricultural and environmental uses water demands will also fluctuate from year to year depending on climate and economic conditions however the historical average releases shown in fig 3 show a clear seasonality with a peak in the irrigation season a reasonable simplification for this illustrative case study we use a single reservoir mass balance model with a daily timestep to represent the system following equation 1 target releases are determined each day by a candidate policy tree infrastructure constraints and rule curves are drawn from available literature including the maximum release rate as a function of storage and the winter flood pool requirements mgs engineering consultants 2005 maher 2011 the model does not account for several smaller reservoirs upstream that provide additional flood control space during large storms a common objective function for this problem would be a squared water supply deficit to be minimized reflecting the fact that large deficits are disproportionately more costly than small ones turner and galelli 2016 5 j 1 h t 0 h max d t r t 1 0 2 s t r t 1 r max t where r t 1 represents the actual release after constraints and spill have been accounted for and r max is the maximum safe downstream release 130 000 cfs at folsom however evolutionary algorithms tend to struggle with hard constraints such as equation 5 since the random initial solutions will likely fail to satisfy the constraint to overcome this issue we instead modify the objective function with a large penalty for flooding 6 j 1 h t 0 h max d t r t 1 0 2 t 0 h c max r t 1 r max 0 2 this formulation ensures that the magnitude of flooding affects the objective function which allows the optimization to make progress toward reducing the flood volume unlike the hard constraint in equation 5 a value of c 103 was chosen to ensure that spill exceeding the downstream flow capacity will be penalized far more heavily than supply deficit policies optimized using equation 6 which fail to meet r t 1 r max at any timestep are considered infeasible later in the analysis these are easily identified by objective function values orders of magnitude larger than other solutions the percentage of infeasible solutions in the population depends on the hydrology for severe flood scenarios the algorithm may not find any policy that satisfies the flooding requirement other constraints that would be required for classical optimization such as mass balance and infrastructure capacity are imposed by the simulation model like many reservoir systems in the western u s folsom reservoir is expected to face several challenges under climate change fig 4 shows projected changes to volume and timing of inflow drawn from a u s bureau of reclamation study in which downscaled climate data from the cmip5 ensemble was run through the variable infiltration capacity vic model to create routed streamflow projections reclamation 2014 fig 4a shows the 50 year moving average of annual inflow to the reservoir with substantial uncertainty in the end of century model projections fig 4b shows the estimate of the 100 year flood event updated cumulatively throughout the time series although the gcm based estimates are biased low relative to historical floods nearly all models suggest an upward trend in flood risk fig 4c shows the distribution of reservoir inflow moving earlier in the year reflecting a loss of snowpack and to a lesser extent an increase in upstream regulation fig 4d confirms this trend showing the 50 year moving average of the water year centroid the day of the water year on which 50 of cumulative runoff is reached declining over the historical record and through the end of the century collectively these statistics underscore the need for adapting operating policies and preparing for a wide range of possible futures 3 2 computational experiments four experiments are performed to demonstrate the ability of the algorithm to design policy trees for the historical period and climate change scenarios descriptions of the experiments are given below tables 1 and 2 describe the indicator variables and actions respectively used in each experiment for constructing the policy trees 1 algorithm test optimize over the time period 1995 2016 using the historical flood pool requirement compare the resulting solutions to the observed storage trajectory and the results from deterministic and stochastic dynamic programming ddp sdp evaluate multiple tree depths and consider convergence efficiency effectiveness and reliability this analysis aims to show the ability of policy tree optimization to design solutions similar to the historical operation encouraging their interpretability for decision makers moreover this comparison shows that the proposed method is competitive with traditional approaches for optimal reservoir control 2 historical optimization optimize over the time period 1995 2016 remove the flood pool requirement and include same day inflow as an indicator variable to explore flexible flood control rules this is equivalent to assuming a perfect 1 day inflow forecast as an initial exploration of alternative flood control options 3 climate change individual scenarios find the optimal policy in each of 97 climate change scenarios over the period 2050 2099 this solution assumes that the operator recognizes the change in climate and revises the policy based on new hydrological conditions it represents the upper bound of system performance in each scenario 4 climate change all scenarios search for an adaptive policy capable of performing well though not optimally in all future scenarios rather than each one individually the policy can be considered adaptive if it includes long term indicators such as climate variables table 1 which allow decisions to change in response to observed climate information adger et al 2005 the objective function is simply the average of equation 6 across all scenarios this solution navigates a range of climate scenarios and reduces the risk of maladaptation for example the use of a policy designed for a single scenario different from the one that actually occurs the ddp and sdp solutions used for comparison in experiment 1 algorithm test are designed by computing the bellman function for each day of the year and over a discretized domain of reservoir storage their performance is evaluated using the same simulation and flood pool requirements from the policy tree optimization experiment over the time period 1995 2016 the stochastic disturbance i e inflow is modeled by means of a time varying periodic lognormal probability distribution calibrated over the full time horizon to provide the same information employed in the policy tree approach the sdp problem formulation hence comprises two state variables i e day of the year and reservoir storage one decision variable and one stochastic disturbance preliminary experiments were performed to calibrate the discretization of state decision and disturbance vectors as a compromise between modeling accuracy and computational requirements table 3 shows the parameters used for the genetic programming method including the number of function evaluations nfe and the algorithm settings which roughly follow recommendations from prior literature bäck and schwefel 1993 the relatively high mutation rate μ is based on testing for this particular case study the choice of d max for experiments 2 4 seeks to minimize the objective function performance found in experiment 1 while avoiding overfitting i e preferring a less complex tree where possible the experiments were parallelized across the number of trials shown in table 3 and performed on the hpc1 cluster at uc davis which contains 60 nodes with 16 cores each running at 2 4 ghz the combined compute time for all experiments was about 20 000 h parallel computing is useful in this initial study to explore convergence properties but is not required the algorithm also runs efficiently on desktop computers 4 results 4 1 algorithm test we would like to investigate whether the algorithm is effective converges to an approximately optimal point efficient converges quickly and reliable converges with high probability across multiple random trials fig 5 a shows the convergence of the objective function value over the number of function evaluations nfe for a maximum tree depth of 4 using 50 random seeds the objective function values associated with deterministic and stochastic dynamic programming ddp sdp are also shown the performance of the policy tree falls between these two ddp represents perfect foresight optimization for this objective function so we expect the policy tree to approach but not exceed this value the algorithm converges reliably across random trials after about 1000 function evaluations and continues to make marginal improvements for the remainder of the search fig 5b shows the distributions of objective function values after 25 000 function evaluations for multiple tree depths in general we might expect the best attainable objective function value to improve as tree depth increases this is true after a depth of 2 but otherwise the benefit of increasing depth is not noticeable the algorithm is able to obtain good performance with relatively simple policies with d max 3 4 we might also expect larger tree depths to require more function evaluations to converge since the search space scales exponentially with depth however 25 000 fe appears sufficient for depths up to 8 for this particular problem policies of all depths outperform sdp while approaching the perfect information limit of ddp a possible cause of this finding is that sdp must assume a probability distribution in this case a cyclostationary lognormal distribution while policy search can train directly on the historical data which better represents the dynamics and autocorrelation of inflow the aim of this comparison is to show that policy search can efficiently obtain solutions with similar performance to well known methods such as sdp while also providing highly interpretable operating rules fig 5c shows the best tree found after 25 000 fe across all random trials for d max 4 this tree combined with the winter flood pool rule will serve as the baseline policy for comparison with later experiments as with any heuristic optimization technique this result is not guaranteed to be the global optimum for the historical period but fig 5a suggests that the algorithm has converged to an approximately optimal solution moreover the thresholds in fig 5c are tailored to the historical period and their performance may not extend to other scenarios for this reason a decision maker might use the threshold values as a guide rather than an exact value a challenge similar to the real world implementation of other policy search methods finally fig 5d shows the trajectory of reservoir storage over the period 1995 2016 generated by the policy tree in fig 5c along with ddp sdp and the observed storage all are constrained by the historical winter flood pool requirement so the tree does not include an action for flood control table 2 the storage trajectory generated by the policy tree is very similar to that from ddp fig 5 shows that the policy tree algorithm can provide performance similar to well known methods despite a restricted set of admissible controls furthermore the convergence is shown to be efficient and not overly sensitive to the depth of the tree 4 2 historical optimization in this experiment the observed 1 day inflow is added as an indicator variable allowing the algorithm to optimize the conditions under which flood control actions are taken rather than relying on the seasonal flood pool requirement this explores the ability of flexible flood control rules to improve water supply in the rest of the year fig 6 a shows the optimal policy tree resulting from 50 trials 25 000 fe each with a maximum depth of 4 see table 3 the policy includes 80 hedging when storage falls below 625 taf and additionally performs flood control actions when inflow exceeds 79 taf day otherwise it proceeds with the regular release schedule to meet daily demand fig 6b shows the same policy as a partitioning of the indicator space note that the third possible indicator the day of the year is not used in the optimal policy this is because flood control operations can now be based on inflow rather than the season so the time of year is less valuable information than the same day inflow fig 6c compares the storage trajectories created by the optimal policy tree with the observed storage over the period 1995 2016 the background colors show the action performed in each interval corresponding to the colors in fig 6a b throughout the period the policy is able to maintain storage levels well above those observed historically because it is not forced to draw down in the winter flood control operations occur during short intervals as shown in fig 6d which is a sub period of fig 6c from november 1996 to may 1997 when the high inflow condition is triggered the reservoir releases the maximum amount subject to infrastructure constraints seeking to create as much of a flood buffer as possible the thresholds are optimized such that the storage trajectory in fig 6d just meets the capacity without exceeding it leaving more water for the rest of the year here we assume a perfect same day inflow forecast for illustrative purposes so the resulting policy does not include any factor of safety related to forecast error in ongoing work this issue will be addressed using a synthetic ensemble of imperfect forecasts over longer lead times 3 7 days 4 3 climate change individual scenarios figs 5 and 6 have shown that the algorithm performs well under historical conditions in the third experiment we investigate how operating policies may need to be modified to adapt to individual gcm scenarios fig 7 a shows all climate scenarios excluding rcp 2 6 plotted on axes which roughly reflect flood and drought risk the vertical axis shows the maximum 7 day inflow in each scenario while the horizontal axis shows the average annual inflow near the end of the century the historical scenario is marked by the black point there are a mix of wetter and drier scenarios on average but nearly all of them show increased flood risk relative to historical data the 7 day peak inflow reflects the fact that sustained high flows may overtop the reservoir even if the 1 day peak during that time is not extreme by historical standards in fig 7a there are many scenarios marked by x for which no policies were found that can adapt to the increased flood risk even if the reservoir is kept nearly empty under all conditions for example fig 7b shows the best policy associated with the highest flood risk scenario which performs flood control operations when storage exceeds 3 taf i e almost always and still cannot manage to meet downstream flooding constraints the threshold at which this occurs roughly 2000 taf week can be considered a limit to adaptation capacity culley et al 2016 in reality flood risk projections for the american river system may be less dire than fig 7a suggests due to several smaller reservoirs upstream that are not included in the simulation model the rest of fig 7c f shows the policies for the scenarios to which operations can be adapted successfully fig 7c contains the scenario with the largest increase in average annual inflow for which floods can be controlled this is done using a combination of storage and inflow thresholds not unlike the historical policy fig 6a but where the storage threshold is more conservative 281 taf compared to 625 taf fig 7d shows the policy for the scenario closest to historical data in terms of flood and drought risk which results in a simple rule to implement flood control based on an inflow threshold with no storage condition required in fig 7e where both flood and drought risk are increased the inflow threshold to trigger flood control is more conservative 55 taf day compared to 117 taf day this policy copes with reduced average water availability by never releasing the full demand only hedging at 90 during non flood periods finally in the driest scenario fig 7f the optimal policy suggests a more complicated series of hedging rules based on storage levels the inflow threshold to trigger flood control actions in this scenario is much higher than in other scenarios because floods are less severe in summary fig 7 provides guidance about what types of policy changes might be needed to adapt to a wide range of plausible flood and drought risks recognizing that none of these scenarios will occur exactly 4 4 climate change all scenarios the policies shown in fig 7 are each tailored to a particular gcm scenario when they are re evaluated in different scenarios performance degrades substantially and they often fail to meet flood control requirements see supplemental material therefore the final experiment seeks to optimize a single policy across the ensemble of gcm scenarios sacrificing some performance in individual scenarios to improve robustness to all of them this experiment is only performed for the scenarios for which policy adaptation alone can control floods fig 7 in the other scenarios infrastructure improvements may be needed to create an adaptive policy several longer term indicator variables are added to the optimization including the moving average annual inflow the estimate of the 100 year flood and the moving average water year centroid table 1 and fig 4 these additional indicators are intended to allow the policy to distinguish between different scenarios and develop rules accordingly while the policy itself remains static during the simulation period the inclusion of longer timescale information enables adaptive capacity in response to shifting climate indicators fig 8 a shows the result of this experiment unlike prior policies this one is conditioned on the day of the year instead of storage in addition to the inflow variable in a system with strong seasonal patterns like california the day of the year is often a proxy for wet dry conditions the policy in fig 8a shows an inflow threshold triggering flood control that is much more conservative than those in fig 7 because the policy must meet flood control requirements across all scenarios of the three long term indicators that were added only the water year centroid wyc appears in the optimal policy the annual inflow and lp3 flood estimate are not included considering fig 4 the water year centroid shows the clearest trend among all of the indicators reflecting its information content for this policy while the inflow and flood risk indicators provide useful information about the past they are not necessarily leading indicators of future conditions to adapt the operating policy fig 8b compares the objective function performance in each climate scenario for three cases the policy optimized to each scenario individually gold the baseline policy using the winter flood pool requirement shown in fig 5 black and the adaptive policy optimized across the ensemble incorporating longer timescale climate indicators blue the climate scenarios are sorted from wet to dry along the vertical axis with the driest scenarios at the top performance of all policies generally decreases along this gradient as expected the baseline policy fails to control flood events in the majority of climate scenarios a deficiency which the adaptive policy is able to fix in these cases the performance of the adaptive policy falls between the optimized and baseline points it does not perform as well as the policy directly optimized to that scenario but substantially outperforms the baseline in other scenarios the baseline solution performs quite well and there is no need for the adaptive policy it is clear that in this system adaptation will be driven primarily by changing flood risk with water supply improvements as a secondary benefit in the absence of more information about the likelihood of these scenarios the adaptive policy shown in fig 8b would be the single best option using this particular set of indicator variables 5 discussion this application of the policy tree optimization method highlights the benefits of policies structured as binary trees efficient search simple interpretation and the ability to adapt rules and information across a range of long term future scenarios this method contributes to the literature on decision triggers for operation and adaptation in which actions are chosen based on the current values of indicator variables relative to specified thresholds binary trees provide interpretable rules that align with the real world use of discrete thresholds for flood control and water supply conservation measures e g basdekas 2014 though some complexity is necessarily sacrificed in the process while this study focuses on the design of reservoir operating policies an important component of climate adaptation benson 2017 the approach can extend to any policy optimization problem where the system is represented by a simulation model here we discuss several important steps for future work statistical validation irreversible actions and indicator selection policies optimized to a single scenario are unlikely to perform well in other scenarios in this study this is particularly true when scenarios differ in flood timing and magnitude policies are more robust when optimized to an ensemble of inflow scenarios whether from a set of gcms or a synthetic generator to account for this uncertainty optimized policies can also be re evaluated in alternative scenarios to test their robustness kasprzyk et al 2013 herman et al 2014 the aggregation of the objective function across scenarios could include the variance in addition to the mean hamarat et al 2014 this approach could be further improved with a leave one out cross validation scheme to prevent overfitting and improve transferability yet even with a formal cross validation there is no guarantee that the scenarios tested will accurately represent the distribution of future outcomes as they only represent a lower bound on the range of uncertainty stainforth et al 2007 ongoing work will explore the role of short term forecasts to overcome this problem recognizing that there is a critical lead time beyond which additional information is not useful the value of forecast information will vary depending on its accuracy and the infrastructure constraints of the system giuliani et al 2015 anghileri et al 2016 related to the issue of validation a distinction must be made between actions that are reversible such as flood control and hedging operations and those that are irreversible such as infrastructure investment while this study focuses only on the former it is increasingly common to optimize both at the same time e g zeff et al 2016 this study focuses on reversible actions because they are likely to be activated several times under different conditions throughout the simulation however more care would need to be taken in the case of infrastructure decisions these will be triggered by the first occurrence of a particular observation regardless of whether this condition truly reflects a trend or is only an anomalous point in this respect policy tree optimization faces the same challenges as real world policy design it must avoid overfitting to a limited record and must separate trend signals from natural variability finally the concept of adaptation presupposes a set of observable indicators that quantify future trends many of the variables we might use for this purpose such as the moving average of annual inflow used in this study are trailing rather than leading indicators of change moreover the long term information needed to identify trends is ill suited to systems where much of the performance is based on short term extreme events the choice of indicator variables will be critical to any policy design study and can perhaps be improved by incorporating trend detection and attribution methods hegerl and zwiers 2011 rosner et al 2014 it may also be desirable to identify correlated indicator variables and combine them to reduce the number of non unique policies the goal of this input variable selection is to choose a subset of indicators that are maximally informative but not redundant galelli et al 2014 it should be formalized for any policy search analysis 6 conclusions this paper contributes a conceptual framework in which control policies are designed as binary trees mapping observed indicators to actions we propose a simulation optimization method to solve problems of this type and demonstrate it using a reservoir operation case study in this example decision thresholds for flood control and water supply hedging are adapted to climate change scenarios by incorporating longer timescale information in the policy the method is also used to design a single policy that performs well across the ensemble of scenarios the algorithm is shown to efficiently approximate the performance of optimal policies from traditional control methods while providing rules that are easy to visualize and interpret compared to existing threshold based policy design methods this approach shifts the key question from identifying when certain actions should be taken to under what conditions they should be taken the policy tree concept applies to short term management of water and environmental systems as well as long term adaptation in future work we aim to show its generality in applications beyond reservoir control policy tree optimization and corresponding open source software provide a template for policy design under uncertainty in water and environmental systems acknowledgments and software availability this work was partially supported by the u s national science foundation infews grant cns 1639268 any opinions findings and conclusions are those of the authors and do not necessarily reflect the views or policies of the nsf we further acknowledge the world climate research program s working group on coupled modeling and the climate modeling groups listed in the supplement of this paper for producing and making available their model output we would like to thank julianne quinn for helpful comments on an early draft of this paper all code and data from this paper is available on github https github com jdherman ptreeopt in the paper branch appendix a supplementary data the following is the supplementary data related to this article supplementary material supplementary material appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2017 09 016 
26468,water resources systems face irreducible uncertainty in supply and demand requiring policies to respond to changing conditions on multiple timescales for both short term operation and long term adaptation thresholds or decision triggers where a policy links observed indicators to actions have featured prominently in recent studies there remains a need for a general method to conceptualize threshold based policies in an easily interpretable structure and a corresponding search algorithm to design them here we propose a conceptual and computational framework where policies are formulated as binary trees using a simulation optimization approach folsom reservoir california serves as an illustrative case study where policies define the thresholds triggering flood control and conservation actions candidate operating rules are generated across an ensemble of climate scenarios incorporating indicator variables describing longer term climate shifts to investigate opportunities for adaptation policy tree optimization and corresponding open source software provide a generalizable interpretable approach to policy design under uncertainty 1 introduction control policies for water and environmental systems must be designed at timescales for which projections of exogenous variables remain highly uncertain pahl wostl 2007 this challenge is primarily driven by nonstationary climate but is amplified by uncertainties in hydrologic and human systems hallegatte 2009 brown et al 2015 the resulting cascade of uncertainty wilby and dessai 2010 inhibits traditional planning methods and has prompted the development of non probabilistic approaches to vulnerability assessment and policy design dessai and hulme 2004 kwakkel et al 2016 much of the work in this area has focused on long term adaptation measures such as infrastructure sequencing mortazavi naeini et al 2014 beh et al 2015 zeff et al 2016 however changes in short term management policies such as reservoir operations urban water conservation and agricultural practices have also been explored as alternative or complementary adaptation measures giuliani et al 2016c culley et al 2016 the role of operating policies in adaptation is increasingly recognized as the performance of a system is often driven by the accumulation of short term decisions moreover the extreme events for which policies are designed are often the most difficult to project with certainty requiring robust policies able to withstand unanticipated conditions walker et al 2001 lempert 2002 herman et al 2015 giuliani and castelletti 2016 a common theme among studies of both long term adaptation and short term management policies has been the use of thresholds or decision triggers where a system changes course in response to observations the long term adaptation problem is perhaps best framed by haasnoot et al 2013 as a choice from a set of candidate pathways in the water resources field this most commonly refers to climate adaptation the response to observed or expected changes in climatic stimuli adger et al 2005 implying decadal timescales or greater by contrast in the socio environmental systems field adaptation may refer to any action taken to manage a system including responses to short timescale stimuli walker et al 2004 folke et al 2010 most reservoir operating policies adapt to short term observations via feedback control loops which explicitly condition management decisions on the system state castelletti et al 2008 embedding long term adaptation mechanisms in operating policies remains an open issue regardless of timescale designing decision thresholds relies on the concept of tipping points which define the conditions under which a current or planned policy will cease to meet its objectives kwadijk et al 2010 these tipping points may then be translated to a scenario dependent ending date for each policy haasnoot et al 2012 in a nonstationary climate this adaptive mechanism allows the management policy to respond to new information as it becomes available while remaining robust to unexpected change hall et al 2014 computational methods to generate adaptive pathways have included evolutionary algorithms with mixed integer formulations to explore the combinatorial problem of sequencing actions on a fixed time interval kwakkel et al 2015 for shorter operational timescales policies with decisions triggered by observations are fundamental in water resources e g young 1967 reservoir operating rules often involve discrete thresholds leading to a release decision shih and revelle 1995 either for water supply or flood control similarly in urban water management studies decision triggers have been used to implement conservation measures or activate alternative supplies mortazavi et al 2012 zeff et al 2014 mortazavi naeini et al 2015 borgomeo et al 2016 these studies in particular have used simulation optimization approaches where the structure of the decision rule is fixed and threshold values are searched as continuous decision variables the design of short term policies can play an important role in long term adaptation which might involve redefining policies more suitable to projected climate scenarios giuliani et al 2016a or the inclusion of longer timescale information in the policy itself the concept of decision triggers holds promise for control problems across multiple timescales to generalize a threshold based policy combines a set of candidate actions with a set of trigger conditions defined by indicator variables and their threshold values several important challenges have been recognized including the design and selection of indicators in cases where multiple observed variables are expected to influence the decision groves et al 2015 haasnoot et al 2015 giuliani et al 2015 accounting for this challenge requires a method in which the structure of the rule can be searched in addition to the threshold values there remains a need to generalize the design of threshold based policies without prespecifying the threshold values sequence or timing of actions in other words to optimize the set of conditions under which certain actions are taken rather than the actions themselves in this paper we frame the design of management policies over multiple timescales as a simulation optimization problem in which the policy is represented as a binary tree the tree structure allows actions to be conditioned on multiple indicator variables characterizing current system conditions as well as longer term climatological variables this combination of short and long term information improves the ability of the resulting solutions to adapt across a range of uncertain futures in addition this approach facilitates the interpretation of the optimized policies by decision makers because the logical rules triggering a specific action can be easily visualized this study focuses on triggering reversible actions such as flood control and hedging operations rather than irreversible ones such as infrastructure investment although precedent exists for the latter statistical concerns arise for actions only triggered once a topic for future study we demonstrate the policy tree optimization method using folsom reservoir california as an illustrative case study first we test the algorithmic performance under historical conditions against solutions designed with traditional control methods the result serves as the baseline policy without any long term adaptation measures we then use the method to develop policy trees capable of navigating a wide range of plausible climate change scenarios the resulting policies suggest how operating rules and thresholds might be adapted in the future despite highly divergent projections of water supply risk due to nonstationary climate 2 methods 2 1 problem statement managed water systems can be modeled with the state transition equation 1 s t 1 f s t u t q t 1 t 0 h where s u and q are vectors of state decision and disturbance variables and h is the evaluation horizon the naming convention reflects a standard reservoir management problem where these are storage release decision and inflow vectors respectively though the approach can be applied to other types of policy design problems with different control variables the time subscript of each variable denotes the time instant at which it assumes a deterministic value the reservoir storage is measured at time t and thus is denoted as s t while inflow in the interval t t 1 is denoted as q t 1 because it can be known only at the end of the time interval the goal is to choose the sequence of release decisions u t for t 0 h 1 that minimizes a cost function j s 0 u 0 h 1 q 1 h for the initial condition s 0 and a particular inflow series q 1 h subject to the state transition equation 1 a common approach to determine the optimal sequence of release decisions is to define an operating policy as a parametric function p θ that provides the release decisions at each timestep t given the current system conditions x t i e state variables along with additional indicator variables in the literature a number of operating rules based on storage and inflow have been proposed e g oliveira and loucks 1997 lund and guzman 1999 an alternative to these rules is represented by the use of nonlinear approximating networks e g raman and chandramouli 1996 busoniu et al 2011 giuliani et al 2014 which provide more flexibility to the operating policy given the selected parameterization of the operating policy p θ the exploration of the parameter space θ θ leads to the policy that optimizes the cost function j 2 θ arg min θ j s 0 p θ q 1 h this direct policy search approach originated in the artificial intelligence field rosenstein and barto 2001 and has been adopted in water resources as parameterization simulation optimization koutsoyiannis and economou 2003 recently extended for multi objective operations problems giuliani et al 2016b 2017 quinn et al 2017 the choice of the parameterized function family may be connected to the choice of the policy input variables policy search is both an information selection problem hejazi et al 2008 giuliani et al 2015 as well as a real valued optimization problem e g zatarain salazar et al 2016 2 2 policy trees in this study we represent policies as binary trees replacing the real valued optimization problem in equation 2 with a search for a set of hierarchical rules to select decisions at each timestep from a discrete set of actions a i a fig 1 each action can be thought of as a different operating mode e g flood control water supply hedging selected according to the current system conditions x t we would like to search for the optimal policy tree t such that the sequence of actions a t t x t minimizes the cost function subject to the dynamics of the system i e 3 t arg min t j s 0 t q 1 h specifically given the set of policy inputs x x hereafter indicator variables and actions a the goal is to partition the indicator space into an arbitrary number of regions r i x defined by constant thresholds k 4 r i x x 1 k 1 x 2 k 2 where each region r i corresponds to an action a i a in other words at time t in the simulation model a t a i if x t r i the number of regions does not necessarily equal the number of candidate actions it may be lower if some actions are not included in the partitioning or higher if some actions appear in more than one region of the indicator space the union of all r i covers the full indicator space i e i 1 n r i x and the regions are mutually exclusive r i r j i j where i j tree structured operating policies offer several advantages the first and perhaps most important is interpretability space partitioning methods such as prim friedman and fisher 1999 and cart breiman et al 1984 have seen widespread application in scenario discovery as well as historical policy fitting in water resources applications bessler et al 2003 yang et al 2016 in part because their results are readily interpretable in high dimensional indicator spaces the method proposed in this paper follows a similar approach but assigns actions rather than outcomes to the regions of the indicator space it explicitly optimizes the tree based policy with respect to an objective function rather than fitting a tree to historical observations this means that the performance of the tree based policy must be evaluated using a simulation model where the tree is used to make decisions at each timestep policy design is therefore a simulation optimization problem rather than a regression problem second this approach directly answers the question under what conditions should certain actions be taken which makes the resulting policies transferable to other forcing scenarios finally the concept of state action rules applies equally to long term adaptation with its focus on signposts and tipping points and short term operation where many policy search methods have originated a policy tree may combine indicators and actions across both timescales 2 3 algorithm the optimization problem in equation 3 may be noisy multimodal or discontinuous making it intractable for gradient based techniques heuristic methods such as evolutionary algorithms have been widely used for such problems as they are able to find approximate solutions despite these difficulties nicklow et al 2010 reed et al 2013 maier et al 2014 evolutionary algorithms are most often applied to real valued problems where decision variables are optimized on a continuous bounded domain in this respect equation 3 is unusual because the decision variable t is a tree structure heuristic optimization of tree structures is the domain of genetic programming koza 1992 a subfield of evolutionary computation concerned with the automated design of computer programs i e hierarchical sets of instructions genetic programming requires the user to specify the set of functions to be used for the internal nodes of the tree the candidate values for terminal nodes and the objective function poli et al 2008 a common application of genetic programming is symbolic regression where the function set includes mathematical operations such as arithmetic or trigonometric functions and the terminals are variables and constants e g bongard and lipson 2007 a similar type of genetic programming has been developed for reservoir operations fallah mehdipour et al 2012 ashofteh et al 2015 where complex nonlinear functions compute releases as a function of inflow and storage similar to a neural network the computational approach developed for this study is a variant of genetic programming customized for binary trees including a discrete set of actions on the terminal nodes fig 1 the internal indicator nodes of the tree perform logical comparisons between an indicator variable and a threshold value returning a boolean value the terminal action nodes are strings representing actions to be taken mathematical details of the actions corresponding to each string must be defined in the simulation model as in any evolutionary algorithm a population of solutions is maintained and updated by combining elements of the most promising solutions the basic structure of this algorithm is a μ λ evolution strategy where the best μ solutions from a population of size λ are chosen as parents for the next generation the child solutions are only accepted if they outperform the parents an elitist strategy which guarantees monotonically improving objective function values bäck and schwefel 1993 multiple random trials are used to avoid convergence to a local optimum the algorithm must perform several operations initialization crossover and mutation all trees are represented as lists in a depth first order to facilitate these operations to generate a random initial population the algorithm uses a grow procedure for each solution koza 1992 beginning with an empty list the grow procedure appends indicator nodes using randomly chosen variables and thresholds with probability p t a terminal node will be added instead using a randomly chosen action this process continues until a user specified maximum depth d max has been reached after which only terminal nodes are added until the tree is complete trees created by this procedure are not always full i e where all branches extend to the maximum depth however we can use the special case of full trees to estimate the size of the search space a full tree with depth d will have 2 d 1 indicator nodes and 2 d action nodes if there are n i indicator variables and n a actions to choose from the number of possible full tree structures scales as n i 2 d 1 n a 2 d the double exponential scaling shows that the depth d drives the difficulty of the search making it very unlikely for the random initialization procedure to generate a near optimal policy crossover and mutation operations are illustrated in fig 2 crossover fig 2a is performed on each member of the population with probability p c and simply swaps subtrees from two parents chosen randomly without replacement from the set of μ to generate a child tree this subtree crossover procedure was inspired by the deap library distributed evolutionary algorithms in python fortin et al 2012 and adapted for the specific case of binary trees crossover will occasionally increase the depth of the child trees a phenomenon known as bloat when left unchecked koza 1992 to avoid this crossover is repeated until the maximum depth requirement is satisfied child trees not generated from crossover with probability 1 p c are replaced with a randomly generated tree using the initialization procedure to encourage exploration of the solution space and avoid premature convergence mutation fig 2b is then performed on all members of the new population each node in the tree is mutated with probability p m for indicator nodes a truncated gaussian mutation is performed on the threshold value following the standard approach for evolution strategy methods bäck and schwefel 1993 and the indicator variable itself is unchanged the threshold value is normalized to 0 1 before the mutation with σ 0 1 to avoid scaling issues with different indicator variables to mutate action nodes a random sample is taken from the discrete set of candidate actions with replacement finally a pruning step fig 2c must be performed to simplify undesirable subtrees created by crossover and mutation where both true and false branches point to the same action blue or the logical relationships between thresholds create unreachable branches red source code for the algorithm is available on github https github com jdherman ptreeopt all code and data from this paper is included in the paper branch the master branch is intended for general use 3 case study experiment 3 1 folsom reservoir folsom reservoir is the primary water supply and flood control reservoir on the american river in northern california fig 3 a b with an active capacity of 966 thousand acre feet taf or 1 19 km3 completed in 1955 as part of the central valley project cvp the reservoir provides agricultural and municipal water supply hydropower environmental flows and flood protection for the city of sacramento the american river basin covers an area of 1850 mi2 with most precipitation historically falling as snow at elevations above 5000 ft carpenter and georgakakos 2001 fig 3c shows the exceedance curves for daily inflow to folsom with one curve per year over the period 1955 2016 inflows for the period 1955 1995 are included to show historical variability but are not used in the model for this study these were reconstructed from two gages maintained by the united states geological survey american river at fair oaks 11446500 available since 1904 and north fork american river 11427000 available since 1941 inflow data for 1995 2016 is provided by the u s bureau of reclamation along with daily storage and release data through the california data exchange center cdec http cdec water ca gov fig 3d shows average daily releases over the year averaged over the period 1995 2016 which serve as a proxy for daily water demand d t in this study the averages exclude flood control releases which are defined as releases exceeding 12 taf day a 25 day centered moving average is applied to smooth daily variability in reality water demands from folsom are far more complicated since the reservoir is operated in coordination with other cvp reservoirs to meet statewide urban agricultural and environmental uses water demands will also fluctuate from year to year depending on climate and economic conditions however the historical average releases shown in fig 3 show a clear seasonality with a peak in the irrigation season a reasonable simplification for this illustrative case study we use a single reservoir mass balance model with a daily timestep to represent the system following equation 1 target releases are determined each day by a candidate policy tree infrastructure constraints and rule curves are drawn from available literature including the maximum release rate as a function of storage and the winter flood pool requirements mgs engineering consultants 2005 maher 2011 the model does not account for several smaller reservoirs upstream that provide additional flood control space during large storms a common objective function for this problem would be a squared water supply deficit to be minimized reflecting the fact that large deficits are disproportionately more costly than small ones turner and galelli 2016 5 j 1 h t 0 h max d t r t 1 0 2 s t r t 1 r max t where r t 1 represents the actual release after constraints and spill have been accounted for and r max is the maximum safe downstream release 130 000 cfs at folsom however evolutionary algorithms tend to struggle with hard constraints such as equation 5 since the random initial solutions will likely fail to satisfy the constraint to overcome this issue we instead modify the objective function with a large penalty for flooding 6 j 1 h t 0 h max d t r t 1 0 2 t 0 h c max r t 1 r max 0 2 this formulation ensures that the magnitude of flooding affects the objective function which allows the optimization to make progress toward reducing the flood volume unlike the hard constraint in equation 5 a value of c 103 was chosen to ensure that spill exceeding the downstream flow capacity will be penalized far more heavily than supply deficit policies optimized using equation 6 which fail to meet r t 1 r max at any timestep are considered infeasible later in the analysis these are easily identified by objective function values orders of magnitude larger than other solutions the percentage of infeasible solutions in the population depends on the hydrology for severe flood scenarios the algorithm may not find any policy that satisfies the flooding requirement other constraints that would be required for classical optimization such as mass balance and infrastructure capacity are imposed by the simulation model like many reservoir systems in the western u s folsom reservoir is expected to face several challenges under climate change fig 4 shows projected changes to volume and timing of inflow drawn from a u s bureau of reclamation study in which downscaled climate data from the cmip5 ensemble was run through the variable infiltration capacity vic model to create routed streamflow projections reclamation 2014 fig 4a shows the 50 year moving average of annual inflow to the reservoir with substantial uncertainty in the end of century model projections fig 4b shows the estimate of the 100 year flood event updated cumulatively throughout the time series although the gcm based estimates are biased low relative to historical floods nearly all models suggest an upward trend in flood risk fig 4c shows the distribution of reservoir inflow moving earlier in the year reflecting a loss of snowpack and to a lesser extent an increase in upstream regulation fig 4d confirms this trend showing the 50 year moving average of the water year centroid the day of the water year on which 50 of cumulative runoff is reached declining over the historical record and through the end of the century collectively these statistics underscore the need for adapting operating policies and preparing for a wide range of possible futures 3 2 computational experiments four experiments are performed to demonstrate the ability of the algorithm to design policy trees for the historical period and climate change scenarios descriptions of the experiments are given below tables 1 and 2 describe the indicator variables and actions respectively used in each experiment for constructing the policy trees 1 algorithm test optimize over the time period 1995 2016 using the historical flood pool requirement compare the resulting solutions to the observed storage trajectory and the results from deterministic and stochastic dynamic programming ddp sdp evaluate multiple tree depths and consider convergence efficiency effectiveness and reliability this analysis aims to show the ability of policy tree optimization to design solutions similar to the historical operation encouraging their interpretability for decision makers moreover this comparison shows that the proposed method is competitive with traditional approaches for optimal reservoir control 2 historical optimization optimize over the time period 1995 2016 remove the flood pool requirement and include same day inflow as an indicator variable to explore flexible flood control rules this is equivalent to assuming a perfect 1 day inflow forecast as an initial exploration of alternative flood control options 3 climate change individual scenarios find the optimal policy in each of 97 climate change scenarios over the period 2050 2099 this solution assumes that the operator recognizes the change in climate and revises the policy based on new hydrological conditions it represents the upper bound of system performance in each scenario 4 climate change all scenarios search for an adaptive policy capable of performing well though not optimally in all future scenarios rather than each one individually the policy can be considered adaptive if it includes long term indicators such as climate variables table 1 which allow decisions to change in response to observed climate information adger et al 2005 the objective function is simply the average of equation 6 across all scenarios this solution navigates a range of climate scenarios and reduces the risk of maladaptation for example the use of a policy designed for a single scenario different from the one that actually occurs the ddp and sdp solutions used for comparison in experiment 1 algorithm test are designed by computing the bellman function for each day of the year and over a discretized domain of reservoir storage their performance is evaluated using the same simulation and flood pool requirements from the policy tree optimization experiment over the time period 1995 2016 the stochastic disturbance i e inflow is modeled by means of a time varying periodic lognormal probability distribution calibrated over the full time horizon to provide the same information employed in the policy tree approach the sdp problem formulation hence comprises two state variables i e day of the year and reservoir storage one decision variable and one stochastic disturbance preliminary experiments were performed to calibrate the discretization of state decision and disturbance vectors as a compromise between modeling accuracy and computational requirements table 3 shows the parameters used for the genetic programming method including the number of function evaluations nfe and the algorithm settings which roughly follow recommendations from prior literature bäck and schwefel 1993 the relatively high mutation rate μ is based on testing for this particular case study the choice of d max for experiments 2 4 seeks to minimize the objective function performance found in experiment 1 while avoiding overfitting i e preferring a less complex tree where possible the experiments were parallelized across the number of trials shown in table 3 and performed on the hpc1 cluster at uc davis which contains 60 nodes with 16 cores each running at 2 4 ghz the combined compute time for all experiments was about 20 000 h parallel computing is useful in this initial study to explore convergence properties but is not required the algorithm also runs efficiently on desktop computers 4 results 4 1 algorithm test we would like to investigate whether the algorithm is effective converges to an approximately optimal point efficient converges quickly and reliable converges with high probability across multiple random trials fig 5 a shows the convergence of the objective function value over the number of function evaluations nfe for a maximum tree depth of 4 using 50 random seeds the objective function values associated with deterministic and stochastic dynamic programming ddp sdp are also shown the performance of the policy tree falls between these two ddp represents perfect foresight optimization for this objective function so we expect the policy tree to approach but not exceed this value the algorithm converges reliably across random trials after about 1000 function evaluations and continues to make marginal improvements for the remainder of the search fig 5b shows the distributions of objective function values after 25 000 function evaluations for multiple tree depths in general we might expect the best attainable objective function value to improve as tree depth increases this is true after a depth of 2 but otherwise the benefit of increasing depth is not noticeable the algorithm is able to obtain good performance with relatively simple policies with d max 3 4 we might also expect larger tree depths to require more function evaluations to converge since the search space scales exponentially with depth however 25 000 fe appears sufficient for depths up to 8 for this particular problem policies of all depths outperform sdp while approaching the perfect information limit of ddp a possible cause of this finding is that sdp must assume a probability distribution in this case a cyclostationary lognormal distribution while policy search can train directly on the historical data which better represents the dynamics and autocorrelation of inflow the aim of this comparison is to show that policy search can efficiently obtain solutions with similar performance to well known methods such as sdp while also providing highly interpretable operating rules fig 5c shows the best tree found after 25 000 fe across all random trials for d max 4 this tree combined with the winter flood pool rule will serve as the baseline policy for comparison with later experiments as with any heuristic optimization technique this result is not guaranteed to be the global optimum for the historical period but fig 5a suggests that the algorithm has converged to an approximately optimal solution moreover the thresholds in fig 5c are tailored to the historical period and their performance may not extend to other scenarios for this reason a decision maker might use the threshold values as a guide rather than an exact value a challenge similar to the real world implementation of other policy search methods finally fig 5d shows the trajectory of reservoir storage over the period 1995 2016 generated by the policy tree in fig 5c along with ddp sdp and the observed storage all are constrained by the historical winter flood pool requirement so the tree does not include an action for flood control table 2 the storage trajectory generated by the policy tree is very similar to that from ddp fig 5 shows that the policy tree algorithm can provide performance similar to well known methods despite a restricted set of admissible controls furthermore the convergence is shown to be efficient and not overly sensitive to the depth of the tree 4 2 historical optimization in this experiment the observed 1 day inflow is added as an indicator variable allowing the algorithm to optimize the conditions under which flood control actions are taken rather than relying on the seasonal flood pool requirement this explores the ability of flexible flood control rules to improve water supply in the rest of the year fig 6 a shows the optimal policy tree resulting from 50 trials 25 000 fe each with a maximum depth of 4 see table 3 the policy includes 80 hedging when storage falls below 625 taf and additionally performs flood control actions when inflow exceeds 79 taf day otherwise it proceeds with the regular release schedule to meet daily demand fig 6b shows the same policy as a partitioning of the indicator space note that the third possible indicator the day of the year is not used in the optimal policy this is because flood control operations can now be based on inflow rather than the season so the time of year is less valuable information than the same day inflow fig 6c compares the storage trajectories created by the optimal policy tree with the observed storage over the period 1995 2016 the background colors show the action performed in each interval corresponding to the colors in fig 6a b throughout the period the policy is able to maintain storage levels well above those observed historically because it is not forced to draw down in the winter flood control operations occur during short intervals as shown in fig 6d which is a sub period of fig 6c from november 1996 to may 1997 when the high inflow condition is triggered the reservoir releases the maximum amount subject to infrastructure constraints seeking to create as much of a flood buffer as possible the thresholds are optimized such that the storage trajectory in fig 6d just meets the capacity without exceeding it leaving more water for the rest of the year here we assume a perfect same day inflow forecast for illustrative purposes so the resulting policy does not include any factor of safety related to forecast error in ongoing work this issue will be addressed using a synthetic ensemble of imperfect forecasts over longer lead times 3 7 days 4 3 climate change individual scenarios figs 5 and 6 have shown that the algorithm performs well under historical conditions in the third experiment we investigate how operating policies may need to be modified to adapt to individual gcm scenarios fig 7 a shows all climate scenarios excluding rcp 2 6 plotted on axes which roughly reflect flood and drought risk the vertical axis shows the maximum 7 day inflow in each scenario while the horizontal axis shows the average annual inflow near the end of the century the historical scenario is marked by the black point there are a mix of wetter and drier scenarios on average but nearly all of them show increased flood risk relative to historical data the 7 day peak inflow reflects the fact that sustained high flows may overtop the reservoir even if the 1 day peak during that time is not extreme by historical standards in fig 7a there are many scenarios marked by x for which no policies were found that can adapt to the increased flood risk even if the reservoir is kept nearly empty under all conditions for example fig 7b shows the best policy associated with the highest flood risk scenario which performs flood control operations when storage exceeds 3 taf i e almost always and still cannot manage to meet downstream flooding constraints the threshold at which this occurs roughly 2000 taf week can be considered a limit to adaptation capacity culley et al 2016 in reality flood risk projections for the american river system may be less dire than fig 7a suggests due to several smaller reservoirs upstream that are not included in the simulation model the rest of fig 7c f shows the policies for the scenarios to which operations can be adapted successfully fig 7c contains the scenario with the largest increase in average annual inflow for which floods can be controlled this is done using a combination of storage and inflow thresholds not unlike the historical policy fig 6a but where the storage threshold is more conservative 281 taf compared to 625 taf fig 7d shows the policy for the scenario closest to historical data in terms of flood and drought risk which results in a simple rule to implement flood control based on an inflow threshold with no storage condition required in fig 7e where both flood and drought risk are increased the inflow threshold to trigger flood control is more conservative 55 taf day compared to 117 taf day this policy copes with reduced average water availability by never releasing the full demand only hedging at 90 during non flood periods finally in the driest scenario fig 7f the optimal policy suggests a more complicated series of hedging rules based on storage levels the inflow threshold to trigger flood control actions in this scenario is much higher than in other scenarios because floods are less severe in summary fig 7 provides guidance about what types of policy changes might be needed to adapt to a wide range of plausible flood and drought risks recognizing that none of these scenarios will occur exactly 4 4 climate change all scenarios the policies shown in fig 7 are each tailored to a particular gcm scenario when they are re evaluated in different scenarios performance degrades substantially and they often fail to meet flood control requirements see supplemental material therefore the final experiment seeks to optimize a single policy across the ensemble of gcm scenarios sacrificing some performance in individual scenarios to improve robustness to all of them this experiment is only performed for the scenarios for which policy adaptation alone can control floods fig 7 in the other scenarios infrastructure improvements may be needed to create an adaptive policy several longer term indicator variables are added to the optimization including the moving average annual inflow the estimate of the 100 year flood and the moving average water year centroid table 1 and fig 4 these additional indicators are intended to allow the policy to distinguish between different scenarios and develop rules accordingly while the policy itself remains static during the simulation period the inclusion of longer timescale information enables adaptive capacity in response to shifting climate indicators fig 8 a shows the result of this experiment unlike prior policies this one is conditioned on the day of the year instead of storage in addition to the inflow variable in a system with strong seasonal patterns like california the day of the year is often a proxy for wet dry conditions the policy in fig 8a shows an inflow threshold triggering flood control that is much more conservative than those in fig 7 because the policy must meet flood control requirements across all scenarios of the three long term indicators that were added only the water year centroid wyc appears in the optimal policy the annual inflow and lp3 flood estimate are not included considering fig 4 the water year centroid shows the clearest trend among all of the indicators reflecting its information content for this policy while the inflow and flood risk indicators provide useful information about the past they are not necessarily leading indicators of future conditions to adapt the operating policy fig 8b compares the objective function performance in each climate scenario for three cases the policy optimized to each scenario individually gold the baseline policy using the winter flood pool requirement shown in fig 5 black and the adaptive policy optimized across the ensemble incorporating longer timescale climate indicators blue the climate scenarios are sorted from wet to dry along the vertical axis with the driest scenarios at the top performance of all policies generally decreases along this gradient as expected the baseline policy fails to control flood events in the majority of climate scenarios a deficiency which the adaptive policy is able to fix in these cases the performance of the adaptive policy falls between the optimized and baseline points it does not perform as well as the policy directly optimized to that scenario but substantially outperforms the baseline in other scenarios the baseline solution performs quite well and there is no need for the adaptive policy it is clear that in this system adaptation will be driven primarily by changing flood risk with water supply improvements as a secondary benefit in the absence of more information about the likelihood of these scenarios the adaptive policy shown in fig 8b would be the single best option using this particular set of indicator variables 5 discussion this application of the policy tree optimization method highlights the benefits of policies structured as binary trees efficient search simple interpretation and the ability to adapt rules and information across a range of long term future scenarios this method contributes to the literature on decision triggers for operation and adaptation in which actions are chosen based on the current values of indicator variables relative to specified thresholds binary trees provide interpretable rules that align with the real world use of discrete thresholds for flood control and water supply conservation measures e g basdekas 2014 though some complexity is necessarily sacrificed in the process while this study focuses on the design of reservoir operating policies an important component of climate adaptation benson 2017 the approach can extend to any policy optimization problem where the system is represented by a simulation model here we discuss several important steps for future work statistical validation irreversible actions and indicator selection policies optimized to a single scenario are unlikely to perform well in other scenarios in this study this is particularly true when scenarios differ in flood timing and magnitude policies are more robust when optimized to an ensemble of inflow scenarios whether from a set of gcms or a synthetic generator to account for this uncertainty optimized policies can also be re evaluated in alternative scenarios to test their robustness kasprzyk et al 2013 herman et al 2014 the aggregation of the objective function across scenarios could include the variance in addition to the mean hamarat et al 2014 this approach could be further improved with a leave one out cross validation scheme to prevent overfitting and improve transferability yet even with a formal cross validation there is no guarantee that the scenarios tested will accurately represent the distribution of future outcomes as they only represent a lower bound on the range of uncertainty stainforth et al 2007 ongoing work will explore the role of short term forecasts to overcome this problem recognizing that there is a critical lead time beyond which additional information is not useful the value of forecast information will vary depending on its accuracy and the infrastructure constraints of the system giuliani et al 2015 anghileri et al 2016 related to the issue of validation a distinction must be made between actions that are reversible such as flood control and hedging operations and those that are irreversible such as infrastructure investment while this study focuses only on the former it is increasingly common to optimize both at the same time e g zeff et al 2016 this study focuses on reversible actions because they are likely to be activated several times under different conditions throughout the simulation however more care would need to be taken in the case of infrastructure decisions these will be triggered by the first occurrence of a particular observation regardless of whether this condition truly reflects a trend or is only an anomalous point in this respect policy tree optimization faces the same challenges as real world policy design it must avoid overfitting to a limited record and must separate trend signals from natural variability finally the concept of adaptation presupposes a set of observable indicators that quantify future trends many of the variables we might use for this purpose such as the moving average of annual inflow used in this study are trailing rather than leading indicators of change moreover the long term information needed to identify trends is ill suited to systems where much of the performance is based on short term extreme events the choice of indicator variables will be critical to any policy design study and can perhaps be improved by incorporating trend detection and attribution methods hegerl and zwiers 2011 rosner et al 2014 it may also be desirable to identify correlated indicator variables and combine them to reduce the number of non unique policies the goal of this input variable selection is to choose a subset of indicators that are maximally informative but not redundant galelli et al 2014 it should be formalized for any policy search analysis 6 conclusions this paper contributes a conceptual framework in which control policies are designed as binary trees mapping observed indicators to actions we propose a simulation optimization method to solve problems of this type and demonstrate it using a reservoir operation case study in this example decision thresholds for flood control and water supply hedging are adapted to climate change scenarios by incorporating longer timescale information in the policy the method is also used to design a single policy that performs well across the ensemble of scenarios the algorithm is shown to efficiently approximate the performance of optimal policies from traditional control methods while providing rules that are easy to visualize and interpret compared to existing threshold based policy design methods this approach shifts the key question from identifying when certain actions should be taken to under what conditions they should be taken the policy tree concept applies to short term management of water and environmental systems as well as long term adaptation in future work we aim to show its generality in applications beyond reservoir control policy tree optimization and corresponding open source software provide a template for policy design under uncertainty in water and environmental systems acknowledgments and software availability this work was partially supported by the u s national science foundation infews grant cns 1639268 any opinions findings and conclusions are those of the authors and do not necessarily reflect the views or policies of the nsf we further acknowledge the world climate research program s working group on coupled modeling and the climate modeling groups listed in the supplement of this paper for producing and making available their model output we would like to thank julianne quinn for helpful comments on an early draft of this paper all code and data from this paper is available on github https github com jdherman ptreeopt in the paper branch appendix a supplementary data the following is the supplementary data related to this article supplementary material supplementary material appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2017 09 016 
26469,umep urban multi scale environmental predictor fig 1 fig 2 after heat wave or cold wave conditions are identified with extremefinder a series of graphs are generated including the daily temperatures with the extreme periods indicated in yellow in the example here heatwaves are identified for london yellow boxes in the period 1990 2010 using the meehl and tebaldi 2004 method table 2 for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 2 fig 3 workflow and geodata for analysing urban energy balance using the suews model bold outlined boxes are mandatory items in some cases alternatives are shown yellow orange and red indicates pre processor processor and post processor tools respectively consistent with fig 1 grey boxes indicate geodatasets and white boxes other types of data dem digital elevation model dsm digital surface model lcz local climate zones it is strongly recommended that all geodata used are transformed into the same projected coordinate system model areas need to be defined in a vector polygon layer for the meteorological forcing users could manipulate their own data metdata processor use the watch wfdei climatological data set download data watch or link to their own already prepared data for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 3 fig 4 examples of input spatial data required to apply suews for central london a land cover overlain with a polygon grid for dis aggregation square grid created in qgis using vector research tools vector grid b digital surface models dsm and canopy digital surface mode cdsm derived from an airborne lidar dataset obtained in the summers of 2005 and 2008 martin holt infoterra ltd personal communication in 2011 and c population density ons 2011 population information can be dis aggregated based on the polygon grid through qgis tool zonal statistics fig 4 fig 5 the umep source area model tool calculating the source area for a individual meteorological conditions and b varying conditions to generate a source area climatology required input information includes a measurement location x y and z a surface elevation database and meteorological conditions fig 5 fig 6 results from applications of suews in a c london uk 17 jul 27 oct 2015 and d f helsinki september november 2010 examples of output from suews analyzer a average daytime sensible heat flux qh b time series of net radiation q and qh for grid id 44 c scatterplot between hourly values of q and qh grid id 44 d aerial image of the water monitoring area 2011 kaupunkimittausosasto helsinki finland e lidar derived land cover fractions nordbo et al 2015 and f scatterplot between surface runoff and precipitation for different planning scenarios base run is the current case and in the alternative scenarios paved surfaces have been changed to street trees and grass areas for visualisation only events with runoff 4 mm have been plotted fig 6 fig 7 workflow and geodata used for analysing mean radiant temperature using solweig in umep bold outlines indicate mandatory items colour coding as in fig 3 for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 7 fig 8 solweig a d spatial input and e f output data displayed with solweig analyzer inputs include raw data a digital surface models dsm and cdsm b ground cover and umep derived data see text c sky view factor from buildings and vegetation d wall pixels and height the pixel resolution here is 1 m t mrt c results for 26 july 2006 gothenburg e at 1 p m and f hourly tmrt and air temperature c for the courtyard point of interest poi the poi can be represented in any gdal ogr a computer software library for reading and writing raster and vector geospatial data formats point vector layer fig 8 fig 9 the civic square medborgarplatsen in stockholm sweden a mean radiant temperature t mrt at 14 00 using meteorological forcing from a hot summer day 28 july 1994 and b hazard map based on number of hours when t mrt 59 4 c on one day c same as b but with a 2 c and d 4 c increase in air temperature fig 9 fig 10 solweig output showing the relation between average ground surface t mrt and vegetation volume for 500 m 500 m grids in stockholm sweden on the 28 july at 2 p m fig 10 fig 11 sebe results for an online application for rooftop irradiance in central uppsala sweden a pop up window with statistics for one of the buildings b 3d view of shortwave irradiance walls and roof for the building www uppsala se solkarta meteorological data used in this example originate from a meso scale model for solar radiation strång www strang smhi se developed by the swedish meteorological and hydrological institute smhi fig 11 fig 12 example outputs from left gqf and right lqf greater london on 2nd october 2015 at 11 00 utc a b building c d transport and e f metabolic emissions are shown to highlight the different spatial distributions that the models produce the same colour scale is used for all maps appendix 2 provides more details about the two methods fig 12 table 1 description of umep components and scales of applicability c city l local neighbourhood m micro e g street canyon park with an example of where their application may be useful those components with post processing visualization tools are indicated with benchmarking or other statistics are indicated with and components described in detail in the text with note the micro scale applications are usable across a whole city but are likely to be computer intensive table 1 component scales description example applications key a pre processor meteorological data prepare existing data c l m formats meteorological data for input to the models dealing with missing data local weather station data can be manipulated into a standard format and subjected to basic quality control n a download data watch c l downloads climate re analysis data modifies it for use in an urban context representative of the local scale if local meteorological data are unavailable allows reanalysis data for land surface modelling to be used weedon et al 2011 2014 kokkonen et al 2017 ward et al 2017a b spatial data spatial data downloader c l m downloads spatial data from public servers if spatial population data within a city are unavailable they can be downloaded from world wide online dataset n a tree generator c l m creation manipulation of 3d vegetation data influence of vegetation on thermal comfort and energy exchanges in a city n a lcz converter c l allows morphometric parameters and land cover fractions see table 4 to be calculated from local climate zone lcz maps generated by wudapt http www wudapt org generates surface input data for city to neighborhood scale modelling stewart and oke 2012 ching et al 2017 urban geometry sky view factor l m amount of the hemisphere with restricted view of the sky solar access urban heat island thermal comfort modelling lindberg and grimmond 2011a b wall height aspect l m height and orientation of buildings and walls solar access urban heat island thermal comfort modelling lindberg et al 2016a urban land cover land cover reclassifier c l m geodata can be translated into the land cover classes used by all the models remote sensing and other geodata sources e g modis classes can be modified for use with models and made appropriate for a local area n a land cover fraction point l m surface cover fractions are determined for an area circle of selected diameter or specific directions table 4 analysis and characterization of a measurement site n a land cover fraction grid c l as above but a grid is used to determine fractions for multiple areas data input for an extensive area for modelling n a urban morphology morphometric calculator point l m morphometric parameters table 4 are determined for an area circle of selected diameter or specific directions can be used interpretation of a measurement location in terms of surface roughness kent et al 2017a b table 4 morphometric calculator grid c l as above but a grid is used to determine parameters for multiple areas data input on surface roughness for an extensive area for modelling kent et al 2017a b table 4 source area point l m as above but determined for an area derived from source area models interpretation of observations investigation of potential siting of instruments kormann and meixner 2001 kljun et al 2015 kent et al 2017a b suews prepare c l prepares input data for the suews model processor based on information derived from other pre processing tools within umep for extensive analysis using suews input forcing data and derived spatial information needed can be prepared n a b processor thermal comfort extremefinder c finds extreme high and extreme low events e g heat waves or cold waves in meteorological time series data table 2 identification of extreme temperatures from a long climate record see table 2 mean radiant temperature solweig l m solweig estimates spatial 2 d variations of 3 d radiation fluxes and the mean radiant temperature t mrt in complex urban settings both 3d vegetation trees and bushes as well as ground cover variations are currently considered in the model t mrt is an important meteorological variable governing the human energy balance and thermal comfort outdoors especially during clear and calm summer days mayer and höppe 1987 lindberg et al 2008 lindberg and grimmond 2011a b lindberg et al 2016b urban energy balance anthropogenic heat q f lqf c l globally applicable method low spatial resolution to calculate q f quantifies contributions to energy budget from building energy use and road traffic allen et al 2011 lindberg et al 2013a gabey et al 2017 anthropogenic heat q f gqf c l locally applicable method high spatial resolution to calculate q f quantifies contributions to energy budget from road traffic residential and non residential building energy use with different fuels and vehicle types considered iamarino et al 2012 gabey et al 2017 urban energy and water balance suews simple c l urban land surface model that allows radiation energy and water fluxes to be calculated for a single point or area simulations of evaporation and heat fluxes for a neighborhood or across a city järvi et al 2011 2014 ward et al 2016 2017b urban energy and water balance suews advanced c l as above but for multiple areas e g a city with 1000s of grid squares or local planning zones of any shape assessment of future city plans and impacts of drought heatwaves water management green infrastructure table 3 solar radiation solar energy on building envelopes sebe l m shortwave irradiance on ground roofs and building walls is estimated based on high resolution digital surface models dsms and input meteorological forcing data potential for energy production resource planning lindberg et al 2016b daily shadow patterns l m shadow maps are derived from buildings and 3d vegetation impact of building form and vegetation on energy production outdoor thermal comfort planning of parks and outdoor spaces lindberg and grimmond 2011a b ratti and richens 1999 c post processor sebe visualization l m visualization of solar irradiation on building envelopes roofs and walls identify areas of good or poor potential for generation of solar energy if panels were installed n a solweig analyzer l m solweig output point temporal model domain spatial temporal identify potential hazard areas potential sites for outdoor activities e g café park n a suews analyzer c l suews output point temporal model domain spatial temporal comparison of indicators under different planning scenarios through time and as maps ward and grimmond 2017 benchmarking c l m statistical tool to compare different datasets model evaluation n a table 2 the heat cold wave indices used in umep extremefinder table 2 extreme event reference index description heat wave meehl and tebaldi 2004 longest period when maximum temperature is above the 97 5th percentile for at least 3 days average daily maximum temperature across the event is over the 97 5th percentile and all days are above the 81st percentile fischer and schär 2010 periods of at least 6 days where maximum temperature exceeds the calendar day 90th percentile vautard et al 2013 periods of various length when daily mean temperature is above the 90th percentile schoetter et al 2014 at least 3 days above the 98th percentile of maximum temperature cold wave keevallik and vint 2015 cold night temperature lower than 10th percentile of daily minimum temperatures calculated for a 5 day window centered on each calendar day in dataset cold wave six consecutive cold nights srivastava et al 2009 minimum temperature is below the normal temperature by 3 c or more consecutively for 3 days or more busuioc et al 2010 cited by micu 2012 at least 6 consecutive days with negative deviations of at least 5 c from the normal value of each calendar day table 3 studies that have evaluated and applied suews presented chronologically note other sub component models have been evaluated and applied prior to these references table 3 city reference variables evaluated application evaluation vancouver canada järvi et al 2011 water use anthropogenic heat flux radiation sensible and latent heat fluxes soil moisture surface wetness los angeles usa järvi et al 2011 radiation sensible and latent heat fluxes helsinki finland järvi et al 2014 radiation sensible and latent heat fluxes snowmelt runoff albedo snow depth montreal canada järvi et al 2014 radiation sensible and latent heat fluxes snowmelt albedo snow density snow depth dublin ireland alexander et al 2015 2016a radiation sensible and latent heat fluxes sacramento usa onomura et al 2015 boundary layer height sensible and latent heat flux hamburg germany alexander et al 2016a sensible and latent heat fluxes melbourne australia alexander et al 2016a sensible and latent heat fluxes phoenix usa alexander et al 2016a sensible and latent heat fluxes swindon uk ward et al 2016 radiation sensible and latent heat fluxes soil moisture surface wetness london uk ward et al 2016 radiation sensible and latent heat fluxes soil moisture helsinki finland karsisto et al 2015 radiation sensible and latent heat fluxes snow depth shanghai china ao et al 2016 radiation singapore demuzere et al 2017 radiation sensible and latent heat fluxes basel switzerland järvi et al 2017 radiation sensible and latent heat fluxes snow depth minneapolis saint paul usa järvi et al 2017 radiation sensible and latent heat fluxes snow depth application helsinki finland nordbo et al 2015 effect of surface cover resolution on suews performance dublin alexander et al 2016a b impact of urban development pathways on sensible and latent heat fluxes across the city of dublin dublin ireland alexander et al 2016b lcz classification combined with suews hamburg germany alexander et al 2016b lcz classification combined with suews melbourne australia alexander et al 2016b lcz classification combined with suews phoenix usa alexander et al 2016b lcz classification combined with suews porto portugal rafael et al 2016 urban resilience measures under different climate scenarios london uk ward and grimmond 2017 impact of urban development and climate mitigation measures on energy partitioning across greater london table 4 spatially related urban surface parameters determined by umep pre processors table 4 plug in parameters land cover types water building paved surfaces bare soil deciduous trees evergreen trees and grass surfacesplan area fraction the combined fractions for a grid must sum to 1 source area two source area models are included kormann and meixner 2001 kljun et al 2015 morphometric methods h av average roughness element height methods for z 0 and z d λ p plan area index rule of thumb grimmond and oke 1999 λ f frontal area index raupach 1994 h max maximum roughness element height bottema and mestayer 1998 σ h standard deviation of roughness element heights macdonald et al 1998 z 0 aerodynamic roughness length millward hopkins et al 2011 z d zero plane displacement kanda et al 2013 wall height and aspect wall heightaspect orientation svf calculator sky view factor values of 1 indicate complete sky access 0 no sky access height of calculations can be varied table 5 evaluation and application studies using the solweig model table 5 city reference variables settings evaluation gothenburg sweden lindberg et al 2008 radiant fluxes and t mrt city square courtyard gothenburg sweden lindberg and grimmond 2011a radiant fluxes and t mrt city square with tree kassel germany lindberg and grimmond 2011a t mrt street canyon freiburg germany lindberg and grimmond 2011a t mrt four urban sites london uk lindberg et al 2016b radiant fluxes and t mrt different urban ground covers shanghai china chen et al 2016 t mrt very dense urban environment hong kong china lau et al 2016 t mrt very dense urban environment application gothenburg sweden thorsson et al 2010 spatial and temporal t mrt future climate scenarios london uk lindberg and grimmond 2011b t mrt intra urban differences gothenburg sweden lindberg et al 2013a b spatial t mrt consideration of weather stockholm sweden thorsson et al 2014 t mrt prediction of heat related mortality porto portugal lau et al 2014 t mrt effects of urban geometry climate change gothenburg sweden lau et al 2014 t mrt effects of urban geometry climate change frankfurt germany lau et al 2014 t mrt effects of urban geometry climate change berlin germany jänicke et al 2016 t mrt city wide characteristics adelaide australia thom et al 2016 t mrt influence of increasing tree cover gothenburg sweden lindberg et al 2016b spatial and temporal t mrt future climate scenarios urban multi scale environmental predictor umep an integrated tool for city based climate services fredrik lindberg a c s b grimmond b andrew gabey b bei huang b c christoph w kent b ting sun b natalie e theeuwes b leena järvi d helen c ward b e i capel timms b yuanyong chang f per jonsson g niklas krave a b dongwei liu f d meyer b k frans g olofson a jianguo tan h dag wästberg g lingbo xue b i zhe zhang b j a department of earth sciences university of gothenburg gothenburg sweden department of earth sciences university of gothenburg gothenburg sweden b department of meteorology university of reading reading united kingdom department of meteorology university of reading reading united kingdom c department of hydraulic engineering tsinghua university beijing china department of hydraulic engineering tsinghua university beijing china d department of physics university of helsinki finland department of physics university of helsinki finland e institute of atmospheric and cryospheric sciences university of innsbruck innsbruck austria institute of atmospheric and cryospheric sciences university of innsbruck innsbruck austria f shanghai institute of meteorological science shanghai meteorological service china shanghai institute of meteorological science shanghai meteorological service china g tyréns ab gothenburg sweden tyréns ab gothenburg sweden h shanghai climate centre shanghai meteorological service china shanghai climate centre shanghai meteorological service china i information center yangzhou university china information center yangzhou university china j school of environment and sustainability university of saskatchewan saskatoon canada school of environment and sustainability university of saskatchewan saskatoon canada corresponding authors umep urban multi scale environmental predictor a city based climate service tool combines models and tools essential for climate simulations applications are presented to illustrate umep s potential in the identification of heat waves and cold waves the impact of green infrastructure on runoff the effects of buildings on human thermal stress solar energy production and the impact of human activities on heat emissions umep has broad utility for applications related to outdoor thermal comfort wind urban energy consumption and climate change mitigation it includes tools to enable users to input atmospheric and surface data from multiple sources to characterise the urban environment to prepare meteorological data for use in cities to undertake simulations and consider scenarios and to compare and visualise different combinations of climate indicators an open source tool umep is designed to be easily updated as new data and tools are developed and to be accessible to researchers decision makers and practitioners keywords qgis urban climate services heat risk solar energy green infrastructure 1 introduction urban environments are particularly vulnerable to high impact weather given the high population densities in many cities and the associated assets and infrastructure e g as evidenced by the impacts of hurricane sandy on new york city solecki 2015 with weather extremes frequently exceeding climate records and with urban areas growing rapidly the ability to deliver city based climate services to those operating and planning different aspects of city life transport energy demand water supply etc is critical horton et al 2016 baklanov et al 2017 a common toolbox accessible to researchers decision makers and practitioners offers great potential for better informed climate related decisions in cities scientists and practitioners from a broad range of disciplines including architecture e g ren et al 2011 climatology e g eliasson 2000 planning e g alcoforado et al 2009 engineering and geography have long been interested in how weather and climate affects cities and their occupants baklanov et al 2017 however the development and adoption of city based climate services which require production translation transfer communication and use of climate knowledge and information for urban planning building design and the operation of cities is not straight forward chrysoulakis et al 2013 grimmond et al 2014 masson et al 2014 baklanov et al 2017 appropriate input data surface and atmospheric can be challenging to access and specialist formats often make them inaccessible to many end users grimmond 2013 communication between producers and users of climate services has been poor with outputs often not easily interpretable by non specialists tools that are more user friendly and are technically and economically accessible to users are needed to improve communication across disciplines researchers and users to better identify user needs to ensure common assumptions across models to build capacity to address urban climate and weather concerns and transfer research into practice past initiatives have tended to focus on specific processes e g herbert et al 1998 or restricted spatial or temporal scales e g bruse and fleer 1998 with applications most often intended for specialist researchers many of these studies have focused on water and waste water management e g paton et al 2014 saagi et al 2017 and not on integrated hydro climatological models appropriate for application at multiple scales neighbourhood to city which account for feedbacks and complex interactions for example the effect of water on heat exchanges as well as on flooding here we introduce umep urban multi scale environmental predictor an integrated tool for urban climatology and climate sensitive planning applications while elements of umep have been presented elsewhere see further discussion below and summary in table 1 this is the first full description of umep and its potential across a broad range of applications in its current form the tool can be used for applications related to outdoor thermal comfort urban energy consumption and climate change mitigation umep consists of a coupled modelling system which combines state of the art 1 d and 2 d models with systems to input data from multiple sources formats and at different temporal and spatial scales and to generate output as data graphs and maps an important feature of umep is its ability to couple relevant processes and to use common data across a range of applications here the basic structure of umep is described followed by examples of applications to illustrate the potential of this tool 2 umep overview umep is being developed as a community open source tool to enable its use without restriction with respect to cost license or rights issues users are encouraged to contribute to the tool to enhance and extend its capabilities one of its major features is the ability for users to interact with spatial information to determine model parameters and to edit map and visualise inputs and results for this reason the software is written as a plug in to qgis a cross platform free and open source desktop geographic information system gis application qgis development team 2017 umep has three main elements fig 1 pre processor for inputs of meteorological and surface information processor modelling system e g urban land surface models ulsm and post processor tools to analyse the outputs individual case and ensemble indicators of uncertainty user applications etc each element is described briefly in table 1 with more complete details presented in the online manual http www urban climate net umep umep umep allows users to integrate atmospheric and surface data from multiple sources take meteorological data measured at standard sites and adapt them to be representative of the urban environment use reanalysis or climate prediction data and compare and visualise results or scenarios for different climate indicators of interest heat indices intense precipitation water energy demand this all can be done at a range of spatial scales consistent with end users needs and interests table 1 to aid uptake and use of the model and to develop capacity in urban modelling more generally a series of tutorials have been developed http www urban climate net umep umep manual tutorials one key contribution of umep is to facilitate the preparation of input data required for city based climate services cbcs umep provides both guidance and tools that enable the preparation and manipulation of data table 1 this is particularly important as most end users are familiar with some but not the full spectrum of data needed for applications for example planners are knowledgeable about building heights materials and their spatial arrangement i e urban surface data and often have gis skills but they may not necessarily have detailed knowledge of meteorological data equally those knowledgeable of the latter may not be expert of the former although remotely sensed data may play a very useful part in cbcs these data may require further processing to be applicable in urban areas umep has been designed to enhance their integration the tools within umep can also be used to provide data to export to other more complex weather climate hydrological environment modelling systems alternatively data from more complex models may be imported into umep umep has a broad range of capabilities table 1 each of its elements may be used independently or in varying combinations users may be interested in the output from tools that are provided in the pre processor for other modelling applications e g in generating urban surface information or standardised meteorological fields or in applications that require a chain of tools to provide climate indicators for decision making as many of the individual tools as well as their evaluations have been described in disciplinary focussed papers see table 1 references here we present a range of examples each of which requires the use of several tools to obtain a solution 3 umep applications in this section examples of applications are presented to illustrate umep s potential specifically in the identification of heat waves and cold waves in cities extremefinder bold is used hereafter to indicate the component of the umep plug in tool the implications of green infrastructure on runoff suews micro scale heat stress solweig solar energy production sebe and sources of anthropogenic human generated heat lqf gqf each application draws on different combinations of umep tools 3 1 application example 1 identification of extreme thermal conditions for many urban planning and human health applications extreme meteorological conditions are of interest and concern to identify these extremes analysis of a long climatological record is required table 2 however if such data are not available for the area of interest umep allows the user to draw on the reanalysis dataset watch forcing data era interim wfdei dee et al 2011 weedon et al 2011 2014 this product was selected as it was designed to be used for hydrological and land surface modelling for climate purposes and has been used in several cities around the world to explore variations in energy flux partitioning best and grimmond 2016 to determine the extreme thermal conditions for a site the first step is to use the umep download data watch table 1 to obtain a meteorological time series for the period and location of interest these data can also be used for other umep applications e g section 3 2 for example they can be downscaled to the area of interest using the techniques of best and grimmond 2016 and ward et al 2017a b appendix 1 currently extremefinder provides four methods to identify heat waves and three for cold waves table 2 as there is no generally accepted definition of either phenomena robinson 2001 vaidyanathan et al 2016 different percentiles are used to define extremes e g table 2 the thresholds for the extremes are based on fixed values or quantiles calculated from the meteorological time series use of a time series spanning decades is therefore recommended the user can modify the fixed thresholds and quantiles http urban climate net umep umep manual outdoor thermal comfort extremefinder daily values are then evaluated to determine if an extreme event has occurred extremefinder identifies the dates and daily maximum average or minimum temperatures of all extreme high low events during the period of interest fig 2 yellow boxes based on the criteria set out by the method chosen 3 2 application example 2 urban energy and water balance fluxes energy and water balance fluxes are critical to surface atmosphere interactions in an urban area the impact of extreme conditions heat waves droughts floods etc are influenced by the state of the urban environment prior to these events with the urban energy and water balance varying with different neighbourhood local scale characteristics the surface urban energy and water balance scheme suews is an urban land surface model included in the processing part of umep table 1 the model simulates the urban radiation energy and water balances using commonly measured meteorological variables and information about the surface cover suews is applicable at the neighborhood to city scale in umep suews is uncoupled i e advection between grids is not accounted for umep allows suews to be run as a standalone model or umep can provide the appropriate parameters for the use of suews within a 3 d model meso scale model such as wrf dudhia 2014 the parameters calculated with umep tools can provide the input parameters to a wide range of urban land surface models either standalone versions surfex masson et al 2013 jules best et al 2011 clm lawrence et al 2011 slucm kusaka et al 2001 or coupled to larger scale models suews uses an evaporation interception approach grimmond and oke 1991 for an area comprised of seven land cover types water buildings grass paved bare soil deciduous trees shrubs and evergreen trees shrubs the state of each surface type at each time step is calculated from the running water balance of the canopy where the evaporation is calculated from the penman monteith equation the soil moisture below each surface type excluding water is considered umep has the latest version of suews ward et al 2017a b accessible through two links a suews simple provides a useful starting place to introduce umep and suews example data are provided so that users can explore the impact of modifying urban surface characteristics with suews simple the ulsm can be executed for a single location area b suews advanced provides a full version of the model appropriate for investigating both spatial and temporal variations of the urban energy balance the suews model has been extensively evaluated for a variety of locations and situations worldwide table 3 the workflow for an application utilizing suews within umep is outlined in fig 3 geodatasets that contain information about the urban environment are used with the pre processor tools fig 3 gray and yellow to provide the required surface parameters the model can be applied to areas of any shape as in most cities planning units have known boundaries already available in vector polygon format e g boroughs wards alternatively a square grid can easily be created in qgis fig 4 a as land cover fig 3 is a key variable for many calculations a method to reclassify data is provided the umep land cover reclassifier enables land cover raster grids to be created from sources such as modis and then converted to the standard umep cover types table 4 surface cover fractions are very important given differences in energy and water partitioning that result from underlying differences in moisture availability and surface properties accessing reliable sources of land cover information to derive these parameters at the scale of interest remains a challenge crowd sourced data sets such as openstreetmap http www openstreetmap org and wudapt http www wudapt org see below offer potential but may be incomplete or inconsistent other sources such as modis https terra nasa gov about terra instruments modis are likely to be complete but give low spatial resolution at the sub km scale in addition the number of human altered urban classes from such data are limited 3 classes and the discrimination between land cover classes needs to be made based on land use in the example given here for central london the land cover information fig 4a is derived from os mastermap topography layer ordnance survey 2010 the land cover fraction grid tool is used to calculate grid based land cover fractions tables 1 and 4 based on the land cover raster grid morphometric parameters table 4 related to surface roughness can be obtained from the morphometric calculator grid using digital surface models dsm fig 4b from these data the zero plane displacement z d aerodynamic roughness length z 0 and other geometric parameters such as mean roughness element height and frontal area index are calculated table 4 the rationale behind the different methods and a basis for selecting between them is outlined in kent et al 2017a b parameters can be derived for the full surrounding area or for sectors reflecting different wind directions applications which involve an assessment of the area surrounding a measurement point can use the source area model point currently there are two turbulent flux source area models included within umep tables 1 and 3 the analytical model of kormann and meixner 2001 and kljun et al s 2015 parameterisation of a lagrangian stochastic particle dispersion model these models indicate the probable surface area contributing to a turbulent flux measurement at a specific point in time and space with imposed boundary conditions e g meteorological conditions sources sinks of passive scalars or surface characteristics the results from these models facilitate interpretation of observations enable improved evaluation of flux models and or allow assessments of the appropriateness of siting of new instrumentation fig 5 population density people per hectare is used in the estimation of anthropogenic heat flux in suews if population density datasets are unavailable e g as would be obtained from local census data the spatial data downloader can be used this plug in is directly connected to various web coverage services wcs including global datasets on population density http urban climate net umep umep manual spatial data spatial data downloader in the example given here averaged population density between residential and working population is used fig 4c such differentiations are very important in locations such as central london for anthropogenic heat flux calculations dong et al 2017 gabey et al 2017 given the challenges of acquiring all the datasets needed dem dsm and land cover in fig 3 local climate zone maps lcz stewart and oke 2012 are included in umep from these a first estimate of input parameters for suews can be made in umep the lcz maps from the wudapt database www wudapt org ching et al 2017 can be translated using the lcz converter if more detailed information is available for specific areas or becomes available subsequently e g local high resolution dsms parameters can be updated the other major input to suews is the meteorological forcing data table a1 1 such data need to be for above the height of the roughness elements trees buildings a common format is used in all umep models table a1 1 most applications require a continuous gap filled data set for many urban applications the start and finish of daylight savings is linked to important behavioural patterns e g the shift of rush hour therefore the individual models account for daylight savings if relevant e g timing of anthropogenic energy use irrigation the preparing existing data umep tool see appendix 1 supports preparation of the meteorological data and conversion into the format used in all umep models once all the required information is pre processed suews prepare can arrange the data so the model can be executed suews analyzer fig 3 allows spatial fig 6 a temporal fig 6b and between variable fig 6c model results to be explored in this example application central london average daytime sensible heat fluxes qh for four months period in 2015 are mapped fig 6a with detail of temporal variations of net all wave radiation q and qh for nine days for one area grid id 44 graphed fig 6b the relation between q and qh for grid id 44 for the whole time period fig 6c is also plotted to illustrate a hydrological application to examine runoff generation in different planning scenarios suews was run for a highly built up catchment area 24 ha in helsinki for 2010 fig 6d f the planning scenarios considered the current land cover use base run and a 10 and 30 increase in areal coverage of street trees and grass surfaces at the expense of paved surfaces fig 6f results from these simulations indicate that the increase in the amount of street trees i e areal fraction of street trees is more effective in reducing surface runoff compared to an increase in grass surfaces a 10 increase in street trees is more effective than a 30 increase in grass surfaces 3 3 application example 3 mean radiant temperature temperature related health problems are expected to increase with rising temperature in cities especially during more extreme temperatures associated with heat waves mean radiant temperature t mrt is one of the most important meteorological variables governing the human energy balance and thermal comfort outdoors especially on clear and calm summer days mayer and höppe 1987 to provide estimates of thermal comfort heat stress for people solweig solar and longwave environmental irradiance geometry model can be used to calculate t mrt in solweig both 3d vegetation trees and bushes as well as variations in ground cover can be considered lindberg and grimmond 2011b lindberg et al 2016b solweig has been evaluated extensively and applied at urban locations worldwide table 5 fig 7 shows the umep workflow to examine 3d radiant fluxes and t mrt of the four geodatasets needed the ground and building dsm fig 8 a is fundamental if available a vegetation dsm cdsm can be added lindberg and grimmond 2011b however as 3d information on vegetation is sparse the tree generator tool allows point vector data of tree locations to be transformed into a cdsm ground cover information can be used to estimate outgoing short and longwave radiation fluxes lindberg et al 2016a b to obtain the appropriate ground cover classes the land cover reclassifier fig 7 can be used to obtain the five ground cover classes water buildings grass paved and bare soil used in solweig fig 8b no bare soil present the sky view factor svf is the ratio between the radiation received or emitted by a planar surface and the radiation emitted or received by the entire hemispheric environment watson and johnson 1987 this dimensionless metric totally obstructed 0 totally unobstructed 1 is important to human comfort fig 8c solar energy and solar access a pixel wise sky view factor calculated in svf uses ground and building dsms and or vegetation dsm fig 8c solar access and radiative exchanges are impacted by wall height and aspect wall height and aspect tables 1 and 4 fig 7 provides wall pixels with their height fig 8d and aspect degrees the latter is a modification of the goodwin et al 2009 linear filter lindberg et al 2015b to model t mrt successfully building footprint locations must be derived from either the ground cover grid or from differences between ground heights dem and a dsm fig 7 solweig can be used for an individual time or a time series for the latter points of interest poi are added within the model domain solweig analyzer can be used to provide spatial fig 8e and temporal fig 8f visualizations of results by comparing the input geodata fig 8a d and the results fig 8e f the micro scale influences on the temporal and spatial patterns can be identified and explained as shown in fig 8f the temporal influence of t mrt is unlike air temperature it is highly affected by other variables such as shortwave and longwave radiation fluxes application of solweig to explore variations in t mrt around the civic square medborgarplatsen of central stockholm shows that at 2 p m shadows from buildings and vegetation are important fig 9 the highest t mrt values are next to sunlit walls and on the sunlit open spaces open areas have high values t mrt due to partly cloudy conditions which increases the proportion of diffuse shortwave radiation the high values of t mrt adjacent to the walls are related to the emitted longwave radiation and reflected shortwave radiation from the sunlit walls to explore the potential impact of t mrt it is useful to consider critical health thresholds from analysis of stockholm county daily all cause mortality data 1990 2002 thorsson et al 2014 found that when t mrt exceeds 59 4 c there is an increase in heat related mortality of 10 for those 80 years of age using this threshold the areas of greatest hazard can be identified adjacent to the sunlit buildings fig 9b to determine the effects of warmer air temperature 2 c 4 c the hazard can be re analysed with further solweig simulations fig 9c and d the hazard increases in both areal and temporal extent with both open spaces and areas adjacent to sunlit walls being identified cf fig 9b walls have greater influence as air temperatures become warmer as surface temperature of walls increase and emit more longwave radiation while the shortwave radiation in open spaces remains constant to investigate patterns at the city scale the influence of building and vegetation density on t mrt across stockholm is examined at a pixel resolution of 1 m the density of buildings and t mrt show no strong correlation however there is a clear relation between t mrt at 2 p m and vegetation density at the 500 m scale fig 10 this demonstrates that increasing vegetation in urban areas could reduce t mrt and mitigate heat stress 3 4 application example 4 solar energy on building envelopes the contrast between sunlit and shaded surfaces can explain micro scale differences in urban climate for example spatial variation in road surface temperatures hu et al 2015 in umep sunlit fractions are computed using high resolution dsms and the shadowcalculator the shadow casting algorithm uses sequential computation of shadow volumes ratti and richens 1999 with a raster dsm ratti and richens 2004 lindberg and grimmond 2010 to map potential solar energy production sebe solar energy on building envelopes can calculate irradiances at pixel resolution on building roofs and walls using a 2 5 dimensional model observed solar radiation data are used with high resolution dsms to derive accurate irradiances for the surfaces modelled lindberg et al 2015a b sebe has been applied to several cities in sweden http www urban climate net umep example applications fig 11 shows a snapshot of an online mapping service where irradiance on roofs in uppsala 14 km2 has been modelled in umep at 0 25 m resolution the surface data are a combination of airborne lidar data and 3d vector polygons representing roof structures for each building post processing analysis derived several statistics including areal extent m2 of roofs and walls suitable for solar energy production fig 11a and the 3d distribution of solar irradiance fig 11b 3 5 application example 5 anthropogenic heat fluxes anthropogenic heat flux q f heat released directly by humans and their activities sailor 2011 is a distinct feature of urban areas with significant impact on energy and water exchanges in umep in addition to the methods within suews q f can be modelled using two standalone approaches appendix 2 i lqf which uses the lucy methodology allen et al 2011 lindberg et al 2013a and provides simple estimates at low spatial resolution and ii gqf which is a reimplementation of greaterqf iamarino et al 2012 and produces high resolution estimates with greater insights into specific types of energy use in umep each has been supplemented with a spatial input data pre processor that makes use of standard gis data formats and outputs spatially and temporally resolved q f estimates of traffic q f t metabolic q f m and building q f b emissions in universal coordinated time the lqf results can be incorporated into the meteorological data used to force suews via the refinement stage of the download data watch tool an example of lqf output across greater london in october 2015 using local super output area lsoa population data shows the spatial distribution of each component and the resultant larger q f towards the city centre fig 12 b d f the assumptions applied here limit lqf to spatial scales of the order 1 km gabey et al 2017 at spatial scales less than 1 km movements of people for example from home to work are important and the structure of the road network needs to be captured gabey et al 2017 example output maps from gqf fig 12a c e show order of magnitude agreement with lqf with a notably different spatial structure in q f t fig 12c d because road network topology is used rather than population count the effect of using the workday gqf rather than residential lqf population on the daytime metabolic emission fig 12e f is visible as a strong enhancement in the centre of the city a similar enhancement is also evident in the building emissions fig 12 a b which is attributable to the use of spatially resolved energy consumption in gqf compared with residential population based attribution in lqf 4 concluding comments the city based climate service tool umep urban multi scale environmental predictor is introduced through a series of applications the qgis plug in has a coupled modelling system of state of the art 1 d and 2 d models which can provide estimates of essential urban climate processes it also provides tools for determining parameters for more complex 3 d models a key contribution of umep is to provide a method to consistently determine model parameters across a suite of models and applications this serves to ensure consistency in theoretical assumptions between models data analysis observations evaluation and applications different scales applications and end users common processing tools also enable rapid updates when new data become available for example release of new national statistical data used in the anthropogenic heat flux or when new parameterisations are developed for example new aerodynamic roughness models of kent et al 2017a b which can then be used to understand flux measurements source area model and to perform energy and water balance calculations suews example applications have been presented to illustrate umep s potential specifically of the identification of heat waves and cold waves in cities extremefinder the implications of green infrastructure on runoff suews micro scale heat stress solweig solar energy production sebe and sources of anthropogenic human generated heat lqf gqf each application draws on different combinations of umep tools umep is under active development and refinement it is designed as an open source tool the development team welcomes all kinds of collaboration through for example submission of comments or issues to the repository www bitbucket fredrik ucg umep participation in coding addition of new features and development of new tutorials for users the online manual provides more details on how to participate http www urban climate net umep umep manual planned developments include tools for pedestrian wind and thermal comfort indices acknowledgements the greater london authority lidar dataset are used courtesy of matthew thomas greater london authority and data from a nerc arsf gb08 19 flight the stockholm data and results are used courtesy of anette jansson environmental office city of stockholm financial support was provided by formas the swedish research council for environment agricultural sciences and spatial planning met office climate science for service partnership cssp china as part of the newton fund h2020 eo 1 2014 project 637519 urbanfluxes nerc case studentship with rms supported cwk british council funded bh epsrc studentship ict and university of reading work sg ag nk ts hcw and visits yyc dwl to the uk were supported by the uk china research innovation partnership fund through the met office climate science for service partnership cssp china as part of the newton fund the umep plug in can be downloaded from http www urban climate net umep software availability name of software urban multi scale environmental predictor umep developers fredrik lindberg sue grimmond andrew gabey bei huang christoph w kent ting sun natalie e theeuwes isabella capel timms leena järvi helen c ward yuanyong chang niklas krave d meyer frans olofson jianguo tan dag wästberg lingbo xue zhe zhang contact fredrik lindberg fredrikl gvc gu se 46 31 786 2606 sue grimmond c s grimmond reading ac 44 118 378 6248 year first available 2015 hardware required na software required qgis 2 x operation system required os independent program language python program size 2 5 mb compressed 9 mb uncompressed availability and cost open source no cost repository www bitbucket org fredrik ucg umep webpage www urban climate net umep appendix 1 meteorological information umep uses a common data format for meteorological data table a1 1 preparing existing data figure a1 1 imports variables from ascii files and allows for time related variables year day of year hour and minute and other time formats such as month day of month etc in preparation for analysis during this process some quality control is performed to ensure the data are within reasonable limits table a1 1 figure a1 1 and to identify missing time intervals fig a1 1 example dialogue box in umep meteorological processor fig a1 1 download data watch provides another source of meteorological forcing data section 3 1 global reanalysis products if observed data are not available however the coarse spatial resolution of reanalysis products e g grids of 0 5 means that downscaling is needed prior to their use for local scale urban hydrological modelling wilby et al 2000 fowler et al 2007 bastola and misra 2014 the methods used to prepare the data are based on best and grimmond 2016 kokkonen et al 2017 and ward et al 2017a these involve i identification of the area of interest ii download of the data and iii generation of a umep formatted file with data aligned to the appropriate time zone at hourly intervals these umep wfdei data corrections are dependent on the meteorological variables as some are instantaneous values whereas others are averages for a 3 h period weedon et al 2011 ward et al 2017a the 3 h data are linearly interpolated to 1 h data however for the incoming solar radiation the times of sunrise and sunset are calculated to ensure that the day length is as expected and the interpolated data are adjusted to take this into account for instance if sunrise and sunset times are 6 00 lt local time and 19 00 lt respectively only the interpolated values between 6 00 lt and 19 00 lt will have non zero short wave radiation but are rescaled for that period retaining the daily average the relative humidity rh is obtained from the specific humidity q v in kg kg 1 as follows r h e a e s 100 with e a and e s the actual and saturation vapor pressures buck 1981 given by e a r v q v p r d q v r v r d e s 6 1121 exp 18 678 t c 234 5 t c t c 257 14 1 00072 p 3 2 10 6 5 9 10 10 t c 2 t c 0 c 6 1115 exp 23 036 t c 333 7 t c t c 279 82 1 00022 p 3 83 10 6 6 4 10 10 t c 2 t c 0 c where r v 461 5 j k 1 kg 1 the specific gas constant for water vapour r d 287 04 j k 1 kg 1 the specific gas constant for dry air p the atmospheric pressure kpa and t c the air temperature c other corrections consider the effect of elevation with a coarse grid the city or of area of interest may be at a lower elevation than the surroundings as one example vancouver the real weighted mean wfdei grid height includes mountains but much of the city is much lower kokkonen et al 2017 thus consideration needs to be given to i the elevation of the area of interest ii the height of the roughness elements buildings trees and iii the appropriate height for the forcing data for the simulation in umep the wfdei temperature and pressure values are adjusted to the simulation height using environmental lapse rate γ 6 5 c km 1 and the hypsometric equation weedon et al 2011 rh used by suews is calculated from the wfdei specific humidity assuming it is constant with altitude to avoid supersaturation interpolation and altitude corrections may require a spin up period to avoid interpolation errors and missing data points at the beginning and at the end of the time series thus longer periods should be used for analysis than the period of specific interest table a1 1 meteorological data used in various components of umep are formatted in the order indicated the metdata pre processor tool does simple quality control to ensure data are within acceptable ranges not all variables are required in umep with the exception of the four time related columns all any that use meteorological data su suews so solweig sa source area model se sebe for some application these data are required bold the variables extracted by download data watch are indicated column 5 when data are not needed it can be assigned 999 to indicate no data available day of year is used instead of date within a month for simplicity the hour and minute is local standard time and refers to time ending table a1 1 no description units accepted range used by watch 1 year yyyy all 2 day of year doy all 3 hour h all 4 minute m all 5 net all wave radiation w m 2 200 to 800 su 6 sensible heat flux w m 2 200 to 750 su 7 latent heat flux w m 2 100 to 650 su 8 storage heat flux w m 2 200 to 650 su 9 anthropogenic heat flux w m 2 0 to 1500 su 10 wind speed m s 1 0 001 to 60 su sa x 11 relative humidity 5 to 100 su so se x 12 air temperature c 30 to 55 su so se x 13 barometric pressure kpa 90 to 107 su so x 14 rainfall mm 0 to 30 per 5 min su x 15 incoming shortwave radiation w m 2 0 to 1200 su so se x 16 snow mm 0 to 300 per 5 min su x 17 incoming longwave radiation w m 2 100 to 600 su x 18 cloud fraction tenths 0 to 1 su 19 external water use m3 0 to 10 per 5 min su 20 observed soil moisture m3 m 3 or kg kg 1 0 01 to 0 5 su 21 observed leaf area index m2 m 2 0 to 15 su 22 diffuse shortwave radiation w m 2 0 to 600 so se 23 direct shortwave radiation w m 2 0 to 1200 so se 24 wind direction 0 to 360 su sa 25 friction velocity m s 1 all sa 26 standard deviation sigma of transverse wind velocity m s 1 all sa 27 obukhov length m all sa 28 boundary layer height m all sa appendix 2 anthropogenic heat flux lqf is designed to provide out of the box anthropogenic heat flux qf estimates at 1 h time steps the minimum user provided input data required are the spatially resolved population count and a daily mean air temperature time series both data sets can be obtained using tools within umep heat fluxes are estimated using a top down methodology that draws on a database of national energy consumption population and vehicle ownership statistics lqf attributes this energy consumption and traffic based on local population count variations and estimates qf in each population area it is possible to replace the national data with provincial or smaller regions if the data are available the database contains diurnal variations for metabolism traffic flow and building energy consumption which are optionally overridden with user specified versions weekend weekday variations are captured for buildings qf b and transport qf t while the user specified versions provide control over each day of the week day to day building energy consumption is estimated using a database held country specific temperature response function and assumption about the prevalence of air conditioning lindberg et al 2013a a blanket weekend traffic reduction is also applied to capture day of week traffic flow changes table a2 1 input data files required by the lqf model table a2 1 dataset type remarks population count polygon shapefile basis of spatial variations of q f components daily mean temperature csv file s basis of day to day building energy consumption variations traffic diurnal profile csv file s optional building energy diurnal profile csv file s optional lqf database spatialite file downloaded from umep website can be edited by user gqf produces q f estimates at higher spatial resolution and 30 min time steps but requires comprehensive input data table a2 2 to support this the shift in population distribution during working days is captured using residential and workday population datasets with morning and evening transition periods road transport emissions are calculated using a vector map containing every road link along with the road class label and traffic flow broken down by vehicle type maps of residential and non residential gas and electricity consumption across the city are used to estimate building emissions the model therefore sub divides q f t by vehicle type and q f b by fuel and consumer and estimates the spatial distribution of transport emissions independently of the population distribution model spatial resolution is dictated by the input residential and workday population datasets with the annual energy consumption data disaggregated to common spatial units based on population day to day variations in building energy consumption and hence q f b are captured using empirical demand data from utility companies and half hourly variations are obtained from week long diurnal profiles with separate profiles specified for each energy consumption category temporal variations in transport are governed by a week long diurnal profile for each vehicle type in which some days have greater mean values than others to reflect day to day traffic variations this segmentation means the temporal evolution of each q f component in a modelled area depends on the balance of vehicle types energy consumers and the residential to workday population ratio gqf also partitions q f t q f b and metabolism q f m into sensible latent and for buildings wastewater fractions these can be included or excluded from the modelled q f at model run time table a2 2 input data sources required by the gqf model table a2 2 data source type remarks residential population count polygon shapefile used for metabolism estimates and to spatially disaggregate energy consumption data to common spatial units workday population count polygon shapefile road network and traffic flow line shapefile each road segment with road classification and annual average daily total traffic for each vehicle type residential energy consumption residential electricityresidential gasresidential economy 7 shapefiles spatially disaggregated using residential population non residential energy consumption non residential electricitynon residential gasnon residential other shapefiles kwh per year spatially resolved within cityspatially disaggregated using workday population daily energy consumption time seriesgaselectricity csv file relative variations used to scale annual to daily values applied to both residential and non residential sectors vehicle diurnal profiles csv file time series for each vehicle type building energy diurnal profiles csv file time series for energy consumption dataset metabolic diurnal profiles csv file time series defining metabolic rate per person and transition between workday and residential population vehicle fuel efficiencies csv file amount of fuel consumed per vehicle class and fuel type 
26469,umep urban multi scale environmental predictor fig 1 fig 2 after heat wave or cold wave conditions are identified with extremefinder a series of graphs are generated including the daily temperatures with the extreme periods indicated in yellow in the example here heatwaves are identified for london yellow boxes in the period 1990 2010 using the meehl and tebaldi 2004 method table 2 for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 2 fig 3 workflow and geodata for analysing urban energy balance using the suews model bold outlined boxes are mandatory items in some cases alternatives are shown yellow orange and red indicates pre processor processor and post processor tools respectively consistent with fig 1 grey boxes indicate geodatasets and white boxes other types of data dem digital elevation model dsm digital surface model lcz local climate zones it is strongly recommended that all geodata used are transformed into the same projected coordinate system model areas need to be defined in a vector polygon layer for the meteorological forcing users could manipulate their own data metdata processor use the watch wfdei climatological data set download data watch or link to their own already prepared data for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 3 fig 4 examples of input spatial data required to apply suews for central london a land cover overlain with a polygon grid for dis aggregation square grid created in qgis using vector research tools vector grid b digital surface models dsm and canopy digital surface mode cdsm derived from an airborne lidar dataset obtained in the summers of 2005 and 2008 martin holt infoterra ltd personal communication in 2011 and c population density ons 2011 population information can be dis aggregated based on the polygon grid through qgis tool zonal statistics fig 4 fig 5 the umep source area model tool calculating the source area for a individual meteorological conditions and b varying conditions to generate a source area climatology required input information includes a measurement location x y and z a surface elevation database and meteorological conditions fig 5 fig 6 results from applications of suews in a c london uk 17 jul 27 oct 2015 and d f helsinki september november 2010 examples of output from suews analyzer a average daytime sensible heat flux qh b time series of net radiation q and qh for grid id 44 c scatterplot between hourly values of q and qh grid id 44 d aerial image of the water monitoring area 2011 kaupunkimittausosasto helsinki finland e lidar derived land cover fractions nordbo et al 2015 and f scatterplot between surface runoff and precipitation for different planning scenarios base run is the current case and in the alternative scenarios paved surfaces have been changed to street trees and grass areas for visualisation only events with runoff 4 mm have been plotted fig 6 fig 7 workflow and geodata used for analysing mean radiant temperature using solweig in umep bold outlines indicate mandatory items colour coding as in fig 3 for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 7 fig 8 solweig a d spatial input and e f output data displayed with solweig analyzer inputs include raw data a digital surface models dsm and cdsm b ground cover and umep derived data see text c sky view factor from buildings and vegetation d wall pixels and height the pixel resolution here is 1 m t mrt c results for 26 july 2006 gothenburg e at 1 p m and f hourly tmrt and air temperature c for the courtyard point of interest poi the poi can be represented in any gdal ogr a computer software library for reading and writing raster and vector geospatial data formats point vector layer fig 8 fig 9 the civic square medborgarplatsen in stockholm sweden a mean radiant temperature t mrt at 14 00 using meteorological forcing from a hot summer day 28 july 1994 and b hazard map based on number of hours when t mrt 59 4 c on one day c same as b but with a 2 c and d 4 c increase in air temperature fig 9 fig 10 solweig output showing the relation between average ground surface t mrt and vegetation volume for 500 m 500 m grids in stockholm sweden on the 28 july at 2 p m fig 10 fig 11 sebe results for an online application for rooftop irradiance in central uppsala sweden a pop up window with statistics for one of the buildings b 3d view of shortwave irradiance walls and roof for the building www uppsala se solkarta meteorological data used in this example originate from a meso scale model for solar radiation strång www strang smhi se developed by the swedish meteorological and hydrological institute smhi fig 11 fig 12 example outputs from left gqf and right lqf greater london on 2nd october 2015 at 11 00 utc a b building c d transport and e f metabolic emissions are shown to highlight the different spatial distributions that the models produce the same colour scale is used for all maps appendix 2 provides more details about the two methods fig 12 table 1 description of umep components and scales of applicability c city l local neighbourhood m micro e g street canyon park with an example of where their application may be useful those components with post processing visualization tools are indicated with benchmarking or other statistics are indicated with and components described in detail in the text with note the micro scale applications are usable across a whole city but are likely to be computer intensive table 1 component scales description example applications key a pre processor meteorological data prepare existing data c l m formats meteorological data for input to the models dealing with missing data local weather station data can be manipulated into a standard format and subjected to basic quality control n a download data watch c l downloads climate re analysis data modifies it for use in an urban context representative of the local scale if local meteorological data are unavailable allows reanalysis data for land surface modelling to be used weedon et al 2011 2014 kokkonen et al 2017 ward et al 2017a b spatial data spatial data downloader c l m downloads spatial data from public servers if spatial population data within a city are unavailable they can be downloaded from world wide online dataset n a tree generator c l m creation manipulation of 3d vegetation data influence of vegetation on thermal comfort and energy exchanges in a city n a lcz converter c l allows morphometric parameters and land cover fractions see table 4 to be calculated from local climate zone lcz maps generated by wudapt http www wudapt org generates surface input data for city to neighborhood scale modelling stewart and oke 2012 ching et al 2017 urban geometry sky view factor l m amount of the hemisphere with restricted view of the sky solar access urban heat island thermal comfort modelling lindberg and grimmond 2011a b wall height aspect l m height and orientation of buildings and walls solar access urban heat island thermal comfort modelling lindberg et al 2016a urban land cover land cover reclassifier c l m geodata can be translated into the land cover classes used by all the models remote sensing and other geodata sources e g modis classes can be modified for use with models and made appropriate for a local area n a land cover fraction point l m surface cover fractions are determined for an area circle of selected diameter or specific directions table 4 analysis and characterization of a measurement site n a land cover fraction grid c l as above but a grid is used to determine fractions for multiple areas data input for an extensive area for modelling n a urban morphology morphometric calculator point l m morphometric parameters table 4 are determined for an area circle of selected diameter or specific directions can be used interpretation of a measurement location in terms of surface roughness kent et al 2017a b table 4 morphometric calculator grid c l as above but a grid is used to determine parameters for multiple areas data input on surface roughness for an extensive area for modelling kent et al 2017a b table 4 source area point l m as above but determined for an area derived from source area models interpretation of observations investigation of potential siting of instruments kormann and meixner 2001 kljun et al 2015 kent et al 2017a b suews prepare c l prepares input data for the suews model processor based on information derived from other pre processing tools within umep for extensive analysis using suews input forcing data and derived spatial information needed can be prepared n a b processor thermal comfort extremefinder c finds extreme high and extreme low events e g heat waves or cold waves in meteorological time series data table 2 identification of extreme temperatures from a long climate record see table 2 mean radiant temperature solweig l m solweig estimates spatial 2 d variations of 3 d radiation fluxes and the mean radiant temperature t mrt in complex urban settings both 3d vegetation trees and bushes as well as ground cover variations are currently considered in the model t mrt is an important meteorological variable governing the human energy balance and thermal comfort outdoors especially during clear and calm summer days mayer and höppe 1987 lindberg et al 2008 lindberg and grimmond 2011a b lindberg et al 2016b urban energy balance anthropogenic heat q f lqf c l globally applicable method low spatial resolution to calculate q f quantifies contributions to energy budget from building energy use and road traffic allen et al 2011 lindberg et al 2013a gabey et al 2017 anthropogenic heat q f gqf c l locally applicable method high spatial resolution to calculate q f quantifies contributions to energy budget from road traffic residential and non residential building energy use with different fuels and vehicle types considered iamarino et al 2012 gabey et al 2017 urban energy and water balance suews simple c l urban land surface model that allows radiation energy and water fluxes to be calculated for a single point or area simulations of evaporation and heat fluxes for a neighborhood or across a city järvi et al 2011 2014 ward et al 2016 2017b urban energy and water balance suews advanced c l as above but for multiple areas e g a city with 1000s of grid squares or local planning zones of any shape assessment of future city plans and impacts of drought heatwaves water management green infrastructure table 3 solar radiation solar energy on building envelopes sebe l m shortwave irradiance on ground roofs and building walls is estimated based on high resolution digital surface models dsms and input meteorological forcing data potential for energy production resource planning lindberg et al 2016b daily shadow patterns l m shadow maps are derived from buildings and 3d vegetation impact of building form and vegetation on energy production outdoor thermal comfort planning of parks and outdoor spaces lindberg and grimmond 2011a b ratti and richens 1999 c post processor sebe visualization l m visualization of solar irradiation on building envelopes roofs and walls identify areas of good or poor potential for generation of solar energy if panels were installed n a solweig analyzer l m solweig output point temporal model domain spatial temporal identify potential hazard areas potential sites for outdoor activities e g café park n a suews analyzer c l suews output point temporal model domain spatial temporal comparison of indicators under different planning scenarios through time and as maps ward and grimmond 2017 benchmarking c l m statistical tool to compare different datasets model evaluation n a table 2 the heat cold wave indices used in umep extremefinder table 2 extreme event reference index description heat wave meehl and tebaldi 2004 longest period when maximum temperature is above the 97 5th percentile for at least 3 days average daily maximum temperature across the event is over the 97 5th percentile and all days are above the 81st percentile fischer and schär 2010 periods of at least 6 days where maximum temperature exceeds the calendar day 90th percentile vautard et al 2013 periods of various length when daily mean temperature is above the 90th percentile schoetter et al 2014 at least 3 days above the 98th percentile of maximum temperature cold wave keevallik and vint 2015 cold night temperature lower than 10th percentile of daily minimum temperatures calculated for a 5 day window centered on each calendar day in dataset cold wave six consecutive cold nights srivastava et al 2009 minimum temperature is below the normal temperature by 3 c or more consecutively for 3 days or more busuioc et al 2010 cited by micu 2012 at least 6 consecutive days with negative deviations of at least 5 c from the normal value of each calendar day table 3 studies that have evaluated and applied suews presented chronologically note other sub component models have been evaluated and applied prior to these references table 3 city reference variables evaluated application evaluation vancouver canada järvi et al 2011 water use anthropogenic heat flux radiation sensible and latent heat fluxes soil moisture surface wetness los angeles usa järvi et al 2011 radiation sensible and latent heat fluxes helsinki finland järvi et al 2014 radiation sensible and latent heat fluxes snowmelt runoff albedo snow depth montreal canada järvi et al 2014 radiation sensible and latent heat fluxes snowmelt albedo snow density snow depth dublin ireland alexander et al 2015 2016a radiation sensible and latent heat fluxes sacramento usa onomura et al 2015 boundary layer height sensible and latent heat flux hamburg germany alexander et al 2016a sensible and latent heat fluxes melbourne australia alexander et al 2016a sensible and latent heat fluxes phoenix usa alexander et al 2016a sensible and latent heat fluxes swindon uk ward et al 2016 radiation sensible and latent heat fluxes soil moisture surface wetness london uk ward et al 2016 radiation sensible and latent heat fluxes soil moisture helsinki finland karsisto et al 2015 radiation sensible and latent heat fluxes snow depth shanghai china ao et al 2016 radiation singapore demuzere et al 2017 radiation sensible and latent heat fluxes basel switzerland järvi et al 2017 radiation sensible and latent heat fluxes snow depth minneapolis saint paul usa järvi et al 2017 radiation sensible and latent heat fluxes snow depth application helsinki finland nordbo et al 2015 effect of surface cover resolution on suews performance dublin alexander et al 2016a b impact of urban development pathways on sensible and latent heat fluxes across the city of dublin dublin ireland alexander et al 2016b lcz classification combined with suews hamburg germany alexander et al 2016b lcz classification combined with suews melbourne australia alexander et al 2016b lcz classification combined with suews phoenix usa alexander et al 2016b lcz classification combined with suews porto portugal rafael et al 2016 urban resilience measures under different climate scenarios london uk ward and grimmond 2017 impact of urban development and climate mitigation measures on energy partitioning across greater london table 4 spatially related urban surface parameters determined by umep pre processors table 4 plug in parameters land cover types water building paved surfaces bare soil deciduous trees evergreen trees and grass surfacesplan area fraction the combined fractions for a grid must sum to 1 source area two source area models are included kormann and meixner 2001 kljun et al 2015 morphometric methods h av average roughness element height methods for z 0 and z d λ p plan area index rule of thumb grimmond and oke 1999 λ f frontal area index raupach 1994 h max maximum roughness element height bottema and mestayer 1998 σ h standard deviation of roughness element heights macdonald et al 1998 z 0 aerodynamic roughness length millward hopkins et al 2011 z d zero plane displacement kanda et al 2013 wall height and aspect wall heightaspect orientation svf calculator sky view factor values of 1 indicate complete sky access 0 no sky access height of calculations can be varied table 5 evaluation and application studies using the solweig model table 5 city reference variables settings evaluation gothenburg sweden lindberg et al 2008 radiant fluxes and t mrt city square courtyard gothenburg sweden lindberg and grimmond 2011a radiant fluxes and t mrt city square with tree kassel germany lindberg and grimmond 2011a t mrt street canyon freiburg germany lindberg and grimmond 2011a t mrt four urban sites london uk lindberg et al 2016b radiant fluxes and t mrt different urban ground covers shanghai china chen et al 2016 t mrt very dense urban environment hong kong china lau et al 2016 t mrt very dense urban environment application gothenburg sweden thorsson et al 2010 spatial and temporal t mrt future climate scenarios london uk lindberg and grimmond 2011b t mrt intra urban differences gothenburg sweden lindberg et al 2013a b spatial t mrt consideration of weather stockholm sweden thorsson et al 2014 t mrt prediction of heat related mortality porto portugal lau et al 2014 t mrt effects of urban geometry climate change gothenburg sweden lau et al 2014 t mrt effects of urban geometry climate change frankfurt germany lau et al 2014 t mrt effects of urban geometry climate change berlin germany jänicke et al 2016 t mrt city wide characteristics adelaide australia thom et al 2016 t mrt influence of increasing tree cover gothenburg sweden lindberg et al 2016b spatial and temporal t mrt future climate scenarios urban multi scale environmental predictor umep an integrated tool for city based climate services fredrik lindberg a c s b grimmond b andrew gabey b bei huang b c christoph w kent b ting sun b natalie e theeuwes b leena järvi d helen c ward b e i capel timms b yuanyong chang f per jonsson g niklas krave a b dongwei liu f d meyer b k frans g olofson a jianguo tan h dag wästberg g lingbo xue b i zhe zhang b j a department of earth sciences university of gothenburg gothenburg sweden department of earth sciences university of gothenburg gothenburg sweden b department of meteorology university of reading reading united kingdom department of meteorology university of reading reading united kingdom c department of hydraulic engineering tsinghua university beijing china department of hydraulic engineering tsinghua university beijing china d department of physics university of helsinki finland department of physics university of helsinki finland e institute of atmospheric and cryospheric sciences university of innsbruck innsbruck austria institute of atmospheric and cryospheric sciences university of innsbruck innsbruck austria f shanghai institute of meteorological science shanghai meteorological service china shanghai institute of meteorological science shanghai meteorological service china g tyréns ab gothenburg sweden tyréns ab gothenburg sweden h shanghai climate centre shanghai meteorological service china shanghai climate centre shanghai meteorological service china i information center yangzhou university china information center yangzhou university china j school of environment and sustainability university of saskatchewan saskatoon canada school of environment and sustainability university of saskatchewan saskatoon canada corresponding authors umep urban multi scale environmental predictor a city based climate service tool combines models and tools essential for climate simulations applications are presented to illustrate umep s potential in the identification of heat waves and cold waves the impact of green infrastructure on runoff the effects of buildings on human thermal stress solar energy production and the impact of human activities on heat emissions umep has broad utility for applications related to outdoor thermal comfort wind urban energy consumption and climate change mitigation it includes tools to enable users to input atmospheric and surface data from multiple sources to characterise the urban environment to prepare meteorological data for use in cities to undertake simulations and consider scenarios and to compare and visualise different combinations of climate indicators an open source tool umep is designed to be easily updated as new data and tools are developed and to be accessible to researchers decision makers and practitioners keywords qgis urban climate services heat risk solar energy green infrastructure 1 introduction urban environments are particularly vulnerable to high impact weather given the high population densities in many cities and the associated assets and infrastructure e g as evidenced by the impacts of hurricane sandy on new york city solecki 2015 with weather extremes frequently exceeding climate records and with urban areas growing rapidly the ability to deliver city based climate services to those operating and planning different aspects of city life transport energy demand water supply etc is critical horton et al 2016 baklanov et al 2017 a common toolbox accessible to researchers decision makers and practitioners offers great potential for better informed climate related decisions in cities scientists and practitioners from a broad range of disciplines including architecture e g ren et al 2011 climatology e g eliasson 2000 planning e g alcoforado et al 2009 engineering and geography have long been interested in how weather and climate affects cities and their occupants baklanov et al 2017 however the development and adoption of city based climate services which require production translation transfer communication and use of climate knowledge and information for urban planning building design and the operation of cities is not straight forward chrysoulakis et al 2013 grimmond et al 2014 masson et al 2014 baklanov et al 2017 appropriate input data surface and atmospheric can be challenging to access and specialist formats often make them inaccessible to many end users grimmond 2013 communication between producers and users of climate services has been poor with outputs often not easily interpretable by non specialists tools that are more user friendly and are technically and economically accessible to users are needed to improve communication across disciplines researchers and users to better identify user needs to ensure common assumptions across models to build capacity to address urban climate and weather concerns and transfer research into practice past initiatives have tended to focus on specific processes e g herbert et al 1998 or restricted spatial or temporal scales e g bruse and fleer 1998 with applications most often intended for specialist researchers many of these studies have focused on water and waste water management e g paton et al 2014 saagi et al 2017 and not on integrated hydro climatological models appropriate for application at multiple scales neighbourhood to city which account for feedbacks and complex interactions for example the effect of water on heat exchanges as well as on flooding here we introduce umep urban multi scale environmental predictor an integrated tool for urban climatology and climate sensitive planning applications while elements of umep have been presented elsewhere see further discussion below and summary in table 1 this is the first full description of umep and its potential across a broad range of applications in its current form the tool can be used for applications related to outdoor thermal comfort urban energy consumption and climate change mitigation umep consists of a coupled modelling system which combines state of the art 1 d and 2 d models with systems to input data from multiple sources formats and at different temporal and spatial scales and to generate output as data graphs and maps an important feature of umep is its ability to couple relevant processes and to use common data across a range of applications here the basic structure of umep is described followed by examples of applications to illustrate the potential of this tool 2 umep overview umep is being developed as a community open source tool to enable its use without restriction with respect to cost license or rights issues users are encouraged to contribute to the tool to enhance and extend its capabilities one of its major features is the ability for users to interact with spatial information to determine model parameters and to edit map and visualise inputs and results for this reason the software is written as a plug in to qgis a cross platform free and open source desktop geographic information system gis application qgis development team 2017 umep has three main elements fig 1 pre processor for inputs of meteorological and surface information processor modelling system e g urban land surface models ulsm and post processor tools to analyse the outputs individual case and ensemble indicators of uncertainty user applications etc each element is described briefly in table 1 with more complete details presented in the online manual http www urban climate net umep umep umep allows users to integrate atmospheric and surface data from multiple sources take meteorological data measured at standard sites and adapt them to be representative of the urban environment use reanalysis or climate prediction data and compare and visualise results or scenarios for different climate indicators of interest heat indices intense precipitation water energy demand this all can be done at a range of spatial scales consistent with end users needs and interests table 1 to aid uptake and use of the model and to develop capacity in urban modelling more generally a series of tutorials have been developed http www urban climate net umep umep manual tutorials one key contribution of umep is to facilitate the preparation of input data required for city based climate services cbcs umep provides both guidance and tools that enable the preparation and manipulation of data table 1 this is particularly important as most end users are familiar with some but not the full spectrum of data needed for applications for example planners are knowledgeable about building heights materials and their spatial arrangement i e urban surface data and often have gis skills but they may not necessarily have detailed knowledge of meteorological data equally those knowledgeable of the latter may not be expert of the former although remotely sensed data may play a very useful part in cbcs these data may require further processing to be applicable in urban areas umep has been designed to enhance their integration the tools within umep can also be used to provide data to export to other more complex weather climate hydrological environment modelling systems alternatively data from more complex models may be imported into umep umep has a broad range of capabilities table 1 each of its elements may be used independently or in varying combinations users may be interested in the output from tools that are provided in the pre processor for other modelling applications e g in generating urban surface information or standardised meteorological fields or in applications that require a chain of tools to provide climate indicators for decision making as many of the individual tools as well as their evaluations have been described in disciplinary focussed papers see table 1 references here we present a range of examples each of which requires the use of several tools to obtain a solution 3 umep applications in this section examples of applications are presented to illustrate umep s potential specifically in the identification of heat waves and cold waves in cities extremefinder bold is used hereafter to indicate the component of the umep plug in tool the implications of green infrastructure on runoff suews micro scale heat stress solweig solar energy production sebe and sources of anthropogenic human generated heat lqf gqf each application draws on different combinations of umep tools 3 1 application example 1 identification of extreme thermal conditions for many urban planning and human health applications extreme meteorological conditions are of interest and concern to identify these extremes analysis of a long climatological record is required table 2 however if such data are not available for the area of interest umep allows the user to draw on the reanalysis dataset watch forcing data era interim wfdei dee et al 2011 weedon et al 2011 2014 this product was selected as it was designed to be used for hydrological and land surface modelling for climate purposes and has been used in several cities around the world to explore variations in energy flux partitioning best and grimmond 2016 to determine the extreme thermal conditions for a site the first step is to use the umep download data watch table 1 to obtain a meteorological time series for the period and location of interest these data can also be used for other umep applications e g section 3 2 for example they can be downscaled to the area of interest using the techniques of best and grimmond 2016 and ward et al 2017a b appendix 1 currently extremefinder provides four methods to identify heat waves and three for cold waves table 2 as there is no generally accepted definition of either phenomena robinson 2001 vaidyanathan et al 2016 different percentiles are used to define extremes e g table 2 the thresholds for the extremes are based on fixed values or quantiles calculated from the meteorological time series use of a time series spanning decades is therefore recommended the user can modify the fixed thresholds and quantiles http urban climate net umep umep manual outdoor thermal comfort extremefinder daily values are then evaluated to determine if an extreme event has occurred extremefinder identifies the dates and daily maximum average or minimum temperatures of all extreme high low events during the period of interest fig 2 yellow boxes based on the criteria set out by the method chosen 3 2 application example 2 urban energy and water balance fluxes energy and water balance fluxes are critical to surface atmosphere interactions in an urban area the impact of extreme conditions heat waves droughts floods etc are influenced by the state of the urban environment prior to these events with the urban energy and water balance varying with different neighbourhood local scale characteristics the surface urban energy and water balance scheme suews is an urban land surface model included in the processing part of umep table 1 the model simulates the urban radiation energy and water balances using commonly measured meteorological variables and information about the surface cover suews is applicable at the neighborhood to city scale in umep suews is uncoupled i e advection between grids is not accounted for umep allows suews to be run as a standalone model or umep can provide the appropriate parameters for the use of suews within a 3 d model meso scale model such as wrf dudhia 2014 the parameters calculated with umep tools can provide the input parameters to a wide range of urban land surface models either standalone versions surfex masson et al 2013 jules best et al 2011 clm lawrence et al 2011 slucm kusaka et al 2001 or coupled to larger scale models suews uses an evaporation interception approach grimmond and oke 1991 for an area comprised of seven land cover types water buildings grass paved bare soil deciduous trees shrubs and evergreen trees shrubs the state of each surface type at each time step is calculated from the running water balance of the canopy where the evaporation is calculated from the penman monteith equation the soil moisture below each surface type excluding water is considered umep has the latest version of suews ward et al 2017a b accessible through two links a suews simple provides a useful starting place to introduce umep and suews example data are provided so that users can explore the impact of modifying urban surface characteristics with suews simple the ulsm can be executed for a single location area b suews advanced provides a full version of the model appropriate for investigating both spatial and temporal variations of the urban energy balance the suews model has been extensively evaluated for a variety of locations and situations worldwide table 3 the workflow for an application utilizing suews within umep is outlined in fig 3 geodatasets that contain information about the urban environment are used with the pre processor tools fig 3 gray and yellow to provide the required surface parameters the model can be applied to areas of any shape as in most cities planning units have known boundaries already available in vector polygon format e g boroughs wards alternatively a square grid can easily be created in qgis fig 4 a as land cover fig 3 is a key variable for many calculations a method to reclassify data is provided the umep land cover reclassifier enables land cover raster grids to be created from sources such as modis and then converted to the standard umep cover types table 4 surface cover fractions are very important given differences in energy and water partitioning that result from underlying differences in moisture availability and surface properties accessing reliable sources of land cover information to derive these parameters at the scale of interest remains a challenge crowd sourced data sets such as openstreetmap http www openstreetmap org and wudapt http www wudapt org see below offer potential but may be incomplete or inconsistent other sources such as modis https terra nasa gov about terra instruments modis are likely to be complete but give low spatial resolution at the sub km scale in addition the number of human altered urban classes from such data are limited 3 classes and the discrimination between land cover classes needs to be made based on land use in the example given here for central london the land cover information fig 4a is derived from os mastermap topography layer ordnance survey 2010 the land cover fraction grid tool is used to calculate grid based land cover fractions tables 1 and 4 based on the land cover raster grid morphometric parameters table 4 related to surface roughness can be obtained from the morphometric calculator grid using digital surface models dsm fig 4b from these data the zero plane displacement z d aerodynamic roughness length z 0 and other geometric parameters such as mean roughness element height and frontal area index are calculated table 4 the rationale behind the different methods and a basis for selecting between them is outlined in kent et al 2017a b parameters can be derived for the full surrounding area or for sectors reflecting different wind directions applications which involve an assessment of the area surrounding a measurement point can use the source area model point currently there are two turbulent flux source area models included within umep tables 1 and 3 the analytical model of kormann and meixner 2001 and kljun et al s 2015 parameterisation of a lagrangian stochastic particle dispersion model these models indicate the probable surface area contributing to a turbulent flux measurement at a specific point in time and space with imposed boundary conditions e g meteorological conditions sources sinks of passive scalars or surface characteristics the results from these models facilitate interpretation of observations enable improved evaluation of flux models and or allow assessments of the appropriateness of siting of new instrumentation fig 5 population density people per hectare is used in the estimation of anthropogenic heat flux in suews if population density datasets are unavailable e g as would be obtained from local census data the spatial data downloader can be used this plug in is directly connected to various web coverage services wcs including global datasets on population density http urban climate net umep umep manual spatial data spatial data downloader in the example given here averaged population density between residential and working population is used fig 4c such differentiations are very important in locations such as central london for anthropogenic heat flux calculations dong et al 2017 gabey et al 2017 given the challenges of acquiring all the datasets needed dem dsm and land cover in fig 3 local climate zone maps lcz stewart and oke 2012 are included in umep from these a first estimate of input parameters for suews can be made in umep the lcz maps from the wudapt database www wudapt org ching et al 2017 can be translated using the lcz converter if more detailed information is available for specific areas or becomes available subsequently e g local high resolution dsms parameters can be updated the other major input to suews is the meteorological forcing data table a1 1 such data need to be for above the height of the roughness elements trees buildings a common format is used in all umep models table a1 1 most applications require a continuous gap filled data set for many urban applications the start and finish of daylight savings is linked to important behavioural patterns e g the shift of rush hour therefore the individual models account for daylight savings if relevant e g timing of anthropogenic energy use irrigation the preparing existing data umep tool see appendix 1 supports preparation of the meteorological data and conversion into the format used in all umep models once all the required information is pre processed suews prepare can arrange the data so the model can be executed suews analyzer fig 3 allows spatial fig 6 a temporal fig 6b and between variable fig 6c model results to be explored in this example application central london average daytime sensible heat fluxes qh for four months period in 2015 are mapped fig 6a with detail of temporal variations of net all wave radiation q and qh for nine days for one area grid id 44 graphed fig 6b the relation between q and qh for grid id 44 for the whole time period fig 6c is also plotted to illustrate a hydrological application to examine runoff generation in different planning scenarios suews was run for a highly built up catchment area 24 ha in helsinki for 2010 fig 6d f the planning scenarios considered the current land cover use base run and a 10 and 30 increase in areal coverage of street trees and grass surfaces at the expense of paved surfaces fig 6f results from these simulations indicate that the increase in the amount of street trees i e areal fraction of street trees is more effective in reducing surface runoff compared to an increase in grass surfaces a 10 increase in street trees is more effective than a 30 increase in grass surfaces 3 3 application example 3 mean radiant temperature temperature related health problems are expected to increase with rising temperature in cities especially during more extreme temperatures associated with heat waves mean radiant temperature t mrt is one of the most important meteorological variables governing the human energy balance and thermal comfort outdoors especially on clear and calm summer days mayer and höppe 1987 to provide estimates of thermal comfort heat stress for people solweig solar and longwave environmental irradiance geometry model can be used to calculate t mrt in solweig both 3d vegetation trees and bushes as well as variations in ground cover can be considered lindberg and grimmond 2011b lindberg et al 2016b solweig has been evaluated extensively and applied at urban locations worldwide table 5 fig 7 shows the umep workflow to examine 3d radiant fluxes and t mrt of the four geodatasets needed the ground and building dsm fig 8 a is fundamental if available a vegetation dsm cdsm can be added lindberg and grimmond 2011b however as 3d information on vegetation is sparse the tree generator tool allows point vector data of tree locations to be transformed into a cdsm ground cover information can be used to estimate outgoing short and longwave radiation fluxes lindberg et al 2016a b to obtain the appropriate ground cover classes the land cover reclassifier fig 7 can be used to obtain the five ground cover classes water buildings grass paved and bare soil used in solweig fig 8b no bare soil present the sky view factor svf is the ratio between the radiation received or emitted by a planar surface and the radiation emitted or received by the entire hemispheric environment watson and johnson 1987 this dimensionless metric totally obstructed 0 totally unobstructed 1 is important to human comfort fig 8c solar energy and solar access a pixel wise sky view factor calculated in svf uses ground and building dsms and or vegetation dsm fig 8c solar access and radiative exchanges are impacted by wall height and aspect wall height and aspect tables 1 and 4 fig 7 provides wall pixels with their height fig 8d and aspect degrees the latter is a modification of the goodwin et al 2009 linear filter lindberg et al 2015b to model t mrt successfully building footprint locations must be derived from either the ground cover grid or from differences between ground heights dem and a dsm fig 7 solweig can be used for an individual time or a time series for the latter points of interest poi are added within the model domain solweig analyzer can be used to provide spatial fig 8e and temporal fig 8f visualizations of results by comparing the input geodata fig 8a d and the results fig 8e f the micro scale influences on the temporal and spatial patterns can be identified and explained as shown in fig 8f the temporal influence of t mrt is unlike air temperature it is highly affected by other variables such as shortwave and longwave radiation fluxes application of solweig to explore variations in t mrt around the civic square medborgarplatsen of central stockholm shows that at 2 p m shadows from buildings and vegetation are important fig 9 the highest t mrt values are next to sunlit walls and on the sunlit open spaces open areas have high values t mrt due to partly cloudy conditions which increases the proportion of diffuse shortwave radiation the high values of t mrt adjacent to the walls are related to the emitted longwave radiation and reflected shortwave radiation from the sunlit walls to explore the potential impact of t mrt it is useful to consider critical health thresholds from analysis of stockholm county daily all cause mortality data 1990 2002 thorsson et al 2014 found that when t mrt exceeds 59 4 c there is an increase in heat related mortality of 10 for those 80 years of age using this threshold the areas of greatest hazard can be identified adjacent to the sunlit buildings fig 9b to determine the effects of warmer air temperature 2 c 4 c the hazard can be re analysed with further solweig simulations fig 9c and d the hazard increases in both areal and temporal extent with both open spaces and areas adjacent to sunlit walls being identified cf fig 9b walls have greater influence as air temperatures become warmer as surface temperature of walls increase and emit more longwave radiation while the shortwave radiation in open spaces remains constant to investigate patterns at the city scale the influence of building and vegetation density on t mrt across stockholm is examined at a pixel resolution of 1 m the density of buildings and t mrt show no strong correlation however there is a clear relation between t mrt at 2 p m and vegetation density at the 500 m scale fig 10 this demonstrates that increasing vegetation in urban areas could reduce t mrt and mitigate heat stress 3 4 application example 4 solar energy on building envelopes the contrast between sunlit and shaded surfaces can explain micro scale differences in urban climate for example spatial variation in road surface temperatures hu et al 2015 in umep sunlit fractions are computed using high resolution dsms and the shadowcalculator the shadow casting algorithm uses sequential computation of shadow volumes ratti and richens 1999 with a raster dsm ratti and richens 2004 lindberg and grimmond 2010 to map potential solar energy production sebe solar energy on building envelopes can calculate irradiances at pixel resolution on building roofs and walls using a 2 5 dimensional model observed solar radiation data are used with high resolution dsms to derive accurate irradiances for the surfaces modelled lindberg et al 2015a b sebe has been applied to several cities in sweden http www urban climate net umep example applications fig 11 shows a snapshot of an online mapping service where irradiance on roofs in uppsala 14 km2 has been modelled in umep at 0 25 m resolution the surface data are a combination of airborne lidar data and 3d vector polygons representing roof structures for each building post processing analysis derived several statistics including areal extent m2 of roofs and walls suitable for solar energy production fig 11a and the 3d distribution of solar irradiance fig 11b 3 5 application example 5 anthropogenic heat fluxes anthropogenic heat flux q f heat released directly by humans and their activities sailor 2011 is a distinct feature of urban areas with significant impact on energy and water exchanges in umep in addition to the methods within suews q f can be modelled using two standalone approaches appendix 2 i lqf which uses the lucy methodology allen et al 2011 lindberg et al 2013a and provides simple estimates at low spatial resolution and ii gqf which is a reimplementation of greaterqf iamarino et al 2012 and produces high resolution estimates with greater insights into specific types of energy use in umep each has been supplemented with a spatial input data pre processor that makes use of standard gis data formats and outputs spatially and temporally resolved q f estimates of traffic q f t metabolic q f m and building q f b emissions in universal coordinated time the lqf results can be incorporated into the meteorological data used to force suews via the refinement stage of the download data watch tool an example of lqf output across greater london in october 2015 using local super output area lsoa population data shows the spatial distribution of each component and the resultant larger q f towards the city centre fig 12 b d f the assumptions applied here limit lqf to spatial scales of the order 1 km gabey et al 2017 at spatial scales less than 1 km movements of people for example from home to work are important and the structure of the road network needs to be captured gabey et al 2017 example output maps from gqf fig 12a c e show order of magnitude agreement with lqf with a notably different spatial structure in q f t fig 12c d because road network topology is used rather than population count the effect of using the workday gqf rather than residential lqf population on the daytime metabolic emission fig 12e f is visible as a strong enhancement in the centre of the city a similar enhancement is also evident in the building emissions fig 12 a b which is attributable to the use of spatially resolved energy consumption in gqf compared with residential population based attribution in lqf 4 concluding comments the city based climate service tool umep urban multi scale environmental predictor is introduced through a series of applications the qgis plug in has a coupled modelling system of state of the art 1 d and 2 d models which can provide estimates of essential urban climate processes it also provides tools for determining parameters for more complex 3 d models a key contribution of umep is to provide a method to consistently determine model parameters across a suite of models and applications this serves to ensure consistency in theoretical assumptions between models data analysis observations evaluation and applications different scales applications and end users common processing tools also enable rapid updates when new data become available for example release of new national statistical data used in the anthropogenic heat flux or when new parameterisations are developed for example new aerodynamic roughness models of kent et al 2017a b which can then be used to understand flux measurements source area model and to perform energy and water balance calculations suews example applications have been presented to illustrate umep s potential specifically of the identification of heat waves and cold waves in cities extremefinder the implications of green infrastructure on runoff suews micro scale heat stress solweig solar energy production sebe and sources of anthropogenic human generated heat lqf gqf each application draws on different combinations of umep tools umep is under active development and refinement it is designed as an open source tool the development team welcomes all kinds of collaboration through for example submission of comments or issues to the repository www bitbucket fredrik ucg umep participation in coding addition of new features and development of new tutorials for users the online manual provides more details on how to participate http www urban climate net umep umep manual planned developments include tools for pedestrian wind and thermal comfort indices acknowledgements the greater london authority lidar dataset are used courtesy of matthew thomas greater london authority and data from a nerc arsf gb08 19 flight the stockholm data and results are used courtesy of anette jansson environmental office city of stockholm financial support was provided by formas the swedish research council for environment agricultural sciences and spatial planning met office climate science for service partnership cssp china as part of the newton fund h2020 eo 1 2014 project 637519 urbanfluxes nerc case studentship with rms supported cwk british council funded bh epsrc studentship ict and university of reading work sg ag nk ts hcw and visits yyc dwl to the uk were supported by the uk china research innovation partnership fund through the met office climate science for service partnership cssp china as part of the newton fund the umep plug in can be downloaded from http www urban climate net umep software availability name of software urban multi scale environmental predictor umep developers fredrik lindberg sue grimmond andrew gabey bei huang christoph w kent ting sun natalie e theeuwes isabella capel timms leena järvi helen c ward yuanyong chang niklas krave d meyer frans olofson jianguo tan dag wästberg lingbo xue zhe zhang contact fredrik lindberg fredrikl gvc gu se 46 31 786 2606 sue grimmond c s grimmond reading ac 44 118 378 6248 year first available 2015 hardware required na software required qgis 2 x operation system required os independent program language python program size 2 5 mb compressed 9 mb uncompressed availability and cost open source no cost repository www bitbucket org fredrik ucg umep webpage www urban climate net umep appendix 1 meteorological information umep uses a common data format for meteorological data table a1 1 preparing existing data figure a1 1 imports variables from ascii files and allows for time related variables year day of year hour and minute and other time formats such as month day of month etc in preparation for analysis during this process some quality control is performed to ensure the data are within reasonable limits table a1 1 figure a1 1 and to identify missing time intervals fig a1 1 example dialogue box in umep meteorological processor fig a1 1 download data watch provides another source of meteorological forcing data section 3 1 global reanalysis products if observed data are not available however the coarse spatial resolution of reanalysis products e g grids of 0 5 means that downscaling is needed prior to their use for local scale urban hydrological modelling wilby et al 2000 fowler et al 2007 bastola and misra 2014 the methods used to prepare the data are based on best and grimmond 2016 kokkonen et al 2017 and ward et al 2017a these involve i identification of the area of interest ii download of the data and iii generation of a umep formatted file with data aligned to the appropriate time zone at hourly intervals these umep wfdei data corrections are dependent on the meteorological variables as some are instantaneous values whereas others are averages for a 3 h period weedon et al 2011 ward et al 2017a the 3 h data are linearly interpolated to 1 h data however for the incoming solar radiation the times of sunrise and sunset are calculated to ensure that the day length is as expected and the interpolated data are adjusted to take this into account for instance if sunrise and sunset times are 6 00 lt local time and 19 00 lt respectively only the interpolated values between 6 00 lt and 19 00 lt will have non zero short wave radiation but are rescaled for that period retaining the daily average the relative humidity rh is obtained from the specific humidity q v in kg kg 1 as follows r h e a e s 100 with e a and e s the actual and saturation vapor pressures buck 1981 given by e a r v q v p r d q v r v r d e s 6 1121 exp 18 678 t c 234 5 t c t c 257 14 1 00072 p 3 2 10 6 5 9 10 10 t c 2 t c 0 c 6 1115 exp 23 036 t c 333 7 t c t c 279 82 1 00022 p 3 83 10 6 6 4 10 10 t c 2 t c 0 c where r v 461 5 j k 1 kg 1 the specific gas constant for water vapour r d 287 04 j k 1 kg 1 the specific gas constant for dry air p the atmospheric pressure kpa and t c the air temperature c other corrections consider the effect of elevation with a coarse grid the city or of area of interest may be at a lower elevation than the surroundings as one example vancouver the real weighted mean wfdei grid height includes mountains but much of the city is much lower kokkonen et al 2017 thus consideration needs to be given to i the elevation of the area of interest ii the height of the roughness elements buildings trees and iii the appropriate height for the forcing data for the simulation in umep the wfdei temperature and pressure values are adjusted to the simulation height using environmental lapse rate γ 6 5 c km 1 and the hypsometric equation weedon et al 2011 rh used by suews is calculated from the wfdei specific humidity assuming it is constant with altitude to avoid supersaturation interpolation and altitude corrections may require a spin up period to avoid interpolation errors and missing data points at the beginning and at the end of the time series thus longer periods should be used for analysis than the period of specific interest table a1 1 meteorological data used in various components of umep are formatted in the order indicated the metdata pre processor tool does simple quality control to ensure data are within acceptable ranges not all variables are required in umep with the exception of the four time related columns all any that use meteorological data su suews so solweig sa source area model se sebe for some application these data are required bold the variables extracted by download data watch are indicated column 5 when data are not needed it can be assigned 999 to indicate no data available day of year is used instead of date within a month for simplicity the hour and minute is local standard time and refers to time ending table a1 1 no description units accepted range used by watch 1 year yyyy all 2 day of year doy all 3 hour h all 4 minute m all 5 net all wave radiation w m 2 200 to 800 su 6 sensible heat flux w m 2 200 to 750 su 7 latent heat flux w m 2 100 to 650 su 8 storage heat flux w m 2 200 to 650 su 9 anthropogenic heat flux w m 2 0 to 1500 su 10 wind speed m s 1 0 001 to 60 su sa x 11 relative humidity 5 to 100 su so se x 12 air temperature c 30 to 55 su so se x 13 barometric pressure kpa 90 to 107 su so x 14 rainfall mm 0 to 30 per 5 min su x 15 incoming shortwave radiation w m 2 0 to 1200 su so se x 16 snow mm 0 to 300 per 5 min su x 17 incoming longwave radiation w m 2 100 to 600 su x 18 cloud fraction tenths 0 to 1 su 19 external water use m3 0 to 10 per 5 min su 20 observed soil moisture m3 m 3 or kg kg 1 0 01 to 0 5 su 21 observed leaf area index m2 m 2 0 to 15 su 22 diffuse shortwave radiation w m 2 0 to 600 so se 23 direct shortwave radiation w m 2 0 to 1200 so se 24 wind direction 0 to 360 su sa 25 friction velocity m s 1 all sa 26 standard deviation sigma of transverse wind velocity m s 1 all sa 27 obukhov length m all sa 28 boundary layer height m all sa appendix 2 anthropogenic heat flux lqf is designed to provide out of the box anthropogenic heat flux qf estimates at 1 h time steps the minimum user provided input data required are the spatially resolved population count and a daily mean air temperature time series both data sets can be obtained using tools within umep heat fluxes are estimated using a top down methodology that draws on a database of national energy consumption population and vehicle ownership statistics lqf attributes this energy consumption and traffic based on local population count variations and estimates qf in each population area it is possible to replace the national data with provincial or smaller regions if the data are available the database contains diurnal variations for metabolism traffic flow and building energy consumption which are optionally overridden with user specified versions weekend weekday variations are captured for buildings qf b and transport qf t while the user specified versions provide control over each day of the week day to day building energy consumption is estimated using a database held country specific temperature response function and assumption about the prevalence of air conditioning lindberg et al 2013a a blanket weekend traffic reduction is also applied to capture day of week traffic flow changes table a2 1 input data files required by the lqf model table a2 1 dataset type remarks population count polygon shapefile basis of spatial variations of q f components daily mean temperature csv file s basis of day to day building energy consumption variations traffic diurnal profile csv file s optional building energy diurnal profile csv file s optional lqf database spatialite file downloaded from umep website can be edited by user gqf produces q f estimates at higher spatial resolution and 30 min time steps but requires comprehensive input data table a2 2 to support this the shift in population distribution during working days is captured using residential and workday population datasets with morning and evening transition periods road transport emissions are calculated using a vector map containing every road link along with the road class label and traffic flow broken down by vehicle type maps of residential and non residential gas and electricity consumption across the city are used to estimate building emissions the model therefore sub divides q f t by vehicle type and q f b by fuel and consumer and estimates the spatial distribution of transport emissions independently of the population distribution model spatial resolution is dictated by the input residential and workday population datasets with the annual energy consumption data disaggregated to common spatial units based on population day to day variations in building energy consumption and hence q f b are captured using empirical demand data from utility companies and half hourly variations are obtained from week long diurnal profiles with separate profiles specified for each energy consumption category temporal variations in transport are governed by a week long diurnal profile for each vehicle type in which some days have greater mean values than others to reflect day to day traffic variations this segmentation means the temporal evolution of each q f component in a modelled area depends on the balance of vehicle types energy consumers and the residential to workday population ratio gqf also partitions q f t q f b and metabolism q f m into sensible latent and for buildings wastewater fractions these can be included or excluded from the modelled q f at model run time table a2 2 input data sources required by the gqf model table a2 2 data source type remarks residential population count polygon shapefile used for metabolism estimates and to spatially disaggregate energy consumption data to common spatial units workday population count polygon shapefile road network and traffic flow line shapefile each road segment with road classification and annual average daily total traffic for each vehicle type residential energy consumption residential electricityresidential gasresidential economy 7 shapefiles spatially disaggregated using residential population non residential energy consumption non residential electricitynon residential gasnon residential other shapefiles kwh per year spatially resolved within cityspatially disaggregated using workday population daily energy consumption time seriesgaselectricity csv file relative variations used to scale annual to daily values applied to both residential and non residential sectors vehicle diurnal profiles csv file time series for each vehicle type building energy diurnal profiles csv file time series for energy consumption dataset metabolic diurnal profiles csv file time series defining metabolic rate per person and transition between workday and residential population vehicle fuel efficiencies csv file amount of fuel consumed per vehicle class and fuel type 
