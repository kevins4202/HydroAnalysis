index,text
495,in large scale heterogeneous aquifer simulations determining the appropriate coarsening scale λ to define an effective hydraulic conductivity keff is a challenging task that involves a trade off between accuracy and cost efficiently adjusting the scale λ is then key in particular for uncertainty quantification in this paper we obtain improved analytical results for the variance of keff valid at any scale in the context of energy dissipation formulation using this formulation we then derive an efficient keff numerical estimator and compare it with those of the potential flow average and permeameter formulations in 2d for lognormal and binary media over a wide range of λ and of heterogeneity we analyze the probability density function pdf mean and variance of these estimators comparing them with the analytical results in the lognormal case the pdf s are rather similar for the three estimators and remain lognormal at all scales in the binary case slow convergence to an asymptotic regime is observed close to the percolation threshold graphical abstract image graphical abstract keywords heterogeneous aquifers stochastic approach volume averaging upscaling 1 introduction describing effective properties of heterogeneous media has important applications in many fields of engineering and science for example the electrical or thermal effective conductivity of mixtures or elastic properties of composites materials have been studied since many years ago maxwell 1873 bruggeman 1935 landau and lifshitz 1960 auriault 1983 willot and jeulin 2009 zhou et al 2016 in particular determining an effective hydraulic conductivity is of major interest in a variety of disciplines related to subsurface flow such as groundwater flow characterization renard and de marsily 1997 matheron 1967 dagan 1989 dagan et al 2013 carbon capture utilisation and storage ccus development akber hassan and jiang 2012 celia et al 2015 and oil and gas reservoir engineering king 1989 durlofsky 1991 1992 preux 2016 malinouskaya et al 2018 the scarcity of field data matheron 1967 dagan 1989 hristopulos 2020 makes it necessary to perform some sort of interpolation with frequent use of a stochastic approach gelhar 1993 linde et al 2015 godoy et al 2018 that treats the point conductivity values as a random process eventually accompanied by field data conditioning while the use of this approach permits a good management of uncertainty it turns too costly to solve the flow at the fine scale provided by laboratory microtomography synchrotron or geological sources dagan et al 2013 specially for large domains in addition one may want to incorporate data obtained at different support scales before interpolation to alleviate this issues upscaling procedures allow us to perform a mapping from a fine scale onto a coarse scale in which the solution of the flow is less costly fig 1 shows the lengthscales and geometrical features of the upscaling process the fine scale conductivity k r r is the position vector is defined over the regional domain ω ℜ d dimension d 1 2 or 3 at a support scale δ the coarsening scale λ determines a domain ϑ over which the effective hydraulic conductivity keff is defined one the one hand for practical and conceptual purposes we can establish an upper bound l for λ determined by the largest subdomain ω over which it is still possible to solve the flow eventually imposing boundary conditions at ω if natural flow conditions are unknown for example l could be a characteristic aquifer scale on the other hand a lower bound for λ is given by the support scale δ the effective conductivity of a block or subdomain ϑ defined by the coarsening scale λ i e keff λ depends on the values of k r within ϑ but also on the conditions at the boundary ϑ which may be imposed or known moreover keff λ is a tensor in principle however for isotropic media and certain flow conditions sánchez vila et al 1995 vereecken et al 2007 the use of a scalar keff is appropriate finding a suitable coarsening scale λ requires dealing with a trade off between accuracy and cost as λ increases the cost to solve the flow decreases but some details of the heterogeneity and of the flow get lost and the values of keff become less representative of the fine description the choice of a scale λ that retains the most salient flow features while keeping the cost of the flow solution low makes upscaling a challenging task in the following section we revisit briefly some upscaling results with focus on the types of media studied in most works including the present one i e lognormal and binary media to later discuss keff distributions and some upscaling formulations 1 1 previous results analytical methods like bounds based approaches hashin and shtrikman 1962 renard and de marsily 1997 le loc h 1987 pozdniakov and tsang 2004 or power averaging journel et al 1986 desbarats and srivastava 1991 masihi et al 2016 provide a remarkable insight although as they estimate keff from the point values k r only they disregard the influence of the flow behavior at ω depending on the detailed context homogenization techniques auriault 1983 durlofsky 1991 jikov et al 2012 armstrong et al 2019 volume averaging techniques hassanizadeh and gray 1979 quintard and whitaker 1998 durlofsky 1998 whitaker 2013 gray and miller 2005 leung and srinivasan 2012 wood and valdés parada 2013 davit and quintard 2017 aguilar madera et al 2019 or stochastic perturbation theory landau and lifshitz 1960 matheron 1967 dagan 1989 king 1989 rubin and gómez hernández 1990 indelman and dagan 1993a 1993b noetinger 1994 indelman and abramovich 1994 ababou 1994 abramovich and indelman 1995 noetinger and gautier 1998 noetinger 2000 liao et al 2019 were developed over many decades all these methods provide a rigorous analytical framework supporting the existence and uniqueness of keff for a wide variety of media types analytical efforts took place mainly using perturbation theory gelhar 1993 dagan 1989 the so called landau lifschitz matheron llm landau and lifshitz 1960 matheron 1967 formula reads 1 k eff k 1 2 d 1 1 2 d in the case of a lognormal distribution of fine scale conductivity this formula can be written under the equivalent form king 1989 noetinger 1994 k eff exp log k e 1 2 1 d c log k r 0 k g e 1 2 1 d c log k r 0 the notation indicates ensemble arithmetic averaging over all the possible realizations of the fine scale structure kg denotes the geometric mean of the fine grid conductivity and c log k r 0 the variance of its logarithm in this work wherever the expressions log k or log keff are shown it is implied that the argument of the logarithm is divided by 1 m day to make it dimensionless in most cases an ergodicity assumption allows to replace the ensemble average by a spatial average ababou 1996 sanchez vila et al 2006 such that for finite block of size l one estimates keff as 2 k eff b l o c k 1 v b l o c k k r 1 2 d d d r 1 1 2 d this formula with dimension d 1 2 3 whose evaluation is straightforward is exact in 1d for any type of media yielding the harmonic average in 2d it corresponds to the geometric average that was found to be exact in 2d for lognormal media by matheron 1967 who derived it using an elegant duality argument specific to 2 dimensions in 3d the formula is exact up to second order dagan 1993 with respect to log conductivity variance using a series expansion of keff up to 4th order in powers of the log conductivity fluctuations but in 3d the proposed formula was shown to be inexact at third order by several authors indelman and abramovich 1994 de wit 1995 stepanyants and teodorovich 2003 moreover higher order results were shown to be structure dependent this prevents the existence of a local evaluation expression like eq 1 in 3d however numerical tests carried out show that llm formula is quite robust in 3d even for large log conductivity variances dagan 1989 romeu and noetinger 1995 renard and de marsily 1997 some generalization of such approaches for anisotropic cases were revisited recently by liao et al 2019 from a more geological point of view a frequent organization of the subsurface heterogeneous formations in a number of hydrofacies that correspond to different types of rock or sediments having a well defined hydraulic property such as porosity or permeability may be observed in natural systems journel et al 1986 beucher and renard 2016 each facies possesses its own characteristic features that promoted the study of the effective conductivity of composite media binary or bimodal media are the simplest cases while still retaining the complexity of percolative systems these types of media have been extensively studied using self consistent effective medium approaches in the electrodynamical or elasticity contexts maxwell 1873 bruggeman 1935 landau and lifshitz 1960 auriault 1983 pozdniakov and tsang 2004 analytical results based on a mixing of characteristic conductivity values and bounds hashin and shtrikman 1962 1963 exist for this type of media bernabé et al 2004 in them connectivity is implicitly taken into account other authors pozdniakov and tsang 2004 knudby and carrera 2005 guin and ritzi 2008 bernabé et al 2016 studied numerically the influence of the contrast between the high and low conductivity components k and k the abrupt change in keff that takes place close to the percolation transition when the k component becomes connected poses difficulties during the upscaling procedure boschan and noetinger 2012 indeed percolation theory scaling berkowitz and balberg 1993 stauffer and aharony 2014 hunt et al 2014 hunt and sahimi 2017 has been used to assess keff in this type of media but some restrictions exist this scaling is only valid for media in which the proportion of high conductivity medium is close to the percolation transition percolation transition is smeared out by finite size effects and finite conductivity contrast values 1 2 keff probability distributions due to the fact that subsurface uncertainty is frequently dealt with by using a stochastic approach it is appropriate to treat keff as a random variable characterized by a probability distribution more than by a deterministic value although the literature mainly focuses on the firsts moments of the probability density function pdf such as the mean and variance rubin and gómez hernández 1990 sánchez vila et al 1995 sanchez vila et al 2006 the shape of the pdf provides unique insight on the underlying flow situation for example in media samples near percolation a bimodal pdf may yield a mean keff value that truly has a negligible occurrence probability this situation may easily arise when dealing with fractured media or in general with media possessing a high degree of heterogeneity the pdf of keff depends on the coarsening scale λ and will be noted p keff λ for clarity p keff λ undergoes a transition from p k r δ to p keff l as λ goes from δ to l for λ δ the distribution of k r is recovered while for λ l p keff λ will tend toward a delta like distribution sharply peaked around a stable keff value see fig 2 if it is possible to define a characteristic lengthscale for example an integral scale i for the media under consideration a crossover is expected when λ approaches it more conceptually a representative elementary volume rev may be determined by inspecting significant changes of the shape of p keff λ the fact that the statistical sampling becomes poorer as λ increases can be compensated in the framework of the stochastic theory and assuming ergodicity by an increase in the number of ensemble realizations the behavior of p keff λ was addressed in several studies king 1989 sanchez vila et al 2006 wen and gómez hernández 1996 wu et al 2013 in boschan and noetinger 2012 the convergence of p keff λ was studied in 3d for lognormal and binary media in the lognormal case p keff λ kept its lognormal nature as λ increased if this result hold in 2d this will be analyzed in the present work it might stem from the work of matheron 1967 in the binary case it was shown that the convergence to a stable keff is slower when the k component is close to the percolation transition stauffer and aharony 2014 finally under the ergodic hypothesis several studies assessed the use of filtering techniques to derive p keff λ at all scales king 1989 noetinger and gautier 1998 noetinger 2000 noetinger and zargar 2004 attinger 2003 eberhard et al 2004 1 3 upscaling formulations and numerical implementations the fact that analytical results are limited to some academic cases and strictly valid only up to second order in 3d imposes the use of numerical techniques to obtain keff as well as its distribution by means of monte carlo simulations several numerical techniques were developed using different approaches and provide accurate solutions desbarats and srivastava 1991 durlofsky 1991 desbarats 1992 quintard and whitaker 1998 wang et al 2014 zheng et al 2017 wang et al 2018 the numerical implementations calculate a value keff in ϑ from the fine conductivity field k r and from the boundary conditions at ϑ in what constitutes a numerical solution of the closure problem posed by the associated laplace equation moreover some of them use border regions including information of the outer neighbourhood of ϑ wen et al 2003 two aspects of the solution of the closure problem by numerical simulations stand out 1 the task of finding the optimal scale λ in each flow scenario makes upscaling a multiscale problem par excellence 2 the choice of the formulation in particular that of the boundary conditions strongly affects accuracy and numerical efficiency for example imposing boundary conditions at ϑ decouples the flow in ϑ from its outer region in a rather invasive procedure in view of item 1 in that sense solving the flow in ω once and then employing this solution to estimate p keff λ i e seems less invasive and more efficient but requires the ability to solve larger systems of equations from the existing upscaling formulations the most widely used is the permeameter darcian one which as a particularity isolates the flow in ϑ suffering from the drawback explained above this formulation and its implementation will be formally introduced in section 2 2 another frequent formulation rubin and gómez hernández 1990 and sánchez vila et al 1995 uses the solution of potential and the associated flow in ω evaluating their averages over ϑ to obtain keff in order to obtain a scalar keff some assumption is required finally indelman and dagan 1993a b bøe 1994 proposed that keff could be defined by assuming that the dissipated energy is conserved during the upscaling procedure this might be the strongest conceptual definition ever formulated however its implementation to obtain keff is mathematically difficult aiming to reduce the computational cost a number of approaches that combine different formulations were proposed chen et al 2003 bauer et al 2008 wu et al 2013 karimi fard and durlofsky 2016 with the support of ergodicity considerations ababou et al 1989 ababou 1994 1996 desbarats and srivastava 1991 1 4 objectives in this paper we intend to explore analytically and numerically the multiscale nature of the upscaling procedure in the context of the different formulations in 2d on the one hand after reviewing the existing body of literature we update the formulae introduced in previous studies to characterize the mean and variance of keff valid at the scale ω at which the boundary conditions are imposed we derive in the context of the energy dissipation formulation a new expression for the variance this time valid at any subscale ϑ ω up to second order in perturbation theory on the other hand using that formulation we define and implement a new numerical estimator of keff based on a scalar energy dissipation average this estimator can be obtained at any subscale λ with nearly negligible additional cpu time once the potential in ω is solved aiming to provide a comprehensive view the pdf the mean and the variance of this estimator are compared with those of the potential flow average estimator and of the permeameter darcian one over a wide range of coarsening scales this study is performed over lognormal media samples with a wide range of fine grid variances and over binary media samples spanning the percolation transition the paper is organized as follows we start by presenting the overall geometry and notation considering a steady state darcian flow in an heterogeneous porous medium and perform some algebraic manipulation to express keff in terms of the viscous dissipation we introduce then section 3 1 a useful variational derivation that allows us to define keff in terms of a minimization of that dissipation by using functional expansion techniques already developed in a previous study noetinger 2013 we provide expressions for the variance of keff in ω up to second order in the perturbation expansion valid for small variances later improving it for higher variances by using a mean field approximation after some more manipulation we get in position to show how these results are valid at any subscale i e the coarsening scale λ even if the variational formulation cannot be applied at any scale smaller than ω the scale in which the boundary conditions are imposed the result depends also on the covariance of k r and on λ while it is possible to apply again the mean field technique now at this scale to improve it section 6 introduces the numerical methodology with the implementation of the three formulations while section 7 presents firstly a numerical validation and then the results regarding the multiscale dependence of keff under the different formulations 2 geometry driving equations and notations 2 1 geometry and local equations we focus our attention on a block ω to be upscaled in d dimensions a square in 2d or a cube in 3d the edges of that domain are of size l in the d directions as sketched in fig 1 the potential is driven by the following laplace equation to be solved in the domain ω 3 k r p r 0 the local potential is denoted by p r this equation is a combination of mass or charge conservation with a phenomenological equation relating the local flux to the local potential gradient such as joule darcy or fourier s law that may arise after a proper averaging of the sub scale transport processes hassanizadeh and gray 1979 in order to get a well defined problem dirichlet or dirichlet neumann conditions must be specified at the frontier ω of the domain these conditions will be discussed in the next section the local conductivity denoted by k r is assumed to be scalar and to depend on position r the conductivity field can be discontinuous with respect to r 2 2 classical darcian definition of the effective conductivity here we defer the discussion of the upscaling problem to references in matheron 1967 durlofsky 1991 neuman and orr 1993 renard and de marsily 1997 quintard and whitaker 1998 willot and jeulin 2009 jikov et al 2012 the effective conductivity can be defined using the solution of the laplace eq 3 to be solved with dirichlet boundary conditions at the inlet outlet denoted by pin and pout neumann no flux boundaries are imposed on the faces of the domain parallel to the average imposed flow which will be the x direction in the rest of the paper this definition of keff is the so called permeameter definition that will be sometimes denoted by kperm this corresponds physically to the basic conductivity measurement that could be performed at the laboratory both in the darcy or electrical context other boundary conditions such as periodic auriault 1983 durlofsky 1991 quintard and whitaker 1998 noetinger 2013 can be chosen but that does not change drastically the analysis so permeameter conditions will be kept throughout the paper by identification with the homogeneous case effective hydraulic conductivity is given by 4 k eff q l d 2 p i n p o u t here q denotes the total fluid flux flowing in any section of the domain perpendicular to the mean flow x direction 5 q i n l e t f a c e d d 1 r k r p r n here p r is the unique solution of the boundary value laplace eq 3 with the permeameter forcing boundary conditions 3 effective conductivity and viscous dissipation for our purpose it is useful to introduce an equivalent algebraic expression of keff that was introduced in the porous media context by jacquard 1965 matheron 1967 and revisited later by wen and gómez hernández 1996 sánchez vila et al 1995 6 q p i n p o u t ω d d 1 r p r k r p r n ω d d r k r p r p r in order to begin with the first equality of eq 6 is obtained by expressing q in terms of integrals over the inlet and outlet faces of the domain as in eq 5 in the outlet according to the convention defining positive flow opposite to the face inward normal the expression have the opposite sign then both face pressures are moved under the integral signs obtaining similar expressions regarding the neumann boundary conditions on lateral faces imposing no pressure gradient both integrals can be combined in only one over the whole domain boundary ω using the divergence theorem combined with laplace eq 3 yields the second equality this equation has a simple physical interpretation the rhs corresponds to the total viscous dissipated power that must coincide with the power spent by external forcing sources set up to create the flow so the effective conductivity may be expressed as 7 k eff 1 p i n p o u t 2 l d 2 ω d d r k r p r 2 1 p ω x 2 l d ω d d r k r p r 2 where p ω x p i n p o u t l is the volume averaged gradient in the x direction which is the mean flow direction the average potential gradient p ω over the block volume ω l d is given by 8 p ω 1 ω ω d d r p r 1 ω ω d d 1 r p r n in the case of a square or cubic ω the retained boundary conditions for potential p give the proposed equality in the x direction eq 7 relates the effective conductivity of the whole block keff to the overall viscous dissipation and the mean forcing potential gradient norm in the imposed flow direction it will be the starting point to define a dissipation based effective conductivity estimator in section 5 1 3 1 a variational characterization of keff we are now in position to propose an alternative formulation that proves to be useful for estimating the sensitivity of large scale parameters to variations of local conductivity this variational characterization of keff may be formulated as follows 9 k eff p i n p o u t 2 l d 2 q p i n p o u t k eff p ω x 2 l d m i n p r θ p r ω d d r k r p r 2 here the potential fields p r among which the minimization is to be performed fulfill the boundary conditions at ω the justification of eq 9 is classical one has to express the extremal conditions r δ θ p r δ p r k r p r 0 the operator δ θ p r δ p r is a functional derivative of the functional θ p r with respect to p r a basic presentation of functional differentiation is given in appendix a using thus the particular quadratic form of θ p r these extremal conditions give rise to laplace eq 3 that governs the potential the final result may be derived using the same methods than eq 6 3 2 functional expansion techniques for the effective conductivity functional techniques combined with the variational formulation are useful to derive directly second order perturbation expansion of the effective conductivity and of its associated variance the starting point is to evaluate the sensitivity of effective conductivity with respect to local perturbations of the local conductivity as it was derived in noetinger 2013 and appendix a the starting point is to decompose the local hydraulic conductivity as k r k δ k r the brackets correspond to ensemble averaging over the conductivity realizations to be not confused with volume averaging denoted by so δ k r 0 one can use the formal equivalent of taylor series formula up to second order also valid for functionals 10 k eff k ω d d r δ k eff δ k r δ k r 1 2 ω d d r ω d d r δ 2 k eff δ k r δ k r δ k r δ k r the reader must note that in these equations the functional derivative must be evaluated while the nominal value of the conductivity map is a uniform value k r k in usual function taylor s expansions this corresponds to the point at which the derivative is evaluated averaging eq 10 yields a second order expansion that coincides with llm conjecture up to this limited order a concise derivation using functional derivatives is given in appendix b 4 estimation of the variance of the effective conductivity at second order in this section we present expressions of the variance of the effective conductivity that are obtained in the context of second order perturbation theory the derivations are given in appendix c finally closed expressions are given for the cases when those expressions are particularized for gaussian covariance functions for the variance of the effective conductivity given by c k eff l k eff 2 k eff 2 k eff k eff 2 the following expression can be obtained eq c 4 11 c k eff l 1 ω 2 ω d d r d d r c k r r a mean field approximation allows to replace each occurrence of keff and k by the corresponding logarithm eq c 7 providing the following expression that can be expected to have a more extended domain of validity for practical applications 12 c log k eff l 1 ω 2 ω d d r d d r c log k r r the resulting formula is similar to eq 11 replacing the covariance function by the log conductivity covariance function for the special case of lognormal media this is a quite natural transformation the same can be done with the simplified formula c 5 in the case of the gaussian covariance with c k r c k r 0 e r 2 2 i c 2 where ic is the correlation length explicit analytical expressions can be derived for c k eff l from eq 11 see appenidx c 2 eq c 8 13 c k eff l c k r 0 i c l 2 d 2 π l i c erf 2 l i c 2 e l 2 2 i c 2 2 d likewise using the simplified eq c 5 one gets after integration eq c 9 14 c k eff l c k r 0 2 π i c l erf 2 2 l i c d the same calculations can be carried out for c log k eff l applying the logarithmic transformation and give analogous results using c log k r 0 and the same spatial dependence 5 a posteriori multiscale estimators of keff distributions in this section two estimators providing intermediate scale effective conductivity distributions are presented both are computed using low cost post processing of one up scaling closure problem at the largest available scale these distributions will be compared to reference distributions determined by computing numerically permeameter effective conductivity of every coarse block at any scale the resulting pdf s will be compared as well as the associated log conductivity mean and variance for completeness the latter will be compared with preceding analytical results 5 1 dissipation estimator 5 1 1 definition of the estimator we consider now that the upscaling laplace problem was solved on a single conductivity realization on the entire block ω the subscale effective conductivity kdiss ϑ on any given cubic or square sub block of size λ included in the overall domain ω can thus be defined as the relation between the dissipation and the average potential gradient at the block level by 15 k d i s s ϑ ϑ d d r k p 2 λ d p ϑ 2 it can be observed using eq 7 that if ϑ ω k d i s s ϑ k eff p x 2 p 2 k eff in the case of statistically isotropic k r if ω is sufficiently large the average potential gradient p y perpendicular to the mean flow vanishes so the effective conductivity determined by dissipation is equal to the usual definition kdiss ϑ ω keff considering the opposite limit ϑ 0 it can be shown using a taylor expansion of the potential gradient under the integral sign that k d i s s ϑ k r if and only if p 2 p 2 0 this last condition corresponds to stagnation no flow points this condition is not surprising as it can correspond to both infinite conductivity regions or to screened regions of vanishing hydraulic conductivity in both cases effective conductivity is not defined assuming that the set of these points is of vanishing measure in most cases the original detailed conductivity map must be recovered this criterion was already introduced and discussed by sánchez vila et al 1995 and bauer et al 2008 the proposed indicator fulfills two intuitive conditions for both extreme ϑ sizes in appendix d it is shown that the average of the dissipation estimator is in agreement with that derived for keff for volumes ϑ tending to ω and the structure of the finite size corrections is given too in next section 5 1 2 it is shown up to second order that the variance of kdiss ϑ coincides with expression 11 by replacing ω by ϑ as integration domain this implies that the evaluation of the variance c log k d i s s λ is obtained by replacing l by the length of the considered subscale block λ in eq 12 5 1 2 evaluation of the variance of block dissipation conductivity kdiss the block equivalent conductivity kdiss ϑ is given by eq 15 and its variance may be evaluated following the same steps that in appendix c it is defined by k d i s s ϑ 2 k d i s s ϑ 2 k d i s s ϑ k d i s s ϑ 2 so one gets finally k d i s s ϑ 2 k d i s s ϑ 2 ω d d r d d r δ k d i s s ϑ δ k r δ k d i s s ϑ δ k r δ k r δ k r note that at present stage the integration volume remains the whole volume ω it is not restricted to ϑ because keff ϑ depends on the entire conductivity map that is defined on the support ω in which the laplace equation is solved at the beginning we have to evaluate the functional derivative δ k d i s s ϑ δ k r the evaluation cannot be simplified because the variational principle that characterizes keff as defined in ω is not relevant at any smaller scale the derivative is given by δ k d i s s ϑ δ k r p 0 r 2 λ d p 0 2 1 ϑ r 2 λ d p 0 2 2 1 λ d p 0 2 ϑ d d r k p 0 r δ p r δ k r 1 λ d ϑ d d r k p 0 r 2 ϑ d d r p 0 r δ p r δ k r in that equation the first term involving the indicator function of ϑ denoted by 1 ϑ r is the remaining of the result that would be provided using the variational approach as shown in appendix c eq c 1 the first integral arises from the derivative of p 2 under the integral sign the second corresponds to the functional derivative of 1 p 2 both terms are equal to 0 if ϑ ω at lowest order the spatial dependence of the conductivity k must be discarded it appears that the second line involving twice integration vanishes because p 0 r e x is constant up to this order so both terms cancel each other so we obtain the same result that would be provided by the variational approach if it was applicable for block dissipation δ k d i s s ϑ δ k r p 0 r 2 λ d p 2 1 ϑ r gathering all the preceding results we obtain the following formula for the variance of the dissipation estimator at scale ϑ 16 k d i s s ϑ 2 k d i s s ϑ 2 1 ϑ 2 ϑ d d r d d r c k r r up to second order this formula is analogous to the variance in eq c 3 of the full up scaled hydraulic conductivity keff the corresponding formulation using logarithms is similar at this order this result allows to extend the validity of eqs 11 and 12 to subscale blocks ϑ 5 2 block average conductivity estimator another keff estimator on subvolume ϑ can be introduced defined as k a v e ϑ q x λ d 1 p x this expression is based on darcy equation where q is the flow rate and p the potential gradient both volume averaged over domain ϑ of size λ this estimator was studied by rubin and gómez hernández 1990 sánchez vila et al 1995 renard and de marsily 1997 bauer et al 2008 in particular using a second order expansion rubin and gómez hernández 1990 computed the average and variance of log kave ϑ as a function of ϑ and the input covariance function of the conductivity that correspond to the observed statistical parameters observed at scale l they give the following expressions log k a v e ϑ log k g 1 2 1 d 1 α c log k r 0 log k a v e ϑ log k a v e ϑ 2 α c log k r 0 the normalized variance correction factor α given by α 1 ϑ 2 ϑ d d r d d r c log k r r c log k r 0 depends only on the geometrical form of the covariance function and on the averaging volume ϑ size λ it can be observed that it shares the same form than the scale dependant variance 11 derived before it can be noticed that using directly llm formula for estimating keff for large size λ using these parameters eq 1 under its second form is recovered as terms involving α terms cancel this highlights some internal consistency of this estimator in practice once the potential is solved the evaluation of kdiss ϑ and kave ϑ is straightforward and of negligible extra computational cost for a given size λ one obtains a set of l λ d d 2 3 values of kdiss ϑ and kave ϑ that can be studied using statistical tools this will be the main topic of next sections 6 numerical methodology 6 1 generation of media samples we first compare the formulations over random lognormal media samples with low and high variance and then over binary media samples that have a high contrast of characteristic conductivities we employed a fast fourier transform fft moving average fft ma method le ravalec et al 2000 to generate these samples lognormal hydraulic conductivity fields with unitary geometric mean kg were generated gaussian covariance with an integral scale i 16 δ defined as the practical range of the covariance function i 3 i c was used to spatially correlate the samples fig 3 left shows as an example a realization of a lognormal medium obtained with this procedure all media samples generated have 1024 1024 cells with a linear size of 1024δ in order to reduce the numerical truncation error when computing the potential field a refining stage of degree 4 was performed romeu and noetinger 1995 liu and wang 2013 resulting in a grid of 4096 4096 computational cells of linear size δ 4 binary random media is generated as follows we start by generating a lognormal one with an arbitrary geometric mean kg and variance σ log k 2 then this lognormal distribution is binarized using a threshold value kt assigning each cell a characteristic k high conductivity or k low conductivity value with k k 10 4 the value of kt controls the relative population p of high conductivity cells three values of p were studied one at the 2d percolation threshold p c 0 5 one smaller p 0 4 and one greater p 0 6 than pc at pc 50 of the realizations percolate we used connect3d software pardo igúzquiza and dowd 2003 to explicitely verify the percolation condition the spatial correlation function of the resulting binary medium remains gaussian in turn the integral scale of the binary medium is determined by the integral scale of the original lognormal medium but also by p to be able to use the former as an input parameter we ve performed an iterative search for each of the values of p studied fig 3 right shows as an example a realization of such a binary medium for each set of parameters we generated 50 samples in order to obtain an acceptable statistical sampling at largest scale l 6 2 potential field calculation for the kave and kdiss formulations it is only required to solve the potential in ω once and then post processing of the obtained field is performed to obtain keff at any scale λ for the kperm formulation the potential must be solved independently for all the sub domains ϑ under study to obtain the potential field we used modflow 2005 1 1 https water usgs gov ogw modflow mf2005 html software harbaugh 2005 with the corresponding boundary conditions this solver uses the finite difference method with a classical 2 d 1 point stencil particularly the block centered flow package bcf6 was used and the linear equation system was solved with the preconditioned conjugate gradient package pcg 6 3 implementation of the permeameter scheme we used classical permeameter boundary conditions in the computation of the potential fields in modflow these boundary conditions are applied assigning constant potentials dirichlet type to two opposite cell layers each of them representing a domain face a unitary potential difference δp between them is set all other faces are constrained by no flow boundary conditions neumann type applied to ghost cell layers outside the domain these boundary conditions are applied at ϑ to compute kperm defined as 17 k p e r m q λ δ p the integral of the flow q is calculated at the inlet or the outlet face of the block ϑ with permeameter boundary conditions for each medium kperm was computed for the whole set of subscales λ 2 n with integer n between 1 and 10 resulting in l λ 2 2 2 10 n values at each subscale the same procedure was followed for the other two estimators 6 4 implementation of the dissipation scheme based on the resulting potential field computed using modflow with permeameter boundary conditions sections 6 2 and 6 3 on domain ω and the theoretical development presented in section 5 1 the dissipation based block estimator computation is as follows as the finite difference scheme adopted in modflow is cell centered after solving the potential field in ω both the hydraulic conductivity k i j and potential p i j at each cell center are known notations are referred to cell i j of ϑ where i 1 j i 1 j i j 1 and i j 1 are the left right top and bottom neighbouring cells respectively using an electrical analogy the local cell dissipation can be computed as 18 ϵ i j ϑ i j d 2 r k i j p 2 2 k i j p i 1 2 j p i j 2 p i 1 2 j p i j 2 p i j 1 2 p i j 2 p i j 1 2 p i j 2 the factor 2k i j corresponds to the conductivity of the half bond between the center and any face of ϑ i j the potential subscript with minus or plus halves refer to cell face potentials computed invoking the equality of flux at both sides of the face for example the potential on the left face of cell i j is given by p i 1 2 j k i j p i j k i 1 j p i 1 j k i j k i 1 j the other cell face potentials are defined analogously using equivalent equations to eliminate face potentials in eq 18 we get ϵ i j 1 2 k i j t i 1 2 j p i 1 j p i j 2 t i 1 2 j p i 1 j p i j 2 t i j 1 2 p i j 1 p i j 2 t i j 1 2 p i j 1 p i j 2 the coefficients t are the usual intercell harmonic averages given by t i 1 2 j 2 k i 1 j k i j k i 1 j k i j and t i j 1 2 2 k i j 1 k i j k i j 1 k i j ohm s law for dissipation can be recognized through the squares of the fluxes flowing through the faces the cell face potentials are also used to compute the cell potential gradient as p i j t p i 1 2 j p i 1 2 j δ p i j 1 2 p i j 1 2 δ thus the averaged potential gradient of the block is p i j p i j n i n j with ni nj the number of cells in each direction inside the block in every case the sum runs over all the fine grid blocks included in ϑ finally the block dissipation based estimator of eq 15 for block ϑ is computed as 19 k d i s s ϑ i j ϵ i j λ 2 p 2 fig 4 presents the resulting dissipation maps for lognormal and binary media samples a strong localization channeling effect may be noticed close to percolation threshold for the binary case 6 5 implementation of the block average conductivity scheme based on the computation of the potential field in ω the second keff estimator can be defined in ϑ as 20 k a v e q x λ p x this expression is based on a large scale darcy equation where q is the flow rate and p the potential gradient both averaged over the domain ϑ of size λ with the proper boundary conditions it is possible to recover the full hydraulic conductivity tensor bauer et al 2008 in this study we only considered the direction of the imposed potential difference δp 7 results we begin this section by comparing as a form of validation the outcomes of the analytical developments of section 4 for lognormal media with the corresponding numerical results using the well known kperm estimator then for both type of media we study the scale dependence of the pdf of the three proposed estimators to later focus on the first two gaussian moments i e mean and variance for this latter case a comparison with the mean field analytical variance of keff eq 13 is performed the common parameters and values used in the simulations are presented in table 1 7 1 comparison of the different analytical expressions for c k eff λ with numerical results fig 5 shows the variance of keff given by eqs 13 and 14 and their equivalent expressions within the mean field approximation compared with the kperm estimator as a function of the coarsening scale λ that varies between fine grid scale δ and l a low σ log k 2 0 1 and a high σ log k 2 7 fine grid variance are used as extreme cases the analytical results are in good agreement with the numerical simulations for σ log k 2 0 1 when using the expressions based on the conductivity variance σ k eff 2 eqs 13 and 14 the difference increases for the case of σ log k 2 7 specially for scales equal or greater than the integral scale defined as the practical range of the covariance function the estimation of the variance of the logarithm σ log k eff 2 appendix c 1 provides a better agreement with the numerical results even for σ log k 2 7 in this case the analytical equations correctly capture the tendency as the scale increases with small discrepancy from the numerical results beyond the integral scale in both cases the simplified formulas eq 14 coincide to a large extent with the complete ones except at the scales close to the integral scale where a small difference appears in view of these observations comparison against analytical results in the next sections will be only carried out with respect to eq 13 using the mean field approximation 7 2 lognormal media 7 2 1 probability density function of the different estimators pdf s of kdiss kave and kperm are plotted in fig 6 left for σ log k 2 7 although kdiss and kave present a sharper pdf they are rather similar the dependence of the pdf of kdiss with the coarsening scale λ is shown in fig 6 right it can be observed that the pdf remain gaussian at all scales as a gaussian pdf is fully described by its mean and variance in the following subsection we focus our attention on these two moments 7 2 2 scale dependence of the mean and variance of keff fig 7 compares the values of the geometric mean of keff indicated by left and the variance σ log k eff 2 scaled by λ i 2 see appendix c right for the three estimators as λ tends to δ keff approaches to the fine scale mean kg for both variances for σ log k 2 0 1 the three formulations yield very similar results while for σ log k 2 7 some discrepancies are observed moreover for λ close to i a depart from the theoretical value of upto 12 is observed for kdiss we recall that as developed in section 5 1 1 if ϑ ω the potential gradients transverse to the mean flow vanish due to the boundary conditions applied at that scale in all cases but if ϑ ω these gradients may exist and be non negligible also they are stronger as the heterogeneity increases explaining the slump in kdiss for λ close to i the variances of keff were evaluated analytically using the mean field approximation of eq 13 in fig 7 right the variances of the three estimators show an excellent agreement with the analytical results for σ log k 2 0 1 while for σ log k 2 7 a slight difference for λ i is observed for the three estimators probably due to discretization effects romeu and noetinger 1995 7 3 binary media 7 3 1 probability density functions of the keff estimators in binary media the lower limiting case is when the upscaling scale λ tends to the fine grid scale δ with only two possible conductivity values k with probability p and k with probability 1 p consequently the pdf of the effective conductivity tends to a two peaked distribution with relative heights given by p and 1 p and its mean is similar to that of the original medium at the fine grid scale on the other hand the upper limit correspond to the upscaling scale reaching the domain scale l in this case the pdf of the effective conductivity looks more like a unimodal distribution with its mean approaching k when p pc and k when p pc at intermediate scales a transition between both extreme behaviors occurs pdf s of kdiss kave and kperm are plotted in fig 8 in order to compare them with the expected behavior three situations with p smaller close to and greater than p c 0 5 for which percolation transition occurs are shown in this figure in the left column of the figure the three methods are compared for λ 32 δ at this intermediate scale different behaviors are observed depending on the method the pdf s of the three estimators considered here exhibit some differences the kperm estimator presents more peaked distributions with two clearly separated modes while those of global methods kdiss and kave are relatively more homogeneous with a continuous variation between the peaks also the values of conductivity corresponding to the facies that does not percolate are only retained in the case of kperm while kdiss and kave smooth them out this is a direct effect of the permeameter boundary conditions that are imposed for each sub domain ϑ when computing kperm this renders percolation in ϑ much more critical for keff on the other hand analyzing the behavior when small middle and large scales are adopted for λ the expected behavior is recovered kdiss converges to an unimodal distribution as λ increases faster as p departs from pc as it was observed in a previous study for kperm boschan and noetinger 2012 in addition as p departs from pc for a given λ the distributions become narrower this implies that the convergence to a representative mean is slower near percolation 7 3 2 scale dependence of the mean and variance of keff in the binary case as it is clearly seen in fig 8 the pdf s of keff are far from being unimodal and then the mean and variance become less representative of the pdf compared with the lognormal case cf section 7 2 1 for example one may note that in panel c of fig 8 the mean would not be particularly representative however previous studies analyzed the mean and variance much more frequently than the complete pdf so we consider interesting to present them for comparison fig 9 shows the variation of geometric mean of keff left and of the variance σ log k eff 2 right for the three estimators as a function of λ for p 0 4 p 0 5 and p 0 6 the values of keff coincide as λ tends to the limiting δ or l for all the values of p the behavior at both limits of the range corresponds to which is expected for a representative effective conductivity furthermore the behavior far from those extreme values is strongly dependent on the particular estimator as observed in fig 8 the two peaks in the kperm histogram remained clearly identifiable at larger λ values in opposition to what happened in the cases of kdiss or kave the outcome is that if p is far from pc kperm converges more slowly than kdiss or kave to the asymptotic value of λ l this is consistent with the faster homogenization shown by the global estimators in the pdf s of section 7 3 1 comparing kdiss and kave the former shows a slight bias to lower keff values the variance σ log k eff 2 computed using the three formulations also coincides as λ tends to δ or l at intermediate scales kperm always yields the highest σ log k eff 2 in agreement with the findings shown in section 7 3 1 where it was shown that the pdf remained bimodal for a greater λ than for the other two methods note that in the non percolating case p 0 4 kdiss produces lower variances than kave while the opposite happens for the percolating case p 0 6 and at p c 0 5 both estimators yield similar values of σ log k eff 2 8 summary discussion and perspectives after introducing an efficient keff estimator based on energy dissipation we revisited numerically and analytically three of the most important upscaling formulations analyzing the scale dependence of the resulting keff distributions for 2d lognormal media keff distributions remain lognormal at intermediate coarsening scales for all the formulations a result that could be theoretically related to the llm formula landau and lifshitz 1960 matheron 1967 the numerical results for keff and σ log k eff 2 are in agreement with the analytical ones this is notable for intermediate coarsening scales having in mind that these last results are not exact in particular the asymptotic behavior of σ log k eff 2 for λ i varying as 1 λ 2 is reminiscent to a central limit theorem in the binary case for p far from pc the pdf of keff evolves from a bimodal to a unimodal distribution with representative mean and variance the mean and variance of the three estimators converge to the same asymptotic keff values for p 0 4 or 0 6 it can be observed that the latter obeys the scaling law with 1 λ 2 in that case close to percolation threshold pc the intermediate scale keff distributions do not exhibit convergence to an asymptotic stable distribution the keff remains close to the fine grid geometric mean kg this may be explained by the fact that in 2d at 0 5 p c the analytical result of matheron 1967 can be applied yielding the geometric average in that very specific case looking more carefully to fig 9 for p p c σ log k eff 2 does not follow the scaling law in 1 λ 2 this should be related to the absence of a representative elementary volume berkowitz and balberg 1993 hunt et al 2014 stauffer and aharony 2014 quantification of such effects remains to be studied and keff estimators that comply to finite size scaling arguments might improve the existing description the computation of keff through kave and kdiss is much more efficient than using kperm because in this case the potential is solved once for ω and then by post treating this solution keff can be obtained at all scales if a multiscale description is required while providing similar results using kperm involves solving the potential independently for each scale due to the strong influence of the boundary conditions imposed at ϑ now comparing kave and kdiss we illustrate the degree of discrepancy between these two estimators as a function of the coarsening scale showing in fig 10 the ratio between the geometric mean of kave and that of kdiss it can be observed that the greater discrepancy occurs both for lognormal and binary media for λ i where i is the practical range of the covariance function as measured in both types of media samples giving a characteristic lengthscale for heterogeneity note that kdiss see section 5 1 is sensible to transverse potential gradients while kave isn t because it assumes a colinearity between potential gradient and flow these transverse potential gradients vanish at λ δ and at λ l while they have a maximum in between at a critical lengthscale despite that media samples are statistically isotropic the degree of discrepancy is then probably driven by the scale dependence of these transverse potential gradients except for the lognormal case of σ log k 2 0 1 kdiss is smaller than kave up to 12 in the lognormal case of σ log k 2 7 and up to 80 in the binary case the bias of kdiss towards lower values was also observed in the pdf s shown in the sections 7 2 1 and 7 3 1 the 3d generalization of this work is currently under development in particular the appearance of an attractive conductivity distribution for the different formulations playing in 3d an analogous role to the lognormal distribution in 2d is of central interest moreover for binary media it is highly interesting to assess the slower convergence to an homogeneous keff distribution close to the percolation transition in 3d media in the context of the different formulations more realistic or complex distributions such as non gaussian or power law panzeri et al 2016 riva et al 2017 guadagnini et al 2018 will be addressed in future work a major practical issue regarding non homogeneous materials is to find some self contained estimation of the rev size allowing to determine for a given case if the rev size is reached that will help to find the optimal meshing size and to quantify uncertainty propagation credit authorship contribution statement iván colecchio conceptualization data curation formal analysis writing original draft alejandro boschan conceptualization data curation formal analysis writing original draft alejandro d otero conceptualization data curation formal analysis writing original draft benoît noetinger conceptualization data curation formal analysis writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to acknowledge the computational time from the tupac cluster made available by the csc conicet for conducting this research appendix a functional differentiation functional differentiation is a generalization of calculus to functionals i e functions having a function as argument our presentation is intuitive let f k be a functional that depends on the whole set of values of k which is an arbitrary function of position r ω the notation recalls that f is a functional examples of functional can be the value of field k at a given location r 0 f 0 k k r 0 the weighted average f f k 1 v v d d r f r k r in which f r is a fixed function that does not depend on k the functional derivative of a functional f k is defined by the following equation l i m ϵ 0 f k ϵ δ k f k ϵ v d d r δ f δ k r δ k r here δk is an arbitrary perturbation the functional derivative has a supplementary spatial argument that corresponds in the case of partial derivatives to the choice of the variable with respect to which the derivative is performed in the examples of f 0 k and f f k one has δ f 0 δ k r δ r r 0 δ f f δ k r f r v it gives the sensibility of the variation of f with respect to a local variation of its argument k at position r nth order functional derivatives can be defined as well as a taylor formula replacing summations by integrations if f x is a standard differentiable real function one has the chain derivative formula δ f f δ k r d f d x f δ f δ k r if p r obeys a laplace equation such as k r p r 0 putting k r k δ k r one obtains k δ k r p r δ p r 0 denoting by δp r the first order variation of potential p r with respect to k r one obtains that δp r obeys the following equation valid at first order a 1 k δ p r δ k r p r as the unperturbed potential p r fulfills the boundary conditions at the domain boundary δ p r 0 on dirichlet boundaries and same conditions for the normal flux at the neumann boundaries this equation has the formal solution a 2 δ p r v d d r g k r r δ k r p 0 r here gk r r is the green s function of the laplace operator that obeys the following equations to be supplemented by consistent boundary conditions k g k r r δ r r g k r x 0 1 r 0 y g k r y 0 1 r 0 so one gets finally after one integration by parts a 3 δ p r δ k r r g k r r p 0 r this result may recovered directly applying the operator δ δ k r at both sides of eq 3 providing k δ p r δ k r δ r r p r which is equivalent to eq a 3 note that the base conductivity field k may also depend on position or be equal to k the choice depends on the application at hand appendix b second order estimation of the average effective conductivity in order to illustrate the functional formalism we carry out with this tool the classical second order expansion of the effective conductivity dagan 1989 the taylor expansion eq 10 gives directly a second order series expansion that will provide the desired expansion after averaging b 1 k eff k 1 2 ω d d r d d r δ 2 k eff δ k r δ k r c k r r the main task is to evaluate explicitly the second order functional derivative that may be simplified in the following form using eq c 1 differentiated once more time δ 2 k eff δ k r δ k r 1 ω 2 p 0 r δ p r δ k r in that equation p 0 r is the non perturbed potential the derivative δ p r δ k r is given by eq a 2 so we get after substitution b 2 δ p r δ k r 1 k g r r p 0 r in that expression g r r is the green s function of laplace operator 2 this explains the factor 1 k note that due to the boundary conditions that break full translational invariance of the system this green s function does not depend only on the argument r r gathering these results in eq b 1 and using the fact that p 0 r e x one obtains b 3 k eff k 1 k ω ω d d r d d r p 0 r δ p r δ k r c k r r k 1 k ω ω d d r d d r r x r x g r r c k r r assuming that ω 1 d is large compared with the integral scale i one can replace g r r by the free space green s function g r r this is equivalent to estimate the green s function assuming that the boundary conditions are rejected at infinity using the correlation function isotropy the integral can be simplified using a classical trace argument yielding k eff k 1 k 1 d c k r 0 up to the same order of approximation this formula can be rewritten on a more usual form as k eff exp log k e 1 2 1 d c log k r 0 for log normal media this formula is equivalent to the llm conjecture eq 1 the second order expansion is thus recovered for large averaging volumes with a quite concise calculation appendix c second order estimation of the variance of the effective conductivity the variance of the effective conductivity is given by c k eff l k eff 2 k eff 2 k eff k eff 2 using the taylor expansion eq 10 and keeping only second order terms one gets dropping the averaging symbol under the integral sign a procedure that is straightforward within the stochastic context dagan 1989 gelhar 1993 hristopulos 2020 the procedure would be different using a volume averaging technique involving boundary of averaging volume corrections hassanizadeh and gray 1979 whitaker 2013 c k eff l ω d d r d d r δ k eff δ k r δ k eff δ k r δ k r δ k r the quantity δ k eff δ k r can be written under a simple form c 1 δ k eff δ k r p ω x 2 ω p r 2 derivation of eq c 1 is straightforward using the variational characterization eq 9 that can be differentiated directly with respect to δk r ignoring the implicit dependence of p r 2 with δk r that is known to vanish thanks to the variational characterization this eq c 1 relates the influence of a local hydraulic conductivity change on keff to the local potential gradient this result was already derived using similar methods by jacquard 1965 and generalized to obtain shape derivatives of effective conductivity with respect to geometrical shape of inclusions by noetinger 2013 one can remark that in a location where p r 0 the local conductivity has no influence at all on the large scale conductivity it is screened by other patterns that imply that there is no flow at this location this is a rather intuitive result thus using eq c 1 we obtain c 2 c k eff l 1 ω 2 ω d d r d d r p r 2 p ω x 2 p r 2 p ω x 2 δ k r δ k r as we are seeking a second order expansion of the variance of effective conductivity the local quantity p r 2 p ω x 2 resp p r 2 p ω x 2 may be replaced by 1 getting c 3 c k eff l 1 ω 2 ω d d r d d r δ k r δ k r after averaging introducing the pair correlation function c k r r δ k r δ k r of the hydraulic conductivity fluctuations we get a formula already obtained by rubin and gómez hernández 1990 sánchez vila et al 1995 wen and gómez hernández 1996 c 4 c k eff l 1 ω 2 ω d d r d d r c k r r note that for small averaging volume size l compared to the integral scale i this formula gives by direct inspection c k eff l c k r 0 on the other limit assuming that the unit volume size is very large compared to the underlying integral scale one gets the asymptotic behavior c 5 c k eff l 1 ω ω d d r c k r for large l one has the scaling c 6 l d i d c k eff l ω d d r c k r i d the factor ld id corresponds to the number of independent statistical units that belong to volume ω this scaling corresponds thus to a central limit theorem characterizing the emergence of a deterministic large scale effective conductivity in other words the system exhibits self averaging properties eqs c 4 and c 5 are solved for the particular case of the gaussian covariance in c 2 c1 improved estimation of the variance mean field approximation the preceding development is limited to small variances in order to find an improved approximation one can use eq c 2 written on an equivalent form k eff 2 k eff 2 1 ω 2 ω d d r d d r k r p r 2 p ω x 2 k r p r 2 p ω x 2 δ k r k r δ k r k r now one can replace k r p r 2 and k r p r 2 by their common average value k eff p ω x 2 so one gets k eff 2 k eff 2 k eff 2 1 ω 2 ω d d r d d r δ k r k r δ k r k r up to this order of approximation the result can be identified with the variance of log keff and the equation can be rewritten as c log k eff l log k eff 2 log k eff 2 1 ω 2 ω d d r d d r δ log k r δ log k r this equation up to this order of approximation is equivalent to eq c 4 by replacing every occurrence of a conductivity by the corresponding logarithm so c 7 c log k eff l 1 ω 2 ω d d r d d r c log k r r the resulting formula is similar to eq c 4 replacing the covariance function by the log conductivity covariance function for the special case of lognormal media this is a quite natural transformation the same can be done with the simplified formula c 5 c2 gaussian covariance case in the isotropic gaussian case the covariance function is given by c k r c k r 0 e r 2 2 i c 2 the integral factorizes and after changing variables x x ic we obtain c 8 c k eff l c k r 0 i c l 2 d l 2 i c l 2 i c l 2 i c l 2 i c d x d y e x y 2 2 d c k r 0 i c l 2 d π 2 l 2 i c l 2 i c d y erf l i c 2 y 2 2 erf l i c 2 y 2 2 d c k r 0 i c l 2 d 2 π l i c erf 2 l i c 2 e l 2 2 i c 2 2 d considering small upscaling volume l small compared with ic we obtain c k eff l c k r 0 as it should in the opposite case considering large upscaling volumes l provides c k eff l c k r 0 2 π i c l d this is a form of a central limit theorem for effective conductivity quantifying the variance reduction leading to convergence of the effective conductivity for large averaging volume finally using the simplified expression c 5 one gets after integration c 9 c k eff l c k r 0 2 π i c l erf 2 2 l i c d it shares the same asymptotic behavior for extreme l than the exact 13 the same calculations can be carried out for c log k eff l and give the same results using c log k r 0 and the same spatial dependance appendix d second order evaluation of the average of block kdiss the block equivalent conductivity kdiss ϑ is given by eq 15 decomposing the conductivity as k r k δ k r one can carry out a second order expansion of kdiss ϑ k d i s s ϑ ϑ d d r k δ k p 0 δ p 2 λ d p 0 δ p 2 this formula must be expanded up to second order in a series expansion of δk note that the technique that was presented in appendix b cannot be followed directly because the variational formulation is efficient at the scale of the whole ω only not on every subvolume ϑ in order to simplify notations we introduce δp r as the first order variation due to a variation δk r the numerator can be expanded up to second order discarding third order terms to yield d 1 ϑ d d r k δ k p 0 δ p 2 ϑ d d r k δ k 1 2 p 0 δ p ϑ d d r k δ p 2 an analogous calculation can be carried out for the denominator recalling that p 0 r e x d 2 λ d p 0 δ p 2 λ d p 0 2 2 p 0 δ p δ p 2 λ d 1 2 p 0 δ p δ p 2 combining eq d 1 and the second order expansion of eq d 2 many cancellations occur yielding still at same order of approximation k d i s s ϑ k 1 λ d 2 ϑ d d r δ k p 0 δ p p 0 δ p k ϑ d d r δ p 2 δ p 2 one has in the general case p 0 p 0 e x it can be observed that in the case of small averaging volume ϑ k d i s s ϑ k r as it should all the contributions cancel each other because in that limit a volume average is equal to the local value δ p δ p further simplifications can be obtained using green s formula on the term k ϑ dd r δp 2 combined with eq a 1 that drives δp yielding d 3 k d i s s ϑ k 1 λ d ϑ d d r δ k p 0 δ p 1 λ d 2 ϑ d d r δ k p 0 δ p ϑ d d r k δ p 2 k λ d ϑ d d 1 r δ p δ p n 1 λ d ϑ d d 1 r δ k δ p p 0 n we obtain after statistical averaging k d i s s ϑ k 1 λ d ϑ d d r ω d d r p 0 r δ p r δ k r c r r 1 λ d ϑ d d r 2 δ k p 0 δ p k δ p 2 k λ d ϑ d d 1 r δ p δ p n 1 λ d ϑ d d 1 r δ k δ p p 0 n using δ p r δ k r 1 k g r r p 0 r and combining this result with eq d 2 one obtains d 4 k d i s s ϑ k 1 k l d ϑ d d r ω d d r r x r x g r r c k r r 1 λ d ϑ d d r 2 δ k p 0 δ p k δ p 2 k λ d ϑ d d 1 r δ p δ p n 1 λ d ϑ d d 1 r δ k δ p p 0 n it can be checked by direct inspection that first line of this formula compares well with eq b 3 the other contributions are finite size effects that cancel if ϑ ω they explain the observed differences in the numerical tests if ϑ tends to zero k d i s s ϑ k supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103594 appendix e supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
495,in large scale heterogeneous aquifer simulations determining the appropriate coarsening scale λ to define an effective hydraulic conductivity keff is a challenging task that involves a trade off between accuracy and cost efficiently adjusting the scale λ is then key in particular for uncertainty quantification in this paper we obtain improved analytical results for the variance of keff valid at any scale in the context of energy dissipation formulation using this formulation we then derive an efficient keff numerical estimator and compare it with those of the potential flow average and permeameter formulations in 2d for lognormal and binary media over a wide range of λ and of heterogeneity we analyze the probability density function pdf mean and variance of these estimators comparing them with the analytical results in the lognormal case the pdf s are rather similar for the three estimators and remain lognormal at all scales in the binary case slow convergence to an asymptotic regime is observed close to the percolation threshold graphical abstract image graphical abstract keywords heterogeneous aquifers stochastic approach volume averaging upscaling 1 introduction describing effective properties of heterogeneous media has important applications in many fields of engineering and science for example the electrical or thermal effective conductivity of mixtures or elastic properties of composites materials have been studied since many years ago maxwell 1873 bruggeman 1935 landau and lifshitz 1960 auriault 1983 willot and jeulin 2009 zhou et al 2016 in particular determining an effective hydraulic conductivity is of major interest in a variety of disciplines related to subsurface flow such as groundwater flow characterization renard and de marsily 1997 matheron 1967 dagan 1989 dagan et al 2013 carbon capture utilisation and storage ccus development akber hassan and jiang 2012 celia et al 2015 and oil and gas reservoir engineering king 1989 durlofsky 1991 1992 preux 2016 malinouskaya et al 2018 the scarcity of field data matheron 1967 dagan 1989 hristopulos 2020 makes it necessary to perform some sort of interpolation with frequent use of a stochastic approach gelhar 1993 linde et al 2015 godoy et al 2018 that treats the point conductivity values as a random process eventually accompanied by field data conditioning while the use of this approach permits a good management of uncertainty it turns too costly to solve the flow at the fine scale provided by laboratory microtomography synchrotron or geological sources dagan et al 2013 specially for large domains in addition one may want to incorporate data obtained at different support scales before interpolation to alleviate this issues upscaling procedures allow us to perform a mapping from a fine scale onto a coarse scale in which the solution of the flow is less costly fig 1 shows the lengthscales and geometrical features of the upscaling process the fine scale conductivity k r r is the position vector is defined over the regional domain ω ℜ d dimension d 1 2 or 3 at a support scale δ the coarsening scale λ determines a domain ϑ over which the effective hydraulic conductivity keff is defined one the one hand for practical and conceptual purposes we can establish an upper bound l for λ determined by the largest subdomain ω over which it is still possible to solve the flow eventually imposing boundary conditions at ω if natural flow conditions are unknown for example l could be a characteristic aquifer scale on the other hand a lower bound for λ is given by the support scale δ the effective conductivity of a block or subdomain ϑ defined by the coarsening scale λ i e keff λ depends on the values of k r within ϑ but also on the conditions at the boundary ϑ which may be imposed or known moreover keff λ is a tensor in principle however for isotropic media and certain flow conditions sánchez vila et al 1995 vereecken et al 2007 the use of a scalar keff is appropriate finding a suitable coarsening scale λ requires dealing with a trade off between accuracy and cost as λ increases the cost to solve the flow decreases but some details of the heterogeneity and of the flow get lost and the values of keff become less representative of the fine description the choice of a scale λ that retains the most salient flow features while keeping the cost of the flow solution low makes upscaling a challenging task in the following section we revisit briefly some upscaling results with focus on the types of media studied in most works including the present one i e lognormal and binary media to later discuss keff distributions and some upscaling formulations 1 1 previous results analytical methods like bounds based approaches hashin and shtrikman 1962 renard and de marsily 1997 le loc h 1987 pozdniakov and tsang 2004 or power averaging journel et al 1986 desbarats and srivastava 1991 masihi et al 2016 provide a remarkable insight although as they estimate keff from the point values k r only they disregard the influence of the flow behavior at ω depending on the detailed context homogenization techniques auriault 1983 durlofsky 1991 jikov et al 2012 armstrong et al 2019 volume averaging techniques hassanizadeh and gray 1979 quintard and whitaker 1998 durlofsky 1998 whitaker 2013 gray and miller 2005 leung and srinivasan 2012 wood and valdés parada 2013 davit and quintard 2017 aguilar madera et al 2019 or stochastic perturbation theory landau and lifshitz 1960 matheron 1967 dagan 1989 king 1989 rubin and gómez hernández 1990 indelman and dagan 1993a 1993b noetinger 1994 indelman and abramovich 1994 ababou 1994 abramovich and indelman 1995 noetinger and gautier 1998 noetinger 2000 liao et al 2019 were developed over many decades all these methods provide a rigorous analytical framework supporting the existence and uniqueness of keff for a wide variety of media types analytical efforts took place mainly using perturbation theory gelhar 1993 dagan 1989 the so called landau lifschitz matheron llm landau and lifshitz 1960 matheron 1967 formula reads 1 k eff k 1 2 d 1 1 2 d in the case of a lognormal distribution of fine scale conductivity this formula can be written under the equivalent form king 1989 noetinger 1994 k eff exp log k e 1 2 1 d c log k r 0 k g e 1 2 1 d c log k r 0 the notation indicates ensemble arithmetic averaging over all the possible realizations of the fine scale structure kg denotes the geometric mean of the fine grid conductivity and c log k r 0 the variance of its logarithm in this work wherever the expressions log k or log keff are shown it is implied that the argument of the logarithm is divided by 1 m day to make it dimensionless in most cases an ergodicity assumption allows to replace the ensemble average by a spatial average ababou 1996 sanchez vila et al 2006 such that for finite block of size l one estimates keff as 2 k eff b l o c k 1 v b l o c k k r 1 2 d d d r 1 1 2 d this formula with dimension d 1 2 3 whose evaluation is straightforward is exact in 1d for any type of media yielding the harmonic average in 2d it corresponds to the geometric average that was found to be exact in 2d for lognormal media by matheron 1967 who derived it using an elegant duality argument specific to 2 dimensions in 3d the formula is exact up to second order dagan 1993 with respect to log conductivity variance using a series expansion of keff up to 4th order in powers of the log conductivity fluctuations but in 3d the proposed formula was shown to be inexact at third order by several authors indelman and abramovich 1994 de wit 1995 stepanyants and teodorovich 2003 moreover higher order results were shown to be structure dependent this prevents the existence of a local evaluation expression like eq 1 in 3d however numerical tests carried out show that llm formula is quite robust in 3d even for large log conductivity variances dagan 1989 romeu and noetinger 1995 renard and de marsily 1997 some generalization of such approaches for anisotropic cases were revisited recently by liao et al 2019 from a more geological point of view a frequent organization of the subsurface heterogeneous formations in a number of hydrofacies that correspond to different types of rock or sediments having a well defined hydraulic property such as porosity or permeability may be observed in natural systems journel et al 1986 beucher and renard 2016 each facies possesses its own characteristic features that promoted the study of the effective conductivity of composite media binary or bimodal media are the simplest cases while still retaining the complexity of percolative systems these types of media have been extensively studied using self consistent effective medium approaches in the electrodynamical or elasticity contexts maxwell 1873 bruggeman 1935 landau and lifshitz 1960 auriault 1983 pozdniakov and tsang 2004 analytical results based on a mixing of characteristic conductivity values and bounds hashin and shtrikman 1962 1963 exist for this type of media bernabé et al 2004 in them connectivity is implicitly taken into account other authors pozdniakov and tsang 2004 knudby and carrera 2005 guin and ritzi 2008 bernabé et al 2016 studied numerically the influence of the contrast between the high and low conductivity components k and k the abrupt change in keff that takes place close to the percolation transition when the k component becomes connected poses difficulties during the upscaling procedure boschan and noetinger 2012 indeed percolation theory scaling berkowitz and balberg 1993 stauffer and aharony 2014 hunt et al 2014 hunt and sahimi 2017 has been used to assess keff in this type of media but some restrictions exist this scaling is only valid for media in which the proportion of high conductivity medium is close to the percolation transition percolation transition is smeared out by finite size effects and finite conductivity contrast values 1 2 keff probability distributions due to the fact that subsurface uncertainty is frequently dealt with by using a stochastic approach it is appropriate to treat keff as a random variable characterized by a probability distribution more than by a deterministic value although the literature mainly focuses on the firsts moments of the probability density function pdf such as the mean and variance rubin and gómez hernández 1990 sánchez vila et al 1995 sanchez vila et al 2006 the shape of the pdf provides unique insight on the underlying flow situation for example in media samples near percolation a bimodal pdf may yield a mean keff value that truly has a negligible occurrence probability this situation may easily arise when dealing with fractured media or in general with media possessing a high degree of heterogeneity the pdf of keff depends on the coarsening scale λ and will be noted p keff λ for clarity p keff λ undergoes a transition from p k r δ to p keff l as λ goes from δ to l for λ δ the distribution of k r is recovered while for λ l p keff λ will tend toward a delta like distribution sharply peaked around a stable keff value see fig 2 if it is possible to define a characteristic lengthscale for example an integral scale i for the media under consideration a crossover is expected when λ approaches it more conceptually a representative elementary volume rev may be determined by inspecting significant changes of the shape of p keff λ the fact that the statistical sampling becomes poorer as λ increases can be compensated in the framework of the stochastic theory and assuming ergodicity by an increase in the number of ensemble realizations the behavior of p keff λ was addressed in several studies king 1989 sanchez vila et al 2006 wen and gómez hernández 1996 wu et al 2013 in boschan and noetinger 2012 the convergence of p keff λ was studied in 3d for lognormal and binary media in the lognormal case p keff λ kept its lognormal nature as λ increased if this result hold in 2d this will be analyzed in the present work it might stem from the work of matheron 1967 in the binary case it was shown that the convergence to a stable keff is slower when the k component is close to the percolation transition stauffer and aharony 2014 finally under the ergodic hypothesis several studies assessed the use of filtering techniques to derive p keff λ at all scales king 1989 noetinger and gautier 1998 noetinger 2000 noetinger and zargar 2004 attinger 2003 eberhard et al 2004 1 3 upscaling formulations and numerical implementations the fact that analytical results are limited to some academic cases and strictly valid only up to second order in 3d imposes the use of numerical techniques to obtain keff as well as its distribution by means of monte carlo simulations several numerical techniques were developed using different approaches and provide accurate solutions desbarats and srivastava 1991 durlofsky 1991 desbarats 1992 quintard and whitaker 1998 wang et al 2014 zheng et al 2017 wang et al 2018 the numerical implementations calculate a value keff in ϑ from the fine conductivity field k r and from the boundary conditions at ϑ in what constitutes a numerical solution of the closure problem posed by the associated laplace equation moreover some of them use border regions including information of the outer neighbourhood of ϑ wen et al 2003 two aspects of the solution of the closure problem by numerical simulations stand out 1 the task of finding the optimal scale λ in each flow scenario makes upscaling a multiscale problem par excellence 2 the choice of the formulation in particular that of the boundary conditions strongly affects accuracy and numerical efficiency for example imposing boundary conditions at ϑ decouples the flow in ϑ from its outer region in a rather invasive procedure in view of item 1 in that sense solving the flow in ω once and then employing this solution to estimate p keff λ i e seems less invasive and more efficient but requires the ability to solve larger systems of equations from the existing upscaling formulations the most widely used is the permeameter darcian one which as a particularity isolates the flow in ϑ suffering from the drawback explained above this formulation and its implementation will be formally introduced in section 2 2 another frequent formulation rubin and gómez hernández 1990 and sánchez vila et al 1995 uses the solution of potential and the associated flow in ω evaluating their averages over ϑ to obtain keff in order to obtain a scalar keff some assumption is required finally indelman and dagan 1993a b bøe 1994 proposed that keff could be defined by assuming that the dissipated energy is conserved during the upscaling procedure this might be the strongest conceptual definition ever formulated however its implementation to obtain keff is mathematically difficult aiming to reduce the computational cost a number of approaches that combine different formulations were proposed chen et al 2003 bauer et al 2008 wu et al 2013 karimi fard and durlofsky 2016 with the support of ergodicity considerations ababou et al 1989 ababou 1994 1996 desbarats and srivastava 1991 1 4 objectives in this paper we intend to explore analytically and numerically the multiscale nature of the upscaling procedure in the context of the different formulations in 2d on the one hand after reviewing the existing body of literature we update the formulae introduced in previous studies to characterize the mean and variance of keff valid at the scale ω at which the boundary conditions are imposed we derive in the context of the energy dissipation formulation a new expression for the variance this time valid at any subscale ϑ ω up to second order in perturbation theory on the other hand using that formulation we define and implement a new numerical estimator of keff based on a scalar energy dissipation average this estimator can be obtained at any subscale λ with nearly negligible additional cpu time once the potential in ω is solved aiming to provide a comprehensive view the pdf the mean and the variance of this estimator are compared with those of the potential flow average estimator and of the permeameter darcian one over a wide range of coarsening scales this study is performed over lognormal media samples with a wide range of fine grid variances and over binary media samples spanning the percolation transition the paper is organized as follows we start by presenting the overall geometry and notation considering a steady state darcian flow in an heterogeneous porous medium and perform some algebraic manipulation to express keff in terms of the viscous dissipation we introduce then section 3 1 a useful variational derivation that allows us to define keff in terms of a minimization of that dissipation by using functional expansion techniques already developed in a previous study noetinger 2013 we provide expressions for the variance of keff in ω up to second order in the perturbation expansion valid for small variances later improving it for higher variances by using a mean field approximation after some more manipulation we get in position to show how these results are valid at any subscale i e the coarsening scale λ even if the variational formulation cannot be applied at any scale smaller than ω the scale in which the boundary conditions are imposed the result depends also on the covariance of k r and on λ while it is possible to apply again the mean field technique now at this scale to improve it section 6 introduces the numerical methodology with the implementation of the three formulations while section 7 presents firstly a numerical validation and then the results regarding the multiscale dependence of keff under the different formulations 2 geometry driving equations and notations 2 1 geometry and local equations we focus our attention on a block ω to be upscaled in d dimensions a square in 2d or a cube in 3d the edges of that domain are of size l in the d directions as sketched in fig 1 the potential is driven by the following laplace equation to be solved in the domain ω 3 k r p r 0 the local potential is denoted by p r this equation is a combination of mass or charge conservation with a phenomenological equation relating the local flux to the local potential gradient such as joule darcy or fourier s law that may arise after a proper averaging of the sub scale transport processes hassanizadeh and gray 1979 in order to get a well defined problem dirichlet or dirichlet neumann conditions must be specified at the frontier ω of the domain these conditions will be discussed in the next section the local conductivity denoted by k r is assumed to be scalar and to depend on position r the conductivity field can be discontinuous with respect to r 2 2 classical darcian definition of the effective conductivity here we defer the discussion of the upscaling problem to references in matheron 1967 durlofsky 1991 neuman and orr 1993 renard and de marsily 1997 quintard and whitaker 1998 willot and jeulin 2009 jikov et al 2012 the effective conductivity can be defined using the solution of the laplace eq 3 to be solved with dirichlet boundary conditions at the inlet outlet denoted by pin and pout neumann no flux boundaries are imposed on the faces of the domain parallel to the average imposed flow which will be the x direction in the rest of the paper this definition of keff is the so called permeameter definition that will be sometimes denoted by kperm this corresponds physically to the basic conductivity measurement that could be performed at the laboratory both in the darcy or electrical context other boundary conditions such as periodic auriault 1983 durlofsky 1991 quintard and whitaker 1998 noetinger 2013 can be chosen but that does not change drastically the analysis so permeameter conditions will be kept throughout the paper by identification with the homogeneous case effective hydraulic conductivity is given by 4 k eff q l d 2 p i n p o u t here q denotes the total fluid flux flowing in any section of the domain perpendicular to the mean flow x direction 5 q i n l e t f a c e d d 1 r k r p r n here p r is the unique solution of the boundary value laplace eq 3 with the permeameter forcing boundary conditions 3 effective conductivity and viscous dissipation for our purpose it is useful to introduce an equivalent algebraic expression of keff that was introduced in the porous media context by jacquard 1965 matheron 1967 and revisited later by wen and gómez hernández 1996 sánchez vila et al 1995 6 q p i n p o u t ω d d 1 r p r k r p r n ω d d r k r p r p r in order to begin with the first equality of eq 6 is obtained by expressing q in terms of integrals over the inlet and outlet faces of the domain as in eq 5 in the outlet according to the convention defining positive flow opposite to the face inward normal the expression have the opposite sign then both face pressures are moved under the integral signs obtaining similar expressions regarding the neumann boundary conditions on lateral faces imposing no pressure gradient both integrals can be combined in only one over the whole domain boundary ω using the divergence theorem combined with laplace eq 3 yields the second equality this equation has a simple physical interpretation the rhs corresponds to the total viscous dissipated power that must coincide with the power spent by external forcing sources set up to create the flow so the effective conductivity may be expressed as 7 k eff 1 p i n p o u t 2 l d 2 ω d d r k r p r 2 1 p ω x 2 l d ω d d r k r p r 2 where p ω x p i n p o u t l is the volume averaged gradient in the x direction which is the mean flow direction the average potential gradient p ω over the block volume ω l d is given by 8 p ω 1 ω ω d d r p r 1 ω ω d d 1 r p r n in the case of a square or cubic ω the retained boundary conditions for potential p give the proposed equality in the x direction eq 7 relates the effective conductivity of the whole block keff to the overall viscous dissipation and the mean forcing potential gradient norm in the imposed flow direction it will be the starting point to define a dissipation based effective conductivity estimator in section 5 1 3 1 a variational characterization of keff we are now in position to propose an alternative formulation that proves to be useful for estimating the sensitivity of large scale parameters to variations of local conductivity this variational characterization of keff may be formulated as follows 9 k eff p i n p o u t 2 l d 2 q p i n p o u t k eff p ω x 2 l d m i n p r θ p r ω d d r k r p r 2 here the potential fields p r among which the minimization is to be performed fulfill the boundary conditions at ω the justification of eq 9 is classical one has to express the extremal conditions r δ θ p r δ p r k r p r 0 the operator δ θ p r δ p r is a functional derivative of the functional θ p r with respect to p r a basic presentation of functional differentiation is given in appendix a using thus the particular quadratic form of θ p r these extremal conditions give rise to laplace eq 3 that governs the potential the final result may be derived using the same methods than eq 6 3 2 functional expansion techniques for the effective conductivity functional techniques combined with the variational formulation are useful to derive directly second order perturbation expansion of the effective conductivity and of its associated variance the starting point is to evaluate the sensitivity of effective conductivity with respect to local perturbations of the local conductivity as it was derived in noetinger 2013 and appendix a the starting point is to decompose the local hydraulic conductivity as k r k δ k r the brackets correspond to ensemble averaging over the conductivity realizations to be not confused with volume averaging denoted by so δ k r 0 one can use the formal equivalent of taylor series formula up to second order also valid for functionals 10 k eff k ω d d r δ k eff δ k r δ k r 1 2 ω d d r ω d d r δ 2 k eff δ k r δ k r δ k r δ k r the reader must note that in these equations the functional derivative must be evaluated while the nominal value of the conductivity map is a uniform value k r k in usual function taylor s expansions this corresponds to the point at which the derivative is evaluated averaging eq 10 yields a second order expansion that coincides with llm conjecture up to this limited order a concise derivation using functional derivatives is given in appendix b 4 estimation of the variance of the effective conductivity at second order in this section we present expressions of the variance of the effective conductivity that are obtained in the context of second order perturbation theory the derivations are given in appendix c finally closed expressions are given for the cases when those expressions are particularized for gaussian covariance functions for the variance of the effective conductivity given by c k eff l k eff 2 k eff 2 k eff k eff 2 the following expression can be obtained eq c 4 11 c k eff l 1 ω 2 ω d d r d d r c k r r a mean field approximation allows to replace each occurrence of keff and k by the corresponding logarithm eq c 7 providing the following expression that can be expected to have a more extended domain of validity for practical applications 12 c log k eff l 1 ω 2 ω d d r d d r c log k r r the resulting formula is similar to eq 11 replacing the covariance function by the log conductivity covariance function for the special case of lognormal media this is a quite natural transformation the same can be done with the simplified formula c 5 in the case of the gaussian covariance with c k r c k r 0 e r 2 2 i c 2 where ic is the correlation length explicit analytical expressions can be derived for c k eff l from eq 11 see appenidx c 2 eq c 8 13 c k eff l c k r 0 i c l 2 d 2 π l i c erf 2 l i c 2 e l 2 2 i c 2 2 d likewise using the simplified eq c 5 one gets after integration eq c 9 14 c k eff l c k r 0 2 π i c l erf 2 2 l i c d the same calculations can be carried out for c log k eff l applying the logarithmic transformation and give analogous results using c log k r 0 and the same spatial dependence 5 a posteriori multiscale estimators of keff distributions in this section two estimators providing intermediate scale effective conductivity distributions are presented both are computed using low cost post processing of one up scaling closure problem at the largest available scale these distributions will be compared to reference distributions determined by computing numerically permeameter effective conductivity of every coarse block at any scale the resulting pdf s will be compared as well as the associated log conductivity mean and variance for completeness the latter will be compared with preceding analytical results 5 1 dissipation estimator 5 1 1 definition of the estimator we consider now that the upscaling laplace problem was solved on a single conductivity realization on the entire block ω the subscale effective conductivity kdiss ϑ on any given cubic or square sub block of size λ included in the overall domain ω can thus be defined as the relation between the dissipation and the average potential gradient at the block level by 15 k d i s s ϑ ϑ d d r k p 2 λ d p ϑ 2 it can be observed using eq 7 that if ϑ ω k d i s s ϑ k eff p x 2 p 2 k eff in the case of statistically isotropic k r if ω is sufficiently large the average potential gradient p y perpendicular to the mean flow vanishes so the effective conductivity determined by dissipation is equal to the usual definition kdiss ϑ ω keff considering the opposite limit ϑ 0 it can be shown using a taylor expansion of the potential gradient under the integral sign that k d i s s ϑ k r if and only if p 2 p 2 0 this last condition corresponds to stagnation no flow points this condition is not surprising as it can correspond to both infinite conductivity regions or to screened regions of vanishing hydraulic conductivity in both cases effective conductivity is not defined assuming that the set of these points is of vanishing measure in most cases the original detailed conductivity map must be recovered this criterion was already introduced and discussed by sánchez vila et al 1995 and bauer et al 2008 the proposed indicator fulfills two intuitive conditions for both extreme ϑ sizes in appendix d it is shown that the average of the dissipation estimator is in agreement with that derived for keff for volumes ϑ tending to ω and the structure of the finite size corrections is given too in next section 5 1 2 it is shown up to second order that the variance of kdiss ϑ coincides with expression 11 by replacing ω by ϑ as integration domain this implies that the evaluation of the variance c log k d i s s λ is obtained by replacing l by the length of the considered subscale block λ in eq 12 5 1 2 evaluation of the variance of block dissipation conductivity kdiss the block equivalent conductivity kdiss ϑ is given by eq 15 and its variance may be evaluated following the same steps that in appendix c it is defined by k d i s s ϑ 2 k d i s s ϑ 2 k d i s s ϑ k d i s s ϑ 2 so one gets finally k d i s s ϑ 2 k d i s s ϑ 2 ω d d r d d r δ k d i s s ϑ δ k r δ k d i s s ϑ δ k r δ k r δ k r note that at present stage the integration volume remains the whole volume ω it is not restricted to ϑ because keff ϑ depends on the entire conductivity map that is defined on the support ω in which the laplace equation is solved at the beginning we have to evaluate the functional derivative δ k d i s s ϑ δ k r the evaluation cannot be simplified because the variational principle that characterizes keff as defined in ω is not relevant at any smaller scale the derivative is given by δ k d i s s ϑ δ k r p 0 r 2 λ d p 0 2 1 ϑ r 2 λ d p 0 2 2 1 λ d p 0 2 ϑ d d r k p 0 r δ p r δ k r 1 λ d ϑ d d r k p 0 r 2 ϑ d d r p 0 r δ p r δ k r in that equation the first term involving the indicator function of ϑ denoted by 1 ϑ r is the remaining of the result that would be provided using the variational approach as shown in appendix c eq c 1 the first integral arises from the derivative of p 2 under the integral sign the second corresponds to the functional derivative of 1 p 2 both terms are equal to 0 if ϑ ω at lowest order the spatial dependence of the conductivity k must be discarded it appears that the second line involving twice integration vanishes because p 0 r e x is constant up to this order so both terms cancel each other so we obtain the same result that would be provided by the variational approach if it was applicable for block dissipation δ k d i s s ϑ δ k r p 0 r 2 λ d p 2 1 ϑ r gathering all the preceding results we obtain the following formula for the variance of the dissipation estimator at scale ϑ 16 k d i s s ϑ 2 k d i s s ϑ 2 1 ϑ 2 ϑ d d r d d r c k r r up to second order this formula is analogous to the variance in eq c 3 of the full up scaled hydraulic conductivity keff the corresponding formulation using logarithms is similar at this order this result allows to extend the validity of eqs 11 and 12 to subscale blocks ϑ 5 2 block average conductivity estimator another keff estimator on subvolume ϑ can be introduced defined as k a v e ϑ q x λ d 1 p x this expression is based on darcy equation where q is the flow rate and p the potential gradient both volume averaged over domain ϑ of size λ this estimator was studied by rubin and gómez hernández 1990 sánchez vila et al 1995 renard and de marsily 1997 bauer et al 2008 in particular using a second order expansion rubin and gómez hernández 1990 computed the average and variance of log kave ϑ as a function of ϑ and the input covariance function of the conductivity that correspond to the observed statistical parameters observed at scale l they give the following expressions log k a v e ϑ log k g 1 2 1 d 1 α c log k r 0 log k a v e ϑ log k a v e ϑ 2 α c log k r 0 the normalized variance correction factor α given by α 1 ϑ 2 ϑ d d r d d r c log k r r c log k r 0 depends only on the geometrical form of the covariance function and on the averaging volume ϑ size λ it can be observed that it shares the same form than the scale dependant variance 11 derived before it can be noticed that using directly llm formula for estimating keff for large size λ using these parameters eq 1 under its second form is recovered as terms involving α terms cancel this highlights some internal consistency of this estimator in practice once the potential is solved the evaluation of kdiss ϑ and kave ϑ is straightforward and of negligible extra computational cost for a given size λ one obtains a set of l λ d d 2 3 values of kdiss ϑ and kave ϑ that can be studied using statistical tools this will be the main topic of next sections 6 numerical methodology 6 1 generation of media samples we first compare the formulations over random lognormal media samples with low and high variance and then over binary media samples that have a high contrast of characteristic conductivities we employed a fast fourier transform fft moving average fft ma method le ravalec et al 2000 to generate these samples lognormal hydraulic conductivity fields with unitary geometric mean kg were generated gaussian covariance with an integral scale i 16 δ defined as the practical range of the covariance function i 3 i c was used to spatially correlate the samples fig 3 left shows as an example a realization of a lognormal medium obtained with this procedure all media samples generated have 1024 1024 cells with a linear size of 1024δ in order to reduce the numerical truncation error when computing the potential field a refining stage of degree 4 was performed romeu and noetinger 1995 liu and wang 2013 resulting in a grid of 4096 4096 computational cells of linear size δ 4 binary random media is generated as follows we start by generating a lognormal one with an arbitrary geometric mean kg and variance σ log k 2 then this lognormal distribution is binarized using a threshold value kt assigning each cell a characteristic k high conductivity or k low conductivity value with k k 10 4 the value of kt controls the relative population p of high conductivity cells three values of p were studied one at the 2d percolation threshold p c 0 5 one smaller p 0 4 and one greater p 0 6 than pc at pc 50 of the realizations percolate we used connect3d software pardo igúzquiza and dowd 2003 to explicitely verify the percolation condition the spatial correlation function of the resulting binary medium remains gaussian in turn the integral scale of the binary medium is determined by the integral scale of the original lognormal medium but also by p to be able to use the former as an input parameter we ve performed an iterative search for each of the values of p studied fig 3 right shows as an example a realization of such a binary medium for each set of parameters we generated 50 samples in order to obtain an acceptable statistical sampling at largest scale l 6 2 potential field calculation for the kave and kdiss formulations it is only required to solve the potential in ω once and then post processing of the obtained field is performed to obtain keff at any scale λ for the kperm formulation the potential must be solved independently for all the sub domains ϑ under study to obtain the potential field we used modflow 2005 1 1 https water usgs gov ogw modflow mf2005 html software harbaugh 2005 with the corresponding boundary conditions this solver uses the finite difference method with a classical 2 d 1 point stencil particularly the block centered flow package bcf6 was used and the linear equation system was solved with the preconditioned conjugate gradient package pcg 6 3 implementation of the permeameter scheme we used classical permeameter boundary conditions in the computation of the potential fields in modflow these boundary conditions are applied assigning constant potentials dirichlet type to two opposite cell layers each of them representing a domain face a unitary potential difference δp between them is set all other faces are constrained by no flow boundary conditions neumann type applied to ghost cell layers outside the domain these boundary conditions are applied at ϑ to compute kperm defined as 17 k p e r m q λ δ p the integral of the flow q is calculated at the inlet or the outlet face of the block ϑ with permeameter boundary conditions for each medium kperm was computed for the whole set of subscales λ 2 n with integer n between 1 and 10 resulting in l λ 2 2 2 10 n values at each subscale the same procedure was followed for the other two estimators 6 4 implementation of the dissipation scheme based on the resulting potential field computed using modflow with permeameter boundary conditions sections 6 2 and 6 3 on domain ω and the theoretical development presented in section 5 1 the dissipation based block estimator computation is as follows as the finite difference scheme adopted in modflow is cell centered after solving the potential field in ω both the hydraulic conductivity k i j and potential p i j at each cell center are known notations are referred to cell i j of ϑ where i 1 j i 1 j i j 1 and i j 1 are the left right top and bottom neighbouring cells respectively using an electrical analogy the local cell dissipation can be computed as 18 ϵ i j ϑ i j d 2 r k i j p 2 2 k i j p i 1 2 j p i j 2 p i 1 2 j p i j 2 p i j 1 2 p i j 2 p i j 1 2 p i j 2 the factor 2k i j corresponds to the conductivity of the half bond between the center and any face of ϑ i j the potential subscript with minus or plus halves refer to cell face potentials computed invoking the equality of flux at both sides of the face for example the potential on the left face of cell i j is given by p i 1 2 j k i j p i j k i 1 j p i 1 j k i j k i 1 j the other cell face potentials are defined analogously using equivalent equations to eliminate face potentials in eq 18 we get ϵ i j 1 2 k i j t i 1 2 j p i 1 j p i j 2 t i 1 2 j p i 1 j p i j 2 t i j 1 2 p i j 1 p i j 2 t i j 1 2 p i j 1 p i j 2 the coefficients t are the usual intercell harmonic averages given by t i 1 2 j 2 k i 1 j k i j k i 1 j k i j and t i j 1 2 2 k i j 1 k i j k i j 1 k i j ohm s law for dissipation can be recognized through the squares of the fluxes flowing through the faces the cell face potentials are also used to compute the cell potential gradient as p i j t p i 1 2 j p i 1 2 j δ p i j 1 2 p i j 1 2 δ thus the averaged potential gradient of the block is p i j p i j n i n j with ni nj the number of cells in each direction inside the block in every case the sum runs over all the fine grid blocks included in ϑ finally the block dissipation based estimator of eq 15 for block ϑ is computed as 19 k d i s s ϑ i j ϵ i j λ 2 p 2 fig 4 presents the resulting dissipation maps for lognormal and binary media samples a strong localization channeling effect may be noticed close to percolation threshold for the binary case 6 5 implementation of the block average conductivity scheme based on the computation of the potential field in ω the second keff estimator can be defined in ϑ as 20 k a v e q x λ p x this expression is based on a large scale darcy equation where q is the flow rate and p the potential gradient both averaged over the domain ϑ of size λ with the proper boundary conditions it is possible to recover the full hydraulic conductivity tensor bauer et al 2008 in this study we only considered the direction of the imposed potential difference δp 7 results we begin this section by comparing as a form of validation the outcomes of the analytical developments of section 4 for lognormal media with the corresponding numerical results using the well known kperm estimator then for both type of media we study the scale dependence of the pdf of the three proposed estimators to later focus on the first two gaussian moments i e mean and variance for this latter case a comparison with the mean field analytical variance of keff eq 13 is performed the common parameters and values used in the simulations are presented in table 1 7 1 comparison of the different analytical expressions for c k eff λ with numerical results fig 5 shows the variance of keff given by eqs 13 and 14 and their equivalent expressions within the mean field approximation compared with the kperm estimator as a function of the coarsening scale λ that varies between fine grid scale δ and l a low σ log k 2 0 1 and a high σ log k 2 7 fine grid variance are used as extreme cases the analytical results are in good agreement with the numerical simulations for σ log k 2 0 1 when using the expressions based on the conductivity variance σ k eff 2 eqs 13 and 14 the difference increases for the case of σ log k 2 7 specially for scales equal or greater than the integral scale defined as the practical range of the covariance function the estimation of the variance of the logarithm σ log k eff 2 appendix c 1 provides a better agreement with the numerical results even for σ log k 2 7 in this case the analytical equations correctly capture the tendency as the scale increases with small discrepancy from the numerical results beyond the integral scale in both cases the simplified formulas eq 14 coincide to a large extent with the complete ones except at the scales close to the integral scale where a small difference appears in view of these observations comparison against analytical results in the next sections will be only carried out with respect to eq 13 using the mean field approximation 7 2 lognormal media 7 2 1 probability density function of the different estimators pdf s of kdiss kave and kperm are plotted in fig 6 left for σ log k 2 7 although kdiss and kave present a sharper pdf they are rather similar the dependence of the pdf of kdiss with the coarsening scale λ is shown in fig 6 right it can be observed that the pdf remain gaussian at all scales as a gaussian pdf is fully described by its mean and variance in the following subsection we focus our attention on these two moments 7 2 2 scale dependence of the mean and variance of keff fig 7 compares the values of the geometric mean of keff indicated by left and the variance σ log k eff 2 scaled by λ i 2 see appendix c right for the three estimators as λ tends to δ keff approaches to the fine scale mean kg for both variances for σ log k 2 0 1 the three formulations yield very similar results while for σ log k 2 7 some discrepancies are observed moreover for λ close to i a depart from the theoretical value of upto 12 is observed for kdiss we recall that as developed in section 5 1 1 if ϑ ω the potential gradients transverse to the mean flow vanish due to the boundary conditions applied at that scale in all cases but if ϑ ω these gradients may exist and be non negligible also they are stronger as the heterogeneity increases explaining the slump in kdiss for λ close to i the variances of keff were evaluated analytically using the mean field approximation of eq 13 in fig 7 right the variances of the three estimators show an excellent agreement with the analytical results for σ log k 2 0 1 while for σ log k 2 7 a slight difference for λ i is observed for the three estimators probably due to discretization effects romeu and noetinger 1995 7 3 binary media 7 3 1 probability density functions of the keff estimators in binary media the lower limiting case is when the upscaling scale λ tends to the fine grid scale δ with only two possible conductivity values k with probability p and k with probability 1 p consequently the pdf of the effective conductivity tends to a two peaked distribution with relative heights given by p and 1 p and its mean is similar to that of the original medium at the fine grid scale on the other hand the upper limit correspond to the upscaling scale reaching the domain scale l in this case the pdf of the effective conductivity looks more like a unimodal distribution with its mean approaching k when p pc and k when p pc at intermediate scales a transition between both extreme behaviors occurs pdf s of kdiss kave and kperm are plotted in fig 8 in order to compare them with the expected behavior three situations with p smaller close to and greater than p c 0 5 for which percolation transition occurs are shown in this figure in the left column of the figure the three methods are compared for λ 32 δ at this intermediate scale different behaviors are observed depending on the method the pdf s of the three estimators considered here exhibit some differences the kperm estimator presents more peaked distributions with two clearly separated modes while those of global methods kdiss and kave are relatively more homogeneous with a continuous variation between the peaks also the values of conductivity corresponding to the facies that does not percolate are only retained in the case of kperm while kdiss and kave smooth them out this is a direct effect of the permeameter boundary conditions that are imposed for each sub domain ϑ when computing kperm this renders percolation in ϑ much more critical for keff on the other hand analyzing the behavior when small middle and large scales are adopted for λ the expected behavior is recovered kdiss converges to an unimodal distribution as λ increases faster as p departs from pc as it was observed in a previous study for kperm boschan and noetinger 2012 in addition as p departs from pc for a given λ the distributions become narrower this implies that the convergence to a representative mean is slower near percolation 7 3 2 scale dependence of the mean and variance of keff in the binary case as it is clearly seen in fig 8 the pdf s of keff are far from being unimodal and then the mean and variance become less representative of the pdf compared with the lognormal case cf section 7 2 1 for example one may note that in panel c of fig 8 the mean would not be particularly representative however previous studies analyzed the mean and variance much more frequently than the complete pdf so we consider interesting to present them for comparison fig 9 shows the variation of geometric mean of keff left and of the variance σ log k eff 2 right for the three estimators as a function of λ for p 0 4 p 0 5 and p 0 6 the values of keff coincide as λ tends to the limiting δ or l for all the values of p the behavior at both limits of the range corresponds to which is expected for a representative effective conductivity furthermore the behavior far from those extreme values is strongly dependent on the particular estimator as observed in fig 8 the two peaks in the kperm histogram remained clearly identifiable at larger λ values in opposition to what happened in the cases of kdiss or kave the outcome is that if p is far from pc kperm converges more slowly than kdiss or kave to the asymptotic value of λ l this is consistent with the faster homogenization shown by the global estimators in the pdf s of section 7 3 1 comparing kdiss and kave the former shows a slight bias to lower keff values the variance σ log k eff 2 computed using the three formulations also coincides as λ tends to δ or l at intermediate scales kperm always yields the highest σ log k eff 2 in agreement with the findings shown in section 7 3 1 where it was shown that the pdf remained bimodal for a greater λ than for the other two methods note that in the non percolating case p 0 4 kdiss produces lower variances than kave while the opposite happens for the percolating case p 0 6 and at p c 0 5 both estimators yield similar values of σ log k eff 2 8 summary discussion and perspectives after introducing an efficient keff estimator based on energy dissipation we revisited numerically and analytically three of the most important upscaling formulations analyzing the scale dependence of the resulting keff distributions for 2d lognormal media keff distributions remain lognormal at intermediate coarsening scales for all the formulations a result that could be theoretically related to the llm formula landau and lifshitz 1960 matheron 1967 the numerical results for keff and σ log k eff 2 are in agreement with the analytical ones this is notable for intermediate coarsening scales having in mind that these last results are not exact in particular the asymptotic behavior of σ log k eff 2 for λ i varying as 1 λ 2 is reminiscent to a central limit theorem in the binary case for p far from pc the pdf of keff evolves from a bimodal to a unimodal distribution with representative mean and variance the mean and variance of the three estimators converge to the same asymptotic keff values for p 0 4 or 0 6 it can be observed that the latter obeys the scaling law with 1 λ 2 in that case close to percolation threshold pc the intermediate scale keff distributions do not exhibit convergence to an asymptotic stable distribution the keff remains close to the fine grid geometric mean kg this may be explained by the fact that in 2d at 0 5 p c the analytical result of matheron 1967 can be applied yielding the geometric average in that very specific case looking more carefully to fig 9 for p p c σ log k eff 2 does not follow the scaling law in 1 λ 2 this should be related to the absence of a representative elementary volume berkowitz and balberg 1993 hunt et al 2014 stauffer and aharony 2014 quantification of such effects remains to be studied and keff estimators that comply to finite size scaling arguments might improve the existing description the computation of keff through kave and kdiss is much more efficient than using kperm because in this case the potential is solved once for ω and then by post treating this solution keff can be obtained at all scales if a multiscale description is required while providing similar results using kperm involves solving the potential independently for each scale due to the strong influence of the boundary conditions imposed at ϑ now comparing kave and kdiss we illustrate the degree of discrepancy between these two estimators as a function of the coarsening scale showing in fig 10 the ratio between the geometric mean of kave and that of kdiss it can be observed that the greater discrepancy occurs both for lognormal and binary media for λ i where i is the practical range of the covariance function as measured in both types of media samples giving a characteristic lengthscale for heterogeneity note that kdiss see section 5 1 is sensible to transverse potential gradients while kave isn t because it assumes a colinearity between potential gradient and flow these transverse potential gradients vanish at λ δ and at λ l while they have a maximum in between at a critical lengthscale despite that media samples are statistically isotropic the degree of discrepancy is then probably driven by the scale dependence of these transverse potential gradients except for the lognormal case of σ log k 2 0 1 kdiss is smaller than kave up to 12 in the lognormal case of σ log k 2 7 and up to 80 in the binary case the bias of kdiss towards lower values was also observed in the pdf s shown in the sections 7 2 1 and 7 3 1 the 3d generalization of this work is currently under development in particular the appearance of an attractive conductivity distribution for the different formulations playing in 3d an analogous role to the lognormal distribution in 2d is of central interest moreover for binary media it is highly interesting to assess the slower convergence to an homogeneous keff distribution close to the percolation transition in 3d media in the context of the different formulations more realistic or complex distributions such as non gaussian or power law panzeri et al 2016 riva et al 2017 guadagnini et al 2018 will be addressed in future work a major practical issue regarding non homogeneous materials is to find some self contained estimation of the rev size allowing to determine for a given case if the rev size is reached that will help to find the optimal meshing size and to quantify uncertainty propagation credit authorship contribution statement iván colecchio conceptualization data curation formal analysis writing original draft alejandro boschan conceptualization data curation formal analysis writing original draft alejandro d otero conceptualization data curation formal analysis writing original draft benoît noetinger conceptualization data curation formal analysis writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to acknowledge the computational time from the tupac cluster made available by the csc conicet for conducting this research appendix a functional differentiation functional differentiation is a generalization of calculus to functionals i e functions having a function as argument our presentation is intuitive let f k be a functional that depends on the whole set of values of k which is an arbitrary function of position r ω the notation recalls that f is a functional examples of functional can be the value of field k at a given location r 0 f 0 k k r 0 the weighted average f f k 1 v v d d r f r k r in which f r is a fixed function that does not depend on k the functional derivative of a functional f k is defined by the following equation l i m ϵ 0 f k ϵ δ k f k ϵ v d d r δ f δ k r δ k r here δk is an arbitrary perturbation the functional derivative has a supplementary spatial argument that corresponds in the case of partial derivatives to the choice of the variable with respect to which the derivative is performed in the examples of f 0 k and f f k one has δ f 0 δ k r δ r r 0 δ f f δ k r f r v it gives the sensibility of the variation of f with respect to a local variation of its argument k at position r nth order functional derivatives can be defined as well as a taylor formula replacing summations by integrations if f x is a standard differentiable real function one has the chain derivative formula δ f f δ k r d f d x f δ f δ k r if p r obeys a laplace equation such as k r p r 0 putting k r k δ k r one obtains k δ k r p r δ p r 0 denoting by δp r the first order variation of potential p r with respect to k r one obtains that δp r obeys the following equation valid at first order a 1 k δ p r δ k r p r as the unperturbed potential p r fulfills the boundary conditions at the domain boundary δ p r 0 on dirichlet boundaries and same conditions for the normal flux at the neumann boundaries this equation has the formal solution a 2 δ p r v d d r g k r r δ k r p 0 r here gk r r is the green s function of the laplace operator that obeys the following equations to be supplemented by consistent boundary conditions k g k r r δ r r g k r x 0 1 r 0 y g k r y 0 1 r 0 so one gets finally after one integration by parts a 3 δ p r δ k r r g k r r p 0 r this result may recovered directly applying the operator δ δ k r at both sides of eq 3 providing k δ p r δ k r δ r r p r which is equivalent to eq a 3 note that the base conductivity field k may also depend on position or be equal to k the choice depends on the application at hand appendix b second order estimation of the average effective conductivity in order to illustrate the functional formalism we carry out with this tool the classical second order expansion of the effective conductivity dagan 1989 the taylor expansion eq 10 gives directly a second order series expansion that will provide the desired expansion after averaging b 1 k eff k 1 2 ω d d r d d r δ 2 k eff δ k r δ k r c k r r the main task is to evaluate explicitly the second order functional derivative that may be simplified in the following form using eq c 1 differentiated once more time δ 2 k eff δ k r δ k r 1 ω 2 p 0 r δ p r δ k r in that equation p 0 r is the non perturbed potential the derivative δ p r δ k r is given by eq a 2 so we get after substitution b 2 δ p r δ k r 1 k g r r p 0 r in that expression g r r is the green s function of laplace operator 2 this explains the factor 1 k note that due to the boundary conditions that break full translational invariance of the system this green s function does not depend only on the argument r r gathering these results in eq b 1 and using the fact that p 0 r e x one obtains b 3 k eff k 1 k ω ω d d r d d r p 0 r δ p r δ k r c k r r k 1 k ω ω d d r d d r r x r x g r r c k r r assuming that ω 1 d is large compared with the integral scale i one can replace g r r by the free space green s function g r r this is equivalent to estimate the green s function assuming that the boundary conditions are rejected at infinity using the correlation function isotropy the integral can be simplified using a classical trace argument yielding k eff k 1 k 1 d c k r 0 up to the same order of approximation this formula can be rewritten on a more usual form as k eff exp log k e 1 2 1 d c log k r 0 for log normal media this formula is equivalent to the llm conjecture eq 1 the second order expansion is thus recovered for large averaging volumes with a quite concise calculation appendix c second order estimation of the variance of the effective conductivity the variance of the effective conductivity is given by c k eff l k eff 2 k eff 2 k eff k eff 2 using the taylor expansion eq 10 and keeping only second order terms one gets dropping the averaging symbol under the integral sign a procedure that is straightforward within the stochastic context dagan 1989 gelhar 1993 hristopulos 2020 the procedure would be different using a volume averaging technique involving boundary of averaging volume corrections hassanizadeh and gray 1979 whitaker 2013 c k eff l ω d d r d d r δ k eff δ k r δ k eff δ k r δ k r δ k r the quantity δ k eff δ k r can be written under a simple form c 1 δ k eff δ k r p ω x 2 ω p r 2 derivation of eq c 1 is straightforward using the variational characterization eq 9 that can be differentiated directly with respect to δk r ignoring the implicit dependence of p r 2 with δk r that is known to vanish thanks to the variational characterization this eq c 1 relates the influence of a local hydraulic conductivity change on keff to the local potential gradient this result was already derived using similar methods by jacquard 1965 and generalized to obtain shape derivatives of effective conductivity with respect to geometrical shape of inclusions by noetinger 2013 one can remark that in a location where p r 0 the local conductivity has no influence at all on the large scale conductivity it is screened by other patterns that imply that there is no flow at this location this is a rather intuitive result thus using eq c 1 we obtain c 2 c k eff l 1 ω 2 ω d d r d d r p r 2 p ω x 2 p r 2 p ω x 2 δ k r δ k r as we are seeking a second order expansion of the variance of effective conductivity the local quantity p r 2 p ω x 2 resp p r 2 p ω x 2 may be replaced by 1 getting c 3 c k eff l 1 ω 2 ω d d r d d r δ k r δ k r after averaging introducing the pair correlation function c k r r δ k r δ k r of the hydraulic conductivity fluctuations we get a formula already obtained by rubin and gómez hernández 1990 sánchez vila et al 1995 wen and gómez hernández 1996 c 4 c k eff l 1 ω 2 ω d d r d d r c k r r note that for small averaging volume size l compared to the integral scale i this formula gives by direct inspection c k eff l c k r 0 on the other limit assuming that the unit volume size is very large compared to the underlying integral scale one gets the asymptotic behavior c 5 c k eff l 1 ω ω d d r c k r for large l one has the scaling c 6 l d i d c k eff l ω d d r c k r i d the factor ld id corresponds to the number of independent statistical units that belong to volume ω this scaling corresponds thus to a central limit theorem characterizing the emergence of a deterministic large scale effective conductivity in other words the system exhibits self averaging properties eqs c 4 and c 5 are solved for the particular case of the gaussian covariance in c 2 c1 improved estimation of the variance mean field approximation the preceding development is limited to small variances in order to find an improved approximation one can use eq c 2 written on an equivalent form k eff 2 k eff 2 1 ω 2 ω d d r d d r k r p r 2 p ω x 2 k r p r 2 p ω x 2 δ k r k r δ k r k r now one can replace k r p r 2 and k r p r 2 by their common average value k eff p ω x 2 so one gets k eff 2 k eff 2 k eff 2 1 ω 2 ω d d r d d r δ k r k r δ k r k r up to this order of approximation the result can be identified with the variance of log keff and the equation can be rewritten as c log k eff l log k eff 2 log k eff 2 1 ω 2 ω d d r d d r δ log k r δ log k r this equation up to this order of approximation is equivalent to eq c 4 by replacing every occurrence of a conductivity by the corresponding logarithm so c 7 c log k eff l 1 ω 2 ω d d r d d r c log k r r the resulting formula is similar to eq c 4 replacing the covariance function by the log conductivity covariance function for the special case of lognormal media this is a quite natural transformation the same can be done with the simplified formula c 5 c2 gaussian covariance case in the isotropic gaussian case the covariance function is given by c k r c k r 0 e r 2 2 i c 2 the integral factorizes and after changing variables x x ic we obtain c 8 c k eff l c k r 0 i c l 2 d l 2 i c l 2 i c l 2 i c l 2 i c d x d y e x y 2 2 d c k r 0 i c l 2 d π 2 l 2 i c l 2 i c d y erf l i c 2 y 2 2 erf l i c 2 y 2 2 d c k r 0 i c l 2 d 2 π l i c erf 2 l i c 2 e l 2 2 i c 2 2 d considering small upscaling volume l small compared with ic we obtain c k eff l c k r 0 as it should in the opposite case considering large upscaling volumes l provides c k eff l c k r 0 2 π i c l d this is a form of a central limit theorem for effective conductivity quantifying the variance reduction leading to convergence of the effective conductivity for large averaging volume finally using the simplified expression c 5 one gets after integration c 9 c k eff l c k r 0 2 π i c l erf 2 2 l i c d it shares the same asymptotic behavior for extreme l than the exact 13 the same calculations can be carried out for c log k eff l and give the same results using c log k r 0 and the same spatial dependance appendix d second order evaluation of the average of block kdiss the block equivalent conductivity kdiss ϑ is given by eq 15 decomposing the conductivity as k r k δ k r one can carry out a second order expansion of kdiss ϑ k d i s s ϑ ϑ d d r k δ k p 0 δ p 2 λ d p 0 δ p 2 this formula must be expanded up to second order in a series expansion of δk note that the technique that was presented in appendix b cannot be followed directly because the variational formulation is efficient at the scale of the whole ω only not on every subvolume ϑ in order to simplify notations we introduce δp r as the first order variation due to a variation δk r the numerator can be expanded up to second order discarding third order terms to yield d 1 ϑ d d r k δ k p 0 δ p 2 ϑ d d r k δ k 1 2 p 0 δ p ϑ d d r k δ p 2 an analogous calculation can be carried out for the denominator recalling that p 0 r e x d 2 λ d p 0 δ p 2 λ d p 0 2 2 p 0 δ p δ p 2 λ d 1 2 p 0 δ p δ p 2 combining eq d 1 and the second order expansion of eq d 2 many cancellations occur yielding still at same order of approximation k d i s s ϑ k 1 λ d 2 ϑ d d r δ k p 0 δ p p 0 δ p k ϑ d d r δ p 2 δ p 2 one has in the general case p 0 p 0 e x it can be observed that in the case of small averaging volume ϑ k d i s s ϑ k r as it should all the contributions cancel each other because in that limit a volume average is equal to the local value δ p δ p further simplifications can be obtained using green s formula on the term k ϑ dd r δp 2 combined with eq a 1 that drives δp yielding d 3 k d i s s ϑ k 1 λ d ϑ d d r δ k p 0 δ p 1 λ d 2 ϑ d d r δ k p 0 δ p ϑ d d r k δ p 2 k λ d ϑ d d 1 r δ p δ p n 1 λ d ϑ d d 1 r δ k δ p p 0 n we obtain after statistical averaging k d i s s ϑ k 1 λ d ϑ d d r ω d d r p 0 r δ p r δ k r c r r 1 λ d ϑ d d r 2 δ k p 0 δ p k δ p 2 k λ d ϑ d d 1 r δ p δ p n 1 λ d ϑ d d 1 r δ k δ p p 0 n using δ p r δ k r 1 k g r r p 0 r and combining this result with eq d 2 one obtains d 4 k d i s s ϑ k 1 k l d ϑ d d r ω d d r r x r x g r r c k r r 1 λ d ϑ d d r 2 δ k p 0 δ p k δ p 2 k λ d ϑ d d 1 r δ p δ p n 1 λ d ϑ d d 1 r δ k δ p p 0 n it can be checked by direct inspection that first line of this formula compares well with eq b 3 the other contributions are finite size effects that cancel if ϑ ω they explain the observed differences in the numerical tests if ϑ tends to zero k d i s s ϑ k supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103594 appendix e supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
496,a new generation of smart stormwater systems promises to reduce the need for new construction by enhancing the performance of the existing infrastructure through real time control smart stormwater systems dynamically adapt their response to individual storms by controlling distributed assets such as valves gates and pumps this paper introduces a real time control approach based on reinforcement learning rl which has emerged as a state of the art methodology for autonomous control in the artificial intelligence community using a deep neural network a rl based controller learns a control strategy by interacting with the system it controls effectively trying various control strategies until converging on those that achieve a desired objective this paper formulates and implements a rl algorithm for the real time control of urban stormwater systems this algorithm trains a rl agent to control valves in a distributed stormwater system across thousands of simulated storm scenarios seeking to achieve water level and flow set points in the system the algorithm is first evaluated for the control of an individual stormwater basin after which it is adapted to the control of multiple basins in a larger watershed 4 km 2 the results indicate that rl can very effectively control individual sites performance is highly sensitive to the reward formulation of the rl agent generally more explicit guidance led to better control performance and more rapid and stable convergence of the learning process while the control of multiple distributed sites also shows promise in reducing flooding and peak flows the complexity of controlling larger systems comes with a number of caveats the rl controller s performance is very sensitive to the formulation of the deep neural network and requires a significant amount of computational resource to achieve a reasonable performance enhancement overall the controlled system significantly outperforms the uncontrolled system especially across storms of high intensity and duration a frank discussion is provided which should allow the benefits and drawbacks of rl to be considered when implementing it for the real time control of stormwater systems an open source implementation of the full simulation environment and control algorithms is also provided keywords real time control reinforcement learning smart stormwater systems 1 introduction urban stormwater and sewer systems are being stressed beyond their intended design the resulting symptoms manifest themselves in frequent flash floods laris karklis and muyskens 2017 and poor receiving water quality watson et al 2016 presently the primary solution to these challenges is the construction of new infrastructure such as bigger pipes basins wetlands and other distributed storage assets redesigning and rebuilding the existing stormwater infrastructure to keep in pace with the evolving inputs is cost prohibitive for most communities kerkez et al 2016 furthermore infrastructure is often upgraded on a site by site basis and rarely optimized for system scale performance present approaches rely heavily on the assumption that these individual upgrades will add up to cumulative benefits while the contrary has actually been illustrated by studies evaluating system level outcomes emerson et al 2005 the changing and highly variable nature of weather and urban environments demands stormwater solutions that can more rapidly adapt to changing community needs instead of relying on new construction a new generation of smart stormwater systems promises to dynamically re purpose existing stormwater systems these systems will use streaming sensor data to infer real time state of a watershed and respond via real time control of distributed control assets such as valves gates and pumps kerkez et al 2016 by achieving system level coordination between many distributed control points the size of infrastructure needed to reduce flooding and improve water quality will become smaller this presents a non trivial control challenge however as any automated decisions must be carried with regard to public safety and must account for the physical complexity inherent to urban watersheds mullapudi et al 2017 schütze et al 2004 in this paper we investigate deep reinforcement learning for the real time control of stormwater systems this approach builds on very recent advances in the artificial intelligence community which have primarily focused on the control of complex autonomous systems such as robots and autonomous vehicles mnih et al 2015 lillicrap et al 2015 in this novel formulation our algorithm will learn the best real time control strategy for a distributed stormwater system by efficiently quantifying the space of all possible control actions in simple terms the algorithm attempts various control actions until discovering those that have the desired outcomes while such an approach has shown promise across many other domains it is presently unclear how it will perform and scale when used for the real time control of water systems specifically urban drainage networks the fundamental contribution of this paper is a formulation of a control algorithm for urban drainage systems based on reinforcement learning given the risk to property and public safety it is imprudent to hand over the control of a real world watershed to a computer that learns by mistake as such a secondary contribution is the evaluation of the reinforcement learning algorithm across a series of simulations which span various drainage system complexities and storms the results will illustrate the benefits limitations and requirement of reinforcement learning when applied to urban stormwater systems to our knowledge this is the first formulation of deep reinforcement learning for the control of stormwater systems the results of this study stand to support a foundation for future studies on the role of artificial intelligence in the control of urban water systems 1 1 real time control of urban drainage systems since the european union s directive on water policy the european parliament and the council of european union 2000 there has been a significant push towards the adoption of real time control for improving wastewater and sewer systems schütze et al 2004 mollerup et al 2016 many of these control approaches fall broadly under the categories of real time control rtc control decisions made solely on the real time state of the system and model predictive control mpc decisions that account for predicted future conditions during the past decade mpc has emerged as a state of the art methodology for developing control strategies and analyzing their potential for controlling urban drainage and sewer networks in simulated setting mpc has been used to regulate dissolved oxygen in the flows to aquatic bodies mahmoodian et al 2017 control inflows to wastewater treatment plants pleau et al 2005 and enhance the system level performance and coordination of sewer network assets mollerup et al 2016 meneses et al 2018 these and many other simulation based studies wong and kerkez 2018 have illustrated the benefits of control the biggest of which is the ability to cost effectively re purpose existing assets in real time without the need to build more passive infrastructure the performance of mpc depends on the extent to which the underlying process can be approximated using a linear model van overloop 2006 a benefit of this linearity assumption is the ability to analytically evaluate the stability robustness and convergence properties of the controller ogata 2011 which is valuable when providing safety and performance guarantees network dynamics of storm and sewer systems and transformations of the pollutants in runoff are known to be heavily non linear this demands a number of approximations and a high level of expertise when applying model predictive control furthermore real world urban watersheds are prone to experiencing pipes blockages sensor breakdowns valve failures or other adverse conditions adapting and re formulating linear control models to such non linear conditions is difficult but is being addressed by promising research wong and kerkez 2018 the constraints of linear approximations and the need for adaptive control algorithms open the door to exploring other control methodologies such as the one presented in this paper 2 reinforcement learning across the artificial intelligence and behavioral research communities reinforcement learning rl has emerged as a state of the art methodology for autonomous control and planning systems unlike in classical feedback control where the controller carries out a pre tuned and analytical control action a rl controller i e a rl agent learns a control strategy by interacting with the system effectively trying various control strategies until learning those that work well rather than just learning one particular control strategy a rl agent continuously attempts to improve its control strategy by assimilating new information and evaluating new control strategies sutton and barto 1998 rl can be used in a model free context since the system s dynamics are implicitly learned by evaluating various control actions leveraging the recent advancements in deep neural networks and the computational power afforded by the high performance clusters hpcs rl agents have been able to plan complex tasks such as observing pixels to play video games at a human level mnih et al 2015 defeating world champions in the game of go silver et al 2017b achieving superhuman performance in chess silver et al 2017a controlling high speed robots kober et al 2013 and navigating autonomous vehicles ng et al 2006 despite the wide adoption of deep neural network based reinforcement learning deep rl in various disciplines of engineering its adoption in civil engineering disciplines has been limited abdulhai and kattan 2003 bhattacharya et al 2003 castelletti et al 2010 deep rl control has yet to be applied to the real time control of urban drainage systems deep rl agents approximate underlying system dynamics implicitly hence not requiring a simplified or linearized control model sutton and barto 1998 a deep rl agent instantaneously identifies a control action by observing the network dynamic thus reducing delay in the decision process mnih et al 2015 silver et al 2017a the explorative nature of the deep rl agents also enables the methodology to adapt its control strategy to changing conditions of the system sutton and barto 1998 hence reinforcement learning shows promise as a potential alternative or supplement to existing control methods for water systems to that end the goal of this paper is to formulate and evaluate of reinforcement learning for the real time control of urban drainage systems the specific contributions of the paper are 1 the formulation and implementation of a reinforcement learning algorithm for the real time non predictive control of urban stormwater systems 2 an evaluation of the control algorithm under a range of storm inputs and network complexities single stormwater basins and an entire network as well as an equivalence analysis that compares the approach to passive infrastructure solutions 3 a fully open sourced implementation of the control algorithm to promote transparency and permit for the direct application of the methods to other systems shared on open storm org 3 methods 3 1 reinforcement learning for stormwater systems when formulated as a reinforcement learning rl problem the control of stormwater systems can be fully described by an agent and environment fig 1 the environment represents an urban stormwater system and the agent represents the entity controlling the system at any given time t the agent takes a control action at e g opening a valve or turning on a pump by observing any number of states st e g water levels or flows in the environment based on the outcomes of its action the agent receives a reward rt from the environment the reward is formulated to reflect the specific control objectives for example an agent could receive positive reward for preventing flooding or a negative reward for causing flooding by quantifying these rewards in response to various actions over time the agent learns the control strategy that will achieve its desired objective sutton and barto 1998 the agent s control actions in any given state are governed by its policy π formally the policy is a mapping from a given state to the agent s actions 1 π s t r n a t r the primary objective of the rl control problem is to learn a policy that maximizes the total reward earned by the agent notation used in this paper is summarized in table 1 while the reward rt at the end of each control action teaches the agent the immediate desirability of taking a particular action for a given state it does not necessarily covey any information about the long term desirability of that action for many water systems maximizing short term rewards will not necessarily lead to the best long term outcomes an agent controlling a watershed or stormwater system should have the ability to take individual actions in the context of the entire storm duration for example holding water in a detention basin may initially provide high rewards since it reduces downstream flooding but may lead to upstream flooding if a storm becomes too large instead of choosing an action that maximizes the reward rt at time t the agent seeks to maximize the expected long term reward described by state value v or action value q 2 v s t e k 0 γ k r t k 1 s t 3 q s t a t e k 0 γ k r t k 1 s t a t the state value provides an estimate of the reward received for an instantaneous action as well as potential future rewards that may arise after state st discounted with a factor γ 0 γ 1 the action value provides a similar estimate conditioned on taking an action at in state st the discount factor γ governs the temporal context of the reward for example a γ of 0 forces the agent to maximize the instantaneous reward while a γ of 1 forces it to equally weigh all the rewards it might receive for present and future outcomes γ is specific to the system being controlled and can vary based on the control objective sutton and barto 1998 a rl agent can learn to control a system by learning the policy directly sutton et al 2000 alternatively the agent can learn the state value or action value estimates and follow a policy that guides it towards the states with high estimates sutton and barto 1998 several methods based on dynamic programming watkins and dayan 1992 sutton 1991 and monte carlo sampling sutton and barto 1998 have been developed to learn the functions that estimate the policy and value functions while these algorithms were computationally efficient and provided guarantees on the convergence their application was limited to simple systems whose state action space can be approximated using lookup tables and linear functions sutton and barto 1998 mnih et al 2013 given the scale and the complexity of urban watersheds and stormwater networks a simple lookup table or a linear function cannot effectively approximate the policy or value functions for each state the agent may encounter while controlling the system as a simple example considering just ten valves in a stormwater system and assuming that each valve has ten possible control actions closed 10 open 20 open this gives 1010 10 billion possible actions that can be taken at any given state making it computationally impossible to build an explicit lookup table for all possible states this however is where very recent advances in deep learning become important it has been shown that for systems with large state action spaces such as stormwater systems these functions can be approximated by a deep neural network sutton and barto 1998 mnih et al 2015 deep neural networks are a class of feed forward artificial neural networks with large layers of interconnected neurons this deeply layered structure permits the network to approximate highly complex functions hornik et al 1989 such as those needed for rl based control each layer in the network generates its output by processing the weighted outputs from the previous layer this means that each layer s output is more complex and abstract than its previous layer given the emergence of cheap and powerful computational hardware over the past decade in particular graphical processing units gpus and high performance clusters hpcs deep neural networks and their variants have emerged as the state of the art in the approximation of complex functions in large state spaces lecun et al 2015a this makes them a good candidate for approximating the complex dynamics across stormwater systems for purposes of this paper a brief mathematical summary of deep neural networks is provided in si section 1 3 2 deep q learning deep reinforcement learning agents deep rl use deep neural networks as approximators for value or policy functions to control complex environments in their relatively recent and seminal deep q network dqn paper mnih et al 2015 demonstrated the first such algorithm which used deep neural networks to train a deep rl agent to play atari video games at a human level this algorithm identifies the optimal control strategy for achieving an objective by learning a function that estimates the action values or q values this function i e q function maps a given state action pair st at to the action value estimate at the beginning of the control problem the agent does not know its environment this is reflected by assigning random q values for all state action pairs over time as the agent takes actions new information obtained from the environment is used to update these initial random estimates after each action the reward obtained from the environment is used to incorporate the new knowledge 4 q s t a t q s t a t α r t 1 γ max a q s t 1 a q s t a t the more actions an agent takes at any given state the closer it gets to converging to the true action value function sutton and barto 1998 the α step size parameter governs how much weight is placed on the new knowledge sutton and barto 1998 an agent will choose an action that maximizes its long term reward this process is known as exploitation since it greedily seeks to maximize a known long term reward this may not always be the best choice however since taking another action may lead the agent to discover a potentially better action which it has not yet tried as such the agent also needs to explore its environment this is accomplished by taking a random action periodically just in case this action leads to better outcomes in such a formulation the exploration vs exploitation is addressed via a ϵ greedy policy where the agent explores for ϵ percent of time and chooses an action associated with the highest action value for the rest this gives the final policy for the rl agent 5 π s t random a ϵ arg max a q s t a e l s e ϵ is often set at a high value e g 50 at the start of the learning process and gradually reduced to a lower value e g 1 as the agent identifies a viable control strategy while there have been prior attempts to approximate the action value function using deep neural networks they were met with minimal success since the learning is highly unstable mnih et al 2015 mnih et al 2015 addressed this by introducing a replay buffer and an additional target neural network the replay buffer acts as the rl agent s memory which records only its most recent experience e g the past 103 states transitions and rewards during the training the rl agent randomly samples data from the replay buffer computes the neural network s loss and updates its weights using stochastic gradient descent 6 l o s s r t γ max a q s t 1 a q s t a t 2 this random sampling enables the training data to be uncorrelated and has been found to improve the training process the target neural network q has the same network architecture as the main network q but acts as a moving target to help stabilize the training process by reducing the variance mnih et al 2015 unlike the neural network approximating q whose weights are constantly updated using gradient decent q weights are updated sporadically e g every 104 timesteps for more background information mnih et al 2015 and lillicrap et al 2015 provide an in depth discussion on the importance of replay memory and target neural networks in training deep rl agents 3 3 evaluation here we investigate the real time control of urban stormwater infrastructure using deep reinforcement learning to begin we formulate and evaluate reward functions for the control of an individual stormwater basin we then extend these lessons to the control of a larger interconnected stormwater network given the relatively nascent nature of deep rl the need to account for public safety and the desire to evaluate multiple control scenarios a real world evaluation is outside of the scope of this paper as such our analysis will be carried out in simulation as a stepping stone toward real world deployment in the future to promote transparency and broader adoption the entire source code examples and implementation details of our implementation are shared freely as an open source package 1 1 https github com klabum rl storm control 3 4 study area motivated by a real world system we apply rl control to a stormwater system inspired by an urban watershed in ann arbor michigan usa 2 our choice to use this watershed is motivated by the fact that it has been retrofitted by our group with wireless sensors and control valves already bartos et al 2017 and will in the future serve as a real world testbed for the ideas proposed in this paper this headwater catchment features 11 interconnected stormwater basins that handle the runoff generated across 4km 2 of predominantly urbanized and impervious sub catchment areas a stormwater management model swmm of the watershed has been developed and calibrated in prior peer reviewed studies wong and kerkez 2018 it is assumed that each controlled basin in the system is equipped with a 1m 2 square gate valve the valves can be partially opened or closed during the simulation which represents the action taken by a rl agent the states of the control problem are given by the water levels and outflows at each controlled location given the small size of the study area as well as the need to constrain this initial study uniform rainfall across the study area is assumed groundwater base flow is assumed to be negligible which has also been confirmed in prior studies wong and kerkez 2018 3 5 analysis prior deep rl studies have revealed that performance is dependent on the formulation of reward function quality of neural networks approximating action value function as well as the size of state space sutton and barto 1998 henderson et al 2017 this creates a number of knobs whose sensitivity must be evaluated before any conclusion can be reached regarding the ability to apply deep rl to control real stormwater systems as such in this paper we formulate a series of experiments across two scenarios to characterize deep rl s ability to control stormwater systems in the first scenario we control a single valve at the outlet of the watershed comparing its particular performance under various reward function formulations given that deep rl has not been used to control water systems this will constrain the size of the state space to establish a baseline assessment of the methodology in the second scenario we scale these findings to simultaneously control multiple valves across the broader watershed and to analyze sensitivity to function approximation neural networks finally the system scale scenario is subjected to storm inputs of varying intensities and durations to provide broader comparison of the benefits of the controlled system in relation to the uncontrolled system 3 6 scenario 1 control of a single basin in this scenario we train a deep rl agent to control the most downstream detention basin in the network basin 1 in fig 2 this basin was chosen because it experiences the total runoff generated in the watershed and because its actions have direct impact on downstream water bodies at any given point in time the rl agent is permitted to set the basin s valve to a position between fully closed or open in 1 increments i e 0 1 2 100 open based on the water height in the basin all other upstream basins remain uncontrolled the overall control objective is to keep the water height state ht in the basin below a flooding threshold h max and the outflows from the basin state ft below a desired downstream flooding or stream erosion threshold f 7 h t h m a x 8 f t f three reward functions are formulated to reach this objective each incorporating more explicit guidance in the form of constraints to guide the rl agent in the first reward function the rl agent receives a positive reward for maintaining the basin s outflow below the specified threshold a negative reward for exceeding the threshold as well as a larger but less likely negative reward if the basin overflows 9 r 1 s t 1 f t f 1 f t f 10 h t h m a x the reward function is represented visually in the first row of fig 3 this reward function formulation is inspired from the classic inverted pendulum problem watkins and dayan 1992 where the agent receives 1 for success and 1 for failure the second reward function is formulated to exhibit a more complex and gradual reward structure in lieu of a jagged or discontinuous plus minus reward structure the agent is rewarded for reaching flows that are close to the desired flow threshold it has been shown that more smooth and continuous rewards such as this may help the agent converge onto a solution faster sutton and barto 1998 aytar et al 2018 visually the reward function looks like a parabola fig 3 where the maximum reward is achieved when the flow threshold is met exactly 10 r 2 s t c 1 f t c 2 f t c 3 c 1 c 2 and c 3 are constants representing the scaling and inflection points of the parabola here we choose c 1 400 e c 2 0 05 and c 3 0 15 to maintain the general scale of the first reward function note that this formulation does not explicitly include the local constraint on the basin s water level since the agent gets implicitly penalized by receiving a negative reward for low outflows the third reward function seeks to provide the most explicit guidance to the rl agent by embedding the most relative amount of information third column fig 3 in this heuristic formulation the agent receives the highest reward for keeping the basin empty water levels and flows equal to zero intuitively this reward formulation seeks to drain all of the water from the basin as fast as possible without exceeding the flow and height thresholds if water level in the pond rises the agent gets penalized thus forcing it to release water if flows remain below the flow threshold f the agent is penalized linearly proportional to the water level in the basin with a more severe factor applied if the height of the basin exceeds the height threshold h if the outflow exceeds the flow threshold f an even more severe penalty is incurred 11 r 3 s t c 1 c 2 h t h t h f t f c 1 c 3 h t h t h f t f c 4 f t c 2 h t c 5 h t h f t f c 4 f t c 3 h t c 5 h t h f t f the penalty rates are governed by a set of five parameters c c 1 c 2 c 3 c 4 c 5 which were parametrized 2 0 0 25 1 5 10 3 to match the scales of the other two reward functions to illustrate the transferability of the control approach to variable inflows storage volumes and the location of a basin in the network control by an agent trained on the third reward function is evaluated on four basins basins 1 4 6 and 9 in fig 2 these basins are chosen to represent distinct components in the network basin 1 is located at the outlet of the watershed basin 4 is the largest in the network and receives flows from the two major branches in the system basin 6 is the largest of the upstream basins while basin 9 is a smaller basin in series with larger basins please see si section 5 additionally to analyze the performance and sensitivity of the agent to the reward function formulation two variants of the third reward are evaluated in the supplementary information please see si section 4 section of this paper the goal of this analysis is to determine the sensitivity of the agent s performance to the choice of mathematical equations in the reward function 3 7 scenario 2 controlling multiple basins this scenario evaluates the ability of an agent to control multiple distributed stormwater basins specifically basins 1 3 and 4 fig 2 are selected for control because they experience the largest average volume during a storm event which often corresponds with the larger control potential schütze et al 2008 it is assumed that at any time step the agent has knowledge of the water levels and valve positions for each of these basins as well as the basin between them basin 2 in fig 2 thus quadrupling the number of observed states compared to the control of a single basin the action space must also be reduced to make the problem computationally tractable for the control of the single basin there are 101 possible actions at any given time step valve opening with 1 granularity for three controlled basins this increases to 1013 possible control actions at any given time step this is not only intractable given our own computational resources but is well beyond the size of any action space covered in other rl literature here to reduce the action space the agent is allowed to only throttle the valves specifically at any time step agent can only open or close the valve in 5 increments or leave its position unchanged this results in only three possible actions for each site and thus 27 or 33 possible actions for the entire network the agent receives an individual reward for controlling each basin these rewards are weighted equally and added together to provide a total reward for controlling the larger system the reward for controlling each basin is given by 12 r 4 s t c 1 h t c 4 h t h f t f c 2 h t 2 c 3 c 4 h t h f t f c 1 h t f f t c 5 h t h f t f c 2 h t 2 c 3 f f t c 5 h t h f t f where reward parameters c c 1 c 2 c 3 c 4 c 5 are chosen as 0 5 1 3 1 10 to retain the relative scale of the single basin reward formulations this reward seeks to accomplish practically identical objectives as the third reward function used in the single basin control scenario the difference is the quadratic penalty term that is applied to the height constraint this modification is made to provide the agent with a more explicit guidance in response to the relatively larger state space compared to the single basin control scenario in the rare instance that flooding should occur at one of the basins agent also receives an additional penalty 3 8 simulation implementation and evaluation beyond the formulation of the reward function the use of rl for the control of stormwater systems faces a number of non trivial implementational challenges the first relates to the hydrologic and hydraulic simulation framework which needs to support the integration of a simulation engine that is compatible with modern rl toolchains the second challenge relates to the implementation of the actual rl toolchain which must include the deep neural network training algorithms most popular stormwater modeling packages such as the stormwater management model swmm rossman 2010 and mike urban elliott and trowsdale 2007 are designed for event based or long term simulation namely the model is initialized inputs are selected and the model run continues until the rainfall terminates or simulation times out while these packages support some rudimentary controls the control logic is pre configured and limited to simple site scale action such as opening a valve when level exceed a certain value the ability to support system level control logic is limited let alone the ability to interface with external control algorithms such as the one proposed in this paper to that end we implement a step wise co simulation approach that was described in one of our prior studies mullapudi et al 2017 our co simulation framework separates the hydraulic solver from the control logic by halting the hydraulic model at every time step the states from the model water levels flows etc are then transferred to the external control algorithm which makes recommendation on which actions to take valves settings pump speeds etc here we adopt a python based swmm package for simulating the stormwater network riaño briceño et al 2016 this allows the entire toolchain to be implemented using a high level programming environment without requiring any major modifications to hydraulic solvers that are often implemented in low level programming languages and difficult to fuse with modern libraries and open source packages while other or more complex stormwater or hydrologic models could be substituted model choice is not necessarily the main contribution of this paper rather we content that swmm adequately captures runoff and flow dynamics for the purposes of this paper swmm models the flow of water in the network using an implicit dynamic wave equation solver rossman 2010 this allows it to effectively model the nuanced conditions e g back channel flows flooding that might develop in the network though real time control furthermore the authors have access to a calibrated version of the model for this particular study area which has been documented in a prior study cdmsmith 2015 wong and kerkez 2018 one major task is the implementation of the deep neural network that is used to approximate the rl agent s action value function deep neural networks are computationally expensive to train lecun et al 2015b efficient implementation address this by leveraging a computer s graphical processing unit gpu to carry out this training which is a non trivial task to that end a number of open source and community libraries have emerged the most popular of which is tensorflow abadi et al 2016 this state of the art library has been used in some of the most well cited rl papers and benchmark problems which is the reason we choose to adopt it for this study tensorflow is a python library and can be seamlessly interfaced with our python based stormwater model implementation multiple agents are trained and evaluated across the two scenarios eight for the control of individual basins across multiple reward function variants and basins and two agents for the multi basin control a deep neural network is designed and implemented to learn the action value function of each agent the network contains 2 layers with 50 neurons per layer this network is set up with a relu activation function goodfellow et al 2016 in the internal layers and a linear activation function in the final layer the full parameters used in the study including those for gradient descent and the dqn are provided in the si section 2 of this paper a root mean square propagation rmsprop goodfellow et al 2016 form of stochastic gradient descent is used for updating the neural network as this variant of gradient descent has been observed to improve convergence one storm event is used to train these agents the swmm model is forced with a 25 year storm event of 6 hour duration and 63 5 mm intensity fig 3 this event generates a total runoff of 3670 639 m 3 with a peak flow of 0 35 m 3 s at the outlet of watershed the agents are provided with an operational water level goal h of 2 m flooding level h max of 3 5 m and outflow exceedance threshold of f of 0 10 m 3 s 1 it is important to note that the outflow threshold in particular serves more as an approximate guide rather than exact requirement since the discrete valve settings used by the rl agents may not allow the exact setpoint to be physically realizable e g throttling a valve by 5 will limit outflow precision correspondingly these setpoints are chosen to reflect realistic flooding and stream erosion goals in the study watershed agents are trained on a tesla k20 gpus on university of michigan s advanced research computing s high performance cluster the second multi basin control agent uses the same neural network architecture of the other multi basin rl control agent trained this time however using batch normalization ioffe and szegedy 2015 batch normalization is the process of normalizing the signals between the internal layers of the neural network to minimize the internal covariance shift and has been observed to improve the performance of the deep rl agents lillicrap et al 2015 ioffe and szegedy 2015 provides a detailed discussion on batch normalization the performance of each agent is evaluated by comparing the rl controlled hydrographs and water levels to those that are specified in the reward functions for the agents controlling the individual basins this is used to determine the importance of the reward formulation on performance reward convergence and training period duration for the multi basin control scenario the same approach is used to quantify overall performance comparing this time the agent that uses the batch normalized neural network to the agent that uses the non normalized network to evaluate the ability of a rl agent to control storms that it is not trained on a final analysis is carried out since the agent controlling multiple basins presents the most complex of the scenarios it is first trained on one of storms and evaluated on a spectrum of storm events with varying return periods 1 to 100 years and durations 5 min to 24 hours these storm events are generated based on the scs type ii curve and historical rainfall intensities for the study region scs 1986 the performance of the agent across these 70 storms is compared to the uncontrolled system to evaluate the boarder benefits of real time control for comparison with an other control algorithm we also implement and compare the performance of rl to an equal filling degree controller which seeks to control the volume in each basin to achieve equal relative filling schütze et al 2018 implementation details of the equal filling algorithm can be found in the si section3 we also evaluate the performance of the rl controller on a back to back storm event 3 h 5 year event followed by a 2 h 2 year event to allow for a comparison between the controlled and uncontrolled system a non negative performance metric is introduced to capture the magnitude and time that the system deviates from desired water level and flows thresholds specifically across a duration t the final performance p adds together the deviation of all n controlled sites from their desired water level ph and flow thresholds pf where 13 p h h h h h h h h 100 h h h m a x 0 o t h e r w i s e 14 p f f 10 f f f f 0 o t h e r w i s e 15 p n 1 n i 0 t p h h i n p f f i n a relatively lower performance value is more desirable since it implies that the system is not flooding nor exceeding desired flow thresholds 4 results 4 1 scenario 1 control of single basin the ability of a rl agent to control a stormwater basin is highly sensitive to the reward function formulation generally a more complex reward function one that embeds more information and explicit guidance performs better as illustrated in fig 3 each column of the figure corresponds with an individual rl agent each of which is trained using a different reward function r 1 r 2 r 3 the reward functions are plotted in the first row while the reward received during training is plotted in the second row the training period is quantified in terms of episodes each of which corresponds to one full swmm simulation across an entire storm the third and fourth rows in the figure compare the uncontrolled flows and water levels respectively for the episode that resulted in the highest reward the rl agent that uses the simplest reward function has the relatively worst performance fig 3 first column even after 5000 training episodes a week of real world simulation time the mean reward does not converge to a stable value playing back the episode that resulted in the highest reward fig 3 rows 3 4 column 1 reveals that the rl agent does retain more water than would have been held in the uncontrolled basin while this lowers the peak flows relative to the uncontrolled basin the rl agent is generally not able to keep flows below the desired threshold more importantly the rl agent s control actions begin oscillating and become unstable toward the middle of the simulation in this episode the agent keeps the water level in the basin relatively constant by opening the valve very briefly to release just a small amount of water this chattering behavior shown as a close up in the figure results in an unstable outflow pattern that oscillates in a step wise fashion between 0 m 3 s and 0 18 m 3 s for various practical reasons such rapid control actions are not desirable since the rl agent never once receives a positive reward it may have converged onto an undesirable local minimum during the training providing more time for training does not appear to resolve this issue which may also suggest that a stable solution cannot be derived using this particular reward formulation embedding more explicit guidance harder constraints into the reward formulation improves the control performance of the rl agent fig 3 second column when the second and more continuous reward function is used by the agent the highest reward episode reveals that the rl agent is relatively more effective at maintaining flows at a constant value unlike the rl agent using the simple step wise reward function the rl agent using the parabolic reward function has more opportunities to receive smaller more gradual rewards during most of the episode this increased flexibility allows the second rl agent to receive positive rewards and keep the outflow below a flow threshold of 0 14 m 3 s while relatively improved the rl agent using the parabolic reward also does not converge to a stable reward value however toward the end of the episode this rl agent also carries out irregular and sudden control actions by opening and closing the valve in short bursts in this case the rl agent is oscillating between a maximum valve open and minimum valve closed reward rather than taking advantage of variable rewards in other configurations this suggests that the agent has either not yet learned a better strategy or again that a stable solution cannot be converged upon using this particular reward formulation this speaks to the need for more explicit constraints as well since a real world stormwater system could not be throttled in this fashion simply put the reward formulations used in this case was too simple to achieve realistically desirable outcomes the rl agent using the third and most constrained formulation exhibits the relatively best control performance this agent regulates flow and water levels in a relatively gradual and smooth manner unlike in the case of the other two rl agents after 3500 training episodes the third agent does converge to a steady reward evaluating the episode resulting in the highest reward fig 3 rows 3 4 column 3 the desired flat outflow hydrograph is achieved no unstable or oscillatory control actions are evident as in the case of the other two reward functions the agent is able to maintain flows below a constant threshold of 0 15 m 3 s while this is not the exact threshold that was specified 0 1 m 3 s it is close considering that the achievable threshold is dependent on water levels and the ability to only throttle the valve in 1 increments as stated in the methods section matching the exact threshold may not be physically realizable in any given situation due to constraints enforced by discretized throttling furthermore the rl agent must balance the desired outflow against the possibility of flooding and is thus more likely to release a greater amount of water than is specified by the threshold interestingly this agent does not change its valve configuration at all rather it keeps its valve 54 open the entire time of the simulation which allows it to meet a mostly constant outflow given the specific inflows overall the general shape of the outflows is improved compared to the uncontrolled scenario furthermore an added benefit of real time control is that the overall volume of water leaving the basin is also reduced by 50 due to infiltration similar to the third reward function agents trained on the 3a and 3b reward functions are successfully able to maintain the outflows close to the threshold during the stormevent figure 3 in si section 4 while these reward functions may appear similar the solution identified by their respective agents differs this is a result of the difference between the decay rates in the exponential and squared terms performance of the agent trained on the 3a and 3b reward functions si section 4 indicates that the ability of the agent to identify a viable control strategy is not dependent on the choice of equations used for the creating the reward functions but rather on the general shape of the reward function in the domain the agent using the third reward function trained on basin 1 is able to control basins 4 6 and 9 without any further modifications si section 5 figure 4 the agent in this formulation makes its control decisions only based on the depth at the current time step and does not incorporate any predictions hence the ability of the controller to shape of outflows should not dependent on the location of the basin in the network magnitude of inflows or the storage curves our simulation results indicate the same though the degree to which the agent is able to achieve the objective is governed by these physical constraints its ability to discover a solution is not influenced by them this scenario which focuses on the control of a single site emphasizes the importance of the reward function formulation in rl based control of stormwater systems the complexity of the reward formulation plays an important role in allowing the rl agent to learn a control policy to meet the desired hydrologic outcomes the importance of reward formulations has been acknowledged in prior studies sutton and barto 1998 ng et al 1999 generally reward functions with more explicit guidance lead to a more rapid convergence of a control policy while avoiding unintended control actions such as the chattering behavior seen in fig 3 in fact prior studies have attributed such erratic control actions to the use of oversimplified reward functions ng et al 1999 but have offered little specificity or concrete design recommendations that could be used to avoid such actions as such our approach heuristically evaluates reward formulations of increasing complexity until arriving at one that mostly meets desired outcomes this introduces an element of design into the use of rl for the real time control of stormwater as one cannot simply rely on the implicit black box nature of neural networks to solve a control problem under complex system dynamics the reward function needs to embed enough information to help guide the rl agent to a stable solution this introduces only a limited amount of overhead as reward functions can be intuitively formulated by someone with knowledge of basic hydrology for control of individual basins the reward function presented here should be directly transferable if more complex outcomes are desired modifications to the reward function may need to be carried out objectively the convergence of the reward will serve as one quality measure of control performance the ultimate performance of rl for the control of individual sites will however need to be assessed on a case by case basis by a designer familiar with the application taking the baseline lessons learned during the control of a single basin the second scenario can now evaluate the simultaneous control of multiple basins 4 2 scenario 2 control of multiple basins when trained using the generic feed forward neural network configuration that was used for the control of a single basin the rl agent controlling multiple assets was unable to converge to a stable reward even after 25 000 episodes of training fig 4 this totaled to 52 days of computation time on our gpu cluster after which the training procedure was halted due to lack of improved reward overall learning performance was low in this configuration not only did the learning procedure not converge to a stable reward but the vast majority of rewards were negative given this observation this ineffective neural network was then replaced with one that was batch normalized the agent using the batch normalized neural network achieved a higher average reward than the agent with a generic feed forward neural network fig 4 furthermore the agent using the batch normalized neural network achieved a relatively high rewards early on in the training process thus making it more computationally favorable while beyond the scope of this study this suggests that the choice of neural network architecture is likely a major design factor in the successful implementation of rl based stormwater control even with batch normalization the rl agent did not consistently return to the same reward or improve its performance when perturbed the exploration in its policy caused the rl agent to oscillate between local reward maxima similar outcomes have been observed in a number of rl benchmark problems henderson et al 2017 mnih et al 2015 which exhibited a high degree of sensitivity to their exploration policy prior studies have noted that the exploration exploitation balance is difficult to parameterize because neural networks tend to latch onto a local optimum larochelle et al 2009 as such it is likely that the lack of convergence observed in this scenario was caused by the use of a neural network as a function approximator forcing neural networks to escape local minima is still an ongoing problem of research osband et al 2016 nonetheless even without a consistent optimum the maximum reward obtained during this scenario can still be used as part of an effective control approach selecting the episode with the highest reward revealed the actions taken by the rl agent during the training storm fig 5 the figure compares the controlled and uncontrolled states of the four basins during a 25 year 6 hour storm event showing the depth in each basin inflows outflows and control actions taken by the rl agent though basin 2 is not explicitly controlled by the controller given that the water level and outflows in this basin are impacted by the actions taken in the upstream basin we have chosen to present its response no flooding occurred during this simulation which means that the reward received by the rl agent was entirely obtained by meeting outflow objectives the valves on basins 1 and 3 throttled between 100 and 95 open which for all practical considerations could be considered uncontrolled as such the rl agent in this scenario earned its reward by only controlling the most upstream basin in this network while the outcome of control was somewhat favorable compared to the uncontrolled systems the playback of the highest reward in fig 5 does not show drastically different outcomes control of the 4th basin shifted the timing of the outflows from the basin but did not reduce its outflows this resulted in improvements at the 1st 2nd and 3rd basins by delaying flows from the 4th basin the rl agent allowed the downstream basins to drain first and to spend less time exceeding the flow threshold interestingly the rl agent did not control basin 1 even while the single basin control scenario makes it is clear that a more favorable outcome can be achieved with control fig 3 as such a better control solution may exist but converging to such a solution using a neural network approximator is difficult this likely has to do with the larger state action space while the site scale rl agent was only observing water level at one basin the system level rl agent had to track levels and flows across more basins which increases the complexity of the learning problem the rewards received by the rl agent in the scenario are cumulative which means that improvement at just a few sites can lead to better rewards without the need to control all of them increasing the opportunity to obtain rewards thus increases the occurrence of local minima during the learning phase in the single basin control scenario the rl agent can immediately observe the impact of its control actions in the system scale scenario more time is needed to observe water flows through the broader system which means that the impact of a control action may not be observed until later timesteps this introduces a challenge as the rl agent has to learn the temporal dynamics of the system this challenge has been observed in other rl studies which have shown better performance for reactive rl problems as opposed to those that are based on the need to plan for future outcomes aytar et al 2018 the need to include planning is still an active area of rl research potential emerging solutions include adversarial play silver et al 2017b 2017a model based rl clavera et al 2018 and policy based learning schulman et al 2017 the benefits of these approaches have recently been demonstrated for other application domains and should be considered in the future for the control of water systems it is important to note that fig 5 represents an evaluation of the rl agent for one storm only namely the training storm realistically the control system will need to respond to storms of varying durations and magnitudes as an example the rl agent s response to a 24 hour 10 year storm is shown in fig 6 performance of the controller in controlling a back to back event is presented in si section6 here the rl agent outperformed the uncontrolled system much more notably compared to the training storm the controlled outflows were much closer to the desired threshold even when only one basin was controlled this broader performance is captured in fig 7 which quantifies performance eq 15 across a spectrum of storm inputs fig 7 compares the uncontrolled system to the rl controlled system both the controlled and uncontrolled systems perform equally well during small magnitude and short events e g the training storm in fig 5 the benefits of control become more pronounced for larger events starting at 10 year storms and those that last over 2 hours this visualization holistically captures the benefits of real time control by highlighting new regions of performance and showing how control can push existing infrastructure to perform beyond its original design 5 discussion given the recent emergence and popularity of reinforcement learning much research still remains to be conducted to evaluate its potential to serve as a viable methodology for the rtc of water systems our study brings to light a number of benefits and challenges associated with this task arguably it seems that the major benefit of using rl to control water systems is the ability to simply hand the learning problem to a computer without needing to worry about the many complexities non linearities and formulations that often complicate other control approaches however as this study showed this comes with a number of considerable caveats these include the challenges associated with formulating rewards choosing function approximators deciding on the complexity of the control problem as well as contending with practical implementation details our study confirms that the performance of rl based stormwater control is sensitive to the formulation of the reward function which has also been observed in other application domains ng et al 1999 the formulation of the reward function requires domain expertise and an element of subjectivity since the rl agent has to be given guidance on what constitutes appropriate actions in the first scenario it was shown that a reward function that is too simple may lead to adverse behavior such as the chattering or sudden actions the reward may also not converge to a stable solution since the neural network can take advantage of the simple objective to maximize rewards using sudden or unintuitive actions the formulation of the problem which depends heavily on neural networks also makes it difficult to determine why one specific reward function may work better than another increasing the complexity of the reward function by incorporating more explicit guidance was shown to help guide the rl agent to a more desirable outcome in other control approaches such as genetic algorithms or model predictive control the design of reward is an iterative process and sometimes involves anticipating fringe cases to improve the robustness of the controller similar to these approaches we can however begin using this early study to formulate a number of practical considerations when formulating reward functions define the reward function for entire domain of the state action space ensuring that it distinguishes the desirable actions from the undesirable ones ensure that the reward function represents a specific hydrologic response that the controller is to achieve while anticipating as much as possible alternate and adverse hydrologic responses that the controller may discover to maximize the reward function relax the mathematical formulation of the reward function and focus rather on the two above points e g the shape of a reward surface rather than its specific mathematical form reward formulations are an ongoing research area in the rl community and some formal methods have recently been proposed to provide a more rigorous framework for reward synthesis fu et al 2017 these formulations should be investigated in the future even when the choice of reward function is appropriate or justifiable the control performance can become sensitive to the approximation function which in our case took the form of a deep neural network choosing the architecture and structure of the underlying network becomes an application dependent task and can often only be derived through trial and error sutton and barto 1998 henderson et al 2017 secondly for challenging control problems such as the one studied here learning the mapping between rewards and all possible control decisions becomes a complex task the neural network must be exposed to as many inputs and outputs as possible which is computationally demanding in our study we ran simulations for many real world months on a high performance cluster but it appears that the learning phase could have continued even longer this in fact has been the approach of many successful studies in the rl community where the number of computers and graphical processing units can be in the hundreds espeholt et al 2018 openai 2018 this was not feasible given our own resources but could be evaluated in the future aside from the formulation of the learning functions and framework the actual complexity and objectives of the control problem may pose a barrier to implementation we showed that a rl agent can learn how to control a single stormwater basin effectively but that controlling many sites at the same time is difficult a major reason is the increase in the number of states and actions that must be represented using the neural network while computational time may remedy this concern the structure of the neural network may also need to be altered in a system scale stormwater scenario actions at one location may influence another location at a later time as such the agent would benefit from a planning based approach which considered not only current states but future forecasts as well such planning based approaches have been proposed in the rl literature and should be investigated to determine if they lead to an improvement in performance clavera et al 2018 depeweg et al 2016 furthermore model based approaches have also recently been introduced and could allow some elements of the neural network to be replaced with an actual physical or numerical stormwater model gu et al 2016 such approaches should be evaluated in the future since they may permit more domain knowledge from water resources to be embedded into training the controller it is important to note that the equal filling algorithm outperforms the rl agent in this study si section 3 it achieves the objective of maintaining the outflow below the desired threshold without causing flooding since equal filling outperforms rl it could very well be considered a superior choice in this study that said developing and deploying equal filling often requires an intuitive understanding of the system and require a highly manual tuning of parameters while it may be relatively straightforward to design control approaches in smaller systems and simple outcomes such as the one in this study developing coordinated control strategies for large scale systems with multiple objective might not be as easy as such we see rl based control as a long term goal which should be investigated in future studies across bigger scales and complex outcomes our study presents an initial goal toward the broader study of rl based stormwater control after which an comprehensive apples to apples comparison may be possible with current state of the art approaches finally the use of rl for the control of stormwater systems is underpinned by a number of practical challenges computational demands are very high especially compared to competing approaches such as dynamical systems control model predictive control or load balancing approachs troutman et al 2020 while computational resources are becoming cheaper the resources require to carry out this study were quite significant and time demanding since actions taken by neural networks cannot easily be explained and explicit guarantees cannot be provided this may limit adoption by decision makers who may consider the approach a black box it is also unlikely that the control of real world stormwater systems will simply be handed over to a computer that learns through mistakes rather simulation based scenarios will be required first it has recently been shown as long as a realistic simulator is used in our case swmm then the agent can be effectively trained in a virtual environment before refining its strategy in the real world openai 2018 6 conclusion this paper introduced an algorithm for the real time control of urban drainage systems based on reinforcement learning rl while rl has been used successfully in the computer science communities to our knowledge this is the first instance for which it has been explicitly adopted for the real time control of urban water systems the methodology and our implementation show promise for using rl as an automated tool chain to learn control rules for simple storage assets such as individual storage basin however the use of rl for more complex system topologies faces a number of challenges as laid out in the discussion simultaneously controlling multiple distributed stormwater assets across large urban areas is a non trivial problem regardless of the control methodology to that end the concepts initial results and formulations provided by this paper should help build a foundation to support rl as a viable option for stormwater control the source code accompanying this paper should also allow others to evaluate many other possible architectures and parameterizations that could be used to improve the results presented in the paper declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by great lakes protection fund grant number 1035 and the us national science foundation grant number 1737432 we also would like to acknowledge the support provided by advanced research computing at the university of michigan ann arbor supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103600 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
496,a new generation of smart stormwater systems promises to reduce the need for new construction by enhancing the performance of the existing infrastructure through real time control smart stormwater systems dynamically adapt their response to individual storms by controlling distributed assets such as valves gates and pumps this paper introduces a real time control approach based on reinforcement learning rl which has emerged as a state of the art methodology for autonomous control in the artificial intelligence community using a deep neural network a rl based controller learns a control strategy by interacting with the system it controls effectively trying various control strategies until converging on those that achieve a desired objective this paper formulates and implements a rl algorithm for the real time control of urban stormwater systems this algorithm trains a rl agent to control valves in a distributed stormwater system across thousands of simulated storm scenarios seeking to achieve water level and flow set points in the system the algorithm is first evaluated for the control of an individual stormwater basin after which it is adapted to the control of multiple basins in a larger watershed 4 km 2 the results indicate that rl can very effectively control individual sites performance is highly sensitive to the reward formulation of the rl agent generally more explicit guidance led to better control performance and more rapid and stable convergence of the learning process while the control of multiple distributed sites also shows promise in reducing flooding and peak flows the complexity of controlling larger systems comes with a number of caveats the rl controller s performance is very sensitive to the formulation of the deep neural network and requires a significant amount of computational resource to achieve a reasonable performance enhancement overall the controlled system significantly outperforms the uncontrolled system especially across storms of high intensity and duration a frank discussion is provided which should allow the benefits and drawbacks of rl to be considered when implementing it for the real time control of stormwater systems an open source implementation of the full simulation environment and control algorithms is also provided keywords real time control reinforcement learning smart stormwater systems 1 introduction urban stormwater and sewer systems are being stressed beyond their intended design the resulting symptoms manifest themselves in frequent flash floods laris karklis and muyskens 2017 and poor receiving water quality watson et al 2016 presently the primary solution to these challenges is the construction of new infrastructure such as bigger pipes basins wetlands and other distributed storage assets redesigning and rebuilding the existing stormwater infrastructure to keep in pace with the evolving inputs is cost prohibitive for most communities kerkez et al 2016 furthermore infrastructure is often upgraded on a site by site basis and rarely optimized for system scale performance present approaches rely heavily on the assumption that these individual upgrades will add up to cumulative benefits while the contrary has actually been illustrated by studies evaluating system level outcomes emerson et al 2005 the changing and highly variable nature of weather and urban environments demands stormwater solutions that can more rapidly adapt to changing community needs instead of relying on new construction a new generation of smart stormwater systems promises to dynamically re purpose existing stormwater systems these systems will use streaming sensor data to infer real time state of a watershed and respond via real time control of distributed control assets such as valves gates and pumps kerkez et al 2016 by achieving system level coordination between many distributed control points the size of infrastructure needed to reduce flooding and improve water quality will become smaller this presents a non trivial control challenge however as any automated decisions must be carried with regard to public safety and must account for the physical complexity inherent to urban watersheds mullapudi et al 2017 schütze et al 2004 in this paper we investigate deep reinforcement learning for the real time control of stormwater systems this approach builds on very recent advances in the artificial intelligence community which have primarily focused on the control of complex autonomous systems such as robots and autonomous vehicles mnih et al 2015 lillicrap et al 2015 in this novel formulation our algorithm will learn the best real time control strategy for a distributed stormwater system by efficiently quantifying the space of all possible control actions in simple terms the algorithm attempts various control actions until discovering those that have the desired outcomes while such an approach has shown promise across many other domains it is presently unclear how it will perform and scale when used for the real time control of water systems specifically urban drainage networks the fundamental contribution of this paper is a formulation of a control algorithm for urban drainage systems based on reinforcement learning given the risk to property and public safety it is imprudent to hand over the control of a real world watershed to a computer that learns by mistake as such a secondary contribution is the evaluation of the reinforcement learning algorithm across a series of simulations which span various drainage system complexities and storms the results will illustrate the benefits limitations and requirement of reinforcement learning when applied to urban stormwater systems to our knowledge this is the first formulation of deep reinforcement learning for the control of stormwater systems the results of this study stand to support a foundation for future studies on the role of artificial intelligence in the control of urban water systems 1 1 real time control of urban drainage systems since the european union s directive on water policy the european parliament and the council of european union 2000 there has been a significant push towards the adoption of real time control for improving wastewater and sewer systems schütze et al 2004 mollerup et al 2016 many of these control approaches fall broadly under the categories of real time control rtc control decisions made solely on the real time state of the system and model predictive control mpc decisions that account for predicted future conditions during the past decade mpc has emerged as a state of the art methodology for developing control strategies and analyzing their potential for controlling urban drainage and sewer networks in simulated setting mpc has been used to regulate dissolved oxygen in the flows to aquatic bodies mahmoodian et al 2017 control inflows to wastewater treatment plants pleau et al 2005 and enhance the system level performance and coordination of sewer network assets mollerup et al 2016 meneses et al 2018 these and many other simulation based studies wong and kerkez 2018 have illustrated the benefits of control the biggest of which is the ability to cost effectively re purpose existing assets in real time without the need to build more passive infrastructure the performance of mpc depends on the extent to which the underlying process can be approximated using a linear model van overloop 2006 a benefit of this linearity assumption is the ability to analytically evaluate the stability robustness and convergence properties of the controller ogata 2011 which is valuable when providing safety and performance guarantees network dynamics of storm and sewer systems and transformations of the pollutants in runoff are known to be heavily non linear this demands a number of approximations and a high level of expertise when applying model predictive control furthermore real world urban watersheds are prone to experiencing pipes blockages sensor breakdowns valve failures or other adverse conditions adapting and re formulating linear control models to such non linear conditions is difficult but is being addressed by promising research wong and kerkez 2018 the constraints of linear approximations and the need for adaptive control algorithms open the door to exploring other control methodologies such as the one presented in this paper 2 reinforcement learning across the artificial intelligence and behavioral research communities reinforcement learning rl has emerged as a state of the art methodology for autonomous control and planning systems unlike in classical feedback control where the controller carries out a pre tuned and analytical control action a rl controller i e a rl agent learns a control strategy by interacting with the system effectively trying various control strategies until learning those that work well rather than just learning one particular control strategy a rl agent continuously attempts to improve its control strategy by assimilating new information and evaluating new control strategies sutton and barto 1998 rl can be used in a model free context since the system s dynamics are implicitly learned by evaluating various control actions leveraging the recent advancements in deep neural networks and the computational power afforded by the high performance clusters hpcs rl agents have been able to plan complex tasks such as observing pixels to play video games at a human level mnih et al 2015 defeating world champions in the game of go silver et al 2017b achieving superhuman performance in chess silver et al 2017a controlling high speed robots kober et al 2013 and navigating autonomous vehicles ng et al 2006 despite the wide adoption of deep neural network based reinforcement learning deep rl in various disciplines of engineering its adoption in civil engineering disciplines has been limited abdulhai and kattan 2003 bhattacharya et al 2003 castelletti et al 2010 deep rl control has yet to be applied to the real time control of urban drainage systems deep rl agents approximate underlying system dynamics implicitly hence not requiring a simplified or linearized control model sutton and barto 1998 a deep rl agent instantaneously identifies a control action by observing the network dynamic thus reducing delay in the decision process mnih et al 2015 silver et al 2017a the explorative nature of the deep rl agents also enables the methodology to adapt its control strategy to changing conditions of the system sutton and barto 1998 hence reinforcement learning shows promise as a potential alternative or supplement to existing control methods for water systems to that end the goal of this paper is to formulate and evaluate of reinforcement learning for the real time control of urban drainage systems the specific contributions of the paper are 1 the formulation and implementation of a reinforcement learning algorithm for the real time non predictive control of urban stormwater systems 2 an evaluation of the control algorithm under a range of storm inputs and network complexities single stormwater basins and an entire network as well as an equivalence analysis that compares the approach to passive infrastructure solutions 3 a fully open sourced implementation of the control algorithm to promote transparency and permit for the direct application of the methods to other systems shared on open storm org 3 methods 3 1 reinforcement learning for stormwater systems when formulated as a reinforcement learning rl problem the control of stormwater systems can be fully described by an agent and environment fig 1 the environment represents an urban stormwater system and the agent represents the entity controlling the system at any given time t the agent takes a control action at e g opening a valve or turning on a pump by observing any number of states st e g water levels or flows in the environment based on the outcomes of its action the agent receives a reward rt from the environment the reward is formulated to reflect the specific control objectives for example an agent could receive positive reward for preventing flooding or a negative reward for causing flooding by quantifying these rewards in response to various actions over time the agent learns the control strategy that will achieve its desired objective sutton and barto 1998 the agent s control actions in any given state are governed by its policy π formally the policy is a mapping from a given state to the agent s actions 1 π s t r n a t r the primary objective of the rl control problem is to learn a policy that maximizes the total reward earned by the agent notation used in this paper is summarized in table 1 while the reward rt at the end of each control action teaches the agent the immediate desirability of taking a particular action for a given state it does not necessarily covey any information about the long term desirability of that action for many water systems maximizing short term rewards will not necessarily lead to the best long term outcomes an agent controlling a watershed or stormwater system should have the ability to take individual actions in the context of the entire storm duration for example holding water in a detention basin may initially provide high rewards since it reduces downstream flooding but may lead to upstream flooding if a storm becomes too large instead of choosing an action that maximizes the reward rt at time t the agent seeks to maximize the expected long term reward described by state value v or action value q 2 v s t e k 0 γ k r t k 1 s t 3 q s t a t e k 0 γ k r t k 1 s t a t the state value provides an estimate of the reward received for an instantaneous action as well as potential future rewards that may arise after state st discounted with a factor γ 0 γ 1 the action value provides a similar estimate conditioned on taking an action at in state st the discount factor γ governs the temporal context of the reward for example a γ of 0 forces the agent to maximize the instantaneous reward while a γ of 1 forces it to equally weigh all the rewards it might receive for present and future outcomes γ is specific to the system being controlled and can vary based on the control objective sutton and barto 1998 a rl agent can learn to control a system by learning the policy directly sutton et al 2000 alternatively the agent can learn the state value or action value estimates and follow a policy that guides it towards the states with high estimates sutton and barto 1998 several methods based on dynamic programming watkins and dayan 1992 sutton 1991 and monte carlo sampling sutton and barto 1998 have been developed to learn the functions that estimate the policy and value functions while these algorithms were computationally efficient and provided guarantees on the convergence their application was limited to simple systems whose state action space can be approximated using lookup tables and linear functions sutton and barto 1998 mnih et al 2013 given the scale and the complexity of urban watersheds and stormwater networks a simple lookup table or a linear function cannot effectively approximate the policy or value functions for each state the agent may encounter while controlling the system as a simple example considering just ten valves in a stormwater system and assuming that each valve has ten possible control actions closed 10 open 20 open this gives 1010 10 billion possible actions that can be taken at any given state making it computationally impossible to build an explicit lookup table for all possible states this however is where very recent advances in deep learning become important it has been shown that for systems with large state action spaces such as stormwater systems these functions can be approximated by a deep neural network sutton and barto 1998 mnih et al 2015 deep neural networks are a class of feed forward artificial neural networks with large layers of interconnected neurons this deeply layered structure permits the network to approximate highly complex functions hornik et al 1989 such as those needed for rl based control each layer in the network generates its output by processing the weighted outputs from the previous layer this means that each layer s output is more complex and abstract than its previous layer given the emergence of cheap and powerful computational hardware over the past decade in particular graphical processing units gpus and high performance clusters hpcs deep neural networks and their variants have emerged as the state of the art in the approximation of complex functions in large state spaces lecun et al 2015a this makes them a good candidate for approximating the complex dynamics across stormwater systems for purposes of this paper a brief mathematical summary of deep neural networks is provided in si section 1 3 2 deep q learning deep reinforcement learning agents deep rl use deep neural networks as approximators for value or policy functions to control complex environments in their relatively recent and seminal deep q network dqn paper mnih et al 2015 demonstrated the first such algorithm which used deep neural networks to train a deep rl agent to play atari video games at a human level this algorithm identifies the optimal control strategy for achieving an objective by learning a function that estimates the action values or q values this function i e q function maps a given state action pair st at to the action value estimate at the beginning of the control problem the agent does not know its environment this is reflected by assigning random q values for all state action pairs over time as the agent takes actions new information obtained from the environment is used to update these initial random estimates after each action the reward obtained from the environment is used to incorporate the new knowledge 4 q s t a t q s t a t α r t 1 γ max a q s t 1 a q s t a t the more actions an agent takes at any given state the closer it gets to converging to the true action value function sutton and barto 1998 the α step size parameter governs how much weight is placed on the new knowledge sutton and barto 1998 an agent will choose an action that maximizes its long term reward this process is known as exploitation since it greedily seeks to maximize a known long term reward this may not always be the best choice however since taking another action may lead the agent to discover a potentially better action which it has not yet tried as such the agent also needs to explore its environment this is accomplished by taking a random action periodically just in case this action leads to better outcomes in such a formulation the exploration vs exploitation is addressed via a ϵ greedy policy where the agent explores for ϵ percent of time and chooses an action associated with the highest action value for the rest this gives the final policy for the rl agent 5 π s t random a ϵ arg max a q s t a e l s e ϵ is often set at a high value e g 50 at the start of the learning process and gradually reduced to a lower value e g 1 as the agent identifies a viable control strategy while there have been prior attempts to approximate the action value function using deep neural networks they were met with minimal success since the learning is highly unstable mnih et al 2015 mnih et al 2015 addressed this by introducing a replay buffer and an additional target neural network the replay buffer acts as the rl agent s memory which records only its most recent experience e g the past 103 states transitions and rewards during the training the rl agent randomly samples data from the replay buffer computes the neural network s loss and updates its weights using stochastic gradient descent 6 l o s s r t γ max a q s t 1 a q s t a t 2 this random sampling enables the training data to be uncorrelated and has been found to improve the training process the target neural network q has the same network architecture as the main network q but acts as a moving target to help stabilize the training process by reducing the variance mnih et al 2015 unlike the neural network approximating q whose weights are constantly updated using gradient decent q weights are updated sporadically e g every 104 timesteps for more background information mnih et al 2015 and lillicrap et al 2015 provide an in depth discussion on the importance of replay memory and target neural networks in training deep rl agents 3 3 evaluation here we investigate the real time control of urban stormwater infrastructure using deep reinforcement learning to begin we formulate and evaluate reward functions for the control of an individual stormwater basin we then extend these lessons to the control of a larger interconnected stormwater network given the relatively nascent nature of deep rl the need to account for public safety and the desire to evaluate multiple control scenarios a real world evaluation is outside of the scope of this paper as such our analysis will be carried out in simulation as a stepping stone toward real world deployment in the future to promote transparency and broader adoption the entire source code examples and implementation details of our implementation are shared freely as an open source package 1 1 https github com klabum rl storm control 3 4 study area motivated by a real world system we apply rl control to a stormwater system inspired by an urban watershed in ann arbor michigan usa 2 our choice to use this watershed is motivated by the fact that it has been retrofitted by our group with wireless sensors and control valves already bartos et al 2017 and will in the future serve as a real world testbed for the ideas proposed in this paper this headwater catchment features 11 interconnected stormwater basins that handle the runoff generated across 4km 2 of predominantly urbanized and impervious sub catchment areas a stormwater management model swmm of the watershed has been developed and calibrated in prior peer reviewed studies wong and kerkez 2018 it is assumed that each controlled basin in the system is equipped with a 1m 2 square gate valve the valves can be partially opened or closed during the simulation which represents the action taken by a rl agent the states of the control problem are given by the water levels and outflows at each controlled location given the small size of the study area as well as the need to constrain this initial study uniform rainfall across the study area is assumed groundwater base flow is assumed to be negligible which has also been confirmed in prior studies wong and kerkez 2018 3 5 analysis prior deep rl studies have revealed that performance is dependent on the formulation of reward function quality of neural networks approximating action value function as well as the size of state space sutton and barto 1998 henderson et al 2017 this creates a number of knobs whose sensitivity must be evaluated before any conclusion can be reached regarding the ability to apply deep rl to control real stormwater systems as such in this paper we formulate a series of experiments across two scenarios to characterize deep rl s ability to control stormwater systems in the first scenario we control a single valve at the outlet of the watershed comparing its particular performance under various reward function formulations given that deep rl has not been used to control water systems this will constrain the size of the state space to establish a baseline assessment of the methodology in the second scenario we scale these findings to simultaneously control multiple valves across the broader watershed and to analyze sensitivity to function approximation neural networks finally the system scale scenario is subjected to storm inputs of varying intensities and durations to provide broader comparison of the benefits of the controlled system in relation to the uncontrolled system 3 6 scenario 1 control of a single basin in this scenario we train a deep rl agent to control the most downstream detention basin in the network basin 1 in fig 2 this basin was chosen because it experiences the total runoff generated in the watershed and because its actions have direct impact on downstream water bodies at any given point in time the rl agent is permitted to set the basin s valve to a position between fully closed or open in 1 increments i e 0 1 2 100 open based on the water height in the basin all other upstream basins remain uncontrolled the overall control objective is to keep the water height state ht in the basin below a flooding threshold h max and the outflows from the basin state ft below a desired downstream flooding or stream erosion threshold f 7 h t h m a x 8 f t f three reward functions are formulated to reach this objective each incorporating more explicit guidance in the form of constraints to guide the rl agent in the first reward function the rl agent receives a positive reward for maintaining the basin s outflow below the specified threshold a negative reward for exceeding the threshold as well as a larger but less likely negative reward if the basin overflows 9 r 1 s t 1 f t f 1 f t f 10 h t h m a x the reward function is represented visually in the first row of fig 3 this reward function formulation is inspired from the classic inverted pendulum problem watkins and dayan 1992 where the agent receives 1 for success and 1 for failure the second reward function is formulated to exhibit a more complex and gradual reward structure in lieu of a jagged or discontinuous plus minus reward structure the agent is rewarded for reaching flows that are close to the desired flow threshold it has been shown that more smooth and continuous rewards such as this may help the agent converge onto a solution faster sutton and barto 1998 aytar et al 2018 visually the reward function looks like a parabola fig 3 where the maximum reward is achieved when the flow threshold is met exactly 10 r 2 s t c 1 f t c 2 f t c 3 c 1 c 2 and c 3 are constants representing the scaling and inflection points of the parabola here we choose c 1 400 e c 2 0 05 and c 3 0 15 to maintain the general scale of the first reward function note that this formulation does not explicitly include the local constraint on the basin s water level since the agent gets implicitly penalized by receiving a negative reward for low outflows the third reward function seeks to provide the most explicit guidance to the rl agent by embedding the most relative amount of information third column fig 3 in this heuristic formulation the agent receives the highest reward for keeping the basin empty water levels and flows equal to zero intuitively this reward formulation seeks to drain all of the water from the basin as fast as possible without exceeding the flow and height thresholds if water level in the pond rises the agent gets penalized thus forcing it to release water if flows remain below the flow threshold f the agent is penalized linearly proportional to the water level in the basin with a more severe factor applied if the height of the basin exceeds the height threshold h if the outflow exceeds the flow threshold f an even more severe penalty is incurred 11 r 3 s t c 1 c 2 h t h t h f t f c 1 c 3 h t h t h f t f c 4 f t c 2 h t c 5 h t h f t f c 4 f t c 3 h t c 5 h t h f t f the penalty rates are governed by a set of five parameters c c 1 c 2 c 3 c 4 c 5 which were parametrized 2 0 0 25 1 5 10 3 to match the scales of the other two reward functions to illustrate the transferability of the control approach to variable inflows storage volumes and the location of a basin in the network control by an agent trained on the third reward function is evaluated on four basins basins 1 4 6 and 9 in fig 2 these basins are chosen to represent distinct components in the network basin 1 is located at the outlet of the watershed basin 4 is the largest in the network and receives flows from the two major branches in the system basin 6 is the largest of the upstream basins while basin 9 is a smaller basin in series with larger basins please see si section 5 additionally to analyze the performance and sensitivity of the agent to the reward function formulation two variants of the third reward are evaluated in the supplementary information please see si section 4 section of this paper the goal of this analysis is to determine the sensitivity of the agent s performance to the choice of mathematical equations in the reward function 3 7 scenario 2 controlling multiple basins this scenario evaluates the ability of an agent to control multiple distributed stormwater basins specifically basins 1 3 and 4 fig 2 are selected for control because they experience the largest average volume during a storm event which often corresponds with the larger control potential schütze et al 2008 it is assumed that at any time step the agent has knowledge of the water levels and valve positions for each of these basins as well as the basin between them basin 2 in fig 2 thus quadrupling the number of observed states compared to the control of a single basin the action space must also be reduced to make the problem computationally tractable for the control of the single basin there are 101 possible actions at any given time step valve opening with 1 granularity for three controlled basins this increases to 1013 possible control actions at any given time step this is not only intractable given our own computational resources but is well beyond the size of any action space covered in other rl literature here to reduce the action space the agent is allowed to only throttle the valves specifically at any time step agent can only open or close the valve in 5 increments or leave its position unchanged this results in only three possible actions for each site and thus 27 or 33 possible actions for the entire network the agent receives an individual reward for controlling each basin these rewards are weighted equally and added together to provide a total reward for controlling the larger system the reward for controlling each basin is given by 12 r 4 s t c 1 h t c 4 h t h f t f c 2 h t 2 c 3 c 4 h t h f t f c 1 h t f f t c 5 h t h f t f c 2 h t 2 c 3 f f t c 5 h t h f t f where reward parameters c c 1 c 2 c 3 c 4 c 5 are chosen as 0 5 1 3 1 10 to retain the relative scale of the single basin reward formulations this reward seeks to accomplish practically identical objectives as the third reward function used in the single basin control scenario the difference is the quadratic penalty term that is applied to the height constraint this modification is made to provide the agent with a more explicit guidance in response to the relatively larger state space compared to the single basin control scenario in the rare instance that flooding should occur at one of the basins agent also receives an additional penalty 3 8 simulation implementation and evaluation beyond the formulation of the reward function the use of rl for the control of stormwater systems faces a number of non trivial implementational challenges the first relates to the hydrologic and hydraulic simulation framework which needs to support the integration of a simulation engine that is compatible with modern rl toolchains the second challenge relates to the implementation of the actual rl toolchain which must include the deep neural network training algorithms most popular stormwater modeling packages such as the stormwater management model swmm rossman 2010 and mike urban elliott and trowsdale 2007 are designed for event based or long term simulation namely the model is initialized inputs are selected and the model run continues until the rainfall terminates or simulation times out while these packages support some rudimentary controls the control logic is pre configured and limited to simple site scale action such as opening a valve when level exceed a certain value the ability to support system level control logic is limited let alone the ability to interface with external control algorithms such as the one proposed in this paper to that end we implement a step wise co simulation approach that was described in one of our prior studies mullapudi et al 2017 our co simulation framework separates the hydraulic solver from the control logic by halting the hydraulic model at every time step the states from the model water levels flows etc are then transferred to the external control algorithm which makes recommendation on which actions to take valves settings pump speeds etc here we adopt a python based swmm package for simulating the stormwater network riaño briceño et al 2016 this allows the entire toolchain to be implemented using a high level programming environment without requiring any major modifications to hydraulic solvers that are often implemented in low level programming languages and difficult to fuse with modern libraries and open source packages while other or more complex stormwater or hydrologic models could be substituted model choice is not necessarily the main contribution of this paper rather we content that swmm adequately captures runoff and flow dynamics for the purposes of this paper swmm models the flow of water in the network using an implicit dynamic wave equation solver rossman 2010 this allows it to effectively model the nuanced conditions e g back channel flows flooding that might develop in the network though real time control furthermore the authors have access to a calibrated version of the model for this particular study area which has been documented in a prior study cdmsmith 2015 wong and kerkez 2018 one major task is the implementation of the deep neural network that is used to approximate the rl agent s action value function deep neural networks are computationally expensive to train lecun et al 2015b efficient implementation address this by leveraging a computer s graphical processing unit gpu to carry out this training which is a non trivial task to that end a number of open source and community libraries have emerged the most popular of which is tensorflow abadi et al 2016 this state of the art library has been used in some of the most well cited rl papers and benchmark problems which is the reason we choose to adopt it for this study tensorflow is a python library and can be seamlessly interfaced with our python based stormwater model implementation multiple agents are trained and evaluated across the two scenarios eight for the control of individual basins across multiple reward function variants and basins and two agents for the multi basin control a deep neural network is designed and implemented to learn the action value function of each agent the network contains 2 layers with 50 neurons per layer this network is set up with a relu activation function goodfellow et al 2016 in the internal layers and a linear activation function in the final layer the full parameters used in the study including those for gradient descent and the dqn are provided in the si section 2 of this paper a root mean square propagation rmsprop goodfellow et al 2016 form of stochastic gradient descent is used for updating the neural network as this variant of gradient descent has been observed to improve convergence one storm event is used to train these agents the swmm model is forced with a 25 year storm event of 6 hour duration and 63 5 mm intensity fig 3 this event generates a total runoff of 3670 639 m 3 with a peak flow of 0 35 m 3 s at the outlet of watershed the agents are provided with an operational water level goal h of 2 m flooding level h max of 3 5 m and outflow exceedance threshold of f of 0 10 m 3 s 1 it is important to note that the outflow threshold in particular serves more as an approximate guide rather than exact requirement since the discrete valve settings used by the rl agents may not allow the exact setpoint to be physically realizable e g throttling a valve by 5 will limit outflow precision correspondingly these setpoints are chosen to reflect realistic flooding and stream erosion goals in the study watershed agents are trained on a tesla k20 gpus on university of michigan s advanced research computing s high performance cluster the second multi basin control agent uses the same neural network architecture of the other multi basin rl control agent trained this time however using batch normalization ioffe and szegedy 2015 batch normalization is the process of normalizing the signals between the internal layers of the neural network to minimize the internal covariance shift and has been observed to improve the performance of the deep rl agents lillicrap et al 2015 ioffe and szegedy 2015 provides a detailed discussion on batch normalization the performance of each agent is evaluated by comparing the rl controlled hydrographs and water levels to those that are specified in the reward functions for the agents controlling the individual basins this is used to determine the importance of the reward formulation on performance reward convergence and training period duration for the multi basin control scenario the same approach is used to quantify overall performance comparing this time the agent that uses the batch normalized neural network to the agent that uses the non normalized network to evaluate the ability of a rl agent to control storms that it is not trained on a final analysis is carried out since the agent controlling multiple basins presents the most complex of the scenarios it is first trained on one of storms and evaluated on a spectrum of storm events with varying return periods 1 to 100 years and durations 5 min to 24 hours these storm events are generated based on the scs type ii curve and historical rainfall intensities for the study region scs 1986 the performance of the agent across these 70 storms is compared to the uncontrolled system to evaluate the boarder benefits of real time control for comparison with an other control algorithm we also implement and compare the performance of rl to an equal filling degree controller which seeks to control the volume in each basin to achieve equal relative filling schütze et al 2018 implementation details of the equal filling algorithm can be found in the si section3 we also evaluate the performance of the rl controller on a back to back storm event 3 h 5 year event followed by a 2 h 2 year event to allow for a comparison between the controlled and uncontrolled system a non negative performance metric is introduced to capture the magnitude and time that the system deviates from desired water level and flows thresholds specifically across a duration t the final performance p adds together the deviation of all n controlled sites from their desired water level ph and flow thresholds pf where 13 p h h h h h h h h 100 h h h m a x 0 o t h e r w i s e 14 p f f 10 f f f f 0 o t h e r w i s e 15 p n 1 n i 0 t p h h i n p f f i n a relatively lower performance value is more desirable since it implies that the system is not flooding nor exceeding desired flow thresholds 4 results 4 1 scenario 1 control of single basin the ability of a rl agent to control a stormwater basin is highly sensitive to the reward function formulation generally a more complex reward function one that embeds more information and explicit guidance performs better as illustrated in fig 3 each column of the figure corresponds with an individual rl agent each of which is trained using a different reward function r 1 r 2 r 3 the reward functions are plotted in the first row while the reward received during training is plotted in the second row the training period is quantified in terms of episodes each of which corresponds to one full swmm simulation across an entire storm the third and fourth rows in the figure compare the uncontrolled flows and water levels respectively for the episode that resulted in the highest reward the rl agent that uses the simplest reward function has the relatively worst performance fig 3 first column even after 5000 training episodes a week of real world simulation time the mean reward does not converge to a stable value playing back the episode that resulted in the highest reward fig 3 rows 3 4 column 1 reveals that the rl agent does retain more water than would have been held in the uncontrolled basin while this lowers the peak flows relative to the uncontrolled basin the rl agent is generally not able to keep flows below the desired threshold more importantly the rl agent s control actions begin oscillating and become unstable toward the middle of the simulation in this episode the agent keeps the water level in the basin relatively constant by opening the valve very briefly to release just a small amount of water this chattering behavior shown as a close up in the figure results in an unstable outflow pattern that oscillates in a step wise fashion between 0 m 3 s and 0 18 m 3 s for various practical reasons such rapid control actions are not desirable since the rl agent never once receives a positive reward it may have converged onto an undesirable local minimum during the training providing more time for training does not appear to resolve this issue which may also suggest that a stable solution cannot be derived using this particular reward formulation embedding more explicit guidance harder constraints into the reward formulation improves the control performance of the rl agent fig 3 second column when the second and more continuous reward function is used by the agent the highest reward episode reveals that the rl agent is relatively more effective at maintaining flows at a constant value unlike the rl agent using the simple step wise reward function the rl agent using the parabolic reward function has more opportunities to receive smaller more gradual rewards during most of the episode this increased flexibility allows the second rl agent to receive positive rewards and keep the outflow below a flow threshold of 0 14 m 3 s while relatively improved the rl agent using the parabolic reward also does not converge to a stable reward value however toward the end of the episode this rl agent also carries out irregular and sudden control actions by opening and closing the valve in short bursts in this case the rl agent is oscillating between a maximum valve open and minimum valve closed reward rather than taking advantage of variable rewards in other configurations this suggests that the agent has either not yet learned a better strategy or again that a stable solution cannot be converged upon using this particular reward formulation this speaks to the need for more explicit constraints as well since a real world stormwater system could not be throttled in this fashion simply put the reward formulations used in this case was too simple to achieve realistically desirable outcomes the rl agent using the third and most constrained formulation exhibits the relatively best control performance this agent regulates flow and water levels in a relatively gradual and smooth manner unlike in the case of the other two rl agents after 3500 training episodes the third agent does converge to a steady reward evaluating the episode resulting in the highest reward fig 3 rows 3 4 column 3 the desired flat outflow hydrograph is achieved no unstable or oscillatory control actions are evident as in the case of the other two reward functions the agent is able to maintain flows below a constant threshold of 0 15 m 3 s while this is not the exact threshold that was specified 0 1 m 3 s it is close considering that the achievable threshold is dependent on water levels and the ability to only throttle the valve in 1 increments as stated in the methods section matching the exact threshold may not be physically realizable in any given situation due to constraints enforced by discretized throttling furthermore the rl agent must balance the desired outflow against the possibility of flooding and is thus more likely to release a greater amount of water than is specified by the threshold interestingly this agent does not change its valve configuration at all rather it keeps its valve 54 open the entire time of the simulation which allows it to meet a mostly constant outflow given the specific inflows overall the general shape of the outflows is improved compared to the uncontrolled scenario furthermore an added benefit of real time control is that the overall volume of water leaving the basin is also reduced by 50 due to infiltration similar to the third reward function agents trained on the 3a and 3b reward functions are successfully able to maintain the outflows close to the threshold during the stormevent figure 3 in si section 4 while these reward functions may appear similar the solution identified by their respective agents differs this is a result of the difference between the decay rates in the exponential and squared terms performance of the agent trained on the 3a and 3b reward functions si section 4 indicates that the ability of the agent to identify a viable control strategy is not dependent on the choice of equations used for the creating the reward functions but rather on the general shape of the reward function in the domain the agent using the third reward function trained on basin 1 is able to control basins 4 6 and 9 without any further modifications si section 5 figure 4 the agent in this formulation makes its control decisions only based on the depth at the current time step and does not incorporate any predictions hence the ability of the controller to shape of outflows should not dependent on the location of the basin in the network magnitude of inflows or the storage curves our simulation results indicate the same though the degree to which the agent is able to achieve the objective is governed by these physical constraints its ability to discover a solution is not influenced by them this scenario which focuses on the control of a single site emphasizes the importance of the reward function formulation in rl based control of stormwater systems the complexity of the reward formulation plays an important role in allowing the rl agent to learn a control policy to meet the desired hydrologic outcomes the importance of reward formulations has been acknowledged in prior studies sutton and barto 1998 ng et al 1999 generally reward functions with more explicit guidance lead to a more rapid convergence of a control policy while avoiding unintended control actions such as the chattering behavior seen in fig 3 in fact prior studies have attributed such erratic control actions to the use of oversimplified reward functions ng et al 1999 but have offered little specificity or concrete design recommendations that could be used to avoid such actions as such our approach heuristically evaluates reward formulations of increasing complexity until arriving at one that mostly meets desired outcomes this introduces an element of design into the use of rl for the real time control of stormwater as one cannot simply rely on the implicit black box nature of neural networks to solve a control problem under complex system dynamics the reward function needs to embed enough information to help guide the rl agent to a stable solution this introduces only a limited amount of overhead as reward functions can be intuitively formulated by someone with knowledge of basic hydrology for control of individual basins the reward function presented here should be directly transferable if more complex outcomes are desired modifications to the reward function may need to be carried out objectively the convergence of the reward will serve as one quality measure of control performance the ultimate performance of rl for the control of individual sites will however need to be assessed on a case by case basis by a designer familiar with the application taking the baseline lessons learned during the control of a single basin the second scenario can now evaluate the simultaneous control of multiple basins 4 2 scenario 2 control of multiple basins when trained using the generic feed forward neural network configuration that was used for the control of a single basin the rl agent controlling multiple assets was unable to converge to a stable reward even after 25 000 episodes of training fig 4 this totaled to 52 days of computation time on our gpu cluster after which the training procedure was halted due to lack of improved reward overall learning performance was low in this configuration not only did the learning procedure not converge to a stable reward but the vast majority of rewards were negative given this observation this ineffective neural network was then replaced with one that was batch normalized the agent using the batch normalized neural network achieved a higher average reward than the agent with a generic feed forward neural network fig 4 furthermore the agent using the batch normalized neural network achieved a relatively high rewards early on in the training process thus making it more computationally favorable while beyond the scope of this study this suggests that the choice of neural network architecture is likely a major design factor in the successful implementation of rl based stormwater control even with batch normalization the rl agent did not consistently return to the same reward or improve its performance when perturbed the exploration in its policy caused the rl agent to oscillate between local reward maxima similar outcomes have been observed in a number of rl benchmark problems henderson et al 2017 mnih et al 2015 which exhibited a high degree of sensitivity to their exploration policy prior studies have noted that the exploration exploitation balance is difficult to parameterize because neural networks tend to latch onto a local optimum larochelle et al 2009 as such it is likely that the lack of convergence observed in this scenario was caused by the use of a neural network as a function approximator forcing neural networks to escape local minima is still an ongoing problem of research osband et al 2016 nonetheless even without a consistent optimum the maximum reward obtained during this scenario can still be used as part of an effective control approach selecting the episode with the highest reward revealed the actions taken by the rl agent during the training storm fig 5 the figure compares the controlled and uncontrolled states of the four basins during a 25 year 6 hour storm event showing the depth in each basin inflows outflows and control actions taken by the rl agent though basin 2 is not explicitly controlled by the controller given that the water level and outflows in this basin are impacted by the actions taken in the upstream basin we have chosen to present its response no flooding occurred during this simulation which means that the reward received by the rl agent was entirely obtained by meeting outflow objectives the valves on basins 1 and 3 throttled between 100 and 95 open which for all practical considerations could be considered uncontrolled as such the rl agent in this scenario earned its reward by only controlling the most upstream basin in this network while the outcome of control was somewhat favorable compared to the uncontrolled systems the playback of the highest reward in fig 5 does not show drastically different outcomes control of the 4th basin shifted the timing of the outflows from the basin but did not reduce its outflows this resulted in improvements at the 1st 2nd and 3rd basins by delaying flows from the 4th basin the rl agent allowed the downstream basins to drain first and to spend less time exceeding the flow threshold interestingly the rl agent did not control basin 1 even while the single basin control scenario makes it is clear that a more favorable outcome can be achieved with control fig 3 as such a better control solution may exist but converging to such a solution using a neural network approximator is difficult this likely has to do with the larger state action space while the site scale rl agent was only observing water level at one basin the system level rl agent had to track levels and flows across more basins which increases the complexity of the learning problem the rewards received by the rl agent in the scenario are cumulative which means that improvement at just a few sites can lead to better rewards without the need to control all of them increasing the opportunity to obtain rewards thus increases the occurrence of local minima during the learning phase in the single basin control scenario the rl agent can immediately observe the impact of its control actions in the system scale scenario more time is needed to observe water flows through the broader system which means that the impact of a control action may not be observed until later timesteps this introduces a challenge as the rl agent has to learn the temporal dynamics of the system this challenge has been observed in other rl studies which have shown better performance for reactive rl problems as opposed to those that are based on the need to plan for future outcomes aytar et al 2018 the need to include planning is still an active area of rl research potential emerging solutions include adversarial play silver et al 2017b 2017a model based rl clavera et al 2018 and policy based learning schulman et al 2017 the benefits of these approaches have recently been demonstrated for other application domains and should be considered in the future for the control of water systems it is important to note that fig 5 represents an evaluation of the rl agent for one storm only namely the training storm realistically the control system will need to respond to storms of varying durations and magnitudes as an example the rl agent s response to a 24 hour 10 year storm is shown in fig 6 performance of the controller in controlling a back to back event is presented in si section6 here the rl agent outperformed the uncontrolled system much more notably compared to the training storm the controlled outflows were much closer to the desired threshold even when only one basin was controlled this broader performance is captured in fig 7 which quantifies performance eq 15 across a spectrum of storm inputs fig 7 compares the uncontrolled system to the rl controlled system both the controlled and uncontrolled systems perform equally well during small magnitude and short events e g the training storm in fig 5 the benefits of control become more pronounced for larger events starting at 10 year storms and those that last over 2 hours this visualization holistically captures the benefits of real time control by highlighting new regions of performance and showing how control can push existing infrastructure to perform beyond its original design 5 discussion given the recent emergence and popularity of reinforcement learning much research still remains to be conducted to evaluate its potential to serve as a viable methodology for the rtc of water systems our study brings to light a number of benefits and challenges associated with this task arguably it seems that the major benefit of using rl to control water systems is the ability to simply hand the learning problem to a computer without needing to worry about the many complexities non linearities and formulations that often complicate other control approaches however as this study showed this comes with a number of considerable caveats these include the challenges associated with formulating rewards choosing function approximators deciding on the complexity of the control problem as well as contending with practical implementation details our study confirms that the performance of rl based stormwater control is sensitive to the formulation of the reward function which has also been observed in other application domains ng et al 1999 the formulation of the reward function requires domain expertise and an element of subjectivity since the rl agent has to be given guidance on what constitutes appropriate actions in the first scenario it was shown that a reward function that is too simple may lead to adverse behavior such as the chattering or sudden actions the reward may also not converge to a stable solution since the neural network can take advantage of the simple objective to maximize rewards using sudden or unintuitive actions the formulation of the problem which depends heavily on neural networks also makes it difficult to determine why one specific reward function may work better than another increasing the complexity of the reward function by incorporating more explicit guidance was shown to help guide the rl agent to a more desirable outcome in other control approaches such as genetic algorithms or model predictive control the design of reward is an iterative process and sometimes involves anticipating fringe cases to improve the robustness of the controller similar to these approaches we can however begin using this early study to formulate a number of practical considerations when formulating reward functions define the reward function for entire domain of the state action space ensuring that it distinguishes the desirable actions from the undesirable ones ensure that the reward function represents a specific hydrologic response that the controller is to achieve while anticipating as much as possible alternate and adverse hydrologic responses that the controller may discover to maximize the reward function relax the mathematical formulation of the reward function and focus rather on the two above points e g the shape of a reward surface rather than its specific mathematical form reward formulations are an ongoing research area in the rl community and some formal methods have recently been proposed to provide a more rigorous framework for reward synthesis fu et al 2017 these formulations should be investigated in the future even when the choice of reward function is appropriate or justifiable the control performance can become sensitive to the approximation function which in our case took the form of a deep neural network choosing the architecture and structure of the underlying network becomes an application dependent task and can often only be derived through trial and error sutton and barto 1998 henderson et al 2017 secondly for challenging control problems such as the one studied here learning the mapping between rewards and all possible control decisions becomes a complex task the neural network must be exposed to as many inputs and outputs as possible which is computationally demanding in our study we ran simulations for many real world months on a high performance cluster but it appears that the learning phase could have continued even longer this in fact has been the approach of many successful studies in the rl community where the number of computers and graphical processing units can be in the hundreds espeholt et al 2018 openai 2018 this was not feasible given our own resources but could be evaluated in the future aside from the formulation of the learning functions and framework the actual complexity and objectives of the control problem may pose a barrier to implementation we showed that a rl agent can learn how to control a single stormwater basin effectively but that controlling many sites at the same time is difficult a major reason is the increase in the number of states and actions that must be represented using the neural network while computational time may remedy this concern the structure of the neural network may also need to be altered in a system scale stormwater scenario actions at one location may influence another location at a later time as such the agent would benefit from a planning based approach which considered not only current states but future forecasts as well such planning based approaches have been proposed in the rl literature and should be investigated to determine if they lead to an improvement in performance clavera et al 2018 depeweg et al 2016 furthermore model based approaches have also recently been introduced and could allow some elements of the neural network to be replaced with an actual physical or numerical stormwater model gu et al 2016 such approaches should be evaluated in the future since they may permit more domain knowledge from water resources to be embedded into training the controller it is important to note that the equal filling algorithm outperforms the rl agent in this study si section 3 it achieves the objective of maintaining the outflow below the desired threshold without causing flooding since equal filling outperforms rl it could very well be considered a superior choice in this study that said developing and deploying equal filling often requires an intuitive understanding of the system and require a highly manual tuning of parameters while it may be relatively straightforward to design control approaches in smaller systems and simple outcomes such as the one in this study developing coordinated control strategies for large scale systems with multiple objective might not be as easy as such we see rl based control as a long term goal which should be investigated in future studies across bigger scales and complex outcomes our study presents an initial goal toward the broader study of rl based stormwater control after which an comprehensive apples to apples comparison may be possible with current state of the art approaches finally the use of rl for the control of stormwater systems is underpinned by a number of practical challenges computational demands are very high especially compared to competing approaches such as dynamical systems control model predictive control or load balancing approachs troutman et al 2020 while computational resources are becoming cheaper the resources require to carry out this study were quite significant and time demanding since actions taken by neural networks cannot easily be explained and explicit guarantees cannot be provided this may limit adoption by decision makers who may consider the approach a black box it is also unlikely that the control of real world stormwater systems will simply be handed over to a computer that learns through mistakes rather simulation based scenarios will be required first it has recently been shown as long as a realistic simulator is used in our case swmm then the agent can be effectively trained in a virtual environment before refining its strategy in the real world openai 2018 6 conclusion this paper introduced an algorithm for the real time control of urban drainage systems based on reinforcement learning rl while rl has been used successfully in the computer science communities to our knowledge this is the first instance for which it has been explicitly adopted for the real time control of urban water systems the methodology and our implementation show promise for using rl as an automated tool chain to learn control rules for simple storage assets such as individual storage basin however the use of rl for more complex system topologies faces a number of challenges as laid out in the discussion simultaneously controlling multiple distributed stormwater assets across large urban areas is a non trivial problem regardless of the control methodology to that end the concepts initial results and formulations provided by this paper should help build a foundation to support rl as a viable option for stormwater control the source code accompanying this paper should also allow others to evaluate many other possible architectures and parameterizations that could be used to improve the results presented in the paper declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by great lakes protection fund grant number 1035 and the us national science foundation grant number 1737432 we also would like to acknowledge the support provided by advanced research computing at the university of michigan ann arbor supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103600 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
497,accurate modeling of variably saturated flow vsf in fractured porous media with the discrete fracture matrix dfm model is a computationally challenging problem the applicability of dfm model to vsf in real field studies at large space and time scales is often limited not only because it requires detailed fracture characterization but also as it involves excessive computational efforts we develop an efficient numerical scheme to solve the richards equation in discretely fractured porous media this scheme combines the mixed hybrid finite element method for space discretization with the method of lines for time integration the fractures are modeled as lower dimensional interfaces 1d within the 2d porous matrix we develop a new mass lumping ml technique for the fractures to eliminate unphysical oscillations and convergence issues in the solution which significantly improves efficiency enabling larger field applications the proposed new scheme is validated against a commercial simulator for problems involving water table recharge at the laboratory scale the computational efficiency of the developed scheme is examined on a challenging problem for water infiltration in fractured dry soil and compared with standard numerical techniques we show that the ml technique is crucial to improve robustness and efficiency which outperforms the commonly used methods that we tested the applicability of our method is then demonstrated in a study concerning the effect of climate change on groundwater resources in a karst aquifer spring system in el assal lebanon simulations including recharge predictions under climate change scenarios are carried out for about 80 years up to 2099 this study demonstrates the applicability of our proposed scheme to deal with real field cases involving large time and space scales with high variable recharge our results indicate that the water table level is sensitive to the presence of fractures where neglecting fractures leads to an overestimation of the available groundwater amount the proposed numerical approach is generic for dfm model and can be extended to different 2d and 3d finite element frameworks keywords variably saturated flow fractured porous media discrete fracture matrix model mass lumping mixed hybrid finite element method method of lines climate change submitted to advances in water resources special issue advances in upscaling and characterization of flow and transport phenomena in porous media 1 introduction understanding variably saturated flow vsf in fractured porous media has great significance to many environmental and geotechnical applications such as groundwater recharge in karst aquifers mudarra and andreo 2011 de rooij et al 2013 de rooij 2019 epikarst chang et al 2019 and unconfined chalk aquifers ireson et al 2009 vsf in fractured zones has been studied for geological disposal of nuclear waste such as the one at yucca mountain in the united states where an unsaturated zone was assessed to serve as a potential site for the deposition of high level nuclear wastes hayden et al 2012 ye et al 2007 other applications include contaminant transport and infiltration of landfill leachate brouyère 2006 ben abdelghani et al 2015 infiltration through unsaturated saprock in hillslopes with shallow fractured shale bedrock guo et al 2019 unsaturated flow and contaminant transport in saprolite van der hoven et al 2003 alazard et al 2016 water flow in cracked soils and stability of soil slopes with cracks pouya et al 2013 wang et al 2019 yang and liu 2020 seepage through fissured dams jiang et al 2014 tunnel excavation gokdemir et al 2019 and protection of structure foundations in contact with water zhao et al 2019 among others fractures in the vadose zone typically provide preferential flow pathways however they could also act as flow barriers from capillary forces depending on the degree of saturation cey et al 2006 wang and narasimhan 1985 the vsf in fractured porous media involves several coupled and complex processes such as capillary and gravity driven transient flows preferential flow in fractures and fracture matrix interactions from imbibition and diffusion hoteit 2013 due to these complexities and despite the broad range of applications the processes of vsf in fractured porous media are not well understood related experimental studies are scarce and limited to simplified fracture configurations for instance yang et al 2019 presented an experimental study to investigate vsf through a simple t shaped fracture intersection wang et al 2017 investigated the effect of fracture aperture on capillary pressure saturation relation kordilla et al 2017 studied the effect of droplet and rivulet unsaturated flow modes at simple intersecting fractures based on experiments tokunaga and wan 2001 introduced a new mechanism of vsf in a single fractured domain named as surface zone flow which can appear when the permeability of skin fractures is significantly higher than that of the porous matrix most of the studies related to vsf in fractured domains rely on numerical simulations which are used for several theoretical and practical purposes for instance understanding physical processes liu et al 2002 2004 field studies zhou et al 2006 ye et al 2007 masciopinto and caputo 2011 kordilla et al 2012 ben abdelghani et al 2015 robineau et al 2018 and validation of laboratory experiments roels et al 2003 malenica et al 2018 in applied studies numerical simulations are considered as an irreplaceable and cost effective tool for designing predicting and uncertainty assessments unsaturated flow in porous media is usually described using the richards equation re that combines darcy s law and continuity equation which are coupled via constitutive relations expressing permeability and water content as a function of the hydraulic head farthing and ogden 2017 re is a simplification of the two phase water air flow model assuming that air remains essentially at atmospheric pressure this approximation is valid when the effect of air on water flow is negligible szymkiewicz 2013 the models used to treat the fractures can be classified into two main categories the equivalent continuum model ecm and the discrete fracture matrix dfm model with the ecm the fractured domain is represented by a homogenous porous media with equivalent hydraulic parameters in this case re is used with a specific permeability constitutive relation and retention curve including the effect of fractures the main drawback of ecm is related to the development of effective retention and permeability curves in the presence of fractures guarracino and quintana 2009 monachesi and guarracino 2011 pouya et al 2013 the dual porosity model which can be seen as an extension of the ecm treats the fractured domains as dual interactive continua representing fractures and porous matrix respectively brouyère 2006 kuráž 2010 different hydraulic properties are associated to each continuum flow cannot occur in the matrix continuum which only acts as a source sink term while the fracture continuum provides the flow connectivity despite its low storage capacity fahs et al 2014 on the other hand the dual permeability model is more used than dual porosity for vsf in fractured domains as it allows for moisture flow in both the fracture and matrix continua kordilla et al 2012 robineau et al 2018 the dual permeability model requires two sets of constitutive relations for the fracture and matrix domains unlike ecm and dual continua models the dfm model is based on an explicit description of fractures with dfm model the hydraulic properties of fractures and their topology are considered explicitly where the matrix and the fractures are modeled as separate elements of one continuum for dfm model re is often utilized to simulate flow in both fractures and matrix but with different constitutive relations and properties for each medium examples of utilization of the dfm model for vsf can be found in therrien and sudicky 1996 masciopinto and caputo 2011 ben abdelghani et al 2015 li and li 2019 and li et al 2020 ecm provides efficient simulations with relatively low computational costs and complexity it is relatively simple and straightforward to implement which is commonly used in real field applications liu et al 2005 however the accuracy of this model is highly dependent on the validity of the equivalent retention curves and constitutive relations in representing the matrix and the fractures liu et al 2005 ecm is not suitable for small scale applications or for cases involving a small number of fractures roels et al 2003 further this method cannot provide a detailed description of the flow dynamics in fractures and fails to reproduce the preferential flow paths encountered in fractured vadose zones liu et al 2005 2007 in many applications dfm model is more suitable to simulate preferential flow as fractures are captured in more detail this model is essential to understand water flow processes in fractures at a small scale cey et al 2006 it is also applied at the field scale with a small number of well defined fractures hirthe and graf 2015 ben abdelghani et al 2015 however dfm model is computationally expensive and requires detailed information about the fractures the inefficiency is related to the dense computational meshes and often causes poor convergence due to the high discontinuity between the hydraulic properties of fractures and matrix particularly in the case of dense fracture networks berre et al 2019 nordbotten et al 2019 a common approach that significantly alleviates the computational complexity of the dfm model is the hybrid dimensional technique therrien and sudicky 1996 hoteit and firoozabadi 2008 li et al 2020 in which the fractures are considered as co dimensional interfaces with respect to the full dimensional elements representing the matrix i e one dimensional fractures in the two dimensional matrix elements with the continued advancement in new numerical methods and the recent progresses in powerful computational technologies the dfm model has received an increasing interest due to its robustness in reproducing physical processes of flow and transport in fractured porous media this results in extensive research on the development of appropriate numerical techniques and schemes that aims at improving the computational performance of the dfm model for saturated flow ahmed et al 2017 berre et al 2019 nordbotten et al 2019 this study focuses on the use of the dfm model for the simulation of unsaturated flow in vadose fractured zones modeling vsf in explicitly fractured domains i e with the dfm model remains a computationally challenging task which usually exhibits numerical complexities li and li 2019 the challenges are not only due to the presence of dense fractures and the associated complex geometry property discontinuities quality of mesh discretization and poor convergence but also due to the inherent numerical complexities of the re li and li 2019 it is well known that the numerical solution of the re even in unfractured domains is one of the most challenging problems in hydrogeology miller et al 2013 numerical difficulties are caused by the mathematical characteristics of this equation that could change from hyperbolic to parabolic depending on the saturation alongside there is strong nonlinearity introduced by the constitutive relationships suk and park 2019 slow no convergence small time steps mass conservation and numerical oscillations are common numerical issues that are usually encountered in the solutions of re significant efforts have been made in last decades on the development of advanced and appropriate numerical techniques for solving this equation celia et al 1990 farthing et al 2003 li et al 2007 ji et al 2008 fahs et al 2009 hassane maina and ackerer 2017 suk and park 2019 ngo cong et al 2020 the most investigated problems are related to the selection of the primary variable pressure head water content or mixed form mass conservative solution time and spatial discretization schemes nonlinear solvers and numerical evaluation of equivalent hydraulic conductivity miller et al 2013 and references therein more details about the numerical solution of re can be found in recent review papers by farthing and ogden 2017 and zha et al 2019 unlike in unfractured media numerical solutions of re in explicitly fractured domains are not well developed most of the existing tools are based on the standard finite element method for space discretization and backward euler scheme for time integration therrien and sudick 1996 these traditional methods may not be suitable to solve the re equation under complex fractured configurations this restricts the applicability of the existing models for engineering practice especially at real scale hence it is important to carry out further studies on the development of robust and efficient numerical techniques to solve the re in explicitly fractured domains involving complex fracture networks which is the main objective of this study this is crucial to improve the capability of current models in developing more realistic simulations and to deal with the growing demand on predicting and understanding the dynamics of aquifers under non stationary conditions at large time and space scales the objective of this paper is to develop a new numerical technique for vsf in fractured porous domains that is not only accurate but also efficient and fast which is a fundamental challenge of computation water resources in this work we couple advanced numerical techniques for space discretization and time integration to solve the re in explicitly fractured domains we consider the head form of the re this form allows for efficient numerical solutions as the pressure head is used as the only primary variable however this approach may lead to non conservative solutions when it is solved with first order time integration methods celia et al 1990 farthing et al 2003 to avoid this problem and to obtain conservative solutions we use high order integration techniques as it is discussed further in this section among different existing techniques for space discretization we use the mixed hybrid finite element mhfe method brezzi and fortin 1991 farhloul and fortin 2002 farhloul 2020 a review about the use of this method and its advantages e g local mass conservation ability to intrinsically treat anisotropic domains consistent velocity field even in highly heterogeneous domains in simulating groundwater flow can be found in younes et al 2010 the mhfe method was initially used to simulate saturated flow in simple porous media younes et al 1999 it has been then extended to vsf by farthing et al 2003 fahs et al 2009 and belfort et al 2009 as the method deals with the water fluxes and average pressures at the edges of the mesh elements it is highly suitable for the dfm model with the hybrid dimensional technique where fractures are defined on the edges of the matrix elements the method has been extended to the simulation of flow in fractured porous media in hoteit and firoozabadi 2008 zidane and firoozabadi 2014 2018 chen et al 2016 moortgat et al 2016 and moortgat 2017 to our knowledge the mhfe has been yet applied for vsf in fractured media one of the objective of this work is to extend this method to vsf in explicitly fractured domains and to evaluate its performance in such an application combined with the mhfe we introduce a new mass lumping ml technique as the nonlinearity of the re imposes small time steps most finite element based methods suffer from spurious oscillations related to the discretization of the transient accumulation term hoteit et al 2002 elguedj et al 2009 scudeler et al 2016 this problem has been encountered with the mhfe in belfort et al 2009 for re the problem of unphysical oscillations is particularly crucial as it leads to a loss of numerical stability that would affect the convergence of the nonlinear solver younes et al 2006 developed an ml technique for the mhfe to eliminate unphysical oscillations belfort et al 2009 extended the ml technique to vsf in unfractured domains fučík 2019 applied the mhfe method to compositional two phase flow in heterogeneous porous media and showed that ml technique is needed for handling material discontinuities in this work we develop an efficient approach to generalize the ml technique to vsf in fractured domains besides spatial discretization selecting an efficient temporal scheme is crucial little attention has been devoted to the time integration of groundwater flow in fractured domains moortgat et al 2016 this is also true for vsf with the dfm model existing numerical models are based on the first order backward euler scheme therrien and sudick 1996 however several works show the advantages of higher order time integration schemes for the simulation of unsaturated flow farthing et al 2003 showed that with a higher order time integration scheme conservative solutions could be obtained even with the non conservative form of the re fahs et al 2009 proved that adaptive high order time integration schemes could lead to faster solutions than standard first order methods here we couple the mhfe and the ml technique to an adaptive high order time integration scheme via the method of lines mol matthews et al 2004 this approach permits using a sophisticated ordinary differential equation ode solver for time integration dlsodis that allows besides high order adaptive time integration an appropriate time stepping management and efficient procedure to deal with nonlinearities 2 governing equations of vsf in fractured domains vsf in fractured and porous media is described by the re coupling the darcy buckingham s law and the mass conservation equation as shown below 1 q β k β s e β h β h β 2 c β h β s s β s w β θ β h β t q β f β 3 h β h β z where the superscript β m f is the medium index m for matrix and f for fracture hβ l and hβ l are respectively the piezometric head and pressure head and z l is the elevation the list of variables and parameters associated with eqs 1 and 2 are provided in table 1 we use the standard form of the van genuchten 1980 model for the inter relation of pressure head and water content where different properties are considered for the matrix and fractures 4 s e β θ β θ r β θ s β θ r β 1 1 α β h β n β m β h β 0 1 h β 0 in the above equation αβ l 1 and n β are parameters related to the mean pore size and uniformity of mean size distribution of the matrix and fractures and m β 1 1 n β for conductivity saturation relationship the van genuchten mualem model mualem 1976 is given by 5 k β k s β s e β 1 1 s e β 1 m β m β 2 3 numerical solution mhfe method ml technique and mol we develop a new numerical scheme to solve the system of eqs 1 5 using 2d unstructured triangular meshes the scheme can also be used with other mesh types as mentioned in the introduction the fractures are considered with the hybrid dimensional technique as 1d interfaces of the 2d elements representing the matrix this approach provides a significant reduction in the complexity of the computational mesh however the local density and complexity of the fracture network should be considered as presented in berre et al 2019 the complex fracture network causes challenges to the generation of a conforming mesh the developed scheme couples the mhfe and ml technique for space discretization with an advanced ode solver for time integration via the mol this method consists of discretizing the space derivatives while maintaining the time derivative in its continuous form this discretization allows converting the system of partial differential equations into a system of odes which is solved using a sophisticated solver the main steps of the developed schemes are detailed here 3 1 trial functions of the mhfe method for the matrix and fractures since the matrix and fracture elements exhibit different dimensions the governing equations are discretized separately then coupled and solved simultaneously in the matrix based on the formulation of mhfe the total flux across an edge of an element e referred to as qe is approximated as the following chavent and jaffré 2014 6 q e i 1 n f q i e w i e where q i e is the flux across edge i in element e referred to as ei this discretization technique applies to the matrix elements fig 1 a and the fracture interfaces fig 1b for fracture edges element e becomes e and the edges of the elements become the nodes of the fracture edge we use the lowest order raviart thomas space raviart and thomas 1977 for which nf is equal to 3 for triangles used for matrix elements and 2 for the fracture edges the shape functions w i e for the ith edge of a matrix element e when using the lowest order raviart thomas space are 7 w i e 1 2 e x x i e z z i e i 1 2 3 where e l2 is the surface area of the matrix element and x i e l and z i e l are respectively the horizontal and vertical coordinates of the opposite node to ei the shape functions for the fracture edges are 8 w i k 1 ℓ ξ ξ i i 1 2 where ℓ l is the length of the fracture edge and ξ i l is the local coordinates of the opposite element node 3 2 flux discretization in the matrix elements mhfe method and ml technique applying the mhfe discretization to eq 1 using the flux expression from eq 6 on a matrix element and then rearranging the two sides of the equation we obtain the following expression of the fluxes younes et al 2006 9 q i e j 1 3 m e i j 1 h e t h j e where he and thj e are respectively the mean piezometric head in element e and on edge ej m e i j 1 is the inverse of the local stiffness matrix obtained as followed 10 m e i j e w i e k e 1 w j e using the mass lumping scheme presented by younes et al 2006 the flux across the edges of the element e are approximated as followed 11 q i e q i e q s e 3 e 3 c e s s e s w e d t h i e d t where q s e l2t 1 is the sink source term imposed on the matrix element e q i e l2t 1 is the flux corresponding to the stationary problem without the sink source term that can only be expressed as a function of alternated local matrix and traces of the piezometric head 12 q i e j 1 3 n e i j t h j e the local matrix ne has the following form with the notations written after 13 n e i j α e i α e j α e m e i j 1 14 α e i j 1 3 m e i j 1 a n d α e i 1 3 α e i 3 3 flux discretization for a fracture element the formulation of mhfe in the fracture element k is similar to the formulation in the matrix elements see hoteit and firoozabadi 2008 using the same approach as presented for the discretization in the matrix fluxes are expressed by the average hydraulic head on the fracture edge and hydraulic head on the fracture nodes see fig 1 15 q i k 1 2 m k i j 1 h k t h j k 16 m k i j ℓ w i k k k 1 w j k applying eq 15 on eq 2 for the fracture edges the continuity equation treated with a finite volume procedure leads to 17 ε ℓ c k h k s s k s w k θ k d h k d t ε i 1 2 q i k q s k q f k where ε l and ℓ l refer to the fracture aperture and length respectively q s k l2t 1 represents the sink source term inside the fracture and q f k l2t 1 is the matrix fracture volumetric exchange flux which is explained in the next section 3 4 hybridization mass conservation on edges obtaining the global format of the discretized equations requires coupling the flux and piezometric head associated with neighboring elements e and e having ei in common if edge ei is not a fracture the continuity of flux and piezometric head is imposed such that 18 q i e q i e 0 t h i e t h i e if ei coincides with a fracture the total flux across both sides coming from the adjacent matrix elements defines the matrix fracture exchange flux q f k which acts as a sink source term on the fracture edge as for the continuity of piezometric heads the mean heads associated with the matrix edges are equal to the mean head in the fracture element that is 19 q i e q i e q f k h k t h i e t h i e for further explanation on the elimination of q f k in the final format of the equations refer to hoteit and firoozabadi 2008 3 5 the new ml technique for fractures the global matrix corresponding to the discrete system of equations does not necessarily satisfy the m matrix conditions which requires a non singular matrix with mii 0 and mij 0 younes et al 2006 hoteit et al 2002 the m matrix property ensures respecting the discrete maximum principle in other words the solution is free from unphysical oscillations the global matrix obtained by mhfe is symmetric and positive definite but is not in general an m matrix in order to improve the property of our numerical scheme we use a combination of two mass lumping techniques one for porous matrix elements as shown in section 3 2 and a new technique that we propose for fracture edges this proposed mass lumping scheme applied to the fracture edges ensures the consistency of the m matrix property for the combined matrix fracture system to explain the mass lumping scheme for the fracture edges the global matrix of the discrete system resulting from the mhfe method is decomposed into nine submatrices including six sub matrices being pairwise transpose of each other due to the symmetry of the global matrix the decomposition of the global matrix and different sub matrices are shown in fig 2 matrix a is composed of the coefficients associated with flux continuity between adjacent porous matrix elements where interfaces are not fractures a is similar to the one obtained with mhfe in unfractured domains as the ml technique is used for porous matrix elements a satisfies the m matrix properties younes et al 2006 matrix b denotes the coefficients associated with the connectivity of the porous matrix and the edges shared with fractures which are all negative or zero see eq 11 matrix c represents the contribution of fracture nodes on the flux continuity on the unfractured edges the coefficients of c are all zero due to the fact that there is no flow exchange between the fracture nodes and matrix edges matrix d is also an m matrix see eq 11 and matrix e has all negative or zero components when applying the mass lumping defined in eq 11 however matrix f which corresponds to the connectivity and flow exchange between fracture edges is not necessarily an m matrix to get a global matrix satisfying the m matrix conditions we propose a numerical integration technique to calculate the stiffness matrix m k i j 1 such that 20 m k i j 1 k f k ℓ 2 0 ℓ ξ ξ i ξ ξ j d ξ kf k is the hydraulic conductivity of the fracture element k the matrix format of m k i j is given by 21 m k 1 k f k ℓ 2 0 ℓ ξ ξ i ξ ξ i d ξ 0 ℓ ξ ξ i ξ ξ j d ξ 0 ℓ ξ ξ j ξ ξ i d ξ 0 ℓ ξ ξ j ξ ξ j d ξ the calculation of the integrals in each component of the matrix can be approximated numerically fig 3 describes schematically the process in fig 3a the red area represents the integral of the diagonal terms of matrix mk eq 21 in fig 3b the red area corresponds to the integral for the off diagonal terms of the mk eq 21 applying the ml technique in the fractures the red areas are approximated using the rectangular integration as represented with the blue areas this integration approach results in zero off diagonal elements for the matrix calculating the integral analytically red surface in fig 3 leads to a stiffness matrix that does not satisfy the m matrix properties however numerical approximation the blue surface in fig 3 leads to the following 22 m k ℓ 2 k f k i 23 m k 1 2 k f k ℓ i where i is the identity matrix the process leads to a diagonal stiffness matrix hence sub matrix f satisfies m matrix condition that guarantees stable solution in each time step the validity of the results is demonstrated in the following sections 3 6 high order adaptive time integration the system of differential equations obtained by coupling the discretized fluxes in the matrix and fracture elements leads to a system of temporal odes in this work we solve this system using the advanced solver dlsodis double precision livermore solver for ordinary differential equations implicit form and sparse matrix which is a public domain solver hindmarsh 1980 seager and balsdon 1982 the solver is based on the backward differentiation formula bdf it has the advantage of using a high order time integration scheme both variable time step sizes and variable integration orders are used to reach accurate solutions with optimized cpu time the integration order variability makes this solver highly accurate when compared to conventional constant order solvers in particular for vsf and as shown in farthing et al 2003 and fahs et al 2009 high order schemes lead to accurate mass balance even with the non conservative form of re the variability of time step size allows reducing the calculation time and therefore results in exceptional efficiency improvement the accuracy of dlsodis is controlled by various tolerances related to the relative and absolute errors which are set to 10 6 in this work the time step size is changed and adapted periodically by the solver to honor the imposed tolerances the algebraic nonlinear system resulting from the temporal integration of each time step is solved using a modified newton iteration scheme radhakrishnan and hindmarsh 1993 where the jacobian matrix is calculated numerically using a finite difference approximation and a column grouping technique of curtis et al 1974 4 results verification and advantages of the new developed numerical scheme 4 1 verifications fractured vauclin test case the developed numerical scheme based on the combination of the mhfe method ml technique and mol was implemented in a fortran code the main goal of this section is to verify the correctness of this code thus we consider a computationally simple example in order to avoid numerical artifacts the example is inspired by the laboratory experiments of vauclin et al 1979 dealing with water table recharge this example is accepted as a standard benchmark for vsf as it provides reliable experimental data with simple boundary conditions the laboratory experiments of vauclin et al 1979 deals with unfractured homogenous soil we adopted four fractured examples by assuming the same configuration geometry dimensions and boundary conditions and by embedding in the domain i a single vertical fracture ii a single horizontal fracture iii a single inclined fracture and iv a network of fractures similar to the ones encountered in karst aquifers the original experimental setup of vauclin et al 1979 consists of a rectangular soil slab 600cm 200cm a constant influx of 355 cm day is applied over a width of 100cm in the center top of the domain initially the water table is located at 65cm from the bottom surface because of the symmetry only the right half of the domain is considered and the axis of symmetry acts as an impermeable boundary on the left the rest of the boundary and initial conditions are similar to the original experiment the hydrological properties of the porous matrix are obtained from clement et al 1994 whereas the fracture properties are selected from fairley et al 2004 kuráž et al 2010 the matrix and fracture parameters are provided in table 2 effects of these parameters on vsf in fractured domain is beyond the scope of the paper the most computationally challenging values are considered with an emphasis of their high hydrodynamic conduction of fractures compared to the soil matrix our developed code based on the mhfe method ml technique for both fractures and matrix and the hybrid dimensional technique 1d fractures and 2d porous matrix is referred to as mh lump 1d 2d this code is verified here by comparison against an in house code based on the mhfe method and dealing with vsf in unfractured domains the in house code has been validated against experimental data in fahs et al 2009 in this in house code both matrix and fractures are considered as 2d elements thus this second code is referred as mh 2d 2d an example of the difference between the computational mesh used in mh lump 1d 2d and mh 2d 2d is given in fig 4 for more confidence in the correctness of the newly developed code mh lump 1d 2d we compare it against a finite element solution from comsol multiphysics this software provides a tool to simulate fractured porous media based on the hybrid dimensional technique however when this tool is used for vsf the fractures are always assumed as saturated which is not the case in our examples thus as in the code mh 2d 2d we consider the fractures as 2d elements in comsol the comsol model is denoted as comsol 2d 2d the numerical codes used for verifications and summary about corresponding numerical techniques are given in table 3 in all codes including the comsol model the time integration is performed in the same manner using the bdf method with variable order the simulations are performed for one hour of recharge for all cases the computational meshes used in the simulations with the code mh lump 1d 2d consist of about 17k elements for the cases of horizontal vertical and inclined fracture and about 40k elements for the fracture network configuration with the same level of refinement in the matrix the corresponding computational meshes used for the codes mh 2d 2d and comsol 2d 2d consist of about 20k elements for the first three cases and about 80k elements for the fracture network case the numbers of elements in the 1d 2d and 2d 2d models show that the hybrid dimensional technique allows for a significant reduction in the mesh density as it avoids local refinements within the fractures the gain is more pronounced for dense fracture networks the computational grids for all cases were generated using the comsol meshing tool fig 5 shows the contour map of the volumetric water content θ for different test cases after one hour t 1hr this figure shows that in the case of a single fracture the higher water table is observed for the vertical fracture fig 5a this behavior makes sense as the vertical preferential flow occurring in the fracture driven by gravity and capillarity enhances the water table recharge the lowest water table is observed in the case of horizontal fracture in which the horizontal preferential flow moves water away from the water table and slow down the water recharge rate fig 5b in the case of the inclined fracture the inclination decreases the vertical component of the preferential flow and increases its horizontal components thus it is expected that the water table in this case falls in the middle between the vertical and horizontal cases fig 5c the case dealing with the schematic karst network leads to the highest water table among all cases fig 5d this behavior is a result of the multiple vertical fractures that could recharge the water table faster than the other cases in the case of a single vertical fracture as the fracture is quickly saturated water exchange with the surrounding matrix is significant hence fig 5a and d show a high level of water saturation around the fractures in the case of a single vertical fracture and fracture network finally fig 5 shows overall excellent agreement between the three codes which gives confidence in the correctness of our code mh lump 1d 2d some minor discrepancies can be observed at the water front which are related to dissimilarities of the mesh size in 2d 2d and 1d 2d refinements near the fractures these differences can be reduced by further refining the mesh near the fractures 4 2 advantages of the ml technique for fractures the advantages of the ml technique for vsf in unfractured domains is discussed in belfort et al 2009 fahs et al 2009 showed that besides stable solutions and good convergence properties the ml technique allows for solving re in unfractured domains in an efficient manner using high order time integration scheme in fractured domains the ml technique is applied for unsaturated flow in this work for the first time for saturated flow this technique may not be critical as the saturated flow does not require small time steps for which numerical instabilities could appear for vsf small time steps should be used to guarantee the convergence of the nonlinear solver thus spurious oscillations may affect both the accuracy and convergence rate of the solutions an essential contribution of this work is the development of the ml technique for the dfm model for the matrix we apply the same ml technique as developed in fahs et al 2009 for unfractured domains the major contribution of this work is in the development of the ml technique for the fractures in section 3 5 we investigate the stability of the corresponding solutions via a theoretical analysis based on the m matrix property the main goal of this section is to verify the stability of the developed ml technique particularly for fractures and to investigate its advantages via numerical experiments to do so we consider the newly developed code mh lump 1d 2d in which the ml technique is implemented for the matrix and fractures and a modified version called mh cons 1d 2d in which ml technique is used only for the matrix to compare these models we consider the challenging case of infiltration in dry soil with imposed heads at the top and bottom surfaces huang et al 1996 ngo cong et al 2020 besides the nonlinearity related to re this problem involves an extremely moving sharp front that cannot be captured numerically without introducing dense grids and small time steps the later causes unphysical oscillations and convergence difficulties in contrast to the imposed flux boundary condition the dirichlet boundary conditions imposed at the soil top surface compound the numerical difficulties as they require an appropriate approach for the evaluation of the equivalent hydraulic conductivity belfort et al 2013 this problem has been widely investigated in the literature and the common question is to develop an accurate solution forsyth and pruess 1995 huang et al 2002 arico et al 2012 younes et al 2013 list and radu 2016 islam et al 2017 zha et al 2017 ngo cong et al 2020 all the exiting studies suggested appropriate numerical solutions for unfractured domains simulations of problems dealing with infiltration in dry fractured soil are not well developed in the literature the results presented here can serve as a benchmark for code verification the geometry is inspired by a real fractured outcrop corresponding to a fractured aquifer in jeita lebanon fig 6 a boundary conditions and soil parameters are similar to huang et al 1996 constant pressure heads of 10 cm and 1000 cm are imposed at the top and bottom boundaries of the domain respectively and an initial pressure head of 1000 cm representing a highly dry soil is assumed side boundaries are assumed impermeable the hydraulic parameters of the matrix and fractures are given in table 2 fig 6b shows the 1d 2d mesh gridding consisting of 1626 triangular elements for the matrix and 272 linear elements for fractures the duration of the simulation is set to be 3 2 104s about 9 hours the mh cons 1d 2d code had convergence difficulties after 3 hours of simulation a close look at the results at this time shows that the waterfront reaches the fractures fig 6c spurious oscillations appear mostly near the fractures incoherent results can be observed with pressure head beyond physics below 1000cm these oscillations cause the convergence of the nonlinear solver to fail as the system of equations becomes ill conditioned the mh lump 1d 2d code runs without any convergence problems for the entire simulation duration the results at t 3 h are given in fig 6d this figure shows a stable solution free from spurious oscillations with further advancement of time fast preferential flow in the dry soil can be noticed along with all the fracture elements fig 6e the demonstration of actual flow in the matrix and fractures can give better insights about the general direction of the flow and conductive behavior of the fractures see fig 6f we also investigate the effect of the ml technique in fractures on the performance of the numerical models thus we compare the cpu time of the mh lump 1d 2d and mh cons 1d 2d codes for different levels of mesh refinement it should be mentioned that the computer system used for all the simulations in this section and other sections has an intel core i7 6700 cpu at 3 4 ghz with 16 gb 2 8gb of installed memory ram fig 7 gives the variation of the cpu for both codes versus the number of elements of the computational grids it shows that the ml technique in fractures allows for a significant reduction in cpu time by 2 orders of magnitude whatever the level of mesh refinement this gain in cpu time is mainly related to the better convergence properties of our proposed scheme 5 results field scale applications 5 1 objectives and overall presentation of the site this section aims at demonstrating the applicability of the proposed numerical scheme in simulating real field cases thus we use our code mh lump 1d 2d to investigate the effect of climate change on groundwater resources in a karst aquifer spring system in el assal lebanon in particular we use this code to evaluate the effect of a fracture network on the hydrodynamics behavior of the aquifer and the predictions of groundwater resources under potential impact of climate change this field application demonstrates the capability of the developed scheme to perform simulations at not only large spatial scale that extends for kilometers but also for large time scale which includes predictions of climate change effects over a period of 80 years it is also essential to show the performance of the new scheme in simulating water table dynamics under highly variable recharge conditions el assal karst spring is located at 1552 m above sea level in mount lebanon lebanon about 50 km from beirut fig 8 a its catchment area of about 12 km2 is delineated based on tracer test experiments the aquifer is composed of three zones of highly fissured thinly layered basal dolostone overlain by dolomitic limestone and limestone of albian to cenomanian age the spring emerges at the top of the underlying marls and volcanics of aptian age the catchment is characterized by a thick unsaturated zone over 400 m dolines were mapped on the catchment to determine zones of point source infiltration disturbed representative soil samples were collected from different locations to determine the hydraulic properties such as particle size distribution and hydraulic conductivity at saturation fractures were mapped in the field along distinct sections the recharge area is located between 1600 m and 2200 m elevation and is mostly dominated by snowmelt the annual discharge of the spring ranges between 15 and 22 mm3 based on high resolution monitoring since 2014 with maxima reaching 2 m3 s following snowmelt and minimum flow rates of 0 24m3 s during recession periods the spring provides downstream villages in the kesrouane district with about 24 000 m3 0 28 m3 s of water daily for domestic use and is an essential historic spring in the region further information about the el assal karst aquifer spring system including the domain geometry and characterization e g soil and aquifer hydraulic parameters is discussed by doummar et al 2018 fig 8b shows the schematic profile of el assal karst aquifer used as the domain of simulation the calibrations of the aquifer properties are out of the scope of this paper the parameters of the porous matrix are used as in doummar et al 2018 where the aperture of the fractures is assumed to be 1cm the saturated hydraulic conductivity of the fractures was calculated using the cubic law and the other parameters were assumed to be similar to the one for the case of infiltration in dry soil see table 2 5 2 methodology for simulation and analysis the domain is discretized using a triangular grid consisting of about 140k elements no flow boundary conditions are assumed at the right inland side and at the bottom surface representing the initial water table on the left side the spring is simulated by imposing a nodal zero pressure head the site is firstly simulated from 2013 to 2019 using real historical data june 1st 2013 to may 29th 2019 in order to understand groundwater flow dynamics in the aquifer under three regimes of recharge including snowmelt precipitation and dry periods we then simulate the site with predicted precipitations for 2019 2099 starting from june 1st 2019 in order to evaluate future responses of the spring discharge variations caused by climate change we extract daily recharge time series 2019 2099 from the calibrated integrated model in doummar et al 2018 where precipitation predictions are obtained from the ipsl cm5 gcm 5th phase of the coupled model intercomparison project dufresne et al 2013 global climatic model for lebanon with a resolution of 0 25 based on the agmerra dataset ruane et al 2015 in doummar et al 2018 the scenario rcp 6 0 was adopted reflecting a stabilization of the radiative forcing value without overshoot pathway at 6 w m2 after 2100 projected raw data were corrected to account for the elevation of the catchment area 1500 2200 m using a constant lapse rate for t 0 24 c and p 5 5 per 100 m elevation for all simulations we consider monthly averaged recharge variation the results of simulations are analysed using the spatial maps of water content θ and three scalar metrics which are i the dimensionless average saturation of the aquifer vm ii the maximum water table elevation h 0 and iii the discharge rate at the spring outlet qout the mathematical expressions of the metrics are stated as follows 24 v m 1 ω ω s e d ω ω is the area of the aquifer and se is the element effective saturation defined in table 1 25 h 0 m a x h x y t h x y t 0 26 q o u t k h x 0 5 3 simulations with real data from 2013 to 2019 we simulate the aquifer using data from june 1st 2013 to may 29th 2019 initially the domain is assumed to be at hydrostatic equilibrium for this period real recharge data are used for 2013 2016 and similar data trends are imposed for 2016 2019 since data for this period are not available to investigate the effect of fractures on the groundwater dynamics we simulate the aquifer using 2 models using the code mh lump 1d 2d the first model considers the fracture network while the second one assumes the domain as homogenous with no fractures the corresponding maps of water content at the end of may 2019 are represented in fig 9 in general similar profiles can be observed on the right side of the aquifer where fractures do not exist a dry zone can be observed between the two wet zones at the top and bottom the appearance of this zone is due to the dry wet cycle of the recharge process during a dry period water saturation at the top aquifer decreases and then during the recharge period the upper surface is rapidly saturated still in the right part of the aquifer but shifted left where fractures occur we observe that the fracture network does not have a dominant trend on the saturation distribution being highly permeable relative to the matrix fractures tend to conduct the flow faster than the adjacent matrix this leads to high dry zones around the fractures which are visible on the top of fig 9a around the centre of the aquifer the preferential flow in the fractures enhances water infiltration and expands horizontally towards the dry zone at the middle depth of the aquifer on the left side the fractures have a more dominant effect contrasting to the results of the unfractured model where a high saturation zone can be observed near the top surface the main streamlines of groundwater flow in the aquifer with the fracture network is shown in fig 10 vertical infiltration can be observed in the unsaturated zone near the water table the groundwater flow is horizontal towards the spring fig 10a it can be seen that flow generally tends to be absorbed and then travel through fractures fig 10b in some instances when a local maximum in the recharge distribution occurs and is followed by a relatively dry period certain points appear near the fractured region which tends to absorb water and create stagnant points nearby fig 10c this behavior is mostly due to the fact that the water is drained faster in the fracture than in the porous matrix resulting in higher conductivity i e higher saturation in the stagnant points compared to their adjacent points in the fracture fig 11 depicts the time variations of the scalar metrics vm h 0 and qout using both the fractured and unfractured models fig 11a confirms that there is a slight gap between both models regarding vm but in general less amount of water is obtained with the fractured model referring to fig 11b we can see that the level of the water table is significantly affected by the fractures which is coherent with the results discussed in fig 9 fig 11c shows that the fractured model leads to higher water flux at the spring outlet compared to the non fracture model these results indicate that the fracture network enhances water infiltration in the aquifer this increases the water discharge through the spring and decreases the amount of water stored in the unsaturated part of the aquifer the results of fig 11c are coherent with the ones in fig 11a as in both models fractured and unfractured the amount of influx from the recharge is the same and more water is discharged with the fracture model fig 11c which should lead to less retention of water in the aquifer with this fracture model this behavior is observed in fig 10a which shows less amount of stored water with the fractured model than the unfractured one 5 4 predictions under climate change from 2019 to 2099 in this section we investigate the effect of fractures on the predictions of water resources in the el assal aquifer under different scenarios reflecting climate change conditions here we investigate the effect of neglecting the fractures on the predicted results thus we simulate the aquifer with the predicted recharge from june 1st 2019 until 2099 we started the simulation with hydrostatic equilibrium on june 1st 2013 we run the models from 2013 until the end of may 2019 using real data as in the previous section we follow with predictions since june 2019 where we consider recharge under climate change the aquifer is simulated using 3 models the first model named f ncc considers the fracture network but neglects the effects of climate change on recharge in this model we assume that the recharge distribution of 2013 2019 occurs over the next eighty years up to 2099 the second model named f cc considers the fracture network and assumes variable recharge due to the effect of climate change as in fig 8c the last model neglects the fracture network i e considers the domain as homogenous and assumes variable recharge due to climate change this model is denoted by nf cc the results of the three models regarding the map of water saturation are presented in fig 12 at first glance the water content and the saturated zone are higher in the model with neglected variations of recharge due to climate change as expected with climate change effects the fracture model leads to a lower water table than the homogenous model this is expected as the preferential flow in the fracture network enhances water infiltration through the unsaturated zone investigating further through the transient behavior of the proposed metrics we can obtain better insights as shown in fig 13 in this figure the effect of climate change reduces the amount of available water in the aquifer as well as the water discharge at the spring outlet this is observed from the differences between the model with neglected climate change effects red curves and the models with these effects blue and orange curves under climate change conditions we can observe two regimes of time variation starting from hydrostatic equilibrium in 2020 during the first 40 years from 2020 to 2060 the amount of water available in the aquifer the water level table and the discharge flux at the spring will increase after 2060 these metrics will exhibit a decreasing variation with time indicating less availability in water resources due to climate change the general patterns of the results of the models f cc and nf cc indicate that neglecting fractures leads to an overestimation of the available water resources in the aquifer the difference in the estimated amount of available water with both f cc and nf cc models is evident from early time and continues during all the simulated period the level of the water table is slightly sensitive to fractures neglecting fractures in the model would lead to some periods where the level of the water table is overestimated and other periods where it is underestimated this effect is also observed for the water discharge in the spring as the spring outlet discharges the most important metric we explore more the variability of this metric in fig 14 for the period 0 7000 days until 2033 it is clear that the discharge flux estimated with the fractured model is higher than the one with the unfractured model thus we focus the analysis in fig 14 on the period 2033 2099 this figure shows simultaneously the normalized distribution of the projected recharge normalized using the maximum recharge value along with the normalized difference between spring outlet discharge of the f cc and nf cc models δqout both recharge and δqout are normalized using the maximum value of the recharge influx it can be observed that the higher variability in the recharge distribution results in higher variability of δqout and higher inaccuracy in the prediction of the outlet discharge the other interesting observation is the delay in the response of the system at approximately 20000 days late 2060 this point corresponds to the high recharge influx at 17000 days early2060 we presume that this delay is due to the high fluctuation of the recharge at this period which results in high dry soil in the next dry season and saturated fractures saturated fractures i e highly permeable fractures tend to absorb the flow from the nearby matrix resulting in much slower flow in the soil and a slower response of the spring in other words the fractures act as a sink for the flow which impacts the flow locally in the aquifer resulting in a lag time between the recharge event and the spring discharge response this lag time can grow over time due to the increase of variation of the recharge caused by the climate change 6 conclusion simulation of the vsf in a discretely fractured domain is a computationally challenging problem which requires solving the re in the matrix and dense fracture networks involving complicated geometry and discontinuities in the hydraulic properties the presence of fractures adds complexity to the re solution which is already a challenging task without fractures existing numerical models of vsf in discrete fractured domains are limited to standard numerical techniques that limit their applications in field studies we develop a new numerical scheme for solving re in discrete fractured domains by combining advanced techniques for space and time discretization the fracture network is considered via the hybrid dimensional technique 1d fractures in a 2d matrix for the space discretization we extend the mhfe to deal with vsf in fractured vadose zones we develop a new ml technique for the fractures to improve the performance and the robustness of the method in simulating preferential flow in dense fracture networks for time integration while existing numerical models for flow and transport in fractured domains deal with standard backward euler first order method we use an sophisticated technique based on adaptive high order technique with accurate adaptive time stepping procedure we use the mol to couple mhfe method ml technique for fractures and high order adaptive technique the mhfe method is used for vsf in fractured media for the first time the new proposed numerical scheme is implemented in a fortran code and validated against comsol multiphysics on a case dealing with water table recharge we show the stability of our scheme based on the m matrix property we also highlight its advantages and performance by comparing it against other standard numerical techniques in simulating a challenging case of water infiltration in dry soil under imposed pressure heads the results show that the suggested ml technique eliminates all numerical oscillations and improves the convergence of the nonlinear solver leading to a significant reduction in computational time the proposed scheme is then used to investigate the effect of climate change on groundwater resources in a karst aquifer spring system in el assal lebanon this application shows the performance of the proposed scheme in simulating problems with large time and space scales under variable recharge conditions the simulations are performed with a computational mesh consisting of about 140k elements for a duration of about 87 years and under high variable recharge conditions snowmelt rain and dry periods the corresponding cpu time is less than 1 hour the results show that neglecting the fracture network in the aquifer would lead to an overestimation of the amount of available water as well as the groundwater discharge through the spring outlet the proposed scheme is generic and can be extended to other applications the developed ml technique for fractures and the procedure used for time integration can be applied for other finite element based methods the application to the el assal aquifer can also be extended to model more detailed analyses aiming at determining the parameters of the matrix and fractures based on available observation data this model has the features to be coupled with an optimization procedure to calibrate simulations with field observations the proposed scheme can be extended to 3d which is an ongoing task of this work author statement behsahd koohbor worked on the development of the numerical model and simulations marwan fahs framed the research questions and worked on the writing hussein hoteit framed the research questions and worked on the model development anis younes and benjmain belfort supervised the research and finalized the manuscript joanna doummar worked on the simulations of the real case declaration of competing interest the authors declare that there is no conflict of interest regarding the publication of this article acknowledgments marwan fahs would acknowledge the support from the national school of water and environmental engineering of strasbourg through the research project poro6100 the characterization of the case study including data collection was funded in the framework of a usaid peer science project award number 102881 cycle 3 the data used in this work are available on the github repository https github com fahs lhyges 
497,accurate modeling of variably saturated flow vsf in fractured porous media with the discrete fracture matrix dfm model is a computationally challenging problem the applicability of dfm model to vsf in real field studies at large space and time scales is often limited not only because it requires detailed fracture characterization but also as it involves excessive computational efforts we develop an efficient numerical scheme to solve the richards equation in discretely fractured porous media this scheme combines the mixed hybrid finite element method for space discretization with the method of lines for time integration the fractures are modeled as lower dimensional interfaces 1d within the 2d porous matrix we develop a new mass lumping ml technique for the fractures to eliminate unphysical oscillations and convergence issues in the solution which significantly improves efficiency enabling larger field applications the proposed new scheme is validated against a commercial simulator for problems involving water table recharge at the laboratory scale the computational efficiency of the developed scheme is examined on a challenging problem for water infiltration in fractured dry soil and compared with standard numerical techniques we show that the ml technique is crucial to improve robustness and efficiency which outperforms the commonly used methods that we tested the applicability of our method is then demonstrated in a study concerning the effect of climate change on groundwater resources in a karst aquifer spring system in el assal lebanon simulations including recharge predictions under climate change scenarios are carried out for about 80 years up to 2099 this study demonstrates the applicability of our proposed scheme to deal with real field cases involving large time and space scales with high variable recharge our results indicate that the water table level is sensitive to the presence of fractures where neglecting fractures leads to an overestimation of the available groundwater amount the proposed numerical approach is generic for dfm model and can be extended to different 2d and 3d finite element frameworks keywords variably saturated flow fractured porous media discrete fracture matrix model mass lumping mixed hybrid finite element method method of lines climate change submitted to advances in water resources special issue advances in upscaling and characterization of flow and transport phenomena in porous media 1 introduction understanding variably saturated flow vsf in fractured porous media has great significance to many environmental and geotechnical applications such as groundwater recharge in karst aquifers mudarra and andreo 2011 de rooij et al 2013 de rooij 2019 epikarst chang et al 2019 and unconfined chalk aquifers ireson et al 2009 vsf in fractured zones has been studied for geological disposal of nuclear waste such as the one at yucca mountain in the united states where an unsaturated zone was assessed to serve as a potential site for the deposition of high level nuclear wastes hayden et al 2012 ye et al 2007 other applications include contaminant transport and infiltration of landfill leachate brouyère 2006 ben abdelghani et al 2015 infiltration through unsaturated saprock in hillslopes with shallow fractured shale bedrock guo et al 2019 unsaturated flow and contaminant transport in saprolite van der hoven et al 2003 alazard et al 2016 water flow in cracked soils and stability of soil slopes with cracks pouya et al 2013 wang et al 2019 yang and liu 2020 seepage through fissured dams jiang et al 2014 tunnel excavation gokdemir et al 2019 and protection of structure foundations in contact with water zhao et al 2019 among others fractures in the vadose zone typically provide preferential flow pathways however they could also act as flow barriers from capillary forces depending on the degree of saturation cey et al 2006 wang and narasimhan 1985 the vsf in fractured porous media involves several coupled and complex processes such as capillary and gravity driven transient flows preferential flow in fractures and fracture matrix interactions from imbibition and diffusion hoteit 2013 due to these complexities and despite the broad range of applications the processes of vsf in fractured porous media are not well understood related experimental studies are scarce and limited to simplified fracture configurations for instance yang et al 2019 presented an experimental study to investigate vsf through a simple t shaped fracture intersection wang et al 2017 investigated the effect of fracture aperture on capillary pressure saturation relation kordilla et al 2017 studied the effect of droplet and rivulet unsaturated flow modes at simple intersecting fractures based on experiments tokunaga and wan 2001 introduced a new mechanism of vsf in a single fractured domain named as surface zone flow which can appear when the permeability of skin fractures is significantly higher than that of the porous matrix most of the studies related to vsf in fractured domains rely on numerical simulations which are used for several theoretical and practical purposes for instance understanding physical processes liu et al 2002 2004 field studies zhou et al 2006 ye et al 2007 masciopinto and caputo 2011 kordilla et al 2012 ben abdelghani et al 2015 robineau et al 2018 and validation of laboratory experiments roels et al 2003 malenica et al 2018 in applied studies numerical simulations are considered as an irreplaceable and cost effective tool for designing predicting and uncertainty assessments unsaturated flow in porous media is usually described using the richards equation re that combines darcy s law and continuity equation which are coupled via constitutive relations expressing permeability and water content as a function of the hydraulic head farthing and ogden 2017 re is a simplification of the two phase water air flow model assuming that air remains essentially at atmospheric pressure this approximation is valid when the effect of air on water flow is negligible szymkiewicz 2013 the models used to treat the fractures can be classified into two main categories the equivalent continuum model ecm and the discrete fracture matrix dfm model with the ecm the fractured domain is represented by a homogenous porous media with equivalent hydraulic parameters in this case re is used with a specific permeability constitutive relation and retention curve including the effect of fractures the main drawback of ecm is related to the development of effective retention and permeability curves in the presence of fractures guarracino and quintana 2009 monachesi and guarracino 2011 pouya et al 2013 the dual porosity model which can be seen as an extension of the ecm treats the fractured domains as dual interactive continua representing fractures and porous matrix respectively brouyère 2006 kuráž 2010 different hydraulic properties are associated to each continuum flow cannot occur in the matrix continuum which only acts as a source sink term while the fracture continuum provides the flow connectivity despite its low storage capacity fahs et al 2014 on the other hand the dual permeability model is more used than dual porosity for vsf in fractured domains as it allows for moisture flow in both the fracture and matrix continua kordilla et al 2012 robineau et al 2018 the dual permeability model requires two sets of constitutive relations for the fracture and matrix domains unlike ecm and dual continua models the dfm model is based on an explicit description of fractures with dfm model the hydraulic properties of fractures and their topology are considered explicitly where the matrix and the fractures are modeled as separate elements of one continuum for dfm model re is often utilized to simulate flow in both fractures and matrix but with different constitutive relations and properties for each medium examples of utilization of the dfm model for vsf can be found in therrien and sudicky 1996 masciopinto and caputo 2011 ben abdelghani et al 2015 li and li 2019 and li et al 2020 ecm provides efficient simulations with relatively low computational costs and complexity it is relatively simple and straightforward to implement which is commonly used in real field applications liu et al 2005 however the accuracy of this model is highly dependent on the validity of the equivalent retention curves and constitutive relations in representing the matrix and the fractures liu et al 2005 ecm is not suitable for small scale applications or for cases involving a small number of fractures roels et al 2003 further this method cannot provide a detailed description of the flow dynamics in fractures and fails to reproduce the preferential flow paths encountered in fractured vadose zones liu et al 2005 2007 in many applications dfm model is more suitable to simulate preferential flow as fractures are captured in more detail this model is essential to understand water flow processes in fractures at a small scale cey et al 2006 it is also applied at the field scale with a small number of well defined fractures hirthe and graf 2015 ben abdelghani et al 2015 however dfm model is computationally expensive and requires detailed information about the fractures the inefficiency is related to the dense computational meshes and often causes poor convergence due to the high discontinuity between the hydraulic properties of fractures and matrix particularly in the case of dense fracture networks berre et al 2019 nordbotten et al 2019 a common approach that significantly alleviates the computational complexity of the dfm model is the hybrid dimensional technique therrien and sudicky 1996 hoteit and firoozabadi 2008 li et al 2020 in which the fractures are considered as co dimensional interfaces with respect to the full dimensional elements representing the matrix i e one dimensional fractures in the two dimensional matrix elements with the continued advancement in new numerical methods and the recent progresses in powerful computational technologies the dfm model has received an increasing interest due to its robustness in reproducing physical processes of flow and transport in fractured porous media this results in extensive research on the development of appropriate numerical techniques and schemes that aims at improving the computational performance of the dfm model for saturated flow ahmed et al 2017 berre et al 2019 nordbotten et al 2019 this study focuses on the use of the dfm model for the simulation of unsaturated flow in vadose fractured zones modeling vsf in explicitly fractured domains i e with the dfm model remains a computationally challenging task which usually exhibits numerical complexities li and li 2019 the challenges are not only due to the presence of dense fractures and the associated complex geometry property discontinuities quality of mesh discretization and poor convergence but also due to the inherent numerical complexities of the re li and li 2019 it is well known that the numerical solution of the re even in unfractured domains is one of the most challenging problems in hydrogeology miller et al 2013 numerical difficulties are caused by the mathematical characteristics of this equation that could change from hyperbolic to parabolic depending on the saturation alongside there is strong nonlinearity introduced by the constitutive relationships suk and park 2019 slow no convergence small time steps mass conservation and numerical oscillations are common numerical issues that are usually encountered in the solutions of re significant efforts have been made in last decades on the development of advanced and appropriate numerical techniques for solving this equation celia et al 1990 farthing et al 2003 li et al 2007 ji et al 2008 fahs et al 2009 hassane maina and ackerer 2017 suk and park 2019 ngo cong et al 2020 the most investigated problems are related to the selection of the primary variable pressure head water content or mixed form mass conservative solution time and spatial discretization schemes nonlinear solvers and numerical evaluation of equivalent hydraulic conductivity miller et al 2013 and references therein more details about the numerical solution of re can be found in recent review papers by farthing and ogden 2017 and zha et al 2019 unlike in unfractured media numerical solutions of re in explicitly fractured domains are not well developed most of the existing tools are based on the standard finite element method for space discretization and backward euler scheme for time integration therrien and sudick 1996 these traditional methods may not be suitable to solve the re equation under complex fractured configurations this restricts the applicability of the existing models for engineering practice especially at real scale hence it is important to carry out further studies on the development of robust and efficient numerical techniques to solve the re in explicitly fractured domains involving complex fracture networks which is the main objective of this study this is crucial to improve the capability of current models in developing more realistic simulations and to deal with the growing demand on predicting and understanding the dynamics of aquifers under non stationary conditions at large time and space scales the objective of this paper is to develop a new numerical technique for vsf in fractured porous domains that is not only accurate but also efficient and fast which is a fundamental challenge of computation water resources in this work we couple advanced numerical techniques for space discretization and time integration to solve the re in explicitly fractured domains we consider the head form of the re this form allows for efficient numerical solutions as the pressure head is used as the only primary variable however this approach may lead to non conservative solutions when it is solved with first order time integration methods celia et al 1990 farthing et al 2003 to avoid this problem and to obtain conservative solutions we use high order integration techniques as it is discussed further in this section among different existing techniques for space discretization we use the mixed hybrid finite element mhfe method brezzi and fortin 1991 farhloul and fortin 2002 farhloul 2020 a review about the use of this method and its advantages e g local mass conservation ability to intrinsically treat anisotropic domains consistent velocity field even in highly heterogeneous domains in simulating groundwater flow can be found in younes et al 2010 the mhfe method was initially used to simulate saturated flow in simple porous media younes et al 1999 it has been then extended to vsf by farthing et al 2003 fahs et al 2009 and belfort et al 2009 as the method deals with the water fluxes and average pressures at the edges of the mesh elements it is highly suitable for the dfm model with the hybrid dimensional technique where fractures are defined on the edges of the matrix elements the method has been extended to the simulation of flow in fractured porous media in hoteit and firoozabadi 2008 zidane and firoozabadi 2014 2018 chen et al 2016 moortgat et al 2016 and moortgat 2017 to our knowledge the mhfe has been yet applied for vsf in fractured media one of the objective of this work is to extend this method to vsf in explicitly fractured domains and to evaluate its performance in such an application combined with the mhfe we introduce a new mass lumping ml technique as the nonlinearity of the re imposes small time steps most finite element based methods suffer from spurious oscillations related to the discretization of the transient accumulation term hoteit et al 2002 elguedj et al 2009 scudeler et al 2016 this problem has been encountered with the mhfe in belfort et al 2009 for re the problem of unphysical oscillations is particularly crucial as it leads to a loss of numerical stability that would affect the convergence of the nonlinear solver younes et al 2006 developed an ml technique for the mhfe to eliminate unphysical oscillations belfort et al 2009 extended the ml technique to vsf in unfractured domains fučík 2019 applied the mhfe method to compositional two phase flow in heterogeneous porous media and showed that ml technique is needed for handling material discontinuities in this work we develop an efficient approach to generalize the ml technique to vsf in fractured domains besides spatial discretization selecting an efficient temporal scheme is crucial little attention has been devoted to the time integration of groundwater flow in fractured domains moortgat et al 2016 this is also true for vsf with the dfm model existing numerical models are based on the first order backward euler scheme therrien and sudick 1996 however several works show the advantages of higher order time integration schemes for the simulation of unsaturated flow farthing et al 2003 showed that with a higher order time integration scheme conservative solutions could be obtained even with the non conservative form of the re fahs et al 2009 proved that adaptive high order time integration schemes could lead to faster solutions than standard first order methods here we couple the mhfe and the ml technique to an adaptive high order time integration scheme via the method of lines mol matthews et al 2004 this approach permits using a sophisticated ordinary differential equation ode solver for time integration dlsodis that allows besides high order adaptive time integration an appropriate time stepping management and efficient procedure to deal with nonlinearities 2 governing equations of vsf in fractured domains vsf in fractured and porous media is described by the re coupling the darcy buckingham s law and the mass conservation equation as shown below 1 q β k β s e β h β h β 2 c β h β s s β s w β θ β h β t q β f β 3 h β h β z where the superscript β m f is the medium index m for matrix and f for fracture hβ l and hβ l are respectively the piezometric head and pressure head and z l is the elevation the list of variables and parameters associated with eqs 1 and 2 are provided in table 1 we use the standard form of the van genuchten 1980 model for the inter relation of pressure head and water content where different properties are considered for the matrix and fractures 4 s e β θ β θ r β θ s β θ r β 1 1 α β h β n β m β h β 0 1 h β 0 in the above equation αβ l 1 and n β are parameters related to the mean pore size and uniformity of mean size distribution of the matrix and fractures and m β 1 1 n β for conductivity saturation relationship the van genuchten mualem model mualem 1976 is given by 5 k β k s β s e β 1 1 s e β 1 m β m β 2 3 numerical solution mhfe method ml technique and mol we develop a new numerical scheme to solve the system of eqs 1 5 using 2d unstructured triangular meshes the scheme can also be used with other mesh types as mentioned in the introduction the fractures are considered with the hybrid dimensional technique as 1d interfaces of the 2d elements representing the matrix this approach provides a significant reduction in the complexity of the computational mesh however the local density and complexity of the fracture network should be considered as presented in berre et al 2019 the complex fracture network causes challenges to the generation of a conforming mesh the developed scheme couples the mhfe and ml technique for space discretization with an advanced ode solver for time integration via the mol this method consists of discretizing the space derivatives while maintaining the time derivative in its continuous form this discretization allows converting the system of partial differential equations into a system of odes which is solved using a sophisticated solver the main steps of the developed schemes are detailed here 3 1 trial functions of the mhfe method for the matrix and fractures since the matrix and fracture elements exhibit different dimensions the governing equations are discretized separately then coupled and solved simultaneously in the matrix based on the formulation of mhfe the total flux across an edge of an element e referred to as qe is approximated as the following chavent and jaffré 2014 6 q e i 1 n f q i e w i e where q i e is the flux across edge i in element e referred to as ei this discretization technique applies to the matrix elements fig 1 a and the fracture interfaces fig 1b for fracture edges element e becomes e and the edges of the elements become the nodes of the fracture edge we use the lowest order raviart thomas space raviart and thomas 1977 for which nf is equal to 3 for triangles used for matrix elements and 2 for the fracture edges the shape functions w i e for the ith edge of a matrix element e when using the lowest order raviart thomas space are 7 w i e 1 2 e x x i e z z i e i 1 2 3 where e l2 is the surface area of the matrix element and x i e l and z i e l are respectively the horizontal and vertical coordinates of the opposite node to ei the shape functions for the fracture edges are 8 w i k 1 ℓ ξ ξ i i 1 2 where ℓ l is the length of the fracture edge and ξ i l is the local coordinates of the opposite element node 3 2 flux discretization in the matrix elements mhfe method and ml technique applying the mhfe discretization to eq 1 using the flux expression from eq 6 on a matrix element and then rearranging the two sides of the equation we obtain the following expression of the fluxes younes et al 2006 9 q i e j 1 3 m e i j 1 h e t h j e where he and thj e are respectively the mean piezometric head in element e and on edge ej m e i j 1 is the inverse of the local stiffness matrix obtained as followed 10 m e i j e w i e k e 1 w j e using the mass lumping scheme presented by younes et al 2006 the flux across the edges of the element e are approximated as followed 11 q i e q i e q s e 3 e 3 c e s s e s w e d t h i e d t where q s e l2t 1 is the sink source term imposed on the matrix element e q i e l2t 1 is the flux corresponding to the stationary problem without the sink source term that can only be expressed as a function of alternated local matrix and traces of the piezometric head 12 q i e j 1 3 n e i j t h j e the local matrix ne has the following form with the notations written after 13 n e i j α e i α e j α e m e i j 1 14 α e i j 1 3 m e i j 1 a n d α e i 1 3 α e i 3 3 flux discretization for a fracture element the formulation of mhfe in the fracture element k is similar to the formulation in the matrix elements see hoteit and firoozabadi 2008 using the same approach as presented for the discretization in the matrix fluxes are expressed by the average hydraulic head on the fracture edge and hydraulic head on the fracture nodes see fig 1 15 q i k 1 2 m k i j 1 h k t h j k 16 m k i j ℓ w i k k k 1 w j k applying eq 15 on eq 2 for the fracture edges the continuity equation treated with a finite volume procedure leads to 17 ε ℓ c k h k s s k s w k θ k d h k d t ε i 1 2 q i k q s k q f k where ε l and ℓ l refer to the fracture aperture and length respectively q s k l2t 1 represents the sink source term inside the fracture and q f k l2t 1 is the matrix fracture volumetric exchange flux which is explained in the next section 3 4 hybridization mass conservation on edges obtaining the global format of the discretized equations requires coupling the flux and piezometric head associated with neighboring elements e and e having ei in common if edge ei is not a fracture the continuity of flux and piezometric head is imposed such that 18 q i e q i e 0 t h i e t h i e if ei coincides with a fracture the total flux across both sides coming from the adjacent matrix elements defines the matrix fracture exchange flux q f k which acts as a sink source term on the fracture edge as for the continuity of piezometric heads the mean heads associated with the matrix edges are equal to the mean head in the fracture element that is 19 q i e q i e q f k h k t h i e t h i e for further explanation on the elimination of q f k in the final format of the equations refer to hoteit and firoozabadi 2008 3 5 the new ml technique for fractures the global matrix corresponding to the discrete system of equations does not necessarily satisfy the m matrix conditions which requires a non singular matrix with mii 0 and mij 0 younes et al 2006 hoteit et al 2002 the m matrix property ensures respecting the discrete maximum principle in other words the solution is free from unphysical oscillations the global matrix obtained by mhfe is symmetric and positive definite but is not in general an m matrix in order to improve the property of our numerical scheme we use a combination of two mass lumping techniques one for porous matrix elements as shown in section 3 2 and a new technique that we propose for fracture edges this proposed mass lumping scheme applied to the fracture edges ensures the consistency of the m matrix property for the combined matrix fracture system to explain the mass lumping scheme for the fracture edges the global matrix of the discrete system resulting from the mhfe method is decomposed into nine submatrices including six sub matrices being pairwise transpose of each other due to the symmetry of the global matrix the decomposition of the global matrix and different sub matrices are shown in fig 2 matrix a is composed of the coefficients associated with flux continuity between adjacent porous matrix elements where interfaces are not fractures a is similar to the one obtained with mhfe in unfractured domains as the ml technique is used for porous matrix elements a satisfies the m matrix properties younes et al 2006 matrix b denotes the coefficients associated with the connectivity of the porous matrix and the edges shared with fractures which are all negative or zero see eq 11 matrix c represents the contribution of fracture nodes on the flux continuity on the unfractured edges the coefficients of c are all zero due to the fact that there is no flow exchange between the fracture nodes and matrix edges matrix d is also an m matrix see eq 11 and matrix e has all negative or zero components when applying the mass lumping defined in eq 11 however matrix f which corresponds to the connectivity and flow exchange between fracture edges is not necessarily an m matrix to get a global matrix satisfying the m matrix conditions we propose a numerical integration technique to calculate the stiffness matrix m k i j 1 such that 20 m k i j 1 k f k ℓ 2 0 ℓ ξ ξ i ξ ξ j d ξ kf k is the hydraulic conductivity of the fracture element k the matrix format of m k i j is given by 21 m k 1 k f k ℓ 2 0 ℓ ξ ξ i ξ ξ i d ξ 0 ℓ ξ ξ i ξ ξ j d ξ 0 ℓ ξ ξ j ξ ξ i d ξ 0 ℓ ξ ξ j ξ ξ j d ξ the calculation of the integrals in each component of the matrix can be approximated numerically fig 3 describes schematically the process in fig 3a the red area represents the integral of the diagonal terms of matrix mk eq 21 in fig 3b the red area corresponds to the integral for the off diagonal terms of the mk eq 21 applying the ml technique in the fractures the red areas are approximated using the rectangular integration as represented with the blue areas this integration approach results in zero off diagonal elements for the matrix calculating the integral analytically red surface in fig 3 leads to a stiffness matrix that does not satisfy the m matrix properties however numerical approximation the blue surface in fig 3 leads to the following 22 m k ℓ 2 k f k i 23 m k 1 2 k f k ℓ i where i is the identity matrix the process leads to a diagonal stiffness matrix hence sub matrix f satisfies m matrix condition that guarantees stable solution in each time step the validity of the results is demonstrated in the following sections 3 6 high order adaptive time integration the system of differential equations obtained by coupling the discretized fluxes in the matrix and fracture elements leads to a system of temporal odes in this work we solve this system using the advanced solver dlsodis double precision livermore solver for ordinary differential equations implicit form and sparse matrix which is a public domain solver hindmarsh 1980 seager and balsdon 1982 the solver is based on the backward differentiation formula bdf it has the advantage of using a high order time integration scheme both variable time step sizes and variable integration orders are used to reach accurate solutions with optimized cpu time the integration order variability makes this solver highly accurate when compared to conventional constant order solvers in particular for vsf and as shown in farthing et al 2003 and fahs et al 2009 high order schemes lead to accurate mass balance even with the non conservative form of re the variability of time step size allows reducing the calculation time and therefore results in exceptional efficiency improvement the accuracy of dlsodis is controlled by various tolerances related to the relative and absolute errors which are set to 10 6 in this work the time step size is changed and adapted periodically by the solver to honor the imposed tolerances the algebraic nonlinear system resulting from the temporal integration of each time step is solved using a modified newton iteration scheme radhakrishnan and hindmarsh 1993 where the jacobian matrix is calculated numerically using a finite difference approximation and a column grouping technique of curtis et al 1974 4 results verification and advantages of the new developed numerical scheme 4 1 verifications fractured vauclin test case the developed numerical scheme based on the combination of the mhfe method ml technique and mol was implemented in a fortran code the main goal of this section is to verify the correctness of this code thus we consider a computationally simple example in order to avoid numerical artifacts the example is inspired by the laboratory experiments of vauclin et al 1979 dealing with water table recharge this example is accepted as a standard benchmark for vsf as it provides reliable experimental data with simple boundary conditions the laboratory experiments of vauclin et al 1979 deals with unfractured homogenous soil we adopted four fractured examples by assuming the same configuration geometry dimensions and boundary conditions and by embedding in the domain i a single vertical fracture ii a single horizontal fracture iii a single inclined fracture and iv a network of fractures similar to the ones encountered in karst aquifers the original experimental setup of vauclin et al 1979 consists of a rectangular soil slab 600cm 200cm a constant influx of 355 cm day is applied over a width of 100cm in the center top of the domain initially the water table is located at 65cm from the bottom surface because of the symmetry only the right half of the domain is considered and the axis of symmetry acts as an impermeable boundary on the left the rest of the boundary and initial conditions are similar to the original experiment the hydrological properties of the porous matrix are obtained from clement et al 1994 whereas the fracture properties are selected from fairley et al 2004 kuráž et al 2010 the matrix and fracture parameters are provided in table 2 effects of these parameters on vsf in fractured domain is beyond the scope of the paper the most computationally challenging values are considered with an emphasis of their high hydrodynamic conduction of fractures compared to the soil matrix our developed code based on the mhfe method ml technique for both fractures and matrix and the hybrid dimensional technique 1d fractures and 2d porous matrix is referred to as mh lump 1d 2d this code is verified here by comparison against an in house code based on the mhfe method and dealing with vsf in unfractured domains the in house code has been validated against experimental data in fahs et al 2009 in this in house code both matrix and fractures are considered as 2d elements thus this second code is referred as mh 2d 2d an example of the difference between the computational mesh used in mh lump 1d 2d and mh 2d 2d is given in fig 4 for more confidence in the correctness of the newly developed code mh lump 1d 2d we compare it against a finite element solution from comsol multiphysics this software provides a tool to simulate fractured porous media based on the hybrid dimensional technique however when this tool is used for vsf the fractures are always assumed as saturated which is not the case in our examples thus as in the code mh 2d 2d we consider the fractures as 2d elements in comsol the comsol model is denoted as comsol 2d 2d the numerical codes used for verifications and summary about corresponding numerical techniques are given in table 3 in all codes including the comsol model the time integration is performed in the same manner using the bdf method with variable order the simulations are performed for one hour of recharge for all cases the computational meshes used in the simulations with the code mh lump 1d 2d consist of about 17k elements for the cases of horizontal vertical and inclined fracture and about 40k elements for the fracture network configuration with the same level of refinement in the matrix the corresponding computational meshes used for the codes mh 2d 2d and comsol 2d 2d consist of about 20k elements for the first three cases and about 80k elements for the fracture network case the numbers of elements in the 1d 2d and 2d 2d models show that the hybrid dimensional technique allows for a significant reduction in the mesh density as it avoids local refinements within the fractures the gain is more pronounced for dense fracture networks the computational grids for all cases were generated using the comsol meshing tool fig 5 shows the contour map of the volumetric water content θ for different test cases after one hour t 1hr this figure shows that in the case of a single fracture the higher water table is observed for the vertical fracture fig 5a this behavior makes sense as the vertical preferential flow occurring in the fracture driven by gravity and capillarity enhances the water table recharge the lowest water table is observed in the case of horizontal fracture in which the horizontal preferential flow moves water away from the water table and slow down the water recharge rate fig 5b in the case of the inclined fracture the inclination decreases the vertical component of the preferential flow and increases its horizontal components thus it is expected that the water table in this case falls in the middle between the vertical and horizontal cases fig 5c the case dealing with the schematic karst network leads to the highest water table among all cases fig 5d this behavior is a result of the multiple vertical fractures that could recharge the water table faster than the other cases in the case of a single vertical fracture as the fracture is quickly saturated water exchange with the surrounding matrix is significant hence fig 5a and d show a high level of water saturation around the fractures in the case of a single vertical fracture and fracture network finally fig 5 shows overall excellent agreement between the three codes which gives confidence in the correctness of our code mh lump 1d 2d some minor discrepancies can be observed at the water front which are related to dissimilarities of the mesh size in 2d 2d and 1d 2d refinements near the fractures these differences can be reduced by further refining the mesh near the fractures 4 2 advantages of the ml technique for fractures the advantages of the ml technique for vsf in unfractured domains is discussed in belfort et al 2009 fahs et al 2009 showed that besides stable solutions and good convergence properties the ml technique allows for solving re in unfractured domains in an efficient manner using high order time integration scheme in fractured domains the ml technique is applied for unsaturated flow in this work for the first time for saturated flow this technique may not be critical as the saturated flow does not require small time steps for which numerical instabilities could appear for vsf small time steps should be used to guarantee the convergence of the nonlinear solver thus spurious oscillations may affect both the accuracy and convergence rate of the solutions an essential contribution of this work is the development of the ml technique for the dfm model for the matrix we apply the same ml technique as developed in fahs et al 2009 for unfractured domains the major contribution of this work is in the development of the ml technique for the fractures in section 3 5 we investigate the stability of the corresponding solutions via a theoretical analysis based on the m matrix property the main goal of this section is to verify the stability of the developed ml technique particularly for fractures and to investigate its advantages via numerical experiments to do so we consider the newly developed code mh lump 1d 2d in which the ml technique is implemented for the matrix and fractures and a modified version called mh cons 1d 2d in which ml technique is used only for the matrix to compare these models we consider the challenging case of infiltration in dry soil with imposed heads at the top and bottom surfaces huang et al 1996 ngo cong et al 2020 besides the nonlinearity related to re this problem involves an extremely moving sharp front that cannot be captured numerically without introducing dense grids and small time steps the later causes unphysical oscillations and convergence difficulties in contrast to the imposed flux boundary condition the dirichlet boundary conditions imposed at the soil top surface compound the numerical difficulties as they require an appropriate approach for the evaluation of the equivalent hydraulic conductivity belfort et al 2013 this problem has been widely investigated in the literature and the common question is to develop an accurate solution forsyth and pruess 1995 huang et al 2002 arico et al 2012 younes et al 2013 list and radu 2016 islam et al 2017 zha et al 2017 ngo cong et al 2020 all the exiting studies suggested appropriate numerical solutions for unfractured domains simulations of problems dealing with infiltration in dry fractured soil are not well developed in the literature the results presented here can serve as a benchmark for code verification the geometry is inspired by a real fractured outcrop corresponding to a fractured aquifer in jeita lebanon fig 6 a boundary conditions and soil parameters are similar to huang et al 1996 constant pressure heads of 10 cm and 1000 cm are imposed at the top and bottom boundaries of the domain respectively and an initial pressure head of 1000 cm representing a highly dry soil is assumed side boundaries are assumed impermeable the hydraulic parameters of the matrix and fractures are given in table 2 fig 6b shows the 1d 2d mesh gridding consisting of 1626 triangular elements for the matrix and 272 linear elements for fractures the duration of the simulation is set to be 3 2 104s about 9 hours the mh cons 1d 2d code had convergence difficulties after 3 hours of simulation a close look at the results at this time shows that the waterfront reaches the fractures fig 6c spurious oscillations appear mostly near the fractures incoherent results can be observed with pressure head beyond physics below 1000cm these oscillations cause the convergence of the nonlinear solver to fail as the system of equations becomes ill conditioned the mh lump 1d 2d code runs without any convergence problems for the entire simulation duration the results at t 3 h are given in fig 6d this figure shows a stable solution free from spurious oscillations with further advancement of time fast preferential flow in the dry soil can be noticed along with all the fracture elements fig 6e the demonstration of actual flow in the matrix and fractures can give better insights about the general direction of the flow and conductive behavior of the fractures see fig 6f we also investigate the effect of the ml technique in fractures on the performance of the numerical models thus we compare the cpu time of the mh lump 1d 2d and mh cons 1d 2d codes for different levels of mesh refinement it should be mentioned that the computer system used for all the simulations in this section and other sections has an intel core i7 6700 cpu at 3 4 ghz with 16 gb 2 8gb of installed memory ram fig 7 gives the variation of the cpu for both codes versus the number of elements of the computational grids it shows that the ml technique in fractures allows for a significant reduction in cpu time by 2 orders of magnitude whatever the level of mesh refinement this gain in cpu time is mainly related to the better convergence properties of our proposed scheme 5 results field scale applications 5 1 objectives and overall presentation of the site this section aims at demonstrating the applicability of the proposed numerical scheme in simulating real field cases thus we use our code mh lump 1d 2d to investigate the effect of climate change on groundwater resources in a karst aquifer spring system in el assal lebanon in particular we use this code to evaluate the effect of a fracture network on the hydrodynamics behavior of the aquifer and the predictions of groundwater resources under potential impact of climate change this field application demonstrates the capability of the developed scheme to perform simulations at not only large spatial scale that extends for kilometers but also for large time scale which includes predictions of climate change effects over a period of 80 years it is also essential to show the performance of the new scheme in simulating water table dynamics under highly variable recharge conditions el assal karst spring is located at 1552 m above sea level in mount lebanon lebanon about 50 km from beirut fig 8 a its catchment area of about 12 km2 is delineated based on tracer test experiments the aquifer is composed of three zones of highly fissured thinly layered basal dolostone overlain by dolomitic limestone and limestone of albian to cenomanian age the spring emerges at the top of the underlying marls and volcanics of aptian age the catchment is characterized by a thick unsaturated zone over 400 m dolines were mapped on the catchment to determine zones of point source infiltration disturbed representative soil samples were collected from different locations to determine the hydraulic properties such as particle size distribution and hydraulic conductivity at saturation fractures were mapped in the field along distinct sections the recharge area is located between 1600 m and 2200 m elevation and is mostly dominated by snowmelt the annual discharge of the spring ranges between 15 and 22 mm3 based on high resolution monitoring since 2014 with maxima reaching 2 m3 s following snowmelt and minimum flow rates of 0 24m3 s during recession periods the spring provides downstream villages in the kesrouane district with about 24 000 m3 0 28 m3 s of water daily for domestic use and is an essential historic spring in the region further information about the el assal karst aquifer spring system including the domain geometry and characterization e g soil and aquifer hydraulic parameters is discussed by doummar et al 2018 fig 8b shows the schematic profile of el assal karst aquifer used as the domain of simulation the calibrations of the aquifer properties are out of the scope of this paper the parameters of the porous matrix are used as in doummar et al 2018 where the aperture of the fractures is assumed to be 1cm the saturated hydraulic conductivity of the fractures was calculated using the cubic law and the other parameters were assumed to be similar to the one for the case of infiltration in dry soil see table 2 5 2 methodology for simulation and analysis the domain is discretized using a triangular grid consisting of about 140k elements no flow boundary conditions are assumed at the right inland side and at the bottom surface representing the initial water table on the left side the spring is simulated by imposing a nodal zero pressure head the site is firstly simulated from 2013 to 2019 using real historical data june 1st 2013 to may 29th 2019 in order to understand groundwater flow dynamics in the aquifer under three regimes of recharge including snowmelt precipitation and dry periods we then simulate the site with predicted precipitations for 2019 2099 starting from june 1st 2019 in order to evaluate future responses of the spring discharge variations caused by climate change we extract daily recharge time series 2019 2099 from the calibrated integrated model in doummar et al 2018 where precipitation predictions are obtained from the ipsl cm5 gcm 5th phase of the coupled model intercomparison project dufresne et al 2013 global climatic model for lebanon with a resolution of 0 25 based on the agmerra dataset ruane et al 2015 in doummar et al 2018 the scenario rcp 6 0 was adopted reflecting a stabilization of the radiative forcing value without overshoot pathway at 6 w m2 after 2100 projected raw data were corrected to account for the elevation of the catchment area 1500 2200 m using a constant lapse rate for t 0 24 c and p 5 5 per 100 m elevation for all simulations we consider monthly averaged recharge variation the results of simulations are analysed using the spatial maps of water content θ and three scalar metrics which are i the dimensionless average saturation of the aquifer vm ii the maximum water table elevation h 0 and iii the discharge rate at the spring outlet qout the mathematical expressions of the metrics are stated as follows 24 v m 1 ω ω s e d ω ω is the area of the aquifer and se is the element effective saturation defined in table 1 25 h 0 m a x h x y t h x y t 0 26 q o u t k h x 0 5 3 simulations with real data from 2013 to 2019 we simulate the aquifer using data from june 1st 2013 to may 29th 2019 initially the domain is assumed to be at hydrostatic equilibrium for this period real recharge data are used for 2013 2016 and similar data trends are imposed for 2016 2019 since data for this period are not available to investigate the effect of fractures on the groundwater dynamics we simulate the aquifer using 2 models using the code mh lump 1d 2d the first model considers the fracture network while the second one assumes the domain as homogenous with no fractures the corresponding maps of water content at the end of may 2019 are represented in fig 9 in general similar profiles can be observed on the right side of the aquifer where fractures do not exist a dry zone can be observed between the two wet zones at the top and bottom the appearance of this zone is due to the dry wet cycle of the recharge process during a dry period water saturation at the top aquifer decreases and then during the recharge period the upper surface is rapidly saturated still in the right part of the aquifer but shifted left where fractures occur we observe that the fracture network does not have a dominant trend on the saturation distribution being highly permeable relative to the matrix fractures tend to conduct the flow faster than the adjacent matrix this leads to high dry zones around the fractures which are visible on the top of fig 9a around the centre of the aquifer the preferential flow in the fractures enhances water infiltration and expands horizontally towards the dry zone at the middle depth of the aquifer on the left side the fractures have a more dominant effect contrasting to the results of the unfractured model where a high saturation zone can be observed near the top surface the main streamlines of groundwater flow in the aquifer with the fracture network is shown in fig 10 vertical infiltration can be observed in the unsaturated zone near the water table the groundwater flow is horizontal towards the spring fig 10a it can be seen that flow generally tends to be absorbed and then travel through fractures fig 10b in some instances when a local maximum in the recharge distribution occurs and is followed by a relatively dry period certain points appear near the fractured region which tends to absorb water and create stagnant points nearby fig 10c this behavior is mostly due to the fact that the water is drained faster in the fracture than in the porous matrix resulting in higher conductivity i e higher saturation in the stagnant points compared to their adjacent points in the fracture fig 11 depicts the time variations of the scalar metrics vm h 0 and qout using both the fractured and unfractured models fig 11a confirms that there is a slight gap between both models regarding vm but in general less amount of water is obtained with the fractured model referring to fig 11b we can see that the level of the water table is significantly affected by the fractures which is coherent with the results discussed in fig 9 fig 11c shows that the fractured model leads to higher water flux at the spring outlet compared to the non fracture model these results indicate that the fracture network enhances water infiltration in the aquifer this increases the water discharge through the spring and decreases the amount of water stored in the unsaturated part of the aquifer the results of fig 11c are coherent with the ones in fig 11a as in both models fractured and unfractured the amount of influx from the recharge is the same and more water is discharged with the fracture model fig 11c which should lead to less retention of water in the aquifer with this fracture model this behavior is observed in fig 10a which shows less amount of stored water with the fractured model than the unfractured one 5 4 predictions under climate change from 2019 to 2099 in this section we investigate the effect of fractures on the predictions of water resources in the el assal aquifer under different scenarios reflecting climate change conditions here we investigate the effect of neglecting the fractures on the predicted results thus we simulate the aquifer with the predicted recharge from june 1st 2019 until 2099 we started the simulation with hydrostatic equilibrium on june 1st 2013 we run the models from 2013 until the end of may 2019 using real data as in the previous section we follow with predictions since june 2019 where we consider recharge under climate change the aquifer is simulated using 3 models the first model named f ncc considers the fracture network but neglects the effects of climate change on recharge in this model we assume that the recharge distribution of 2013 2019 occurs over the next eighty years up to 2099 the second model named f cc considers the fracture network and assumes variable recharge due to the effect of climate change as in fig 8c the last model neglects the fracture network i e considers the domain as homogenous and assumes variable recharge due to climate change this model is denoted by nf cc the results of the three models regarding the map of water saturation are presented in fig 12 at first glance the water content and the saturated zone are higher in the model with neglected variations of recharge due to climate change as expected with climate change effects the fracture model leads to a lower water table than the homogenous model this is expected as the preferential flow in the fracture network enhances water infiltration through the unsaturated zone investigating further through the transient behavior of the proposed metrics we can obtain better insights as shown in fig 13 in this figure the effect of climate change reduces the amount of available water in the aquifer as well as the water discharge at the spring outlet this is observed from the differences between the model with neglected climate change effects red curves and the models with these effects blue and orange curves under climate change conditions we can observe two regimes of time variation starting from hydrostatic equilibrium in 2020 during the first 40 years from 2020 to 2060 the amount of water available in the aquifer the water level table and the discharge flux at the spring will increase after 2060 these metrics will exhibit a decreasing variation with time indicating less availability in water resources due to climate change the general patterns of the results of the models f cc and nf cc indicate that neglecting fractures leads to an overestimation of the available water resources in the aquifer the difference in the estimated amount of available water with both f cc and nf cc models is evident from early time and continues during all the simulated period the level of the water table is slightly sensitive to fractures neglecting fractures in the model would lead to some periods where the level of the water table is overestimated and other periods where it is underestimated this effect is also observed for the water discharge in the spring as the spring outlet discharges the most important metric we explore more the variability of this metric in fig 14 for the period 0 7000 days until 2033 it is clear that the discharge flux estimated with the fractured model is higher than the one with the unfractured model thus we focus the analysis in fig 14 on the period 2033 2099 this figure shows simultaneously the normalized distribution of the projected recharge normalized using the maximum recharge value along with the normalized difference between spring outlet discharge of the f cc and nf cc models δqout both recharge and δqout are normalized using the maximum value of the recharge influx it can be observed that the higher variability in the recharge distribution results in higher variability of δqout and higher inaccuracy in the prediction of the outlet discharge the other interesting observation is the delay in the response of the system at approximately 20000 days late 2060 this point corresponds to the high recharge influx at 17000 days early2060 we presume that this delay is due to the high fluctuation of the recharge at this period which results in high dry soil in the next dry season and saturated fractures saturated fractures i e highly permeable fractures tend to absorb the flow from the nearby matrix resulting in much slower flow in the soil and a slower response of the spring in other words the fractures act as a sink for the flow which impacts the flow locally in the aquifer resulting in a lag time between the recharge event and the spring discharge response this lag time can grow over time due to the increase of variation of the recharge caused by the climate change 6 conclusion simulation of the vsf in a discretely fractured domain is a computationally challenging problem which requires solving the re in the matrix and dense fracture networks involving complicated geometry and discontinuities in the hydraulic properties the presence of fractures adds complexity to the re solution which is already a challenging task without fractures existing numerical models of vsf in discrete fractured domains are limited to standard numerical techniques that limit their applications in field studies we develop a new numerical scheme for solving re in discrete fractured domains by combining advanced techniques for space and time discretization the fracture network is considered via the hybrid dimensional technique 1d fractures in a 2d matrix for the space discretization we extend the mhfe to deal with vsf in fractured vadose zones we develop a new ml technique for the fractures to improve the performance and the robustness of the method in simulating preferential flow in dense fracture networks for time integration while existing numerical models for flow and transport in fractured domains deal with standard backward euler first order method we use an sophisticated technique based on adaptive high order technique with accurate adaptive time stepping procedure we use the mol to couple mhfe method ml technique for fractures and high order adaptive technique the mhfe method is used for vsf in fractured media for the first time the new proposed numerical scheme is implemented in a fortran code and validated against comsol multiphysics on a case dealing with water table recharge we show the stability of our scheme based on the m matrix property we also highlight its advantages and performance by comparing it against other standard numerical techniques in simulating a challenging case of water infiltration in dry soil under imposed pressure heads the results show that the suggested ml technique eliminates all numerical oscillations and improves the convergence of the nonlinear solver leading to a significant reduction in computational time the proposed scheme is then used to investigate the effect of climate change on groundwater resources in a karst aquifer spring system in el assal lebanon this application shows the performance of the proposed scheme in simulating problems with large time and space scales under variable recharge conditions the simulations are performed with a computational mesh consisting of about 140k elements for a duration of about 87 years and under high variable recharge conditions snowmelt rain and dry periods the corresponding cpu time is less than 1 hour the results show that neglecting the fracture network in the aquifer would lead to an overestimation of the amount of available water as well as the groundwater discharge through the spring outlet the proposed scheme is generic and can be extended to other applications the developed ml technique for fractures and the procedure used for time integration can be applied for other finite element based methods the application to the el assal aquifer can also be extended to model more detailed analyses aiming at determining the parameters of the matrix and fractures based on available observation data this model has the features to be coupled with an optimization procedure to calibrate simulations with field observations the proposed scheme can be extended to 3d which is an ongoing task of this work author statement behsahd koohbor worked on the development of the numerical model and simulations marwan fahs framed the research questions and worked on the writing hussein hoteit framed the research questions and worked on the model development anis younes and benjmain belfort supervised the research and finalized the manuscript joanna doummar worked on the simulations of the real case declaration of competing interest the authors declare that there is no conflict of interest regarding the publication of this article acknowledgments marwan fahs would acknowledge the support from the national school of water and environmental engineering of strasbourg through the research project poro6100 the characterization of the case study including data collection was funded in the framework of a usaid peer science project award number 102881 cycle 3 the data used in this work are available on the github repository https github com fahs lhyges 
498,stray gas migration resulting from oil and gas operations can have negative impacts on shallow groundwater resources and the atmosphere the movement and architecture of free phase gas can have important implications on the expected effect of stray gas migration for example free phase gas can become trapped in the subsurface and then dissolve or gas flow can reach the surface in this study intermediate scale laboratory experiments in quasi two dimensional flow cells employing a modified light transmission method were used to better understand free phase gas migration under gravity destabilized conditions quantification of both gas movement and saturation improves our understanding of the expected source architecture of stray gas the results of this study show that gas flow became discontinuous away from the source and that gas saturations decreased immediately following the stoppage of a leak the results of this study will lead to enhanced knowledge concerning mass transfer to groundwater both spatially and temporally keywords gas migration multiphase flow source architecture light transmission gravity destabilized methane 1 introduction and background unconventional oil and gas has become a viable resource for fulfilling energy needs globally as a result of directional drilling and high volume production increasing feasibility and yield kerr 2010 moniz et al 2011 rivard et al 2014 this production however has sparked controversy due to environmental concerns regarding recovery techniques and supporting infrastructure cca 2014 dusseault and jackson 2014 jackson et al 2013a vengosh et al 2014 vidic et al 2013 these concerns include the potential degradation of surface water and groundwater quality in proximity to production wells vengosh et al 2014 and the degradation of ambient air quality bachu 2017 dusseault and jackson 2014 kelly et al 1985 creating challenges for the oil and gas and environmental industries although there are a variety of potential contaminants over the life cycle of production and decommissioning a major concern is the risk that stray gas poses to groundwater resources and the atmosphere cca 2014 stray gas which is natural gas mainly composed of methane gorody 2012 jackson et al 2013b lan et al 2015 zumberge et al 2012 can migrate along pathways in the subsurface both from production zones well below the earth s surface 1000 3000 m and from intermediate zones dusseault et al 2014 dusseault and jackson 2014 gurevich et al 1993 myers 2012 it is now generally accepted that stray gas is the result of preferential pathways created by improperly or poorly sealed new production wells or pre existing oil and gas wells which have not been decommissioned properly cca 2014 dusseault and jackson 2014 these preferential pathways allow stray gas to migrate upwards due to buoyancy and pressure gradients and enter aquifers or the atmosphere and are applicable to both conventional and unconventional oil and gas development once in shallow aquifers stray gas has the potential to decrease water quality through aerobic and anaerobic oxidation alkalinity changes reduction of dissolved oxygen liberation of contaminants e g metals and changes in biological activity and taxa forde et al 2019b kelly et al 1985 roy et al 2016 son and carlson 2015 van stempvoort et al 2005 it can also create an explosion and asphyxiation risk if gas migrates into wells or homes if the gas enters the atmosphere there is an additional concern regarding its contribution to climate change as methane is a powerful greenhouse gas myhre et al 2013 field scale research has been conducted for a variety of research objectives including to understand the effects of stray gas migration at known sites cahill et al 2018 2017 kelly et al 1985 schout et al 2019 2017 steelman et al 2017 to investigate correlation and causation related to stray gas migration darrah et al 2014 jackson et al 2013b molofsky et al 2011 osborn et al 2011 and to identify the number of sites that have stray gas migration issues bachu 2017 watson and bachu 2009 to date few studies have focused on the development of a representative conceptual model for stray gas migration in the subsurface a conceptual model for this complex problem provides a useful framework to assess potential spatial extent longevity and approaches to mitigate risk and monitor the impact on air and water quality arising as a result of stray gas studies that have included a discussion of conceptual models include field scale investigations cahill et al 2018 2017 woda et al 2018 modeling studies lackey and rajaram 2019 nowamooz et al 2015 roy et al 2016 zhang and soeder 2016 and literature review ryan et al 2015 however there have been no studies conducted at the laboratory scale focused on stray gas migration to support conceptual model development key aspects of a conceptual model for stray gas include the distinction between free phase gas and dissolved gas and their migration pathways the influence of heterogeneity on gas migration and the fate of dissolved phase methane to understand free phase gas migration related to stray gas insight can be gained from studies of gas movement related to other applications in water saturated porous media gas movement in porous media can be either stabilized by gravity when gas invades saturated media from above and creates a consistent front saffman and taylor 1958 or be gravity destabilized when gas invades saturated media from below and creates a complex channelized network of gas frette et al 1992 stray gas migration is expected to result in gravity destabilized flow and is the focus of this study it is well known that when gas is injected or leaks in the subsurface gas movement is influenced by the competition of gravity capillary and viscous forces creating fingered patterns which percolate upward to the water table brooks et al 1999 elder and benson 1999 glass et al 2001 ji et al 1993 roosevelt and corapcioglu 1998 in homogeneous media the main factors influencing the gas distribution are the grain size and flow rate ultimately creating either discontinuous transitional or continuous flow ahlfeld et al 1994 brooks et al 1999 geistlinger et al 2006 ji et al 1993 selker et al 2007 stöhr and khalili 2006 van de ven and mumford 2019 as a result of difficulty measuring subsurface characteristics leading to gas migration the rate at which stray gas would enter an aquifer and migrate through the subsurface is not well known however surface casing vent flows scvfs in western canada have been found to range from 0 01 to 5000 m3 day with an average rate of 300 m3 day nowamooz et al 2015 and can be used as a surrogate for migration rate this flow occurs within the surface casing annulus and may result in gas migration depending on well construction e g open annuli poor seals and bonds it is reasonable to expect that scvf could be greater than the rate of gas migration into the subsurface for jurisdictions that allow sealed surface casing vents it would be expected that gas migration rates could approach scvfs as pressure builds within the annulus to a point were gas circumvents the annulus into the subsurface lackey and rajaram 2019 several studies have investigated the effect of flow rate on gas migration patterns geistlinger et al 2006 selker et al 2007 van de ven and mumford 2019 it has been shown that viscous forces dominate in proximity to a gas injection point selker et al 2007 and that gas flow transitions from continuous to discontinuous flow based on the gas injection rate and the media grain size geistlinger et al 2006 previous studies have also hypothesised that gas injection patterns that were continuous near an injection point became discontinuous as gas moved away from the source but due to the limited vertical scale of these experiments all 50 cm this has not been validated previous laboratory studies have focused on gas movement during active injection or leakage of gas into the media meaning that a gas injection pressure was sustained during the experiments in the context of stray gas however consideration of gas dynamics after the extinction of a gas injection pressure referred to here as gas relaxation is of interest when considering a leak which has become inactive cahill et al 2018 as would be the case if a leak were repaired or the source were depleted when a sustained gas pressure is dissipated water that has been displaced by gas is able to imbibe back into the gas occupied pore space potentially increasing dissolution from the trapped gas as a result of increased gas water interfacial area gorody 2012 this relaxation has been observed in studies of light non aqueous phase liquid lnapl migration resulting in a reduction in lnapl saturation behind an advancing front of higher saturation kechavarzi et al 2005 this reduction in saturation and the associated reduction in lnapl relative permeability suggests that the lnapl phase was becoming disconnected breaking up into discrete blobs and ganglia relaxation has also been observed in studies of gas movement stöhr and khalili 2006 where channels of injected gas that exited the top of a flow cell collapsed to disconnected clusters when considering the free phase movement of stray gas both active and inactive leaks need to be understood as the condition of the leak can affect the gas migration visualization is a powerful qualitative and quantitative technique to observe gas flow in porous media in bench scale laboratory experiments light transmission methods ltm have been used for the qualitative observation of gravity destabilized gas flow in porous media allowing the migration pathway and resulting architecture to be studied geistlinger et al 2006 ji et al 1993 selker et al 2007 stöhr and khalili 2006 this visualization technique has also been used to calculate gas saturation in a number of studies including those focused on gravity driven fingering dicarlo 2004 weisbrod et al 2002 interfacial surface area niemet et al 2002 gas production from microbial activity ye et al 2009 and groundwater remediation hegele and mumford 2014 the methodology to quantify gas saturation was developed through the work of tidwell and glass 1994 and niemet and selker 2001 and calculated saturations are typically validated against experiments of gravity stabilized flow it is clear from previous work on gas and napl movement in the subsurface agartan et al 2015 clayton 1998 parker and park 2004 sale and mcwhorter 2001 yang et al 2014 that to understand the potential impact of stray gas migration on the environment the conceptual model needs to consider both free phase gas movement and gas dissolution which are related through the architecture of the gas distribution bench scale experiments can be used to better understand this migration under both active and inactive conditions the goal of this study was to investigate gas flow geometry shape and dimensions as a result of subsurface gas injections from initial injection to breakthrough and during redistribution following the extinction of injection pressure relaxation this study used air injected into air saturated water as a surrogate for methane to eliminate mass transfer from the invading gas and focused only on free phase gas movement the specific objectives of this study were to i assess the validity of light transmission for the measurement of local near pore scale gas saturations during gravity destabilized gas flow ii understand the spatial and temporal dependence of gas flow geometry on injection rate and distance from injection source and iii quantify and compare gas flow geometry during active leaks and inactive leaks two sets of intermediate scale experiments were conducted using quasi two dimensional light transmission flow cells i a small scale experiment for validation of local gas saturation over a range of gas injection rates and ii a large scale experiment for investigating gas dynamics and changes in gas flow geometry with increased distance from the injection point 2 materials and methods 2 1 small scale experiments gas injections conducted by van de ven and mumford 2019 were used to validate local gas saturations the small scale flow cell was constructed of 1 1 cm thick acrylic plates allowing sand to be packed between the plates creating a sand pack of dimension 25 25 1 cm3 the 1 cm thick cell construction allows for a slice approximately 14 grain diameters thick using 0 7 mm grains of sand to be studied the effluent from a clear well that spanned the total height of the cell was set to a constant height equal to the height of the flow cell lid water displaced from the sand pack through the effluent tubing during gas injection was collected in a covered beaker placed on a balance mettler toledo ms6002s and displaced water mass was recorded every 1 s four ports along the bottom of the flow cell were fitted with hydrophilic 10 µm nylon membranes to allow the entire sand pack to be drained to a residual water saturation further details of the flow cell and gas injection experiments can be found in van de ven and mumford 2019 which were analyzed in this study to investigate transient gas saturations 2 2 large scale experiments the two dimensional flow cell used in the large scale experiments had internal dimensions of 146 150 2 cm3 and consisted of two 1 5 cm thick glass panels separated by a 2 cm space for sand packing to reduce possible deflection in the glass the panels were supported by a stainless steel frame sealed to the glass using viton foam gaskets with two support bars over the glass face fig 1 nine drainage ports along the bottom of the cell were fitted with 10 µm nylon membranes the cell lid was sealed to the frame using a hydrophobic neoprene gasket to establish a confined sand pack and to prevent grain rearrangement during gas injection perforated stainless steel channels wrapped in wire mesh served as clear wells on each side of the sand pack an effluent port was installed in the top right corner of the cell allowing water to be displaced from the cell and through the clear well during gas injection tubing connected to the effluent port was set at a constant height equal to the height of the confining gasket a point source injection was used to replicate a stray gas leak in an aquifer for example as would occur at the first intersection of a gas pathway associated with a defective well seal and shallow aquifer material with a relatively low entry pressure the point source consisted of a 15 24 cm long 22 gage 0 413 mm inner diameter stainless steel needle placed in the middle drainage port along the bottom of the cell and reached 7 2 cm into the sand pack fig 1 prior to packing the injection needle was filled with air at a pressure equal to the hydrostatic pressure within the cell 2 3 porous media the small scale cell was packed with uniform silica sand 20 30 accusil agsco corp with a median grain size of 0 713 mm schroth et al 1996 which was washed before use to remove any fines the large scale flow cell was packed with washed 12 20 accusil with a median grain size of 1 105 mm schroth et al 1996 different sand grain sizes were selected for the small and large scale experiments because of the difference in cell thickness 1 cm for the small scale and 2 cm for the large scale because of the greater thickness of the large scale cell a coarser sand was required to ensure that changes in gas saturations could be detected sand was packed into each cell by continuously funneling a wet slurry of sand and deionized water to promote a fully water saturated and homogeneous pack consistent with previous experiments conducted in similar flow cells van de ven and mumford 2018 the sand pack was vibrated during and after packing and allowed to settle overnight to reduce grain rearrangement during gas injections due to minor impurities within the coarser sand and packing procedures at this scale some heterogeneity bedding structure is present in the large scale experiment seen as dark lines in the sand pack fig 1 the porosities for all experiments were measured gravimetrically dry sand mass following gas injection 2 4 gas injection and gas pressure measurement gas injection was performed using a syringe pump cole parmer 78 0232c to provide a constant gas flow during injection multiple syringes maximum total volume of 244 ml were connected to the stainless steel needle in the cell using ptfe high pressure tubing each syringe contained a small drop of water to humidify the injected gas thereby limiting partitioning from the water to the gas gas was injected at 0 1 10 100 250 and 498 ml min in the small scale experiments and continued until the injected gas reached the flow cell s lid these gas injection rates are at the lower end of measured scvfs nowamooz et al 2015 all but the 0 1 ml min injection were performed in triplicate table 1 gas was injected at 332 ml min in the large scale experiment also until gas reached the flow cell s lid which required 220 ml of gas in the large scale experiment the gas could redistribute after gas injection was stopped to investigate changes in the gas flow geometry immediately following active injection and during subsequent relaxation gas pressure was measured at the injection point in the small and large scale experiment using a gage pressure sensor connected to the gas injection line honeywell abpdjjt001pgaa5 for the test at 0 1 ml min honeywell abpdant005pgaa5 for tests at 10 100 and 250 ml min and honeywell abpdant015pgaa5 for tests at 498 ml min and the large scale experiment recorded every 0 6 s using a data logger campbell scientific cr300 the gas pressure measured is therefore the pressure of the gas flowing within the injection line as well as the gas that is connected to gas in the sand van de ven and mumford 2019 this gas pressure can be used to help identify the occurrence of discontinuous or continuous gas flow geistlinger et al 2006 mumford et al 2009 van de ven and mumford 2019 because fragmentation and mobilization during discontinuous gas flow causes pressure fluctuations that do not occur during continuous gas flow for example during continuous flow gas pressure increases over time due to an increase in the viscous resistance to flow as the length of a gas channel in the porous medium increases this is unlike during discontinuous flow in which the pressure fluctuates due to repeated fragmentation events that limit the maximum length of the gas channel 2 5 image acquisition and data processing images of the gas injections were recorded using a canon eos 6d fitted with a canon ef 17 40 mm lens for both the small and large scale experiments for the small scale experiments the camera was placed 60 cm from the flow cell and for the large scale experiment it was placed 2 1 m from the flow cell the flow cells were backlit using led light panels 9216 lm panel ledgo lg 1200s for the small scale experiments and a custom built 150 150 cm2 10 500 led 5050 smd panel custom effects led solutions for the large scale experiment to capture high temporal resolution images of the gas injections and gain insight into the transient gas dynamics high definition video was recorded at 1920 1080 resolution final resolution of small and large scale experiments were 0 25 mm pixel and 1 4 mm pixel respectively and a frame rate of 29 97 fps the camera settings were chosen manually to ensure high image quality and maintain consistency during the experiments iso2000 f6 3 and a shutter speed of 1 30 for the analysis of gas saturations still frames were extracted from the videos cropped to remove the cell frame and converted to greyscale intensity the images were also up scale discretized to 1 1 mm2 blocks for the small scale experiments and 7 7 mm2 blocks for the large scale experiment to capture full grains of sand and to reduce noise in the images this up scaled resolution was achieved by averaging the intensity value of all pixels in the area of each block at the desired discretization and applying the average intensity to all pixels within the block this upscaling removes noise created by dark pixels and minor variations in the incident light van de ven and mumford 2018 the images were used to calculate gas saturations using the light transmission method ltm which is an established technique based on the calibration of measured intensity of light passing through a thin slice of a porous medium niemet and selker 2001 tidwell and glass 1994 the technique combines beer s law which describes the light passing through a homogeneous medium and fresnel s law which describes the refraction and absorbance of light passing through interfaces described mathematically as 1 i c i o τ pl 2 k s e τ pg 2 k 1 s e exp α p d p k where i is the transmitted intensity c is a geometric constant which corrects for the position of emitted and captured light i o is the incident light intensity τ is the average transmittance of an interface and the subscripts p l and g refer to the grain liquid and gas respectively k is the number of pores through which incident light travels se is the effective water filled saturation αp is the absorbance coefficient of the grains and dp is the thickness of a grain a key assumption for the measurement of gas saturations using light intensity is that the incident light is normal to the thin slab of media at every location where i is measured assuming that the porous medium consists of uniform pores that are either water filled or contain only residual water films the effective water saturation can be calculated as niemet and selker 2001 2 s e 1 ln i i s ln i r i s 1 s g s r 1 s r where is the light intensity transmitted through a water saturated sand ir is the light intensity transmitted through a sand at residual wetting saturation sg is the gas saturation and sr is the residual wetting saturation in many applications of ltm eq 2 is calibrated using images of a sand pack under water saturated and residual conditions to determine local effective saturations from images of the sand pack under unsaturated conditions video was collected prior to the injection of gas for both the small and large scale experiments to determine the saturated light intensity is following the completion of gas injection the flow cells were drained for a minimum of 24 h and then video was recorded to determine the residual light intensity ir the water displaced during drainage to residual saturation was collected and weighed to calculate the residual saturation saturated and residual images were based on the average intensity over a 5 s period 150 images each prior to injection and after drainage to residual respectively the gas saturation detection limit was set to three times the standard deviation of the calculated gas saturation in an area of each flow cell that did not contain gas in any experiment the average detection limit for the 13 small scale experiments was 0 032 sg detection limit of 0 025 0 039 across all experiments and was 0 057 for the large scale experiment table 1 because the lower detection limit is the error associated with a water saturation of 1 the error on water and gas saturations is assumed to be 3 2 for the small scale and 5 7 for the large scale experiment 3 results and discussion 3 1 validation of calculated gas saturations using light transmission methods gas injections in the small scale flow cell were used to validate the measurements of local gas saturations using ltm although the volume of gas calculated using eq 2 and the measured i s and ir values matched the volume of displaced water during stable drainage air invaded from the top of the flow cell the calculated volume of gas was substantially less than the volume of displaced water in the gas injection gravity destabilized experiments fig 2 a the average measured ir is values over the 25 cm 25 cm face of the flow cell for the 13 experiments ranged from 0 120 to 0 211 table 1 similar to the reported value by niemet and selker 2001 however larger values would be required to match the water displacement data during gas injection as reported by mumford et al 2015 fitting the water displacement data by adjusting the value of ir is rather than using measured intensity values fig 2b required fitted ir is values of 0 35 to 0 63 table 1 the best fit ir is value of 0 63 for experiment 0 1 a is equal to the average best fit value reported by mumford et al 2015 for slow gas injection into 20 30 accusand although mumford et al 2015 suggested that the difference between traditional ir is values used in gravity stable experiments and those in their study were caused by some light passing around the experimental apparatus rather than through the sand the current study used a different cell and improved light control but required the same ir is value to match the injected gas volume the original conceptualization for the light transmission method niemet and selker 2001 tidwell and glass 1994 assumed that transmitted light passed through the thin sand pack orthogonal y direction to the light source fig 3 a this assumption is valid for gravity stabilized systems where interfaces between gas water and grains are consistent in the x direction due to stable fronts however in gravity destabilized systems where thin in the x direction channels develop over the height of the cell z direction interfaces along the incident light direction cause refraction of light fig 3b the need to calibrate ir is values for gravity destabilized gas flow arises because the light intensity of gas occupied pore spaces during gravity destabilized gas flow are higher brighter because of refraction from the adjacent water saturated sand that is the transmitted light intensity at a given location in the sand pack that is drained to residual saturation is higher if it is part of a gas channel gravity destabilized than if the entire pack was drained to residual saturation gravity stabilized because it is lit both from the side refracted light due to interfaces in the y direction and by the back transmitted light fig 3b therefore a higher value of ir is needs to be used in eq 2 to fit the gas volume to account for this additional light the more gas channels that are present 0 1 ml min vs 498 ml min the less each gas channel is lit from the side causing the best fit ir is value to be closer to the measured ratio at higher gas injections rates failure to account for this change in ir is results in an underestimation of the gas volume during gravity destabilized gas flow to account for the discrepancies between injected and measured gas volumes for gravity destabilized gas flow both in this study and mumford et al 2015 it is hypothesised that the required ir is value depends on the gas flow geometry i e gravity destabilized compared to gravity stabilized flow this is evidenced by the trend in the best fit ir is value with increasing gas injection rate while the slope of the data for each gas flow rate was less than 1 1 the discrepancy between the injected gas volume based on water displacement and the imaged gas volume was larger for lower flow rates i e data for 498 ml min upper dotted line is closer to 1 1 than data for 0 1 ml min lower dotted line fig 2a combining this observation with the calibrated saturation maps for each experiment fig 4 shows that the calibrated ir is decreases with increasing occupation of the domain by gas from 0 63 for the 0 1 ml min injection to 0 35 for the 498 ml min injections using validated gas saturations calculated with the best fit ir is values to account for gravity destabilized gas flow it was observed that gas injections at 0 1 and 10 ml min each produced a single gas channel which grew vertically until the channel made contact with the lid of the cell fig 4a b minimal lateral movement of the gas channel was seen at these flow rates unlike experiments at 0 1 and 10 ml min gas injections at 100 250 and 498 ml min showed complex patterns composed of multiple continuous channels fig 4c e for the higher flow rate experiments the injected gas pattern widened as the gas migrated vertically before contact with the lid and the number of channels increased with increased flow rate all gas injections showed signs of local i e pore scale heterogeneity with varying gas saturations 0 03 0 4 throughout the gas channels fig 4 typically each gas channel was composed of a high saturation inner core gas saturations of 0 2 to 0 4 surrounded by a lower saturation outer shell gas saturations of 0 03 to 0 2 as a result of channel geometry and some refraction of light during the large scale injection gas saturations calculated using ltm were compared to the volume of injected gas rather than the volume of displaced water similar to the small scale injections the volume of gas calculated using eq 2 is underestimated if measured values were used for ir is therefore a best fit ir is value of 0 33 was used table 1 to generate gas saturation maps during injection and relaxation fig 5 the best fit value for the large scale injection is consistent with those used for the small scale injection at the higher injection rates 3 2 gas flow pattern during active injection gas injection into the large scale flow cell ls produced a dynamic flow pattern which changed as the gas progressed away from the source fig 5a g early in the injection gas was observed to flow mostly vertically as multiple laterally overlapping gas channels fig 5a and b the pattern appeared to be continuous strongly influenced by gravity and viscous forces as the gas progressed away from the source to a height of approximately 50 cm above the source fig 5c the gas fingers appeared more unstable migrating vertically with some lateral movement as gas injection continued the gas pattern became more unstable 66 cm above source moving as more discrete channels with some lateral spreading fig 5d f this phenomenon is the result of reduced viscous forces as the gas channel spreads laterally x direction causing the total gas flow to be spread over a greater cross sectional area and allowing gravity and capillary forces to dominate the flow pattern measured gas pressure black line in fig 5h was used to better define changes in the gas pattern away from the source distinguishing between continuous and discontinuous gas flow at early times the pressure increased nearly linearly and gas entered the sand point a pressurization following pressurization a growth stage was observed where gas pressure increased non monotonically point a e the pressure increases point b c and d e by 12 and 34 cm of h2o respectively and decrease c to d by 34 cm of h2o are the result of continuous gas channels contacting thin bedding structures within the sand pack during pressure increases the gas channels vertical movement is hindered by the minor bedding structure higher entry pressure and the entire connected gas structure pressure increases once the gas pressure is high enough to break through the bedding structure the gas structure decreased in saturation near the injection needle fig 5c e as a result of mobilization of gas fragmenting the channels this is further supported by the pressure decrease between point c and d however the generally increasing slope of the gas pressure at these points suggests that the fragmented structure quickly became continuous again although this study is not focused on these short term saturation fluctuations the results demonstrate that even in a reasonably homogeneous sand pack local variations in permeability will affect gas flow following the growth stage a discontinuity stage is seen from point e to f indicated by the slowly decreasing gas pressure previous work van de ven and mumford 2019 suggests that if the gas flow at this constant injection rate had remained continuous further increases in gas pressure at the injection point would have occurred due to viscous resistance through a longer gas flow pathway in the sand after gas injection stopped point f the pressure quickly decreased relaxation until a constant pressure of 152 cm h2o was reached which represents the pressure of a gas cluster that remained connected to the needle this is 35 of the pressure represented by point a the measured gas pressure is clear evidence of the injection transitioning from continuous point a e to discontinuous flow van de ven and mumford 2019 used gas injection pressure to distinguish between continuous transitional and discontinuous flow continuous flow is observed when gas pressure increases linearly as a result of connected gas clusters migrating from the source causing higher frictional forces as the structure grows in width and length point a e when gas flow is transitional and discontinuous the linear pressure increase is observed to flatten out as a steady state frictional resistance is reached causing a steady gas pressure except for minor fragmentation events observed as small episodic pressure fluctuations due to the uncertainty of the pressure sensor used 1 5 fss equating to 3 cm of water the small pressure fluctuations of discontinuous channels expected to be approximately 2 cm mumford et al 2009 cannot be observed however the decrease in slope observed after point e coupled with saturation maps showing non monotonic gas channels fig 5f are indicative of discontinuous flow the gas saturations and pattern as gas progressed away from the source can be linked to the observed injection patterns in the small scale experiments adding insight to the dynamic conceptual model for free phase stray gas movement during active injection dense overlapping channels with saturations ranging from 0 1 to 0 4 fig 6 a were observed near the injection point this dense cluster is consistent with a high flow rate injection fig 6f where multiple channels develop allowing for the high mass flow rate to be distributed over the cross sectional area of the cell as the gas moved upwards approximately 35 cm above the injection point the channel network became less dense as the channels were distributed over a wider area replicating observations of a lower flow rate injection but still with high gas saturations between 0 1 to 0 4 fig 6e once the gas extended 66 cm from the injection source the channel network continued to become less dense creating discrete channels of sustained high saturation pressure measurements show that gas flow in this region was continuous but began to show signs of transitional behavior similar to the small scale experiments with an injection rate of 100 ml min fig 6d for this experiment at a height of 105 cm above the injection source flow became transitional showing sparse continuous channels which resembled flow in the small scale experiments of 10 ml min fig 6c the saturation of these channels was lower than the bulk cluster below ranging from 0 1 to 0 25 discontinuous flow was observed 121 cm above the injection point discrete relatively low saturation 0 1 to 0 25 channels were seen which show disconnection over the vertical length and were similar to those observed during the 0 1 ml min gas injection in the small scale experiments fig 6b although the detection limit was higher in the larger flow cell 0 057 it would be expected that below this saturation flow would not be connected this evidence of discontinuous flow is supported by the pressure measurements the large scale gas injection is to the best of the authors knowledge the first investigation of a high flow rate injection gas pattern transitioning from continuous to discontinuous gas flow as the gas moved vertically away from the injection source this transition occurs as a result of increased lateral spread of the injected gas which causes the constant mass injection rate to be distributed over a greater cross sectional area decreasing the local gas flow rate in individual channels as the gas moves further from the source geistlinger et al 2006 selker et al 2007 this finding suggests that the conceptual model for free phase gas injection in a homogenous subsurface depends on the vertical distance of that gas from the injection point the distance at which this transition occurs depends on the viscous resistance to flow which is affected by the medium through which the gas flows and the injection rate with finer media and higher rates resulting in discontinuous gas flow further from the source for gas flow in the sands such as those used in this study this distance is expected to be on the meter scale the similarities between small and large scale experiments show that bench scale experimentation can provide valuable insight regarding conceptual model development and field scale investigations however careful consideration must be paid to the location represented in the experiments because the gas flow is expected to change with increasing distance from the gas source these similarities between the small and large scale experimental results can also be used to better understand pore scale phenomena over the vertical extent of the gas pattern and provide insight to the effect of that gas pattern on mass transfer from the gas to the aqueous phase and inform related modeling efforts 3 3 gas saturations during active injection and relaxation comparison was made between gas saturations during active injection fig 7 a and relaxation fig 7b during the large scale experiment ls changes in both the gas saturations and the gas geometry from active to relaxed conditions are highlighted by subtracting the two gas saturation maps fig 7c a green color represents a decrease in gas saturation and red represents an increase fig 7c shows that gas saturations vary substantially decreasing at most locations between active and relaxed conditions with local decreases as high as 0 15 the geometry of the gas injection area however did not change substantially indicated by minimal red color in fig 7c the bulk of the gas distribution remained unchanged apart from an increased number of fingers in the discontinuous zone to further compare the changes in gas saturations between the active and relaxed conditions average gas saturations were measured over the height of the gas fig 7d gas saturations were averaged horizontally considering only gas saturations greater than the detection limit average gas saturations decreased approximately by 0 07 from active to relaxed conditions in a region directly above the injection to a height of 65 cm greater than 120 cm above the injection only minor local changes occurred these regions correspond well with the occurrence of continuous and discontinuous flow fig 6 with transitional flow occurring between them regions in which continuous gas flow occurs allow for greater relaxation a decrease in gas saturation once injection has terminated compared to discontinuous regions this is the result of continuous flow patterns being composed of multiple overlapping connected channels of gas these connected channels have a high enough volume of gas to create a sufficient buoyant drive to overcome local capillary trapping thresholds causing vertical migration to continue even after the termination of an injection pressure because the channels are connected the channel needs only enough buoyant drive to overcome the entry pressure of the least resistant pore for flow at the top of the channel to occur in contrast discontinuous and transitional patterns are composed of disconnected gas clusters which do not have sufficient buoyant drive to overcome capillarity this finding is consistent with the work of stöhr and khalili 2006 who found that following the breakthrough of migrating gas from the top of their test apparatus substantial redistribution was observed following channel flow continuous flow and minimal redistribution for cluster flow discontinuous flow it is likely that a critical gas saturation exists at which the buoyant drive of connected gas clusters is sufficient to cause vertical redistribution as an estimate of this value the average gas saturation was found to be 0 1 in the 1 1 mm sand following relaxation 4 summary and conclusions air was injected at a high rate into a large scale two dimensional flow cell to develop a better understanding of free phase gas flow related to stray gas migration in unconsolidated porous media visualization techniques enabled observations of spatial and temporal gas dynamics during migration over a large vertical length scale relative to many previously published studies results of the large scale experiment were combined with results from gas injections into a small scale flow cell which were used for validation of gas saturations and near pore scale observation at varying flow rates an important component of the free phase stray gas conceptual model is quantification of the source architecture it was found that the traditional light transmission method was not able to accurately quantify gas saturations in sand during gravity destabilized gas injections and required correction using ir is as a fitting parameter that was greater than measured ir is values obtained under gravity stabilized conditions the best fit value of 0 63 agreed with previous studies for slow gas injections but decreased with increased gas flow rate as a greater portion of the flow cell was occupied by gas at higher injection rates the observed discrepancy between fit and measured values was attributed to internal refraction within the gas channels created during gravity destabilized gas flow which increases the light intensity transmitted through gas filled pores adjacent to water filled pores following the methodology proposed for the small scale experiments gas saturations in the large scale experiment were fitted to the known volume of injected gas the results of the large scale experiment showed that any conceptual model for free phase gas flow should consider changes in the gas flow pattern with increased height from the injection or leak source gas injection rates high enough to create continuous gas flow near the source result in the formation of a dense network of channels with high gas saturation 10 40 however as gas migrates away from the source the gas flow transitions to discontinuous channels of lower gas saturation 10 25 this transition is the result of local gas flow rates decreasing as gas flow is distributed over a larger cross sectional area this finding has substantial implications for stray gas migration in homogeneous aquifers first the resulting gas architecture will affect mass transfer it would be expected that near to the source continuous region mass transfer would be limited by low interfacial area and a reduced aqueous relative permeability further from the source where gas becomes discontinuous mass transfer would be substantially higher as a result of higher interfacial area and increased aqueous relative permeability one possible effect of this variation of gas architecture with height is that the longevity of the free gas depends on its depth within the system longer dissolution times are expected for free phase gas near the source and shorter dissolution times for migrating gas in shallower portions of an impacted system with the faster dissolution rates associated with higher interfacial area in shallower portions potentially leading to higher aqueous concentrations heterogeneity will affect these implications particularly in systems with high contrasts in permeability where capillary barriers will result in the accumulation of gas pools secondly it is common that stray gas migration is identified and monitored by means of surface measurement of gas forde et al 2018 molofsky et al 2016 based on the findings of this study depending on the leak rate and the depth at which the leakage is occurring it is likely that gas flow at the surface would be intermittent despite a continuous leak at depth this is expected because of the transition of flow from continuous to discontinuous which would cause gas to reach the surface as disconnected clusters this is in addition to other factors including variations in environmental forcing and characteristics of the gas leak that can affect the magnitude and frequency of gas emissions at ground surface dusseault and jackson 2014 forde et al 2019 therefore it is important that when monitoring for stray gas migration at the surface high temporal resolution monitoring be used as discrete measurement may not capture the intermittent releases of stray gas also depending on the sampling technique this intermittent migration may dilute small intermittent releases below detection limits for longer duration sampling events in these experiments the source architecture of the free phase gas was found to be highly dependent on whether a leak is active or relaxation has occurred due to extinction of injection pressure although the geometric characteristics of free phase gas remained similar between active and relaxed conditions the local gas saturations varied greatly once gas injection had ceased the buoyancy of the gas in the connected gas region allowed gas to continue migrating upward leaving behind average residual gas saturations of approximately 0 1 in the coarse sand used in this study it was found that a critical gas saturation of 0 1 or greater was required to allow for gas to buoyantly migrate without a sustained gas injection pressure in the discontinuous region gas saturations were not substantially affected by the extinction of gas injection this finding suggests that if a high rate gas leak ceases gas flow will dramatically decrease the original mass available for mass transfer to the groundwater near the source and will likely continue to move vertically toward the surface the development of conceptual models for stray gas migration need to consider spatial and temporal variation in free phase gas architecture gas movement occurs as a combination of continuous and discontinuous flow and this variation will affect mass transfer longevity and release characteristics ultimately influencing monitoring and detection strategies and the accurate estimate of migration emissions and impacts in a homogeneous system it was found that a high fraction of mass is concentrated at the point of the leak when gas is actively being injected and that this mass will move upwards after injection has ceased it is important to note that stray gas migration is complex and dynamic but will also depend on the scale being considered particularly with respect to heterogeneity and anisotropy future research efforts and conceptual model development must consider the timeframe and proximity to the source as well as potential gas pathways to accurately assess these systems credit authorship contribution statement cole j c van de ven conceptualization methodology validation formal analysis investigation writing original draft visualization writing review editing justine e f abraham investigation writing original draft kevin g mumford conceptualization methodology validation resources writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the natural sciences and engineering research council nserc of canada through a canada graduate scholarship to c j c van de ven collaborative research and training experience create grant 449311 2014 and a strategic partnerships grant for projects spg 506784 2017 the assistance of stanley prunster is gratefully acknowledged we also recognize the hard work of lisa tauskela and allison finer 
498,stray gas migration resulting from oil and gas operations can have negative impacts on shallow groundwater resources and the atmosphere the movement and architecture of free phase gas can have important implications on the expected effect of stray gas migration for example free phase gas can become trapped in the subsurface and then dissolve or gas flow can reach the surface in this study intermediate scale laboratory experiments in quasi two dimensional flow cells employing a modified light transmission method were used to better understand free phase gas migration under gravity destabilized conditions quantification of both gas movement and saturation improves our understanding of the expected source architecture of stray gas the results of this study show that gas flow became discontinuous away from the source and that gas saturations decreased immediately following the stoppage of a leak the results of this study will lead to enhanced knowledge concerning mass transfer to groundwater both spatially and temporally keywords gas migration multiphase flow source architecture light transmission gravity destabilized methane 1 introduction and background unconventional oil and gas has become a viable resource for fulfilling energy needs globally as a result of directional drilling and high volume production increasing feasibility and yield kerr 2010 moniz et al 2011 rivard et al 2014 this production however has sparked controversy due to environmental concerns regarding recovery techniques and supporting infrastructure cca 2014 dusseault and jackson 2014 jackson et al 2013a vengosh et al 2014 vidic et al 2013 these concerns include the potential degradation of surface water and groundwater quality in proximity to production wells vengosh et al 2014 and the degradation of ambient air quality bachu 2017 dusseault and jackson 2014 kelly et al 1985 creating challenges for the oil and gas and environmental industries although there are a variety of potential contaminants over the life cycle of production and decommissioning a major concern is the risk that stray gas poses to groundwater resources and the atmosphere cca 2014 stray gas which is natural gas mainly composed of methane gorody 2012 jackson et al 2013b lan et al 2015 zumberge et al 2012 can migrate along pathways in the subsurface both from production zones well below the earth s surface 1000 3000 m and from intermediate zones dusseault et al 2014 dusseault and jackson 2014 gurevich et al 1993 myers 2012 it is now generally accepted that stray gas is the result of preferential pathways created by improperly or poorly sealed new production wells or pre existing oil and gas wells which have not been decommissioned properly cca 2014 dusseault and jackson 2014 these preferential pathways allow stray gas to migrate upwards due to buoyancy and pressure gradients and enter aquifers or the atmosphere and are applicable to both conventional and unconventional oil and gas development once in shallow aquifers stray gas has the potential to decrease water quality through aerobic and anaerobic oxidation alkalinity changes reduction of dissolved oxygen liberation of contaminants e g metals and changes in biological activity and taxa forde et al 2019b kelly et al 1985 roy et al 2016 son and carlson 2015 van stempvoort et al 2005 it can also create an explosion and asphyxiation risk if gas migrates into wells or homes if the gas enters the atmosphere there is an additional concern regarding its contribution to climate change as methane is a powerful greenhouse gas myhre et al 2013 field scale research has been conducted for a variety of research objectives including to understand the effects of stray gas migration at known sites cahill et al 2018 2017 kelly et al 1985 schout et al 2019 2017 steelman et al 2017 to investigate correlation and causation related to stray gas migration darrah et al 2014 jackson et al 2013b molofsky et al 2011 osborn et al 2011 and to identify the number of sites that have stray gas migration issues bachu 2017 watson and bachu 2009 to date few studies have focused on the development of a representative conceptual model for stray gas migration in the subsurface a conceptual model for this complex problem provides a useful framework to assess potential spatial extent longevity and approaches to mitigate risk and monitor the impact on air and water quality arising as a result of stray gas studies that have included a discussion of conceptual models include field scale investigations cahill et al 2018 2017 woda et al 2018 modeling studies lackey and rajaram 2019 nowamooz et al 2015 roy et al 2016 zhang and soeder 2016 and literature review ryan et al 2015 however there have been no studies conducted at the laboratory scale focused on stray gas migration to support conceptual model development key aspects of a conceptual model for stray gas include the distinction between free phase gas and dissolved gas and their migration pathways the influence of heterogeneity on gas migration and the fate of dissolved phase methane to understand free phase gas migration related to stray gas insight can be gained from studies of gas movement related to other applications in water saturated porous media gas movement in porous media can be either stabilized by gravity when gas invades saturated media from above and creates a consistent front saffman and taylor 1958 or be gravity destabilized when gas invades saturated media from below and creates a complex channelized network of gas frette et al 1992 stray gas migration is expected to result in gravity destabilized flow and is the focus of this study it is well known that when gas is injected or leaks in the subsurface gas movement is influenced by the competition of gravity capillary and viscous forces creating fingered patterns which percolate upward to the water table brooks et al 1999 elder and benson 1999 glass et al 2001 ji et al 1993 roosevelt and corapcioglu 1998 in homogeneous media the main factors influencing the gas distribution are the grain size and flow rate ultimately creating either discontinuous transitional or continuous flow ahlfeld et al 1994 brooks et al 1999 geistlinger et al 2006 ji et al 1993 selker et al 2007 stöhr and khalili 2006 van de ven and mumford 2019 as a result of difficulty measuring subsurface characteristics leading to gas migration the rate at which stray gas would enter an aquifer and migrate through the subsurface is not well known however surface casing vent flows scvfs in western canada have been found to range from 0 01 to 5000 m3 day with an average rate of 300 m3 day nowamooz et al 2015 and can be used as a surrogate for migration rate this flow occurs within the surface casing annulus and may result in gas migration depending on well construction e g open annuli poor seals and bonds it is reasonable to expect that scvf could be greater than the rate of gas migration into the subsurface for jurisdictions that allow sealed surface casing vents it would be expected that gas migration rates could approach scvfs as pressure builds within the annulus to a point were gas circumvents the annulus into the subsurface lackey and rajaram 2019 several studies have investigated the effect of flow rate on gas migration patterns geistlinger et al 2006 selker et al 2007 van de ven and mumford 2019 it has been shown that viscous forces dominate in proximity to a gas injection point selker et al 2007 and that gas flow transitions from continuous to discontinuous flow based on the gas injection rate and the media grain size geistlinger et al 2006 previous studies have also hypothesised that gas injection patterns that were continuous near an injection point became discontinuous as gas moved away from the source but due to the limited vertical scale of these experiments all 50 cm this has not been validated previous laboratory studies have focused on gas movement during active injection or leakage of gas into the media meaning that a gas injection pressure was sustained during the experiments in the context of stray gas however consideration of gas dynamics after the extinction of a gas injection pressure referred to here as gas relaxation is of interest when considering a leak which has become inactive cahill et al 2018 as would be the case if a leak were repaired or the source were depleted when a sustained gas pressure is dissipated water that has been displaced by gas is able to imbibe back into the gas occupied pore space potentially increasing dissolution from the trapped gas as a result of increased gas water interfacial area gorody 2012 this relaxation has been observed in studies of light non aqueous phase liquid lnapl migration resulting in a reduction in lnapl saturation behind an advancing front of higher saturation kechavarzi et al 2005 this reduction in saturation and the associated reduction in lnapl relative permeability suggests that the lnapl phase was becoming disconnected breaking up into discrete blobs and ganglia relaxation has also been observed in studies of gas movement stöhr and khalili 2006 where channels of injected gas that exited the top of a flow cell collapsed to disconnected clusters when considering the free phase movement of stray gas both active and inactive leaks need to be understood as the condition of the leak can affect the gas migration visualization is a powerful qualitative and quantitative technique to observe gas flow in porous media in bench scale laboratory experiments light transmission methods ltm have been used for the qualitative observation of gravity destabilized gas flow in porous media allowing the migration pathway and resulting architecture to be studied geistlinger et al 2006 ji et al 1993 selker et al 2007 stöhr and khalili 2006 this visualization technique has also been used to calculate gas saturation in a number of studies including those focused on gravity driven fingering dicarlo 2004 weisbrod et al 2002 interfacial surface area niemet et al 2002 gas production from microbial activity ye et al 2009 and groundwater remediation hegele and mumford 2014 the methodology to quantify gas saturation was developed through the work of tidwell and glass 1994 and niemet and selker 2001 and calculated saturations are typically validated against experiments of gravity stabilized flow it is clear from previous work on gas and napl movement in the subsurface agartan et al 2015 clayton 1998 parker and park 2004 sale and mcwhorter 2001 yang et al 2014 that to understand the potential impact of stray gas migration on the environment the conceptual model needs to consider both free phase gas movement and gas dissolution which are related through the architecture of the gas distribution bench scale experiments can be used to better understand this migration under both active and inactive conditions the goal of this study was to investigate gas flow geometry shape and dimensions as a result of subsurface gas injections from initial injection to breakthrough and during redistribution following the extinction of injection pressure relaxation this study used air injected into air saturated water as a surrogate for methane to eliminate mass transfer from the invading gas and focused only on free phase gas movement the specific objectives of this study were to i assess the validity of light transmission for the measurement of local near pore scale gas saturations during gravity destabilized gas flow ii understand the spatial and temporal dependence of gas flow geometry on injection rate and distance from injection source and iii quantify and compare gas flow geometry during active leaks and inactive leaks two sets of intermediate scale experiments were conducted using quasi two dimensional light transmission flow cells i a small scale experiment for validation of local gas saturation over a range of gas injection rates and ii a large scale experiment for investigating gas dynamics and changes in gas flow geometry with increased distance from the injection point 2 materials and methods 2 1 small scale experiments gas injections conducted by van de ven and mumford 2019 were used to validate local gas saturations the small scale flow cell was constructed of 1 1 cm thick acrylic plates allowing sand to be packed between the plates creating a sand pack of dimension 25 25 1 cm3 the 1 cm thick cell construction allows for a slice approximately 14 grain diameters thick using 0 7 mm grains of sand to be studied the effluent from a clear well that spanned the total height of the cell was set to a constant height equal to the height of the flow cell lid water displaced from the sand pack through the effluent tubing during gas injection was collected in a covered beaker placed on a balance mettler toledo ms6002s and displaced water mass was recorded every 1 s four ports along the bottom of the flow cell were fitted with hydrophilic 10 µm nylon membranes to allow the entire sand pack to be drained to a residual water saturation further details of the flow cell and gas injection experiments can be found in van de ven and mumford 2019 which were analyzed in this study to investigate transient gas saturations 2 2 large scale experiments the two dimensional flow cell used in the large scale experiments had internal dimensions of 146 150 2 cm3 and consisted of two 1 5 cm thick glass panels separated by a 2 cm space for sand packing to reduce possible deflection in the glass the panels were supported by a stainless steel frame sealed to the glass using viton foam gaskets with two support bars over the glass face fig 1 nine drainage ports along the bottom of the cell were fitted with 10 µm nylon membranes the cell lid was sealed to the frame using a hydrophobic neoprene gasket to establish a confined sand pack and to prevent grain rearrangement during gas injection perforated stainless steel channels wrapped in wire mesh served as clear wells on each side of the sand pack an effluent port was installed in the top right corner of the cell allowing water to be displaced from the cell and through the clear well during gas injection tubing connected to the effluent port was set at a constant height equal to the height of the confining gasket a point source injection was used to replicate a stray gas leak in an aquifer for example as would occur at the first intersection of a gas pathway associated with a defective well seal and shallow aquifer material with a relatively low entry pressure the point source consisted of a 15 24 cm long 22 gage 0 413 mm inner diameter stainless steel needle placed in the middle drainage port along the bottom of the cell and reached 7 2 cm into the sand pack fig 1 prior to packing the injection needle was filled with air at a pressure equal to the hydrostatic pressure within the cell 2 3 porous media the small scale cell was packed with uniform silica sand 20 30 accusil agsco corp with a median grain size of 0 713 mm schroth et al 1996 which was washed before use to remove any fines the large scale flow cell was packed with washed 12 20 accusil with a median grain size of 1 105 mm schroth et al 1996 different sand grain sizes were selected for the small and large scale experiments because of the difference in cell thickness 1 cm for the small scale and 2 cm for the large scale because of the greater thickness of the large scale cell a coarser sand was required to ensure that changes in gas saturations could be detected sand was packed into each cell by continuously funneling a wet slurry of sand and deionized water to promote a fully water saturated and homogeneous pack consistent with previous experiments conducted in similar flow cells van de ven and mumford 2018 the sand pack was vibrated during and after packing and allowed to settle overnight to reduce grain rearrangement during gas injections due to minor impurities within the coarser sand and packing procedures at this scale some heterogeneity bedding structure is present in the large scale experiment seen as dark lines in the sand pack fig 1 the porosities for all experiments were measured gravimetrically dry sand mass following gas injection 2 4 gas injection and gas pressure measurement gas injection was performed using a syringe pump cole parmer 78 0232c to provide a constant gas flow during injection multiple syringes maximum total volume of 244 ml were connected to the stainless steel needle in the cell using ptfe high pressure tubing each syringe contained a small drop of water to humidify the injected gas thereby limiting partitioning from the water to the gas gas was injected at 0 1 10 100 250 and 498 ml min in the small scale experiments and continued until the injected gas reached the flow cell s lid these gas injection rates are at the lower end of measured scvfs nowamooz et al 2015 all but the 0 1 ml min injection were performed in triplicate table 1 gas was injected at 332 ml min in the large scale experiment also until gas reached the flow cell s lid which required 220 ml of gas in the large scale experiment the gas could redistribute after gas injection was stopped to investigate changes in the gas flow geometry immediately following active injection and during subsequent relaxation gas pressure was measured at the injection point in the small and large scale experiment using a gage pressure sensor connected to the gas injection line honeywell abpdjjt001pgaa5 for the test at 0 1 ml min honeywell abpdant005pgaa5 for tests at 10 100 and 250 ml min and honeywell abpdant015pgaa5 for tests at 498 ml min and the large scale experiment recorded every 0 6 s using a data logger campbell scientific cr300 the gas pressure measured is therefore the pressure of the gas flowing within the injection line as well as the gas that is connected to gas in the sand van de ven and mumford 2019 this gas pressure can be used to help identify the occurrence of discontinuous or continuous gas flow geistlinger et al 2006 mumford et al 2009 van de ven and mumford 2019 because fragmentation and mobilization during discontinuous gas flow causes pressure fluctuations that do not occur during continuous gas flow for example during continuous flow gas pressure increases over time due to an increase in the viscous resistance to flow as the length of a gas channel in the porous medium increases this is unlike during discontinuous flow in which the pressure fluctuates due to repeated fragmentation events that limit the maximum length of the gas channel 2 5 image acquisition and data processing images of the gas injections were recorded using a canon eos 6d fitted with a canon ef 17 40 mm lens for both the small and large scale experiments for the small scale experiments the camera was placed 60 cm from the flow cell and for the large scale experiment it was placed 2 1 m from the flow cell the flow cells were backlit using led light panels 9216 lm panel ledgo lg 1200s for the small scale experiments and a custom built 150 150 cm2 10 500 led 5050 smd panel custom effects led solutions for the large scale experiment to capture high temporal resolution images of the gas injections and gain insight into the transient gas dynamics high definition video was recorded at 1920 1080 resolution final resolution of small and large scale experiments were 0 25 mm pixel and 1 4 mm pixel respectively and a frame rate of 29 97 fps the camera settings were chosen manually to ensure high image quality and maintain consistency during the experiments iso2000 f6 3 and a shutter speed of 1 30 for the analysis of gas saturations still frames were extracted from the videos cropped to remove the cell frame and converted to greyscale intensity the images were also up scale discretized to 1 1 mm2 blocks for the small scale experiments and 7 7 mm2 blocks for the large scale experiment to capture full grains of sand and to reduce noise in the images this up scaled resolution was achieved by averaging the intensity value of all pixels in the area of each block at the desired discretization and applying the average intensity to all pixels within the block this upscaling removes noise created by dark pixels and minor variations in the incident light van de ven and mumford 2018 the images were used to calculate gas saturations using the light transmission method ltm which is an established technique based on the calibration of measured intensity of light passing through a thin slice of a porous medium niemet and selker 2001 tidwell and glass 1994 the technique combines beer s law which describes the light passing through a homogeneous medium and fresnel s law which describes the refraction and absorbance of light passing through interfaces described mathematically as 1 i c i o τ pl 2 k s e τ pg 2 k 1 s e exp α p d p k where i is the transmitted intensity c is a geometric constant which corrects for the position of emitted and captured light i o is the incident light intensity τ is the average transmittance of an interface and the subscripts p l and g refer to the grain liquid and gas respectively k is the number of pores through which incident light travels se is the effective water filled saturation αp is the absorbance coefficient of the grains and dp is the thickness of a grain a key assumption for the measurement of gas saturations using light intensity is that the incident light is normal to the thin slab of media at every location where i is measured assuming that the porous medium consists of uniform pores that are either water filled or contain only residual water films the effective water saturation can be calculated as niemet and selker 2001 2 s e 1 ln i i s ln i r i s 1 s g s r 1 s r where is the light intensity transmitted through a water saturated sand ir is the light intensity transmitted through a sand at residual wetting saturation sg is the gas saturation and sr is the residual wetting saturation in many applications of ltm eq 2 is calibrated using images of a sand pack under water saturated and residual conditions to determine local effective saturations from images of the sand pack under unsaturated conditions video was collected prior to the injection of gas for both the small and large scale experiments to determine the saturated light intensity is following the completion of gas injection the flow cells were drained for a minimum of 24 h and then video was recorded to determine the residual light intensity ir the water displaced during drainage to residual saturation was collected and weighed to calculate the residual saturation saturated and residual images were based on the average intensity over a 5 s period 150 images each prior to injection and after drainage to residual respectively the gas saturation detection limit was set to three times the standard deviation of the calculated gas saturation in an area of each flow cell that did not contain gas in any experiment the average detection limit for the 13 small scale experiments was 0 032 sg detection limit of 0 025 0 039 across all experiments and was 0 057 for the large scale experiment table 1 because the lower detection limit is the error associated with a water saturation of 1 the error on water and gas saturations is assumed to be 3 2 for the small scale and 5 7 for the large scale experiment 3 results and discussion 3 1 validation of calculated gas saturations using light transmission methods gas injections in the small scale flow cell were used to validate the measurements of local gas saturations using ltm although the volume of gas calculated using eq 2 and the measured i s and ir values matched the volume of displaced water during stable drainage air invaded from the top of the flow cell the calculated volume of gas was substantially less than the volume of displaced water in the gas injection gravity destabilized experiments fig 2 a the average measured ir is values over the 25 cm 25 cm face of the flow cell for the 13 experiments ranged from 0 120 to 0 211 table 1 similar to the reported value by niemet and selker 2001 however larger values would be required to match the water displacement data during gas injection as reported by mumford et al 2015 fitting the water displacement data by adjusting the value of ir is rather than using measured intensity values fig 2b required fitted ir is values of 0 35 to 0 63 table 1 the best fit ir is value of 0 63 for experiment 0 1 a is equal to the average best fit value reported by mumford et al 2015 for slow gas injection into 20 30 accusand although mumford et al 2015 suggested that the difference between traditional ir is values used in gravity stable experiments and those in their study were caused by some light passing around the experimental apparatus rather than through the sand the current study used a different cell and improved light control but required the same ir is value to match the injected gas volume the original conceptualization for the light transmission method niemet and selker 2001 tidwell and glass 1994 assumed that transmitted light passed through the thin sand pack orthogonal y direction to the light source fig 3 a this assumption is valid for gravity stabilized systems where interfaces between gas water and grains are consistent in the x direction due to stable fronts however in gravity destabilized systems where thin in the x direction channels develop over the height of the cell z direction interfaces along the incident light direction cause refraction of light fig 3b the need to calibrate ir is values for gravity destabilized gas flow arises because the light intensity of gas occupied pore spaces during gravity destabilized gas flow are higher brighter because of refraction from the adjacent water saturated sand that is the transmitted light intensity at a given location in the sand pack that is drained to residual saturation is higher if it is part of a gas channel gravity destabilized than if the entire pack was drained to residual saturation gravity stabilized because it is lit both from the side refracted light due to interfaces in the y direction and by the back transmitted light fig 3b therefore a higher value of ir is needs to be used in eq 2 to fit the gas volume to account for this additional light the more gas channels that are present 0 1 ml min vs 498 ml min the less each gas channel is lit from the side causing the best fit ir is value to be closer to the measured ratio at higher gas injections rates failure to account for this change in ir is results in an underestimation of the gas volume during gravity destabilized gas flow to account for the discrepancies between injected and measured gas volumes for gravity destabilized gas flow both in this study and mumford et al 2015 it is hypothesised that the required ir is value depends on the gas flow geometry i e gravity destabilized compared to gravity stabilized flow this is evidenced by the trend in the best fit ir is value with increasing gas injection rate while the slope of the data for each gas flow rate was less than 1 1 the discrepancy between the injected gas volume based on water displacement and the imaged gas volume was larger for lower flow rates i e data for 498 ml min upper dotted line is closer to 1 1 than data for 0 1 ml min lower dotted line fig 2a combining this observation with the calibrated saturation maps for each experiment fig 4 shows that the calibrated ir is decreases with increasing occupation of the domain by gas from 0 63 for the 0 1 ml min injection to 0 35 for the 498 ml min injections using validated gas saturations calculated with the best fit ir is values to account for gravity destabilized gas flow it was observed that gas injections at 0 1 and 10 ml min each produced a single gas channel which grew vertically until the channel made contact with the lid of the cell fig 4a b minimal lateral movement of the gas channel was seen at these flow rates unlike experiments at 0 1 and 10 ml min gas injections at 100 250 and 498 ml min showed complex patterns composed of multiple continuous channels fig 4c e for the higher flow rate experiments the injected gas pattern widened as the gas migrated vertically before contact with the lid and the number of channels increased with increased flow rate all gas injections showed signs of local i e pore scale heterogeneity with varying gas saturations 0 03 0 4 throughout the gas channels fig 4 typically each gas channel was composed of a high saturation inner core gas saturations of 0 2 to 0 4 surrounded by a lower saturation outer shell gas saturations of 0 03 to 0 2 as a result of channel geometry and some refraction of light during the large scale injection gas saturations calculated using ltm were compared to the volume of injected gas rather than the volume of displaced water similar to the small scale injections the volume of gas calculated using eq 2 is underestimated if measured values were used for ir is therefore a best fit ir is value of 0 33 was used table 1 to generate gas saturation maps during injection and relaxation fig 5 the best fit value for the large scale injection is consistent with those used for the small scale injection at the higher injection rates 3 2 gas flow pattern during active injection gas injection into the large scale flow cell ls produced a dynamic flow pattern which changed as the gas progressed away from the source fig 5a g early in the injection gas was observed to flow mostly vertically as multiple laterally overlapping gas channels fig 5a and b the pattern appeared to be continuous strongly influenced by gravity and viscous forces as the gas progressed away from the source to a height of approximately 50 cm above the source fig 5c the gas fingers appeared more unstable migrating vertically with some lateral movement as gas injection continued the gas pattern became more unstable 66 cm above source moving as more discrete channels with some lateral spreading fig 5d f this phenomenon is the result of reduced viscous forces as the gas channel spreads laterally x direction causing the total gas flow to be spread over a greater cross sectional area and allowing gravity and capillary forces to dominate the flow pattern measured gas pressure black line in fig 5h was used to better define changes in the gas pattern away from the source distinguishing between continuous and discontinuous gas flow at early times the pressure increased nearly linearly and gas entered the sand point a pressurization following pressurization a growth stage was observed where gas pressure increased non monotonically point a e the pressure increases point b c and d e by 12 and 34 cm of h2o respectively and decrease c to d by 34 cm of h2o are the result of continuous gas channels contacting thin bedding structures within the sand pack during pressure increases the gas channels vertical movement is hindered by the minor bedding structure higher entry pressure and the entire connected gas structure pressure increases once the gas pressure is high enough to break through the bedding structure the gas structure decreased in saturation near the injection needle fig 5c e as a result of mobilization of gas fragmenting the channels this is further supported by the pressure decrease between point c and d however the generally increasing slope of the gas pressure at these points suggests that the fragmented structure quickly became continuous again although this study is not focused on these short term saturation fluctuations the results demonstrate that even in a reasonably homogeneous sand pack local variations in permeability will affect gas flow following the growth stage a discontinuity stage is seen from point e to f indicated by the slowly decreasing gas pressure previous work van de ven and mumford 2019 suggests that if the gas flow at this constant injection rate had remained continuous further increases in gas pressure at the injection point would have occurred due to viscous resistance through a longer gas flow pathway in the sand after gas injection stopped point f the pressure quickly decreased relaxation until a constant pressure of 152 cm h2o was reached which represents the pressure of a gas cluster that remained connected to the needle this is 35 of the pressure represented by point a the measured gas pressure is clear evidence of the injection transitioning from continuous point a e to discontinuous flow van de ven and mumford 2019 used gas injection pressure to distinguish between continuous transitional and discontinuous flow continuous flow is observed when gas pressure increases linearly as a result of connected gas clusters migrating from the source causing higher frictional forces as the structure grows in width and length point a e when gas flow is transitional and discontinuous the linear pressure increase is observed to flatten out as a steady state frictional resistance is reached causing a steady gas pressure except for minor fragmentation events observed as small episodic pressure fluctuations due to the uncertainty of the pressure sensor used 1 5 fss equating to 3 cm of water the small pressure fluctuations of discontinuous channels expected to be approximately 2 cm mumford et al 2009 cannot be observed however the decrease in slope observed after point e coupled with saturation maps showing non monotonic gas channels fig 5f are indicative of discontinuous flow the gas saturations and pattern as gas progressed away from the source can be linked to the observed injection patterns in the small scale experiments adding insight to the dynamic conceptual model for free phase stray gas movement during active injection dense overlapping channels with saturations ranging from 0 1 to 0 4 fig 6 a were observed near the injection point this dense cluster is consistent with a high flow rate injection fig 6f where multiple channels develop allowing for the high mass flow rate to be distributed over the cross sectional area of the cell as the gas moved upwards approximately 35 cm above the injection point the channel network became less dense as the channels were distributed over a wider area replicating observations of a lower flow rate injection but still with high gas saturations between 0 1 to 0 4 fig 6e once the gas extended 66 cm from the injection source the channel network continued to become less dense creating discrete channels of sustained high saturation pressure measurements show that gas flow in this region was continuous but began to show signs of transitional behavior similar to the small scale experiments with an injection rate of 100 ml min fig 6d for this experiment at a height of 105 cm above the injection source flow became transitional showing sparse continuous channels which resembled flow in the small scale experiments of 10 ml min fig 6c the saturation of these channels was lower than the bulk cluster below ranging from 0 1 to 0 25 discontinuous flow was observed 121 cm above the injection point discrete relatively low saturation 0 1 to 0 25 channels were seen which show disconnection over the vertical length and were similar to those observed during the 0 1 ml min gas injection in the small scale experiments fig 6b although the detection limit was higher in the larger flow cell 0 057 it would be expected that below this saturation flow would not be connected this evidence of discontinuous flow is supported by the pressure measurements the large scale gas injection is to the best of the authors knowledge the first investigation of a high flow rate injection gas pattern transitioning from continuous to discontinuous gas flow as the gas moved vertically away from the injection source this transition occurs as a result of increased lateral spread of the injected gas which causes the constant mass injection rate to be distributed over a greater cross sectional area decreasing the local gas flow rate in individual channels as the gas moves further from the source geistlinger et al 2006 selker et al 2007 this finding suggests that the conceptual model for free phase gas injection in a homogenous subsurface depends on the vertical distance of that gas from the injection point the distance at which this transition occurs depends on the viscous resistance to flow which is affected by the medium through which the gas flows and the injection rate with finer media and higher rates resulting in discontinuous gas flow further from the source for gas flow in the sands such as those used in this study this distance is expected to be on the meter scale the similarities between small and large scale experiments show that bench scale experimentation can provide valuable insight regarding conceptual model development and field scale investigations however careful consideration must be paid to the location represented in the experiments because the gas flow is expected to change with increasing distance from the gas source these similarities between the small and large scale experimental results can also be used to better understand pore scale phenomena over the vertical extent of the gas pattern and provide insight to the effect of that gas pattern on mass transfer from the gas to the aqueous phase and inform related modeling efforts 3 3 gas saturations during active injection and relaxation comparison was made between gas saturations during active injection fig 7 a and relaxation fig 7b during the large scale experiment ls changes in both the gas saturations and the gas geometry from active to relaxed conditions are highlighted by subtracting the two gas saturation maps fig 7c a green color represents a decrease in gas saturation and red represents an increase fig 7c shows that gas saturations vary substantially decreasing at most locations between active and relaxed conditions with local decreases as high as 0 15 the geometry of the gas injection area however did not change substantially indicated by minimal red color in fig 7c the bulk of the gas distribution remained unchanged apart from an increased number of fingers in the discontinuous zone to further compare the changes in gas saturations between the active and relaxed conditions average gas saturations were measured over the height of the gas fig 7d gas saturations were averaged horizontally considering only gas saturations greater than the detection limit average gas saturations decreased approximately by 0 07 from active to relaxed conditions in a region directly above the injection to a height of 65 cm greater than 120 cm above the injection only minor local changes occurred these regions correspond well with the occurrence of continuous and discontinuous flow fig 6 with transitional flow occurring between them regions in which continuous gas flow occurs allow for greater relaxation a decrease in gas saturation once injection has terminated compared to discontinuous regions this is the result of continuous flow patterns being composed of multiple overlapping connected channels of gas these connected channels have a high enough volume of gas to create a sufficient buoyant drive to overcome local capillary trapping thresholds causing vertical migration to continue even after the termination of an injection pressure because the channels are connected the channel needs only enough buoyant drive to overcome the entry pressure of the least resistant pore for flow at the top of the channel to occur in contrast discontinuous and transitional patterns are composed of disconnected gas clusters which do not have sufficient buoyant drive to overcome capillarity this finding is consistent with the work of stöhr and khalili 2006 who found that following the breakthrough of migrating gas from the top of their test apparatus substantial redistribution was observed following channel flow continuous flow and minimal redistribution for cluster flow discontinuous flow it is likely that a critical gas saturation exists at which the buoyant drive of connected gas clusters is sufficient to cause vertical redistribution as an estimate of this value the average gas saturation was found to be 0 1 in the 1 1 mm sand following relaxation 4 summary and conclusions air was injected at a high rate into a large scale two dimensional flow cell to develop a better understanding of free phase gas flow related to stray gas migration in unconsolidated porous media visualization techniques enabled observations of spatial and temporal gas dynamics during migration over a large vertical length scale relative to many previously published studies results of the large scale experiment were combined with results from gas injections into a small scale flow cell which were used for validation of gas saturations and near pore scale observation at varying flow rates an important component of the free phase stray gas conceptual model is quantification of the source architecture it was found that the traditional light transmission method was not able to accurately quantify gas saturations in sand during gravity destabilized gas injections and required correction using ir is as a fitting parameter that was greater than measured ir is values obtained under gravity stabilized conditions the best fit value of 0 63 agreed with previous studies for slow gas injections but decreased with increased gas flow rate as a greater portion of the flow cell was occupied by gas at higher injection rates the observed discrepancy between fit and measured values was attributed to internal refraction within the gas channels created during gravity destabilized gas flow which increases the light intensity transmitted through gas filled pores adjacent to water filled pores following the methodology proposed for the small scale experiments gas saturations in the large scale experiment were fitted to the known volume of injected gas the results of the large scale experiment showed that any conceptual model for free phase gas flow should consider changes in the gas flow pattern with increased height from the injection or leak source gas injection rates high enough to create continuous gas flow near the source result in the formation of a dense network of channels with high gas saturation 10 40 however as gas migrates away from the source the gas flow transitions to discontinuous channels of lower gas saturation 10 25 this transition is the result of local gas flow rates decreasing as gas flow is distributed over a larger cross sectional area this finding has substantial implications for stray gas migration in homogeneous aquifers first the resulting gas architecture will affect mass transfer it would be expected that near to the source continuous region mass transfer would be limited by low interfacial area and a reduced aqueous relative permeability further from the source where gas becomes discontinuous mass transfer would be substantially higher as a result of higher interfacial area and increased aqueous relative permeability one possible effect of this variation of gas architecture with height is that the longevity of the free gas depends on its depth within the system longer dissolution times are expected for free phase gas near the source and shorter dissolution times for migrating gas in shallower portions of an impacted system with the faster dissolution rates associated with higher interfacial area in shallower portions potentially leading to higher aqueous concentrations heterogeneity will affect these implications particularly in systems with high contrasts in permeability where capillary barriers will result in the accumulation of gas pools secondly it is common that stray gas migration is identified and monitored by means of surface measurement of gas forde et al 2018 molofsky et al 2016 based on the findings of this study depending on the leak rate and the depth at which the leakage is occurring it is likely that gas flow at the surface would be intermittent despite a continuous leak at depth this is expected because of the transition of flow from continuous to discontinuous which would cause gas to reach the surface as disconnected clusters this is in addition to other factors including variations in environmental forcing and characteristics of the gas leak that can affect the magnitude and frequency of gas emissions at ground surface dusseault and jackson 2014 forde et al 2019 therefore it is important that when monitoring for stray gas migration at the surface high temporal resolution monitoring be used as discrete measurement may not capture the intermittent releases of stray gas also depending on the sampling technique this intermittent migration may dilute small intermittent releases below detection limits for longer duration sampling events in these experiments the source architecture of the free phase gas was found to be highly dependent on whether a leak is active or relaxation has occurred due to extinction of injection pressure although the geometric characteristics of free phase gas remained similar between active and relaxed conditions the local gas saturations varied greatly once gas injection had ceased the buoyancy of the gas in the connected gas region allowed gas to continue migrating upward leaving behind average residual gas saturations of approximately 0 1 in the coarse sand used in this study it was found that a critical gas saturation of 0 1 or greater was required to allow for gas to buoyantly migrate without a sustained gas injection pressure in the discontinuous region gas saturations were not substantially affected by the extinction of gas injection this finding suggests that if a high rate gas leak ceases gas flow will dramatically decrease the original mass available for mass transfer to the groundwater near the source and will likely continue to move vertically toward the surface the development of conceptual models for stray gas migration need to consider spatial and temporal variation in free phase gas architecture gas movement occurs as a combination of continuous and discontinuous flow and this variation will affect mass transfer longevity and release characteristics ultimately influencing monitoring and detection strategies and the accurate estimate of migration emissions and impacts in a homogeneous system it was found that a high fraction of mass is concentrated at the point of the leak when gas is actively being injected and that this mass will move upwards after injection has ceased it is important to note that stray gas migration is complex and dynamic but will also depend on the scale being considered particularly with respect to heterogeneity and anisotropy future research efforts and conceptual model development must consider the timeframe and proximity to the source as well as potential gas pathways to accurately assess these systems credit authorship contribution statement cole j c van de ven conceptualization methodology validation formal analysis investigation writing original draft visualization writing review editing justine e f abraham investigation writing original draft kevin g mumford conceptualization methodology validation resources writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the natural sciences and engineering research council nserc of canada through a canada graduate scholarship to c j c van de ven collaborative research and training experience create grant 449311 2014 and a strategic partnerships grant for projects spg 506784 2017 the assistance of stanley prunster is gratefully acknowledged we also recognize the hard work of lisa tauskela and allison finer 
499,co2 reinjection in petroleum reservoirs brings advantages in oil production but may cause dissolution in carbonate reservoirs two scale continuum models have been successfully used to simulate acidification however the use of realistic porosity and permeability fields in mesh simulations is still a challenge in such a way that uniform and normal distributions have been used to generate these fields in the past the main objective of this work was to transcript the plugs heterogeneity from the micro ct images to simulation the porosity field was calculated directly from micro ct images and two methodologies are proposed to calculate the permeability field a reactive two scale continuum solver was implemented in openfoam and used to simulate reactive flow in two carbonate samples with different intrinsic reaction rates calcite and dolomite the experimental permeability evolution curves as well as wormholes shapes and paths are reproduced in the simulations we observed a critical influence of specific surface area reaction rate constant and initial permeability field for the simulations of acidification processes keywords digital rock physics carbonates reactive flow modeling two scale continuum model openfoam 1 introduction carbon dioxide is considered the most crucial gas contributor to the greenhouse effect its concentration in the atmosphere is increasing mainly due to fuel burning abedini and torabi 2014 hasanvand et al 2013 co2 is present in some petroleum reservoirs as in brazilian pre salt carbonates and is produced along with oil exploitation some alternatives to avoid its emission to the atmosphere include geologic storage reinjection and water alternating gas injection wag han and kim 2018 harp et al 2018 wang et al 2018 myshakin et al 2018 sanguinito et al 2018 bielicki et al 2018 yang et al 2018 shevalier et al 2013 when co2 dissolves in reservoir fluids carbonic acid h2co3 is generated which decreases the ph of the solution and possibly causing the dissolution of some constituent rock minerals it can cause severe damage to the reservoir such as the collapse of injection wells klokov et al 2018 peng et al 2015 yasuda et al 2013 fitts and peters 2013 adebayo et al 2015 carbonate dissolution depends on temperature pressure and salinity renforth and henderson 2017 farquhar et al 2015 speciation of co2 and dissolution equations for calcite and dolomite are given by yoo et al 2018 sainz garcia et al 2017 al shalabi et al 2014 plummer et al 1978 baritantonaki et al 2017 peng et al 2016 1 c o 2 h 2 o h 2 c o 3 h h c o 3 2 h c a c o 3 c a 2 h c o 3 3 2 h c a m g c o 3 2 c a 2 m g 2 2 h c o 3 many studies were carried out to understand the role of co2 in modifying carbonates peng et al 2018 pearce and dawson 2018 le gallo and de dios 2018 claes et al 2018 lebedev et al 2017 deng and peters 2018 studied the effects of co2 on fracture transmissibility using 2d models to characterize the flow of co2 in fractured carbonates kim et al 2018 investigated geomechanical changes in calcitic reservoirs due to co2 injection bickle et al 2017 focused on the reactivity of reservoir rocks by sampling fluids from sites where co2 was injected for over six months guo et al 2018 observed significant changes in hydraulic permeability even for rocks with small carbonate content among the different techniques used to investigate experimental rock alterations caused by dissolution singh et al 2018 numeric simulation is an essential tool to help understand the effects of co2 injection in reservoirs there are many software packages available for this purpose coores eclipse gem phreeqc toughreact openfoam and in house solutions lamy chappuis et al 2018 yasuda et al 2018 saxena et al 2018 tambach et al 2017 snippe et al 2017 rostami et al 2019 jiang 2011 xu et al 2006 used toughreact to study the flow in a fractured 1d medium andre et al 2007 used the same software to simulate the 1d radial flow from the borehole to the reservoir comparing the effects of injecting saturated brine with those caused by the injection of supercritical co2 ahmad et al 2016 chose multiphysics as the computational tool to simulate the injection of co2 saturated brine in a geological reservoir the model was based on the navier stokes darcy equation also known as the brinkman equation to characterize flow and the lasaga equation lasaga et al 1994 for reaction kinetics menke et al 2015 carried out flow experiments and pore scale simulations phenomena that occur at the pore level using openfoam to evaluate the effects of carbonate heterogeneity on reaction rates they point out that mineral dissolution decreases the tortuosity of the flow path in another study using the same models menke et al 2016 investigated the flow of co2 rich brines in highly heterogeneous carbonates they observed a strong influence of the initial porous system configuration in the shape of the wormhole created during reactive flow since flow path prefers high permeability regions dissolution will be concentrated in these sections of the rock enhancing pore connection and forming a preferential flow path the authors suggested that the formation of a preferential path occurs instead of wormholing pereira nunes et al 2016a b studied the effects of initial physical heterogeneity on carbonate dissolution by co2 saturated brines using a pore scale model they observed lower reaction rates in porous media compared to batch reactor values and concluded that reaction may be surface controlled inside pores and transport controlled at plug scale qajar et al 2013 studied the effects of fines migration and chemical dissolution in carbonates by micro ct in another work qajar and arns 2017 investigated the evolution of permeability with pore throat diameter in carbonate reactive flooding experiments and showed that the impact of reactive flow concentrates in the larger pores increasing the connectivity of macropores izgec et al 2010 conducted acidification experiments of vuggy carbonates using hcl their experiments showed that wormhole formation is faster in vuggy carbonates to understand vug effects on the non reactive flow they implemented a solver based on the brinkman equation and demonstrated that flow connects the vugs which acts as a highly permeable path besides izgec et al 2010 and menke et al 2015 2016 many authors investigated the effects of carbonate heterogeneities on the flow and wormhole formation al khulaifi et al 2018 xiao et al 2017 sun et al 2017 menke et al 2018 and concluded that heterogeneity is a crucial factor to describe correctly flow effects on carbonates menke et al 2018 cohen et al 2008 kalia and balakotaiah 2009 maheshwari et al 2013 smith et al 2013 two scale continuum models have been used to simulate wormhole formation predicting qualitative behavior in wormholing at darcy scale and requiring moderate computational effort this kind of model uses information from pore scale to complement the equations in darcy scale besides treating boundaries between pores and solids in a continuum way thus avoiding problems of high gradients in interfaces panga et al 2005 developed a 2d two scale continuum model to study carbonate acidification using hcl their model describes transport and reaction and couples darcy scale variables such as darcy velocity and pressure to pore scale properties by relationships that updates permeability pore radius and other properties based on porosity changes in their work they used fixed porosity and uniform distribution of permeability on the mesh liu and liu 2016 modified darcy law by navier stokes darcy equation in the continuum model developed by panga et al 2005 using a mesh with constant initial porosity and permeability to simulate carbonate acidification with viscoelastic surfactant based self diverting ves acids the typical approach to transcript the intricate pore system to the mesh is to generate porosity fields based on a constant value in which a perturbation random normal and others is applied panga et al 2005 liu and liu 2016 liu et al 2017 ghommem et al 2015 mahmoodi et al 2018 roded et al 2018 and the use of simplified 2d models deng and peters 2018 izgec et al 2010 roded et al 2018 chen et al 2018 to capture rock heterogeneities hao et al 2013 smith et al 2017 used a 3d continuum reactive transport model to simulate co2 injection in carbonate plugs they compared the results with reactive flow experiments in which a vuggy limestone and a marly dolostone were flooded by co2 saturated brines at different pressures simulations were conducted with non isothermal unsaturated saturated flow and transport nuft algorithm the model used darcy s law to handle fluid transport and mass balance to model multi component transport scanning electron microscopy sem images were used to estimate relative amounts of pores calcite and dolomite in different samples the results were correlated to grayscale ranges in micro ct images to determine porosity at each point of the mesh to evaluate the permeability field the authors classified the pore system in three regions of permeability based on 2d segmented sem images each region had a constant value of permeability the significant contribution of their study was to simulate reactive flow in a mesh that captured the heterogeneities of the pore system at the micro ct image resolution in general panga s two scale continuum model has been successfully used in wormholing and reactive flow modeling the main difficulty using it relies on creating a 3d mesh that faithfully represents carbonate porous structures as this type of rock may have a very complex porous system from micropores to vugs darcy equation may not accurately characterize flow in the larger pores hosseinzadeh and bazargan 2018 hao et al 2013 smith et al 2017 estimated porosity and permeability fields to be used as inputs to simulations instead of using constant values the sample was segmented in three regions and the permeability values of these regions were geometrically estimated based on micro ct and 2d sem images several authors adopted simplified 2d models or normal and linear distributions of porosity and permeability in the mesh hao et al 2013 smith et al 2017 estimated these fields by using 2d sem images and darcy s law in simulations which might not correctly characterize flow in vuggy carbonates hosseinzadeh and bazargan 2018 this demonstrates that there is a gap in the literature about the methodology for a realistic estimation of porosity and permeability fields for flow simulations the main objective of our work was to use micro ct images of carbonate plugs to estimate more realistic porosity and permeability fields for each voxel based on direct numerical simulation dns as well as characterization and flow experiments these fields were fed to a two scale continuum solver that uses navier stokes darcy equation implemented in openfoam to conduct 3d simulations of reactive flow on a vuggy carbonate silurian dolomite and a non vuggy homogeneous carbonate indiana limestone this model is used to investigate the influence of the methodology of permeability field estimation among other essential properties on wormholing process 2 mathematical modeling our solver is based on the two scale continuum model presented by panga et al 2005 it uses the navier stokes darcy equation instead of darcy equation for a better characterization of the flow in the vugs as follows 4 ρ u t ρ u u ϵ ϵ p μ 2 u ϵ μ k u 5 ϵ t u 0 6 ϵ c f l t u c f l ϵ d e c f l a v r c s 7 u u x u y u z where ρ is fluid density kg m 3 u velocity vector m s 1 t time s ϵ porosity p pressure kg m 1 s 2 μ viscosity kg m 1 s 1 k permeability m2 cfl the cup mixing concentration of acid in solution mol m 3 d e effective dispersion tensor m2 s 1 av specific surface area per volume m 1 and r cs the reaction kinetics the brinkman eq 4 for fluid flow was developed in 1947 to characterize porous media flow and free flow in vugs and big pores it is valid for a homogeneous porous media incompressible fluid and considering boussinesq approximation of the momentum equation basirat et al 2015 from left to right the two first terms represent the local and convective accelerations respectively and the three right hand terms side represent pressure gradient viscous effects and the darcy term respectively this equation has the advantage of not requiring a full pore boundary description in a simulation cell representing the porous media pressure gradient and darcy terms are the only significant ones so that eq 4 becomes darcy law inside pore cells a high permeability value is assigned making the darcy term negligible and turning eq 4 into the navier stokes equation the first term of the continuity eq 5 characterizes volume changes caused by dissolution eq 6 is responsible for acid transport its first term refers to accumulation the second term calculates convection the third term is responsible for dispersion and the fourth one is related to acid consumption by the reaction panga et al 2005 assumed that r cs can be calculated as follows 8 r c s k c c f l c s where kc is the local mass transfer coefficient m s 1 and cs the acid concentration at the solid fluid interface mol m 3 since they used a porosity distribution between 5 and 35 at least some rock was available for reaction in all cells of the mesh since our work proposes to simulate reactive flow in vuggy carbonates and for the vug cells there is no available rock for reaction we cannot use eq 8 a new term was added in order to consider reaction on vug cells as follows 9 r c s k c c f l c s r f 10 r f 1 ϵ 1 ϵ 10 20 where rf is the reaction factor the constant 10 20 was inserted in the equation to avoid a division by zero in the vugs cells where ϵ 1 resulting in rf 0 when ϵ 1 rf 1 and reaction is accounted for first order reaction kinetics the reaction rate may be calculated as follows 11 r c s k s c s r f where ks is the reaction rate constant at the surface m s 1 using eq 11 into 9 we get 12 c s c f l 1 k s k c at kinetic regime cs cfl while at mass transfer regime cs 0 the parameter ks is specific for each acid while kc depends on the pore geometry reaction rate and local flow regime the equation below takes into account both regimes describing porosity evolution caused by reaction 13 ϵ t r c s a v α ρ s where α is the dissolving power of the acid defined as the mass of dissolved rock per mol of reacted acid kg mol 1 and ρs the density of the rock kg m 3 eqs 4 to 6 and 9 to 13 describe the macroscopic variables and form the darcy scale model equations from pore scale model account for local phenomena which occur at the scale of pores panga et al 2005 divided them into three groups structure property relations that update permeability pore radius and specific surface area due to structure alterations dissolution mass transfer coefficient to quantify acid transport from the fluid phase to the fluid solid interface and dispersion coefficients semi empiric equations are used to update structure properties as follows 14 k t k o ϵ t ϵ o ϵ t 1 ϵ o ϵ o 1 ϵ t 2 β 15 r p t r p o k t ϵ o k o ϵ t 16 a v t a v o ϵ t r p o ϵ o r p t where rp is the mean radius of the pores m β is an adjusting parameter and superscripts t and o represent the variable at the new time step and at the old time step respectively sherwood number sh is used to estimate kc as follows balakotaiah and west 2002 17 sh 2 k c r p d m sh b r e p 1 2 sc 1 3 18 r e p 2 ρ u r p μ 19 sc μ ρ d m where sh is asymptotic sherwood number for the pore and according to balakotaiah and west 2002 assumes 3 66 for spherical pores b is a constant b 0 7 rep reynolds number in the pore dm molecular diffusivity of the acid m2 s 1 and sc schmidt number defined as a ratio between the momentum and mass diffusivities in the fluid for homogeneous and isotropic porous media dispersion tensor is a sum of two terms the longitudinal and transverse coefficients random walk models and analogy with packed beds are used to calculate these two terms as follows 20 d e d e x d e t 21 d x d e x d m α 0 s λ x p e p 22 d t d e t d m α 0 s λ t p e p 23 p e p u d h ϵ d m where dex is the longitudinal term of dispersion tensor det the transverse component α 0s λx and λt are constants related to the porous media structure dm the molecular diffusivity of acid m2 s 1 dh the hydraulic diameter of the pore m and pep péclet number on the pore for a pack of spheres λx 0 5 and λt 0 1 the system was considered isothermal and incompressible the boundary conditions were based on the experiments constant flow of brine at the inlet constant pressure at the outlet and impermeable boundaries at the sides of the plug as shown in fig 1 3 laboratory experiments we use the experimental permeability evolution and final pore system to validate the simulations besides simulations also require plug dimensions acid concentrations and flow rates used in the experiments four outcrop rock samples provided by kocurek 2018 3 83 cm diameter plugs were used in this work three of them dolomite 1 dolomite 2 and dolomite 3 correspond to silurian dolostone 97 9 of dolomite from illinois usa and one calcite 1 corresponds to a mississippian limestone 99 of calcite from indiana usa these two carbonate types are also known as silurian dolomite and indiana limestone respectively one sample of each outcrop was submitted to a mercury injection capillary pressure test micp using a mercury porosimeter autopore iv 9500 micromeritics the experimental apparatus used in the flood experiments is sketched in fig 2 all experiments were carried out at constant temperature reactive flow experiments consist of the following steps 1 saturation of the plug in a brine with typical composition of reservoir formation water 2 plug confinement at the holder confining pressure 2 758 107 pa and back pressure valve 2 069 107 pa 3 flow at a constant rate see table 1 of 40 pore volumes pv of saturation brine to stabilize the system 4 flow at a constant rate see table 1 of reactive brine 9 pv to 98 pv depending on the test pressure drop was registered between plug inlet and outlet using three transducers yokogawatm the co2 reactive brine preparations consisted of injecting the exact amounts of co2 and injection brine table 2 in a hastelloy floating piston accumulator vinci 1 l 6 895 107 pa 150 c increasing the system pressure to the final value and agitating it for one day before using brine containing hcl was simpler to prepare hcl was mixed with injection brine at the accumulator and pressure was increased to 2 069 107 pa the value of cfl for the experiments with co2 was calculated by the amount of gas and brine injected in the hastelloy accumulator while hcl final concentration was measured by titration with naoh table 1 presents experimental parameters and the composition of each brine the flow velocity at the inlet u z i n l e t is calculated dividing the volumetric flow rate q by the sectional cylinder area microtomography images were acquired in an x ray scanner phoenix vtomex 140 kv 250 ma and resolution 40 µm voxel the plugs were analyzed before and after each test in order to evaluate changes in the pore system at petrobras research center cenpes the capillary pressure curves and the pore throat size distribution for the two outcrops are presented in fig 3 in indiana limestone microporosity pore radius 0 5 µm connects 39 of total porosity mesoporosity pore radius between 0 5 and 5 µm and macroporosity pore radius 5 µm connect 18 and 43 respectively for silurian dolomite microporosity mesoporosity and macroporosity are responsible for connecting 53 33 and 14 of total porosity respectively fig 3 b shows that indiana limestone has two significant peaks for pore throat radius at 0 33 and 5 µm silurian dolomite has a wider distribution of pore throats but the two more significant peaks are 0 07 and 1 µm both outcrops have a significant part of the pore throats in the microporosity region which is responsible for connecting the big pores in these samples silurian dolomite samples showed almost no reaction with co2 dolomite 1 even after the injection of 98 pv of reactive brine had its permeability increased from 35 to 38 md in an attempt to increase reactivity the plug dolomite 2 was submitted to a higher co2 concentration and increased injection rate but these changes had little effect on the plug permeability which increased from 17 to 21 md micro ct images did not show alteration appreciable in the pore system for both plugs therefore these two plugs were not used in simulations dolomite 3 was submitted to a reactive flow using hcl and a variation in permeability was observed from 19 to over 2500 md with less than 10 pv of injected brine from the micro ct image acquired after the acidification the pore system was segmented and filtered to show only the wormholes as exemplified in fig 4 in this image as well as in all other figures of this work the flow direction is lined up with the positive z axis inlet is on the base fig 4 shows a dominant wormhole in red besides small secondary wormholes a detailed view of the secondary wormholes is presented in fig 5 which reveals the presence of two small secondary wormholes pointed out by the yellow arrows and also shows that early in the flow experiment four wormholes indicated by the white arrows started to grow they ended up connecting to become a dominant wormhole permeability of calcite 1 increased from 10 to over 2200 md during reactive flow the same procedure used in dolomite 3 was applied in the micro ct image of calcite 1 in order to show the wormholes generated as can be seen in fig 6 initially more than one ramified wormhole is formed but then the secondary ones stop growing as long as the main wormhole increasingly focused the flow the permeability evolution curves for the flooding experiments in dolomite 3 and calcite 1 are presented in fig 7 this figure shows a rapid increase in permeability at the acid breakthrough 36 pore volumes injected for the experiment with the plug calcite 1 and co2 rich brine 4 numerical methods simulation mesh was generated from micro ct images of the plugs before flow experiments preserving the pore system structures each original micro ct image has a resolution of 40 µm voxel and dimensions 1 300x1 300x1 500 voxels a volume too big for the solver to handle they were resampled to 400 µm voxel using the lanczos resampling kernel clouard 2018 which assures excellent results despite being very time consuming the final dimension of the resampled images was about 1003 voxels reactivecenpesmesh transforms each voxel from a segmented micro ct image in mesh cells since micro ct voxels are hexahedral and orthogonal the generated mesh is also orthogonal which is simpler to solve numerically reactivecenpesmesh requires the porosity and permeability values for each cell of the mesh 4 1 initial porosity distribution the porosity estimation method was similar to that used by hao et al 2013 smith et al 2017 since their sample was not pure they correlated grayscale range with porosity calculated using sem images silurian dolomite and indiana limestone are composed of approximately 97 of dolomite and 99 calcite respectively we considered both outcrops pure and thus the grayscale range from micro ct images is assumed to be directly proportional to the local porosity micro ct resampled images were used to calculate plug s porosity distribution according to the following steps 1 segmentation of pores and assignment of porosity 100 to the corresponding grayscale threshold value gspore 2 segmentation of solid and assignment of porosity bp background porosity to the corresponding grayscale threshold value gssolid arns et al 2019 applied the background porosity concept to match simulated electrical properties to experimental data if only solid is segmented bp 0 but since 38 and 53 of the total porosity in indiana limestone and silurian dolomite are connected by pore throats in the region of microporosity it is important to calculate the amount of porosity at gssolid following the procedure used by lin et al 2016 in which micro ct images are acquired from dry and saturated samples we obtained the total porosity fields for samples dolomite 4 and calcite 2 plugs dolomite 3 and calcite 1 could not be used because of a laboratory restriction with gssolid and the grayscale ranges for samples dolomite 3 and calcite 1 we corrected gssolid for samples dolomite 4 and calcite 2 and segmented the solid phases we used these segmentations and the total porosity fields to calculate the values of bp resulting in 5 1 and 6 for silurian dolomite and indiana limestone respectively we adopter bp 5 for both outcrops 3 porosity calculation directly in the micro ct voxels according to the following equation 24 ϵ v o x e l 100 b p g s v o x e l g s s o l i d g s p o r e g s s o l i d b p porosity calculated using this methodology was compared to experimental results for dolomite 3 ϵ lab 11 8 and ϵ calc 12 01 while for calcite 1 ϵ lab 14 9 and ϵ calc 15 3 calculated porosity for samples calcite 1 and dolomite 3 are shown in fig 8 4 2 initial permeability distribution for simplicity we considered isotropic samples kxx kyy kzz and k i j i j 0 two methodologies were used to calculate the initial permeability distribution based on winland kolodzie 1980 and swanson swanson 1981 correlations as well as dns during simulations permeability update is computed by eq 14 as discussed before in the pore zones the brinkman eq 4 requires very high permeability values to characterize the flow correctly we set k 1 1010 md in these regions regardless of the methodology adopted 4 2 1 methodology p the porosity values in each voxel are used to estimate the initial permeability field by the empirical winland equation 25 log r 35 0 732 0 588 log k 0 864 log ϵ where r 35 is the pore aperture that corresponds to 35 of mercury saturation calculated by using experimental porosity and permeability values this methodology has the advantage of capturing porosity variation in the sample which in turn is used to calculate the permeability field fig 9 shows the initial permeability fields calculated for samples calcite 1 and dolomite 3 4 2 2 methodology s the methodology consists in segmenting a micro ct image in 3 or 4 regions of similar permeabilities the permeability of each region is calculated with dns and correlations the segmentation process in three and four phases assumes that regions of similar permeabilities have similar grayscale values as follows 3 phase segmentation pores dark grayscale more conductive high k phase and light grayscale less conductive low k phase 4 phase segmentation pores dark grayscale more conductive high k phase medium grayscale intermediate conductive medium k phase and light grayscale less conductive low k phase both samples were segmented in 3 phases however silurian dolomite is more heterogeneous and was also segmented in 4 phases three subsamples were cut from a region visually more porous of a silurian dolomite plug these subsamples were imaged at 2 4 µm voxel their pore systems were segmented and had connectivity confirmed next they were used in dns to estimate k one sample was obtained from a region with no visible porosity and imaged at 0 5 µm voxel however its pore system was not connected and no direct numerical simulation was possible for this region an in house lattice boltzmann lbm solver that has stokes equation implemented was used to execute the dns for more details about lbm and permeability simulation see andra et al 2013 from a plug of indiana limestone two samples were obtained and imaged at resolutions of 4 µm voxel 2 4 µm voxel and 0 5 µm voxel however even at the higher resolution its pore system was not connected thus it was not possible to estimate permeability by dns for this sample in regions where dns could not be performed permeability was estimated by winland and swanson correlations the swanson correlation was used to calculate k in the low k phases it uses the maximum ratio of hg saturation sb by hg capillary pressure pc as a parameter to estimate carbonate permeability according to the following equation 26 k 290 s b p c a 1 901 we used the mean porosity value calculated for the low k region as input in swanson equation to estimate the permeability in both samples in the medium k region winland eq 25 was applied to determine k in the high k phase k was estimated by dns for silurian dolomite and by winland equation for indiana limestone fig 10 shows segmentation images from samples calcite 1 and dolomite 3 4 3 simulation parameters besides the experimental parameters listed in table 1 general parameters used in the simulations are presented in table 3 many authors considered the specific surface area for carbonates to be approximately 5000 m 1 maheshwari et al 2013 liu and liu 2016 ghommem et al 2015 mahmoodi et al 2018 ratnakar et al 2013 maheshwari and balakotaiah 2013 others calculated this parameter from image analysis al khulaifi et al 2018 hao et al 2013 smith et al 2017 for indiana limestone tagavifar et al 2018 measured specific surface area by bet and reported av 3 4 x 106 m 1 while churcher et al 1991 using the same technique found av between 1 3 x 106 and 1 9 x 106 m 1 menke et al 2015 found av 5 1 x 106 m 1 by bet and av 8000 m 1 by micro ct measurements on the outcrop ketton carbonate they justify the difference between the measured and calculated values as being caused by the inclusions of the area due to microporosity which are not detected on micro ct technique besides surface roughness also may be responsible for the difference and is not fully resolved by micro ct in our work we use micro ct images 2 4 µm voxel to segment the pore system the specific surface area was calculated by dividing the total area of the segmented pores by the total volume of the 3d images this way of estimating av only considers the area of the pores that are visible in the micro ct image assuming that the flow occurs at the more accessible paths the bet specific surface area may not represent the real surface area in contact with the fluid overestimating it for silurian dolomite the calculated value was 18 000 m 1 smith et al 2017 using sem images estimated av between 8500 and 39 000 m 1 for dolomite arbuckle dolostone plugs from wellington field and for indiana limestone 65 000 m 1 these values are the default for simulations using silurian dolomite and indiana limestone plugs however to evaluate the effects of specific surface area some simulations were conducted using different values of av and in these particular cases av value is explicitly expressed 5 results many parameters changed in the simulations the methodology used to calculate the initial permeability field ks av β and the permeability values assigned to the phases high k medium k and low k in order to organize the different cases we named each one by the carbonate sample d for dolomite 3 and c for calcite 1 followed by the methodology used to generate the permeability field and a number cases simulated with methodologies p and s are listed in tables 4 and 5 respectively 5 1 dolomite 3 simulations methodologies p and s were used to estimate permeability fields in a mesh with about 106 cells the plug was segmented in 3 regions of different permeabilities segmentation 1 as already shown in fig 10 d however the pore system of this sample is composed of big and small pores besides regions with intermediate grayscale values corresponding to regions of different porosities we also generated a 4 phase segmentation denominated segmentation 2 and shown in fig 10 e to transcript as much of the plug heterogeneity to the mesh as possible the influence of segmentation on simulations was investigated by changing the relative amount of the phases in the segmentations 1 and 2 the low k phase percentage was decreased increasing the overall hydraulic conductivity of the meshes two new segmentations were generated segmentations 3 and 4 as shown in fig 11 table 6 shows the relative amount of each phase in the segmentations 5 1 1 methodology p fig 12 shows permeability evolution curves for cases using methodology p in the initial permeability field calculation the value of ks increases from dp6 to dp1 and a first analysis of fig 12 shows that this parameter changes the slope and shape of the permeability evolution curve with the increase of ks the wormhole formation process accelerates since the acid breakthrough occurs with less injected acid however the acid breakthrough occurred with almost the same volume injected in curves dp2 ks 1 10 4 m s 1 and dp1 1 10 3 m s 1 suggesting that there is a limit to the tendency observed besides this chart shows that ks is not the only critical factor to model the acidification process variation of this parameter alone is not sufficient to fit the simulated permeability evolution curve increasing ks from 2 10 5 to 1 10 4 m s 1 strongly changed the simulation results comparing cases dp6 av 18 000 m 1 and dp7 av 5000 m 1 we see similar tendency for av and ks increasing av results in earlier acid breakthrough and higher inclination of the permeability evolution curve fig 13 shows the experimental and simulated pore systems for selected cases except for case dp7 av 5000 m 1 all cases show a dominant wormhole in the same region observed experimentally except for case dp7 in all cases presented in fig 13 simulations predicted correctly the region experimentally observed for the main wormhole as well as its shape however the predicted secondary wormholes are longer than the ones observed experimentally the simulated permeability evolution curve for case dp4 ks 3 10 5 m s 1 av 18 000 m 1 is in reasonable agreement with the experiment fig 12 5 1 2 methodology s using dns the permeability of high k phase was calculated in the range 1000 to 4000 md for low k phase swanson equation estimated permeabilities between 0 22 and 1 md simulation with different segmentations and the impact of the permeability value assigned to the different phases are shown in fig 14 in fig 14 a the influence of the segmentation process is evaluated on 3 phase segmentations cases ds1 ds3 and ds5 used segmentation 1 while ds2 ds4 and ds6 used segmentation 3 simulations confirm the expected behavior since segmentation 3 has more of high k and less low k phases than segmentation 1 thus flow and reaction effects are better distributed inside the sample for simulations that use segmentation 3 resulting in lower wormhole formation velocity in fig 14 b we analyze the influence of the permeability assigned for each phase cases ds8 and ds9 show that increasing the permeability assigned to phase high k from 1000 to 2000 md resulted in small change in the permeability evolution curve nevertheless the acid breakthrough occurred at the same moment in both cases curves for cases ds9 and ds10 k assigned to phase low k 1 and 0 22 md respectivey indicate that the decrease in permeability of low k phase accelerated wormhole formation in cases ds4 and ds7 the reduction in k assigned to low k phase did not cause the same effect as observed in the two previous cases this may be explained by ks which reduced from 5 10 5 m s 1 in cases ds4 and ds7 to 1 10 5 m s 1 in cases ds9 and ds10 these three pairs of cases indicate that increasing the permeability difference from phases high k to low k increased wormhole formation velocity but this effect is affected by the reaction rate constant a higher difference between the assigned permeability values forces flow to occur mainly at the more permeable paths concentrating the dissolution effects and accelerating wormhole formation the pore system from some selected cases are presented in fig 15 case ds6 almost fit the permeability evolution curve fig 14 but the predicted wormhole was very different from the one observed in the experiment even using different values of ks and av a good match between experimental and simulated permeability evolution curves was not achieved possible explanations include the need of more than three phases in order to correctly capture porous media heterogeneity and phase high k permeability overestimation as indicated by simulated wormhole always appearing before what we observed experimentally we now discuss simulations using 4 phase segmentations permeability for phase medium k was estimated in 35 and 20 md for segmentations 2 and 4 respectively by using winland equation in case ds12 however we used segmentation 4 and k 35 md for medium k phase in order to analyze the segmentation influence in the permeability curve prediction fig 16 shows the simulated permeability curves using 4 phase segmentations and the corresponding extracted pore systems are presented in fig 17 fig 16 shows a better fit for cases using 4 phase segmentations cases ds12 and ds15 show the impact of the segmentation procedure increasing the medium k phase percentage resulted in lower wormhole formation velocity strongly affecting the acid breakthrough 5 7 and 7 5 pv for cases ds12 and ds15 respectively the increase in the permeability assigned to this phase cases ds14 and ds15 also resulted in lower wormhole formation velocity with the acid breakthrough after 6 0 and 7 5 pv respectively these results were expected since the increase in medium k phase decreasing low k phase has the same effect as assigning a higher permeability in medium k phase this results in an increase in the overall sample permeability with more available conductive paths the flow is better distributed in the sample reducing dissolution effects and delaying wormhole formation fig 17 shows that cases ds12 ds13 and ds15 correctly predicted the dominant wormhole position cases ds12 and ds13 fit reasonably well the experimental permeability evolution curve case ds15 however predicted many secondary wormholes but those were not observed in the experimental case these secondary wormholes growth affect the plug permeability resulting in a different permeability evolution curve from the experimental data 5 1 3 comparison between methodologies p and s as discussed before in dolomite 3 four wormholes connected themselves to become the dominant wormhole since these channels join near the inlet it should have happened quickly after the beginning of their formation fig 5 small secondary wormholes are present in all simulations however they are bigger than the ones observed and are spread in the inlet face of the plug fig 18 presents the simulated and experimental pore system after the reactive flow for cases dp4 ds12 and ds13 fig 18 confirms that both methodologies can predict the formation and position of wormholes especially the dominant ones the three cases from fig 18 used ks 3 10 5 m s 1 but while cases dp4 and ds12 used av 18 000 m 1 case ds13 used av 5000 m 1 fig 16 reveals a better fit for case ds13 than ds12 and a simulated pore system more similar to the experimental data fig 18 both values of av the one from the literature 5000 m 1 panga et al 2005 and our predicted good results depending on the methodology used to estimate the initial permeability field overall results using methodology s showed better results for dolomite 3 samples figs 19 and 20 present streamlines for acid concentration and uz respectively at several timesteps for cases dp4 ds12 and ds13 these images clarify the wormhole formation process the flow starts without preferential paths but after injection of only two pore volumes of reactive brine one can observe small wormholes growing streamlines for acid concentration and velocity give complementary information while streamlines for acid concentration show where acid reaches in concentrations high enough to dissolve the rock the streamlines for velocity reveal the magnitude of the flow in these regions fig 19 indicates high acid concentrations in all wormholes besides streamlines for velocity show that after 4 pv the flow is already focused in one region which becomes the dominant wormhole during the experiment literature reports ks 2 10 3 m s 1 for calcite dissolution with hcl panga et al 2005 for dolomite it should be 1 3 to 1 60 of the calcite value edery et al 2011 6 6 10 4 k s d o l h c l 3 3 10 5 our value ks 3 10 5 m s 1 was the best fit for dolomite 3 97 dolomite acidification in agreement with the approximate range reported by literature 5 2 calcite 1 simulations 5 2 1 methodology p several cases were simulated using ks in the range 1 0 10 8 to 1 0 10 6 m s 1 and av between 5000 and 520 000 m 1 and results are presented in fig 21 fig 21 a shows the same pattern observed in dolomite 3 increasing ks anticipates the acid breakthrough increasing av also increased the curve inclination as shown in fig 21 b however this effect is not as strong as it was observed by changing ks which has a higher influence in the acid breakthrough streamlines were calculated for initial pore system and the pore system after the injection of 38 pv of reactive brine as shown in fig 22 fig 22 shows that for low values of ks no wormhole was generated after 38 pv of reactive brine injected a small specific surface area leads to low dissolution and almost no difference in the pore system while a significant value in this parameter increases dissolution kinetics and wormhole formation however even for high values of av wormhole formation is not completed with ks 1 10 8 m s 1 confirming that ks has a stronger impact in wormhole formation than av 5 2 2 methodology s the micp curves from fig 3 were used as input for swanson equation to estimate the permeability value for phase low k we obtained k 1 md the permeability of high k phase 24 md was obtained by winland equation using the mean porosity of this phase as input two additional cases were simulated using 0 24 and 2 md as the permeability value in low k phase to test the influence of the less conductive phase in the general flow simulated permeability evolution curves are shown in fig 23 cases from fig 23 show that increasing permeability assigned to phase low k increases wormhole formation velocity as well as the slopes of the permeability curves cases cs1 to cs3 cs4 to cs6 and cs7 to cs9 show that increasing ks from 5 10 8 to 5 10 7 m s 1 results in higher slopes in the permeability curves fig 24 shows the extracted pore systems the pore systems from cases that used ks 5 10 8 are similar after pv 38 thus only cs1 is reported wormhole paths of cases with the same ks are all very similar fig 24 the simulated wormholes from cases cs3 cs6 and cs9 have small differences such as the number and size of secondary wormholes besides there was no wormhole formation in the cases that used ks 5 10 8 m s 1 cs1 cs4 and cs7 after pv 38 5 2 3 comparison between methodologies p and s although a wide range of values for parameters ks and av were used in the simulations we did not achieve a proper fit between experimental and simulated evolution of permeability in both methodologies when using values very low for both parameters wormhole formation did not occur additionally different combinations of ks and av always led to the creation of wormholes before what was experimentally observed in all simulations permeability increased faster than experimentally observed according to smith et al 2017 the parameter β should be adjusted in their work they used the following power law equation to describe k variation with ϵ 27 k t k o ϵ t ϵ o n they adjusted the empirical parameter n in range 1 6 to 8 to fit the porosity permeability evolution in their simulations and comparing eqs 14 and 27 n 2β 1 the range of n used by smith et al is equivalent to 0 3 β 3 5 simulations were repeated using β 0 5 and a good match between the experimental and simulated permeability evolution was achieved as presented in fig 25 the extracted pore systems at pv 45 for the best fit cases are shown in fig 26 from fig 25 the curves cp10 cs12 and cs15 correctly predict the acid breakthrough occurring around pv 36 but the permeabilities predicted by these cases before this point are higher than the ones observed in the experiments curve cs14 on the other hand fits better the permeability curve until pv 36 but does not predict the abrupt permeability increase from this point fig 26 shows that the wormhole is not completed in case cs14 at pv 45 in all cases many secondary wormholes are predicted it is in agreement with the experiments although the predicted ones are not in the exact positions of those from the experiments the wormhole path predicted by all cases have a similar shape but they are in a different position from what we observed in the experiments as discussed before fig 7 after the acid breakthrough a rapid increase in permeability was observed in calcite 1 experiment which was not reproduced by the simulations in order to investigate this streamlines were calculated for cases cp10 cs12 and cs15 they are presented in fig 27 colored by acid concentration and if fig 28 colored by fluid speed figs 27 and 28 show that the fluid quickly creates preferential paths that concentrate fluid flow and that with time one of these channels becomes more important and starts to drain the fluid stopping the growth of other channels in the last time frame shown the fluid flow appears to occur only at the channel besides the evolution of acid concentration and fluid flow did not have significant differences between methodologies in similar timesteps after pv 32 figs 27 and 28 show that most of the flow occurs inside the wormhole path with the acid breakthrough at 36 pv the dissolution may rapidly widen the channel especially at the tighter pore throats this might be the cause for the quick permeability increase observed experimentally this behavior was not observed in the experiment with dolomite 3 more precise porosity and permeability fields may be required to capture this behavior with the simulations fig 29 shows the simulated and experimental pore systems for case cs15 methodology s ks 1 10 7 m s 1 av 65 000 m 1 β 0 5 k 24 and 0 24 md in phases high k and low k respectively cases cp10 and cs12 results are similar to case cs15 and therefore they are not reported although a good fit of the permeability evolution was achieved for calcite 1 as shown in fig 25 fig 29 shows that the simulations could not predict the channel path reasonably this can be related to the presence of feldkamp and beam hardening artifact effects in the micro ct image from the plug before the experiment even though a software treatment was applied in the image it did not entirely remove these artifacts especially in the first slices of the sample which coincide with the inlet of the plug since the porosity and permeability fields were calculated based on the grayscale range the shadows coming from the feldkamp effect were interpreted as regions of higher porosity and permeability and the simulated channels were inevitably predicted in these regions fig 30 shows the first slice from the micro ct image of the plug calcite 1 using the sample range 2977 to 13494 and a second range 10354 to 13494 in which feldkamp and beam hardening effects are more easily identified 5 3 microscopic permeability evolution the evolution permeability curves like figs 12 and 26 show the macroscopic permeability evolution with time however to see how k evolves in each mesh s cell during simulation we need to look into the permeability field since higher changes in permeability occur at the wormhole path we extracted planes that longitudinally cut the wormhole paths for cases dp4 and cs15 fig 31 exemplifies the extraction of a plane for simulation case cs15 fig 32 shows the permeability field in the extracted planes at different simulation times for cases dp4 and cs15 for case dp4 dolomite 3 methodology p fig 32 shows the existence a region of higher permeability values at pv 0 as expected the wormhole path developed in this region the increase in permeability however occurs locally and affects only the regions near the wormhole path the same is observed in case cs15 calcite 1 methodology s before wormhole has developed the permeability of its future path is not affected by the flow unless near the wormhole tip this is explained by figs 19 and 27 that showed the acid distribution inside the sample with time the acid concentration decreases rapidly outside the wormhole path due to the high reactivity between the reactive brines and the carbonates studied here thus outside the wormhole path no significant change in permeability is expected fig 32 gives a last hint about the wormhole development in case cs15 the yellow arrow at pv 0 indicate a region near the base of the plug with higher permeability and the wormhole develops exactly at this point although the wormhole predicted in case cs15 was in a different region from that observed experimentally this figure confirms the wormhole growth through the initially more permeable regions of the plug and indicates the importance of correctly characterizing sample heterogeneities for reactive flow simulations especially for highly heterogeneous samples such as carbonates 6 conclusions the main contribution of this work was to capture the impact of rock heterogeneity on dissolution by using micro ct images to obtain pore space geometry and accounting for these details in the simulation mesh the micro ct images were also used as input to calculate the porosity and permeability fields to be used in simulations experiments showed very low silurian dolomite reactivity with co2 a test between a dolostone plug silurian dolomite outcrop and hcl was carried out simulations of this test showed that increasing the parameters ks and av accelerates the wormholing process and affects the path of the formed wormhole although the simulated wormholes grew in the same plug region for both methodologies its shape depends on the ks and av values a proper fitting of experimental k versus pv injected curve was achieved both methodologies used to generate the initial permeability field successfully reproduced the experimental pore system the segmentation process used to generate the initial permeability field influences the simulated permeability curve during the acidification but this influence depends on ks as the difference between ks in the phases high k and low k increases the wormhole formation velocity also increased for the indiana limestone sample simulations showed the same influence of ks and av observed in silurian dolomite simulations both methodologies using β 0 5 were able to reproduce the k versus pv injected curve using ks 1 10 7 m s 1 and av 65 000 m 1 predicting formation of a ramified wormhole as confirmed by experiments a rapid change in permeability was experimentally observed at pv 36 but was not reproduced in the simulations streamlines showed that at pv 32 most of the flow occurs at the wormhole path increased acid availability may cause a rapid dissolution of the last pore throats on the wormhole path increasing rapidly the macroscopic permeability until pv 36 when the acid breakthrough takes place and wormhole formation is complete this effect was not observed in experiments with the silurian dolomite plug and more precise porosity and permeability fields might be required to correctly capture this behavior with the simulations feldkamp and beam hardening effects in micro ct image caused deformations in the porosity and permeability fields and simulations did not predict the correct region where the channel should be formed this shows the critical importance of micro ct image quality in this kind of simulation we plan to improve these simulations in future works finally a close examination of the permeability fields during simulation confirmed that the wormhole growths in the initially more permeable regions the increase in permeability was concentrated near the wormhole path and simulations showed a rapid decrease in acid concentration outside the channel credit authorship contribution statement leandro de paulo ferreira methodology software formal analysis investigation writing original draft rodrigo surmas conceptualization software writing review editing funding acquisition sandra nelis tonietto resources writing review editing mônica antunes pereira da silva supervision writing review editing ricardo pires peçanha supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we gratefully acknowledge petrobras digital rock physics group as well as the petrophysics team from petrobras research center for the support l p f wishes to thank specially to maria aparecida do espírito santo for her inestimable help to rodolfo araujo victor for the discussion of results to jovani l favero for the help in openfoam to the tomography laboratory group for the images and support and to the fce group for the flow experiments the original and resampled micro ct images as well as the segmentations and porosity files have been made available for download at the digital rocks portal doi 10 17612 v09y aw80 ferreira 2020 supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103564 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
499,co2 reinjection in petroleum reservoirs brings advantages in oil production but may cause dissolution in carbonate reservoirs two scale continuum models have been successfully used to simulate acidification however the use of realistic porosity and permeability fields in mesh simulations is still a challenge in such a way that uniform and normal distributions have been used to generate these fields in the past the main objective of this work was to transcript the plugs heterogeneity from the micro ct images to simulation the porosity field was calculated directly from micro ct images and two methodologies are proposed to calculate the permeability field a reactive two scale continuum solver was implemented in openfoam and used to simulate reactive flow in two carbonate samples with different intrinsic reaction rates calcite and dolomite the experimental permeability evolution curves as well as wormholes shapes and paths are reproduced in the simulations we observed a critical influence of specific surface area reaction rate constant and initial permeability field for the simulations of acidification processes keywords digital rock physics carbonates reactive flow modeling two scale continuum model openfoam 1 introduction carbon dioxide is considered the most crucial gas contributor to the greenhouse effect its concentration in the atmosphere is increasing mainly due to fuel burning abedini and torabi 2014 hasanvand et al 2013 co2 is present in some petroleum reservoirs as in brazilian pre salt carbonates and is produced along with oil exploitation some alternatives to avoid its emission to the atmosphere include geologic storage reinjection and water alternating gas injection wag han and kim 2018 harp et al 2018 wang et al 2018 myshakin et al 2018 sanguinito et al 2018 bielicki et al 2018 yang et al 2018 shevalier et al 2013 when co2 dissolves in reservoir fluids carbonic acid h2co3 is generated which decreases the ph of the solution and possibly causing the dissolution of some constituent rock minerals it can cause severe damage to the reservoir such as the collapse of injection wells klokov et al 2018 peng et al 2015 yasuda et al 2013 fitts and peters 2013 adebayo et al 2015 carbonate dissolution depends on temperature pressure and salinity renforth and henderson 2017 farquhar et al 2015 speciation of co2 and dissolution equations for calcite and dolomite are given by yoo et al 2018 sainz garcia et al 2017 al shalabi et al 2014 plummer et al 1978 baritantonaki et al 2017 peng et al 2016 1 c o 2 h 2 o h 2 c o 3 h h c o 3 2 h c a c o 3 c a 2 h c o 3 3 2 h c a m g c o 3 2 c a 2 m g 2 2 h c o 3 many studies were carried out to understand the role of co2 in modifying carbonates peng et al 2018 pearce and dawson 2018 le gallo and de dios 2018 claes et al 2018 lebedev et al 2017 deng and peters 2018 studied the effects of co2 on fracture transmissibility using 2d models to characterize the flow of co2 in fractured carbonates kim et al 2018 investigated geomechanical changes in calcitic reservoirs due to co2 injection bickle et al 2017 focused on the reactivity of reservoir rocks by sampling fluids from sites where co2 was injected for over six months guo et al 2018 observed significant changes in hydraulic permeability even for rocks with small carbonate content among the different techniques used to investigate experimental rock alterations caused by dissolution singh et al 2018 numeric simulation is an essential tool to help understand the effects of co2 injection in reservoirs there are many software packages available for this purpose coores eclipse gem phreeqc toughreact openfoam and in house solutions lamy chappuis et al 2018 yasuda et al 2018 saxena et al 2018 tambach et al 2017 snippe et al 2017 rostami et al 2019 jiang 2011 xu et al 2006 used toughreact to study the flow in a fractured 1d medium andre et al 2007 used the same software to simulate the 1d radial flow from the borehole to the reservoir comparing the effects of injecting saturated brine with those caused by the injection of supercritical co2 ahmad et al 2016 chose multiphysics as the computational tool to simulate the injection of co2 saturated brine in a geological reservoir the model was based on the navier stokes darcy equation also known as the brinkman equation to characterize flow and the lasaga equation lasaga et al 1994 for reaction kinetics menke et al 2015 carried out flow experiments and pore scale simulations phenomena that occur at the pore level using openfoam to evaluate the effects of carbonate heterogeneity on reaction rates they point out that mineral dissolution decreases the tortuosity of the flow path in another study using the same models menke et al 2016 investigated the flow of co2 rich brines in highly heterogeneous carbonates they observed a strong influence of the initial porous system configuration in the shape of the wormhole created during reactive flow since flow path prefers high permeability regions dissolution will be concentrated in these sections of the rock enhancing pore connection and forming a preferential flow path the authors suggested that the formation of a preferential path occurs instead of wormholing pereira nunes et al 2016a b studied the effects of initial physical heterogeneity on carbonate dissolution by co2 saturated brines using a pore scale model they observed lower reaction rates in porous media compared to batch reactor values and concluded that reaction may be surface controlled inside pores and transport controlled at plug scale qajar et al 2013 studied the effects of fines migration and chemical dissolution in carbonates by micro ct in another work qajar and arns 2017 investigated the evolution of permeability with pore throat diameter in carbonate reactive flooding experiments and showed that the impact of reactive flow concentrates in the larger pores increasing the connectivity of macropores izgec et al 2010 conducted acidification experiments of vuggy carbonates using hcl their experiments showed that wormhole formation is faster in vuggy carbonates to understand vug effects on the non reactive flow they implemented a solver based on the brinkman equation and demonstrated that flow connects the vugs which acts as a highly permeable path besides izgec et al 2010 and menke et al 2015 2016 many authors investigated the effects of carbonate heterogeneities on the flow and wormhole formation al khulaifi et al 2018 xiao et al 2017 sun et al 2017 menke et al 2018 and concluded that heterogeneity is a crucial factor to describe correctly flow effects on carbonates menke et al 2018 cohen et al 2008 kalia and balakotaiah 2009 maheshwari et al 2013 smith et al 2013 two scale continuum models have been used to simulate wormhole formation predicting qualitative behavior in wormholing at darcy scale and requiring moderate computational effort this kind of model uses information from pore scale to complement the equations in darcy scale besides treating boundaries between pores and solids in a continuum way thus avoiding problems of high gradients in interfaces panga et al 2005 developed a 2d two scale continuum model to study carbonate acidification using hcl their model describes transport and reaction and couples darcy scale variables such as darcy velocity and pressure to pore scale properties by relationships that updates permeability pore radius and other properties based on porosity changes in their work they used fixed porosity and uniform distribution of permeability on the mesh liu and liu 2016 modified darcy law by navier stokes darcy equation in the continuum model developed by panga et al 2005 using a mesh with constant initial porosity and permeability to simulate carbonate acidification with viscoelastic surfactant based self diverting ves acids the typical approach to transcript the intricate pore system to the mesh is to generate porosity fields based on a constant value in which a perturbation random normal and others is applied panga et al 2005 liu and liu 2016 liu et al 2017 ghommem et al 2015 mahmoodi et al 2018 roded et al 2018 and the use of simplified 2d models deng and peters 2018 izgec et al 2010 roded et al 2018 chen et al 2018 to capture rock heterogeneities hao et al 2013 smith et al 2017 used a 3d continuum reactive transport model to simulate co2 injection in carbonate plugs they compared the results with reactive flow experiments in which a vuggy limestone and a marly dolostone were flooded by co2 saturated brines at different pressures simulations were conducted with non isothermal unsaturated saturated flow and transport nuft algorithm the model used darcy s law to handle fluid transport and mass balance to model multi component transport scanning electron microscopy sem images were used to estimate relative amounts of pores calcite and dolomite in different samples the results were correlated to grayscale ranges in micro ct images to determine porosity at each point of the mesh to evaluate the permeability field the authors classified the pore system in three regions of permeability based on 2d segmented sem images each region had a constant value of permeability the significant contribution of their study was to simulate reactive flow in a mesh that captured the heterogeneities of the pore system at the micro ct image resolution in general panga s two scale continuum model has been successfully used in wormholing and reactive flow modeling the main difficulty using it relies on creating a 3d mesh that faithfully represents carbonate porous structures as this type of rock may have a very complex porous system from micropores to vugs darcy equation may not accurately characterize flow in the larger pores hosseinzadeh and bazargan 2018 hao et al 2013 smith et al 2017 estimated porosity and permeability fields to be used as inputs to simulations instead of using constant values the sample was segmented in three regions and the permeability values of these regions were geometrically estimated based on micro ct and 2d sem images several authors adopted simplified 2d models or normal and linear distributions of porosity and permeability in the mesh hao et al 2013 smith et al 2017 estimated these fields by using 2d sem images and darcy s law in simulations which might not correctly characterize flow in vuggy carbonates hosseinzadeh and bazargan 2018 this demonstrates that there is a gap in the literature about the methodology for a realistic estimation of porosity and permeability fields for flow simulations the main objective of our work was to use micro ct images of carbonate plugs to estimate more realistic porosity and permeability fields for each voxel based on direct numerical simulation dns as well as characterization and flow experiments these fields were fed to a two scale continuum solver that uses navier stokes darcy equation implemented in openfoam to conduct 3d simulations of reactive flow on a vuggy carbonate silurian dolomite and a non vuggy homogeneous carbonate indiana limestone this model is used to investigate the influence of the methodology of permeability field estimation among other essential properties on wormholing process 2 mathematical modeling our solver is based on the two scale continuum model presented by panga et al 2005 it uses the navier stokes darcy equation instead of darcy equation for a better characterization of the flow in the vugs as follows 4 ρ u t ρ u u ϵ ϵ p μ 2 u ϵ μ k u 5 ϵ t u 0 6 ϵ c f l t u c f l ϵ d e c f l a v r c s 7 u u x u y u z where ρ is fluid density kg m 3 u velocity vector m s 1 t time s ϵ porosity p pressure kg m 1 s 2 μ viscosity kg m 1 s 1 k permeability m2 cfl the cup mixing concentration of acid in solution mol m 3 d e effective dispersion tensor m2 s 1 av specific surface area per volume m 1 and r cs the reaction kinetics the brinkman eq 4 for fluid flow was developed in 1947 to characterize porous media flow and free flow in vugs and big pores it is valid for a homogeneous porous media incompressible fluid and considering boussinesq approximation of the momentum equation basirat et al 2015 from left to right the two first terms represent the local and convective accelerations respectively and the three right hand terms side represent pressure gradient viscous effects and the darcy term respectively this equation has the advantage of not requiring a full pore boundary description in a simulation cell representing the porous media pressure gradient and darcy terms are the only significant ones so that eq 4 becomes darcy law inside pore cells a high permeability value is assigned making the darcy term negligible and turning eq 4 into the navier stokes equation the first term of the continuity eq 5 characterizes volume changes caused by dissolution eq 6 is responsible for acid transport its first term refers to accumulation the second term calculates convection the third term is responsible for dispersion and the fourth one is related to acid consumption by the reaction panga et al 2005 assumed that r cs can be calculated as follows 8 r c s k c c f l c s where kc is the local mass transfer coefficient m s 1 and cs the acid concentration at the solid fluid interface mol m 3 since they used a porosity distribution between 5 and 35 at least some rock was available for reaction in all cells of the mesh since our work proposes to simulate reactive flow in vuggy carbonates and for the vug cells there is no available rock for reaction we cannot use eq 8 a new term was added in order to consider reaction on vug cells as follows 9 r c s k c c f l c s r f 10 r f 1 ϵ 1 ϵ 10 20 where rf is the reaction factor the constant 10 20 was inserted in the equation to avoid a division by zero in the vugs cells where ϵ 1 resulting in rf 0 when ϵ 1 rf 1 and reaction is accounted for first order reaction kinetics the reaction rate may be calculated as follows 11 r c s k s c s r f where ks is the reaction rate constant at the surface m s 1 using eq 11 into 9 we get 12 c s c f l 1 k s k c at kinetic regime cs cfl while at mass transfer regime cs 0 the parameter ks is specific for each acid while kc depends on the pore geometry reaction rate and local flow regime the equation below takes into account both regimes describing porosity evolution caused by reaction 13 ϵ t r c s a v α ρ s where α is the dissolving power of the acid defined as the mass of dissolved rock per mol of reacted acid kg mol 1 and ρs the density of the rock kg m 3 eqs 4 to 6 and 9 to 13 describe the macroscopic variables and form the darcy scale model equations from pore scale model account for local phenomena which occur at the scale of pores panga et al 2005 divided them into three groups structure property relations that update permeability pore radius and specific surface area due to structure alterations dissolution mass transfer coefficient to quantify acid transport from the fluid phase to the fluid solid interface and dispersion coefficients semi empiric equations are used to update structure properties as follows 14 k t k o ϵ t ϵ o ϵ t 1 ϵ o ϵ o 1 ϵ t 2 β 15 r p t r p o k t ϵ o k o ϵ t 16 a v t a v o ϵ t r p o ϵ o r p t where rp is the mean radius of the pores m β is an adjusting parameter and superscripts t and o represent the variable at the new time step and at the old time step respectively sherwood number sh is used to estimate kc as follows balakotaiah and west 2002 17 sh 2 k c r p d m sh b r e p 1 2 sc 1 3 18 r e p 2 ρ u r p μ 19 sc μ ρ d m where sh is asymptotic sherwood number for the pore and according to balakotaiah and west 2002 assumes 3 66 for spherical pores b is a constant b 0 7 rep reynolds number in the pore dm molecular diffusivity of the acid m2 s 1 and sc schmidt number defined as a ratio between the momentum and mass diffusivities in the fluid for homogeneous and isotropic porous media dispersion tensor is a sum of two terms the longitudinal and transverse coefficients random walk models and analogy with packed beds are used to calculate these two terms as follows 20 d e d e x d e t 21 d x d e x d m α 0 s λ x p e p 22 d t d e t d m α 0 s λ t p e p 23 p e p u d h ϵ d m where dex is the longitudinal term of dispersion tensor det the transverse component α 0s λx and λt are constants related to the porous media structure dm the molecular diffusivity of acid m2 s 1 dh the hydraulic diameter of the pore m and pep péclet number on the pore for a pack of spheres λx 0 5 and λt 0 1 the system was considered isothermal and incompressible the boundary conditions were based on the experiments constant flow of brine at the inlet constant pressure at the outlet and impermeable boundaries at the sides of the plug as shown in fig 1 3 laboratory experiments we use the experimental permeability evolution and final pore system to validate the simulations besides simulations also require plug dimensions acid concentrations and flow rates used in the experiments four outcrop rock samples provided by kocurek 2018 3 83 cm diameter plugs were used in this work three of them dolomite 1 dolomite 2 and dolomite 3 correspond to silurian dolostone 97 9 of dolomite from illinois usa and one calcite 1 corresponds to a mississippian limestone 99 of calcite from indiana usa these two carbonate types are also known as silurian dolomite and indiana limestone respectively one sample of each outcrop was submitted to a mercury injection capillary pressure test micp using a mercury porosimeter autopore iv 9500 micromeritics the experimental apparatus used in the flood experiments is sketched in fig 2 all experiments were carried out at constant temperature reactive flow experiments consist of the following steps 1 saturation of the plug in a brine with typical composition of reservoir formation water 2 plug confinement at the holder confining pressure 2 758 107 pa and back pressure valve 2 069 107 pa 3 flow at a constant rate see table 1 of 40 pore volumes pv of saturation brine to stabilize the system 4 flow at a constant rate see table 1 of reactive brine 9 pv to 98 pv depending on the test pressure drop was registered between plug inlet and outlet using three transducers yokogawatm the co2 reactive brine preparations consisted of injecting the exact amounts of co2 and injection brine table 2 in a hastelloy floating piston accumulator vinci 1 l 6 895 107 pa 150 c increasing the system pressure to the final value and agitating it for one day before using brine containing hcl was simpler to prepare hcl was mixed with injection brine at the accumulator and pressure was increased to 2 069 107 pa the value of cfl for the experiments with co2 was calculated by the amount of gas and brine injected in the hastelloy accumulator while hcl final concentration was measured by titration with naoh table 1 presents experimental parameters and the composition of each brine the flow velocity at the inlet u z i n l e t is calculated dividing the volumetric flow rate q by the sectional cylinder area microtomography images were acquired in an x ray scanner phoenix vtomex 140 kv 250 ma and resolution 40 µm voxel the plugs were analyzed before and after each test in order to evaluate changes in the pore system at petrobras research center cenpes the capillary pressure curves and the pore throat size distribution for the two outcrops are presented in fig 3 in indiana limestone microporosity pore radius 0 5 µm connects 39 of total porosity mesoporosity pore radius between 0 5 and 5 µm and macroporosity pore radius 5 µm connect 18 and 43 respectively for silurian dolomite microporosity mesoporosity and macroporosity are responsible for connecting 53 33 and 14 of total porosity respectively fig 3 b shows that indiana limestone has two significant peaks for pore throat radius at 0 33 and 5 µm silurian dolomite has a wider distribution of pore throats but the two more significant peaks are 0 07 and 1 µm both outcrops have a significant part of the pore throats in the microporosity region which is responsible for connecting the big pores in these samples silurian dolomite samples showed almost no reaction with co2 dolomite 1 even after the injection of 98 pv of reactive brine had its permeability increased from 35 to 38 md in an attempt to increase reactivity the plug dolomite 2 was submitted to a higher co2 concentration and increased injection rate but these changes had little effect on the plug permeability which increased from 17 to 21 md micro ct images did not show alteration appreciable in the pore system for both plugs therefore these two plugs were not used in simulations dolomite 3 was submitted to a reactive flow using hcl and a variation in permeability was observed from 19 to over 2500 md with less than 10 pv of injected brine from the micro ct image acquired after the acidification the pore system was segmented and filtered to show only the wormholes as exemplified in fig 4 in this image as well as in all other figures of this work the flow direction is lined up with the positive z axis inlet is on the base fig 4 shows a dominant wormhole in red besides small secondary wormholes a detailed view of the secondary wormholes is presented in fig 5 which reveals the presence of two small secondary wormholes pointed out by the yellow arrows and also shows that early in the flow experiment four wormholes indicated by the white arrows started to grow they ended up connecting to become a dominant wormhole permeability of calcite 1 increased from 10 to over 2200 md during reactive flow the same procedure used in dolomite 3 was applied in the micro ct image of calcite 1 in order to show the wormholes generated as can be seen in fig 6 initially more than one ramified wormhole is formed but then the secondary ones stop growing as long as the main wormhole increasingly focused the flow the permeability evolution curves for the flooding experiments in dolomite 3 and calcite 1 are presented in fig 7 this figure shows a rapid increase in permeability at the acid breakthrough 36 pore volumes injected for the experiment with the plug calcite 1 and co2 rich brine 4 numerical methods simulation mesh was generated from micro ct images of the plugs before flow experiments preserving the pore system structures each original micro ct image has a resolution of 40 µm voxel and dimensions 1 300x1 300x1 500 voxels a volume too big for the solver to handle they were resampled to 400 µm voxel using the lanczos resampling kernel clouard 2018 which assures excellent results despite being very time consuming the final dimension of the resampled images was about 1003 voxels reactivecenpesmesh transforms each voxel from a segmented micro ct image in mesh cells since micro ct voxels are hexahedral and orthogonal the generated mesh is also orthogonal which is simpler to solve numerically reactivecenpesmesh requires the porosity and permeability values for each cell of the mesh 4 1 initial porosity distribution the porosity estimation method was similar to that used by hao et al 2013 smith et al 2017 since their sample was not pure they correlated grayscale range with porosity calculated using sem images silurian dolomite and indiana limestone are composed of approximately 97 of dolomite and 99 calcite respectively we considered both outcrops pure and thus the grayscale range from micro ct images is assumed to be directly proportional to the local porosity micro ct resampled images were used to calculate plug s porosity distribution according to the following steps 1 segmentation of pores and assignment of porosity 100 to the corresponding grayscale threshold value gspore 2 segmentation of solid and assignment of porosity bp background porosity to the corresponding grayscale threshold value gssolid arns et al 2019 applied the background porosity concept to match simulated electrical properties to experimental data if only solid is segmented bp 0 but since 38 and 53 of the total porosity in indiana limestone and silurian dolomite are connected by pore throats in the region of microporosity it is important to calculate the amount of porosity at gssolid following the procedure used by lin et al 2016 in which micro ct images are acquired from dry and saturated samples we obtained the total porosity fields for samples dolomite 4 and calcite 2 plugs dolomite 3 and calcite 1 could not be used because of a laboratory restriction with gssolid and the grayscale ranges for samples dolomite 3 and calcite 1 we corrected gssolid for samples dolomite 4 and calcite 2 and segmented the solid phases we used these segmentations and the total porosity fields to calculate the values of bp resulting in 5 1 and 6 for silurian dolomite and indiana limestone respectively we adopter bp 5 for both outcrops 3 porosity calculation directly in the micro ct voxels according to the following equation 24 ϵ v o x e l 100 b p g s v o x e l g s s o l i d g s p o r e g s s o l i d b p porosity calculated using this methodology was compared to experimental results for dolomite 3 ϵ lab 11 8 and ϵ calc 12 01 while for calcite 1 ϵ lab 14 9 and ϵ calc 15 3 calculated porosity for samples calcite 1 and dolomite 3 are shown in fig 8 4 2 initial permeability distribution for simplicity we considered isotropic samples kxx kyy kzz and k i j i j 0 two methodologies were used to calculate the initial permeability distribution based on winland kolodzie 1980 and swanson swanson 1981 correlations as well as dns during simulations permeability update is computed by eq 14 as discussed before in the pore zones the brinkman eq 4 requires very high permeability values to characterize the flow correctly we set k 1 1010 md in these regions regardless of the methodology adopted 4 2 1 methodology p the porosity values in each voxel are used to estimate the initial permeability field by the empirical winland equation 25 log r 35 0 732 0 588 log k 0 864 log ϵ where r 35 is the pore aperture that corresponds to 35 of mercury saturation calculated by using experimental porosity and permeability values this methodology has the advantage of capturing porosity variation in the sample which in turn is used to calculate the permeability field fig 9 shows the initial permeability fields calculated for samples calcite 1 and dolomite 3 4 2 2 methodology s the methodology consists in segmenting a micro ct image in 3 or 4 regions of similar permeabilities the permeability of each region is calculated with dns and correlations the segmentation process in three and four phases assumes that regions of similar permeabilities have similar grayscale values as follows 3 phase segmentation pores dark grayscale more conductive high k phase and light grayscale less conductive low k phase 4 phase segmentation pores dark grayscale more conductive high k phase medium grayscale intermediate conductive medium k phase and light grayscale less conductive low k phase both samples were segmented in 3 phases however silurian dolomite is more heterogeneous and was also segmented in 4 phases three subsamples were cut from a region visually more porous of a silurian dolomite plug these subsamples were imaged at 2 4 µm voxel their pore systems were segmented and had connectivity confirmed next they were used in dns to estimate k one sample was obtained from a region with no visible porosity and imaged at 0 5 µm voxel however its pore system was not connected and no direct numerical simulation was possible for this region an in house lattice boltzmann lbm solver that has stokes equation implemented was used to execute the dns for more details about lbm and permeability simulation see andra et al 2013 from a plug of indiana limestone two samples were obtained and imaged at resolutions of 4 µm voxel 2 4 µm voxel and 0 5 µm voxel however even at the higher resolution its pore system was not connected thus it was not possible to estimate permeability by dns for this sample in regions where dns could not be performed permeability was estimated by winland and swanson correlations the swanson correlation was used to calculate k in the low k phases it uses the maximum ratio of hg saturation sb by hg capillary pressure pc as a parameter to estimate carbonate permeability according to the following equation 26 k 290 s b p c a 1 901 we used the mean porosity value calculated for the low k region as input in swanson equation to estimate the permeability in both samples in the medium k region winland eq 25 was applied to determine k in the high k phase k was estimated by dns for silurian dolomite and by winland equation for indiana limestone fig 10 shows segmentation images from samples calcite 1 and dolomite 3 4 3 simulation parameters besides the experimental parameters listed in table 1 general parameters used in the simulations are presented in table 3 many authors considered the specific surface area for carbonates to be approximately 5000 m 1 maheshwari et al 2013 liu and liu 2016 ghommem et al 2015 mahmoodi et al 2018 ratnakar et al 2013 maheshwari and balakotaiah 2013 others calculated this parameter from image analysis al khulaifi et al 2018 hao et al 2013 smith et al 2017 for indiana limestone tagavifar et al 2018 measured specific surface area by bet and reported av 3 4 x 106 m 1 while churcher et al 1991 using the same technique found av between 1 3 x 106 and 1 9 x 106 m 1 menke et al 2015 found av 5 1 x 106 m 1 by bet and av 8000 m 1 by micro ct measurements on the outcrop ketton carbonate they justify the difference between the measured and calculated values as being caused by the inclusions of the area due to microporosity which are not detected on micro ct technique besides surface roughness also may be responsible for the difference and is not fully resolved by micro ct in our work we use micro ct images 2 4 µm voxel to segment the pore system the specific surface area was calculated by dividing the total area of the segmented pores by the total volume of the 3d images this way of estimating av only considers the area of the pores that are visible in the micro ct image assuming that the flow occurs at the more accessible paths the bet specific surface area may not represent the real surface area in contact with the fluid overestimating it for silurian dolomite the calculated value was 18 000 m 1 smith et al 2017 using sem images estimated av between 8500 and 39 000 m 1 for dolomite arbuckle dolostone plugs from wellington field and for indiana limestone 65 000 m 1 these values are the default for simulations using silurian dolomite and indiana limestone plugs however to evaluate the effects of specific surface area some simulations were conducted using different values of av and in these particular cases av value is explicitly expressed 5 results many parameters changed in the simulations the methodology used to calculate the initial permeability field ks av β and the permeability values assigned to the phases high k medium k and low k in order to organize the different cases we named each one by the carbonate sample d for dolomite 3 and c for calcite 1 followed by the methodology used to generate the permeability field and a number cases simulated with methodologies p and s are listed in tables 4 and 5 respectively 5 1 dolomite 3 simulations methodologies p and s were used to estimate permeability fields in a mesh with about 106 cells the plug was segmented in 3 regions of different permeabilities segmentation 1 as already shown in fig 10 d however the pore system of this sample is composed of big and small pores besides regions with intermediate grayscale values corresponding to regions of different porosities we also generated a 4 phase segmentation denominated segmentation 2 and shown in fig 10 e to transcript as much of the plug heterogeneity to the mesh as possible the influence of segmentation on simulations was investigated by changing the relative amount of the phases in the segmentations 1 and 2 the low k phase percentage was decreased increasing the overall hydraulic conductivity of the meshes two new segmentations were generated segmentations 3 and 4 as shown in fig 11 table 6 shows the relative amount of each phase in the segmentations 5 1 1 methodology p fig 12 shows permeability evolution curves for cases using methodology p in the initial permeability field calculation the value of ks increases from dp6 to dp1 and a first analysis of fig 12 shows that this parameter changes the slope and shape of the permeability evolution curve with the increase of ks the wormhole formation process accelerates since the acid breakthrough occurs with less injected acid however the acid breakthrough occurred with almost the same volume injected in curves dp2 ks 1 10 4 m s 1 and dp1 1 10 3 m s 1 suggesting that there is a limit to the tendency observed besides this chart shows that ks is not the only critical factor to model the acidification process variation of this parameter alone is not sufficient to fit the simulated permeability evolution curve increasing ks from 2 10 5 to 1 10 4 m s 1 strongly changed the simulation results comparing cases dp6 av 18 000 m 1 and dp7 av 5000 m 1 we see similar tendency for av and ks increasing av results in earlier acid breakthrough and higher inclination of the permeability evolution curve fig 13 shows the experimental and simulated pore systems for selected cases except for case dp7 av 5000 m 1 all cases show a dominant wormhole in the same region observed experimentally except for case dp7 in all cases presented in fig 13 simulations predicted correctly the region experimentally observed for the main wormhole as well as its shape however the predicted secondary wormholes are longer than the ones observed experimentally the simulated permeability evolution curve for case dp4 ks 3 10 5 m s 1 av 18 000 m 1 is in reasonable agreement with the experiment fig 12 5 1 2 methodology s using dns the permeability of high k phase was calculated in the range 1000 to 4000 md for low k phase swanson equation estimated permeabilities between 0 22 and 1 md simulation with different segmentations and the impact of the permeability value assigned to the different phases are shown in fig 14 in fig 14 a the influence of the segmentation process is evaluated on 3 phase segmentations cases ds1 ds3 and ds5 used segmentation 1 while ds2 ds4 and ds6 used segmentation 3 simulations confirm the expected behavior since segmentation 3 has more of high k and less low k phases than segmentation 1 thus flow and reaction effects are better distributed inside the sample for simulations that use segmentation 3 resulting in lower wormhole formation velocity in fig 14 b we analyze the influence of the permeability assigned for each phase cases ds8 and ds9 show that increasing the permeability assigned to phase high k from 1000 to 2000 md resulted in small change in the permeability evolution curve nevertheless the acid breakthrough occurred at the same moment in both cases curves for cases ds9 and ds10 k assigned to phase low k 1 and 0 22 md respectivey indicate that the decrease in permeability of low k phase accelerated wormhole formation in cases ds4 and ds7 the reduction in k assigned to low k phase did not cause the same effect as observed in the two previous cases this may be explained by ks which reduced from 5 10 5 m s 1 in cases ds4 and ds7 to 1 10 5 m s 1 in cases ds9 and ds10 these three pairs of cases indicate that increasing the permeability difference from phases high k to low k increased wormhole formation velocity but this effect is affected by the reaction rate constant a higher difference between the assigned permeability values forces flow to occur mainly at the more permeable paths concentrating the dissolution effects and accelerating wormhole formation the pore system from some selected cases are presented in fig 15 case ds6 almost fit the permeability evolution curve fig 14 but the predicted wormhole was very different from the one observed in the experiment even using different values of ks and av a good match between experimental and simulated permeability evolution curves was not achieved possible explanations include the need of more than three phases in order to correctly capture porous media heterogeneity and phase high k permeability overestimation as indicated by simulated wormhole always appearing before what we observed experimentally we now discuss simulations using 4 phase segmentations permeability for phase medium k was estimated in 35 and 20 md for segmentations 2 and 4 respectively by using winland equation in case ds12 however we used segmentation 4 and k 35 md for medium k phase in order to analyze the segmentation influence in the permeability curve prediction fig 16 shows the simulated permeability curves using 4 phase segmentations and the corresponding extracted pore systems are presented in fig 17 fig 16 shows a better fit for cases using 4 phase segmentations cases ds12 and ds15 show the impact of the segmentation procedure increasing the medium k phase percentage resulted in lower wormhole formation velocity strongly affecting the acid breakthrough 5 7 and 7 5 pv for cases ds12 and ds15 respectively the increase in the permeability assigned to this phase cases ds14 and ds15 also resulted in lower wormhole formation velocity with the acid breakthrough after 6 0 and 7 5 pv respectively these results were expected since the increase in medium k phase decreasing low k phase has the same effect as assigning a higher permeability in medium k phase this results in an increase in the overall sample permeability with more available conductive paths the flow is better distributed in the sample reducing dissolution effects and delaying wormhole formation fig 17 shows that cases ds12 ds13 and ds15 correctly predicted the dominant wormhole position cases ds12 and ds13 fit reasonably well the experimental permeability evolution curve case ds15 however predicted many secondary wormholes but those were not observed in the experimental case these secondary wormholes growth affect the plug permeability resulting in a different permeability evolution curve from the experimental data 5 1 3 comparison between methodologies p and s as discussed before in dolomite 3 four wormholes connected themselves to become the dominant wormhole since these channels join near the inlet it should have happened quickly after the beginning of their formation fig 5 small secondary wormholes are present in all simulations however they are bigger than the ones observed and are spread in the inlet face of the plug fig 18 presents the simulated and experimental pore system after the reactive flow for cases dp4 ds12 and ds13 fig 18 confirms that both methodologies can predict the formation and position of wormholes especially the dominant ones the three cases from fig 18 used ks 3 10 5 m s 1 but while cases dp4 and ds12 used av 18 000 m 1 case ds13 used av 5000 m 1 fig 16 reveals a better fit for case ds13 than ds12 and a simulated pore system more similar to the experimental data fig 18 both values of av the one from the literature 5000 m 1 panga et al 2005 and our predicted good results depending on the methodology used to estimate the initial permeability field overall results using methodology s showed better results for dolomite 3 samples figs 19 and 20 present streamlines for acid concentration and uz respectively at several timesteps for cases dp4 ds12 and ds13 these images clarify the wormhole formation process the flow starts without preferential paths but after injection of only two pore volumes of reactive brine one can observe small wormholes growing streamlines for acid concentration and velocity give complementary information while streamlines for acid concentration show where acid reaches in concentrations high enough to dissolve the rock the streamlines for velocity reveal the magnitude of the flow in these regions fig 19 indicates high acid concentrations in all wormholes besides streamlines for velocity show that after 4 pv the flow is already focused in one region which becomes the dominant wormhole during the experiment literature reports ks 2 10 3 m s 1 for calcite dissolution with hcl panga et al 2005 for dolomite it should be 1 3 to 1 60 of the calcite value edery et al 2011 6 6 10 4 k s d o l h c l 3 3 10 5 our value ks 3 10 5 m s 1 was the best fit for dolomite 3 97 dolomite acidification in agreement with the approximate range reported by literature 5 2 calcite 1 simulations 5 2 1 methodology p several cases were simulated using ks in the range 1 0 10 8 to 1 0 10 6 m s 1 and av between 5000 and 520 000 m 1 and results are presented in fig 21 fig 21 a shows the same pattern observed in dolomite 3 increasing ks anticipates the acid breakthrough increasing av also increased the curve inclination as shown in fig 21 b however this effect is not as strong as it was observed by changing ks which has a higher influence in the acid breakthrough streamlines were calculated for initial pore system and the pore system after the injection of 38 pv of reactive brine as shown in fig 22 fig 22 shows that for low values of ks no wormhole was generated after 38 pv of reactive brine injected a small specific surface area leads to low dissolution and almost no difference in the pore system while a significant value in this parameter increases dissolution kinetics and wormhole formation however even for high values of av wormhole formation is not completed with ks 1 10 8 m s 1 confirming that ks has a stronger impact in wormhole formation than av 5 2 2 methodology s the micp curves from fig 3 were used as input for swanson equation to estimate the permeability value for phase low k we obtained k 1 md the permeability of high k phase 24 md was obtained by winland equation using the mean porosity of this phase as input two additional cases were simulated using 0 24 and 2 md as the permeability value in low k phase to test the influence of the less conductive phase in the general flow simulated permeability evolution curves are shown in fig 23 cases from fig 23 show that increasing permeability assigned to phase low k increases wormhole formation velocity as well as the slopes of the permeability curves cases cs1 to cs3 cs4 to cs6 and cs7 to cs9 show that increasing ks from 5 10 8 to 5 10 7 m s 1 results in higher slopes in the permeability curves fig 24 shows the extracted pore systems the pore systems from cases that used ks 5 10 8 are similar after pv 38 thus only cs1 is reported wormhole paths of cases with the same ks are all very similar fig 24 the simulated wormholes from cases cs3 cs6 and cs9 have small differences such as the number and size of secondary wormholes besides there was no wormhole formation in the cases that used ks 5 10 8 m s 1 cs1 cs4 and cs7 after pv 38 5 2 3 comparison between methodologies p and s although a wide range of values for parameters ks and av were used in the simulations we did not achieve a proper fit between experimental and simulated evolution of permeability in both methodologies when using values very low for both parameters wormhole formation did not occur additionally different combinations of ks and av always led to the creation of wormholes before what was experimentally observed in all simulations permeability increased faster than experimentally observed according to smith et al 2017 the parameter β should be adjusted in their work they used the following power law equation to describe k variation with ϵ 27 k t k o ϵ t ϵ o n they adjusted the empirical parameter n in range 1 6 to 8 to fit the porosity permeability evolution in their simulations and comparing eqs 14 and 27 n 2β 1 the range of n used by smith et al is equivalent to 0 3 β 3 5 simulations were repeated using β 0 5 and a good match between the experimental and simulated permeability evolution was achieved as presented in fig 25 the extracted pore systems at pv 45 for the best fit cases are shown in fig 26 from fig 25 the curves cp10 cs12 and cs15 correctly predict the acid breakthrough occurring around pv 36 but the permeabilities predicted by these cases before this point are higher than the ones observed in the experiments curve cs14 on the other hand fits better the permeability curve until pv 36 but does not predict the abrupt permeability increase from this point fig 26 shows that the wormhole is not completed in case cs14 at pv 45 in all cases many secondary wormholes are predicted it is in agreement with the experiments although the predicted ones are not in the exact positions of those from the experiments the wormhole path predicted by all cases have a similar shape but they are in a different position from what we observed in the experiments as discussed before fig 7 after the acid breakthrough a rapid increase in permeability was observed in calcite 1 experiment which was not reproduced by the simulations in order to investigate this streamlines were calculated for cases cp10 cs12 and cs15 they are presented in fig 27 colored by acid concentration and if fig 28 colored by fluid speed figs 27 and 28 show that the fluid quickly creates preferential paths that concentrate fluid flow and that with time one of these channels becomes more important and starts to drain the fluid stopping the growth of other channels in the last time frame shown the fluid flow appears to occur only at the channel besides the evolution of acid concentration and fluid flow did not have significant differences between methodologies in similar timesteps after pv 32 figs 27 and 28 show that most of the flow occurs inside the wormhole path with the acid breakthrough at 36 pv the dissolution may rapidly widen the channel especially at the tighter pore throats this might be the cause for the quick permeability increase observed experimentally this behavior was not observed in the experiment with dolomite 3 more precise porosity and permeability fields may be required to capture this behavior with the simulations fig 29 shows the simulated and experimental pore systems for case cs15 methodology s ks 1 10 7 m s 1 av 65 000 m 1 β 0 5 k 24 and 0 24 md in phases high k and low k respectively cases cp10 and cs12 results are similar to case cs15 and therefore they are not reported although a good fit of the permeability evolution was achieved for calcite 1 as shown in fig 25 fig 29 shows that the simulations could not predict the channel path reasonably this can be related to the presence of feldkamp and beam hardening artifact effects in the micro ct image from the plug before the experiment even though a software treatment was applied in the image it did not entirely remove these artifacts especially in the first slices of the sample which coincide with the inlet of the plug since the porosity and permeability fields were calculated based on the grayscale range the shadows coming from the feldkamp effect were interpreted as regions of higher porosity and permeability and the simulated channels were inevitably predicted in these regions fig 30 shows the first slice from the micro ct image of the plug calcite 1 using the sample range 2977 to 13494 and a second range 10354 to 13494 in which feldkamp and beam hardening effects are more easily identified 5 3 microscopic permeability evolution the evolution permeability curves like figs 12 and 26 show the macroscopic permeability evolution with time however to see how k evolves in each mesh s cell during simulation we need to look into the permeability field since higher changes in permeability occur at the wormhole path we extracted planes that longitudinally cut the wormhole paths for cases dp4 and cs15 fig 31 exemplifies the extraction of a plane for simulation case cs15 fig 32 shows the permeability field in the extracted planes at different simulation times for cases dp4 and cs15 for case dp4 dolomite 3 methodology p fig 32 shows the existence a region of higher permeability values at pv 0 as expected the wormhole path developed in this region the increase in permeability however occurs locally and affects only the regions near the wormhole path the same is observed in case cs15 calcite 1 methodology s before wormhole has developed the permeability of its future path is not affected by the flow unless near the wormhole tip this is explained by figs 19 and 27 that showed the acid distribution inside the sample with time the acid concentration decreases rapidly outside the wormhole path due to the high reactivity between the reactive brines and the carbonates studied here thus outside the wormhole path no significant change in permeability is expected fig 32 gives a last hint about the wormhole development in case cs15 the yellow arrow at pv 0 indicate a region near the base of the plug with higher permeability and the wormhole develops exactly at this point although the wormhole predicted in case cs15 was in a different region from that observed experimentally this figure confirms the wormhole growth through the initially more permeable regions of the plug and indicates the importance of correctly characterizing sample heterogeneities for reactive flow simulations especially for highly heterogeneous samples such as carbonates 6 conclusions the main contribution of this work was to capture the impact of rock heterogeneity on dissolution by using micro ct images to obtain pore space geometry and accounting for these details in the simulation mesh the micro ct images were also used as input to calculate the porosity and permeability fields to be used in simulations experiments showed very low silurian dolomite reactivity with co2 a test between a dolostone plug silurian dolomite outcrop and hcl was carried out simulations of this test showed that increasing the parameters ks and av accelerates the wormholing process and affects the path of the formed wormhole although the simulated wormholes grew in the same plug region for both methodologies its shape depends on the ks and av values a proper fitting of experimental k versus pv injected curve was achieved both methodologies used to generate the initial permeability field successfully reproduced the experimental pore system the segmentation process used to generate the initial permeability field influences the simulated permeability curve during the acidification but this influence depends on ks as the difference between ks in the phases high k and low k increases the wormhole formation velocity also increased for the indiana limestone sample simulations showed the same influence of ks and av observed in silurian dolomite simulations both methodologies using β 0 5 were able to reproduce the k versus pv injected curve using ks 1 10 7 m s 1 and av 65 000 m 1 predicting formation of a ramified wormhole as confirmed by experiments a rapid change in permeability was experimentally observed at pv 36 but was not reproduced in the simulations streamlines showed that at pv 32 most of the flow occurs at the wormhole path increased acid availability may cause a rapid dissolution of the last pore throats on the wormhole path increasing rapidly the macroscopic permeability until pv 36 when the acid breakthrough takes place and wormhole formation is complete this effect was not observed in experiments with the silurian dolomite plug and more precise porosity and permeability fields might be required to correctly capture this behavior with the simulations feldkamp and beam hardening effects in micro ct image caused deformations in the porosity and permeability fields and simulations did not predict the correct region where the channel should be formed this shows the critical importance of micro ct image quality in this kind of simulation we plan to improve these simulations in future works finally a close examination of the permeability fields during simulation confirmed that the wormhole growths in the initially more permeable regions the increase in permeability was concentrated near the wormhole path and simulations showed a rapid decrease in acid concentration outside the channel credit authorship contribution statement leandro de paulo ferreira methodology software formal analysis investigation writing original draft rodrigo surmas conceptualization software writing review editing funding acquisition sandra nelis tonietto resources writing review editing mônica antunes pereira da silva supervision writing review editing ricardo pires peçanha supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we gratefully acknowledge petrobras digital rock physics group as well as the petrophysics team from petrobras research center for the support l p f wishes to thank specially to maria aparecida do espírito santo for her inestimable help to rodolfo araujo victor for the discussion of results to jovani l favero for the help in openfoam to the tomography laboratory group for the images and support and to the fce group for the flow experiments the original and resampled micro ct images as well as the segmentations and porosity files have been made available for download at the digital rocks portal doi 10 17612 v09y aw80 ferreira 2020 supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103564 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
