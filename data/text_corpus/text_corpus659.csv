index,text
3295,attributing a physical meaning to the calibration of a conceptual hydrological model is a risk due to equifinality i e the existence of multiple optimal parameterizations that might or might not represent the actual behavior of a catchment a risk that propagates to posterior studies that use the outputs of the hydrological model as an input this study proposes and analyses sequential procedures for calibrating conceptual hydrological models aimed at reducing equifinality these procedures force the model to reproduce a flow separation of the observed streamflow into quick flow and base flow which we assumed representative of the run off generating processes in the catchment the sequential calibration of the model parameters that control quick flow and base flow forces the model to reproduce the flow separation and introduces additional constraints in the calibration process that reduce equifinality and improve the overall calibration procedure we applied this procedure to two mesoscale catchments in the picos de europa national park northern spain we compared the performance of the different calibration procedures both in the real scenario and in hypothetical scenarios of land use and soil permeability to provide a sounder assessment of the ability of the procedures under diverse conditions results show that a calibration method applying hydrograph separation ensures models with a better discharge partition whereas methods that do not apply separation failed in a considerable number of cases in terms of performance nse and bias the method applying hydrograph separation outperformed the reference method without separation for the real scenario even for total streamflow in the hypothetical scenarios though the improvement in process representativeness came at the expense of a slight loss in performance the sequential methods here developed were more computationally efficient since they explore the parameter space in subsets the number of iterations until convergence was a third of that needed with the reference method in summary we have developed a simple calibration procedure that ensures a better model behavior more in line with the underlying conceptualization with a similar and even better performance and a shorter calibration time than the reference method keywords hydrological modeling calibration equifinality hydrograph separation 1 introduction reproducing the real functioning of a catchment by calibration of a conceptual hydrological model is an extremely complicated task due to the multidimensionality of the optimisation problem shokri et al 2018 the equifinality of a model is the impossibility to select a single best model parameterization from the set of parameterizations with optimal performance beven and freer 2001 these multiple optimal parameterizations might represent models that behave in distinct ways i e in which the processes generating discharge overland flow interflow and base flow are differently partitioned beven and binely 1992 the usual calibration procedure either using manual or automatic calibration would choose the model parameterization that maximizes a specific performance metric however the parameter set with the highest performance might not reproduce the actual catchment functioning instead sub optimal parameterizations might be more realistic kavetski 2018 equifinality is partly caused by the large number of parameters present in conceptual hydrological models even though physical processes based models may contain even more parameters and the lack of observations against which to compare the model outputs shokri et al 2018 which in a regular case in hydrology is the observed discharge in one or several gauging station it may even be exacerbated in conceptual models due to the limited physical base of some of the processes considered for instance the separation between overland flow interflow and baseflow the uncertainty in the representativeness of the optimized model prevents granting it a physical meaning and thus its application as a starting point for further studies such as erosion vegetation dynamics or nutrient transport is compromised acero triana et al 2019 cain et al 2019 a way to tackle equifinality is to increase the number of target variables during calibration forcing the model to properly reproduce specific additional processes in the water cycle beven and binely 1992 several authors have applied satellite products linked to vegetation pasquato et al 2015 ruiz pérez 2016 such as ndvi normalized difference vegetation index rouse et al 1974 or lai leaf area index evapotranspiration koch et al 2015 demirel et al 2017 mendiguren et al 2017 koch et al 2018 stisen et al 2018 wambura et al 2018 rajib et al 2018 jiang et al 2020 snow yassin et al 2017 bai et al 2018 tuo et al 2018 nemri and kinnard 2020 or soil moisture li et al 2018 to calibrate spatially distributed hydrological models in order to reduce the uncertainty in the optimization by forcing surface hydrology subsurface hydrology is one of the sources of uncertainty in rainfall runoff models conceptual models often represent subsurface hydrology as a series of linear reservoirs corresponding to soil layers topsoil unsaturated and saturated zone for example each reservoir generates a horizontal flow overland flow interflow and baseflow following the previous example that aggregates in the stream network parameterizing this set of linear reservoirs is a complicated task mainly for two reasons the general scarcity of data about soil properties and the fact that the variable usually targeted in calibration is the total streamflow i e an aggregated value of the outflow from the linear reservoirs the result is a marked equifinality in the sense that totally different allocations to each of the horizontal flows may result in a similar streamflow without any certainty that any of these allocations reproduces the actual partition between surface and subsurface runoff in the catchment as an example of this zhang et al 2020 compared the base flow simulated by two hydrological models against the base flow obtained from the average of four common hydrograph separation methods to find out that even though the models performed properly in terms of total streamflow the simulated base flow suffered from a strong bias total streamflow can be decomposed into several types of flow representing different sources and delays which in the most common case are two quick flow and base flow stoelzle et al 2020 quick flow also referred to as direct or storm flow represents the component directly caused by precipitation events both by surface runoff or by preferential paths in the soil cain et al 2019 base flow is the component coming from delayed sources such as groundwater hall 1968 tallaksen 1995 and representing the longest and slowest decaying flows duncan 2019 this type of flow is responsible for maintaining streamflow under prolonged dry weather stoelzle et al 2020 decomposing total streamflow allows us to better understand the catchment processes zhang et al 2017 a knowledge that can be used for several purposes such as improving water resources management in both drought and flood events characterize aquifers analyze long term changes in the water balance zhang and schilling 2006 and introduce new information in the calibration of hydrological models tallaksen 1995 zhang et al 2017 zhang et al 2020 hydrograph separation methods are techniques that decompose the total streamflow in its components we will focus in two component quick and base flow separation techniques even though some authors have explored multi component separation methods stoelzle et al 2020 separation methods can be classified in two groups depending on whether they use tracers or not stoelzle et al 2020 zhang et al 2020 zhang et al 2017 tracer based methods use the physico chemical signature chloride electric conductivity temperature etc of the streamflow to estimate the age of the water and to separate quick flow from base flow they are the most physically grounded separation methods but require data which is often not available and whose generation requires time and resources tallaksen 1995 stoelzle et al 2020 hydrograph based separation methods only require gauged streamflow in some cases also precipitation records mei et al apr 2015 they resort to graphical tools digital filters and recession curves based on the boussinesq exponential decay equation boussinesq 1877 boussinesq 1904 eq 1 where b 0 represents the baseflow at time 0 b t represents the baseflow t periods later and k describes the rate at which baseflow decreases between storm events duncan 2019 graphical methods include the widely used local minimum method sloto and crouse 1996 developed by the usgs the united kingdom institute of hydrology ukih method gustard et al 1992 and modifications of it piggott et al oct 2005 these methods identify turning points in the hydrograph and assume that base flow is the linear interpolation between those points therefore their main advantage is their simplicity and absence of parameters to be calibrated whereas the main drawback is the lack of physical grounds since the recession decay is not applied filter methods include the lyne hollick method lyne and hollick 1979 the chapman maxwell method chapman apr 1999 the eckhardt method eckhardt 2005 and the duncan method duncan 2019 they filter the high frequency variability of total streamflow to generate either a quick flow lyne hollick method or a base flow chapman maxwell eckhardt and duncan methods time series these are parametric methods requiring at least the fitting of k which is defined as the relation between baseflow at any given time and one period earlier it is always smaller than 1 the recession constant in the boussinesq equation eq 1 and in some cases such as the eckhardt method a second parameter named the maximum base flow index bfi 1 b t b 0 k t the objective of this study is to use the additional information about the runoff generating processes that we can extract from hydrograph separation methods to reduce the equifinality in the calibration of a conceptual hydrological model the idea is to decompose the streamflow records in quick flow and base flow and to sequentially calibrate the horizontal flows in the conceptual hydrological model against these decomposed flows we hypothesize that such a calibration procedure will constrain the model to mimic the real flow decomposition hence reducing equifinality by constraining the spectrum of optimal parameterizations this hypothesis is built upon the idea that introducing internal state values even though approximated will help distinguishing among equifinal parameterizations beven and binely 1992 for the sake of simplicity and to enhance the applicability of our results we use simple and widely spread methods in the case of hydrograph separation we use the local minimum method sloto and crouse 1996 whereas for the optimization of model parameters we apply the shuffled complex evolution university of arizona method duan et al 1992 duan et al 1993 duan et al 1994 the final goal is to constrain the equifinality of the calibration process and ensure obtaining plausible models without the need for any additional data apart from the observed streamflow 2 study area and data the study area are two mesoscale basins with an approximate area of 480 km 2 each in the picos de europa national park northern spain the upper sella and the cares river basins both are middle high mountain catchments fig 1 with a large elevation range roughly from 50 to 2600 m a s l that causes a sharp climate gradient the climate in this area goes from temperate oceanic cfb in köppen geiger s classification in the valleys and close to the sea to subarctic sub alpine dfc in the mountain tops barceló and nunes 2009 mean annual precipitation in the area is around 1600 mm and the mean annual temperature is 10 6 c anthropogenic intervention is limited in both catchments land cover is dominated by shrubland and deciduous forest in lower areas that turns into grassland and rock outcrops in higher altitudes the hydrometeorologic data required for the study are daily climatic time series as input for the hydrological model and daily streamflow records as the target variable for performance assessment the spanish meteorological agency aemet provided the climatic data from the stations in the national park and surrounding area fig 1 from this data we generated daily maps of precipitation mean air temperature and diurnal temperature variation by spatial interpolation we performed a leave one out loo cross validation to identify the best spatial interpolation method in a loo procedure the interpolation model is iteratively fitted excluding data from one station at a time the variable is interpolated to the excluded location and the correspondence between observed and interpolated values is evaluated once this has been done for all the stations an aggregated performance metric in our case the root mean square error is computed to compare several spatial interpolation methods the loo crossed validation proved that universal kriging assuming linearity between mean monthly precipitation and elevation was the highest performing method to interpolate precipitation universal kriging a k a kriging with an external drift is a spatial interpolation method that fits a trend to the original data and applies kriging to the residues of that trend goovaerts 2000 in our case we looked for linear trends with three geographic variables that we deemed relevant elevation aspect and distance to the coast in the case of temperature both daily mean temperature and diurnal variation the best interpolation method was inverse distance weighted over the residuals of the linear regression between monthly mean temperature and elevation daily potential evapotranspiration maps were derived by the hargreaves samani method hargreaves and samani 1985 from the mean air temperature and diurnal temperature variation maps the official gauging station network of spain roea cedex 2016 provided the observed streamflow in the gauging stations at the outlet of both catchments fig 1 since both data sets had a daily temporal resolution that is the resolution chosen for the hydrological modeling cartographic data consisted of a digital terrain model dtm and land cover and soil property maps the spanish national center for geographic information cnig provided a 20 m resolution dtm of the study area the soil property maps were extracted from the database eu soilhydrogrids tóth et al 2017 which contains 250 m resolution maps for saturated hydraulic conductivity and available water capacity lastly we used a land cover map created by classification of landsat images from 2005 álvarez martínez et al 2018 with 30 m resolution we chose a spatial resolution of 100 m as a trade off between model resolution and computation time to adapt the data to this resolution we applied a bi linear resampling algorithm to continuous variables and a nearest neighbor algorithm to categorical variables 3 methods 3 1 hydrological model the hydrological model used in this study is tetis gimha 2018 a conceptual and spatially distributed model tetis has been applied to a broad range of climates including mediterranean alpine temperate oceanic and tropical climates specially in spain vélez et al 2009 but also in other countries such as france ruiz villanueva et al oct 2014 china li et al sep 2017 uk mcgrane et al feb 2017 colombia peña et al 2016 and kenya ruiz pérez et al 2017 its tank based structure is similar to that of other renowned conceptual models but unlike most of those its fully spatially distributed characteristic grants it a particular interest for analyzing the impacts of land cover change tetis conceptualizes the water cycle as a series of seven reservoirs representing the storages in the water cycle interception snow pack static surface gravitational aquifer and streams fig 2 this study focuses on the last four of these compartments i e those directly affecting runoff generation tetis divides the soil column in three layers each represented by a linear reservoir respectively named surface gravitational and aquifer storage the surface and gravitational storage are responsible for the overland flow and interflow respectively which discharge into gullies the lower order streams in the stream network whereas the aquifer storage produces base flow which is only discharged into rivers higher order streams streamflow routing along the stream network gullies and rivers is simulated using a geomorphological kinematic wave approach in total modeling runoff generation requires 25 parameters 7 corresponding to the three compartments representing soil layers 9 to gullies and 9 to rivers to simplify the calibration process tetis is able to fit all these parameters by just calibrating 8 dimensionless hyperparameters or correction factors fc 2 linked to the surface storage 3 to the gravitational storage 2 to the aquifer and 1 to the streamflow routing in gullies and rivers the term hyperparameter is used in modeling to denote model parameters that modify other parameters of a lower level in the case of tetis the parameters in blue in fig 2 are maps inferred from physical properties of the soil the land cover and the topography they are fixed to keep their spatial structure instead of modifying the parameters directly the hyperparameters in red in fig 2 modify the parameter maps as a whole these hyperparameters are the values tuned in the model calibration as mentioned in section 2 given the extent of the catchments the objective of the analysis and the available data we created models for both catchments with 100 m spatial resolution and daily temporal resolution the calibration period spans hydrological years starting the 1st of october from 2008 to 2013 both included and the validation period from 2000 to 2007 in both runs we used the first year as spin up time 3 2 hydrograph separation the main hypothesis behind this study is that the separation of the observed streamflow in two time series quick flow and base flow can be attributed to the three horizontal flows in tetis we assume that the quick flow represents the aggregation of overland flow and interflow whereas base flow corresponds to the outflow of the aquifer storage this assumption is grounded in tetis conceptualization fig 2 in which both overland flow and interflow represent streamflow generated by storm events that is discharged into ephemeral streams named gullies in tetis and is further supported by previous publications stoelzle et al 2020 soto 2020 cain et al 2019 duncan 2019 chow et al 1988 with this approach without any additional observation such as soil moisture ndvi or et we have three time series quick flow base flow and total streamflow to calibrate sequentially the horizontal flows generated by the different compartments in a regular calibration however all the compartments are fitted simultaneously against the unique total streamflow we adopted as separation method the local minimum method taken from the usgs software hysep sloto and crouse 1996 we chose this method based on its simplicity and widespread application chen and teegavarapu 2020 soto 2020 killian et al 2019 eckhardt apr 2008 zhang and schilling 2006 since the purpose of this study is to develop a calibration procedure we focused on that front assuming that if the local minimum method improves the performance of the calibrated model more complex and site specific separation methods will perform better we analyzed more complex hydrograph separation methods that reproduce the base flow regime more realistically i e complying with the five features of base flow enumerated by duncan 2019 however we adopted the local minimum method for the sake of simplicity since no separation method reproduces faithfully either the real or the simulated base flow behavior tallaksen 1995 with this approach we expect to approximate the partition of total streamflow in quick and base flow even though this method is unable to reproduce a physically meaningful base flow hydrograph to prove that we conducted experiments to check that this simple approach is able to improve the calibration on an array of synthetic cases in tetis see the supplementary material of this paper fig 3 shows an extract of the local minimum method application to the streamflow records in the two gauging stations in the study the local minimum method is a graphical method consisting on two steps the first step is the identification of local minima in the hydrograph black markers a local minimum is a day with the lowest streamflow in a centered time window of width 2 n gray shadings eq 2 defines the overland flow duration in days n where a is the area of the catchment in km 2 and 2 n is the closest odd number to the value 2 n once the dates of the local minima are identified the base flow hydrograph is the linear interpolation of the observed flow in those dates blue line in case the linear interpolation exceeds the observed hydrograph the base flow is equal to the total streamflow mid january in fig 3 2 n 0 8 a 0 2 days 3 3 model calibration tetis includes the automatic optimization algorithm shuffled complex evolution university of arizona sce ua duan et al 1992 duan et al 1993 duan et al 1994 to calibrate the model sce ua tries to replicate the natural evolution in the optimization process the modeler defines a n dimensional parameter space inside which the algorithm will look for the global optimum n is the number of parameters to be calibrated the algorithm starts by randomly sampling across this parameter space a population of parameter sets vectors of length n with a value for each parameter from this point it iterates a three step process division evolution and shuffling until a convergence criterion is fulfilled and the parameter set with highest performance is selected as the global optimum duan et al 1992 in the division step the population of parameter sets is randomly divided into groups a k a complexes during evolution each complex evolves independently towards higher performing members the evolution is based on the competitive complex evolution cce algorithm duan et al 1992 cce selects a couple of members from the complex parents and creates a new parameter set offspring the offspring replaces in the complex the worst performing parent cce iterates allowing each member in the complex a chance to generate offspring so there is no loss of information as in natural evolution the probability of a member being selected as parent is not equal those members with higher performance are more likely to be selected also following natural evolution offspring can be created by reflection using information from the parents or mutation to avoid local minima and add new information at some point the evolution stops and complexes are shuffled to make up again a unique population this step prevents the algorithm from finding local instead of global optima to grade the performance in sce ua we must define an objective criteria in this study we used two objective criteria the bias eq 3 and the nash sutcliffe efficiency coefficient nse eq 4 nash and sutcliffe 1970 3 bias t 1 n q s t q o t t 1 n q o t 100 4 nse 1 t 1 n q o t q s t 2 t 1 n q o t q o 2 where q o t and q s t are respectively the observed and simulated streamflow for day t and q o is the mean observed streamflow the first step in the calibration procedure is minimizing the bias so that the model generates the correct amount of streamflow in this step we fit the hyperparameters of the three storage compartments in gray shading in fig 2 interception snowpack and static i e those that control the losses of water in the system by evapotranspiration according to tetis conceptualization see fig 2 water can only exit the interception and static storage compartments through evapotranspiration therefore they only affect the water balance i e the bias in the streamflow the snowmelt exiting the snowpack storage can either feed the static storage losses through evapotranspiration or join precipitation to produce streamflow from the point of view of calibrating the runoff generation processes it is either a loss or an input therefore we also calibrate it against bias in particular we adjust six parameters three parameters of the degree day snowmelt method ddf 1 ddf 2 t b two parameters controlling soil water sorption p 1 fc 1 and a factor of the potential evapotranspiration time series fc 2 bias fitting is done independently for each catchment the hyperparameters here fitted are fixed for the rest of the calibration steps ensuring an unbiased total streamflow once the bias is fitted the following steps in the calibration try to reproduce the flow regime in the observed streamflow the objective criteria is the nse and the calibration focuses on the 8 hyperparameters related to runoff generation we compare 5 calibration methods bottom left hand panel in fig 4 method 0 represents the reference calibration method in which we do not apply hydrograph separation and we use the full power of the automatic calibration algorithm we fit simultaneously all the 8 hyperparameters against the total streamflow allowing the algorithm to explore the parameter space without constraints the lack of constraint in this type of calibration may lead to non realistic catchment models even if the performance is high which is the essence of equifinality and the reason for this study as opposed to this reference method we analyze four sequential calibration methods in these methods we calibrate successive combinations of the reservoirs controlling runoff generation so that we can calibrate each of these combinations against the most adequate flow quick base or total method 1 represents the common practice of many hydrologists who sequentially calibrate parameters led by expert knowledge and the visual inspection of the simulated streamflow in this case we calibrate sequentially the horizontal flows in the order that a raindrop would follow along the conceptualization of the model fig 2 overland flow and interflow t2 and t3 base flow t4 and streamflow routing t5 this method does not apply hydrograph separation so the target time series in all the three steps is the total streamflow method 2 replicates the three phases in method 1 but applies hydrograph separation the sum of overland flow and interflow is calibrated against quick flow the outflow of the aquifer storage against the base flow and streamflow routing against total streamflow method 3 also applies hydrograph separation but it inverts the order of the phases in method 2 we first calibrate base flow secondly quick flow and finally total streamflow in order to calibrate tank 4 in the first phase of method 3 we must also fit the two hyperparameters affecting infiltration and percolation fc 3 and fc 5 which control the inflow to the tank method 4 is a simplification of method 2 in which we fuse the last two phases i e we fit simultaneously base flow and routing against total streamflow tables 1 and 2 define more precisely the setup of the calibration methods table 1 defines the phases in each calibration method for each phase it indicates the target flow time series the objective criteria and the parameters tuned table 2 defines the search range minimum and maximum values and the initial value applied in the calibration of the 8 hyperparameters related to runoff generation processes 3 4 scenarios we applied the five calibration methods to three scenarios the calibration of the real land use and soil scenario using the observed streamflow and the calibration of synthetic streamflow using either the real land use and permeability maps or hypothetical maps fig 4 summarises the general workflow of the study in the first experiment we calibrated the two catchment models in the regular case i e using the observed streamflow and observed land use and permeability maps for the subsequent experiments a reference parameterization was required cf ref in fig 4 to make sure that this parameterization represented a feasible set we used the results from the calibration by the reference method method 0 selecting from the sce ua iterations those parameterizations we considered behavioral bias 5 and nse 0 58 and calculating for each parameter the median value among those behavioral parameterizations since the median of a set of behavioral parameterizations does not need to be behavioral we checked that the median parameterization did satisfy this requirement experiments two and three are synthetic cases in which we created a fictitious streamflow by running the model with the reference parameterization and various land use and permeability maps calibrating synthetic cases has some advantages since the target streamflow is generated by the model itself we are certain that it is possible to reach an ideal performance and we expect to find the original parameterization problems in reaching any of these two goals must be attributed to a poor calibration procedure or to equifinality furthermore synthetic cases allow us to check if the hydrograph separation method represents the partition between quick flow and base flow in the hydrological model we compare the synthetic base flow not used in the calibration procedure with the base flow obtained from the separation of the synthetic total streamflow in experiment two we simulated a synthetic streamflow using the reference parameterization and the observed land use and permeability maps we proceeded by calibrating the model with the five methods against this synthetic streamflow the whole procedure simulation of a synthetic streamflow and calibration was repeated for both catchments in experiment three with the objective of analysing the applicability of the methodology to diverse conditions without studying a large amount of catchments we designed a series of hypothetical scenarios of land cover and soil permeability in the cares basin we generated synthetic streamflow for the nine hypothetical scenarios and calibrated each of them by the five methods for the sake of brevity the methodology of experiment three and the results of the second and third experiments are explained in the supplementary material 3 4 1 assessment of performance in all three experiments the procedure is the same separation of the target total streamflow and calibration by means of the 5 methods described in section 3 3 we compared methods in three ways performance in both the total and separated flows visual inspection of hydrographs and values of the optimized parameterization we must stress that in the synthetic cases the flow time series used for calibration and performance assessment are not the same to calibrate we feed the algorithm with the time series resulting from the hydrograph separation method thereby reproducing a real case in which the base flow is unknown however we assess performance by comparison with the synthetic base flow so that we evaluate how the calibrated model reproduces the original partition instead of the approximation done by the hydrograph separation method 4 results 4 1 observed streamflow in the real scenario fig 5 shows the performance in the calibration and validation periods for the experiment 1 i e the real scenario calibrated against the observed streamflow left hand panels show the performance in terms of nse central panels for bias and the top right hand panel for the number of iterations required in each of the calibration phases results are organised by type of flow quick base or total and calibration method from 0 to 4 vertical gray lines indicate the distance to the target value of the objective function regarding the total flow there are four methods all but method 3 that performed good in both catchments total flow bias is close to zero and the nse can be classified as good around 0 6 except method 0 with values slightly lower than 0 5 method 3 has a strong negative bias in both catchments close to 50 and a poor nse below 0 4 we expected that the reference method method 0 would be the highest performing in terms of total flow since it uses the full power of the automatic algorithm to our surprise the reference method is the one with the lowest efficiency among those performing appropriately whereas methods applying flow separation methods 2 and 4 performed slightly better than the rest even for the total flow total flow performance in the validation period is basically similar method 3 misbehaves while the other four methods are still unbiased but show a certain loss in nse this loss is larger in the sella basin which causes that the efficiency in the sella model is lower than that of the cares model during the validation period contrary to what happened for the calibration period the four well performing models in terms of total flow behave differently when looking at the partition in quick and base flow the two methods without hydrograph separation methods 0 and 1 show a strong bias even larger than 100 quick flow in method 0 for the sella basin the nse for these two methods is poor for both separated flows close to 1 for the base flow and distinctly lower than the two methods that apply hydrograph separation methods 2 and 4 these last two methods are the ones with the highest performance the separated bias is close to null and the nse is larger than the rest of methods with the exception of base flow in the sella model the similar performance of these two methods comes from the fact that method 4 is a simplification of method 2 with a common quick flow calibration phase method 3 rejected in terms of total flow performance also misbehaves in the separated flows it shows negative bias in both quick and base flow stronger in the former whereas nse is poor for the quick flow 0 15 in average but acceptable for the base flow 0 35 in average similar to methods 2 and 4 the performance of separated flows in the validation period renders a similar behavior where methods 2 and 4 are those performing better as well as in the total flow the loss of efficiency in the validation is larger for the sella model this loss is more marked for the base than the quick flow both in terms of bias and nse the null variability in the number of iterations among catchment models is remarkable regardless of the catchment the number of iterations that sce ua requires to converge is controlled by the number of parameters to be optimized in a given phase this fact favours sequential calibration methods all but method 0 that instead of analysing an eight dimensional parameter space as many as parameters involved in runoff generation explore subsets of it the result is that sequential methods require a third of the number of iterations needed by the reference method this reduction in computation time is gained at the expense of a less exhaustive analysis of the parameter space and thus a lower probability of finding the global optimum the difference between sequential methods applying flow separation methods 2 3 and 4 and the common practice method 1 is that we use our knowledge about how the catchment may work to ensure optimized models with a proper flow partition the scatter plots in fig 6 provide an insight into the previous performance results the plots compare the observed flow q obs with the simulated flow q sim generated with the optimized parameterization each dot represents the pair of values for a day colours depict types of flow in order to show how the calibrated model reproduces flow partition in a perfect fit all the dots would be placed along the 1 1 line which means equal observed and simulated flow we must stress that in this experiment the observed quick and base flows are not actually observed but created with the hydrograph separation method this means that the partition has no real meaning nevertheless the results of the synthetic experiments supplementary material prove that the simplicity of the hydrograph separation method here employed was representative enough of the real behavior of the catchment a visual analysis shows that 5 out of the 10 plots represent a correct model namely method 1 in the sella basin and methods 2 and 4 in both basins method 0 optimized completely opposite models for the two basins whereas in the cares model base flow accounts for almost the entire total flow therefore quick flow is basically non existent in the sella model there is no base flow and the total flow is equal to the quick flow given the similar climate and geology in these two adjacent basins it is extremely unlikely that the two basins function in such a different manner most likely the real catchments do not behave in any of these extreme ways the cares model optimized by method 1 also suffers from an incorrect flow partition similarly to method 0 the model attributes almost the entire total flow to the base flow so there is no quick flow method 3 fails to reproduce quick flow probably due to a wrong parameterization of infiltration and percolation during the base flow fitting the optimized hyperparameter values obtained by each calibration method are shown in fig 7 each plot contains the values for a catchment hyperparameters are grouped by the type of flow they directly affect the dotted gray line spans the extreme optimized values to show the variability among methods parameter values are normalized by their search range table 2 to be able to show parameters with different orders of magnitude the four methods with an optimal total flow performance methods 0 1 2 and 4 optimized diverse parameterizations an example of the equifinality problem when comparing those methods that partition flow correctly methods 2 and 4 and method 1 in the sella basin the variability in the parameterizations is notably reduced fc 3 fc 5 fc 6 fc 7 fc 8 and fc 9 adopt similar values in the sella basin and parameterizations in the cares basin are almost identical for methods 2 and 4 this means that the parameter range that properly addresses flow partition is narrower than that which only reproduces correctly the total flow our approach attempts to guide the automatic calibration algorithm towards this limited range thus avoiding cases where a correct total flow calibration does not represent a realistic catchment functioning in the majority of cases the extreme optimized values correspond to one of the methods that could not reproduce the flow partition methods 0 and 3 and method 1 in the cares basin quick flow parameters show larger variability than the base and total flow parameters with the exception of fc 7 in the sella model the variability in the optimized values might be linked to the sensitivity of the parameter highly sensitive parameters have a narrow range of values with optimum performance pianosi et al 2016 so the calibrated parameter value is similar regardless of the calibration method therefore base and total flow parameters would be more sensitive than quick flow parameters 4 2 synthetic streamflow in the real scenario the results of this experiment are thoroughly commented on the supplementary material to summarize this experiment proved that the proposed correspondence between the quick and base flow time series resulting from hydrograph separation and those simulated with tetis is not perfect but approximate enough in terms of performance in the simulation of total flow only methods 1 and 2 obtained a high nse and a negligible bias in both catchments when analysing separated flows method 1 which does not apply flow separation is clearly outperformed by method 2 which does apply flow separation regarding optimized hyperparameter values none of the calibration methods was able to replicate the reference parameterization proving that the calibration methods here applied do not remove equifinality even in a simplified scenario such as a synthetic case however methods that apply flow separation get values closer among them and closer to the reference value these results prove that even though method 2 does not remove equifinality it can at least constrain it and force the calibration to get parameterizations closer to the reference and with a correct behavior in terms of runoff partition 4 3 hypothetical scenarios the results of this experiment are thoroughly commented on the supplementary material the eighteen calibrations carried out in this experiment are a perfect example of the problem of equifinality and the potential of the sequential methods here exposed when analysing the total flow performance all methods performed successfully both in terms of nse and bias as expected the reference method method 0 was the highest performing one the difference between methods appears when looking at the performance for the quick and base flow where methods that apply flow separation stand out specially method 2 in some scenarios method 0 represents the perfect example of the risk of granting physical meaning to an optimised model without further tests the simulation of total flow was utterly perfect but the partition clearly wrong methods applying flow separation instead reproduce adequately flow partition at the expense of a slight loss in total flow performance the automatic optimization algorithm could not find the reference parameterization in any of the hypothetical scenarios this is the case even for method 0 for which we allowed the algorithm to exhaustively explore the parameter space however methods using hydrograph separation 2 3 and 4 reduce the variability in the optimized hyperparameter values among scenarios hence constraining the equifinality problem 5 discussion the multiple cases here presented dwell in the difficulty of coping with the equifinality problem and the need to constrain the calibration process in order to tackle it we show how diverse parameterizations representing different catchment functioning are equivalent in terms of total flow performance our approach attempts to distinguish which of those parameterizations also reproduce the actual catchment processes which we represent by the partition of the total flow results show that the reference calibration method in which we apply no constraints in the parameter space to be evaluated outperforms the methods here designed in the hypothetical scenarios but not in the real scenario neither with a synthetic nor the observed streamflow as calibration target apart from that fact the reference method has two disadvantages in the first place in a considerable number of cases the method optimizes catchment models physically unfeasible i e in which the partition in quick and base flow is incorrect from our results this fact occurs in all the four real case scenarios and in three out of nine hypothetical scenarios in the second place this method is computationally less efficient than the sequential methods since the algorithm must explore at once the eight dimensional parameter space the number of iterations it requires is approximately 3 times larger than that needed in the sequential methods which explore subsets of that parameter space as a method in between the reference and the partition methods here developed we included the common practice of many hydrologists who calibrate models by sequentially fitting parameters always with the total streamflow as target results prove that this method outperforms the reference method in the real scenarios but is the one with the lowest performance in the hypothetical scenarios in both real and hypothetical scenarios it shows high performance in terms of total flow but it fails to reproduce flow partition in one out of four real scenarios and all of the nine hypothetical scenarios among the methods that apply flow separation method 2 stands out as the highest performing of all in this method we sequentially calibrate storages from top to bottom soil layers and lastly the streamflow routing the main attribute of this method is that it ensures a correct flow partition in all cases in the real scenario both synthetic and observed streamflow this method outperforms all of the others even unexpectedly for the total flow in the hypothetical scenarios the improvement in flow partition is gained at the expense of a slight loss of total flow performance when compared with the reference method because this method explores subsets of the parameter space it may not find the global optimum what explains the loss of total flow performance in the hypothetical scenarios but it reduces the computational effort to a third none of the methods is able to resolve the equifinality in the calibration of the conceptual hydrological model proof of that fact are the diverse parameterizations that performed correctly in the synthetic cases in which the calibration algorithm should have found similar parameter values to the reference parameterization the fact that the automatic calibration algorithm when applied with total freedom such as in method 0 has not been able to replicate neither the streamflow nor the parameterization in the synthetic cases of the real scenario raises doubts about its efficiency in real scenarios although equifinality is not removed the results show that constraining the global search in the parameter space such as in method 2 guides the automatic algorithm towards a reduced region in the parameter space with better performance and more importantly realistic catchment models this study does not attempt to invalidate sce ua as a global optimization algorithm but we draw attention to the importance of constraining the calibration of conceptual hydrological models in order to prevent equifinality from generating unrealistic catchment models this is of vital importance when the hydrological model is the starting point of a posterior analysis for instance erosion nutrient transport or vegetation dynamics we have employed the local minimum method to separate the total streamflow into its quick and base flow components which is a simplistic approach to prove that the simplicity of this method does not affect the outcomes of the study we evaluated its performance in synthetic cases both in the real and hypothetical scenarios the negligible bias between separated and synthetic flows see figure s1 proves that the separation method properly represents the flow partition in tetis however there is ground for improvement in this part applying more realistic separation methods such as those presented in duncan 2019 eckhardt apr 2008 chapman apr 1999 lyne and hollick 1979 or tracer methods if available will enhance the capabilities of the sequential calibration procedures here developed specifically in terms of base flow nse there is a limitation in this regard which is the representation of the aquifer s outflow in the hydrological model no matter how realistic the separation method is the base flow performance is limited to the ability of the model to simulate base flow which in the case of tetis seems to be excessively reactive giving support to the implementation of a cascade of linear reservoirs instead of a single one tallaksen 1995 future research might also deal with the idea of dividing streamflow in more than two components stoelzle et al 2020 if we could separate it in three components surface runoff interflow and base flow we could calibrate individually each of the three soil storage reservoirs involved in runoff generation boosting the advantages of the sequential calibration method here developed this approach may also improve the observed lack of sensitivity of the quick flow parameters by calibrating these 5 parameters in two instead of one single phase in this study we have not addressed equifinality in crucial processes such as snow melt processes and notably evapotranspiration represented in tetis by three specific storage reservoirs interception snowpack and static current research in our group deals with this shortcoming we are exploring how to incorporate remotely sensed products in the calibration of snow cover and evapotranspiration exploiting also the spatially distributed property of tetis koch et al 2015 demirel et al 2017 mendiguren et al 2017 koch et al 2018 bai et al 2018 tuo et al 2018 nemri and kinnard 2020 the results here presented are specific to a type of climate and hydrological regime we consider that the benefits of sequential calibration and flow partition can be extrapolated to other climates and hydrological regimes though further analyses must be done to prove it specially regarding the hydrograph separation method 6 conclusions in this study we have analyzed the equifinality in the calibration of a conceptual hydrological model and developed a sequential calibration method that limits its consequences the idea is to calibrate independently the outflows of the different runoff generating reservoirs in the hydrological model against a time series representative of that process to create these target time series we apply hydrograph separation using the local minimum method the study focuses on two mesoscale catchments in the northern side of the picos de europa national park spain in these two catchments we carried out three calibration experiments the real case scenario with both the observed and a synthetic streamflow as targets in the calibration and hypothetical scenarios of land cover and soil permeability with synthetic streamflows results prove that a sequential calibration method using separated flows leads the automatic calibration algorithm towards model parameterizations that better reproduce the runoff generating processes occurring in the catchment in the real scenario this procedure not only improves the performance for the separated flows but also for total streamflow only when applied to hypothetical scenarios of soil permeability and land cover the improved performance in the separated flows comes at the expense of a slight loss of total streamflow performance the constraints imposed in the sequential calibration procedures reduce the range in the parameter space of the behavioral models hence they reduce equifinality on top of the previous sequential calibration methods are computationally more efficient since they explore the parameter space in subspaces the setup of this study reduced the number of iterations in the optimization algorithm to a third this study presents a first promising attempt to use hydrograph separation to improve the calibration of conceptual hydrological models further research should implement more realistic separation methods that better reproduce the nature of base flow or decompose streamflow in more than two components we strongly suggest imposing constraints such as separated flows in the calibration of hydrological models to induce models that better reproduce catchment processes this is of grand importance if the purpose of hydrological model is not focused strictly on streamflow but to analyse catchment processes such as erosion impacts of land cover change groundwater recharge or nutrient cycling for instance credit authorship contribution statement jesús casado rodríguez conceptualization methodology software validation formal analysis data curation writing original draft visualization manuel del jesus methodology writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was originally funded by the spanish national research agency and the european regional development fund through the research project gesdivah ref bia2016 78397 p the first author is sponsored by the spanish ministry of education and vocational training through a pre doctoral scholarship fpu 17 05353 manuel del jesus acknowledges the financial support from the government of cantabria through the fénix programme the authors would like to thank josé manuel álvarez martínez for contributing the land cover map appendix a supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2022 127816 supplementary data the following are the supplementary data to this article supplementary data 1 
3295,attributing a physical meaning to the calibration of a conceptual hydrological model is a risk due to equifinality i e the existence of multiple optimal parameterizations that might or might not represent the actual behavior of a catchment a risk that propagates to posterior studies that use the outputs of the hydrological model as an input this study proposes and analyses sequential procedures for calibrating conceptual hydrological models aimed at reducing equifinality these procedures force the model to reproduce a flow separation of the observed streamflow into quick flow and base flow which we assumed representative of the run off generating processes in the catchment the sequential calibration of the model parameters that control quick flow and base flow forces the model to reproduce the flow separation and introduces additional constraints in the calibration process that reduce equifinality and improve the overall calibration procedure we applied this procedure to two mesoscale catchments in the picos de europa national park northern spain we compared the performance of the different calibration procedures both in the real scenario and in hypothetical scenarios of land use and soil permeability to provide a sounder assessment of the ability of the procedures under diverse conditions results show that a calibration method applying hydrograph separation ensures models with a better discharge partition whereas methods that do not apply separation failed in a considerable number of cases in terms of performance nse and bias the method applying hydrograph separation outperformed the reference method without separation for the real scenario even for total streamflow in the hypothetical scenarios though the improvement in process representativeness came at the expense of a slight loss in performance the sequential methods here developed were more computationally efficient since they explore the parameter space in subsets the number of iterations until convergence was a third of that needed with the reference method in summary we have developed a simple calibration procedure that ensures a better model behavior more in line with the underlying conceptualization with a similar and even better performance and a shorter calibration time than the reference method keywords hydrological modeling calibration equifinality hydrograph separation 1 introduction reproducing the real functioning of a catchment by calibration of a conceptual hydrological model is an extremely complicated task due to the multidimensionality of the optimisation problem shokri et al 2018 the equifinality of a model is the impossibility to select a single best model parameterization from the set of parameterizations with optimal performance beven and freer 2001 these multiple optimal parameterizations might represent models that behave in distinct ways i e in which the processes generating discharge overland flow interflow and base flow are differently partitioned beven and binely 1992 the usual calibration procedure either using manual or automatic calibration would choose the model parameterization that maximizes a specific performance metric however the parameter set with the highest performance might not reproduce the actual catchment functioning instead sub optimal parameterizations might be more realistic kavetski 2018 equifinality is partly caused by the large number of parameters present in conceptual hydrological models even though physical processes based models may contain even more parameters and the lack of observations against which to compare the model outputs shokri et al 2018 which in a regular case in hydrology is the observed discharge in one or several gauging station it may even be exacerbated in conceptual models due to the limited physical base of some of the processes considered for instance the separation between overland flow interflow and baseflow the uncertainty in the representativeness of the optimized model prevents granting it a physical meaning and thus its application as a starting point for further studies such as erosion vegetation dynamics or nutrient transport is compromised acero triana et al 2019 cain et al 2019 a way to tackle equifinality is to increase the number of target variables during calibration forcing the model to properly reproduce specific additional processes in the water cycle beven and binely 1992 several authors have applied satellite products linked to vegetation pasquato et al 2015 ruiz pérez 2016 such as ndvi normalized difference vegetation index rouse et al 1974 or lai leaf area index evapotranspiration koch et al 2015 demirel et al 2017 mendiguren et al 2017 koch et al 2018 stisen et al 2018 wambura et al 2018 rajib et al 2018 jiang et al 2020 snow yassin et al 2017 bai et al 2018 tuo et al 2018 nemri and kinnard 2020 or soil moisture li et al 2018 to calibrate spatially distributed hydrological models in order to reduce the uncertainty in the optimization by forcing surface hydrology subsurface hydrology is one of the sources of uncertainty in rainfall runoff models conceptual models often represent subsurface hydrology as a series of linear reservoirs corresponding to soil layers topsoil unsaturated and saturated zone for example each reservoir generates a horizontal flow overland flow interflow and baseflow following the previous example that aggregates in the stream network parameterizing this set of linear reservoirs is a complicated task mainly for two reasons the general scarcity of data about soil properties and the fact that the variable usually targeted in calibration is the total streamflow i e an aggregated value of the outflow from the linear reservoirs the result is a marked equifinality in the sense that totally different allocations to each of the horizontal flows may result in a similar streamflow without any certainty that any of these allocations reproduces the actual partition between surface and subsurface runoff in the catchment as an example of this zhang et al 2020 compared the base flow simulated by two hydrological models against the base flow obtained from the average of four common hydrograph separation methods to find out that even though the models performed properly in terms of total streamflow the simulated base flow suffered from a strong bias total streamflow can be decomposed into several types of flow representing different sources and delays which in the most common case are two quick flow and base flow stoelzle et al 2020 quick flow also referred to as direct or storm flow represents the component directly caused by precipitation events both by surface runoff or by preferential paths in the soil cain et al 2019 base flow is the component coming from delayed sources such as groundwater hall 1968 tallaksen 1995 and representing the longest and slowest decaying flows duncan 2019 this type of flow is responsible for maintaining streamflow under prolonged dry weather stoelzle et al 2020 decomposing total streamflow allows us to better understand the catchment processes zhang et al 2017 a knowledge that can be used for several purposes such as improving water resources management in both drought and flood events characterize aquifers analyze long term changes in the water balance zhang and schilling 2006 and introduce new information in the calibration of hydrological models tallaksen 1995 zhang et al 2017 zhang et al 2020 hydrograph separation methods are techniques that decompose the total streamflow in its components we will focus in two component quick and base flow separation techniques even though some authors have explored multi component separation methods stoelzle et al 2020 separation methods can be classified in two groups depending on whether they use tracers or not stoelzle et al 2020 zhang et al 2020 zhang et al 2017 tracer based methods use the physico chemical signature chloride electric conductivity temperature etc of the streamflow to estimate the age of the water and to separate quick flow from base flow they are the most physically grounded separation methods but require data which is often not available and whose generation requires time and resources tallaksen 1995 stoelzle et al 2020 hydrograph based separation methods only require gauged streamflow in some cases also precipitation records mei et al apr 2015 they resort to graphical tools digital filters and recession curves based on the boussinesq exponential decay equation boussinesq 1877 boussinesq 1904 eq 1 where b 0 represents the baseflow at time 0 b t represents the baseflow t periods later and k describes the rate at which baseflow decreases between storm events duncan 2019 graphical methods include the widely used local minimum method sloto and crouse 1996 developed by the usgs the united kingdom institute of hydrology ukih method gustard et al 1992 and modifications of it piggott et al oct 2005 these methods identify turning points in the hydrograph and assume that base flow is the linear interpolation between those points therefore their main advantage is their simplicity and absence of parameters to be calibrated whereas the main drawback is the lack of physical grounds since the recession decay is not applied filter methods include the lyne hollick method lyne and hollick 1979 the chapman maxwell method chapman apr 1999 the eckhardt method eckhardt 2005 and the duncan method duncan 2019 they filter the high frequency variability of total streamflow to generate either a quick flow lyne hollick method or a base flow chapman maxwell eckhardt and duncan methods time series these are parametric methods requiring at least the fitting of k which is defined as the relation between baseflow at any given time and one period earlier it is always smaller than 1 the recession constant in the boussinesq equation eq 1 and in some cases such as the eckhardt method a second parameter named the maximum base flow index bfi 1 b t b 0 k t the objective of this study is to use the additional information about the runoff generating processes that we can extract from hydrograph separation methods to reduce the equifinality in the calibration of a conceptual hydrological model the idea is to decompose the streamflow records in quick flow and base flow and to sequentially calibrate the horizontal flows in the conceptual hydrological model against these decomposed flows we hypothesize that such a calibration procedure will constrain the model to mimic the real flow decomposition hence reducing equifinality by constraining the spectrum of optimal parameterizations this hypothesis is built upon the idea that introducing internal state values even though approximated will help distinguishing among equifinal parameterizations beven and binely 1992 for the sake of simplicity and to enhance the applicability of our results we use simple and widely spread methods in the case of hydrograph separation we use the local minimum method sloto and crouse 1996 whereas for the optimization of model parameters we apply the shuffled complex evolution university of arizona method duan et al 1992 duan et al 1993 duan et al 1994 the final goal is to constrain the equifinality of the calibration process and ensure obtaining plausible models without the need for any additional data apart from the observed streamflow 2 study area and data the study area are two mesoscale basins with an approximate area of 480 km 2 each in the picos de europa national park northern spain the upper sella and the cares river basins both are middle high mountain catchments fig 1 with a large elevation range roughly from 50 to 2600 m a s l that causes a sharp climate gradient the climate in this area goes from temperate oceanic cfb in köppen geiger s classification in the valleys and close to the sea to subarctic sub alpine dfc in the mountain tops barceló and nunes 2009 mean annual precipitation in the area is around 1600 mm and the mean annual temperature is 10 6 c anthropogenic intervention is limited in both catchments land cover is dominated by shrubland and deciduous forest in lower areas that turns into grassland and rock outcrops in higher altitudes the hydrometeorologic data required for the study are daily climatic time series as input for the hydrological model and daily streamflow records as the target variable for performance assessment the spanish meteorological agency aemet provided the climatic data from the stations in the national park and surrounding area fig 1 from this data we generated daily maps of precipitation mean air temperature and diurnal temperature variation by spatial interpolation we performed a leave one out loo cross validation to identify the best spatial interpolation method in a loo procedure the interpolation model is iteratively fitted excluding data from one station at a time the variable is interpolated to the excluded location and the correspondence between observed and interpolated values is evaluated once this has been done for all the stations an aggregated performance metric in our case the root mean square error is computed to compare several spatial interpolation methods the loo crossed validation proved that universal kriging assuming linearity between mean monthly precipitation and elevation was the highest performing method to interpolate precipitation universal kriging a k a kriging with an external drift is a spatial interpolation method that fits a trend to the original data and applies kriging to the residues of that trend goovaerts 2000 in our case we looked for linear trends with three geographic variables that we deemed relevant elevation aspect and distance to the coast in the case of temperature both daily mean temperature and diurnal variation the best interpolation method was inverse distance weighted over the residuals of the linear regression between monthly mean temperature and elevation daily potential evapotranspiration maps were derived by the hargreaves samani method hargreaves and samani 1985 from the mean air temperature and diurnal temperature variation maps the official gauging station network of spain roea cedex 2016 provided the observed streamflow in the gauging stations at the outlet of both catchments fig 1 since both data sets had a daily temporal resolution that is the resolution chosen for the hydrological modeling cartographic data consisted of a digital terrain model dtm and land cover and soil property maps the spanish national center for geographic information cnig provided a 20 m resolution dtm of the study area the soil property maps were extracted from the database eu soilhydrogrids tóth et al 2017 which contains 250 m resolution maps for saturated hydraulic conductivity and available water capacity lastly we used a land cover map created by classification of landsat images from 2005 álvarez martínez et al 2018 with 30 m resolution we chose a spatial resolution of 100 m as a trade off between model resolution and computation time to adapt the data to this resolution we applied a bi linear resampling algorithm to continuous variables and a nearest neighbor algorithm to categorical variables 3 methods 3 1 hydrological model the hydrological model used in this study is tetis gimha 2018 a conceptual and spatially distributed model tetis has been applied to a broad range of climates including mediterranean alpine temperate oceanic and tropical climates specially in spain vélez et al 2009 but also in other countries such as france ruiz villanueva et al oct 2014 china li et al sep 2017 uk mcgrane et al feb 2017 colombia peña et al 2016 and kenya ruiz pérez et al 2017 its tank based structure is similar to that of other renowned conceptual models but unlike most of those its fully spatially distributed characteristic grants it a particular interest for analyzing the impacts of land cover change tetis conceptualizes the water cycle as a series of seven reservoirs representing the storages in the water cycle interception snow pack static surface gravitational aquifer and streams fig 2 this study focuses on the last four of these compartments i e those directly affecting runoff generation tetis divides the soil column in three layers each represented by a linear reservoir respectively named surface gravitational and aquifer storage the surface and gravitational storage are responsible for the overland flow and interflow respectively which discharge into gullies the lower order streams in the stream network whereas the aquifer storage produces base flow which is only discharged into rivers higher order streams streamflow routing along the stream network gullies and rivers is simulated using a geomorphological kinematic wave approach in total modeling runoff generation requires 25 parameters 7 corresponding to the three compartments representing soil layers 9 to gullies and 9 to rivers to simplify the calibration process tetis is able to fit all these parameters by just calibrating 8 dimensionless hyperparameters or correction factors fc 2 linked to the surface storage 3 to the gravitational storage 2 to the aquifer and 1 to the streamflow routing in gullies and rivers the term hyperparameter is used in modeling to denote model parameters that modify other parameters of a lower level in the case of tetis the parameters in blue in fig 2 are maps inferred from physical properties of the soil the land cover and the topography they are fixed to keep their spatial structure instead of modifying the parameters directly the hyperparameters in red in fig 2 modify the parameter maps as a whole these hyperparameters are the values tuned in the model calibration as mentioned in section 2 given the extent of the catchments the objective of the analysis and the available data we created models for both catchments with 100 m spatial resolution and daily temporal resolution the calibration period spans hydrological years starting the 1st of october from 2008 to 2013 both included and the validation period from 2000 to 2007 in both runs we used the first year as spin up time 3 2 hydrograph separation the main hypothesis behind this study is that the separation of the observed streamflow in two time series quick flow and base flow can be attributed to the three horizontal flows in tetis we assume that the quick flow represents the aggregation of overland flow and interflow whereas base flow corresponds to the outflow of the aquifer storage this assumption is grounded in tetis conceptualization fig 2 in which both overland flow and interflow represent streamflow generated by storm events that is discharged into ephemeral streams named gullies in tetis and is further supported by previous publications stoelzle et al 2020 soto 2020 cain et al 2019 duncan 2019 chow et al 1988 with this approach without any additional observation such as soil moisture ndvi or et we have three time series quick flow base flow and total streamflow to calibrate sequentially the horizontal flows generated by the different compartments in a regular calibration however all the compartments are fitted simultaneously against the unique total streamflow we adopted as separation method the local minimum method taken from the usgs software hysep sloto and crouse 1996 we chose this method based on its simplicity and widespread application chen and teegavarapu 2020 soto 2020 killian et al 2019 eckhardt apr 2008 zhang and schilling 2006 since the purpose of this study is to develop a calibration procedure we focused on that front assuming that if the local minimum method improves the performance of the calibrated model more complex and site specific separation methods will perform better we analyzed more complex hydrograph separation methods that reproduce the base flow regime more realistically i e complying with the five features of base flow enumerated by duncan 2019 however we adopted the local minimum method for the sake of simplicity since no separation method reproduces faithfully either the real or the simulated base flow behavior tallaksen 1995 with this approach we expect to approximate the partition of total streamflow in quick and base flow even though this method is unable to reproduce a physically meaningful base flow hydrograph to prove that we conducted experiments to check that this simple approach is able to improve the calibration on an array of synthetic cases in tetis see the supplementary material of this paper fig 3 shows an extract of the local minimum method application to the streamflow records in the two gauging stations in the study the local minimum method is a graphical method consisting on two steps the first step is the identification of local minima in the hydrograph black markers a local minimum is a day with the lowest streamflow in a centered time window of width 2 n gray shadings eq 2 defines the overland flow duration in days n where a is the area of the catchment in km 2 and 2 n is the closest odd number to the value 2 n once the dates of the local minima are identified the base flow hydrograph is the linear interpolation of the observed flow in those dates blue line in case the linear interpolation exceeds the observed hydrograph the base flow is equal to the total streamflow mid january in fig 3 2 n 0 8 a 0 2 days 3 3 model calibration tetis includes the automatic optimization algorithm shuffled complex evolution university of arizona sce ua duan et al 1992 duan et al 1993 duan et al 1994 to calibrate the model sce ua tries to replicate the natural evolution in the optimization process the modeler defines a n dimensional parameter space inside which the algorithm will look for the global optimum n is the number of parameters to be calibrated the algorithm starts by randomly sampling across this parameter space a population of parameter sets vectors of length n with a value for each parameter from this point it iterates a three step process division evolution and shuffling until a convergence criterion is fulfilled and the parameter set with highest performance is selected as the global optimum duan et al 1992 in the division step the population of parameter sets is randomly divided into groups a k a complexes during evolution each complex evolves independently towards higher performing members the evolution is based on the competitive complex evolution cce algorithm duan et al 1992 cce selects a couple of members from the complex parents and creates a new parameter set offspring the offspring replaces in the complex the worst performing parent cce iterates allowing each member in the complex a chance to generate offspring so there is no loss of information as in natural evolution the probability of a member being selected as parent is not equal those members with higher performance are more likely to be selected also following natural evolution offspring can be created by reflection using information from the parents or mutation to avoid local minima and add new information at some point the evolution stops and complexes are shuffled to make up again a unique population this step prevents the algorithm from finding local instead of global optima to grade the performance in sce ua we must define an objective criteria in this study we used two objective criteria the bias eq 3 and the nash sutcliffe efficiency coefficient nse eq 4 nash and sutcliffe 1970 3 bias t 1 n q s t q o t t 1 n q o t 100 4 nse 1 t 1 n q o t q s t 2 t 1 n q o t q o 2 where q o t and q s t are respectively the observed and simulated streamflow for day t and q o is the mean observed streamflow the first step in the calibration procedure is minimizing the bias so that the model generates the correct amount of streamflow in this step we fit the hyperparameters of the three storage compartments in gray shading in fig 2 interception snowpack and static i e those that control the losses of water in the system by evapotranspiration according to tetis conceptualization see fig 2 water can only exit the interception and static storage compartments through evapotranspiration therefore they only affect the water balance i e the bias in the streamflow the snowmelt exiting the snowpack storage can either feed the static storage losses through evapotranspiration or join precipitation to produce streamflow from the point of view of calibrating the runoff generation processes it is either a loss or an input therefore we also calibrate it against bias in particular we adjust six parameters three parameters of the degree day snowmelt method ddf 1 ddf 2 t b two parameters controlling soil water sorption p 1 fc 1 and a factor of the potential evapotranspiration time series fc 2 bias fitting is done independently for each catchment the hyperparameters here fitted are fixed for the rest of the calibration steps ensuring an unbiased total streamflow once the bias is fitted the following steps in the calibration try to reproduce the flow regime in the observed streamflow the objective criteria is the nse and the calibration focuses on the 8 hyperparameters related to runoff generation we compare 5 calibration methods bottom left hand panel in fig 4 method 0 represents the reference calibration method in which we do not apply hydrograph separation and we use the full power of the automatic calibration algorithm we fit simultaneously all the 8 hyperparameters against the total streamflow allowing the algorithm to explore the parameter space without constraints the lack of constraint in this type of calibration may lead to non realistic catchment models even if the performance is high which is the essence of equifinality and the reason for this study as opposed to this reference method we analyze four sequential calibration methods in these methods we calibrate successive combinations of the reservoirs controlling runoff generation so that we can calibrate each of these combinations against the most adequate flow quick base or total method 1 represents the common practice of many hydrologists who sequentially calibrate parameters led by expert knowledge and the visual inspection of the simulated streamflow in this case we calibrate sequentially the horizontal flows in the order that a raindrop would follow along the conceptualization of the model fig 2 overland flow and interflow t2 and t3 base flow t4 and streamflow routing t5 this method does not apply hydrograph separation so the target time series in all the three steps is the total streamflow method 2 replicates the three phases in method 1 but applies hydrograph separation the sum of overland flow and interflow is calibrated against quick flow the outflow of the aquifer storage against the base flow and streamflow routing against total streamflow method 3 also applies hydrograph separation but it inverts the order of the phases in method 2 we first calibrate base flow secondly quick flow and finally total streamflow in order to calibrate tank 4 in the first phase of method 3 we must also fit the two hyperparameters affecting infiltration and percolation fc 3 and fc 5 which control the inflow to the tank method 4 is a simplification of method 2 in which we fuse the last two phases i e we fit simultaneously base flow and routing against total streamflow tables 1 and 2 define more precisely the setup of the calibration methods table 1 defines the phases in each calibration method for each phase it indicates the target flow time series the objective criteria and the parameters tuned table 2 defines the search range minimum and maximum values and the initial value applied in the calibration of the 8 hyperparameters related to runoff generation processes 3 4 scenarios we applied the five calibration methods to three scenarios the calibration of the real land use and soil scenario using the observed streamflow and the calibration of synthetic streamflow using either the real land use and permeability maps or hypothetical maps fig 4 summarises the general workflow of the study in the first experiment we calibrated the two catchment models in the regular case i e using the observed streamflow and observed land use and permeability maps for the subsequent experiments a reference parameterization was required cf ref in fig 4 to make sure that this parameterization represented a feasible set we used the results from the calibration by the reference method method 0 selecting from the sce ua iterations those parameterizations we considered behavioral bias 5 and nse 0 58 and calculating for each parameter the median value among those behavioral parameterizations since the median of a set of behavioral parameterizations does not need to be behavioral we checked that the median parameterization did satisfy this requirement experiments two and three are synthetic cases in which we created a fictitious streamflow by running the model with the reference parameterization and various land use and permeability maps calibrating synthetic cases has some advantages since the target streamflow is generated by the model itself we are certain that it is possible to reach an ideal performance and we expect to find the original parameterization problems in reaching any of these two goals must be attributed to a poor calibration procedure or to equifinality furthermore synthetic cases allow us to check if the hydrograph separation method represents the partition between quick flow and base flow in the hydrological model we compare the synthetic base flow not used in the calibration procedure with the base flow obtained from the separation of the synthetic total streamflow in experiment two we simulated a synthetic streamflow using the reference parameterization and the observed land use and permeability maps we proceeded by calibrating the model with the five methods against this synthetic streamflow the whole procedure simulation of a synthetic streamflow and calibration was repeated for both catchments in experiment three with the objective of analysing the applicability of the methodology to diverse conditions without studying a large amount of catchments we designed a series of hypothetical scenarios of land cover and soil permeability in the cares basin we generated synthetic streamflow for the nine hypothetical scenarios and calibrated each of them by the five methods for the sake of brevity the methodology of experiment three and the results of the second and third experiments are explained in the supplementary material 3 4 1 assessment of performance in all three experiments the procedure is the same separation of the target total streamflow and calibration by means of the 5 methods described in section 3 3 we compared methods in three ways performance in both the total and separated flows visual inspection of hydrographs and values of the optimized parameterization we must stress that in the synthetic cases the flow time series used for calibration and performance assessment are not the same to calibrate we feed the algorithm with the time series resulting from the hydrograph separation method thereby reproducing a real case in which the base flow is unknown however we assess performance by comparison with the synthetic base flow so that we evaluate how the calibrated model reproduces the original partition instead of the approximation done by the hydrograph separation method 4 results 4 1 observed streamflow in the real scenario fig 5 shows the performance in the calibration and validation periods for the experiment 1 i e the real scenario calibrated against the observed streamflow left hand panels show the performance in terms of nse central panels for bias and the top right hand panel for the number of iterations required in each of the calibration phases results are organised by type of flow quick base or total and calibration method from 0 to 4 vertical gray lines indicate the distance to the target value of the objective function regarding the total flow there are four methods all but method 3 that performed good in both catchments total flow bias is close to zero and the nse can be classified as good around 0 6 except method 0 with values slightly lower than 0 5 method 3 has a strong negative bias in both catchments close to 50 and a poor nse below 0 4 we expected that the reference method method 0 would be the highest performing in terms of total flow since it uses the full power of the automatic algorithm to our surprise the reference method is the one with the lowest efficiency among those performing appropriately whereas methods applying flow separation methods 2 and 4 performed slightly better than the rest even for the total flow total flow performance in the validation period is basically similar method 3 misbehaves while the other four methods are still unbiased but show a certain loss in nse this loss is larger in the sella basin which causes that the efficiency in the sella model is lower than that of the cares model during the validation period contrary to what happened for the calibration period the four well performing models in terms of total flow behave differently when looking at the partition in quick and base flow the two methods without hydrograph separation methods 0 and 1 show a strong bias even larger than 100 quick flow in method 0 for the sella basin the nse for these two methods is poor for both separated flows close to 1 for the base flow and distinctly lower than the two methods that apply hydrograph separation methods 2 and 4 these last two methods are the ones with the highest performance the separated bias is close to null and the nse is larger than the rest of methods with the exception of base flow in the sella model the similar performance of these two methods comes from the fact that method 4 is a simplification of method 2 with a common quick flow calibration phase method 3 rejected in terms of total flow performance also misbehaves in the separated flows it shows negative bias in both quick and base flow stronger in the former whereas nse is poor for the quick flow 0 15 in average but acceptable for the base flow 0 35 in average similar to methods 2 and 4 the performance of separated flows in the validation period renders a similar behavior where methods 2 and 4 are those performing better as well as in the total flow the loss of efficiency in the validation is larger for the sella model this loss is more marked for the base than the quick flow both in terms of bias and nse the null variability in the number of iterations among catchment models is remarkable regardless of the catchment the number of iterations that sce ua requires to converge is controlled by the number of parameters to be optimized in a given phase this fact favours sequential calibration methods all but method 0 that instead of analysing an eight dimensional parameter space as many as parameters involved in runoff generation explore subsets of it the result is that sequential methods require a third of the number of iterations needed by the reference method this reduction in computation time is gained at the expense of a less exhaustive analysis of the parameter space and thus a lower probability of finding the global optimum the difference between sequential methods applying flow separation methods 2 3 and 4 and the common practice method 1 is that we use our knowledge about how the catchment may work to ensure optimized models with a proper flow partition the scatter plots in fig 6 provide an insight into the previous performance results the plots compare the observed flow q obs with the simulated flow q sim generated with the optimized parameterization each dot represents the pair of values for a day colours depict types of flow in order to show how the calibrated model reproduces flow partition in a perfect fit all the dots would be placed along the 1 1 line which means equal observed and simulated flow we must stress that in this experiment the observed quick and base flows are not actually observed but created with the hydrograph separation method this means that the partition has no real meaning nevertheless the results of the synthetic experiments supplementary material prove that the simplicity of the hydrograph separation method here employed was representative enough of the real behavior of the catchment a visual analysis shows that 5 out of the 10 plots represent a correct model namely method 1 in the sella basin and methods 2 and 4 in both basins method 0 optimized completely opposite models for the two basins whereas in the cares model base flow accounts for almost the entire total flow therefore quick flow is basically non existent in the sella model there is no base flow and the total flow is equal to the quick flow given the similar climate and geology in these two adjacent basins it is extremely unlikely that the two basins function in such a different manner most likely the real catchments do not behave in any of these extreme ways the cares model optimized by method 1 also suffers from an incorrect flow partition similarly to method 0 the model attributes almost the entire total flow to the base flow so there is no quick flow method 3 fails to reproduce quick flow probably due to a wrong parameterization of infiltration and percolation during the base flow fitting the optimized hyperparameter values obtained by each calibration method are shown in fig 7 each plot contains the values for a catchment hyperparameters are grouped by the type of flow they directly affect the dotted gray line spans the extreme optimized values to show the variability among methods parameter values are normalized by their search range table 2 to be able to show parameters with different orders of magnitude the four methods with an optimal total flow performance methods 0 1 2 and 4 optimized diverse parameterizations an example of the equifinality problem when comparing those methods that partition flow correctly methods 2 and 4 and method 1 in the sella basin the variability in the parameterizations is notably reduced fc 3 fc 5 fc 6 fc 7 fc 8 and fc 9 adopt similar values in the sella basin and parameterizations in the cares basin are almost identical for methods 2 and 4 this means that the parameter range that properly addresses flow partition is narrower than that which only reproduces correctly the total flow our approach attempts to guide the automatic calibration algorithm towards this limited range thus avoiding cases where a correct total flow calibration does not represent a realistic catchment functioning in the majority of cases the extreme optimized values correspond to one of the methods that could not reproduce the flow partition methods 0 and 3 and method 1 in the cares basin quick flow parameters show larger variability than the base and total flow parameters with the exception of fc 7 in the sella model the variability in the optimized values might be linked to the sensitivity of the parameter highly sensitive parameters have a narrow range of values with optimum performance pianosi et al 2016 so the calibrated parameter value is similar regardless of the calibration method therefore base and total flow parameters would be more sensitive than quick flow parameters 4 2 synthetic streamflow in the real scenario the results of this experiment are thoroughly commented on the supplementary material to summarize this experiment proved that the proposed correspondence between the quick and base flow time series resulting from hydrograph separation and those simulated with tetis is not perfect but approximate enough in terms of performance in the simulation of total flow only methods 1 and 2 obtained a high nse and a negligible bias in both catchments when analysing separated flows method 1 which does not apply flow separation is clearly outperformed by method 2 which does apply flow separation regarding optimized hyperparameter values none of the calibration methods was able to replicate the reference parameterization proving that the calibration methods here applied do not remove equifinality even in a simplified scenario such as a synthetic case however methods that apply flow separation get values closer among them and closer to the reference value these results prove that even though method 2 does not remove equifinality it can at least constrain it and force the calibration to get parameterizations closer to the reference and with a correct behavior in terms of runoff partition 4 3 hypothetical scenarios the results of this experiment are thoroughly commented on the supplementary material the eighteen calibrations carried out in this experiment are a perfect example of the problem of equifinality and the potential of the sequential methods here exposed when analysing the total flow performance all methods performed successfully both in terms of nse and bias as expected the reference method method 0 was the highest performing one the difference between methods appears when looking at the performance for the quick and base flow where methods that apply flow separation stand out specially method 2 in some scenarios method 0 represents the perfect example of the risk of granting physical meaning to an optimised model without further tests the simulation of total flow was utterly perfect but the partition clearly wrong methods applying flow separation instead reproduce adequately flow partition at the expense of a slight loss in total flow performance the automatic optimization algorithm could not find the reference parameterization in any of the hypothetical scenarios this is the case even for method 0 for which we allowed the algorithm to exhaustively explore the parameter space however methods using hydrograph separation 2 3 and 4 reduce the variability in the optimized hyperparameter values among scenarios hence constraining the equifinality problem 5 discussion the multiple cases here presented dwell in the difficulty of coping with the equifinality problem and the need to constrain the calibration process in order to tackle it we show how diverse parameterizations representing different catchment functioning are equivalent in terms of total flow performance our approach attempts to distinguish which of those parameterizations also reproduce the actual catchment processes which we represent by the partition of the total flow results show that the reference calibration method in which we apply no constraints in the parameter space to be evaluated outperforms the methods here designed in the hypothetical scenarios but not in the real scenario neither with a synthetic nor the observed streamflow as calibration target apart from that fact the reference method has two disadvantages in the first place in a considerable number of cases the method optimizes catchment models physically unfeasible i e in which the partition in quick and base flow is incorrect from our results this fact occurs in all the four real case scenarios and in three out of nine hypothetical scenarios in the second place this method is computationally less efficient than the sequential methods since the algorithm must explore at once the eight dimensional parameter space the number of iterations it requires is approximately 3 times larger than that needed in the sequential methods which explore subsets of that parameter space as a method in between the reference and the partition methods here developed we included the common practice of many hydrologists who calibrate models by sequentially fitting parameters always with the total streamflow as target results prove that this method outperforms the reference method in the real scenarios but is the one with the lowest performance in the hypothetical scenarios in both real and hypothetical scenarios it shows high performance in terms of total flow but it fails to reproduce flow partition in one out of four real scenarios and all of the nine hypothetical scenarios among the methods that apply flow separation method 2 stands out as the highest performing of all in this method we sequentially calibrate storages from top to bottom soil layers and lastly the streamflow routing the main attribute of this method is that it ensures a correct flow partition in all cases in the real scenario both synthetic and observed streamflow this method outperforms all of the others even unexpectedly for the total flow in the hypothetical scenarios the improvement in flow partition is gained at the expense of a slight loss of total flow performance when compared with the reference method because this method explores subsets of the parameter space it may not find the global optimum what explains the loss of total flow performance in the hypothetical scenarios but it reduces the computational effort to a third none of the methods is able to resolve the equifinality in the calibration of the conceptual hydrological model proof of that fact are the diverse parameterizations that performed correctly in the synthetic cases in which the calibration algorithm should have found similar parameter values to the reference parameterization the fact that the automatic calibration algorithm when applied with total freedom such as in method 0 has not been able to replicate neither the streamflow nor the parameterization in the synthetic cases of the real scenario raises doubts about its efficiency in real scenarios although equifinality is not removed the results show that constraining the global search in the parameter space such as in method 2 guides the automatic algorithm towards a reduced region in the parameter space with better performance and more importantly realistic catchment models this study does not attempt to invalidate sce ua as a global optimization algorithm but we draw attention to the importance of constraining the calibration of conceptual hydrological models in order to prevent equifinality from generating unrealistic catchment models this is of vital importance when the hydrological model is the starting point of a posterior analysis for instance erosion nutrient transport or vegetation dynamics we have employed the local minimum method to separate the total streamflow into its quick and base flow components which is a simplistic approach to prove that the simplicity of this method does not affect the outcomes of the study we evaluated its performance in synthetic cases both in the real and hypothetical scenarios the negligible bias between separated and synthetic flows see figure s1 proves that the separation method properly represents the flow partition in tetis however there is ground for improvement in this part applying more realistic separation methods such as those presented in duncan 2019 eckhardt apr 2008 chapman apr 1999 lyne and hollick 1979 or tracer methods if available will enhance the capabilities of the sequential calibration procedures here developed specifically in terms of base flow nse there is a limitation in this regard which is the representation of the aquifer s outflow in the hydrological model no matter how realistic the separation method is the base flow performance is limited to the ability of the model to simulate base flow which in the case of tetis seems to be excessively reactive giving support to the implementation of a cascade of linear reservoirs instead of a single one tallaksen 1995 future research might also deal with the idea of dividing streamflow in more than two components stoelzle et al 2020 if we could separate it in three components surface runoff interflow and base flow we could calibrate individually each of the three soil storage reservoirs involved in runoff generation boosting the advantages of the sequential calibration method here developed this approach may also improve the observed lack of sensitivity of the quick flow parameters by calibrating these 5 parameters in two instead of one single phase in this study we have not addressed equifinality in crucial processes such as snow melt processes and notably evapotranspiration represented in tetis by three specific storage reservoirs interception snowpack and static current research in our group deals with this shortcoming we are exploring how to incorporate remotely sensed products in the calibration of snow cover and evapotranspiration exploiting also the spatially distributed property of tetis koch et al 2015 demirel et al 2017 mendiguren et al 2017 koch et al 2018 bai et al 2018 tuo et al 2018 nemri and kinnard 2020 the results here presented are specific to a type of climate and hydrological regime we consider that the benefits of sequential calibration and flow partition can be extrapolated to other climates and hydrological regimes though further analyses must be done to prove it specially regarding the hydrograph separation method 6 conclusions in this study we have analyzed the equifinality in the calibration of a conceptual hydrological model and developed a sequential calibration method that limits its consequences the idea is to calibrate independently the outflows of the different runoff generating reservoirs in the hydrological model against a time series representative of that process to create these target time series we apply hydrograph separation using the local minimum method the study focuses on two mesoscale catchments in the northern side of the picos de europa national park spain in these two catchments we carried out three calibration experiments the real case scenario with both the observed and a synthetic streamflow as targets in the calibration and hypothetical scenarios of land cover and soil permeability with synthetic streamflows results prove that a sequential calibration method using separated flows leads the automatic calibration algorithm towards model parameterizations that better reproduce the runoff generating processes occurring in the catchment in the real scenario this procedure not only improves the performance for the separated flows but also for total streamflow only when applied to hypothetical scenarios of soil permeability and land cover the improved performance in the separated flows comes at the expense of a slight loss of total streamflow performance the constraints imposed in the sequential calibration procedures reduce the range in the parameter space of the behavioral models hence they reduce equifinality on top of the previous sequential calibration methods are computationally more efficient since they explore the parameter space in subspaces the setup of this study reduced the number of iterations in the optimization algorithm to a third this study presents a first promising attempt to use hydrograph separation to improve the calibration of conceptual hydrological models further research should implement more realistic separation methods that better reproduce the nature of base flow or decompose streamflow in more than two components we strongly suggest imposing constraints such as separated flows in the calibration of hydrological models to induce models that better reproduce catchment processes this is of grand importance if the purpose of hydrological model is not focused strictly on streamflow but to analyse catchment processes such as erosion impacts of land cover change groundwater recharge or nutrient cycling for instance credit authorship contribution statement jesús casado rodríguez conceptualization methodology software validation formal analysis data curation writing original draft visualization manuel del jesus methodology writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was originally funded by the spanish national research agency and the european regional development fund through the research project gesdivah ref bia2016 78397 p the first author is sponsored by the spanish ministry of education and vocational training through a pre doctoral scholarship fpu 17 05353 manuel del jesus acknowledges the financial support from the government of cantabria through the fénix programme the authors would like to thank josé manuel álvarez martínez for contributing the land cover map appendix a supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2022 127816 supplementary data the following are the supplementary data to this article supplementary data 1 
3296,as the most widespread natural hazard drought has significant impacts on the livelihood and ecosystems in the lancang mekong river basin lmrb however few studies focus on the seasonal characteristics of drought in the lmrb especially under future climate projections by the sixth phase of coupled model inter comparison project cmip6 this study filled the knowledge gap using spi and spei based on eight gcms of cmip6 under three scenarios i e ssp1 2 6 ssp2 4 5 ssp5 8 5 our results show that the lmrb tends to experience wetter wet season and drier dry season with the rising temperature considered based on spei while the temporal trend of dry season spi is not significant the future trends of spei are 0 006 per year and 0 011 per year under ssp2 4 5 and ssp5 8 5 respectively the trend magnitudes demonstrate spatial heterogeneities our evaluation based on spei shows that the most notable increases of dry season drought in terms of duration and intensity are distributed in the middle reaches of lmrb the upper lancang and middle mekong basin will likely experience more wet season droughts the dry season drought accounts for 60 of total drought events in the near future i e 2021 2055 and more than 80 in the far future i e 2061 2095 under ssp2 4 5 effective strategies are needed to enhance food and drinking water security in the lmrb especially for the dry seasons under a changing climate keywords lancang mekong river seasonal drought climate change water security cmip6 1 introduction drought is one of the most common and harmful natural hazards according to the international disaster database em dat 2021 drought accounts for 59 economic losses induced by climate related extremes li et al 2021a many parts of the world are experiencing more frequent droughts in recent decades cook et al 2020 kang et al 2021 droughts have hit the lancang mekong river basin lmrb several times in the last 30 years and are becoming even more severe over the last decade kang and sridhar 2020 kang et al 2021 liu 2021 liu et al 2020 te 2007 tian and liu 2016 the negative impacts of drought demonstrate many facets including water supplies orth and destouni 2018 environment yang et al 2016 and agriculture lesk et al 2016 especially for regional agriculture due to the nature of the uneven spatial and temporal distribution of droughts li et al 2021a zhang et al 2020 some previous studies have examined future drought characteristics in the mekong river basin mrb for instance previous studies show that the lower mrb may experience more severe and intense droughts which will be more unevenly distributed compared to the historical period li et al 2021b thilakarathne and sridhar 2017 wang et al 2021 assessed global drought characteristics using multiple indicators based on eleven cmip6 models their results suggest that future droughts will increase in most parts of the world with changes in evapotranspiration as one of the key factors however few studies have focused on the seasonal characteristics of drought in the lmrb especially based on the new cmip6 results our study area is the lmrb it is located in the asian monsoon region with distinct wet season and dry season wet season precipitation accounts for 80 of annual precipitation liu 2021 the drought characteristics during the dry season are not paid enough attention due to the small percentage of annual precipitation in this season agriculture is indeed the primary source of income for the inhabitants of the lmrb farming in the lmrb has seasonal characteristics tens of thousands of farmers across the basin produce the second or even third rice crop each year the irrigation facilities are overwhelmingly used for rice crops during the wet season with a low assured rate of rice crops during the dry season according to kang et al 2021 food production must increase by 50 approximately 80 million tons during the next 30 years to satisfy the food demand from a 50 expansion in population however there are large areas with a low ratio of equipped irrigation in the lmrb the mekong river commission mrc is uncertain about whether the storage of upstream reservoir development is able to meet the potential increased irrigation demand under climate change mrc 2021 on the other hand drinking water security is another one of the concerns in this region mrc 2021 it is suggested that the water infrastructures should be further enhanced and the potentials of existing projects should be exploited liu 2021 it remains unsettled where and when the structural and non structural measures will be needed the most therefore the seasonal characteristics of future drought should be examined the newly available cmip6 maybe further explored for relative studies here both standardized precipitation index spi and standardized precipitation evapotranspiration index spei are employed to investigate future meteorological drought under a changing climate we examine the temporal trend and spatial pattern duration and intensity in the wet season dry season and the whole year we expect to provide a new understanding of future drought in the lmrb and provide valuable information for water related decision makers our results are based on the new cmip6 results that can better capture the key elements of future climate conditions 2 data and methodology 2 1 study area the lmrb 93 45 108 50 e 8 27 33 54 n is located in the southeast part of asia fig 1 the lancang mekong river lmr originates from yushu tibetan autonomous prefecture qinghai china it is known as the mekong river after flowing out of china from xishuangbanna dai autonomous prefecture yunnan china the river flows through six countries including china myanmar lao pdr thailand cambodia and vietnam and pours into the south china sea west of ho chi minh city vietnam the lmr is approximately 4 880 km long with a drainage area of 795 000 km2 and an average annual runoff volume of 475 km3 it is one of southeast asia s seven most important rivers and the tenth longest river in the world with the eleventh highest annual water supply the mekong river in particular has a drainage area of 630 600 km2 a length of 2 750 km and an average annual runoff volume of 410 9 km3 accounting for 79 56 and 86 5 of the entire lmr respectively the river flows through a slope of 5 060 m from its source in the qinghai tibet plateau to the estuary with an average gradient of 1 04 mrc and mwr 2016 because lmrb is located in the transitional zone of asian monsoons there are two distinct seasons in the basin i e wet season and dry season the start of the wet and dry seasons vary depend on the arrivals of monsoons over the upper and lower basins in this study we define the wet season as june to november and the dry season as december to may of the following year jacobs 2002 mrc and mwr 2016 the average annual temperature is calculated based on the era5 land temperature during 1981 2014 the temperature gradually rises from upstream to downstream with 8 0 c at the river source area and 20 7 c at yunjinghong close to the chinese border the temperature is relatively uniform within the mekong river basin the average annual temperature is between 20 and 28 c the average relative humidity is slightly greater than 80 in september while it is only 60 in march liu 2021 2 2 future climate projections the most recent cmip6 model simulations have enhanced the performance of temperature and regional rainfall projections eyring et al 2019 gusain et al 2020 long et al 2021 thorarinsdottir et al 2020 zhou et al 2019 in this study we choose three scenarios i e ssp1 rcp2 6 ssp1 2 6 ssp2 rcp4 5 ssp2 4 5 and ssp5 rcp8 5 ssp5 8 5 riahi et al 2011 thomson et al 2011 historical simulations 1850 to 2014 and projections 2015 to 2100 from eight cmip6 gcms are employed in this study see table 1 for details the climatic variables include daily maximum near surface air temperature tasmax in k daily minimum near surface air temperature tasmin in k daily mean near surface air temperature tasmean k precipitation rate pr in mm day near surface wind speed sfcwind in m s near surface eastward component of wind uas in m s near surface northward component of wind vas in m s these gcms have been widely used in previous studies cook et al 2020 grose et al 2020 jiang et al 2020 li et al 2021a song et al 2021 xu et al 2021 zhang et al 2021 and have projections of all the three selected scenarios with the whole time span of this research needed the entire study period was divided into three 35 year periods for equal comparison i e history from 1980 to 2014 near future nf from 2021 to 2055 and far future ff from 2061 to 2095 we interpolate the gcm model grids of different spatial resolutions into 0 1 by extracting the grid value that is the closest to the grid point 2 3 reference data provided by the european centre for medium range weather forecasts ecmwf era5 land provides worldwide hourly high resolution data for a more accurate representation of the water and energy cycles muñoz sabater et al 2021 hourly data with a spatial resolution of 0 1 is available previous studies show that the temperature and precipitation biases in era5 land are consistently lower than other reanalysis products e g era interim tarek et al 2020 nogueira 2020 show the rainfall anomalies correlation is around 0 9 1 0 in the entire lmrb region making it reasonable to derive drought indexes i e spi and spei in this study we use four variables i e total precipitation in mm 2 m temperature in k 10 m wind in both the eastward and northward component of the 10 m wind in m s 2 4 drought indices spi spei the metrics of drought include duration d area a intensity i and severity s the number of consecutive months in which the running mean drought index remained below the drought threshold is referred to as duration while the number of drought events throughout the time is referred to as frequency fig 2 during a drought intensity is the difference between the drought threshold and the monthly running mean drought index averaged over all months the cumulative intensity of drought across an area throughout the drought is referred to as severity ukkola et al 2020 the spi and the spei are two meteorological drought indices spi was introduced in 1993 as a computed drought index based on precipitation records mckee et al 1993 in addition spi has become a commonly used indicator for drought diagnosis worldwide guo et al 2017 liu et al 2016 song et al 2021 wang et al 2021 the world meteorological organization wmo recommends spi as a reference drought index guo et al 2017 hao and aghakouchak 2014 vicente serrano et al 2010 proposed spei to account for the impact of temperature on drought spei is based on precipitation and temperature it has the advantage of combining multi scale characteristics with the capacity to include the effects of temperature variability on drought assessment vicente serrano et al 2010 similar to spi spei has been widely used in drought assessment and is considered to be a reliable index for regional drought monitoring and analysis under global climate change li et al 2021a liu et al 2016 tirivarombo et al 2018 wang et al 2021 this study uses spi and spei for meteorological droughts analysis we set the threshold as 0 5 a threshold of abnormally dry used by u s drought monitor the following is a typical spi calculation procedure 1 precipitation series is fitted to a gamma γ distribution 2 a normal standardization of a skewed probability distribution is performed and 3 drought is graded using the cumulative frequency of standardized precipitation distribution the spi is a meteorological drought monitoring and evaluation indicator that applies on or above the monthly scale and expresses the probability of precipitation occurring in a given period spi has been widely used to illustrate meteorological drought in recent years due to its easy access to data simple calculation adjustable temporal scale and regional comparability the formula to calculate spi are as follows mckee et al 1993 1 s p i s t c 2 t c 1 t c 0 d 3 t d 2 t d 1 t 1 0 2 t ln 1 g x 2 where x is precipitation sample value s is the positive and negative coefficients of probability density c0 c1 c2 and d1 d2 d3 are calculation parameters of the simplified approximation analysis formula for converting γ distribution probability into cumulative frequency and c0 2 515517 c1 0 802853 c2 0 010328 d1 1 432788 d2 0 189269 and d3 0 001308 g x is the rainfall distribution probability related to the γ function according to the probability density integral formula of γ function is 3 g x 2 β γ τ γ 0 0 x x γ 1 e x β d x x 0 where s 1 when g x 0 5 s 1 when g x 0 5 the method for calculating spei is identical to that for the spi rather than using precipitation spei is based on the concept of climatic water balance i e the difference between precipitation and potential evapotranspiration pet as the input beguería et al 2014 the hargreaves method is used to calculate pet hargreaves and samani 1985 it is a straightforward method that can be used instead of the penman monteith method which relies solely on temperature observations to calculate reference evapotranspiration althoff et al 2019 the penman monteith and hargreaves methods show reasonable agreement with reference datasets in previous studies droogers and allen 2002 the spi spei calculation time scale range from 1 to 48 months or longer and are expressed as spi1 spei1 spi2 spei2 and spi48 spei48 wmo 2012 in sections 3 2 and 3 4 spi12 spei12 in december was used to investigate the trend and intensity of drought at the annual scale spi6 spei6 in may and november calculated based on the data of the past six months were used to represent the dry season and the wet season respectively spi3 spei3 were used in sections 3 1 3 3 and 3 5 this is because the 3 month scale index could reflect drought characteristics and the widespread impact of seasonal drought in tropical and temperate regions they can be more effective in highlighting available moisture conditions in primary agricultural regions guo et al 2017 wmo 2012 ukkola et al 2020 2 5 mann kendall trend test the mann kendall mk test is a non dimensional statistical method used to detect trends in time series kendall and gibbons 1990 mann 1945 and is recommend by the world meteorological organization wmo for trend analysis liu et al 2016 the mann kendall test was employed to examine the temporal trend of spi and spei in this study for all results the significance of the trend was tested at the 5 level 3 results 3 1 comparison of cmip6 and era5 land based results we compared the spi spei results during the historical period 1981 2014 based on cmip6 and era5 land data to verify the reliability of the average of eight gcms from cmip6 drought metrics of duration intensity and severity were analyzed based on spi3 spei3 the probability curve of spi drought duration and intensity based on the two datasets were very close with comparable spatial patterns in drought duration and intensity across the basin fig 3 this indicates that the cmip6 could faithfully reflect historical spi drought characteristics in this region there are slightly more differences in drought severity fig 3g i this is mainly because severity reflects the accumulation of intensity differences during the whole timespan the performance of spei drought metrics were further investigated as can be seen from fig 3 compared with the good agreement of spi the spei curves by cmip6 and era5 land showed larger differences indicating that the prediction of future spei may have greater uncertainty than that of spi the direction of change in spei is consistent with spi with the spei distribution located on the right side of spi spei and spi results based on era5 land varied more dramatically than those based on cmip6 one possible reason is the cmip6 results were based on the average of eight gcms with some spatially heterogeneous features homogenized resulting in less significant changes while era5 land is a reanalysis dataset that integrates observational information the spatial resolution of era5 land is also higher than that of cmip6 the large variation of spei may be due to more variables involved than spi resulting in a different probability density distribution curve 3 2 future trend of drought table 2 and fig 4 illustrate the temporal trend of spi and spei in the entire lmrb the spatial distribution of evolution trend in the lmrb is shown in figs 5 and 6 the lmrb will become wetter in the wet season as demonstrated by spi fig 4a b c and fig 5 but the trend is not statistically significant in the dry season however as indicated by spei fig 4d e f and fig 6 lmrb will become wetter in the wet season and drier in the dry season in the future due to the influence of increasing temperature under a warming climate there is a rising trend of spi in the whole year and wet season of the lmrb under ssp2 4 5 and ssp5 8 5 table 2 but no significant trend in the dry season under ssp2 4 5 and ssp5 8 5 the whole year spi i e spi12 of december increased by 0 011 per year and 0 016 per year respectively across the entire basin the dry season spi i e spi6 in may increased by 0 002 per year and 0 003 per year respectively not statistically significant the wet season spi i e spi6 of november show significant increases i e 0 012 per year and 0 017 per year under ssp2 4 5 and ssp5 8 5 respectively the whole year spei and wet season spei of the lmrb show slight increases whereas the dry season spei is decreased table 2 the results indicate that drought tend to be more severe throughout the dry season while the wet season and the whole year tend to experience less severe drought under ssp2 4 5 and ssp5 8 5 the whole year spei i e spei12 of december increased by 0 003 per year and 0 005 per year the wet season spei i e spei6 of november increased by 0 007 per year and 0 012 per year respectively for the entire basin whereas the dry season spei i e spei6 in may will decrease by 0 006 per year and 0 011 per year respectively in terms of the spi the right bank of the middle reach the eastern border region of the lower reach and the delta region of the lmrb would be more drought prone during the dry season fig 5a d and g the contrary is true over the entire basin during the wet season fig 5b e and h and throughout the year fig 5c f and i the eight cmip6 models demonstrate notable consistence in terms of the changes in the whole year and wet season see the stippling area in fig 5 in terms of the spei except for a portion of the lancang river basin lrb most of the lmrb would experience more severe drought throughout the dry season fig 6a d and g during the wet season drought would be weakened across a large portion of the basin fig 6b e and h in terms of the whole year the middle lancang and the middle mekong would experience more severe drought whereas the rest of the basin would be wetter fig 6c f and i 3 3 projections of drought duration we compare two future periods i e near future nf 2021 2055 and far future ff 2061 2095 with the historical period history 1980 2014 to analyze changes in future drought duration in different seasons see appendix for details based on these results most of the lmrb will experience extended drought throughout the dry season in nf and ff drought duration is shortened in most subbasins during the wet season except the upper lancang and middle mekong regions in the nf for the whole year more extended drought will persist in the middle lancang and middle mekong reaches the details are illustrated as follows the drought durations during the three periods and the changes between them are estimated for spi fig s1 s3 compared to the historical period the annual drought duration in fig s1 is reduced for most regions in the nf except for the lower lancang region the nf and ff both showed greater drought duration in the middle reach of the lrb and the eastern border area of the basin with the largest increases in the middle lancang when we examined drought duration variations in the dry season fig s2 for the wet season the nf and ff show shorter drought duration in most parts of the basin fig s3 the differences between the three ssp scenarios are limited the ff will experience shorter drought durations from the perspective of the whole basin the results for spei are shown in fig s4 s6 except for cambodia and the delta region the annual drought duration is longer for most regions under ssp2 4 5 and ssp5 8 5 fig s4 the nf and ff show longer drought duration in most parts of the basin with the largest increases in the lower lancang and the middle mekong in the dry season fig s5 the results of ssp5 8 5 are often more pronounced than those of ssp2 4 5 for the wet season the nf sees shorter drought duration in the southern part and regions of myanmar and northern laos fig s6 at the same time the greater drought duration is recorded in the central mekong region and parts of the lrb the results for the three ssp scenarios show limited differences the ff registers shorter drought durations from the perspective of the whole basin 3 4 projections of drought intensity for spi the nf and ff record weakened annual and wet season drought intensity over a large part of the region while higher intensity area may expand in the dry season fig s7 to fig s9 for the spei the nf and ff both recorded higher annual drought intensity in the upper lancang mekong region and areas on the left bank the intensified area may expand in the dry season and shrink in the wet season fig s10 to fig s12 the details are as follows for spi the nf and ff both register weakened annual drought intensity in large parts of the region with uneven spatial distribution fig s7 the nf records more areas with more intensified or less weakened drought intensity in general than the ff in most basin areas except the upper lancang the dry season drought intensified under ssp5 8 5 in the ff fig s8 the wet season shows reduced drought intensity in most areas of the basin except for some hot spots fig s9 under the three different scenarios changes in nf show a substantial spatial diversity under ssp5 8 5 the middle reaches of the lrb myanmar and north laos show more severe drought while other areas might experience reduced drought hazards for spei compared with the historical period the nf and ff both record stronger annual drought intensity in the upper lancang mekong region and its left bank with weakened annual intensity on the right bank in thailand and the delta region fig s10 in the dry season drought intensity increases in most basin areas under ssp2 4 5 and ssp5 8 5 except for areas in the se kong se san sre pok river basin fig s11 in the wet season except for a small fraction in the upper lancang and other spotted areas drought intensity decreases in most areas of the basin in the ff fig s12 changes in the nf show a considerable spatial diversity under three different scenarios the river source area in the lrb in particular registers greater drought intensity fig s12 3 5 projections of seasonal drought distribution the seasonal distribution of meteorological drought in the future is illustrated in table 3 generally the dry season drought accounts for a larger proportion than the wet season under ssp1 2 6 the dry season drought approaches 55 of total drought events in the nf for all drought grades the percentage is above 80 in the ff for severe and exceptional drought the percentage of the dry season is 67 to 100 under ssp2 4 5 the dry season drought accounts for 60 of total drought events in the nf for all drought grades the percentage is also above 80 in the ff the dry season drought percentage is over 60 for severe and exceptional drought the ff results under ssp5 8 5 are similar to those under ssp2 4 5 with notable differences between the dry and wet seasons 4 discussion 4 1 comparison with other researches several studies have assessed future drought changes based on cmip5 and cmip6 in the lmrb for instance based on cmip5 thilakarathne and sridhar 2017 characterized the future drought conditions in the lower mekong basin lmb their results suggested that the lower lmb and the se kong se san sre pok subbasins expected to experience more severe and intense droughts li et al 2021b used spi spei and ssi to assess meteorological and hydrological droughts in the lmrb and its surrounding areas their results showed that the meteorological drought in the northeastern part of the study area might intensify during 2010 2039 the increasing trend is followed by a reduction in drought after the year 2039 based on cmip6 wang et al 2021 assessed drought characteristics at global scale based on multiple indicators from eleven cmip6 models the variation of spei in the mekong river region is larger than that of spi with larger future drought duration changes by spei than that by spi in the region previous studies show that the southeast asian region would experience more droughts under the scenarios ssp1 2 6 ssp2 4 5 and ssp5 8 5 li et al 2021a zeng et al 2022 our results are overall consistent with previous studies based on the cmip6 model projections our analyses further investigate the seasonal drought characteristics in the lmrb 4 2 bias of eight gcms our results are primarily based on the average of eight cmip6 models under three different scenarios there are variations in terms of the temporal trends of drought among the eight cmip6 models similarly see e g chen and yuan 2021 grose et al 2020 li et al 2021a song et al 2021 wang et al 2021 however our analyses show that the eight gcms are highly consistent in terms of the temporal trends and drought characteristics in the lmrb see figs 5 and 6 for details the average of eight cmip6 models also show good consistency with era5 land in the historical period fig 3 the consistency among the eight cmip6 models in terms of future changes in drought duration and intensity is only evident when there are large change rates this indicates that the cmip6 models might be more consistent in projecting extreme climate conditions 4 3 seasonal drought impact it is commonly recognized that crop yield would be affected by drought our study shows a wetting tendency in the wet season but a drying tendency in the dry season in the lmrb this kind of change will benefit agricultural production in the wet season but do harms in the dry season however previous studies on future rice yields do not agree with each other for instance thuy and anh 2015 suggested that rice yields would decrease in the mekong river delta in the future while some studies show that co2 fertilization is an important factor for crop yield under the climate change according to kang et al 2021 the increase in precipitation and co2 concentration in the lower mekong basin could result in 24 to 43 increases in rice yield kontgis et al 2019 used a model to estimate future rice yields they found that rice yields will decrease if co2 fertilization is not considered according to tsujimoto et al 2022 the main factor restricting future rice production is soil wetness related to the projected changes in the seasonal distribution of rainfall considering the uneven distribution of irrigation equipment and spatially heterogeneous changes in future drought additional studies need to investigate how future changes in drought influence food and water security in the lmrb and explore possible mitigation and adaptation strategies 5 conclusion based on the average of eight cmip6 models under three climate change scenarios we examine the future drought characteristics using spi and spei in the lmrb we highlight the contrasting changes in the dry and wet seasons the conclusions are as follows 1 the average of eight cmip6 models shows a good consistency with era5 land in historical drought analysis the consistency is higher based on spi than spei even though both indices are applicable for drought projection 2 the lmrb witnesses significant increases in the dry season drought based on spei as well as significant decreases in annual and wet season drought based on spi and spei under ssp2 4 5 and ssp5 8 5 the future trend in dry season spei is 0 006 per year and 0 011 per year under ssp2 4 5 and ssp5 8 5 respectively the trends demonstrate spatial variability in the entire basin 3 based on spei the largest increases in dry season drought duration and intensity are projected in the middle reaches of the lmrb while longer drought duration and higher drought intensity in the wet season are expected in the upper lancang and middle mekong river 4 future drought would be more severe in the dry season for instance the dry season drought would account for approximately 60 in the near future and above 80 in the far future under the ssp2 4 5 scenario since future drought in the dry season is likely to become more severe in the lmrb we suggest that further studies should be carried out to investigate the potential impacts of future drought possible measures e g high efficient water utilization water redistribution projects are needed to enhance the water security in this populous region credit authorship contribution statement zhiqiang dong writing original draft investigation validation visualization hui liu conceptualization writing review editing funding acquisition resources formal analysis methodology baiyinbaoligao conceptualization writing review editing hongchang hu writing review editing methodology funding acquisition mohd yawar ali khan writing review editing jie wen writing review editing lajiao chen methodology writing review editing fuqiang tian writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by the lancang mekong cooperation fund 126301001000200041 126301001000210002 the second tibetan plateau scientific expedition and research program step no 2019qzkk0903 and national natural science foundation of china nsfc51879136 and state key laboratory of hydroscience and engineering 22 ky 03 we thank the anonymous reviewers for their valuable comments and suggestions appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127815 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3296,as the most widespread natural hazard drought has significant impacts on the livelihood and ecosystems in the lancang mekong river basin lmrb however few studies focus on the seasonal characteristics of drought in the lmrb especially under future climate projections by the sixth phase of coupled model inter comparison project cmip6 this study filled the knowledge gap using spi and spei based on eight gcms of cmip6 under three scenarios i e ssp1 2 6 ssp2 4 5 ssp5 8 5 our results show that the lmrb tends to experience wetter wet season and drier dry season with the rising temperature considered based on spei while the temporal trend of dry season spi is not significant the future trends of spei are 0 006 per year and 0 011 per year under ssp2 4 5 and ssp5 8 5 respectively the trend magnitudes demonstrate spatial heterogeneities our evaluation based on spei shows that the most notable increases of dry season drought in terms of duration and intensity are distributed in the middle reaches of lmrb the upper lancang and middle mekong basin will likely experience more wet season droughts the dry season drought accounts for 60 of total drought events in the near future i e 2021 2055 and more than 80 in the far future i e 2061 2095 under ssp2 4 5 effective strategies are needed to enhance food and drinking water security in the lmrb especially for the dry seasons under a changing climate keywords lancang mekong river seasonal drought climate change water security cmip6 1 introduction drought is one of the most common and harmful natural hazards according to the international disaster database em dat 2021 drought accounts for 59 economic losses induced by climate related extremes li et al 2021a many parts of the world are experiencing more frequent droughts in recent decades cook et al 2020 kang et al 2021 droughts have hit the lancang mekong river basin lmrb several times in the last 30 years and are becoming even more severe over the last decade kang and sridhar 2020 kang et al 2021 liu 2021 liu et al 2020 te 2007 tian and liu 2016 the negative impacts of drought demonstrate many facets including water supplies orth and destouni 2018 environment yang et al 2016 and agriculture lesk et al 2016 especially for regional agriculture due to the nature of the uneven spatial and temporal distribution of droughts li et al 2021a zhang et al 2020 some previous studies have examined future drought characteristics in the mekong river basin mrb for instance previous studies show that the lower mrb may experience more severe and intense droughts which will be more unevenly distributed compared to the historical period li et al 2021b thilakarathne and sridhar 2017 wang et al 2021 assessed global drought characteristics using multiple indicators based on eleven cmip6 models their results suggest that future droughts will increase in most parts of the world with changes in evapotranspiration as one of the key factors however few studies have focused on the seasonal characteristics of drought in the lmrb especially based on the new cmip6 results our study area is the lmrb it is located in the asian monsoon region with distinct wet season and dry season wet season precipitation accounts for 80 of annual precipitation liu 2021 the drought characteristics during the dry season are not paid enough attention due to the small percentage of annual precipitation in this season agriculture is indeed the primary source of income for the inhabitants of the lmrb farming in the lmrb has seasonal characteristics tens of thousands of farmers across the basin produce the second or even third rice crop each year the irrigation facilities are overwhelmingly used for rice crops during the wet season with a low assured rate of rice crops during the dry season according to kang et al 2021 food production must increase by 50 approximately 80 million tons during the next 30 years to satisfy the food demand from a 50 expansion in population however there are large areas with a low ratio of equipped irrigation in the lmrb the mekong river commission mrc is uncertain about whether the storage of upstream reservoir development is able to meet the potential increased irrigation demand under climate change mrc 2021 on the other hand drinking water security is another one of the concerns in this region mrc 2021 it is suggested that the water infrastructures should be further enhanced and the potentials of existing projects should be exploited liu 2021 it remains unsettled where and when the structural and non structural measures will be needed the most therefore the seasonal characteristics of future drought should be examined the newly available cmip6 maybe further explored for relative studies here both standardized precipitation index spi and standardized precipitation evapotranspiration index spei are employed to investigate future meteorological drought under a changing climate we examine the temporal trend and spatial pattern duration and intensity in the wet season dry season and the whole year we expect to provide a new understanding of future drought in the lmrb and provide valuable information for water related decision makers our results are based on the new cmip6 results that can better capture the key elements of future climate conditions 2 data and methodology 2 1 study area the lmrb 93 45 108 50 e 8 27 33 54 n is located in the southeast part of asia fig 1 the lancang mekong river lmr originates from yushu tibetan autonomous prefecture qinghai china it is known as the mekong river after flowing out of china from xishuangbanna dai autonomous prefecture yunnan china the river flows through six countries including china myanmar lao pdr thailand cambodia and vietnam and pours into the south china sea west of ho chi minh city vietnam the lmr is approximately 4 880 km long with a drainage area of 795 000 km2 and an average annual runoff volume of 475 km3 it is one of southeast asia s seven most important rivers and the tenth longest river in the world with the eleventh highest annual water supply the mekong river in particular has a drainage area of 630 600 km2 a length of 2 750 km and an average annual runoff volume of 410 9 km3 accounting for 79 56 and 86 5 of the entire lmr respectively the river flows through a slope of 5 060 m from its source in the qinghai tibet plateau to the estuary with an average gradient of 1 04 mrc and mwr 2016 because lmrb is located in the transitional zone of asian monsoons there are two distinct seasons in the basin i e wet season and dry season the start of the wet and dry seasons vary depend on the arrivals of monsoons over the upper and lower basins in this study we define the wet season as june to november and the dry season as december to may of the following year jacobs 2002 mrc and mwr 2016 the average annual temperature is calculated based on the era5 land temperature during 1981 2014 the temperature gradually rises from upstream to downstream with 8 0 c at the river source area and 20 7 c at yunjinghong close to the chinese border the temperature is relatively uniform within the mekong river basin the average annual temperature is between 20 and 28 c the average relative humidity is slightly greater than 80 in september while it is only 60 in march liu 2021 2 2 future climate projections the most recent cmip6 model simulations have enhanced the performance of temperature and regional rainfall projections eyring et al 2019 gusain et al 2020 long et al 2021 thorarinsdottir et al 2020 zhou et al 2019 in this study we choose three scenarios i e ssp1 rcp2 6 ssp1 2 6 ssp2 rcp4 5 ssp2 4 5 and ssp5 rcp8 5 ssp5 8 5 riahi et al 2011 thomson et al 2011 historical simulations 1850 to 2014 and projections 2015 to 2100 from eight cmip6 gcms are employed in this study see table 1 for details the climatic variables include daily maximum near surface air temperature tasmax in k daily minimum near surface air temperature tasmin in k daily mean near surface air temperature tasmean k precipitation rate pr in mm day near surface wind speed sfcwind in m s near surface eastward component of wind uas in m s near surface northward component of wind vas in m s these gcms have been widely used in previous studies cook et al 2020 grose et al 2020 jiang et al 2020 li et al 2021a song et al 2021 xu et al 2021 zhang et al 2021 and have projections of all the three selected scenarios with the whole time span of this research needed the entire study period was divided into three 35 year periods for equal comparison i e history from 1980 to 2014 near future nf from 2021 to 2055 and far future ff from 2061 to 2095 we interpolate the gcm model grids of different spatial resolutions into 0 1 by extracting the grid value that is the closest to the grid point 2 3 reference data provided by the european centre for medium range weather forecasts ecmwf era5 land provides worldwide hourly high resolution data for a more accurate representation of the water and energy cycles muñoz sabater et al 2021 hourly data with a spatial resolution of 0 1 is available previous studies show that the temperature and precipitation biases in era5 land are consistently lower than other reanalysis products e g era interim tarek et al 2020 nogueira 2020 show the rainfall anomalies correlation is around 0 9 1 0 in the entire lmrb region making it reasonable to derive drought indexes i e spi and spei in this study we use four variables i e total precipitation in mm 2 m temperature in k 10 m wind in both the eastward and northward component of the 10 m wind in m s 2 4 drought indices spi spei the metrics of drought include duration d area a intensity i and severity s the number of consecutive months in which the running mean drought index remained below the drought threshold is referred to as duration while the number of drought events throughout the time is referred to as frequency fig 2 during a drought intensity is the difference between the drought threshold and the monthly running mean drought index averaged over all months the cumulative intensity of drought across an area throughout the drought is referred to as severity ukkola et al 2020 the spi and the spei are two meteorological drought indices spi was introduced in 1993 as a computed drought index based on precipitation records mckee et al 1993 in addition spi has become a commonly used indicator for drought diagnosis worldwide guo et al 2017 liu et al 2016 song et al 2021 wang et al 2021 the world meteorological organization wmo recommends spi as a reference drought index guo et al 2017 hao and aghakouchak 2014 vicente serrano et al 2010 proposed spei to account for the impact of temperature on drought spei is based on precipitation and temperature it has the advantage of combining multi scale characteristics with the capacity to include the effects of temperature variability on drought assessment vicente serrano et al 2010 similar to spi spei has been widely used in drought assessment and is considered to be a reliable index for regional drought monitoring and analysis under global climate change li et al 2021a liu et al 2016 tirivarombo et al 2018 wang et al 2021 this study uses spi and spei for meteorological droughts analysis we set the threshold as 0 5 a threshold of abnormally dry used by u s drought monitor the following is a typical spi calculation procedure 1 precipitation series is fitted to a gamma γ distribution 2 a normal standardization of a skewed probability distribution is performed and 3 drought is graded using the cumulative frequency of standardized precipitation distribution the spi is a meteorological drought monitoring and evaluation indicator that applies on or above the monthly scale and expresses the probability of precipitation occurring in a given period spi has been widely used to illustrate meteorological drought in recent years due to its easy access to data simple calculation adjustable temporal scale and regional comparability the formula to calculate spi are as follows mckee et al 1993 1 s p i s t c 2 t c 1 t c 0 d 3 t d 2 t d 1 t 1 0 2 t ln 1 g x 2 where x is precipitation sample value s is the positive and negative coefficients of probability density c0 c1 c2 and d1 d2 d3 are calculation parameters of the simplified approximation analysis formula for converting γ distribution probability into cumulative frequency and c0 2 515517 c1 0 802853 c2 0 010328 d1 1 432788 d2 0 189269 and d3 0 001308 g x is the rainfall distribution probability related to the γ function according to the probability density integral formula of γ function is 3 g x 2 β γ τ γ 0 0 x x γ 1 e x β d x x 0 where s 1 when g x 0 5 s 1 when g x 0 5 the method for calculating spei is identical to that for the spi rather than using precipitation spei is based on the concept of climatic water balance i e the difference between precipitation and potential evapotranspiration pet as the input beguería et al 2014 the hargreaves method is used to calculate pet hargreaves and samani 1985 it is a straightforward method that can be used instead of the penman monteith method which relies solely on temperature observations to calculate reference evapotranspiration althoff et al 2019 the penman monteith and hargreaves methods show reasonable agreement with reference datasets in previous studies droogers and allen 2002 the spi spei calculation time scale range from 1 to 48 months or longer and are expressed as spi1 spei1 spi2 spei2 and spi48 spei48 wmo 2012 in sections 3 2 and 3 4 spi12 spei12 in december was used to investigate the trend and intensity of drought at the annual scale spi6 spei6 in may and november calculated based on the data of the past six months were used to represent the dry season and the wet season respectively spi3 spei3 were used in sections 3 1 3 3 and 3 5 this is because the 3 month scale index could reflect drought characteristics and the widespread impact of seasonal drought in tropical and temperate regions they can be more effective in highlighting available moisture conditions in primary agricultural regions guo et al 2017 wmo 2012 ukkola et al 2020 2 5 mann kendall trend test the mann kendall mk test is a non dimensional statistical method used to detect trends in time series kendall and gibbons 1990 mann 1945 and is recommend by the world meteorological organization wmo for trend analysis liu et al 2016 the mann kendall test was employed to examine the temporal trend of spi and spei in this study for all results the significance of the trend was tested at the 5 level 3 results 3 1 comparison of cmip6 and era5 land based results we compared the spi spei results during the historical period 1981 2014 based on cmip6 and era5 land data to verify the reliability of the average of eight gcms from cmip6 drought metrics of duration intensity and severity were analyzed based on spi3 spei3 the probability curve of spi drought duration and intensity based on the two datasets were very close with comparable spatial patterns in drought duration and intensity across the basin fig 3 this indicates that the cmip6 could faithfully reflect historical spi drought characteristics in this region there are slightly more differences in drought severity fig 3g i this is mainly because severity reflects the accumulation of intensity differences during the whole timespan the performance of spei drought metrics were further investigated as can be seen from fig 3 compared with the good agreement of spi the spei curves by cmip6 and era5 land showed larger differences indicating that the prediction of future spei may have greater uncertainty than that of spi the direction of change in spei is consistent with spi with the spei distribution located on the right side of spi spei and spi results based on era5 land varied more dramatically than those based on cmip6 one possible reason is the cmip6 results were based on the average of eight gcms with some spatially heterogeneous features homogenized resulting in less significant changes while era5 land is a reanalysis dataset that integrates observational information the spatial resolution of era5 land is also higher than that of cmip6 the large variation of spei may be due to more variables involved than spi resulting in a different probability density distribution curve 3 2 future trend of drought table 2 and fig 4 illustrate the temporal trend of spi and spei in the entire lmrb the spatial distribution of evolution trend in the lmrb is shown in figs 5 and 6 the lmrb will become wetter in the wet season as demonstrated by spi fig 4a b c and fig 5 but the trend is not statistically significant in the dry season however as indicated by spei fig 4d e f and fig 6 lmrb will become wetter in the wet season and drier in the dry season in the future due to the influence of increasing temperature under a warming climate there is a rising trend of spi in the whole year and wet season of the lmrb under ssp2 4 5 and ssp5 8 5 table 2 but no significant trend in the dry season under ssp2 4 5 and ssp5 8 5 the whole year spi i e spi12 of december increased by 0 011 per year and 0 016 per year respectively across the entire basin the dry season spi i e spi6 in may increased by 0 002 per year and 0 003 per year respectively not statistically significant the wet season spi i e spi6 of november show significant increases i e 0 012 per year and 0 017 per year under ssp2 4 5 and ssp5 8 5 respectively the whole year spei and wet season spei of the lmrb show slight increases whereas the dry season spei is decreased table 2 the results indicate that drought tend to be more severe throughout the dry season while the wet season and the whole year tend to experience less severe drought under ssp2 4 5 and ssp5 8 5 the whole year spei i e spei12 of december increased by 0 003 per year and 0 005 per year the wet season spei i e spei6 of november increased by 0 007 per year and 0 012 per year respectively for the entire basin whereas the dry season spei i e spei6 in may will decrease by 0 006 per year and 0 011 per year respectively in terms of the spi the right bank of the middle reach the eastern border region of the lower reach and the delta region of the lmrb would be more drought prone during the dry season fig 5a d and g the contrary is true over the entire basin during the wet season fig 5b e and h and throughout the year fig 5c f and i the eight cmip6 models demonstrate notable consistence in terms of the changes in the whole year and wet season see the stippling area in fig 5 in terms of the spei except for a portion of the lancang river basin lrb most of the lmrb would experience more severe drought throughout the dry season fig 6a d and g during the wet season drought would be weakened across a large portion of the basin fig 6b e and h in terms of the whole year the middle lancang and the middle mekong would experience more severe drought whereas the rest of the basin would be wetter fig 6c f and i 3 3 projections of drought duration we compare two future periods i e near future nf 2021 2055 and far future ff 2061 2095 with the historical period history 1980 2014 to analyze changes in future drought duration in different seasons see appendix for details based on these results most of the lmrb will experience extended drought throughout the dry season in nf and ff drought duration is shortened in most subbasins during the wet season except the upper lancang and middle mekong regions in the nf for the whole year more extended drought will persist in the middle lancang and middle mekong reaches the details are illustrated as follows the drought durations during the three periods and the changes between them are estimated for spi fig s1 s3 compared to the historical period the annual drought duration in fig s1 is reduced for most regions in the nf except for the lower lancang region the nf and ff both showed greater drought duration in the middle reach of the lrb and the eastern border area of the basin with the largest increases in the middle lancang when we examined drought duration variations in the dry season fig s2 for the wet season the nf and ff show shorter drought duration in most parts of the basin fig s3 the differences between the three ssp scenarios are limited the ff will experience shorter drought durations from the perspective of the whole basin the results for spei are shown in fig s4 s6 except for cambodia and the delta region the annual drought duration is longer for most regions under ssp2 4 5 and ssp5 8 5 fig s4 the nf and ff show longer drought duration in most parts of the basin with the largest increases in the lower lancang and the middle mekong in the dry season fig s5 the results of ssp5 8 5 are often more pronounced than those of ssp2 4 5 for the wet season the nf sees shorter drought duration in the southern part and regions of myanmar and northern laos fig s6 at the same time the greater drought duration is recorded in the central mekong region and parts of the lrb the results for the three ssp scenarios show limited differences the ff registers shorter drought durations from the perspective of the whole basin 3 4 projections of drought intensity for spi the nf and ff record weakened annual and wet season drought intensity over a large part of the region while higher intensity area may expand in the dry season fig s7 to fig s9 for the spei the nf and ff both recorded higher annual drought intensity in the upper lancang mekong region and areas on the left bank the intensified area may expand in the dry season and shrink in the wet season fig s10 to fig s12 the details are as follows for spi the nf and ff both register weakened annual drought intensity in large parts of the region with uneven spatial distribution fig s7 the nf records more areas with more intensified or less weakened drought intensity in general than the ff in most basin areas except the upper lancang the dry season drought intensified under ssp5 8 5 in the ff fig s8 the wet season shows reduced drought intensity in most areas of the basin except for some hot spots fig s9 under the three different scenarios changes in nf show a substantial spatial diversity under ssp5 8 5 the middle reaches of the lrb myanmar and north laos show more severe drought while other areas might experience reduced drought hazards for spei compared with the historical period the nf and ff both record stronger annual drought intensity in the upper lancang mekong region and its left bank with weakened annual intensity on the right bank in thailand and the delta region fig s10 in the dry season drought intensity increases in most basin areas under ssp2 4 5 and ssp5 8 5 except for areas in the se kong se san sre pok river basin fig s11 in the wet season except for a small fraction in the upper lancang and other spotted areas drought intensity decreases in most areas of the basin in the ff fig s12 changes in the nf show a considerable spatial diversity under three different scenarios the river source area in the lrb in particular registers greater drought intensity fig s12 3 5 projections of seasonal drought distribution the seasonal distribution of meteorological drought in the future is illustrated in table 3 generally the dry season drought accounts for a larger proportion than the wet season under ssp1 2 6 the dry season drought approaches 55 of total drought events in the nf for all drought grades the percentage is above 80 in the ff for severe and exceptional drought the percentage of the dry season is 67 to 100 under ssp2 4 5 the dry season drought accounts for 60 of total drought events in the nf for all drought grades the percentage is also above 80 in the ff the dry season drought percentage is over 60 for severe and exceptional drought the ff results under ssp5 8 5 are similar to those under ssp2 4 5 with notable differences between the dry and wet seasons 4 discussion 4 1 comparison with other researches several studies have assessed future drought changes based on cmip5 and cmip6 in the lmrb for instance based on cmip5 thilakarathne and sridhar 2017 characterized the future drought conditions in the lower mekong basin lmb their results suggested that the lower lmb and the se kong se san sre pok subbasins expected to experience more severe and intense droughts li et al 2021b used spi spei and ssi to assess meteorological and hydrological droughts in the lmrb and its surrounding areas their results showed that the meteorological drought in the northeastern part of the study area might intensify during 2010 2039 the increasing trend is followed by a reduction in drought after the year 2039 based on cmip6 wang et al 2021 assessed drought characteristics at global scale based on multiple indicators from eleven cmip6 models the variation of spei in the mekong river region is larger than that of spi with larger future drought duration changes by spei than that by spi in the region previous studies show that the southeast asian region would experience more droughts under the scenarios ssp1 2 6 ssp2 4 5 and ssp5 8 5 li et al 2021a zeng et al 2022 our results are overall consistent with previous studies based on the cmip6 model projections our analyses further investigate the seasonal drought characteristics in the lmrb 4 2 bias of eight gcms our results are primarily based on the average of eight cmip6 models under three different scenarios there are variations in terms of the temporal trends of drought among the eight cmip6 models similarly see e g chen and yuan 2021 grose et al 2020 li et al 2021a song et al 2021 wang et al 2021 however our analyses show that the eight gcms are highly consistent in terms of the temporal trends and drought characteristics in the lmrb see figs 5 and 6 for details the average of eight cmip6 models also show good consistency with era5 land in the historical period fig 3 the consistency among the eight cmip6 models in terms of future changes in drought duration and intensity is only evident when there are large change rates this indicates that the cmip6 models might be more consistent in projecting extreme climate conditions 4 3 seasonal drought impact it is commonly recognized that crop yield would be affected by drought our study shows a wetting tendency in the wet season but a drying tendency in the dry season in the lmrb this kind of change will benefit agricultural production in the wet season but do harms in the dry season however previous studies on future rice yields do not agree with each other for instance thuy and anh 2015 suggested that rice yields would decrease in the mekong river delta in the future while some studies show that co2 fertilization is an important factor for crop yield under the climate change according to kang et al 2021 the increase in precipitation and co2 concentration in the lower mekong basin could result in 24 to 43 increases in rice yield kontgis et al 2019 used a model to estimate future rice yields they found that rice yields will decrease if co2 fertilization is not considered according to tsujimoto et al 2022 the main factor restricting future rice production is soil wetness related to the projected changes in the seasonal distribution of rainfall considering the uneven distribution of irrigation equipment and spatially heterogeneous changes in future drought additional studies need to investigate how future changes in drought influence food and water security in the lmrb and explore possible mitigation and adaptation strategies 5 conclusion based on the average of eight cmip6 models under three climate change scenarios we examine the future drought characteristics using spi and spei in the lmrb we highlight the contrasting changes in the dry and wet seasons the conclusions are as follows 1 the average of eight cmip6 models shows a good consistency with era5 land in historical drought analysis the consistency is higher based on spi than spei even though both indices are applicable for drought projection 2 the lmrb witnesses significant increases in the dry season drought based on spei as well as significant decreases in annual and wet season drought based on spi and spei under ssp2 4 5 and ssp5 8 5 the future trend in dry season spei is 0 006 per year and 0 011 per year under ssp2 4 5 and ssp5 8 5 respectively the trends demonstrate spatial variability in the entire basin 3 based on spei the largest increases in dry season drought duration and intensity are projected in the middle reaches of the lmrb while longer drought duration and higher drought intensity in the wet season are expected in the upper lancang and middle mekong river 4 future drought would be more severe in the dry season for instance the dry season drought would account for approximately 60 in the near future and above 80 in the far future under the ssp2 4 5 scenario since future drought in the dry season is likely to become more severe in the lmrb we suggest that further studies should be carried out to investigate the potential impacts of future drought possible measures e g high efficient water utilization water redistribution projects are needed to enhance the water security in this populous region credit authorship contribution statement zhiqiang dong writing original draft investigation validation visualization hui liu conceptualization writing review editing funding acquisition resources formal analysis methodology baiyinbaoligao conceptualization writing review editing hongchang hu writing review editing methodology funding acquisition mohd yawar ali khan writing review editing jie wen writing review editing lajiao chen methodology writing review editing fuqiang tian writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by the lancang mekong cooperation fund 126301001000200041 126301001000210002 the second tibetan plateau scientific expedition and research program step no 2019qzkk0903 and national natural science foundation of china nsfc51879136 and state key laboratory of hydroscience and engineering 22 ky 03 we thank the anonymous reviewers for their valuable comments and suggestions appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127815 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3297,a disaggregated multi level factorial hydrologic data assimilation model fhda is proposed for exploring not only the direct effects from individual uncertainties but also more importantly the composite ones from multi layer and multi parameter interactions among multiple uncertainties in hydrologic data assimilation systems based on a disaggregated multi level factorial analysis method the proposed fhda examined the contributions of multiple uncertainty sources including data assimilation scheme sample size forcing data error and observed data error three parameter assimilation schemes of data assimilation i e ensemble kalman filter enkf standard kernel smoother enkfsks and kernel smoother with location shrinkage enkfksls are tested the results indicate that i the streamflow observations can be well tracked by 95 prediction intervals ii reducing streamflow observation error is the most efficient way to improve both deterministic and probabilistic predictions iii data assimilation scheme plays a vital role in hydrological predictions especially for probabilistic ones i e contributes 22 for the ensemble prediction uncertainty therefore to improve the prediction accuracy it is necessary to optimize the parameter assimilation schemes in hydrological data assimilation model keywords hydrologic data assimilation uncertainty partition multi level factorial analysis 1 introduction extensive uncertainties are generally embedded in hydrologic predictions which come from many sources including deficient model structures hui et al 2020 inexact forcing data and output observations wan et al 2021 inappropriate initial conditions shen et al 2018 and imprecise parameter estimates chen et al 2011 effective uncertainty quantification and reduction methods are required to handle these uncertainty sources and produce reliable hydrologic forecasts for many real world water resources applications fan et al 2016 li et al 2020 guo et al 2020 among numerous uncertainty estimation methods huang and fan 2021 wang et al 2017a data assimilation methods have been developed to explicitly deal with various uncertainties in forcing data and merge observations into uncertain model predictions dechant and moradkhani 2014 fan et al 2015 with the ability to provide probabilistic forecasting for both streamflow and some state variables data assimilation approaches have been widely applied for real time hydrological predictions however one of the most critical challenges is that the resulting uncertainties from any data assimilation method e g the ensemble kalman filter enkf particle filter pf are strongly dependent on the uncertainty quantification in both observations and models pathiraja et al 2017 therefore tracing the uncertainty sources and identifying the most significant contributors in the hydrologic data assimilation predictions is important for improving the predictability of hydrologic data assimilation methods in the past great efforts have been made to develop advanced data assimilation methods and identify the various uncertainty sources in them abbaszadeh et al 2019 moradkhani et al 2005a pathiraja et al 2016 in details during the data assimilation process stochastic perturbations are usually applied to present the uncertainty of both model simulations and measurements inappropriate uncertainty quantification stochastic perturbations may result in great uncertainties in model states and parameters leading to unsatisfactory performance of the data assimilation system crow and van loon 2006 in addition the sample size is another key factor for some monte carlo based data assimilation methods e g enkf pf which plays a crucial role in the effectiveness of data assimilation system fan et al 2015 yin et al 2015 the use of a large sample size makes it easier to characterize the probability distribution function of transient state parameter but at the expense of a significantly increased cpu cost zhang et al 2017 moreover there are a number of data assimilation approaches developed in the past decades such as enkf pf particle filter markov chain monte carlo pmcmc copula based particle filter coppf fan et al 2017a moradkhani et al 2012 pathiraja et al 2017 for one specific hydrologic prediction problem different approaches may present different abilities in producing probabilistic predictions zhang et al 2017 therefore the approach is also one uncertain source that may significantly influences the predictability of hydrologic models di et al 2021 consequently it is desired to comprehensively investigate the major factors in hydrologic data assimilation that have significant effects on hydrologic predictability to track the uncertainty sources in the hydrologic data assimilation predictions tremendous efforts have been made in recent years for instance ajami et al 2007 proposed a framework to tackle three major sources of uncertainty including uncertainty inherited in input forcing parameter estimation and model structure and suggested that ignoring input forcing error or model structural uncertainty will lead to unrealistic model simulations and incorrect uncertainty bounds pauwels and de lannoy 2009 assessed the impact of the observation error on data assimilation algorithms through adding gaussian random errors and found the observation errors play a dominate effect on the prediction precision de lannoy and reichle 2016 examined the random parameters in enkf and argued that the uncertainty in observations would produce noticeable effects on the land surface data assimilation systems zhang et al 2017 revealed that the biases in the forcing data and observations would have a considerable contribution to the temporal fluctuations of the estimated parameter more recently a few data assimilation efforts using land surface models and hydrological models have addressed different points such as ensemble size model uncertainty and tuning of input error parameters and data assimilation methods abbaszadeh et al 2019 pathiraja et al 2016 however complex interactions among various factors e g perturbed precipitation and streamflow observations are exist in data assimilation wang et al 2017b such interactions may engender uncertainties in relevant hydrological prediction fan et al 2017a xu and gertner 2008 for instance fan et al 2017b reveled the individual effects of data assimilation schemes and ensemble sizes on the predictability of hydrological models qualitatively through boxplot wang et al 2017b examined the interactions among the enkf factors including the ensemble size and random perturbations added to precipitation potential evapotranspiration and streamflow observation data through multi way analysis of variance the results uncover that the pairwise interaction between perturbed precipitation and streamflow observations has the most significant impact on the performance of the enkf system wang et al 2017b lyu and fan 2021 tested different uncertainty scenarios for model inputs and outputs as well as streamflow observations through multilevel factorial analysis the multi level factorial results suggest that the impact for one factor is generally dependent upon the others and scenarios with extreme stochastic perturbations low or high may more likely result in a good performance for data assimilation schemes lyu and fan 2021 in general most of the previous studies were undertaken to evaluate the direct effects of individual uncertainties in terms of modeling inputs parameter settings and assimilation schemes however these uncertainties may interact with each other resulting in composite impacts i e interactive effects on streamflow simulation in detail multiple combinations of multi layer and multi parameter interactions among the uncertainties with fluctuated levels of positive negative correlations among these uncertainties and their combinations may lead to compound complexities in the simulation efforts bringing about significant prediction errors therefore as an extension of previous studies the objective of this study is to develop a disaggregated multi level factorial hydrologic data assimilation model fhda for exploring not only the direct effects from individual uncertainties but also more importantly the composite ones from multi layer and multi parameter interactions among these uncertainties the proposed fhda will then be applied to jinghe river basin the results are expected to reveal the major dominant factors affecting hydrologic prediction which will provide a reference for the future research direction of hydrological data assimilation 2 development of a disaggregated multi level factorial hydrologic data assimilation model fhda to track the major factors that influence the predictability in hydrologic data assimilation systems a disaggregated multi level factorial hydrologic data assimilation model fhda is developed as shown in figure 1 2 1 data assimilation data assimilation approaches have been widely applied for real time hydrological predictions which can provide probabilistic forecasting for both streamflow and state variables pathiraja et al 2016 wang et al 2018 in enkf based filters ensembles of states are used to approximate the covariance matrices between model state and model simulation to achieve suboptimal state estimations generally distributed errors and the monte carlo approach are applied in enkf to approximate the error statistics evensen 2009 then approximate kalman gain matrixes for updating model and state variables are calculated based on the covariance matrix of simulations and observations a general framework of enkf for states and parameters updating is described briefly below consider a stochastic dynamic state model f x μ θ described by forcing data μ e g precipitation temperature state variables x e g nonlinear tank storage and model parameters θ e g maximum soil moisture capacity within the catchment for hymod used in this study the descriptions of forcing data μ model state variables x and parameters θ are presented in table 3 in the implementation of enkf the prior and posterior distributions for state variables x and model parameters θ are characterized by random samples name ensembles fan et al 2017a at any given time t the prior and posterior distributions of states and parameter are assumed to be denoted through a set of ensembles below x t x 1 t x i t x ns t θ t θ 1 t θ i t θ ns t x t x 1 t x i t x ns t θ t θ 1 t θ i t θ ns t where the superscript indicates the prior distributional information and the superscript refers the posterior distributional information after assimilation the subscript i denotes to the ith ensemble member and ns represents the total number of ensembles in data assimilation process a set of stochastic perturbations are usually added to forcing data model states and observations to account for the uncertainties the stochastic perturbations are assumed to have particular distribution according to their actual characteristics for instance the precipitation errors are normally assumed to have a log normal distribution while the potential evapotranspiration errors are assumed to have normal distributions expressed as p i t obs p t obs ω i t p log ω i t p n 0 τ p p t obs e i t obs e t obs ω i t e ω i t e n 0 τ e e t obs where p t obs and e t obs denote the observed precipitation and potential evapotranspiration p t obs and e t obs present the perturbed precipitation and potential evapotranspiration τ p and τ e are small tuning parameters that means the strength of perturbations uncertainty in measurements the ensemble of model states is propagated forward in time and the model forecast can be made as follows x i t 1 f x i t μ i t 1 θ i t 1 y i t 1 sim h x i t 1 θ i t 1 where x i t is the posterior model state of ensemble number i at the previous time step t μ i t 1 is the model input at the current time step t 1 θ i t 1 is the predicted model parameter at the current time step t 1 and x i t 1 is the predicted model state of ensemble number i at the current time step t 1 f is the forward model that propagates state variables from time t to t 1 h is an observation operator that converts model states to observed variables y i t 1 sim indicates the ith ensemble member of the model simulation of the observed variable using the prior parameters before assimilating observations a set of perturbed observations y i t 1 obs is generated through adding stochastic perturbations based on gaussian distribution to account for the uncertainty in streamflow measurements roberts et al 2019 the streamflow measurement errors are generally assumed to follow a normal distribution expressed as y i t 1 obs y t 1 obs ε i t 1 y ε i t 1 y n 0 τ y y t 1 obs where y t 1 obs denotes the raw observation and τ y is a small tuning parameter that means the strength of perturbations then the ensemble members of model states and parameters can be updated as follows x i t 1 x i t 1 k t 1 x y i t 1 obs y i t 1 sim θ i t 1 θ i t 1 k t 1 θ y i t 1 obs y i t 1 sim where k t 1 x and k t 1 θ are the kalman gain matrices for model states and parameters respectively k t 1 x and k t 1 θ can be written by k t 1 x σ t 1 xy sim σ t 1 y sim y sim σ t 1 y obs y obs 1 k t 1 θ σ t 1 θ y sim σ t 1 y sim y sim σ t 1 y obs y obs 1 where σ t 1 xy sim is the covariance matrix between model state x t 1 and model simulation y sim σ t 1 θ y sim is the covariance matrix between model parameter θ t 1 and model simulation y sim generally σ t 1 xy sim and σ t 1 θ y sim are the state error covariance and the parameter error covariance respectively σ t 1 y sim y sim is the covariance matrix of model simulations σ t 1 y obs y obs is the covariance matrix of observations in data assimilation process the parameter ensemble θ i t 1 are updated based on the posterior parameter ensemble θ i t and covariance t θ the covariance t θ for enkf and its variant are presented in table 1 to generate a suitable prior parameter ensemble efforts were made to develop parameter assimilation schemes abbaszadeh et al 2019 moradkhani et al 2005a pathiraja et al 2016 in recent decades following pathiraja et al 2016 three parameter assimilation schemes i e enkf enkfsks and enkfksls are applied to estimate the model parameters here in the enkf distributions of the system variables are replaced with random samples or an ensemble evensen 2009 in the enkfsks standard kernel smoothing approach west 1993 is applied to generate the background hyperparameter ensemble individual ensemble members are drawn from a truncated multivariate normal distribution with heteroscedastic covariance to deal with the increased variance and adjust the mean of the standard kernel smoother kernel smoother with location shrinkage liu and west 2001 was applied to filter divergence in the enkfksls so that the posterior variance from the previous time step would be maintained these three parameter assimilation schemes have been used in a number of studies e g moradkhani et al 2005b xie et al 2014 pathiraja et al 2018 and are selected in our study the brief description of them are presented in table 1 2 2 uncertainty sources in data assimilation the basic idea of data assimilation is to merge information from models and observations to reduce and quantify uncertainties in model predictions during the data assimilation process stochastic perturbations are usually added to the forcing data and observations to represent the measurements uncertainties however inappropriate stochastic perturbations can also result in great uncertainties in model states and parameters leading to unsatisfactory performance of the data assimilation system crow and van loon 2006 in addition the sample size is another key factor for some monte carlo based data assimilation methods e g enkf which plays a crucial role in the effectiveness of data assimilation system fan et al 2015 yin et al 2015 the use of a large sample size makes it easier to characterize the probability distribution function of transient state parameter but at the expense of a significantly increased cpu cost zhang et al 2017 for one specific hydrologic prediction problem different approaches may present different abilities in producing probabilistic predictions zhang et al 2017 therefore the approach is also one uncertain source that may significantly influences the predictability of hydrologic models in detail the predictability of one specific data assimilation approach would be influenced sample sizes e g ns in equations 1 4 random errors in forcing data e g ω i t p and ω i t e in equations 5 and 7 and output measurements e g ε i t 1 y in equation 11 given the assumed distribution these random errors ω i t p ω i t e and ε i t 1 y are controlled by the tuning parameters τ p τ e and τ y in equations 6 8 and 12 respectively consequently to characterize the individual and interactive effects of these factors a number of scenarios are set for the specifications of these tuning parameters i e τ p τ e and τ y and the ensemble size i e ns in addition for one specific hydrologic data assimilation prediction problem different parameter assimilation schemes may present different abilities in producing probabilistic predictions zhang et al 2017 thus parameter assimilation scheme is also one uncertain source consequently the impacts from data assimilation algorithms are also need to be characterized as presented in table 2 four perturbation scenarios are tested with the proportionality factors being 0 1 0 2 0 3 and 0 4 the ensemble sizes of 20 50 100 and 200 are tested in combination with various error parameters in addition the enkf and its variants i e enkfsks and enkfksls are tested in this study 2 3 hydrological simulation in this study rainfall runoff simulation is undertaken through hymod which is widely used for hydrologic predictions wang et al 2021b the general concept of the model is based on the probability distribution of soil moisture modeling proposed by moore moore 1985 in brief a catchment consists of infinite points each defined by a soil moisture capacity c soil moisture capacity vary within the catchment because of variability in soil texture and depth a cumulative distribution function cdf describes catchment soil moisture variability f c 1 1 c c max b exp 0 c c max where c is soil moisture capacity cmax is the maximum storage capacity and the exponent bexp is the degree of spatial variability of storage capacity over the basin as shown in figure 1 the runoff generation process partitions excess rainfall into surface storage characterized by three quick i e rq and slow i e rs flow tanks through a partitioning factor i e alpha moore 2007 the total discharge from both quick and slow tanks is the generated streamflow in the river basin table 3 presents the descriptions and initial fluctuating ranges of the five parameters the five parameters including cmax bexp alpha rs and rq cannot be measured directly but can be obtained through a model calibration process fan et al 2016 fan et al 2015 to drive the hymod daily input data of precipitation p mm day and potential evapotranspiration e mm day are required for the sake of brevity we refer our readers to moore 2007 moore 1985 for a comprehensive description of hymod 2 4 disaggregated multi level factorial analyses factorial analysis fa is a powerful statistical method for examining the effects of multiple factors on response variables through experimental design and data analysis montgomery and runger 2010 to reveal potential interactions among multiple factors all possible combinations of the levels of factors are examined in a factorial experiment then the decomposition of the sum of squares as described within the analysis of variance anova theory are used to quantify the contributions of these multiple factors déqué et al 2012 wang et al 2022 to diminish the effect of the sample size on contribution quantification in factorial analysis subsampled factorial analysis was proposed by bosshard et al 2013 and extend as disaggregated multi level factorial analyses wang et al 2020 compared with traditional sensitivity analysis methods such as sobol s the proposed disaggregated multi level factorial analyses have been proven to have the essential strengths i are effective and feasible for sensitivity analysis with relatively low computational requirements and ii can characterize sensitivities for both numeric and non numeric variables in water resources and environmental models which can hardly be treated by the sobol s approach as a powerful statistical method to reveal potential interactions among multiple factors the disaggregated multi level factorial analyses have been used in fan et al 2020 and fan et al 2021 in this study the disaggregated multi level factorial analysis is applied to data assimilation experiments for exploring not only the direct effects from individual uncertainties but also more importantly the composite ones from multi layer and multi parameter interactions among these uncertainties in detail the disaggregated multi level factorial analysis is constructed based on the hypothesis that the enkf design parameters e g the ensemble size the precipitation error the potential evapotranspiration error and the observation error have an influence on the response variable i e the predictive accuracy and we want to quantify such influence to make this clear assuming that a generalized model is defined as y f a b c d where a b c d represent the experimental factors correspond to the scenarios of the enkf design parameters e g the ensemble size the precipitation error the potential evapotranspiration error and the observation error y represents the predictive accuracy i e nse rmse and crps there are i scenarios of the ensemble size j scenarios of the precipitation error k scenarios of the potential evapotranspiration error and l scenarios of the observation error totally there are i j k l estimations of the nse rmse crps values derived through hydrologic data assimilation in a complete factorial experiment in disaggregated multi level factorial analysis for each experimental factor two scenarios are selected out of all scenarios that results in a total of c t 2 specify that c is the combination symbol t is the total scenarios possible experimental factor pairs in details c t 2 1 1 1 2 2 t 2 t 2 t 1 2 3 t 3 4 t 1 t t therefore there are c i 2 c j 2 c k 2 and c l 2 possible experimental factor pairs for ensemble size precipitation error potential evapotranspiration error and observation error respectively finally n where n c i 2 c j 2 c k 2 c l 2 subsampling iterations are observed which end up with two ensemble size two precipitation error two potential evapotranspiration error and two observation error that define our model combination matrix for the variance decomposition for each subsampling iteration n n 1 2 n the total sum of the squares sst can be divided into the sum of squares due to individual model parameters and their interactions as follows according to the anova theory saltelli et al 2010 ss t n s s a n s s b n s s c n s s d n s s i n ss i n s s a b n s s a c n s s a d n s s b c n s s b d n s s c d n s s a b c n s s a b d n s s b c d n where ssa ssb ssc and ssd present the individual effects of ensemble size precipitation error potential evapotranspiration error and observation error respectively ssi means all interaction terms for the model combination matrix defined by two ensemble size two precipitation error two potential evapotranspiration error and two observation error the variance decomposition can be calculated as follows ss t n i 1 2 j 1 2 k 1 2 l 1 2 y i j k l y o o o o 2 ss a n 2 2 2 i 1 2 y i o o o y o o o o 2 ss b n 2 2 2 j 1 2 y o j o o y o o o o 2 ss c n 2 2 2 k 1 2 y o o k o y o o o o 2 ss d n 2 2 2 l 1 2 y o o o l y o o o o 2 ss i n i 1 2 j 1 2 k 1 2 l 1 2 y i j k l y i o o o y o j o o y o o k o y o o o l 3 y o o o o 2 where n is in 1 n and n c i 2 c j 2 c k 2 c l 2 the symbol o indicates averaging over the particular index for instance y o o o o indicates the average of y i e nse rmse and crps under all cases and y o o o o 1 16 i 1 2 j 1 2 k 1 2 l 1 2 y i j k l then for each effect the variance fraction η is derived as follows η a 1 n n 1 n ss a n ss t n η b 1 n n 1 n ss b n ss t n η c 1 n n 1 n ss c n ss t n η d 1 n n 1 n ss d n ss t n η i 1 n n 1 n ss i n ss t n the values of variance fraction η are range from 0 to 1 corresponding to a contribution of an experimental factor from 0 to 100 respectively for more information about ifa please see figure s1 in this study the disaggregated multi level factorial analysis is performed to identify the most sensitive parameters of the data assimilation including the ensemble size the precipitation error the potential evapotranspiration error and the streamflow observation error the results of sensitivity analysis provide a possible direction for improving the performance of hydrological data assimilation wang et al 2018 3 case study the proposed fhda model is tested for hydrologic data assimilation in daxi river located in the north part of china figure 2 shows the location of daxi river catchment as the tributary of jinghe river located in the middle of the loess plateau daxi river has a drainage area of 2485 km2 the annual precipitation of approximately 579 9 mm ran 1992 and the annual streamflow of 4 17 m3 s in general the daxi river basin has a semiarid and subhumid continental monsoon climate resulting in considerable temporal spatial variations in precipitation in this study the inputs of the hymod are obtained based on meteorological measurements at the national stations the black triangles in figure 2 while the streamflow measurements at zhangjiagou station 107 76e and 35 10 n are used for data assimilation with different parameter assimilation schemes the areal precipitation data for hymod were interpolated from site precipitation denoted as p measurements distributed over the catchment and the areal potential evapotranspiration denoted as e data were interpolated from potential evapotranspiration at the national meteorological stations in the jing river basin the streamflow observations at zhangjiagou station were used in this case study a total of 3286 days of data from january 1975 to december 1983 were used to assimilate daily streamflow the first 50 days was used as a spin up period to reduce sensitivity to state value initialization 4 performance of hydrological prediction 4 1 performances of different parameter assimilation schemes to explore the reliability of the parameter assimilation schemes including enkf enkfsks and enkfksls these methods are employed for real time hydrological prediction through hymod under different uncertainty scenarios in inputs outputs and sample size the initial ensembles for the five parameters i e cmax bexp alpha rs and rq are sampled uniformly from predefined intervals as shown in table 3 the initial ensembles for the state variable of the storage and slow flow tank are sampled from normal distribution the initial state variables of the three quick flow tanks are set to be 0 and the sample size used in this section is 50 three indices including root mean square error rmse the nash sutcliffe efficiency nse coefficient and continuous ranked probability score crps are used for the evaluation of the performance of data assimilation approaches li et al 2019 rmse and nse are based on the ensemble average which are expressed as rmse 1 n i 1 n q obs i q sim i 2 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 where q obs i are the observed streamflow q sim i are the simulated streamflow from the hydrologic model q obs is the mean of observed streamflow and n is the total number of observed or simulated streamflow the crps is a measurement of error for probabilistic prediction and defined as the integrated squared difference between the cdf of forecasts and observations fan et al 2017a hersbach 2000 murphy and winkler 1987 crps f sim x f obs x 2 d x where f sim and f obs are cdfs for predicted streamflow and observed streamflow respectively a small crps value indicates a better model performance with the value of zero suggesting a perfect accuracy for model prediction figure 3 shows the comparison of observations and predictions for daxi river through the different data assimilation schemes the results demonstrate that the predictive mean values can well track the observations and the associated 95 predictive intervals consisting of 2 5 and 97 5 quantiles can generally bracket the fluctuation during the three data assimilation schemes it is noticed that all data assimilation schemes provide accurate predictions during the low flow periods however for high flow periods enkfsks generates overestimations while enkfksls generates underestimations the three indices i e nse rmse and crps correspond to the predictions of enkf are 0 68 7 28 and 1 47 respectively those indices are 0 69 7 15 and 1 75 for enkfsks and 0 67 7 40 and 1 93 for enkfksls respectively consequently among these parameter assimilation schemes enkfsks has a best perform in both deterministic and probabilistic predictions if they are evaluated through nse rmse and crps the enkf generates best probabilistic predictions and enkfksls leads to worst probabilistic predictions figure 4 presents the temporal evolution of the five parameters in hymod i e cmax bexp alpha rs rq with 95 confidence intervals in the data assimilation process through enkf the corresponding temporal evolution of enkfsks and enkfksls are presented in figures s2 s3 the results indicate that all five parameters in hymod are identified well after a number of data assimilation steps a discharge series larger than 1000 days appear to be enough to quantify parameter distributions with limited ranges through enkf enkfsks and enkfksls in hydrologic models their parameters are generally interrelated and thus the optimal value of one parameter is dependent upon the values of other parameters fan et al 2017a similarly such interrelationships among parameters exist in the data assimilation process wang et al 2017b in this study the temporal variations of correlation among different pairs of parameters denoted as cmax bexp cmax alpha cmax rs cmax rq bexp alpha bexp rs bexp rq alpha rs alpha rq and rs rq measured through kendall s values are presented in figure 5 and figure s4 as shown in figure 5 the correlations among different parameters are varied in the enkf taking the interdependence of cmax bexp as an example these two parameters are generally positive correlated in the former data assimilation steps then develop a negative correlation structure in the later period the correlation among other parameters also shows similar characteristics the diverse correlation patterns observed implies that the dependence structures of one pair of parameters in hymod are varied in data assimilation process which is consistent with the research of fan et al 2017a for different parameter assimilation schemes the correlations of the obtained posterior parameters are diverse 4 2 impacts of sample size to further characterize the impacts of sample sizes on those three data assimilation schemes four sample scenarios are further tested for hymod in daxi river including 20 50 100 and 200 figure 6 presents the boxplot of model performances through enkf enkfsks and enkfksls under different sample size scenarios the results show that all three methods will perform better with an increase in sample size generally the enkfsks performs best than the other in both deterministic and probabilistic predictions if they are evaluated through nse rmse and crps in detail the enkf produce best predictions with higher values for nse lowest values for rmse and lowest values for crps followed by enkfsks and enkfksls when the same size is 20 the performance of enkf is better than enkfsks and enkfksls for probabilistic predictions in terms of crps when the same size is larger than 100 the lowest values for crps is obtained in enkfsks indicating closest distance between the predictive and observed cumulative distribution functions as shown in table 4 all the three parameter assimilation schemes can generate reliable results for both deterministic and probabilistic predictions as the increase of sample size hymod would generate reliable predictions with the deterministic and probabilistic evaluation indices varied within very limited intervals meanwhile the hydrological predictions are affected by the sample size and the increased sample size would increase the model performance significantly in comparison the enkf and enkfsks may generate unsatisfactory results with a sample size less than 50 and the enkfksls may generate unsatisfactory results with a sample size less than 100 therefore larger sample size may be required in parameter perturbation process to achieve good estimations 4 3 impacts of modeling inputs apart of the sample size the input and output measurement errors would also lead to uncertainties during data assimilation process stochastic perturbations are mandatory in a data assimilation framework to analyses the various uncertainty sources such as model inputs parameters and structures fan et al 2017b therefore to tackle these uncertainties random perturbations are added to the forcing data precipitation and evapotranspiration and streamflow observations in this study as recommended in many researches dechant and moradkhani 2012 rasmussen et al 2015 wang et al 2018 gaussian noise distributions are adopted for potential evapotranspiration and observations in this study for precipitation the log normal noise is employed as the better perform is reported by dechant and moradkhani 2012 moradkhani et al 2012 finally four scenarios were given on the strength of perturbations error standard deviations including 10 20 30 and 40 table 5 presents the performance of hymod at daxi river under different precipitation error disturbance obviously both the deterministic and probabilistic predictions of the three parameter assimilation schemes are insensitive to precipitation error disturbance similarly most of the posterior parameters are insensitive to precipitation error disturbance except bexp and alpha in enkfksls and cmax and alpha in enkfksls in the same way the effects of evapotranspiration error disturbance and runoff observation error disturbance on the model performance are presented in tables 6 and 7 respectively similar to precipitation error disturbance the evapotranspirationerror disturbance has little effect on the performance of the three parameter assimilation schemes as to the runoff observation error disturbance the increased disturbances lead to a decreased nse an increased rmse and an increased crps for the four data assimilation schemes meanwhile the four data assimilation schemes have different sensitivity to runoff observation error for instance with the runoff observation error disturbance increased from 10 to 40 the nse of predictions from enkfsks decreased significantly from 0 70 to 0 63 thus it s desired to examine the evolution of input and output uncertainties and their interactions that affect the predictive performance based on different index for each data assimilation scheme 5 individual and interactive effects of multiple impact factors 5 1 impacts of modeling inputs and parameter settings on specific data assimilation scheme in this section four experimental factors are considered including the ensemble size the precipitation error the evapotranspiration error and streamflow observation error to reveal their individual and interactive effects on the performances of three data assimilation schemes i e enkf enkfsks and enkfksls each factor has multi levels scenarios and a 44 factorial design contained 256 combinations is obtained for each data assimilation scheme according to factorial design 256 nse rmse and crps values are obtained then the disaggregated multi level factorial analysis is employed to examine the sensitivities of these design parameters quantitatively in term of the deterministic and probabilistic prediction indexes figure 7 depicts the standardized effects including main and interaction effects for the enkf enkfsks and enkfksls for enkf the main effects of the ensemble size the precipitation error the evapotranspiration error and streamflow observation error are 0 24 0 02 0 03 and 0 42 respectively if they are evaluated though deterministic predictions e g nse this means that the streamflow observation error is the most significant factor for deterministic predictions through enkf followed by the ensemble size the uncertainty caused by the forcing data errors i e the precipitation error and the evapotranspiration error are not quite visible wang et al 2017b claimed the identification of the uncertainty sources are conditional on different statistical e g the deterministic and probabilistic prediction indices since there is a different recursive pattern of parameter perturbation for them therefore the main effects evaluated though probabilistic prediction index i e crps are also presented in figure 7 like the deterministic prediction the streamflow observation error is still the most significant factor for the probabilistic prediction in daxi river followed by the ensemble size nevertheless comparing with the deterministic prediction the magnitude of the contribution caused by streamflow observation error slightly increased from 0 42 to 0 45 in probabilistic prediction and that caused by ensemble size decreased from 0 24 to 0 19 this means that the influence of streamflow observation on probabilistic prediction is more significant at the same time sample size has more impact on deterministic prediction for enkfsks the main effects of the ensemble size the precipitation error the evapotranspiration error and streamflow observation error are 0 12 0 03 0 04 and 0 40 respectively evaluated though the deterministic prediction e g nse these four kinds of uncertainty sources respectively have a main contribution of 0 45 0 03 0 03 and 0 08 for the probabilistic predictions comparing with the deterministic prediction the magnitude of the uncertainty caused by streamflow observation error significantly changed as presented in figure 7 b despite the above differences a common pattern is that streamflow observation error is the primary source of uncertainty for enkfsks data assimilation in daxi river followed by the ensemble size at the same time it can be found that the order of sources of uncertainty is the same as that for enkf no matter whether they are evaluated by deterministic or probabilistic prediction indices while the magnitude of the uncertainty for enkfsks varies greatly from that for enkf especially for deterministic prediction index the enkfsks is more sensitive to streamflow observation error in terms of deterministic prediction and sample size has more impact on probabilistic prediction for enkfksls as presented in figure 7c the four main effects are 0 12 0 06 0 06 and 0 08 for the deterministic prediction and 0 18 0 05 0 06 and 0 07 for the probabilistic prediction a marked difference is that ensemble size is the primary source of uncertainty for enkfksls data assimilation followed by the streamflow observation error this suggests that to obtain a better deterministic and probabilistic predictions more sample size is desired in enkfksls moreover it can be found that more than one third the uncertainty comes from the overall interactions of two factors overall the three parameter assimilation schemes have a common pattern despite a variety of magnitude differences first the streamflow observation error is the primary source of uncertainty for enkf and enkfsks which is the second uncertainty source for enkfksls this suggests that the streamflow observation error would influence prediction accuracy greatly in both deterministic and probabilistic predictions therefore well quantification of streamflow uncertainty is the most efficient way to improve prediction accuracy second the ensemble size is a very important source of uncertainty in data assimilation methods next to the streamflow observation error third the disturbances of input data i e precipitation and evapotranspiration have little influence i e the main effects are less than 0 06 on the prediction accuracy for all the four data assimilation schemes lastly the contributions of two factor interactions vary from 0 16 to 0 37 depends on different data assimilation methods and prediction indices the contributions of three factor interactions vary from 0 10 to 0 24 commonly the interaction effects evaluated through probabilistic prediction indexes i e crps are smaller than that evaluated through deterministic prediction indexes i e nse and rmse 5 2 impacts of data assimilation schemes to clarify whether different data assimilation schemes have a significant impact on the prediction results this study will analyze the uncertainty caused by data assimilation methods figure 8 presents the standardized effects including main and interaction effects of various factors on prediction accuracy from figure 8 the streamflow observation error 0 16 is the primary source of uncertainty followed by ensemble size 0 09 and data assimilation schemes 0 06 if they are evaluated though deterministic prediction index e g nse the main effects of precipitation error and potential evapotranspiration error are less than 0 02 at the same time these factors present significant interactions in affecting hydrologic prediction especially the interactions of two factors 0 27 in total the interactions decrease gradually with the number of interacted factors the results indicate that comparing with input measurement errors streamflow observation error plays a vital role in the deterministic data assimilation prediction process compared to the deterministic predictions the probabilistic predictions present a different sensitivity pattern for example the main effects of the data assimilation schemes and sample size increased from 0 05 and 0 09 estimated by nse to 0 22 and 0 15 estimated by crps respectively meanwhile the main effect of streamflow observation error decreased from 0 16 estimated by nse to 0 06 estimated by crps similar to the deterministic predictions the main effects of precipitation error and potential evapotranspiration error are also less than 0 02 for the probabilistic predictions at the same time the interactions of multi factors also decreased nearly half the choice of evaluation index not only influences the magnitude of the main effect of each uncertainty source but also influences the order of such main effects for instance evaluated by deterministic prediction indexes i e nse and rmse the order of the main effects would be err q ns method err p err e while under the scheme evaluated by probabilistic prediction index i e crps the main effects yield a different order method ns err q err p err e this means that the probabilistic prediction is more sensitive to algorithms and sample size in data assimilation process in order to improve the prediction accuracy it is necessary to optimize the data assimilation schemes or develop more advanced data assimilation schemes moreover more efforts to improve the accuracy of runoff observations and increase the number of samples are also recommended 6 discussion to quantify the interactive individual and integrative impacts of multiple uncertainty sources in the data assimilation hydrological model a disaggregated multi level factorial hydrologic data assimilation model fhda was developed in this study in fact the uncertainty sources contributions can also be characterized by the traditional factorial analysis approach while bosshard et al 2013 and wang et al 2020 have proved that fa would underestimate the variance in small sample size to diminish the effect of the biased variance estimator on the quantification of the variance contribution disaggregated multi level factorial analysis is incorporated into fhda in which each factor has multi level to be subsampled see section 2 4 after subsampling the quantification of such impacts under multi uncertainties is achieved through rigorous statistical inferences unbiasedly which is the most representative advantage of disaggregated multi level factorial analysis over the other sensitivity analysis methods fan et al 2020 in addition disaggregated multi level factorial analysis has the advantage of analyzing the latent interactions of numerical variables e g sample sizes and non numerical variables e g data assimilation schemes as well as their impacts on the modeling response e g streamflow prediction while the application of disaggregated multi level factorial analysis in complex models has a linear assumption wang et al 2021a the influence of this assumption on the results needs to be further explored here four uncertainty sources i e model input model observation ensemble size and data assimilation scheme in hydrologic data assimilation are quantified to explore the individual and interactive effects of them results presented in this application indicate that the streamflow observation errors influence hydrological prediction greatly in both deterministic and probabilistic predictions this can be explained by that the observational uncertainty defines how the filter trusts the observations and thus to what extent they are assimilated into the model piazzi et al 2021 thus it is critically important to reduce the observation error for improving prediction accuracy as illustrated in the case of daxi river the choice of parameter assimilation schemes for generating background parameter ensembles poses the most significant influence on hydrological prediction especially for probabilistic prediction pathiraja et al 2016 had demonstrated that parameter assimilation scheme was critical in determining the effectiveness of data assimilation samuel et al 2014 also indicated that there are significant differences in soil moisture variations and streamflow estimates when three assimilation approaches of ensemble kalman filter were applied at the same time results presented in this application also revealed that the performances for enkf and its variant would be insensitive to uncertainties in forcing data precipitation and evapotranspiration one possible reason is that biases in the input forcing are compensated in the state updating step over time which needs to be explored further another point highlighted here shows that the interactions among these uncertainty factors significantly affect hydrologic prediction especially the interactions between two factors this corroborates with the findings of others fan et al 2017a who proposed a coppf approach to improve the performance of hydrological data assimilation by introducing copulas to describe parameter interdependence bosshard et al 2013 had pointed out the nonnegligible contributions of interactions between the different uncertainty sources note though that we do not disentangle the errors from interactions in the disaggregated multi level factorial analysis which would require multiple realizations of each hydrologic modeling chain combination bosshard et al 2013 wang et al 2020 without considering the errors the importance of individual as well as interaction uncertainty sources may be overestimated slightly results presented in this paper may updated as more datasets cases become available and included an obvious future step will also be the inclusion of more catchments including semi arid semi humid and humid basins moreover the influences of dataset length geographical conditions topography vegetation human activities and other potential factors on the performance of hydrologic data assimilation model 7 conclusion in this study a disaggregated multi level factorial hydrologic data assimilation model fhda for exploring not only the direct effects from individual uncertainties but also more importantly the composite ones from multi layer and multi parameter interactions among multiple uncertainties the disaggregated multi level factorial analysis of hydrologic data assimilation experiments can examine the main contributions of various uncertainties sources including data assimilation scheme sample size forcing data error and observed data error on the predictive accuracy three parameter assimilation schemes i e enkf enkfsks and enkfksls are tested and the main findings are as follows first the streamflow observations can be well tracked by the 95 predictive intervals in data assimilation schemes the temporal evolution of model parameters for streamflow assimilation are uncovered in the daxi river watershed among the three data assimilation schemes enkfsks has a best perform if they are evaluated through nse rmse and crps second for each data assimilation scheme the streamflow observation error is the main source of uncertainty in both deterministic and probabilistic predictions third the data assimilation scheme contributes 0 06 0 22 for the ensemble prediction uncertainty if it is considered as one of the uncertainty sources comparing with ensemble size and input measurement error the data assimilation scheme plays a vital role in the predictions especially for probabilistic ones therefore to improve the prediction accuracy it is necessary to optimize the data assimilation scheme or develop more advanced data assimilation schemes moreover the interactions among multiple uncertainty factors significantly affect hydrologic prediction especially the interactions between two factors this study revealed the uncertainty sources in hydrologic data assimilation process and pointed out the vital role of data assimilation schemes in improving the hydrological data assimilation predictions the results of uncertainty analysis present a possible direction for improving the performance of hydrological data assimilation which provides a reference for the future research direction of hydrological data assimilation credit authorship contribution statement f wang data curation software writing original draft visualization g h huang writing review editing supervision funding acquisition y fan methodology software conceptualization writing review editing y p li supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research was supported by the strategic priority research program of cas xda20060302 natural science foundation u2040212 mwr cas institute of hydroecology and natural science and engineering research council of canada we are also very grateful for the helpful inputs from the editor and anonymous reviewers data availability statements the data that support the findings of this study are available from https www researchgate net publication 353286792 data for zhangjiagou the main r code used are available from https www researchgate net publication 356287977 main r code for development of a disaggregated multi level factorial hydrologic data assimilation model appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127802 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3297,a disaggregated multi level factorial hydrologic data assimilation model fhda is proposed for exploring not only the direct effects from individual uncertainties but also more importantly the composite ones from multi layer and multi parameter interactions among multiple uncertainties in hydrologic data assimilation systems based on a disaggregated multi level factorial analysis method the proposed fhda examined the contributions of multiple uncertainty sources including data assimilation scheme sample size forcing data error and observed data error three parameter assimilation schemes of data assimilation i e ensemble kalman filter enkf standard kernel smoother enkfsks and kernel smoother with location shrinkage enkfksls are tested the results indicate that i the streamflow observations can be well tracked by 95 prediction intervals ii reducing streamflow observation error is the most efficient way to improve both deterministic and probabilistic predictions iii data assimilation scheme plays a vital role in hydrological predictions especially for probabilistic ones i e contributes 22 for the ensemble prediction uncertainty therefore to improve the prediction accuracy it is necessary to optimize the parameter assimilation schemes in hydrological data assimilation model keywords hydrologic data assimilation uncertainty partition multi level factorial analysis 1 introduction extensive uncertainties are generally embedded in hydrologic predictions which come from many sources including deficient model structures hui et al 2020 inexact forcing data and output observations wan et al 2021 inappropriate initial conditions shen et al 2018 and imprecise parameter estimates chen et al 2011 effective uncertainty quantification and reduction methods are required to handle these uncertainty sources and produce reliable hydrologic forecasts for many real world water resources applications fan et al 2016 li et al 2020 guo et al 2020 among numerous uncertainty estimation methods huang and fan 2021 wang et al 2017a data assimilation methods have been developed to explicitly deal with various uncertainties in forcing data and merge observations into uncertain model predictions dechant and moradkhani 2014 fan et al 2015 with the ability to provide probabilistic forecasting for both streamflow and some state variables data assimilation approaches have been widely applied for real time hydrological predictions however one of the most critical challenges is that the resulting uncertainties from any data assimilation method e g the ensemble kalman filter enkf particle filter pf are strongly dependent on the uncertainty quantification in both observations and models pathiraja et al 2017 therefore tracing the uncertainty sources and identifying the most significant contributors in the hydrologic data assimilation predictions is important for improving the predictability of hydrologic data assimilation methods in the past great efforts have been made to develop advanced data assimilation methods and identify the various uncertainty sources in them abbaszadeh et al 2019 moradkhani et al 2005a pathiraja et al 2016 in details during the data assimilation process stochastic perturbations are usually applied to present the uncertainty of both model simulations and measurements inappropriate uncertainty quantification stochastic perturbations may result in great uncertainties in model states and parameters leading to unsatisfactory performance of the data assimilation system crow and van loon 2006 in addition the sample size is another key factor for some monte carlo based data assimilation methods e g enkf pf which plays a crucial role in the effectiveness of data assimilation system fan et al 2015 yin et al 2015 the use of a large sample size makes it easier to characterize the probability distribution function of transient state parameter but at the expense of a significantly increased cpu cost zhang et al 2017 moreover there are a number of data assimilation approaches developed in the past decades such as enkf pf particle filter markov chain monte carlo pmcmc copula based particle filter coppf fan et al 2017a moradkhani et al 2012 pathiraja et al 2017 for one specific hydrologic prediction problem different approaches may present different abilities in producing probabilistic predictions zhang et al 2017 therefore the approach is also one uncertain source that may significantly influences the predictability of hydrologic models di et al 2021 consequently it is desired to comprehensively investigate the major factors in hydrologic data assimilation that have significant effects on hydrologic predictability to track the uncertainty sources in the hydrologic data assimilation predictions tremendous efforts have been made in recent years for instance ajami et al 2007 proposed a framework to tackle three major sources of uncertainty including uncertainty inherited in input forcing parameter estimation and model structure and suggested that ignoring input forcing error or model structural uncertainty will lead to unrealistic model simulations and incorrect uncertainty bounds pauwels and de lannoy 2009 assessed the impact of the observation error on data assimilation algorithms through adding gaussian random errors and found the observation errors play a dominate effect on the prediction precision de lannoy and reichle 2016 examined the random parameters in enkf and argued that the uncertainty in observations would produce noticeable effects on the land surface data assimilation systems zhang et al 2017 revealed that the biases in the forcing data and observations would have a considerable contribution to the temporal fluctuations of the estimated parameter more recently a few data assimilation efforts using land surface models and hydrological models have addressed different points such as ensemble size model uncertainty and tuning of input error parameters and data assimilation methods abbaszadeh et al 2019 pathiraja et al 2016 however complex interactions among various factors e g perturbed precipitation and streamflow observations are exist in data assimilation wang et al 2017b such interactions may engender uncertainties in relevant hydrological prediction fan et al 2017a xu and gertner 2008 for instance fan et al 2017b reveled the individual effects of data assimilation schemes and ensemble sizes on the predictability of hydrological models qualitatively through boxplot wang et al 2017b examined the interactions among the enkf factors including the ensemble size and random perturbations added to precipitation potential evapotranspiration and streamflow observation data through multi way analysis of variance the results uncover that the pairwise interaction between perturbed precipitation and streamflow observations has the most significant impact on the performance of the enkf system wang et al 2017b lyu and fan 2021 tested different uncertainty scenarios for model inputs and outputs as well as streamflow observations through multilevel factorial analysis the multi level factorial results suggest that the impact for one factor is generally dependent upon the others and scenarios with extreme stochastic perturbations low or high may more likely result in a good performance for data assimilation schemes lyu and fan 2021 in general most of the previous studies were undertaken to evaluate the direct effects of individual uncertainties in terms of modeling inputs parameter settings and assimilation schemes however these uncertainties may interact with each other resulting in composite impacts i e interactive effects on streamflow simulation in detail multiple combinations of multi layer and multi parameter interactions among the uncertainties with fluctuated levels of positive negative correlations among these uncertainties and their combinations may lead to compound complexities in the simulation efforts bringing about significant prediction errors therefore as an extension of previous studies the objective of this study is to develop a disaggregated multi level factorial hydrologic data assimilation model fhda for exploring not only the direct effects from individual uncertainties but also more importantly the composite ones from multi layer and multi parameter interactions among these uncertainties the proposed fhda will then be applied to jinghe river basin the results are expected to reveal the major dominant factors affecting hydrologic prediction which will provide a reference for the future research direction of hydrological data assimilation 2 development of a disaggregated multi level factorial hydrologic data assimilation model fhda to track the major factors that influence the predictability in hydrologic data assimilation systems a disaggregated multi level factorial hydrologic data assimilation model fhda is developed as shown in figure 1 2 1 data assimilation data assimilation approaches have been widely applied for real time hydrological predictions which can provide probabilistic forecasting for both streamflow and state variables pathiraja et al 2016 wang et al 2018 in enkf based filters ensembles of states are used to approximate the covariance matrices between model state and model simulation to achieve suboptimal state estimations generally distributed errors and the monte carlo approach are applied in enkf to approximate the error statistics evensen 2009 then approximate kalman gain matrixes for updating model and state variables are calculated based on the covariance matrix of simulations and observations a general framework of enkf for states and parameters updating is described briefly below consider a stochastic dynamic state model f x μ θ described by forcing data μ e g precipitation temperature state variables x e g nonlinear tank storage and model parameters θ e g maximum soil moisture capacity within the catchment for hymod used in this study the descriptions of forcing data μ model state variables x and parameters θ are presented in table 3 in the implementation of enkf the prior and posterior distributions for state variables x and model parameters θ are characterized by random samples name ensembles fan et al 2017a at any given time t the prior and posterior distributions of states and parameter are assumed to be denoted through a set of ensembles below x t x 1 t x i t x ns t θ t θ 1 t θ i t θ ns t x t x 1 t x i t x ns t θ t θ 1 t θ i t θ ns t where the superscript indicates the prior distributional information and the superscript refers the posterior distributional information after assimilation the subscript i denotes to the ith ensemble member and ns represents the total number of ensembles in data assimilation process a set of stochastic perturbations are usually added to forcing data model states and observations to account for the uncertainties the stochastic perturbations are assumed to have particular distribution according to their actual characteristics for instance the precipitation errors are normally assumed to have a log normal distribution while the potential evapotranspiration errors are assumed to have normal distributions expressed as p i t obs p t obs ω i t p log ω i t p n 0 τ p p t obs e i t obs e t obs ω i t e ω i t e n 0 τ e e t obs where p t obs and e t obs denote the observed precipitation and potential evapotranspiration p t obs and e t obs present the perturbed precipitation and potential evapotranspiration τ p and τ e are small tuning parameters that means the strength of perturbations uncertainty in measurements the ensemble of model states is propagated forward in time and the model forecast can be made as follows x i t 1 f x i t μ i t 1 θ i t 1 y i t 1 sim h x i t 1 θ i t 1 where x i t is the posterior model state of ensemble number i at the previous time step t μ i t 1 is the model input at the current time step t 1 θ i t 1 is the predicted model parameter at the current time step t 1 and x i t 1 is the predicted model state of ensemble number i at the current time step t 1 f is the forward model that propagates state variables from time t to t 1 h is an observation operator that converts model states to observed variables y i t 1 sim indicates the ith ensemble member of the model simulation of the observed variable using the prior parameters before assimilating observations a set of perturbed observations y i t 1 obs is generated through adding stochastic perturbations based on gaussian distribution to account for the uncertainty in streamflow measurements roberts et al 2019 the streamflow measurement errors are generally assumed to follow a normal distribution expressed as y i t 1 obs y t 1 obs ε i t 1 y ε i t 1 y n 0 τ y y t 1 obs where y t 1 obs denotes the raw observation and τ y is a small tuning parameter that means the strength of perturbations then the ensemble members of model states and parameters can be updated as follows x i t 1 x i t 1 k t 1 x y i t 1 obs y i t 1 sim θ i t 1 θ i t 1 k t 1 θ y i t 1 obs y i t 1 sim where k t 1 x and k t 1 θ are the kalman gain matrices for model states and parameters respectively k t 1 x and k t 1 θ can be written by k t 1 x σ t 1 xy sim σ t 1 y sim y sim σ t 1 y obs y obs 1 k t 1 θ σ t 1 θ y sim σ t 1 y sim y sim σ t 1 y obs y obs 1 where σ t 1 xy sim is the covariance matrix between model state x t 1 and model simulation y sim σ t 1 θ y sim is the covariance matrix between model parameter θ t 1 and model simulation y sim generally σ t 1 xy sim and σ t 1 θ y sim are the state error covariance and the parameter error covariance respectively σ t 1 y sim y sim is the covariance matrix of model simulations σ t 1 y obs y obs is the covariance matrix of observations in data assimilation process the parameter ensemble θ i t 1 are updated based on the posterior parameter ensemble θ i t and covariance t θ the covariance t θ for enkf and its variant are presented in table 1 to generate a suitable prior parameter ensemble efforts were made to develop parameter assimilation schemes abbaszadeh et al 2019 moradkhani et al 2005a pathiraja et al 2016 in recent decades following pathiraja et al 2016 three parameter assimilation schemes i e enkf enkfsks and enkfksls are applied to estimate the model parameters here in the enkf distributions of the system variables are replaced with random samples or an ensemble evensen 2009 in the enkfsks standard kernel smoothing approach west 1993 is applied to generate the background hyperparameter ensemble individual ensemble members are drawn from a truncated multivariate normal distribution with heteroscedastic covariance to deal with the increased variance and adjust the mean of the standard kernel smoother kernel smoother with location shrinkage liu and west 2001 was applied to filter divergence in the enkfksls so that the posterior variance from the previous time step would be maintained these three parameter assimilation schemes have been used in a number of studies e g moradkhani et al 2005b xie et al 2014 pathiraja et al 2018 and are selected in our study the brief description of them are presented in table 1 2 2 uncertainty sources in data assimilation the basic idea of data assimilation is to merge information from models and observations to reduce and quantify uncertainties in model predictions during the data assimilation process stochastic perturbations are usually added to the forcing data and observations to represent the measurements uncertainties however inappropriate stochastic perturbations can also result in great uncertainties in model states and parameters leading to unsatisfactory performance of the data assimilation system crow and van loon 2006 in addition the sample size is another key factor for some monte carlo based data assimilation methods e g enkf which plays a crucial role in the effectiveness of data assimilation system fan et al 2015 yin et al 2015 the use of a large sample size makes it easier to characterize the probability distribution function of transient state parameter but at the expense of a significantly increased cpu cost zhang et al 2017 for one specific hydrologic prediction problem different approaches may present different abilities in producing probabilistic predictions zhang et al 2017 therefore the approach is also one uncertain source that may significantly influences the predictability of hydrologic models in detail the predictability of one specific data assimilation approach would be influenced sample sizes e g ns in equations 1 4 random errors in forcing data e g ω i t p and ω i t e in equations 5 and 7 and output measurements e g ε i t 1 y in equation 11 given the assumed distribution these random errors ω i t p ω i t e and ε i t 1 y are controlled by the tuning parameters τ p τ e and τ y in equations 6 8 and 12 respectively consequently to characterize the individual and interactive effects of these factors a number of scenarios are set for the specifications of these tuning parameters i e τ p τ e and τ y and the ensemble size i e ns in addition for one specific hydrologic data assimilation prediction problem different parameter assimilation schemes may present different abilities in producing probabilistic predictions zhang et al 2017 thus parameter assimilation scheme is also one uncertain source consequently the impacts from data assimilation algorithms are also need to be characterized as presented in table 2 four perturbation scenarios are tested with the proportionality factors being 0 1 0 2 0 3 and 0 4 the ensemble sizes of 20 50 100 and 200 are tested in combination with various error parameters in addition the enkf and its variants i e enkfsks and enkfksls are tested in this study 2 3 hydrological simulation in this study rainfall runoff simulation is undertaken through hymod which is widely used for hydrologic predictions wang et al 2021b the general concept of the model is based on the probability distribution of soil moisture modeling proposed by moore moore 1985 in brief a catchment consists of infinite points each defined by a soil moisture capacity c soil moisture capacity vary within the catchment because of variability in soil texture and depth a cumulative distribution function cdf describes catchment soil moisture variability f c 1 1 c c max b exp 0 c c max where c is soil moisture capacity cmax is the maximum storage capacity and the exponent bexp is the degree of spatial variability of storage capacity over the basin as shown in figure 1 the runoff generation process partitions excess rainfall into surface storage characterized by three quick i e rq and slow i e rs flow tanks through a partitioning factor i e alpha moore 2007 the total discharge from both quick and slow tanks is the generated streamflow in the river basin table 3 presents the descriptions and initial fluctuating ranges of the five parameters the five parameters including cmax bexp alpha rs and rq cannot be measured directly but can be obtained through a model calibration process fan et al 2016 fan et al 2015 to drive the hymod daily input data of precipitation p mm day and potential evapotranspiration e mm day are required for the sake of brevity we refer our readers to moore 2007 moore 1985 for a comprehensive description of hymod 2 4 disaggregated multi level factorial analyses factorial analysis fa is a powerful statistical method for examining the effects of multiple factors on response variables through experimental design and data analysis montgomery and runger 2010 to reveal potential interactions among multiple factors all possible combinations of the levels of factors are examined in a factorial experiment then the decomposition of the sum of squares as described within the analysis of variance anova theory are used to quantify the contributions of these multiple factors déqué et al 2012 wang et al 2022 to diminish the effect of the sample size on contribution quantification in factorial analysis subsampled factorial analysis was proposed by bosshard et al 2013 and extend as disaggregated multi level factorial analyses wang et al 2020 compared with traditional sensitivity analysis methods such as sobol s the proposed disaggregated multi level factorial analyses have been proven to have the essential strengths i are effective and feasible for sensitivity analysis with relatively low computational requirements and ii can characterize sensitivities for both numeric and non numeric variables in water resources and environmental models which can hardly be treated by the sobol s approach as a powerful statistical method to reveal potential interactions among multiple factors the disaggregated multi level factorial analyses have been used in fan et al 2020 and fan et al 2021 in this study the disaggregated multi level factorial analysis is applied to data assimilation experiments for exploring not only the direct effects from individual uncertainties but also more importantly the composite ones from multi layer and multi parameter interactions among these uncertainties in detail the disaggregated multi level factorial analysis is constructed based on the hypothesis that the enkf design parameters e g the ensemble size the precipitation error the potential evapotranspiration error and the observation error have an influence on the response variable i e the predictive accuracy and we want to quantify such influence to make this clear assuming that a generalized model is defined as y f a b c d where a b c d represent the experimental factors correspond to the scenarios of the enkf design parameters e g the ensemble size the precipitation error the potential evapotranspiration error and the observation error y represents the predictive accuracy i e nse rmse and crps there are i scenarios of the ensemble size j scenarios of the precipitation error k scenarios of the potential evapotranspiration error and l scenarios of the observation error totally there are i j k l estimations of the nse rmse crps values derived through hydrologic data assimilation in a complete factorial experiment in disaggregated multi level factorial analysis for each experimental factor two scenarios are selected out of all scenarios that results in a total of c t 2 specify that c is the combination symbol t is the total scenarios possible experimental factor pairs in details c t 2 1 1 1 2 2 t 2 t 2 t 1 2 3 t 3 4 t 1 t t therefore there are c i 2 c j 2 c k 2 and c l 2 possible experimental factor pairs for ensemble size precipitation error potential evapotranspiration error and observation error respectively finally n where n c i 2 c j 2 c k 2 c l 2 subsampling iterations are observed which end up with two ensemble size two precipitation error two potential evapotranspiration error and two observation error that define our model combination matrix for the variance decomposition for each subsampling iteration n n 1 2 n the total sum of the squares sst can be divided into the sum of squares due to individual model parameters and their interactions as follows according to the anova theory saltelli et al 2010 ss t n s s a n s s b n s s c n s s d n s s i n ss i n s s a b n s s a c n s s a d n s s b c n s s b d n s s c d n s s a b c n s s a b d n s s b c d n where ssa ssb ssc and ssd present the individual effects of ensemble size precipitation error potential evapotranspiration error and observation error respectively ssi means all interaction terms for the model combination matrix defined by two ensemble size two precipitation error two potential evapotranspiration error and two observation error the variance decomposition can be calculated as follows ss t n i 1 2 j 1 2 k 1 2 l 1 2 y i j k l y o o o o 2 ss a n 2 2 2 i 1 2 y i o o o y o o o o 2 ss b n 2 2 2 j 1 2 y o j o o y o o o o 2 ss c n 2 2 2 k 1 2 y o o k o y o o o o 2 ss d n 2 2 2 l 1 2 y o o o l y o o o o 2 ss i n i 1 2 j 1 2 k 1 2 l 1 2 y i j k l y i o o o y o j o o y o o k o y o o o l 3 y o o o o 2 where n is in 1 n and n c i 2 c j 2 c k 2 c l 2 the symbol o indicates averaging over the particular index for instance y o o o o indicates the average of y i e nse rmse and crps under all cases and y o o o o 1 16 i 1 2 j 1 2 k 1 2 l 1 2 y i j k l then for each effect the variance fraction η is derived as follows η a 1 n n 1 n ss a n ss t n η b 1 n n 1 n ss b n ss t n η c 1 n n 1 n ss c n ss t n η d 1 n n 1 n ss d n ss t n η i 1 n n 1 n ss i n ss t n the values of variance fraction η are range from 0 to 1 corresponding to a contribution of an experimental factor from 0 to 100 respectively for more information about ifa please see figure s1 in this study the disaggregated multi level factorial analysis is performed to identify the most sensitive parameters of the data assimilation including the ensemble size the precipitation error the potential evapotranspiration error and the streamflow observation error the results of sensitivity analysis provide a possible direction for improving the performance of hydrological data assimilation wang et al 2018 3 case study the proposed fhda model is tested for hydrologic data assimilation in daxi river located in the north part of china figure 2 shows the location of daxi river catchment as the tributary of jinghe river located in the middle of the loess plateau daxi river has a drainage area of 2485 km2 the annual precipitation of approximately 579 9 mm ran 1992 and the annual streamflow of 4 17 m3 s in general the daxi river basin has a semiarid and subhumid continental monsoon climate resulting in considerable temporal spatial variations in precipitation in this study the inputs of the hymod are obtained based on meteorological measurements at the national stations the black triangles in figure 2 while the streamflow measurements at zhangjiagou station 107 76e and 35 10 n are used for data assimilation with different parameter assimilation schemes the areal precipitation data for hymod were interpolated from site precipitation denoted as p measurements distributed over the catchment and the areal potential evapotranspiration denoted as e data were interpolated from potential evapotranspiration at the national meteorological stations in the jing river basin the streamflow observations at zhangjiagou station were used in this case study a total of 3286 days of data from january 1975 to december 1983 were used to assimilate daily streamflow the first 50 days was used as a spin up period to reduce sensitivity to state value initialization 4 performance of hydrological prediction 4 1 performances of different parameter assimilation schemes to explore the reliability of the parameter assimilation schemes including enkf enkfsks and enkfksls these methods are employed for real time hydrological prediction through hymod under different uncertainty scenarios in inputs outputs and sample size the initial ensembles for the five parameters i e cmax bexp alpha rs and rq are sampled uniformly from predefined intervals as shown in table 3 the initial ensembles for the state variable of the storage and slow flow tank are sampled from normal distribution the initial state variables of the three quick flow tanks are set to be 0 and the sample size used in this section is 50 three indices including root mean square error rmse the nash sutcliffe efficiency nse coefficient and continuous ranked probability score crps are used for the evaluation of the performance of data assimilation approaches li et al 2019 rmse and nse are based on the ensemble average which are expressed as rmse 1 n i 1 n q obs i q sim i 2 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 where q obs i are the observed streamflow q sim i are the simulated streamflow from the hydrologic model q obs is the mean of observed streamflow and n is the total number of observed or simulated streamflow the crps is a measurement of error for probabilistic prediction and defined as the integrated squared difference between the cdf of forecasts and observations fan et al 2017a hersbach 2000 murphy and winkler 1987 crps f sim x f obs x 2 d x where f sim and f obs are cdfs for predicted streamflow and observed streamflow respectively a small crps value indicates a better model performance with the value of zero suggesting a perfect accuracy for model prediction figure 3 shows the comparison of observations and predictions for daxi river through the different data assimilation schemes the results demonstrate that the predictive mean values can well track the observations and the associated 95 predictive intervals consisting of 2 5 and 97 5 quantiles can generally bracket the fluctuation during the three data assimilation schemes it is noticed that all data assimilation schemes provide accurate predictions during the low flow periods however for high flow periods enkfsks generates overestimations while enkfksls generates underestimations the three indices i e nse rmse and crps correspond to the predictions of enkf are 0 68 7 28 and 1 47 respectively those indices are 0 69 7 15 and 1 75 for enkfsks and 0 67 7 40 and 1 93 for enkfksls respectively consequently among these parameter assimilation schemes enkfsks has a best perform in both deterministic and probabilistic predictions if they are evaluated through nse rmse and crps the enkf generates best probabilistic predictions and enkfksls leads to worst probabilistic predictions figure 4 presents the temporal evolution of the five parameters in hymod i e cmax bexp alpha rs rq with 95 confidence intervals in the data assimilation process through enkf the corresponding temporal evolution of enkfsks and enkfksls are presented in figures s2 s3 the results indicate that all five parameters in hymod are identified well after a number of data assimilation steps a discharge series larger than 1000 days appear to be enough to quantify parameter distributions with limited ranges through enkf enkfsks and enkfksls in hydrologic models their parameters are generally interrelated and thus the optimal value of one parameter is dependent upon the values of other parameters fan et al 2017a similarly such interrelationships among parameters exist in the data assimilation process wang et al 2017b in this study the temporal variations of correlation among different pairs of parameters denoted as cmax bexp cmax alpha cmax rs cmax rq bexp alpha bexp rs bexp rq alpha rs alpha rq and rs rq measured through kendall s values are presented in figure 5 and figure s4 as shown in figure 5 the correlations among different parameters are varied in the enkf taking the interdependence of cmax bexp as an example these two parameters are generally positive correlated in the former data assimilation steps then develop a negative correlation structure in the later period the correlation among other parameters also shows similar characteristics the diverse correlation patterns observed implies that the dependence structures of one pair of parameters in hymod are varied in data assimilation process which is consistent with the research of fan et al 2017a for different parameter assimilation schemes the correlations of the obtained posterior parameters are diverse 4 2 impacts of sample size to further characterize the impacts of sample sizes on those three data assimilation schemes four sample scenarios are further tested for hymod in daxi river including 20 50 100 and 200 figure 6 presents the boxplot of model performances through enkf enkfsks and enkfksls under different sample size scenarios the results show that all three methods will perform better with an increase in sample size generally the enkfsks performs best than the other in both deterministic and probabilistic predictions if they are evaluated through nse rmse and crps in detail the enkf produce best predictions with higher values for nse lowest values for rmse and lowest values for crps followed by enkfsks and enkfksls when the same size is 20 the performance of enkf is better than enkfsks and enkfksls for probabilistic predictions in terms of crps when the same size is larger than 100 the lowest values for crps is obtained in enkfsks indicating closest distance between the predictive and observed cumulative distribution functions as shown in table 4 all the three parameter assimilation schemes can generate reliable results for both deterministic and probabilistic predictions as the increase of sample size hymod would generate reliable predictions with the deterministic and probabilistic evaluation indices varied within very limited intervals meanwhile the hydrological predictions are affected by the sample size and the increased sample size would increase the model performance significantly in comparison the enkf and enkfsks may generate unsatisfactory results with a sample size less than 50 and the enkfksls may generate unsatisfactory results with a sample size less than 100 therefore larger sample size may be required in parameter perturbation process to achieve good estimations 4 3 impacts of modeling inputs apart of the sample size the input and output measurement errors would also lead to uncertainties during data assimilation process stochastic perturbations are mandatory in a data assimilation framework to analyses the various uncertainty sources such as model inputs parameters and structures fan et al 2017b therefore to tackle these uncertainties random perturbations are added to the forcing data precipitation and evapotranspiration and streamflow observations in this study as recommended in many researches dechant and moradkhani 2012 rasmussen et al 2015 wang et al 2018 gaussian noise distributions are adopted for potential evapotranspiration and observations in this study for precipitation the log normal noise is employed as the better perform is reported by dechant and moradkhani 2012 moradkhani et al 2012 finally four scenarios were given on the strength of perturbations error standard deviations including 10 20 30 and 40 table 5 presents the performance of hymod at daxi river under different precipitation error disturbance obviously both the deterministic and probabilistic predictions of the three parameter assimilation schemes are insensitive to precipitation error disturbance similarly most of the posterior parameters are insensitive to precipitation error disturbance except bexp and alpha in enkfksls and cmax and alpha in enkfksls in the same way the effects of evapotranspiration error disturbance and runoff observation error disturbance on the model performance are presented in tables 6 and 7 respectively similar to precipitation error disturbance the evapotranspirationerror disturbance has little effect on the performance of the three parameter assimilation schemes as to the runoff observation error disturbance the increased disturbances lead to a decreased nse an increased rmse and an increased crps for the four data assimilation schemes meanwhile the four data assimilation schemes have different sensitivity to runoff observation error for instance with the runoff observation error disturbance increased from 10 to 40 the nse of predictions from enkfsks decreased significantly from 0 70 to 0 63 thus it s desired to examine the evolution of input and output uncertainties and their interactions that affect the predictive performance based on different index for each data assimilation scheme 5 individual and interactive effects of multiple impact factors 5 1 impacts of modeling inputs and parameter settings on specific data assimilation scheme in this section four experimental factors are considered including the ensemble size the precipitation error the evapotranspiration error and streamflow observation error to reveal their individual and interactive effects on the performances of three data assimilation schemes i e enkf enkfsks and enkfksls each factor has multi levels scenarios and a 44 factorial design contained 256 combinations is obtained for each data assimilation scheme according to factorial design 256 nse rmse and crps values are obtained then the disaggregated multi level factorial analysis is employed to examine the sensitivities of these design parameters quantitatively in term of the deterministic and probabilistic prediction indexes figure 7 depicts the standardized effects including main and interaction effects for the enkf enkfsks and enkfksls for enkf the main effects of the ensemble size the precipitation error the evapotranspiration error and streamflow observation error are 0 24 0 02 0 03 and 0 42 respectively if they are evaluated though deterministic predictions e g nse this means that the streamflow observation error is the most significant factor for deterministic predictions through enkf followed by the ensemble size the uncertainty caused by the forcing data errors i e the precipitation error and the evapotranspiration error are not quite visible wang et al 2017b claimed the identification of the uncertainty sources are conditional on different statistical e g the deterministic and probabilistic prediction indices since there is a different recursive pattern of parameter perturbation for them therefore the main effects evaluated though probabilistic prediction index i e crps are also presented in figure 7 like the deterministic prediction the streamflow observation error is still the most significant factor for the probabilistic prediction in daxi river followed by the ensemble size nevertheless comparing with the deterministic prediction the magnitude of the contribution caused by streamflow observation error slightly increased from 0 42 to 0 45 in probabilistic prediction and that caused by ensemble size decreased from 0 24 to 0 19 this means that the influence of streamflow observation on probabilistic prediction is more significant at the same time sample size has more impact on deterministic prediction for enkfsks the main effects of the ensemble size the precipitation error the evapotranspiration error and streamflow observation error are 0 12 0 03 0 04 and 0 40 respectively evaluated though the deterministic prediction e g nse these four kinds of uncertainty sources respectively have a main contribution of 0 45 0 03 0 03 and 0 08 for the probabilistic predictions comparing with the deterministic prediction the magnitude of the uncertainty caused by streamflow observation error significantly changed as presented in figure 7 b despite the above differences a common pattern is that streamflow observation error is the primary source of uncertainty for enkfsks data assimilation in daxi river followed by the ensemble size at the same time it can be found that the order of sources of uncertainty is the same as that for enkf no matter whether they are evaluated by deterministic or probabilistic prediction indices while the magnitude of the uncertainty for enkfsks varies greatly from that for enkf especially for deterministic prediction index the enkfsks is more sensitive to streamflow observation error in terms of deterministic prediction and sample size has more impact on probabilistic prediction for enkfksls as presented in figure 7c the four main effects are 0 12 0 06 0 06 and 0 08 for the deterministic prediction and 0 18 0 05 0 06 and 0 07 for the probabilistic prediction a marked difference is that ensemble size is the primary source of uncertainty for enkfksls data assimilation followed by the streamflow observation error this suggests that to obtain a better deterministic and probabilistic predictions more sample size is desired in enkfksls moreover it can be found that more than one third the uncertainty comes from the overall interactions of two factors overall the three parameter assimilation schemes have a common pattern despite a variety of magnitude differences first the streamflow observation error is the primary source of uncertainty for enkf and enkfsks which is the second uncertainty source for enkfksls this suggests that the streamflow observation error would influence prediction accuracy greatly in both deterministic and probabilistic predictions therefore well quantification of streamflow uncertainty is the most efficient way to improve prediction accuracy second the ensemble size is a very important source of uncertainty in data assimilation methods next to the streamflow observation error third the disturbances of input data i e precipitation and evapotranspiration have little influence i e the main effects are less than 0 06 on the prediction accuracy for all the four data assimilation schemes lastly the contributions of two factor interactions vary from 0 16 to 0 37 depends on different data assimilation methods and prediction indices the contributions of three factor interactions vary from 0 10 to 0 24 commonly the interaction effects evaluated through probabilistic prediction indexes i e crps are smaller than that evaluated through deterministic prediction indexes i e nse and rmse 5 2 impacts of data assimilation schemes to clarify whether different data assimilation schemes have a significant impact on the prediction results this study will analyze the uncertainty caused by data assimilation methods figure 8 presents the standardized effects including main and interaction effects of various factors on prediction accuracy from figure 8 the streamflow observation error 0 16 is the primary source of uncertainty followed by ensemble size 0 09 and data assimilation schemes 0 06 if they are evaluated though deterministic prediction index e g nse the main effects of precipitation error and potential evapotranspiration error are less than 0 02 at the same time these factors present significant interactions in affecting hydrologic prediction especially the interactions of two factors 0 27 in total the interactions decrease gradually with the number of interacted factors the results indicate that comparing with input measurement errors streamflow observation error plays a vital role in the deterministic data assimilation prediction process compared to the deterministic predictions the probabilistic predictions present a different sensitivity pattern for example the main effects of the data assimilation schemes and sample size increased from 0 05 and 0 09 estimated by nse to 0 22 and 0 15 estimated by crps respectively meanwhile the main effect of streamflow observation error decreased from 0 16 estimated by nse to 0 06 estimated by crps similar to the deterministic predictions the main effects of precipitation error and potential evapotranspiration error are also less than 0 02 for the probabilistic predictions at the same time the interactions of multi factors also decreased nearly half the choice of evaluation index not only influences the magnitude of the main effect of each uncertainty source but also influences the order of such main effects for instance evaluated by deterministic prediction indexes i e nse and rmse the order of the main effects would be err q ns method err p err e while under the scheme evaluated by probabilistic prediction index i e crps the main effects yield a different order method ns err q err p err e this means that the probabilistic prediction is more sensitive to algorithms and sample size in data assimilation process in order to improve the prediction accuracy it is necessary to optimize the data assimilation schemes or develop more advanced data assimilation schemes moreover more efforts to improve the accuracy of runoff observations and increase the number of samples are also recommended 6 discussion to quantify the interactive individual and integrative impacts of multiple uncertainty sources in the data assimilation hydrological model a disaggregated multi level factorial hydrologic data assimilation model fhda was developed in this study in fact the uncertainty sources contributions can also be characterized by the traditional factorial analysis approach while bosshard et al 2013 and wang et al 2020 have proved that fa would underestimate the variance in small sample size to diminish the effect of the biased variance estimator on the quantification of the variance contribution disaggregated multi level factorial analysis is incorporated into fhda in which each factor has multi level to be subsampled see section 2 4 after subsampling the quantification of such impacts under multi uncertainties is achieved through rigorous statistical inferences unbiasedly which is the most representative advantage of disaggregated multi level factorial analysis over the other sensitivity analysis methods fan et al 2020 in addition disaggregated multi level factorial analysis has the advantage of analyzing the latent interactions of numerical variables e g sample sizes and non numerical variables e g data assimilation schemes as well as their impacts on the modeling response e g streamflow prediction while the application of disaggregated multi level factorial analysis in complex models has a linear assumption wang et al 2021a the influence of this assumption on the results needs to be further explored here four uncertainty sources i e model input model observation ensemble size and data assimilation scheme in hydrologic data assimilation are quantified to explore the individual and interactive effects of them results presented in this application indicate that the streamflow observation errors influence hydrological prediction greatly in both deterministic and probabilistic predictions this can be explained by that the observational uncertainty defines how the filter trusts the observations and thus to what extent they are assimilated into the model piazzi et al 2021 thus it is critically important to reduce the observation error for improving prediction accuracy as illustrated in the case of daxi river the choice of parameter assimilation schemes for generating background parameter ensembles poses the most significant influence on hydrological prediction especially for probabilistic prediction pathiraja et al 2016 had demonstrated that parameter assimilation scheme was critical in determining the effectiveness of data assimilation samuel et al 2014 also indicated that there are significant differences in soil moisture variations and streamflow estimates when three assimilation approaches of ensemble kalman filter were applied at the same time results presented in this application also revealed that the performances for enkf and its variant would be insensitive to uncertainties in forcing data precipitation and evapotranspiration one possible reason is that biases in the input forcing are compensated in the state updating step over time which needs to be explored further another point highlighted here shows that the interactions among these uncertainty factors significantly affect hydrologic prediction especially the interactions between two factors this corroborates with the findings of others fan et al 2017a who proposed a coppf approach to improve the performance of hydrological data assimilation by introducing copulas to describe parameter interdependence bosshard et al 2013 had pointed out the nonnegligible contributions of interactions between the different uncertainty sources note though that we do not disentangle the errors from interactions in the disaggregated multi level factorial analysis which would require multiple realizations of each hydrologic modeling chain combination bosshard et al 2013 wang et al 2020 without considering the errors the importance of individual as well as interaction uncertainty sources may be overestimated slightly results presented in this paper may updated as more datasets cases become available and included an obvious future step will also be the inclusion of more catchments including semi arid semi humid and humid basins moreover the influences of dataset length geographical conditions topography vegetation human activities and other potential factors on the performance of hydrologic data assimilation model 7 conclusion in this study a disaggregated multi level factorial hydrologic data assimilation model fhda for exploring not only the direct effects from individual uncertainties but also more importantly the composite ones from multi layer and multi parameter interactions among multiple uncertainties the disaggregated multi level factorial analysis of hydrologic data assimilation experiments can examine the main contributions of various uncertainties sources including data assimilation scheme sample size forcing data error and observed data error on the predictive accuracy three parameter assimilation schemes i e enkf enkfsks and enkfksls are tested and the main findings are as follows first the streamflow observations can be well tracked by the 95 predictive intervals in data assimilation schemes the temporal evolution of model parameters for streamflow assimilation are uncovered in the daxi river watershed among the three data assimilation schemes enkfsks has a best perform if they are evaluated through nse rmse and crps second for each data assimilation scheme the streamflow observation error is the main source of uncertainty in both deterministic and probabilistic predictions third the data assimilation scheme contributes 0 06 0 22 for the ensemble prediction uncertainty if it is considered as one of the uncertainty sources comparing with ensemble size and input measurement error the data assimilation scheme plays a vital role in the predictions especially for probabilistic ones therefore to improve the prediction accuracy it is necessary to optimize the data assimilation scheme or develop more advanced data assimilation schemes moreover the interactions among multiple uncertainty factors significantly affect hydrologic prediction especially the interactions between two factors this study revealed the uncertainty sources in hydrologic data assimilation process and pointed out the vital role of data assimilation schemes in improving the hydrological data assimilation predictions the results of uncertainty analysis present a possible direction for improving the performance of hydrological data assimilation which provides a reference for the future research direction of hydrological data assimilation credit authorship contribution statement f wang data curation software writing original draft visualization g h huang writing review editing supervision funding acquisition y fan methodology software conceptualization writing review editing y p li supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research was supported by the strategic priority research program of cas xda20060302 natural science foundation u2040212 mwr cas institute of hydroecology and natural science and engineering research council of canada we are also very grateful for the helpful inputs from the editor and anonymous reviewers data availability statements the data that support the findings of this study are available from https www researchgate net publication 353286792 data for zhangjiagou the main r code used are available from https www researchgate net publication 356287977 main r code for development of a disaggregated multi level factorial hydrologic data assimilation model appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127802 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3298,sedimentary deposits in both colorado basin and salado basin two geological basins originated after the atlantic rifting in the coastal area of argentina contain deep confined aquifers bearing thermal waters previous studies on the paleogroundwater of this region have been limited by the radiocarbon dating range in this study 81kr dating is applied to reveal groundwater ages up to 1 1 ma so far the oldest found in south america groundwater in the colorado basin previously assigned to the last glacial maximum lgm is reassigned to a period from marine isotope stage 1 to 5 mis 1 to mis 5 the age information combined with water stable isotopes and noble gases suggests the possible existence of the south american low level jet sallj in this period that had carried the recycled water vapor from the tropical amazonia to locations further south compared to the present time also the inferred recharge conditions in both basins during mid pleistocene agree with the very dry climate in this period suggested by previous studies keywords 81kr dating thermal groundwater mid pleistocene paleoclimate deep aquifers in argentina radiogenic4he 1 introduction 81kr t1 2 229 000 a an ideal isotope tracer for dating very old groundwater has been applied to some of the largest aquifer systems worldwide including the nubian aquifer the baltic artesian basin and the north china plain aquifer revealing old groundwater up to 1 ma old sturchio et al 2004 li et al 2017 matsumoto et al 2018 matsumoto et al 2020 gerber et al 2017 in south america 81kr dating of very old groundwater up to 770 ka was performed to reveal 4he degassing and the hydraulic flow system of the guaraní aquifer aggarwal et al 2015 vives et al 2020 in this work deep confined aquifers in thick sedimentary basins situated on the atlantic coast of central argentina 35 s to 40 s are studied with both 81kr and 14c covering an extended age range from a few hundred years to 1 3 million years loosli and oeschger 1969 lu et al 2014 jiang et al 2020 aquifer water in the geological basins of the province of buenos aires argentina is presently pumped up and used mostly to supply thermal resorts among the few previous studies that had been done to estimate groundwater ages the aquifer of the southern basin was dated with 14c bonorino 1988 which showed results beyond the radiocarbon dating range of 30 ka before present in this work the combination of 81kr and 14c allows us not only to determine the much older recharge time but also to characterize the dispersion effects in groundwater transport moreover with information retrieved from multiple tracers water stable isotopes water chemistry and noble gases we are able to improve the conceptual models of the confined aquifer system and adding new knowledge on the pleistocene climate in the region the paper is organized as follows first background information about the study area is are introduced the sampling and analytical methods are presented in section 2 in section 3 various data including hydrochemistry data stable water isotopes tracer data 3h 14c and kr and noble gases data are presented finally in section 4 discussions based on the data are given in this section the recharge routes of the study areas are identified then the interpretation of the data focuses on the recharge conditions where the water stable isotopes and noble gases are used to infer the climatic conditions during recharge and the 14c 81kr tracer data are used to estimate when the recharge occurred several hypotheses about the middle and upper pleistocene climate in the study area are presented the relation between these hypothesis and previous studies are discussed as well 1 1 geological and hydrogeological features of the study area the study region covers two major tectonic basins salado basin and colorado basin separated by a positive structural area fig 1 precambrian and paleozoic rocks are exposed in the tandilia and ventania ranges between them a 9 km thick paleozoic sequence has accumulated in the claromecó basin ramos 1999 the salado basin sb and colorado basin cb are rift basins generated during the late jurassic to early cretaceous period as a result of the gondwana breakup and the opening of the south atlantic ocean the sedimentary sequence of sb unconformably overlies the serra geral basalts cretaceous in cb palaeozoic quartzitic rocks from the ventania and granitic environment constitute the basement of the hydrothermal system bonorino 1988 fig 2 due to their common origin the sedimentary fillings of sb and cb are quite alike with greater than 6 km thick cretaceous to quaternary deposits fig 2 the lower section of both basins is made of early cretaceous continental red beds composed of conglomerates sandstones and mudstones yrigoyen 1975 the middle section sag basin phase begins with cretaceous red beds general belgrano formation colorado formation followed by maastrichtian danian deltaic and transitional deposits sb las chilcas formation cb pedro luro formation composed of greenish gray deposits and claystones with subordinated sandstones gypsum and anhydrite the upper sections of the sedimentary fillings passive margin stage are composed of continental and transgressive regressive marine sequences corresponding to olivos formation in sb and elvira ombuctá formations in cb yrigoyen 1975 the uppermost part of the sedimentary filling consists of loess and loess like deposits pampean formation the main hydrogeological units in sb and cb can be divided into three sequential sections sala 1975 the upper section has an aquifer behavior it is formed by fluvial and eolian sediments that consist of the semi confined puelche aquifer and the unconfined semi confined pampeano aquifer these aquifers are the most important water resource in the province the intermediate section is represented by the paraná formation sb and barranca final cb consisting of clays and sands deposited during the middle miocene lower pliocene marine ingression this section has a thickness of several hundred meters and is recognized by its characteristic green color its hydrogeological behavior is that of an aquitard and is usually considered the hydrogeological basement the lower section includes the tertiary sediments named as olivos sb and ombucta pedro luro formations cb in addition these neogene formations constitute aquifers containing thermal groundwater 2 sampling and analytical methods the first sampling campaign in 2017 2018 covered 11 wells fig 1 table 1 samples were collected for major ion chemistry water stable isotopes 3h 14c and noble gases in situ parameters including temperature ph electrical conductivity ec were recorded a second campaign in 2019 collected samples for 81kr analysis from 8 of the 11 wells because at that time the wells sbr 2 and cbr 2 were not accessible and the pumping system was out of operation for sbr 1 the samples are named after the basin they belong to cb colorado basin sb salado basin and the well locations within each basin r close the supposed recharge zone d far from the recharge zone salinity was in cb an additional criterion to assign a sample to r or d groups assuming that a lower salinity is observed closer to recharge zones for example sample cbr 3 is the sample number 3 of the recharge zone r in the colorado basin cb chemical and stable isotope analyses were performed at the hydrogeochemistry and isotope hydrology laboratory of national university of mar del plata argentina water stable isotopes 2h h 18o 16o were analyzed using a lwia 45 ep laser spectroscopy analyzer the analytical uncertainties are 0 15 for δ18o and 1 0 for δ2h 3h was determined by liquid scintillation counting at the isotope hydrology laboratory of the international atomic energy agency iaea and by the university of waterloo it was also measured using the 3he ingrowth method at the hungarian institute for nuclear research 14c and δ13c were analyzed using accelerator mass spectrometry ams at both the university of waterloo and the hungarian institute for nuclear research for stable noble gas isotopes groundwater samples were collected in copper tubes and isolated with pinch off metal clamps to avoid gas exchange with the atmosphere dissolved gases were extracted and analyzed using a magnetic sector mass spectrometer for helium and a quadrupole mass spectrometer for neon to xenon at the isotope hydrology laboratory of iaea matsumoto et al 2017 all analytical results are given in annex 2 of the supplementary material dissolved gas samples for 81kr analyses were taken with a gas extractor and were analyzed using the atom trap trace analysis atta method at the university of science and technology of china ustc local air samples containing 85kr t1 2 11 y were collected in order to assess possible atmospheric contamination during sampling details of the sampling and analytical methods are given in lu et al 2014 3 results 3 1 field parameters and hydrochemistry the relationship between the water temperature and the total depth of each well table 1 reveals different thermal gradients in the salado and the colorado basins despite their similar tectonic evolution and stratigraphy the gradient is 4 5 c 100 m for cb and 2 5 c 100 m for sb the higher anomalous thermal gradient in cb was attributed to a locally thinned continental crust allowing convective water currents in a high fracture density zone kostadinoff reartes 1993 the temperatures regressed at the surfaces are 18 c for cb and 14 5 c for sb close to the mean air temperature of the areas fig 3 the samples have a large range of salinities expressed by ec table 1 fig 3 in sb ec increases linearly with depth in cb samples in the area covering the city of bahía blanca cbr 1 and cbr 2 and a neighboring town to the southwest cbr 3 have ecs below 3 5 ms cm samples situated 50 km to the south cbd 1 and cbd 2 have high salinities and ecs above 100 ms cm the cationic composition is mostly homogeneous with a high dominance of sodium waters but the samples at sbr 1 have higher proportions of calcium and magnesium the anionic composition of most of the thermal waters is chloride or chloride sulfate types but the three low salinity samples of cb have dominant amounts of bicarbonates fig 4 in sb the waters with lower ec values sbr 1 11 0 ms cm sbr 2 2 44 ms cm are also differentiated because they have a higher proportion of calcium or bicarbonate the waters with ec values higher than 50 ms cm are mostly sodium chloride waters with significant proportions of sulfate and calcium in cb all samples are of sodium type but the low salinity waters cbr 1 cbr 2 and cbr 3 with ec values below 3 5 ms cm are differentiated because of their higher proportion of bicarbonate in the anionic composition the high saline waters with ec values above 110 ms cm are sodium chloride waters 3 2 stable isotopes of water δ2h and δ18o the water stable isotope values vary over a wide range table 2 and are plotted in a δ18o vs δ2h diagram fig 5 a together with the global meteoric water line gmwl the four groups of samples cbr cbd sbr and sbd are separated on the δ18o vs δ2h diagram within each basin there are two groups one including samples along a trending line of slope close to that of gmwl 8 and the other more enriched in 18o with a gentler slope than gwml the most isotopically depleted samples are those from cb located closer to the recharge area bonorino 1988 bonorino et al 1989 these three samples cbr have low salinities and a high deuterium excess and form a line parallel to gmwl fig 5 a they are isotopically more depleted compared to the weighted average values δ18o 5 79 δ2h 37 9 of the present precipitation in bahía blanca station from the global network of isotopes in precipitation gnip iaea wmo current year on the other hand the high salinity cbd samples lie below the gmwl fig 5 a but defining a slope lower than 2 i e not in the range of an evaporation line slope 3 to 5 this suggests that they are affected by the 18o shift due to the interaction with rocks at a high temperature ma et al 2010 as it was also proposed by bonorino et al 1989 plotting δ18o vs d excess fig 5 b is another way to show the clustering of the samples cbr samples are depleted having a d excess over 10 while samples at sbr are relatively more enriched isotopically and having lower d excess values around 5 on the other hand waters from the discharge zones are progressively enriched with decreasing d excess values in sb one group is formed by the low salinity samples at the borders of the basin sbr 1 and sbr 2 and the saline sbr 3 fig 5 c the salinity difference is because sbr 1 and sbr 2 are from the relatively shallow wells placed on the elevated bedrock blocks where the miocene marine transgression deposits are thin or not present while sbr 3 is from a deeper well in the sunken block having and crossing several hundred meters of marine clay fig 2 the other group is formed by the high salinity samples at the axis of the basin sbd the sbr samples are along a line of slope 7 17 with a d value of 1 58 the high salinity samples from the axis of the basin sbd are isotopically more enriched and fit along a line of slope 3 56 resembling an evaporation line el it is quite different from the present values at a close representative gnip station in azul city present precipitation at that station has a lmwl δ2h 8 16 δ18o 13 2 dapeña et al 2010 and a weighted average isotope composition of δ18o 5 5 and δ2h 31 3 3 groundwater age tracers 3h 14c and 81kr 3 3 1 3h the concentrations of 3h in the groundwater samples table 2 are mostly below the detection limit 0 8 tu confirming that the samples contain negligible amount of young groundwater 3 3 2 14c most of the samples yielded 14c values below 5 pmc table 2 and given the potential for atmospheric contamination and following aggarwal et al 2014 these samples are considered to be older than 30 ka then the following discussions about corrected 14c ages based on different models are focused on the 3 samples with radiocarbon contents higher than 5 pmc see table 2 sample sbd 2 showed a radiocarbon content of 9 12 pmc however the 85kr measurement indicated the observed 14c is most likely due to contamination by modern air it is therefore not included in the discussion below two single sample based models for radiocarbon dating of dic i e the iaea model and the han plummer s model are used to calculate the corrected 14c ages following the procedures in han and plummer 2016 the iaea model and the han plummer s model are chosen because the observed δ13c values fall into their applicable ranges moreover it is known that the results calculated from the han plummer s model can be biased to younger ages while the results calculated by the iaea model may be biased to older ages han and plummer 2016 by applying these two models we can show the variation of the obtained 14c ages due to different model selections the initial 14c activities and corrected 14c ages are presented in table 2 in the 14c calculations the values of biogenic soil co2 is assumed to have δ13c of 25 and the δ13c for carbonates is assumed to be 0 the obtained initial 14c activities and corrected radiometric ages are shown in table 2 pointing the focus in samples cbr 1 and cbr 3 it is observed that initial activities differ from values around 40 pmc for the han plummer s model to values around 70 pmc in the iaea model the corrected 14c ages range from 3 4 ka to 20 7 ka for sample cbr 2 the corrections result in negative ages indicating over correction from both models the causes could be other geochemical processes that are not included in the 14c correction models this sample is excluded for the rest of the discussions 3 3 3 81kr the apparent 81kr age of a groundwater sample can be calculated according to purtschert et al 2013 1 ag e 81 k r t 1 2 ln 2 ln i a 81 100 where ia81 is the 81kr abundance of the sample relative to that of the modern air the unit pmkr stands for percent of the modern 81kr level 85kr half life 10 8 a activities are also measured in order to check modern air contamination among all samples six of them show low modern contaminations 3 two samples sbr 3 and sbd 2 have more significant contaminations up to 20 the contamination is likely caused by the complex piping of the thermal water from resort wells the effect of modern air contamination can be corrected using the measured 85kr activities see supplementary material annex 1 for details in two cases that correspond to low salinity waters of cb the 81kr ages are young close to the 14c dating range the sample from the border sbr 3 has a 81kr age of 640 ka the high salinity waters in the southern part of cb and the center part of sb have 81kr ages close to 1 ma these are the oldest groundwaters found so far in south america fig 5 d 3 3 4 noble gases the samples analyzed see table 3 in supplementary material annex 2 here yielded 4he concentrations varying from 3 10 7 cm3 stp g to 3 10 5 cm3 stp g and are all significantly enriched in 4he compared with the concentrations in modern groundwater typically 10 8 cm3 stp g the isotope ratio of helium 3he 4he is significantly lower than the atmospheric ratio 1 4 10 6 3he 4he and ne he ratios form a clear mixing trend extending from the atmospheric component at the recharge to the crustal radiogenic component fig 6 the enhanced 4he concentrations reflect long term accumulation of radiogenic 4he within the aquifer solomon 2000 all samples are along a line from the atmospheric component to the crustal component sbr 1 and sbr 2 samples sb borders are the closest to the atmospheric component and the samples corresponding to brines sbd 1 sbd 2 sbd 3 cbd 1 cbd 2 the closest to the crustal component there is no ng result for sbr 3 because the sampling is impeded by an abundance of gas bubbles in water the 81kr ages provide additional information about the origin of 4he in the samples a typical in situ production rate of 4he in sedimentary rock by local u and th decay is about 6 10 12 cm3 stp g a wei et al 2015 by applying this rate the observed amounts of 4he in the samples yield 4he ages that are 0 5 16 times their respective 81kr ages this discrepancy suggests that the in situ production is too slow to account for the observed 4he concentrations over the time scales suggested by the 81kr ages and that an external basal 4he flux into the aquifer is required to contribute the amount of 4he in the samples e g torgersen ivey 1985 this external basal flux is higher in cb resulting in lower ne he ratios in the recharge area the higher basal flux in cb compared with sb could be the result of the larger number of faults and block displacements at relatively low depths fig 2 inoble2 7 code was used to calculate both the noble gas temperature ngt at recharge and the excess air aeschbach hertig et al 2000 wilson mcneill 1997 based on the measured noble gas contents in the water samples most of the samples show a ʃχ2 error too high probably due to the effect of high temperatures for old thermal groundwaters with high salinities this is not uncommon and the ngt cannot be reliably recovered in these cases only the sampling sites cbr 1 and cbr 3 give reasonable results ʃχ2 0 19 and 0 75 the obtained ngt is 16 c for cbr 1 and 13 c for cbr 3 the excess air values are 7 39 and 3 30 cc kg respectively 4 discussion 4 1 recharge routes of the colorado and salado basins groundwater flow in the artesian aquifer of cb has been studied since the work of bonorino 1988 pointing to a recharge area close to the ventania range however the recharge area for the thermal aquifers in sb is still unknown hernández et al 1975 suggested a probable recharge through overlying layers along the piedmont of the tandilia range with elevated bedrock blocking the southern border carol et al 2010 considered that the recharge could occur by leaking from the overlying parana formation in this work the hydrochemical features of lower salinity lower calcium or bicarbonate composition the ne he ratios closer to the atmospheric component and the water age all combine to support the hypothesis of recharge at the piedmont moreover recharge from the northern border of the basin is also identified from the occurrence of low salinity waters with a ne he ratio that duplicate the values observed in the axis the flow is from the borders of sb in the area of the two regional faults towards the depocenter 4 2 recharge conditions and impact on paleoclimate records the stable water isotopes and noble gases of the groundwater carries paleoclimate information in these two basins of the pampa however these data may be masked by the water rock interactions during the long residence time underground in this section we will try to identity the effects of water rock interactions and retrieve the paleoclimate information during recharge as mentioned earlier in each basin there are two groups of groundwater fig 5 a sub modern groundwater group parallel to gmwl and an old groundwater group that is shifted to the right due to δ18o enrichment because of their different behaviors in fig 5 and different ages separate discussions about these two groups are given below 4 2 1 sub modern groundwater group a samples close to the recharge zone in the colorado basin cbr the three samples from this area have 14c activities larger than 5 pmc corrected 14c ages are calculated based on two single sample based models the iaea model and the han and plummer s model the sample cbr 2 shows both high 14c activity and δ13c as a result both radiocarbon models over correct this sample and produce negative ages it is therefore excluded from the analysis the other two samples have 14c ages between 3 4 ka and 20 7 ka which agree with the results of bonorino 1988 however the 81kr ages are all older than the 14c ages see table 2 for cbr 1 the 14c age is 3 4 ka han plummer s model 7 4 ka iaea model while its 81kr age is 30 1 8 5 8 7 ka for cbr 3 the 14c age is 16 4 ka han plummer s model 20 7 ka iaea model while 81kr age is 49 1 9 3 9 6 ka the difference between 14c and 81kr ages can be explained by dispersion in the groundwater transport process joint analysis of tracers with different time responses allows us to go beyond the piston flow model and take the effect of dispersion into account the effect of dispersion on tracer age distributions and groundwater ages can be considered with a dispersion model as described by maloszewski zuber 1982 and applied in many examples such as the works of corcho alvarado et al 2007 visser et al 2013 gilmore et al 2016 etc here a dispersion model that results in a transit time distribution ttd with an inverse gaussian form is used for the analysis see supplementary material annex 3 for details waugh et al 2003 the ttd function is controlled by two parameters γ is the mean age of the groundwater δ is the width of the ttd function the peclet number pe relates both parameters pe δ γ 2 and characterizes the degree of mixing or dispersion by combining the 14c and 81kr ages these two parameters can be determined see annex 3 for details following a method reported in ebser et al 2018 the inferred ttd functions for cbr 3 and cbr 1 are plotted in fig 7 in both cases the pe values indicate significant contribution from dispersion during the groundwater transportation the cbr 1 sample shows a larger dispersion than the cbr 3 sample if the han plummer s model is used for the 14c correction no solution can be found with the measured 14c and 81kr data for cbr 1 this suggests that the iaea model may be a better model to use for this case other reasons such as modern figs 8 and 9 air contaminations or mixing with young groundwater could cause the disagreement between radiocarbon and 81kr ages as well however modern air contamination during sampling was ruled out based on the very low 85kr contents and the similar radiocarbon values previously obtained by bonorino 1988 the very low 3h contents reject the possibility of mixing with young groundwater based on these evidences we conclude that the dispersion during groundwater transportation is more likely to be the cause of the observed age differences between 14c and 81kr the high dispersion observed could be due to the high heterogeneity of the grain size composition of the aquifer plus the long flow paths as dispersion is depending on the scale of the groundwater transportation gelhar et al 1992 the above observation brings new insights about the time of recharge previously the recharge time was proposed to be during the last glacial maximum lgm based on the isotopically depleted values and the 14c ages bonorino 1988 based on the relative sea level data the lgm occurred from 26 5 to 19 0 ka which sits inside mis 2 29 14 ka lisiecki and raymo 2005 clark et al 2009 however the results for these two wells indicate that recharges are distributed over a much longer period of time from mis 1 to mis 5 fig 6 for cbr 3 the recharge is concentrated in a period from mis 1 to mis 3 while for cbr 1 the recharge is more concentrated in mis 1 the isotopic composition is measured to be depleted against the present precipitation which suggests that the recharge happened at a colder temperature however ngt values for cbr 1 16 c and cbr 3 13 c are close to the present mean temperature values of 15 1 c for bahía blanca city a possible explanation for the lower isotopic contents is the provenance from a different vapor source affected by the continental effect in those periods comparing to the studies on ice cores retrieved from vostok in east antarctica red curves in fig 87 we see that these recharges mainly happened in a period with low d excess compared to present jouzel et al 1982 vimeux et al 1999 yiou et al 2001 here the d excess record from vostok is used as a global indicator although the local d excess at our study region may have a different value than the precipitation in east antarctica it should follow a similar trend based on this assumption we can make estimations on the average d excess of cbr 1 and cbr 3 using the recovered ttds and the vostok d excess record the calculation shows that the average d excess of cbr 1 14 0 and cbr 3 13 3 are both lower than the d excess in the modern local precipitation 15 5 interestingly the water isotope measurements show a greater d excess relative to gmwl and the modern precipitation instead fig 5 a and fig 5 b we suggest that the observed high d excess could be a result of enhanced moisture recycling froelich et al 2002 a possible scenario is that the recycled vapor is brought by the south american low level jet sallj from the amazonas basin which is strengthened by the displacement of the south atlantic subtropical high sash heil et al 2010 the sallj was first recognized in the 1980 s with the aid of sparse radiosonde station data and satellite derived cloud winds and it can reach as far as the de la plata river basin containing sb but north to cb in the south what is particular interesting is that this scenario not only suggest that sallj may have existed as early as in mis 3 but also suggest that it may have extended further south into the colorado basin compared to the present time although the proposed mechanisms are consistent with the variations of the regional climate forcing there may be possibilities other than the hypothesis proposed above especially considering the limited data the uncertainty of the measurements and the limitations on the simple form of the ig ttd one alternative is a two component mixing with one end member substantially older than mis5 although it may be hard to explain the observed low salinity obviously additional efforts are needed to further constrain the model and confirm the hypothesized processes one way to go beyond the ig ttd used in this study is to use shape free age distributions holzer primeau 2010 massoudieh et al 2014 more tracers are needed to constrain such a more complex ttd with sufficient amount of data groundwater studies may provide supplements to the current climate proxy records marine sediment ice core loess spalletium etc mostly found in the northern hemisphere voelker 2002 b samples close to the recharge zone in the salado basin sbr in this group the 14c activities of the samples are below or close to the background leading to calculated ages larger than 30 40 ka one of them is dated with 81kr with an apparent age 640 ka sbr 3 the ages of sbr 1 and sbr 2 are unfortunately not dated with 81kr their ages are likely well beyond the 14c dating range as their ne he ratio are toward the crustal member the fact that the ne he ratios for sbr 1 and sbr 2 are closer to the atmospheric member indicates ages younger than sbr 3 the two younger samples sbr 1 and sbr 2 have a depleted δ18o value around 5 5 while the older one sbr 3 is more enriched with a δ18o of 4 19 the isotopic composition of these waters is characterized by a d excess lower than the present precipitation the observation is consistent with dominating marine vapor sources from the adjacent ocean with a high relative humidity at the sea surface compared to the modern ocean froehlich et al 2002 pfahl sodemann 2014 4 2 2 very old groundwater group a samples at the southern part of the colorado basin cbd this group of samples is isotopically more enriched compared to cbr with δ18o values ranging from 5 0 to 3 5 the data shows a notable horizontal 18o shift with a gentle slope of 1 6 the 81kr ages of these samples are all around 900 ka the observed 18o shift is attributed to the water rock interaction wri at high temperatures the cbd 2 has a larger 18o shift compared to cbd 1 due to stronger wri this trend can also be seen on the giggenbach triangle giggenbach 1988 in which cbd 2 is closer to the fully equilibrated waters at the temperatures line around 150 c fig 98 and can be then considered close to the water rock interaction extreme member the isotopic composition of the aquifer forming rock is unknown according to a previous study zakharov and bindeman 2019 δ18o positive values in the range of 2 to 8 could be supposed the composition of the old ground water upon recharge can be obtained by plotting the line that goes through cbd 1 and cbd 2 backward to the gmwl see fig 5a alvis isidro et al 1993 mook 2001 the interception shows that the recharge happened at 900 ka with more enriched isotopic value than those in the cbr samples which could hint at a warmer climate however more data are needed to further support this hypothesis b samples at the axis of the salado basin sbd this group includes the oldest water in this study their 81kr ages are all around 1 ma in mid pleistocene they are isotopically enriched water compared to sbr fitting to a line with a slope of 3 5 a progressive isotope enrichment is observed from sbd 1 to sbd 3 on the δ2h vs δ18o plot fig 5 the enrichment is well correlated r2 0 99 with the increase of salinity expressed in chloride concentration fig 5 c the linear relationship and their uniform ages suggest that these water are formed from mixing between two end members one end member is a low salinity and isotopically depleted recharge water the other is an enriched brine the interception of the line with the meteoric water line reveals the low salinity end member and the recharge conditions of the salado basin during the mid pleistocene the δ18o value at the interception around 4 is slightly more enriched than the present contents in the precipitation in the area 5 this could be a result of climate conditions warmer than present during recharge although the uncertainty is fairly large this hypothesis seems to be in line with previous studies on loess and sediments from the region heil et al 2010 the origin of the brine end member is less clear the wri at the observed temperatures are not enough to explain the high salinity of the water other possible explanation includes the leaking of high salinity connate water from the overlying marine sediments but this water should be free of 81kr and the mixing should have resulted in different apparent ages instead of the observed similar ages recharge from an evaporated shallow sea is another possibility however it is ruled out by the existence of 300 400 m of plastic marine clay deposited during the upper miocene which would impede water infiltrating from the surface in this area lastly recharges from saline lakes seem to be the most plausible hypothesis it has some support in the occurrence of gypsum deposits observed in the nearby claromecó basin del blanco et al 2005 indicating the existence of supersaturated brines the present arid conditions in the pampa patagonia transition area including large saline lakes can be extrapolated to the past conditions in the sb the infiltrated brines mixed with precipitation recharged at the same time at elevated zones to form the observed groundwater fig 109 the mixing process does not change the age of the mixed water but the resulting salinity and water isotopic composition are different depending on the degree of mixing a similar phenomenon of groundwater recharge redissolving previously precipitated salts on lake beds was observed by kwicklis et al 2021 at pahute mesa nevada usa 4 2 3 pleistocene climate during recharge the above discussions and the proposed hypothesis are in agreement with paleoclimatic inferences based on sedimentological and paleomagnetic analysis carried out in the study region in this regard the magneto climatological study of a continental succession at the northern margin of sb indicates arid conditions some time prior to the matuyama brunhes polarity transition bidegain et al 2005 later the environmental magnetic characterization of a 1 9 ma section in the same area heil et al 2010 reveals the occurrence of the driest conditions in 0 96 1 93 ma which coincides with the lowest summer sea surface temperatures in the southern ocean and the lower variability between glacial and interglacial stages becquey gersonde 2002 2003 the dominance of general arid conditions at 1 ma in central argentina occurred when the great patagonian glaciations took place in southern patagonia and the glaciers reached their major extension rabassa et al 2005 the prevailing aridity is thought to result from less moisture carried to tropical and subtropical south america due to a northward displacement of both the south atlantic anticyclone and the polar front zone heil et al 2010 this condition of a very arid period with a strong marine vapor influence and minimal contributions from tropical humidity in the mid pleistocene is in line with the enriched water stable isotopes of the recharge inferred from the cbd and sbd samples and the hypothesis of recharging through saline lakes 5 conclusions the 81kr dating method allows study of old groundwater up to 1 1 ma in the deep sedimentary basins in the central coastal argentina the multiple age tracers combined with water stable isotopes water chemistry etc provide new insights to the groundwater recharge time as well as the paleoclimate condition at that time in this region it shows that deep groundwater can be used as a proxy for paleoclimate studies several climate changes along the pleistocene were insinuated based on isotope proxies and groundwater dating the results from two wells in the cbr zone allowed re examination of the recharge period and conditions based on the new information it was proposed that the recharge occurred during mis 1 to 5 and that the sallj existed further south for that time mid pleistocene climate can also be observed from those proxies from the trends in isotope compositions and the very high salinity of the waters the recharge climate at 1 ma was assigned to arid conditions as the most feasible explanations future exploration with denser sampling in this region may shed more lights on these aquifers and the paleoclimate conditions in south america funding this works is supported by the national natural science foundation of china grants no 41861224007 no 41727901 the national key research and development program of china grant no 2016yfa0302200 the international atomic energy agency iaea through the coordinated research project crp f33023 a bilateral cooperation project between the national natural science foundation of china nsfc and the national council of scientific and technological investigations conicet of argentina resol 2018 308 apn dir conicet the national found for science and technology of argentina foncyt through the project pict2018 01584 credit authorship contribution statement d e martínez conceptualization funding acquisition investigation writing original draft w jiang conceptualization writing original draft resources t matsumoto supervision conceptualization funding acquisition resources o m quiroz londoño investigation writing review editing visualization resources f ritterbusch investigation writing review editing c lexow investigation writing review editing g m yang resources investigation validation l bertolín resources investigation j mabry resources investigation validation n romeo resources investigation validation m zárate conceptualization investigation writing review editing z t lu supervision conceptualization funding acquisition resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the cooperation in sampling activities from the colleagues rene albouy melisa glok galli sebastian grondona eduardo kruse leandro rodrigues capitulo and hector massone also to the managers of thermal resorts lucio serron martin lezcano roberto rivademar leandro oldoni and oscar ibarra who facilitate the field activities on their thermal waters wells we thank dr luis araguas iaea for a very useful discussion about the correction models for radiocarbon dating the technician gustavo bernava preformed the water chemical analyses different areas of conicet contributed in the office of foreing commerce helped for importing the sampling machine and the office of international cooperation and the scientific technological centre cct mar del plata developed the general project administration appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127846 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3298,sedimentary deposits in both colorado basin and salado basin two geological basins originated after the atlantic rifting in the coastal area of argentina contain deep confined aquifers bearing thermal waters previous studies on the paleogroundwater of this region have been limited by the radiocarbon dating range in this study 81kr dating is applied to reveal groundwater ages up to 1 1 ma so far the oldest found in south america groundwater in the colorado basin previously assigned to the last glacial maximum lgm is reassigned to a period from marine isotope stage 1 to 5 mis 1 to mis 5 the age information combined with water stable isotopes and noble gases suggests the possible existence of the south american low level jet sallj in this period that had carried the recycled water vapor from the tropical amazonia to locations further south compared to the present time also the inferred recharge conditions in both basins during mid pleistocene agree with the very dry climate in this period suggested by previous studies keywords 81kr dating thermal groundwater mid pleistocene paleoclimate deep aquifers in argentina radiogenic4he 1 introduction 81kr t1 2 229 000 a an ideal isotope tracer for dating very old groundwater has been applied to some of the largest aquifer systems worldwide including the nubian aquifer the baltic artesian basin and the north china plain aquifer revealing old groundwater up to 1 ma old sturchio et al 2004 li et al 2017 matsumoto et al 2018 matsumoto et al 2020 gerber et al 2017 in south america 81kr dating of very old groundwater up to 770 ka was performed to reveal 4he degassing and the hydraulic flow system of the guaraní aquifer aggarwal et al 2015 vives et al 2020 in this work deep confined aquifers in thick sedimentary basins situated on the atlantic coast of central argentina 35 s to 40 s are studied with both 81kr and 14c covering an extended age range from a few hundred years to 1 3 million years loosli and oeschger 1969 lu et al 2014 jiang et al 2020 aquifer water in the geological basins of the province of buenos aires argentina is presently pumped up and used mostly to supply thermal resorts among the few previous studies that had been done to estimate groundwater ages the aquifer of the southern basin was dated with 14c bonorino 1988 which showed results beyond the radiocarbon dating range of 30 ka before present in this work the combination of 81kr and 14c allows us not only to determine the much older recharge time but also to characterize the dispersion effects in groundwater transport moreover with information retrieved from multiple tracers water stable isotopes water chemistry and noble gases we are able to improve the conceptual models of the confined aquifer system and adding new knowledge on the pleistocene climate in the region the paper is organized as follows first background information about the study area is are introduced the sampling and analytical methods are presented in section 2 in section 3 various data including hydrochemistry data stable water isotopes tracer data 3h 14c and kr and noble gases data are presented finally in section 4 discussions based on the data are given in this section the recharge routes of the study areas are identified then the interpretation of the data focuses on the recharge conditions where the water stable isotopes and noble gases are used to infer the climatic conditions during recharge and the 14c 81kr tracer data are used to estimate when the recharge occurred several hypotheses about the middle and upper pleistocene climate in the study area are presented the relation between these hypothesis and previous studies are discussed as well 1 1 geological and hydrogeological features of the study area the study region covers two major tectonic basins salado basin and colorado basin separated by a positive structural area fig 1 precambrian and paleozoic rocks are exposed in the tandilia and ventania ranges between them a 9 km thick paleozoic sequence has accumulated in the claromecó basin ramos 1999 the salado basin sb and colorado basin cb are rift basins generated during the late jurassic to early cretaceous period as a result of the gondwana breakup and the opening of the south atlantic ocean the sedimentary sequence of sb unconformably overlies the serra geral basalts cretaceous in cb palaeozoic quartzitic rocks from the ventania and granitic environment constitute the basement of the hydrothermal system bonorino 1988 fig 2 due to their common origin the sedimentary fillings of sb and cb are quite alike with greater than 6 km thick cretaceous to quaternary deposits fig 2 the lower section of both basins is made of early cretaceous continental red beds composed of conglomerates sandstones and mudstones yrigoyen 1975 the middle section sag basin phase begins with cretaceous red beds general belgrano formation colorado formation followed by maastrichtian danian deltaic and transitional deposits sb las chilcas formation cb pedro luro formation composed of greenish gray deposits and claystones with subordinated sandstones gypsum and anhydrite the upper sections of the sedimentary fillings passive margin stage are composed of continental and transgressive regressive marine sequences corresponding to olivos formation in sb and elvira ombuctá formations in cb yrigoyen 1975 the uppermost part of the sedimentary filling consists of loess and loess like deposits pampean formation the main hydrogeological units in sb and cb can be divided into three sequential sections sala 1975 the upper section has an aquifer behavior it is formed by fluvial and eolian sediments that consist of the semi confined puelche aquifer and the unconfined semi confined pampeano aquifer these aquifers are the most important water resource in the province the intermediate section is represented by the paraná formation sb and barranca final cb consisting of clays and sands deposited during the middle miocene lower pliocene marine ingression this section has a thickness of several hundred meters and is recognized by its characteristic green color its hydrogeological behavior is that of an aquitard and is usually considered the hydrogeological basement the lower section includes the tertiary sediments named as olivos sb and ombucta pedro luro formations cb in addition these neogene formations constitute aquifers containing thermal groundwater 2 sampling and analytical methods the first sampling campaign in 2017 2018 covered 11 wells fig 1 table 1 samples were collected for major ion chemistry water stable isotopes 3h 14c and noble gases in situ parameters including temperature ph electrical conductivity ec were recorded a second campaign in 2019 collected samples for 81kr analysis from 8 of the 11 wells because at that time the wells sbr 2 and cbr 2 were not accessible and the pumping system was out of operation for sbr 1 the samples are named after the basin they belong to cb colorado basin sb salado basin and the well locations within each basin r close the supposed recharge zone d far from the recharge zone salinity was in cb an additional criterion to assign a sample to r or d groups assuming that a lower salinity is observed closer to recharge zones for example sample cbr 3 is the sample number 3 of the recharge zone r in the colorado basin cb chemical and stable isotope analyses were performed at the hydrogeochemistry and isotope hydrology laboratory of national university of mar del plata argentina water stable isotopes 2h h 18o 16o were analyzed using a lwia 45 ep laser spectroscopy analyzer the analytical uncertainties are 0 15 for δ18o and 1 0 for δ2h 3h was determined by liquid scintillation counting at the isotope hydrology laboratory of the international atomic energy agency iaea and by the university of waterloo it was also measured using the 3he ingrowth method at the hungarian institute for nuclear research 14c and δ13c were analyzed using accelerator mass spectrometry ams at both the university of waterloo and the hungarian institute for nuclear research for stable noble gas isotopes groundwater samples were collected in copper tubes and isolated with pinch off metal clamps to avoid gas exchange with the atmosphere dissolved gases were extracted and analyzed using a magnetic sector mass spectrometer for helium and a quadrupole mass spectrometer for neon to xenon at the isotope hydrology laboratory of iaea matsumoto et al 2017 all analytical results are given in annex 2 of the supplementary material dissolved gas samples for 81kr analyses were taken with a gas extractor and were analyzed using the atom trap trace analysis atta method at the university of science and technology of china ustc local air samples containing 85kr t1 2 11 y were collected in order to assess possible atmospheric contamination during sampling details of the sampling and analytical methods are given in lu et al 2014 3 results 3 1 field parameters and hydrochemistry the relationship between the water temperature and the total depth of each well table 1 reveals different thermal gradients in the salado and the colorado basins despite their similar tectonic evolution and stratigraphy the gradient is 4 5 c 100 m for cb and 2 5 c 100 m for sb the higher anomalous thermal gradient in cb was attributed to a locally thinned continental crust allowing convective water currents in a high fracture density zone kostadinoff reartes 1993 the temperatures regressed at the surfaces are 18 c for cb and 14 5 c for sb close to the mean air temperature of the areas fig 3 the samples have a large range of salinities expressed by ec table 1 fig 3 in sb ec increases linearly with depth in cb samples in the area covering the city of bahía blanca cbr 1 and cbr 2 and a neighboring town to the southwest cbr 3 have ecs below 3 5 ms cm samples situated 50 km to the south cbd 1 and cbd 2 have high salinities and ecs above 100 ms cm the cationic composition is mostly homogeneous with a high dominance of sodium waters but the samples at sbr 1 have higher proportions of calcium and magnesium the anionic composition of most of the thermal waters is chloride or chloride sulfate types but the three low salinity samples of cb have dominant amounts of bicarbonates fig 4 in sb the waters with lower ec values sbr 1 11 0 ms cm sbr 2 2 44 ms cm are also differentiated because they have a higher proportion of calcium or bicarbonate the waters with ec values higher than 50 ms cm are mostly sodium chloride waters with significant proportions of sulfate and calcium in cb all samples are of sodium type but the low salinity waters cbr 1 cbr 2 and cbr 3 with ec values below 3 5 ms cm are differentiated because of their higher proportion of bicarbonate in the anionic composition the high saline waters with ec values above 110 ms cm are sodium chloride waters 3 2 stable isotopes of water δ2h and δ18o the water stable isotope values vary over a wide range table 2 and are plotted in a δ18o vs δ2h diagram fig 5 a together with the global meteoric water line gmwl the four groups of samples cbr cbd sbr and sbd are separated on the δ18o vs δ2h diagram within each basin there are two groups one including samples along a trending line of slope close to that of gmwl 8 and the other more enriched in 18o with a gentler slope than gwml the most isotopically depleted samples are those from cb located closer to the recharge area bonorino 1988 bonorino et al 1989 these three samples cbr have low salinities and a high deuterium excess and form a line parallel to gmwl fig 5 a they are isotopically more depleted compared to the weighted average values δ18o 5 79 δ2h 37 9 of the present precipitation in bahía blanca station from the global network of isotopes in precipitation gnip iaea wmo current year on the other hand the high salinity cbd samples lie below the gmwl fig 5 a but defining a slope lower than 2 i e not in the range of an evaporation line slope 3 to 5 this suggests that they are affected by the 18o shift due to the interaction with rocks at a high temperature ma et al 2010 as it was also proposed by bonorino et al 1989 plotting δ18o vs d excess fig 5 b is another way to show the clustering of the samples cbr samples are depleted having a d excess over 10 while samples at sbr are relatively more enriched isotopically and having lower d excess values around 5 on the other hand waters from the discharge zones are progressively enriched with decreasing d excess values in sb one group is formed by the low salinity samples at the borders of the basin sbr 1 and sbr 2 and the saline sbr 3 fig 5 c the salinity difference is because sbr 1 and sbr 2 are from the relatively shallow wells placed on the elevated bedrock blocks where the miocene marine transgression deposits are thin or not present while sbr 3 is from a deeper well in the sunken block having and crossing several hundred meters of marine clay fig 2 the other group is formed by the high salinity samples at the axis of the basin sbd the sbr samples are along a line of slope 7 17 with a d value of 1 58 the high salinity samples from the axis of the basin sbd are isotopically more enriched and fit along a line of slope 3 56 resembling an evaporation line el it is quite different from the present values at a close representative gnip station in azul city present precipitation at that station has a lmwl δ2h 8 16 δ18o 13 2 dapeña et al 2010 and a weighted average isotope composition of δ18o 5 5 and δ2h 31 3 3 groundwater age tracers 3h 14c and 81kr 3 3 1 3h the concentrations of 3h in the groundwater samples table 2 are mostly below the detection limit 0 8 tu confirming that the samples contain negligible amount of young groundwater 3 3 2 14c most of the samples yielded 14c values below 5 pmc table 2 and given the potential for atmospheric contamination and following aggarwal et al 2014 these samples are considered to be older than 30 ka then the following discussions about corrected 14c ages based on different models are focused on the 3 samples with radiocarbon contents higher than 5 pmc see table 2 sample sbd 2 showed a radiocarbon content of 9 12 pmc however the 85kr measurement indicated the observed 14c is most likely due to contamination by modern air it is therefore not included in the discussion below two single sample based models for radiocarbon dating of dic i e the iaea model and the han plummer s model are used to calculate the corrected 14c ages following the procedures in han and plummer 2016 the iaea model and the han plummer s model are chosen because the observed δ13c values fall into their applicable ranges moreover it is known that the results calculated from the han plummer s model can be biased to younger ages while the results calculated by the iaea model may be biased to older ages han and plummer 2016 by applying these two models we can show the variation of the obtained 14c ages due to different model selections the initial 14c activities and corrected 14c ages are presented in table 2 in the 14c calculations the values of biogenic soil co2 is assumed to have δ13c of 25 and the δ13c for carbonates is assumed to be 0 the obtained initial 14c activities and corrected radiometric ages are shown in table 2 pointing the focus in samples cbr 1 and cbr 3 it is observed that initial activities differ from values around 40 pmc for the han plummer s model to values around 70 pmc in the iaea model the corrected 14c ages range from 3 4 ka to 20 7 ka for sample cbr 2 the corrections result in negative ages indicating over correction from both models the causes could be other geochemical processes that are not included in the 14c correction models this sample is excluded for the rest of the discussions 3 3 3 81kr the apparent 81kr age of a groundwater sample can be calculated according to purtschert et al 2013 1 ag e 81 k r t 1 2 ln 2 ln i a 81 100 where ia81 is the 81kr abundance of the sample relative to that of the modern air the unit pmkr stands for percent of the modern 81kr level 85kr half life 10 8 a activities are also measured in order to check modern air contamination among all samples six of them show low modern contaminations 3 two samples sbr 3 and sbd 2 have more significant contaminations up to 20 the contamination is likely caused by the complex piping of the thermal water from resort wells the effect of modern air contamination can be corrected using the measured 85kr activities see supplementary material annex 1 for details in two cases that correspond to low salinity waters of cb the 81kr ages are young close to the 14c dating range the sample from the border sbr 3 has a 81kr age of 640 ka the high salinity waters in the southern part of cb and the center part of sb have 81kr ages close to 1 ma these are the oldest groundwaters found so far in south america fig 5 d 3 3 4 noble gases the samples analyzed see table 3 in supplementary material annex 2 here yielded 4he concentrations varying from 3 10 7 cm3 stp g to 3 10 5 cm3 stp g and are all significantly enriched in 4he compared with the concentrations in modern groundwater typically 10 8 cm3 stp g the isotope ratio of helium 3he 4he is significantly lower than the atmospheric ratio 1 4 10 6 3he 4he and ne he ratios form a clear mixing trend extending from the atmospheric component at the recharge to the crustal radiogenic component fig 6 the enhanced 4he concentrations reflect long term accumulation of radiogenic 4he within the aquifer solomon 2000 all samples are along a line from the atmospheric component to the crustal component sbr 1 and sbr 2 samples sb borders are the closest to the atmospheric component and the samples corresponding to brines sbd 1 sbd 2 sbd 3 cbd 1 cbd 2 the closest to the crustal component there is no ng result for sbr 3 because the sampling is impeded by an abundance of gas bubbles in water the 81kr ages provide additional information about the origin of 4he in the samples a typical in situ production rate of 4he in sedimentary rock by local u and th decay is about 6 10 12 cm3 stp g a wei et al 2015 by applying this rate the observed amounts of 4he in the samples yield 4he ages that are 0 5 16 times their respective 81kr ages this discrepancy suggests that the in situ production is too slow to account for the observed 4he concentrations over the time scales suggested by the 81kr ages and that an external basal 4he flux into the aquifer is required to contribute the amount of 4he in the samples e g torgersen ivey 1985 this external basal flux is higher in cb resulting in lower ne he ratios in the recharge area the higher basal flux in cb compared with sb could be the result of the larger number of faults and block displacements at relatively low depths fig 2 inoble2 7 code was used to calculate both the noble gas temperature ngt at recharge and the excess air aeschbach hertig et al 2000 wilson mcneill 1997 based on the measured noble gas contents in the water samples most of the samples show a ʃχ2 error too high probably due to the effect of high temperatures for old thermal groundwaters with high salinities this is not uncommon and the ngt cannot be reliably recovered in these cases only the sampling sites cbr 1 and cbr 3 give reasonable results ʃχ2 0 19 and 0 75 the obtained ngt is 16 c for cbr 1 and 13 c for cbr 3 the excess air values are 7 39 and 3 30 cc kg respectively 4 discussion 4 1 recharge routes of the colorado and salado basins groundwater flow in the artesian aquifer of cb has been studied since the work of bonorino 1988 pointing to a recharge area close to the ventania range however the recharge area for the thermal aquifers in sb is still unknown hernández et al 1975 suggested a probable recharge through overlying layers along the piedmont of the tandilia range with elevated bedrock blocking the southern border carol et al 2010 considered that the recharge could occur by leaking from the overlying parana formation in this work the hydrochemical features of lower salinity lower calcium or bicarbonate composition the ne he ratios closer to the atmospheric component and the water age all combine to support the hypothesis of recharge at the piedmont moreover recharge from the northern border of the basin is also identified from the occurrence of low salinity waters with a ne he ratio that duplicate the values observed in the axis the flow is from the borders of sb in the area of the two regional faults towards the depocenter 4 2 recharge conditions and impact on paleoclimate records the stable water isotopes and noble gases of the groundwater carries paleoclimate information in these two basins of the pampa however these data may be masked by the water rock interactions during the long residence time underground in this section we will try to identity the effects of water rock interactions and retrieve the paleoclimate information during recharge as mentioned earlier in each basin there are two groups of groundwater fig 5 a sub modern groundwater group parallel to gmwl and an old groundwater group that is shifted to the right due to δ18o enrichment because of their different behaviors in fig 5 and different ages separate discussions about these two groups are given below 4 2 1 sub modern groundwater group a samples close to the recharge zone in the colorado basin cbr the three samples from this area have 14c activities larger than 5 pmc corrected 14c ages are calculated based on two single sample based models the iaea model and the han and plummer s model the sample cbr 2 shows both high 14c activity and δ13c as a result both radiocarbon models over correct this sample and produce negative ages it is therefore excluded from the analysis the other two samples have 14c ages between 3 4 ka and 20 7 ka which agree with the results of bonorino 1988 however the 81kr ages are all older than the 14c ages see table 2 for cbr 1 the 14c age is 3 4 ka han plummer s model 7 4 ka iaea model while its 81kr age is 30 1 8 5 8 7 ka for cbr 3 the 14c age is 16 4 ka han plummer s model 20 7 ka iaea model while 81kr age is 49 1 9 3 9 6 ka the difference between 14c and 81kr ages can be explained by dispersion in the groundwater transport process joint analysis of tracers with different time responses allows us to go beyond the piston flow model and take the effect of dispersion into account the effect of dispersion on tracer age distributions and groundwater ages can be considered with a dispersion model as described by maloszewski zuber 1982 and applied in many examples such as the works of corcho alvarado et al 2007 visser et al 2013 gilmore et al 2016 etc here a dispersion model that results in a transit time distribution ttd with an inverse gaussian form is used for the analysis see supplementary material annex 3 for details waugh et al 2003 the ttd function is controlled by two parameters γ is the mean age of the groundwater δ is the width of the ttd function the peclet number pe relates both parameters pe δ γ 2 and characterizes the degree of mixing or dispersion by combining the 14c and 81kr ages these two parameters can be determined see annex 3 for details following a method reported in ebser et al 2018 the inferred ttd functions for cbr 3 and cbr 1 are plotted in fig 7 in both cases the pe values indicate significant contribution from dispersion during the groundwater transportation the cbr 1 sample shows a larger dispersion than the cbr 3 sample if the han plummer s model is used for the 14c correction no solution can be found with the measured 14c and 81kr data for cbr 1 this suggests that the iaea model may be a better model to use for this case other reasons such as modern figs 8 and 9 air contaminations or mixing with young groundwater could cause the disagreement between radiocarbon and 81kr ages as well however modern air contamination during sampling was ruled out based on the very low 85kr contents and the similar radiocarbon values previously obtained by bonorino 1988 the very low 3h contents reject the possibility of mixing with young groundwater based on these evidences we conclude that the dispersion during groundwater transportation is more likely to be the cause of the observed age differences between 14c and 81kr the high dispersion observed could be due to the high heterogeneity of the grain size composition of the aquifer plus the long flow paths as dispersion is depending on the scale of the groundwater transportation gelhar et al 1992 the above observation brings new insights about the time of recharge previously the recharge time was proposed to be during the last glacial maximum lgm based on the isotopically depleted values and the 14c ages bonorino 1988 based on the relative sea level data the lgm occurred from 26 5 to 19 0 ka which sits inside mis 2 29 14 ka lisiecki and raymo 2005 clark et al 2009 however the results for these two wells indicate that recharges are distributed over a much longer period of time from mis 1 to mis 5 fig 6 for cbr 3 the recharge is concentrated in a period from mis 1 to mis 3 while for cbr 1 the recharge is more concentrated in mis 1 the isotopic composition is measured to be depleted against the present precipitation which suggests that the recharge happened at a colder temperature however ngt values for cbr 1 16 c and cbr 3 13 c are close to the present mean temperature values of 15 1 c for bahía blanca city a possible explanation for the lower isotopic contents is the provenance from a different vapor source affected by the continental effect in those periods comparing to the studies on ice cores retrieved from vostok in east antarctica red curves in fig 87 we see that these recharges mainly happened in a period with low d excess compared to present jouzel et al 1982 vimeux et al 1999 yiou et al 2001 here the d excess record from vostok is used as a global indicator although the local d excess at our study region may have a different value than the precipitation in east antarctica it should follow a similar trend based on this assumption we can make estimations on the average d excess of cbr 1 and cbr 3 using the recovered ttds and the vostok d excess record the calculation shows that the average d excess of cbr 1 14 0 and cbr 3 13 3 are both lower than the d excess in the modern local precipitation 15 5 interestingly the water isotope measurements show a greater d excess relative to gmwl and the modern precipitation instead fig 5 a and fig 5 b we suggest that the observed high d excess could be a result of enhanced moisture recycling froelich et al 2002 a possible scenario is that the recycled vapor is brought by the south american low level jet sallj from the amazonas basin which is strengthened by the displacement of the south atlantic subtropical high sash heil et al 2010 the sallj was first recognized in the 1980 s with the aid of sparse radiosonde station data and satellite derived cloud winds and it can reach as far as the de la plata river basin containing sb but north to cb in the south what is particular interesting is that this scenario not only suggest that sallj may have existed as early as in mis 3 but also suggest that it may have extended further south into the colorado basin compared to the present time although the proposed mechanisms are consistent with the variations of the regional climate forcing there may be possibilities other than the hypothesis proposed above especially considering the limited data the uncertainty of the measurements and the limitations on the simple form of the ig ttd one alternative is a two component mixing with one end member substantially older than mis5 although it may be hard to explain the observed low salinity obviously additional efforts are needed to further constrain the model and confirm the hypothesized processes one way to go beyond the ig ttd used in this study is to use shape free age distributions holzer primeau 2010 massoudieh et al 2014 more tracers are needed to constrain such a more complex ttd with sufficient amount of data groundwater studies may provide supplements to the current climate proxy records marine sediment ice core loess spalletium etc mostly found in the northern hemisphere voelker 2002 b samples close to the recharge zone in the salado basin sbr in this group the 14c activities of the samples are below or close to the background leading to calculated ages larger than 30 40 ka one of them is dated with 81kr with an apparent age 640 ka sbr 3 the ages of sbr 1 and sbr 2 are unfortunately not dated with 81kr their ages are likely well beyond the 14c dating range as their ne he ratio are toward the crustal member the fact that the ne he ratios for sbr 1 and sbr 2 are closer to the atmospheric member indicates ages younger than sbr 3 the two younger samples sbr 1 and sbr 2 have a depleted δ18o value around 5 5 while the older one sbr 3 is more enriched with a δ18o of 4 19 the isotopic composition of these waters is characterized by a d excess lower than the present precipitation the observation is consistent with dominating marine vapor sources from the adjacent ocean with a high relative humidity at the sea surface compared to the modern ocean froehlich et al 2002 pfahl sodemann 2014 4 2 2 very old groundwater group a samples at the southern part of the colorado basin cbd this group of samples is isotopically more enriched compared to cbr with δ18o values ranging from 5 0 to 3 5 the data shows a notable horizontal 18o shift with a gentle slope of 1 6 the 81kr ages of these samples are all around 900 ka the observed 18o shift is attributed to the water rock interaction wri at high temperatures the cbd 2 has a larger 18o shift compared to cbd 1 due to stronger wri this trend can also be seen on the giggenbach triangle giggenbach 1988 in which cbd 2 is closer to the fully equilibrated waters at the temperatures line around 150 c fig 98 and can be then considered close to the water rock interaction extreme member the isotopic composition of the aquifer forming rock is unknown according to a previous study zakharov and bindeman 2019 δ18o positive values in the range of 2 to 8 could be supposed the composition of the old ground water upon recharge can be obtained by plotting the line that goes through cbd 1 and cbd 2 backward to the gmwl see fig 5a alvis isidro et al 1993 mook 2001 the interception shows that the recharge happened at 900 ka with more enriched isotopic value than those in the cbr samples which could hint at a warmer climate however more data are needed to further support this hypothesis b samples at the axis of the salado basin sbd this group includes the oldest water in this study their 81kr ages are all around 1 ma in mid pleistocene they are isotopically enriched water compared to sbr fitting to a line with a slope of 3 5 a progressive isotope enrichment is observed from sbd 1 to sbd 3 on the δ2h vs δ18o plot fig 5 the enrichment is well correlated r2 0 99 with the increase of salinity expressed in chloride concentration fig 5 c the linear relationship and their uniform ages suggest that these water are formed from mixing between two end members one end member is a low salinity and isotopically depleted recharge water the other is an enriched brine the interception of the line with the meteoric water line reveals the low salinity end member and the recharge conditions of the salado basin during the mid pleistocene the δ18o value at the interception around 4 is slightly more enriched than the present contents in the precipitation in the area 5 this could be a result of climate conditions warmer than present during recharge although the uncertainty is fairly large this hypothesis seems to be in line with previous studies on loess and sediments from the region heil et al 2010 the origin of the brine end member is less clear the wri at the observed temperatures are not enough to explain the high salinity of the water other possible explanation includes the leaking of high salinity connate water from the overlying marine sediments but this water should be free of 81kr and the mixing should have resulted in different apparent ages instead of the observed similar ages recharge from an evaporated shallow sea is another possibility however it is ruled out by the existence of 300 400 m of plastic marine clay deposited during the upper miocene which would impede water infiltrating from the surface in this area lastly recharges from saline lakes seem to be the most plausible hypothesis it has some support in the occurrence of gypsum deposits observed in the nearby claromecó basin del blanco et al 2005 indicating the existence of supersaturated brines the present arid conditions in the pampa patagonia transition area including large saline lakes can be extrapolated to the past conditions in the sb the infiltrated brines mixed with precipitation recharged at the same time at elevated zones to form the observed groundwater fig 109 the mixing process does not change the age of the mixed water but the resulting salinity and water isotopic composition are different depending on the degree of mixing a similar phenomenon of groundwater recharge redissolving previously precipitated salts on lake beds was observed by kwicklis et al 2021 at pahute mesa nevada usa 4 2 3 pleistocene climate during recharge the above discussions and the proposed hypothesis are in agreement with paleoclimatic inferences based on sedimentological and paleomagnetic analysis carried out in the study region in this regard the magneto climatological study of a continental succession at the northern margin of sb indicates arid conditions some time prior to the matuyama brunhes polarity transition bidegain et al 2005 later the environmental magnetic characterization of a 1 9 ma section in the same area heil et al 2010 reveals the occurrence of the driest conditions in 0 96 1 93 ma which coincides with the lowest summer sea surface temperatures in the southern ocean and the lower variability between glacial and interglacial stages becquey gersonde 2002 2003 the dominance of general arid conditions at 1 ma in central argentina occurred when the great patagonian glaciations took place in southern patagonia and the glaciers reached their major extension rabassa et al 2005 the prevailing aridity is thought to result from less moisture carried to tropical and subtropical south america due to a northward displacement of both the south atlantic anticyclone and the polar front zone heil et al 2010 this condition of a very arid period with a strong marine vapor influence and minimal contributions from tropical humidity in the mid pleistocene is in line with the enriched water stable isotopes of the recharge inferred from the cbd and sbd samples and the hypothesis of recharging through saline lakes 5 conclusions the 81kr dating method allows study of old groundwater up to 1 1 ma in the deep sedimentary basins in the central coastal argentina the multiple age tracers combined with water stable isotopes water chemistry etc provide new insights to the groundwater recharge time as well as the paleoclimate condition at that time in this region it shows that deep groundwater can be used as a proxy for paleoclimate studies several climate changes along the pleistocene were insinuated based on isotope proxies and groundwater dating the results from two wells in the cbr zone allowed re examination of the recharge period and conditions based on the new information it was proposed that the recharge occurred during mis 1 to 5 and that the sallj existed further south for that time mid pleistocene climate can also be observed from those proxies from the trends in isotope compositions and the very high salinity of the waters the recharge climate at 1 ma was assigned to arid conditions as the most feasible explanations future exploration with denser sampling in this region may shed more lights on these aquifers and the paleoclimate conditions in south america funding this works is supported by the national natural science foundation of china grants no 41861224007 no 41727901 the national key research and development program of china grant no 2016yfa0302200 the international atomic energy agency iaea through the coordinated research project crp f33023 a bilateral cooperation project between the national natural science foundation of china nsfc and the national council of scientific and technological investigations conicet of argentina resol 2018 308 apn dir conicet the national found for science and technology of argentina foncyt through the project pict2018 01584 credit authorship contribution statement d e martínez conceptualization funding acquisition investigation writing original draft w jiang conceptualization writing original draft resources t matsumoto supervision conceptualization funding acquisition resources o m quiroz londoño investigation writing review editing visualization resources f ritterbusch investigation writing review editing c lexow investigation writing review editing g m yang resources investigation validation l bertolín resources investigation j mabry resources investigation validation n romeo resources investigation validation m zárate conceptualization investigation writing review editing z t lu supervision conceptualization funding acquisition resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the cooperation in sampling activities from the colleagues rene albouy melisa glok galli sebastian grondona eduardo kruse leandro rodrigues capitulo and hector massone also to the managers of thermal resorts lucio serron martin lezcano roberto rivademar leandro oldoni and oscar ibarra who facilitate the field activities on their thermal waters wells we thank dr luis araguas iaea for a very useful discussion about the correction models for radiocarbon dating the technician gustavo bernava preformed the water chemical analyses different areas of conicet contributed in the office of foreing commerce helped for importing the sampling machine and the office of international cooperation and the scientific technological centre cct mar del plata developed the general project administration appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127846 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3299,a strong innovative tendency is nowadays emerging that largely comprises new hydrological modelling approaches based on causal reasoning through probabilistic graphical modelling pgm because its ability to support probabilistic reasoning from data with uncertainty these novel modelling frameworks are quite diverse and disperse not only in terms of techniques but also regarding its aims it seems necessary to find a general and robust methodology for assessing its performance this paper aims to provide a novel general methodology for assessing the performance of pgm based on bayesian causality for modelling and analysing the riverś runoff behaviour for it a structured four step approach is developed and showed throughout the paper the proposed methodology begins with the identification of the two main factors that condition the bayesian causal bc modelling the number of synthetic series data amount and the number of intervals for probability distributions for training and learning processes the developed analysis comprises the definition of three levels for the first factor and seven levels for the second one as well as the design of an innovative stability framework that assesses the level of bc modelling performance furthermore it has been necessary to create define two novel indexes named similarity and stability indexes from 21 scenarios arising from the combination of the levels of the both factors the optimal combination of factors is identified through a bi objectives recursive approach based on previous indexes main results drawn successfully show a high relationship between the level of modelling performance measured in terms of stability and the river runoff temporal behaviour measured in terms of temporal dependence this research may help water managers and engineers to develop more rigorous and robust hydrological causal modelling implementations keywords probabilistic graphical models bayesian causal modelling stability time series analysis 1 introduction probabilistic graphical models pgms since their emergence in the 1980s within the statistical and artificial intelligence reasoning communities javidian et al 2020 have been increasingly getting more notoriety in scientific community this is mainly because they are an intuitive formalism to capture the probabilistic in dependence information of a domain pearl 1988 vogel et al 2018 through the combination of probability graph theories vogel et al 2014 as well as a powerful framework for reasoning under uncertainty in knowledge based systems cabañas de paz 2017 javidian et al 2020 according to koller and friedman 2009 a pgm use a graph based representation as the basis for compactly encoding a complex distribution over a high dimensional space formally it is defined by a joint probability distribution p x on the set of variables of the problem x and a graph g that represents the in dependence relationship amongst variables cabañas de paz 2017 at its core they are characterized by a qualitative part which encodes a set of conditional in dependence relationships amongst variables and a second quantitative one that measures the in dependence strength cabañas de paz 2017 pgms have been widely applied to a variety of reasoning tasks related to prediction diagnosis classification and risk assessment under original approaches and applied to different scientific disciplines engelke and hitz 2020 introduces a general theory of conditional independence applied to graphical models for extremes for its part javidian et al 2020 propose a new algorithm named lcd amp applied to chain graphs that overcomes the problems of data order dependence ramos fernández 2018 designs a naïve bayes pgm as a medical tool for predicting the severe course of acute bronchitis in infants lehikoinen et al 2019 by bayesian network bn classifiers assesses the effects of multiple natural and anthropogenic factors on marine ecosystems simultaneously for the first time macian sorribes et al 2020 addresses the spatio temporal dependence dimensions of inflows in hydrology through bns in vogel et al 2018 is identified the driving factors of flood loss at residential buildings applying novel pgms approaches based on bns and markov blankets on the other side the relation among probability distribution and the graph defines the pgm type existing three classes basically diez et al 2018 a undirected graphs e g markov networks b directed acyclic graphs e g bns and c chain graphs which are a unification of the first two javidian et al 2020 of these the most widely used is the one based on bns cabañas de paz 2017 javidian et al 2020 due to its ability to describe the overall behaviour of a system through the propagation of in dependence among the variables throughout the whole graphical structure vogel et al 2018 in addition the fact that bns are based on the notion of conditional in dependence steck 2001 makes them particularly useful for dealing with forecasting and analysing of the general behaviour in complex natural processes molina et al 2019 referring specifically to hydrology and water resources bns have been satisfactorily applied to issues such as water planning of catchments mamitimin et al 2015 xue et al 2017 integrated groundwater management carmona et al 2011 molina et al 2013 reservoir management malekmohammadi et al 2009 assessment of environmental risk on large dams ahmadi et al 2015 flood damage schroeter et al 2014 and drought forecasting and management shin et al 2019 among others recently new hydrological challenges have begun to be addressed through the potential that bns offer to discover causal structures in observed data spirtes 2010 because the intrinsic in dependence relationships within of temporal series are not known in depth molina and zazo 2018 molina et al 2019 this is performed under a novel framework named bayesian causal bc modelling based on causality and which is addressed in form of causal reasoning cr supported by bayesian modelling macian sorribes et al 2020 zazo 2017 bc modelling is a suitable technique for modelling the temporal behaviour of water resources of a basin when 1 the approach is done from top to down 2 the analysis is focused on the cause and 3 the objective comprises the prediction of the consequence macian sorribes et al 2020 pearl 2009 as in the case of bayesian causality by means of bc modelling it is highlighted the hidden logical temporal in dependence structure that inherently underlies into hydrological historical records macian sorribes et al 2020 zazo et al 2020 under this approach some noteworthy contributions have emerged in the field of stochastic hydrology in molina et al 2016 a preliminary dynamic analysis of temporal dependence propagation was presented for its part molina and zazo 2018 discovered and quantified for the first time two opposite temporal fractions within annual runoff time series one conditioned by time and other no molina et al 2019 developed a dynamic predictive runoff model based on the temporal behaviour trends of previously discovered runoff temporal fractions zazo et al 2019 showed a qualitative approach for assessing temporal dependence through a novel dependence graph recently macian sorribes et al 2020 analysed and assessed simultaneous and completely of spatio temporal dimension of inflows across two adjacent and parallel river basins in this sense bc modelling framework deliver much more accurate and powerful hydrological simulations and predictions in line with new trends in stochastic hydrological research based on hybrid approaches between traditional novel techniques mohammadi et al 2006 nourani et al 2011 valipour et al 2012 at this point it is worth highlighting that pgms are characterised by learning directly from the data when the structure of the network is unknown javidian et al 2020 malone and yuan 2012 and that such learning comprises not only the quantitative dimension of the data but also its intrinsic structure koller and friedman 2009 steck 2001 therefore issues such as the number of data or the modelling structure itself are crucial for suitable and reliable model performances koller and friedman 2009 vogel et al 2018 in this sense there are significant algorithm based developments for learning model structure from sampled data which are well known stablished in the scientific community for instance inductive causation ic algorithm verma and pearl 1991 1992 a similar approach independently developed by peter spirtes and clark glymour known as pc algorithm spirtes et al 2000 madsen et al 2003 based on conditional independence decisions le et al 2016 and the improvement of the latter named npc learning algorithm that introduces the notion of a necessary path condition madsen et al 2003 steck 2001 nevertheless in respect of the data there are two key driving factors for building a reliable dataset for learning and or training which have not yet been addressed in depth these are 1 number of synthetic series and 2 number of intervals for discrete probability distributions the aim of this research is to provide a methodological framework for achieving an optimal combination between the different considered levels of two main driving factors that condition learning training processes of bc modelling this approach was applied to increase knowledge of the temporal behaviour of water resources in a river basin and have not yet been addressed by any hydrological research based on bayesian causality the first external one is number of synthetic series that populates the bayesian causal models factor 1 three considered levels in annual synthetic data the second internal one is number of intervals for discrete probability distributions of synthetic data factor 2 with seven considered levels this was developed to improve the performance of causal models with respect to their analytical and predictive capacity in the context of temporal behaviour of water resources of a basin the influence between the levels of both factors was measured through two innovative indices named similarity index and stability index these allowed the identification of the optimal combination between the levels of both factors through a bi objectives recursive approach in terms of overall stability of the bc modelling process these findings may be extrapolated to other approaches based on this type of pgms for improving their analytical and forecast capabilities this paper is organized as follows after this introduction the methodological section and data description is addressed then the main results drawn from the research are presented finally in discussion and conclusions section the results are discussed in detail as well as the general conclusions from the study are outlined 2 methodological approach the framework for assessing the bc modelling performance in terms of overall stability process comprises a four step approach fig 1 step 1 implies the generation of synthetic data from historical records through a parametric autoregressive moving average model arma model or any alternative model approach able to generate synthetic time series use of observational data would only be possible if enough data to populate the bns is available step 2 designs the bc modelling by 4 sequential phases learning preprocessing constraints and structure learning process in step 3 probability propagation is addressed by dependence mitigation graphs dmgs obtaining also its uncertainty bands through a bootstrap approach finally step 4 assesses the bc modelling performance innovatively firstly a novel similarity index is defined through an in depth analysis of the overlap between uncertainty bands of wrap around averages of dmgs secondly a stability index is created for assessing global bc modelling performance of all possible combinations between the levels of both factors then a bi objectives recursive approach identifies the optimal combination of factors as dmg supposes an innovative way for assessing probability propagation for understanding of the reader uncertainty band generation and their overlap analysis are facilitated by exemplary figures on the other side the application of arma models to hydrological analysis simulation and prediction reveals a wide heterogeneity of data samples for example in srinivas and srinivasan 2006 is assessed a hybrid model for stochastic simulation of multi season stream flows through 100 synthetic data seasonal threshold model borgomeo et al 2015 presented a method to generate synthetic monthly streamflow through random sampling from a parametric or a nonparametric distribution assessed by 100 flow sequences in molina et al 2019 a dynamic predictive model which was populated with 200 synthetic annual runoff series from an arma model is developed based on the review of the scientific literature and in the expertise acquired in the development of causal models applied to the analysis and prediction of spatio temporal behaviour of water resources in a river basin s three different numbers of annual synthetic series factor 1 50 100 y 200 were generated in each case study all of them with the same length of the historical datasets in contrast factor 2 number of intervals for probability discretization and whose influence has not yet been addressed within the framework of hydrological research was given seven levels 3 4 5 6 7 8 and 9 intervals this led to the design execution and analysis of the results of 21 causal models for each case study which ensures the robustness of the findings and the designed methodological framework data description case studies the framework in which this research is conducted involves that the case studies form part of the methodological section in order to define a robust methodological approach that would allow extrapolating the research findings to the field of prediction based on bayesian causal models two headwater case studies were chosen according to the following key aspects 1 their completely opposite temporal behaviour temporal in dependence 2 same time period of analysis and 3 lack of spatial correlation between them both headwaters porma in the north and adaja in the south belong to duero river basin the largest international river basin between spain and portugal furthermore they are defined by gauging stations located upstream the first regulating reservoir flows under natural regime they are camposolillo code 2078 in the first case and adaja code 2046 in the second one fig 2 a the time period covered 37 hydrological years from october to september 1974 75 and 2010 11 the historical records without missing data were supported by the network of gauging stations of duero river basin authority miteco 2021 table 1 summarizes the main statistical parameters porma case study displays a temporal behaviour completely dependent with its correlation coefficients outside the anderson limits of the correlogram or very close it in contrast adaja case study exhibits an opposite behaviour clearly independent with all correlation coefficients within the independence area of the correlogram fig 2b displays both correlograms both case studies are characterized by a cold mediterranean climate highly continental porma case study shows an annual average rainfall of 1430 mm geologically there are important formations of limestones sandstone and alluvial deposits in the fluvial courses hydrogeological speaking it is characterized by low permeability or impermeable materials and low productivity and small extension aquifers molina and zazo 2018 adaja case study presents an average annual about 400 mm geologically it shows important areas of arkoses granitic blocks and alluvial deposits at the bottom of the valley regarding hydrogeology impermeable or very low permeability formations are present molina and zazo 2018 fig 2c displays the main climatic factors and fig 2d shows the graphic of both historical annual series 2 1 step 1 synthetic data generation this step is addressed through a parsimonious arma 1 1 model for each sub basin developed according to molina et al 2016 arma model plays a crucial role in this research because it provides reliable data to populate the bc modelling process in this sense the purpose of this initial phase is to generate in form of synthetic series all of them equiprobable to the historical series considered the amount of information necessary to populate the subsequent bayesian causal models this stochastic parsimonious and unconditioned model confers the highest degree of freedom to bayesian modelling an arma p q is expressed as salas et al 1980 1 y t μ j 1 p j y t j μ t j 1 q θ j t j where yt is the value of the temporal series at a certain time step t μ is the mean of the time series p q are the number of autoregressive ar and moving average ma average parameters j θj are the coefficient of ar and ma average model respectively and t represents the historical residuals before the postulation of the model a normalization process was applied using three different methods square root natural logarithm plus one and natural double logarithm plus one salas et al 1980 these functions are commonly applied to operational hydrology ochoa rivera et al 2007 the natural logarithm plus one method was chosen in both cases as it yielded the lowest skewness coefficient afterwards the synthetic data equiprobable to historical records were generated the validation of synthetic time series was carried out comparing their relevant statistics to those of historical records ochoa rivera et al 2007 in this case due to use annual time series this process was focused on mean values molina et al 2021 given that the levels considered for factor 1 50 100 and 200 synthetic series and the length of the historical data 37 years a total of 1850 3700 and 7400 annual synthetic data were respectively generated in each case study 2 2 step 2 bayesian causal model design conceptually bc modelling as pgm based on bns is defined as a direct acyclic graph dag in which conditional probability among variables is computed molina et al 2021 and propagated omnidirectionally supported by bayes theorem zazo et al 2020 mathematically bc modelling is expressed as madsen et al 2003 2 p v x v p x p a x where p v is the joint probability distribution over set of nodes v random variables x present in the graph and which are defined through dag and p x pa x is the conditional probability distribution for each variable x v that belongs to a set of probability distributions bc modelling application to hydrological time series makes possible to determine quantify the strength of in dependence relationships between variables in a dynamic and step by step manner macian sorribes et al 2020 this is performed through modifying and analyzing the evolution of the probability distribution over time macian sorribes et al 2020 by maximizing the statistical evidence of highest discrete probability distributions interval in each bńs variable molina et al 2016 after this maximization over a particular variable node the change its influence in the expected value of the other ones is assessed and quantified molina et al 2016 bc modelling design was developed in 4 phases 1 learning from synthetic data from arma 1 1 models factor 1 2 preprocessing that implies the discretization of the synthetic data into discrete probability distributions factor 2 all of them with the same amplitude 3 considering constraints initially that the main relationship among variables is natural consecutive variables linking time lag 1 and 4 structure learning which highlights the real structure of interdependence of runoff series by a constraint based approach steck 2001 vogel et al 2018 which finds a dag structure from synthetic data through conditional independence statistical tests this final stage is the core of bc modelling because it reveals the hidden non trivial and logical interdependence structure time lag 1 that underlies into hydrological series it was done through npc learning algorithm madsen et al 2003 which allows efficient simplifications to find net structures steck 2001 under the condition of not including links between conditionally independent nodes hugin 2021 bc modelling design was supported by software hugin expert version 7 3 with a significance level of 0 05 for structure learning process all bc modelling parameters were fixed except the two factors analyzed 2 3 step 3 probability propagation this step comprises probability propagation analysis over the time throughout the network through an innovative dependence mitigation graphs dmg zazo et al 2019 dmg encompasses two variables 1 time x axe in form of time lag and 2 relative of change y axe propagation of temporal dependence strength over the time conceptually dmg is obtained through the relative percentage of change produced in the child variable connected with the parent molina et al 2016 zazo et al 2019 fig 3 shows two dmgs for both sub basins temporally dependent basins tend to present a dominant positive part fig 3a porma in contrast temporally non dependent basins show a tendency towards symmetric wrap around results positive or wrap around maximum w max and negative or wrap around minimum w min as found in fig 3b adaja molina et al 2016 2 3 1 uncertainty bands generation in order to study the uncertainty of the wrap around results before changes in the levels of the two parameters factors studied 95 uncertainty bands for w max and w min series were generated by bootstrap estimation efron and tibshirani 1993 for the band around w max let x 1 x 2 x n be the values used for getting max i x i for a particular lag from these values 10 000 bootstrap samples x 1 x 2 x n were generated and the maximum value max i x i was calculated for each one then 2 5th and 97 5th percentiles of those maximum values were obtained those percentiles were named max x 0 025 and max x 0 975 respectively finally the 95 confidence interval for this particular time lag is developed as 3 2 max i x i max x 0 975 2 max i x i max x 0 025 then 95 uncertainty band for w max series is calculated by joining the upper and lower limits from the confidence intervals similarly it is determined w min 95 confidence intervals from both bands the 95 uncertainty band for the wrap around average w ave can be constructed the usefulness of w ave is based on the application of the three fold criterion statistical comparability representativeness 1 statistically of the three wrap arounds w ave exhibits the lowest dispersion 2 in river basins with temporally dependent behavior w max is clearly predominant with a minimal influence of w min by contrast in independent ones w max and w min tend to compensate each other molina et al 2016 zazo et al 2019 consequently w ave can compare both types of river basins through a unique wrap around and 3 w ave is also able to capture represent the temporal behavior of water basins when w ave is generally positioned above the dmg x axis the basin exhibits a dependent behavior whereas if w ave is positioned in both sides of the x axis the behavior is independent finally uncertainty band for w ave is built by averaging the 95 uncertainty bands for w max and w min series in other words the upper lower limit of the uncertainty band for the w ave series become the average of the upper lower limits of the uncertainty bands for the w max and min series in this manner a single wrap around with its uncertainty band is available for a better understanding of this process fig 4 schematizes the w ave generation process and its uncertainty band 2 4 step 4 bc modelling performance assessment this step determines how the w ave built depends on factors 1 and 2 of bc modelling for this purpose for each of the 21 scenarios 3x7 considered w ave and 95 uncertainty band are constructed and then the overlapping between all of them is analysed in this regard two novel indexes have been defined 1 similarity index and 2 stability index the first one analyses in depth the overlap between uncertainty bands for the w ave and the second one assesses the overall performance of the process moreover in the scientific literature there are a variety of indices based on bayesian approaches such as the bayesian information criterion schwarz 1978 one of the most widely applied to model selection those arising from the combination of different indices and causes bradley et al 2015 kim et al 2018 or from the combination of different causes to assess a particular problem giné garriga et al 2018 among others 2 4 1 similarity index for each pairwise comparison of scenarios a similarity index is calculated through a complete uncertainty bands overlapping analysis uboa as follows 1 if the two uncertainty bands overlap for a certain time lag the value 1 is assigned to that time lag otherwise a 0 value is assigned this is mathematically expressed by a boolean factor of overlap fo 2 a weighted sum of the overlaps of all time lag is obtained through following weights wi 0 5 for lag0 and lag1 w0 w1 0 5 0 1 for lag2 to lag4 w2 w3 w4 0 1 and 0 01 for the rest lags wi 0 01 for i 4 this weight structure is based on the acquired knowledge on dmg zazo et al 2019 dmg allows us to identify two regions of higher and lower mitigation of time dependence of these lag0 and lag1 are those that present a higher mitigation gradient for that w0 w1 0 5 the limit between these regions has been observed in lag4 or lag5 mainly in lag4 which justifies the assignment of weight 0 1 to lag2 4 from lag5 the mitigation gradient is gradual up to a relative percentage of change equal to 0 3 the weighted sum is corrected through a multiplicative factor 0 1 2 3 4 5 that considers the consecutiveness of the overlap of uncertainty bands for the first 5 time lags denoted as f c if the bands are overlapped within the first 5 lags multiplier f c is 5 4 if the overlap is within the first 4 lags and successively f c 0 if no overlap in the first 5 lags this threshold first 5 time lags up to lag4 is defined according to the limit between the two regions of dependence mitigation indicated above 4 the similarity index of each pairwise comparison is obtained by the normalization of the previous rate to be enclosed within 0 no overlap and 1 total overlap this normalization is done by dividing the previous rate by the summation of all time lag weights and multiplying the result by 5 maximum fo value fig 5 schematizes uboa process for a similarity index value of 0 71 similarity index is formally expressed as 4 similarity index f c w i f o 5 w i then similarity index values were arranged in matrix form and grouped on two categories and five classes table 2 for each case study 10 different matrices were defined seven 3x3 matrixes for grouping the results of factor 1 vs factor 2 and three 7x7 matrixes in the case of factor 2 vs factor 1 results 2 4 2 stability index the stability index is computed by averaging the similarity indexes of each scenario with the others including the scenario in hand in the form of a transposed matrix consequently the previous ten matrixes for each case study are summarized in only two one of dimensions 3x7 in the case of factor 1 and second one of 7x3 for grouping the results of factor 2 both matrixes are expressed as 5 s f 1 3 x 7 m 1 3 si l 1 f 2 m 1 3 l 1 f 1 m 1 3 si l 7 f 2 m 1 3 l 1 f 1 m 1 3 si l 1 f 2 m 1 3 l 2 f 1 m 1 3 si l 7 f 2 m 1 3 l 2 f 1 m 1 3 si l 1 f 2 m 7 3 l 3 f 1 m 1 3 si l 7 f 2 m 7 3 l 3 f 1 6 s f 2 7 x 3 m 1 7 si l 1 f 1 m 1 7 m 1 7 si l 2 f 1 m 1 7 m 1 7 si l 3 f 1 m 1 7 m 1 7 si l 1 f 1 m 7 7 m 1 7 si l 2 f 1 m 7 7 m 1 7 si l 3 f 1 m 7 7 where sili f 1 and sili f 2 are the mean values of similarity index si of each levels of factors 1 and 2 respectively then overall performance of stability indexes was recursively analysed through trend graphs according to their classification in two categories and five classes table 3 2 4 3 stability framework the influence of the factors over the bc modelling performance is analyzed through a recursive process that provides the highest possible stability 1 the process starts with the evaluation of factor 1 through plotting the performance of the stability index y axis versus factor 2 x axis in this graph the factor 1 level with the highest stability indexes is selected 2 the level value of factor 2 is determined through plotting the trend of the stability index y axis versus factor 1 x axis the number of intervals factor 2 levels is chosen so that the stability index for the previously determined value of factor 1 displays the highest value this is done recursively if there are several values that satisfy the indicated condition 3 results 3 1 generation of synthetic time series average values of mean standard deviation and skewness coefficient were determined from each historical records and synthetic data time series of each case study table 4 it is worth to highlight the maintenance of the mean value according to the average behaviour that annual data offer fig 6 shows the spectrum wrap arounds of each set of synthetic data of factor 1 which will populate the bc modelling 3 2 similarity indexes fig 7 shows similarity indexes obtained in matrix form in general it is noticeable that the values are relevant for 6 intervals and beyond fig 7 left for this reason the analysis of the resulting 7x7 dimension matrixes factor 1 vs factor 2 focuses on intervals 6 to 9 in contrast 3x3 matrixes of the factor 2 vs factor 1 are analysed for all of them in porma case study the highest values are obtained with 50 and 200 ss factor 1 with the combination of 200 ss and intervals 6 to 9 factor 2 showing the highest indexes 6 7 0 94 6 8 0 94 6 9 0 97 7 8 0 97 7 9 0 99 and 8 9 0 74 in contrast in the case of 50 ss the highest values are only obtained with the combination of 7 to 9 intervals 7 8 0 96 7 9 0 94 and 8 9 1 00 in both cases 50 200 ss the values are homogeneous with minimal variability high evidence of similarity and belonging principally to the fully similar class on the other hand the matrixes factor 1 vs factor 2 for adaja case study are less homogeneous although the highest values are also associated with 50 and 200 ss moreover the 200 ss level shows that for 6 to 9 intervals there is an alternation between values with null or low evidence of similarity 6 8 0 34 7 8 0 32 8 9 0 34 and values belonging to class slight similarity 6 7 0 75 6 9 0 75 7 9 0 75 in the 50 ss level the disparity of values is meaningful where values of practically null evidence of similarity 7 8 0 12 8 9 0 39 are alternating with values of total similarity 7 9 0 99 in both case studies the 100 ss level factor 1 shows the highest variability of indexes even with the lowest values the lowest evidence of similarity porma 6 9 0 07 7 9 0 08 8 9 0 19 adaja 6 8 0 10 7 8 0 39 8 9 0 10 on the other hand the analysis of the 3x3 matrixes factor 2 vs factor 1 highlights clearly that the highest indexes were found for 7 intervals except for the combination of 5 intervals with 100 and 200 ss in the adaja case study value of 0 75 in the rest of combinations the values show null or low evidence of similarity finally it is evident that the highest similarity is achieved with 200 ss being its combinations with 7 to 9 intervals the ones that a priori offer the greatest similarity the assessment of the overall performance of both factors through the stability indexes and by means bi objectives recursive process will allow defining the optimal combination of both factors 3 3 bc modelling performance assessment 3 3 1 stability indexes table 5 summarizes the stability indexes of factor 1 vs factor 2 in contrast table 6 shows the stability indexes resulting according to the levels of factor 2 for fixed levels of factor 1 it is observed that the highest values of the stability index are mainly associated with the combination of 200 ss factor 1 with 7 to 9 intervals factor 2 in particular for porma case study 200 ss vs 7 intervals 0 61 8 intervals 0 67 and for adaja case study 200 ss vs 6 intervals 0 67 7 intervals 0 62 9 intervals 0 71 see table 5 on the other side it is worth noting that in porma case study no stability index is above 0 5 lower limit of the stability threshold for the levels 50 and 100 ss of factor 1 and almost the same result is observed in adaja save two combinations 50 ss 9 intervals 0 70 and 100 ss 7 intervals 0 51 furthermore in adaja stability indices for all combinations of factor 1 with 8 intervals are lower than the preceding and following ones 0 40 0 27 0 42 additionally in both case studies the stability indexes for 200 ss and 7 intervals exhibit a high and almost equal evidence of stability 0 61 and 0 62 respectively being the combination that offers the greatest stability of results with the minimum spread of values regarding the stability indexes of factor 1 levels after setting the levels of factor 2 table 6 the highest stability indexes are achieved in general from 7 intervals in all levels of factor 1 in this sense the highest values are observed in adaja case study for 9 intervals 0 99 0 83 and 0 83 and in porma case study for 100 ss and 7 intervals 0 81 however a detailed analysis reveals that the level of the 7 intervals of factor 2 is the only one for which the resulting values are all higher than 0 50 in both cases in particular adaja case study shows increasing values from 0 56 to 0 77 3 3 2 bi objective recursive process optimal combination of levels the influence of both factors over the general bc modelling performance is analysed through a bi objective recursive approach inspired by a one way anova as indicated previously the highest stability index for factor 1 level is determined firstly and then the stability trend for the levels of factor 2 is observed for the set level in this manner both factors are controlled simultaneously and recursively fig 8 displays the overall stability framework of the process the choice of the level of factor 1 upper fig 8 is clear in both case studies the highest overall stability indexes and trends are only achieved for the level 200 ss of factor 1 in the case of porma sub basin the values display an increasing trend from 0 19 minimum value 3 intervals to 0 60 6 intervals from this point a stability is observed with a maximum of 0 67 8 intervals and a gradual decrease to 0 58 9 intervals in the case of the other two levels of factor 1 50 and 100 ss the described behavioural pattern is generally maintained but always inside the category of null or low evidence of stability on the other hand in the adaja sub basin case the highest overall stability trend is found for the levels of 6 and 7 intervals of factor 2 0 67 maximum and 0 62 respectively the other two levels for factor 1 exhibit an irregular stability behaviour once set the level of factor 1 200 ss the best level of factor 2 is determined the graphs at the bottom of fig 8 in porma case study all levels of factor 2 display a pattern of lack of relevant stability in the results excluding the level of 7 intervals the overall stability indexes of this level are higher than 0 50 in all cases in contrast in adaja case study is not so evident with two meaningful levels whilst the 9 interval level shows the highest stability values with a clearly stable trend at the value 0 83 for 100 and 200 ss see table 6 the 7 interval level shows a clearly increasing trend of stability up to 0 77 200 ss considering the minimal difference between both values of the stability index 0 83 vs 0 77 roughly 7 both values confirm a high evidence of stability and for consistency and homogeneity of results with the previous case the best level of intervals is achieved for 7 ones consequently the optimal combination of levels of both factors is obtained with 200 ss and 7 intervals 4 discussion and conclusions this research proposes an innovative methodological framework for assessing and improving the performance of bc modelling applied to the analysis and the prediction of runoff temporal behaviour of a river basin based on causality for that a robust stability framework to assess performance learning training processes of bc modelling is set up employing an innovative bi objective recursive approach this is conditioned by two main factors the number of synthetic series that populate the causal models factor 1 and the number of intervals defined for discrete probability distributions of synthetic data factor 2 these factors have not yet been addressed by any hydrological research based on bayesian causality this innovative stability framework has led to the development of two novel indicators the first one named similarity index enables an in depth analysis of the overlap between wrap around of dmgs in this case focused on w ave uncertainty bands the second one called stability index assesses the overall bc modelling performance process in addition the number of causal models executed analyzed together with the strong mathematical foundations applied highlights the robustness and reliability of the findings moreover this research has revealed for the first time the influence of the number of intervals of probability distributions of synthetic data factor 2 on the bc modelling process and by extension to bayesian pgms by means of similarity and stability indexes this factor had not yet been analysed in a hydrological causal reasoning context this research focused on two exemplary temporal case studies through bi objective recursive developed approach highlights that the most stable combination of factors is achieved through the combination of the 200 ss level of factor 1 and 7 interval level of factor 2 as the improvement of bc modelling performance has been conducted on the decision variables of the process itself in this case annual normalizable runoff time series the optimal combination of levels achieved may also be effective for other temporal scales such as seasonal and or monthly normalizable ones as well furthermore the fact that the case studies show opposite and exemplary temporal behaviors indicates that the conclusions of this research can be extrapolated to other river basins on the other hand the optimal combination of factor levels will allow a better understanding of statistical evidence propagation between the model variables this will undoubtedly make possible to predict future events and analyze the temporal and spatio temporal behaviour of water resources in a river basin in a more reliably way furthermore the optimization of the bc modelling will enable progressing in future work on the dmg by incorporating uncertainty bands and developing new indicators of temporal and even spatio temporal behaviour these latter addressed by means of multivariate analysis additionally the framework developed might be applied to both flow classification and prediction it provides an in depth knowledge of the historical flow patterns as an alternative to standard statistical analyses and maybe automatized subject to data requirements to classify river reaches according to how the conditioned and the unconditioned fraction behave and interact in addition bc modelling might be used to predict streamflows in an alternative way compared to traditional hydrometeorological forecasting methods e g ensemble streamflow prediction use of stochastic models use of meteorological forecasts to force a hydrological model in fact it is one of the most promising applications of the methodology proposed finally the methodological framework may serve as a basis for further advances in the field of classification applied to bayesian pgms credit authorship contribution statement santiago zazo conceptualization methodology formal analysis visualization investigation ana maría martín methodology software formal analysis investigation jose luis molina conceptualization methodology supervision validation hector macian sorribes supervision validation manuel pulido velázquez supervision validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank salamanca university for the funding given to this study through the call for concept testing and results protection of the university of salamanca tcue plan 2018 2020 
3299,a strong innovative tendency is nowadays emerging that largely comprises new hydrological modelling approaches based on causal reasoning through probabilistic graphical modelling pgm because its ability to support probabilistic reasoning from data with uncertainty these novel modelling frameworks are quite diverse and disperse not only in terms of techniques but also regarding its aims it seems necessary to find a general and robust methodology for assessing its performance this paper aims to provide a novel general methodology for assessing the performance of pgm based on bayesian causality for modelling and analysing the riverś runoff behaviour for it a structured four step approach is developed and showed throughout the paper the proposed methodology begins with the identification of the two main factors that condition the bayesian causal bc modelling the number of synthetic series data amount and the number of intervals for probability distributions for training and learning processes the developed analysis comprises the definition of three levels for the first factor and seven levels for the second one as well as the design of an innovative stability framework that assesses the level of bc modelling performance furthermore it has been necessary to create define two novel indexes named similarity and stability indexes from 21 scenarios arising from the combination of the levels of the both factors the optimal combination of factors is identified through a bi objectives recursive approach based on previous indexes main results drawn successfully show a high relationship between the level of modelling performance measured in terms of stability and the river runoff temporal behaviour measured in terms of temporal dependence this research may help water managers and engineers to develop more rigorous and robust hydrological causal modelling implementations keywords probabilistic graphical models bayesian causal modelling stability time series analysis 1 introduction probabilistic graphical models pgms since their emergence in the 1980s within the statistical and artificial intelligence reasoning communities javidian et al 2020 have been increasingly getting more notoriety in scientific community this is mainly because they are an intuitive formalism to capture the probabilistic in dependence information of a domain pearl 1988 vogel et al 2018 through the combination of probability graph theories vogel et al 2014 as well as a powerful framework for reasoning under uncertainty in knowledge based systems cabañas de paz 2017 javidian et al 2020 according to koller and friedman 2009 a pgm use a graph based representation as the basis for compactly encoding a complex distribution over a high dimensional space formally it is defined by a joint probability distribution p x on the set of variables of the problem x and a graph g that represents the in dependence relationship amongst variables cabañas de paz 2017 at its core they are characterized by a qualitative part which encodes a set of conditional in dependence relationships amongst variables and a second quantitative one that measures the in dependence strength cabañas de paz 2017 pgms have been widely applied to a variety of reasoning tasks related to prediction diagnosis classification and risk assessment under original approaches and applied to different scientific disciplines engelke and hitz 2020 introduces a general theory of conditional independence applied to graphical models for extremes for its part javidian et al 2020 propose a new algorithm named lcd amp applied to chain graphs that overcomes the problems of data order dependence ramos fernández 2018 designs a naïve bayes pgm as a medical tool for predicting the severe course of acute bronchitis in infants lehikoinen et al 2019 by bayesian network bn classifiers assesses the effects of multiple natural and anthropogenic factors on marine ecosystems simultaneously for the first time macian sorribes et al 2020 addresses the spatio temporal dependence dimensions of inflows in hydrology through bns in vogel et al 2018 is identified the driving factors of flood loss at residential buildings applying novel pgms approaches based on bns and markov blankets on the other side the relation among probability distribution and the graph defines the pgm type existing three classes basically diez et al 2018 a undirected graphs e g markov networks b directed acyclic graphs e g bns and c chain graphs which are a unification of the first two javidian et al 2020 of these the most widely used is the one based on bns cabañas de paz 2017 javidian et al 2020 due to its ability to describe the overall behaviour of a system through the propagation of in dependence among the variables throughout the whole graphical structure vogel et al 2018 in addition the fact that bns are based on the notion of conditional in dependence steck 2001 makes them particularly useful for dealing with forecasting and analysing of the general behaviour in complex natural processes molina et al 2019 referring specifically to hydrology and water resources bns have been satisfactorily applied to issues such as water planning of catchments mamitimin et al 2015 xue et al 2017 integrated groundwater management carmona et al 2011 molina et al 2013 reservoir management malekmohammadi et al 2009 assessment of environmental risk on large dams ahmadi et al 2015 flood damage schroeter et al 2014 and drought forecasting and management shin et al 2019 among others recently new hydrological challenges have begun to be addressed through the potential that bns offer to discover causal structures in observed data spirtes 2010 because the intrinsic in dependence relationships within of temporal series are not known in depth molina and zazo 2018 molina et al 2019 this is performed under a novel framework named bayesian causal bc modelling based on causality and which is addressed in form of causal reasoning cr supported by bayesian modelling macian sorribes et al 2020 zazo 2017 bc modelling is a suitable technique for modelling the temporal behaviour of water resources of a basin when 1 the approach is done from top to down 2 the analysis is focused on the cause and 3 the objective comprises the prediction of the consequence macian sorribes et al 2020 pearl 2009 as in the case of bayesian causality by means of bc modelling it is highlighted the hidden logical temporal in dependence structure that inherently underlies into hydrological historical records macian sorribes et al 2020 zazo et al 2020 under this approach some noteworthy contributions have emerged in the field of stochastic hydrology in molina et al 2016 a preliminary dynamic analysis of temporal dependence propagation was presented for its part molina and zazo 2018 discovered and quantified for the first time two opposite temporal fractions within annual runoff time series one conditioned by time and other no molina et al 2019 developed a dynamic predictive runoff model based on the temporal behaviour trends of previously discovered runoff temporal fractions zazo et al 2019 showed a qualitative approach for assessing temporal dependence through a novel dependence graph recently macian sorribes et al 2020 analysed and assessed simultaneous and completely of spatio temporal dimension of inflows across two adjacent and parallel river basins in this sense bc modelling framework deliver much more accurate and powerful hydrological simulations and predictions in line with new trends in stochastic hydrological research based on hybrid approaches between traditional novel techniques mohammadi et al 2006 nourani et al 2011 valipour et al 2012 at this point it is worth highlighting that pgms are characterised by learning directly from the data when the structure of the network is unknown javidian et al 2020 malone and yuan 2012 and that such learning comprises not only the quantitative dimension of the data but also its intrinsic structure koller and friedman 2009 steck 2001 therefore issues such as the number of data or the modelling structure itself are crucial for suitable and reliable model performances koller and friedman 2009 vogel et al 2018 in this sense there are significant algorithm based developments for learning model structure from sampled data which are well known stablished in the scientific community for instance inductive causation ic algorithm verma and pearl 1991 1992 a similar approach independently developed by peter spirtes and clark glymour known as pc algorithm spirtes et al 2000 madsen et al 2003 based on conditional independence decisions le et al 2016 and the improvement of the latter named npc learning algorithm that introduces the notion of a necessary path condition madsen et al 2003 steck 2001 nevertheless in respect of the data there are two key driving factors for building a reliable dataset for learning and or training which have not yet been addressed in depth these are 1 number of synthetic series and 2 number of intervals for discrete probability distributions the aim of this research is to provide a methodological framework for achieving an optimal combination between the different considered levels of two main driving factors that condition learning training processes of bc modelling this approach was applied to increase knowledge of the temporal behaviour of water resources in a river basin and have not yet been addressed by any hydrological research based on bayesian causality the first external one is number of synthetic series that populates the bayesian causal models factor 1 three considered levels in annual synthetic data the second internal one is number of intervals for discrete probability distributions of synthetic data factor 2 with seven considered levels this was developed to improve the performance of causal models with respect to their analytical and predictive capacity in the context of temporal behaviour of water resources of a basin the influence between the levels of both factors was measured through two innovative indices named similarity index and stability index these allowed the identification of the optimal combination between the levels of both factors through a bi objectives recursive approach in terms of overall stability of the bc modelling process these findings may be extrapolated to other approaches based on this type of pgms for improving their analytical and forecast capabilities this paper is organized as follows after this introduction the methodological section and data description is addressed then the main results drawn from the research are presented finally in discussion and conclusions section the results are discussed in detail as well as the general conclusions from the study are outlined 2 methodological approach the framework for assessing the bc modelling performance in terms of overall stability process comprises a four step approach fig 1 step 1 implies the generation of synthetic data from historical records through a parametric autoregressive moving average model arma model or any alternative model approach able to generate synthetic time series use of observational data would only be possible if enough data to populate the bns is available step 2 designs the bc modelling by 4 sequential phases learning preprocessing constraints and structure learning process in step 3 probability propagation is addressed by dependence mitigation graphs dmgs obtaining also its uncertainty bands through a bootstrap approach finally step 4 assesses the bc modelling performance innovatively firstly a novel similarity index is defined through an in depth analysis of the overlap between uncertainty bands of wrap around averages of dmgs secondly a stability index is created for assessing global bc modelling performance of all possible combinations between the levels of both factors then a bi objectives recursive approach identifies the optimal combination of factors as dmg supposes an innovative way for assessing probability propagation for understanding of the reader uncertainty band generation and their overlap analysis are facilitated by exemplary figures on the other side the application of arma models to hydrological analysis simulation and prediction reveals a wide heterogeneity of data samples for example in srinivas and srinivasan 2006 is assessed a hybrid model for stochastic simulation of multi season stream flows through 100 synthetic data seasonal threshold model borgomeo et al 2015 presented a method to generate synthetic monthly streamflow through random sampling from a parametric or a nonparametric distribution assessed by 100 flow sequences in molina et al 2019 a dynamic predictive model which was populated with 200 synthetic annual runoff series from an arma model is developed based on the review of the scientific literature and in the expertise acquired in the development of causal models applied to the analysis and prediction of spatio temporal behaviour of water resources in a river basin s three different numbers of annual synthetic series factor 1 50 100 y 200 were generated in each case study all of them with the same length of the historical datasets in contrast factor 2 number of intervals for probability discretization and whose influence has not yet been addressed within the framework of hydrological research was given seven levels 3 4 5 6 7 8 and 9 intervals this led to the design execution and analysis of the results of 21 causal models for each case study which ensures the robustness of the findings and the designed methodological framework data description case studies the framework in which this research is conducted involves that the case studies form part of the methodological section in order to define a robust methodological approach that would allow extrapolating the research findings to the field of prediction based on bayesian causal models two headwater case studies were chosen according to the following key aspects 1 their completely opposite temporal behaviour temporal in dependence 2 same time period of analysis and 3 lack of spatial correlation between them both headwaters porma in the north and adaja in the south belong to duero river basin the largest international river basin between spain and portugal furthermore they are defined by gauging stations located upstream the first regulating reservoir flows under natural regime they are camposolillo code 2078 in the first case and adaja code 2046 in the second one fig 2 a the time period covered 37 hydrological years from october to september 1974 75 and 2010 11 the historical records without missing data were supported by the network of gauging stations of duero river basin authority miteco 2021 table 1 summarizes the main statistical parameters porma case study displays a temporal behaviour completely dependent with its correlation coefficients outside the anderson limits of the correlogram or very close it in contrast adaja case study exhibits an opposite behaviour clearly independent with all correlation coefficients within the independence area of the correlogram fig 2b displays both correlograms both case studies are characterized by a cold mediterranean climate highly continental porma case study shows an annual average rainfall of 1430 mm geologically there are important formations of limestones sandstone and alluvial deposits in the fluvial courses hydrogeological speaking it is characterized by low permeability or impermeable materials and low productivity and small extension aquifers molina and zazo 2018 adaja case study presents an average annual about 400 mm geologically it shows important areas of arkoses granitic blocks and alluvial deposits at the bottom of the valley regarding hydrogeology impermeable or very low permeability formations are present molina and zazo 2018 fig 2c displays the main climatic factors and fig 2d shows the graphic of both historical annual series 2 1 step 1 synthetic data generation this step is addressed through a parsimonious arma 1 1 model for each sub basin developed according to molina et al 2016 arma model plays a crucial role in this research because it provides reliable data to populate the bc modelling process in this sense the purpose of this initial phase is to generate in form of synthetic series all of them equiprobable to the historical series considered the amount of information necessary to populate the subsequent bayesian causal models this stochastic parsimonious and unconditioned model confers the highest degree of freedom to bayesian modelling an arma p q is expressed as salas et al 1980 1 y t μ j 1 p j y t j μ t j 1 q θ j t j where yt is the value of the temporal series at a certain time step t μ is the mean of the time series p q are the number of autoregressive ar and moving average ma average parameters j θj are the coefficient of ar and ma average model respectively and t represents the historical residuals before the postulation of the model a normalization process was applied using three different methods square root natural logarithm plus one and natural double logarithm plus one salas et al 1980 these functions are commonly applied to operational hydrology ochoa rivera et al 2007 the natural logarithm plus one method was chosen in both cases as it yielded the lowest skewness coefficient afterwards the synthetic data equiprobable to historical records were generated the validation of synthetic time series was carried out comparing their relevant statistics to those of historical records ochoa rivera et al 2007 in this case due to use annual time series this process was focused on mean values molina et al 2021 given that the levels considered for factor 1 50 100 and 200 synthetic series and the length of the historical data 37 years a total of 1850 3700 and 7400 annual synthetic data were respectively generated in each case study 2 2 step 2 bayesian causal model design conceptually bc modelling as pgm based on bns is defined as a direct acyclic graph dag in which conditional probability among variables is computed molina et al 2021 and propagated omnidirectionally supported by bayes theorem zazo et al 2020 mathematically bc modelling is expressed as madsen et al 2003 2 p v x v p x p a x where p v is the joint probability distribution over set of nodes v random variables x present in the graph and which are defined through dag and p x pa x is the conditional probability distribution for each variable x v that belongs to a set of probability distributions bc modelling application to hydrological time series makes possible to determine quantify the strength of in dependence relationships between variables in a dynamic and step by step manner macian sorribes et al 2020 this is performed through modifying and analyzing the evolution of the probability distribution over time macian sorribes et al 2020 by maximizing the statistical evidence of highest discrete probability distributions interval in each bńs variable molina et al 2016 after this maximization over a particular variable node the change its influence in the expected value of the other ones is assessed and quantified molina et al 2016 bc modelling design was developed in 4 phases 1 learning from synthetic data from arma 1 1 models factor 1 2 preprocessing that implies the discretization of the synthetic data into discrete probability distributions factor 2 all of them with the same amplitude 3 considering constraints initially that the main relationship among variables is natural consecutive variables linking time lag 1 and 4 structure learning which highlights the real structure of interdependence of runoff series by a constraint based approach steck 2001 vogel et al 2018 which finds a dag structure from synthetic data through conditional independence statistical tests this final stage is the core of bc modelling because it reveals the hidden non trivial and logical interdependence structure time lag 1 that underlies into hydrological series it was done through npc learning algorithm madsen et al 2003 which allows efficient simplifications to find net structures steck 2001 under the condition of not including links between conditionally independent nodes hugin 2021 bc modelling design was supported by software hugin expert version 7 3 with a significance level of 0 05 for structure learning process all bc modelling parameters were fixed except the two factors analyzed 2 3 step 3 probability propagation this step comprises probability propagation analysis over the time throughout the network through an innovative dependence mitigation graphs dmg zazo et al 2019 dmg encompasses two variables 1 time x axe in form of time lag and 2 relative of change y axe propagation of temporal dependence strength over the time conceptually dmg is obtained through the relative percentage of change produced in the child variable connected with the parent molina et al 2016 zazo et al 2019 fig 3 shows two dmgs for both sub basins temporally dependent basins tend to present a dominant positive part fig 3a porma in contrast temporally non dependent basins show a tendency towards symmetric wrap around results positive or wrap around maximum w max and negative or wrap around minimum w min as found in fig 3b adaja molina et al 2016 2 3 1 uncertainty bands generation in order to study the uncertainty of the wrap around results before changes in the levels of the two parameters factors studied 95 uncertainty bands for w max and w min series were generated by bootstrap estimation efron and tibshirani 1993 for the band around w max let x 1 x 2 x n be the values used for getting max i x i for a particular lag from these values 10 000 bootstrap samples x 1 x 2 x n were generated and the maximum value max i x i was calculated for each one then 2 5th and 97 5th percentiles of those maximum values were obtained those percentiles were named max x 0 025 and max x 0 975 respectively finally the 95 confidence interval for this particular time lag is developed as 3 2 max i x i max x 0 975 2 max i x i max x 0 025 then 95 uncertainty band for w max series is calculated by joining the upper and lower limits from the confidence intervals similarly it is determined w min 95 confidence intervals from both bands the 95 uncertainty band for the wrap around average w ave can be constructed the usefulness of w ave is based on the application of the three fold criterion statistical comparability representativeness 1 statistically of the three wrap arounds w ave exhibits the lowest dispersion 2 in river basins with temporally dependent behavior w max is clearly predominant with a minimal influence of w min by contrast in independent ones w max and w min tend to compensate each other molina et al 2016 zazo et al 2019 consequently w ave can compare both types of river basins through a unique wrap around and 3 w ave is also able to capture represent the temporal behavior of water basins when w ave is generally positioned above the dmg x axis the basin exhibits a dependent behavior whereas if w ave is positioned in both sides of the x axis the behavior is independent finally uncertainty band for w ave is built by averaging the 95 uncertainty bands for w max and w min series in other words the upper lower limit of the uncertainty band for the w ave series become the average of the upper lower limits of the uncertainty bands for the w max and min series in this manner a single wrap around with its uncertainty band is available for a better understanding of this process fig 4 schematizes the w ave generation process and its uncertainty band 2 4 step 4 bc modelling performance assessment this step determines how the w ave built depends on factors 1 and 2 of bc modelling for this purpose for each of the 21 scenarios 3x7 considered w ave and 95 uncertainty band are constructed and then the overlapping between all of them is analysed in this regard two novel indexes have been defined 1 similarity index and 2 stability index the first one analyses in depth the overlap between uncertainty bands for the w ave and the second one assesses the overall performance of the process moreover in the scientific literature there are a variety of indices based on bayesian approaches such as the bayesian information criterion schwarz 1978 one of the most widely applied to model selection those arising from the combination of different indices and causes bradley et al 2015 kim et al 2018 or from the combination of different causes to assess a particular problem giné garriga et al 2018 among others 2 4 1 similarity index for each pairwise comparison of scenarios a similarity index is calculated through a complete uncertainty bands overlapping analysis uboa as follows 1 if the two uncertainty bands overlap for a certain time lag the value 1 is assigned to that time lag otherwise a 0 value is assigned this is mathematically expressed by a boolean factor of overlap fo 2 a weighted sum of the overlaps of all time lag is obtained through following weights wi 0 5 for lag0 and lag1 w0 w1 0 5 0 1 for lag2 to lag4 w2 w3 w4 0 1 and 0 01 for the rest lags wi 0 01 for i 4 this weight structure is based on the acquired knowledge on dmg zazo et al 2019 dmg allows us to identify two regions of higher and lower mitigation of time dependence of these lag0 and lag1 are those that present a higher mitigation gradient for that w0 w1 0 5 the limit between these regions has been observed in lag4 or lag5 mainly in lag4 which justifies the assignment of weight 0 1 to lag2 4 from lag5 the mitigation gradient is gradual up to a relative percentage of change equal to 0 3 the weighted sum is corrected through a multiplicative factor 0 1 2 3 4 5 that considers the consecutiveness of the overlap of uncertainty bands for the first 5 time lags denoted as f c if the bands are overlapped within the first 5 lags multiplier f c is 5 4 if the overlap is within the first 4 lags and successively f c 0 if no overlap in the first 5 lags this threshold first 5 time lags up to lag4 is defined according to the limit between the two regions of dependence mitigation indicated above 4 the similarity index of each pairwise comparison is obtained by the normalization of the previous rate to be enclosed within 0 no overlap and 1 total overlap this normalization is done by dividing the previous rate by the summation of all time lag weights and multiplying the result by 5 maximum fo value fig 5 schematizes uboa process for a similarity index value of 0 71 similarity index is formally expressed as 4 similarity index f c w i f o 5 w i then similarity index values were arranged in matrix form and grouped on two categories and five classes table 2 for each case study 10 different matrices were defined seven 3x3 matrixes for grouping the results of factor 1 vs factor 2 and three 7x7 matrixes in the case of factor 2 vs factor 1 results 2 4 2 stability index the stability index is computed by averaging the similarity indexes of each scenario with the others including the scenario in hand in the form of a transposed matrix consequently the previous ten matrixes for each case study are summarized in only two one of dimensions 3x7 in the case of factor 1 and second one of 7x3 for grouping the results of factor 2 both matrixes are expressed as 5 s f 1 3 x 7 m 1 3 si l 1 f 2 m 1 3 l 1 f 1 m 1 3 si l 7 f 2 m 1 3 l 1 f 1 m 1 3 si l 1 f 2 m 1 3 l 2 f 1 m 1 3 si l 7 f 2 m 1 3 l 2 f 1 m 1 3 si l 1 f 2 m 7 3 l 3 f 1 m 1 3 si l 7 f 2 m 7 3 l 3 f 1 6 s f 2 7 x 3 m 1 7 si l 1 f 1 m 1 7 m 1 7 si l 2 f 1 m 1 7 m 1 7 si l 3 f 1 m 1 7 m 1 7 si l 1 f 1 m 7 7 m 1 7 si l 2 f 1 m 7 7 m 1 7 si l 3 f 1 m 7 7 where sili f 1 and sili f 2 are the mean values of similarity index si of each levels of factors 1 and 2 respectively then overall performance of stability indexes was recursively analysed through trend graphs according to their classification in two categories and five classes table 3 2 4 3 stability framework the influence of the factors over the bc modelling performance is analyzed through a recursive process that provides the highest possible stability 1 the process starts with the evaluation of factor 1 through plotting the performance of the stability index y axis versus factor 2 x axis in this graph the factor 1 level with the highest stability indexes is selected 2 the level value of factor 2 is determined through plotting the trend of the stability index y axis versus factor 1 x axis the number of intervals factor 2 levels is chosen so that the stability index for the previously determined value of factor 1 displays the highest value this is done recursively if there are several values that satisfy the indicated condition 3 results 3 1 generation of synthetic time series average values of mean standard deviation and skewness coefficient were determined from each historical records and synthetic data time series of each case study table 4 it is worth to highlight the maintenance of the mean value according to the average behaviour that annual data offer fig 6 shows the spectrum wrap arounds of each set of synthetic data of factor 1 which will populate the bc modelling 3 2 similarity indexes fig 7 shows similarity indexes obtained in matrix form in general it is noticeable that the values are relevant for 6 intervals and beyond fig 7 left for this reason the analysis of the resulting 7x7 dimension matrixes factor 1 vs factor 2 focuses on intervals 6 to 9 in contrast 3x3 matrixes of the factor 2 vs factor 1 are analysed for all of them in porma case study the highest values are obtained with 50 and 200 ss factor 1 with the combination of 200 ss and intervals 6 to 9 factor 2 showing the highest indexes 6 7 0 94 6 8 0 94 6 9 0 97 7 8 0 97 7 9 0 99 and 8 9 0 74 in contrast in the case of 50 ss the highest values are only obtained with the combination of 7 to 9 intervals 7 8 0 96 7 9 0 94 and 8 9 1 00 in both cases 50 200 ss the values are homogeneous with minimal variability high evidence of similarity and belonging principally to the fully similar class on the other hand the matrixes factor 1 vs factor 2 for adaja case study are less homogeneous although the highest values are also associated with 50 and 200 ss moreover the 200 ss level shows that for 6 to 9 intervals there is an alternation between values with null or low evidence of similarity 6 8 0 34 7 8 0 32 8 9 0 34 and values belonging to class slight similarity 6 7 0 75 6 9 0 75 7 9 0 75 in the 50 ss level the disparity of values is meaningful where values of practically null evidence of similarity 7 8 0 12 8 9 0 39 are alternating with values of total similarity 7 9 0 99 in both case studies the 100 ss level factor 1 shows the highest variability of indexes even with the lowest values the lowest evidence of similarity porma 6 9 0 07 7 9 0 08 8 9 0 19 adaja 6 8 0 10 7 8 0 39 8 9 0 10 on the other hand the analysis of the 3x3 matrixes factor 2 vs factor 1 highlights clearly that the highest indexes were found for 7 intervals except for the combination of 5 intervals with 100 and 200 ss in the adaja case study value of 0 75 in the rest of combinations the values show null or low evidence of similarity finally it is evident that the highest similarity is achieved with 200 ss being its combinations with 7 to 9 intervals the ones that a priori offer the greatest similarity the assessment of the overall performance of both factors through the stability indexes and by means bi objectives recursive process will allow defining the optimal combination of both factors 3 3 bc modelling performance assessment 3 3 1 stability indexes table 5 summarizes the stability indexes of factor 1 vs factor 2 in contrast table 6 shows the stability indexes resulting according to the levels of factor 2 for fixed levels of factor 1 it is observed that the highest values of the stability index are mainly associated with the combination of 200 ss factor 1 with 7 to 9 intervals factor 2 in particular for porma case study 200 ss vs 7 intervals 0 61 8 intervals 0 67 and for adaja case study 200 ss vs 6 intervals 0 67 7 intervals 0 62 9 intervals 0 71 see table 5 on the other side it is worth noting that in porma case study no stability index is above 0 5 lower limit of the stability threshold for the levels 50 and 100 ss of factor 1 and almost the same result is observed in adaja save two combinations 50 ss 9 intervals 0 70 and 100 ss 7 intervals 0 51 furthermore in adaja stability indices for all combinations of factor 1 with 8 intervals are lower than the preceding and following ones 0 40 0 27 0 42 additionally in both case studies the stability indexes for 200 ss and 7 intervals exhibit a high and almost equal evidence of stability 0 61 and 0 62 respectively being the combination that offers the greatest stability of results with the minimum spread of values regarding the stability indexes of factor 1 levels after setting the levels of factor 2 table 6 the highest stability indexes are achieved in general from 7 intervals in all levels of factor 1 in this sense the highest values are observed in adaja case study for 9 intervals 0 99 0 83 and 0 83 and in porma case study for 100 ss and 7 intervals 0 81 however a detailed analysis reveals that the level of the 7 intervals of factor 2 is the only one for which the resulting values are all higher than 0 50 in both cases in particular adaja case study shows increasing values from 0 56 to 0 77 3 3 2 bi objective recursive process optimal combination of levels the influence of both factors over the general bc modelling performance is analysed through a bi objective recursive approach inspired by a one way anova as indicated previously the highest stability index for factor 1 level is determined firstly and then the stability trend for the levels of factor 2 is observed for the set level in this manner both factors are controlled simultaneously and recursively fig 8 displays the overall stability framework of the process the choice of the level of factor 1 upper fig 8 is clear in both case studies the highest overall stability indexes and trends are only achieved for the level 200 ss of factor 1 in the case of porma sub basin the values display an increasing trend from 0 19 minimum value 3 intervals to 0 60 6 intervals from this point a stability is observed with a maximum of 0 67 8 intervals and a gradual decrease to 0 58 9 intervals in the case of the other two levels of factor 1 50 and 100 ss the described behavioural pattern is generally maintained but always inside the category of null or low evidence of stability on the other hand in the adaja sub basin case the highest overall stability trend is found for the levels of 6 and 7 intervals of factor 2 0 67 maximum and 0 62 respectively the other two levels for factor 1 exhibit an irregular stability behaviour once set the level of factor 1 200 ss the best level of factor 2 is determined the graphs at the bottom of fig 8 in porma case study all levels of factor 2 display a pattern of lack of relevant stability in the results excluding the level of 7 intervals the overall stability indexes of this level are higher than 0 50 in all cases in contrast in adaja case study is not so evident with two meaningful levels whilst the 9 interval level shows the highest stability values with a clearly stable trend at the value 0 83 for 100 and 200 ss see table 6 the 7 interval level shows a clearly increasing trend of stability up to 0 77 200 ss considering the minimal difference between both values of the stability index 0 83 vs 0 77 roughly 7 both values confirm a high evidence of stability and for consistency and homogeneity of results with the previous case the best level of intervals is achieved for 7 ones consequently the optimal combination of levels of both factors is obtained with 200 ss and 7 intervals 4 discussion and conclusions this research proposes an innovative methodological framework for assessing and improving the performance of bc modelling applied to the analysis and the prediction of runoff temporal behaviour of a river basin based on causality for that a robust stability framework to assess performance learning training processes of bc modelling is set up employing an innovative bi objective recursive approach this is conditioned by two main factors the number of synthetic series that populate the causal models factor 1 and the number of intervals defined for discrete probability distributions of synthetic data factor 2 these factors have not yet been addressed by any hydrological research based on bayesian causality this innovative stability framework has led to the development of two novel indicators the first one named similarity index enables an in depth analysis of the overlap between wrap around of dmgs in this case focused on w ave uncertainty bands the second one called stability index assesses the overall bc modelling performance process in addition the number of causal models executed analyzed together with the strong mathematical foundations applied highlights the robustness and reliability of the findings moreover this research has revealed for the first time the influence of the number of intervals of probability distributions of synthetic data factor 2 on the bc modelling process and by extension to bayesian pgms by means of similarity and stability indexes this factor had not yet been analysed in a hydrological causal reasoning context this research focused on two exemplary temporal case studies through bi objective recursive developed approach highlights that the most stable combination of factors is achieved through the combination of the 200 ss level of factor 1 and 7 interval level of factor 2 as the improvement of bc modelling performance has been conducted on the decision variables of the process itself in this case annual normalizable runoff time series the optimal combination of levels achieved may also be effective for other temporal scales such as seasonal and or monthly normalizable ones as well furthermore the fact that the case studies show opposite and exemplary temporal behaviors indicates that the conclusions of this research can be extrapolated to other river basins on the other hand the optimal combination of factor levels will allow a better understanding of statistical evidence propagation between the model variables this will undoubtedly make possible to predict future events and analyze the temporal and spatio temporal behaviour of water resources in a river basin in a more reliably way furthermore the optimization of the bc modelling will enable progressing in future work on the dmg by incorporating uncertainty bands and developing new indicators of temporal and even spatio temporal behaviour these latter addressed by means of multivariate analysis additionally the framework developed might be applied to both flow classification and prediction it provides an in depth knowledge of the historical flow patterns as an alternative to standard statistical analyses and maybe automatized subject to data requirements to classify river reaches according to how the conditioned and the unconditioned fraction behave and interact in addition bc modelling might be used to predict streamflows in an alternative way compared to traditional hydrometeorological forecasting methods e g ensemble streamflow prediction use of stochastic models use of meteorological forecasts to force a hydrological model in fact it is one of the most promising applications of the methodology proposed finally the methodological framework may serve as a basis for further advances in the field of classification applied to bayesian pgms credit authorship contribution statement santiago zazo conceptualization methodology formal analysis visualization investigation ana maría martín methodology software formal analysis investigation jose luis molina conceptualization methodology supervision validation hector macian sorribes supervision validation manuel pulido velázquez supervision validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank salamanca university for the funding given to this study through the call for concept testing and results protection of the university of salamanca tcue plan 2018 2020 
