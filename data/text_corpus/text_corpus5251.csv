index,text
26255,a persistent problem in numerical hydrologic modeling is tracking provenance or how particular data came to be with multiple modules available for individual flux parameterizations and over 100 parameters the precipitation runoff modeling system prms is a perfect example of why it is such a challenge to track the history of input and output of complex models we present a lightweight object oriented python framework with programmatic tools for management and visualization using prms as an example platform within this framework a modeler can write intuitive code for a myriad of basic or advanced applications the framework also includes methods that for example apply systematic or stochastic parameter modifications while simultaneously saving metadata on which parameters were varied and with what improvement in performance we include a case study that uses built in monte carlo parameter resampling for global sensitivity analysis of eight prms parameters related to estimation of shortwave solar radiation keywords python framework prms pawn parameter sensitivity software information name of software prms python developers john volk and matthew turner contact via github program language python requirements python2 7 or python3 4 windows mac os x or linux prms 3 or newer availability this software is open source bsd3 license and freely available since 2018 on github https github com prms python prms python it is also on the python package index https pypi org project prms python additional documentation an online documentation website is included at http prms python github io prms python jupyter notebooks with examples of basic and advanced workflows using prms python are included with the package 1 introduction application of distributed hydrologic models often requires knowledge of physical parameters throughout space and time as well as procedures for model development calibration and management and analysis of large datasets often these routines are opaque to the observer and tedious to the scientist hutton et al 2016 these challenges also unfortunately limit the applications of models such as sensitivity analysis and multiple hypotheses testing for example of different hydrologic flux parameterizations to enhance the reproducibility and efficiency of modeling applications we developed prms python an open source python package for the precipitation runoff modeling system prms leavesley et al 1983 markstrom et al 2015 unlike luca a graphical user interface application for step wise parameter calibration of prms hay and umemoto 2006 prms python has functionality to access prms data structures modify inputs visualize input and output and manage large model ensembles including a monte carlo parameter resampling routine management of large model ensembles includes multiple levels of self generating metadata that is useful for user management and sharing model data and procedures with the greater hydrologic research community e g on hydroshare tarboton et al 2014 if prms modelers conduct modeling workflows and analysis using prms python and utilize its self documenting metadata the challenge of reproducibility of numerical experiments can be overcome saraswat et al 2015 hutton et al 2016 the objects within prms python integrate with common scientific libraries in python and can be combined in myriad ways to conduct advanced modeling analyses our modular approach facilitates future scientific work and new software extensions both by us and we hope by others 1 1 challenges in spatially distributed hydrologic modeling the development and application of spatially distributed hydrologic models is complex involving multiple steps e g data cleaning model grid or domain development parameter estimation parameter calibration input and output management and analysis and visualization of results these steps are learned over time through hard work in addition to scientific competency in multiple domains spatially distributed hydrologic modeling applications present computational challenges that tend to limit the exploration of model features and applications mendoza et al 2015 for example the multitude of parameters in prms often with parameter to parameter interactions which need to be calibrated presents a major challenge even when applied to small watershed domains prms models may contain tens of thousands of hydrologic response units hrus each of which need to be assigned multiple parameter values commonly 30 model development and work flow challenges also arise when keeping track of inputs and outputs of many simulations e g climate change scenarios or parameter uncertainty analysis modification of model inputs and organization and analysis of inputs outputs are thus common challenges to most modeling applications which act to limit their reproducibility saraswat et al 2015 hutton et al 2016 further significant time is spent on data management related to model input and output contributing to increased potential for human error as well as taking away crucial time that could be dedicated towards scientific applications mendoza et al 2016 consequences may also include inadequate calibration and understanding of parameter uncertainty and unexplored model structures the latter is particularly relevant to the prms model which unlike some hydrologic models offers multiple parameterizations for estimating various climatic and hydrologic fluxes a unifying challenge in the field of hydrologic science has been to define individual theoretical laws that accurately represent particular physical processes at intermediate scales e g from hillslope to catchment scales with inherent spatial and temporal heterogeneity dooge 1986 as a result the subdiscipline of hydrologic numerical modeling has recently trended towards the evaluation of multiple flux parameterizations scientifically viewed as competing physical hypotheses for individual hydrologic fluxes by evaluating the effectiveness and limitations of competing parameterizations we can begin to reduce the large number of them and better classify them according to when where they are most and least appropriate this process also expands fundamental hydrologic knowledge this is the main concept behind the structure for unifying multiple modeling alternatives summa clark et al 2015a b which is a hydrologic model that allows for testing of multiple model decisions including different parameterizations of hydrologic fluxes model spatial discretizations and connectivity analogous to the concept behind summa is the prms model s modular system in which the user can choose several parameterizations for the estimation of individual hydrologic processes e g potential evapotranspiration this allows prms modelers to evaluate competing hypotheses of the underlying physics of the model clark et al 2011a b although this is seldom done in practice clark et al 2015a b analysis of competing hydrologic hypotheses using numerical models often requires large numbers of simulations and hierarchical frameworks of model modifications alongside field measurements the prms python framework alleviates many common challenges for the modeler and encourages advanced exploration of model parameters and flux hypotheses thus encouraging progress in fundamental hydrologic research 1 2 similar software applications that facilitate numerical models are common groundwater vistas gms and visual modflow are examples of proprietary user interface applications for modflow harbaugh et al 2000 the united states geological survey s usgs program for groundwater flow modeling these applications consist of a graphical user interface that is complex offering many features for data preprocessing model building parameter optimization uncertainty data management and post processing however they are proprietary and therefore in our opinion can be somewhat inflexible for certain scientific applications open source software for models like prms or modflow also exist they are typically geared for specific purposes such as model calibration or parameter uncertainty e g hay and umemoto 2006 doherty and hunt 2010 prms python is different as it is comprised of a set of python classes and functions which allow scripting of many common tasks involved with prms modeling prms python was developed with an emphasis on creating an intuitive interface between prms data structures and powerful open source well documented and well supported python scientific libraries perkel 2015 as a result prms python gives flexibility and control of prms that is limited only by the user s understanding of prms and python unlike flopy a similar python module for modflow bakker et al 2016 prms python has limited features for initial model building due to the large number of spatial parameters and optional modules in prms there is no clear and consistent set of physical data e g vegetation coverage and parameter estimation techniques for the wide range of potential prms applications mendoza et al 2016 therefore the initial development of a prms model needs to be conducted beforehand typically using a geographic information system gis the gsflow arcpy software enables creation of prms input files within a python environment gardner et al 2018 however prms python includes tools for modification and visualization of parameter and climate input data to aid the process of model input assignment and validation the flexibility of the prms python framework allows for workflows that are not explicitly written in prms python several recipes are included in the online documentation therefore components of prms python can be used to make simple scripts to conduct common scientific modeling applications or be used to develop additional software that interacts with prms for example a user with experience in spatial analysis in python e g using geopandas fiona shapely or other packages can integrate spatial analysis tools with prms python to estimate initial parameter sets for prms a potential alternative to traditional gis based approaches a key component of prms python functionality is loading prms text files into efficient memory based numpy arrays van der walt et al 2011 and pandas dataframes mckinney 2013 standard building blocks for advanced scientific computing and visualization in python oliphant 2007 1 3 design principles prms python is fundamentally an attempt to build abstract representations of both the foundational data structures of prms and the execution of the model itself these abstractions take the form of python classes that for example allow a user to get and set prms parameters as a numpy array van der walt et al 2011 like one would do with columns of a dataframe in the popular pandas library mckinney 2013 while we do use basic abstractions as building blocks to for example programmatically optimize model parameters these representations of prms data structures are useful in their own right and are designed for multiple uses because prms python allows for model input parameters and climatic forcing data as well as model output to be represented as numpy arrays and pandas dataframes many other tools from the python ecosystem can be used for example other numpy operations van der walt et al 2011 and visualization with matplotlib hunter 2007 this is the main reason for choosing python there is already a wealth of scientific and mathematical tools available in the language oliphant 2007 perkel 2015 in addition python occupies a niche where unlike java or c it is a perfect first language so future developers of prms python might include geoscience students who are new to programming perkel 2015 python is also a powerful object oriented language that is used by professional programmers the major components of prms python although flexible in their applications enforce standardization of prms simulation structure for example prms python simulations follow a strict file and directory naming and structure with only partial control given to the user these design choices were chosen for multiple reasons 1 to limit code complexity and potential for bugs and 2 to aid users so that they do not have to develop their own system a secondary benefit of this design is that a user community can share their workflows without running into compatibility issues between platforms and individual nuances in format saraswat et al 2015 hutton et al 2016 1 4 purpose and motivation we designed prms python as a lightweight object oriented python library for multiple model applications and workflows different modeling applications e g parameter calibration uncertainty analysis or climate impact experiments require many data handling management and visualization routines that vary on a case by case basis therefore we feel that a set of highly flexible tools in the form of carefully designed intuitive python objects and functions is an ideal software architecture for addressing multiple model independent prms applications additionally scripting of prms applications within the prms python framework results in reproducible numerical experiments the flexibility of model workflows and their reproducibility can be challenging when conducted with graphical user interface applications similarly the inherent connection between native prms data structures and python scientific data structures and routines is a substantial benefit of this approach an example case study in this paper demonstrates how the prms python framework can be used to conduct a global parameter sensitivity analysis a common modeling challenge however this is an arbitrary example of many potential uses of the prms python framework the structures in prms python build upon each other and can be combined in different ways e g some allow access to model inputs whereas others leverage these to conduct simulations where input is systematically modified and simulation inputs and outputs are tracked via metadata files ultimately this lightweight framework aims to facilitate scientific discovery and operational applications using the prms hydrologic model by giving the user intuitive and efficient control of model workflows and tools for data provenance and analysis 2 implementation 2 1 the precipitation runoff modeling system prms the spatially distributed watershed model prms is commonly used by hydrologists and water resource managers for predicting watershed hydrologic response to climate dynamics at multiple spatial and temporal scales e g hay et al 2011 markstrom et al 2016 maintained and updated by the usgs prms continues to be upgraded and improved markstrom et al 2015 for example the usgs has recently added new useful features including a dynamic parameter option regan and lafontaine 2017 furthermore the recent application of prms to the conterminous u s is considered the national hydrology model by the usgs markstrom et al 2016 with source code written in fortran and c prms was developed as a modular framework enabling the user to choose between multiple physical modules leavesley et al 1983 1996 markstrom et al 2015 most prms inputs and outputs are ascii files that follow simple yet strict formats prms requires inputs of daily climate forcing variables physical parameters that are dependent on the physical modules chosen and control parameters commonly used outputs include time series of simulated statistical variables e g stream discharge or soil moisture spatial output and water balance summary files 2 2 software overview prms python was developed and tested on linux and windows platforms the package is open source with a bsd 3 license and compatible with python 2 7 and python 3 4 dependencies are limited to common python modules and automatically handled when installing from the python package index using the python package installer pip the source code of prms python follows the guidelines suggested by the python enhancement proposal 8 or pep 8 e g class names backwards compatibility etc prms python is heavily object oriented resulting in a modular framework fig 1 we developed python classes to represent two input files of prms the data file which contains time series of climate variables that drive prms simulations and the parameter file which holds mostly physical model dimensions and parameters required by different process modules as a side note words herein that are italicized distinguish them as part of the prms model as opposed to part of prms python building on these primary data structures the simulation and simulationseries classes enforce basic and strict management and execution of single or multiple parallelized prms simulations in a python environment similarly the scenario and scenarioseries classes utilize the simulation and simulationseries and give the ability to modify input parameters of python simulations including more advanced post management of simulations via a metadata file the optimizer class is built on the simulationseries as well and offers routines for monte carlo parameter resampling prms python objects that execute the prms model i e simulation simulationseries scenario etc require a strict file naming convention for prms input files specifically the user must name his her prms control file as control the parameter file as parameters the data file as data and the statistical variable output file must be named statvar dat the optimizationresult class utilizes information from metadata file s that record critical information about a set of optimizations for a user defined optimization stage as described in hay et al 2006 stages or steps of calibration might include solar radiation potential evapotranspiration or multiple parameter sets that control surface and subsurface flow the optimizationresult class allows for multiple goodness of fit metrics to be calculated and used to rank optimization stage results it also includes a method to archive output from a given optimization stage greatly reducing disk storage when an optimization stage has produced large quantities of model output a module of utility functions util for miscellaneous tasks such as calculating goodness of fit metrics for model output is also included in prms python fig 1 the subsections below give more detailed descriptions of selected prms python classes that were custom built for this framework all python objects and functions in the prms python framework can be classified as custom development however they commonly transform data structures from the prms format to data structures of the numpy and pandas python libraries van der walt et al 2011 mckinney 2013 additional prms python functionality and data that is in development or otherwise not discussed in detail in this article include a cross platform command line interface cli for prms python a unit testing module and a full prms model for testing and experimenting with different prms python objects the prmspy executable gives access to prms python from the command line currently the cli offers a routine to scale pairs of prms parameters over a 2 dimensional grid run the associated simulations and produce pdf documents of the resulting goodness of fit as 2 dimensional matrix plots for an arbitrary number of parameter pairs unit tests were developed for major prms python classes using the python unittest package the tests are located in the test test prms python py module within prms python unit tests as well as other documentation examples described in subsection 2 11 utilize a functional not calibrated prms model that was developed for the lehman and baker creek watersheds in the great basin nv volk 2014 2 3 data the prms data input file contains date indexed climate variables that are used to force the hydrologic model it may also contain climate and hydrologic variables e g measured stream discharge that can be used for model evaluation the prms python data class loads the data file into python and has a class property data frame that converts the climatic forcing data to a date indexed pandas dataframe once loaded climate data can easily be adjusted and visualized in the dataframe format the modify method allows efficient function based modification of the time series hydro climatic data within the file a familiar example use is the modification of temperature forcing data to create synthetic warming scenarios a metadata property of the data class holds the hydro climatic variable names and other header data as found in the data file the data class has a write method which converts the pandas dataframe representation of the data file back to prms ascii text format if the climatic variables were accessed if not it simply copies the file for the sake of computational efficiency all information stored in a prms data is represented in two data properties metadata and data frame therefore it is possible to build a new data file using a data instance that was not initialized on a preexisting data file for example climatic data from a comma separated value file could be loaded with pandas and applied to a data instance s data frame along with the appropriate metadata to create a new data file for prms 2 4 parameters physical dimensions and parameter values of prms models are stored in the prms parameter input file the parameters class enables efficient access to model parameters for modification and visualization the parameters class manages parameters metadata such as parameter name dimensions data types and length in a manner loosely similar to that of a netcdf file dimensions of the prms model and dimensions lengths names data type float integer etc for individual parameters are stored in the dimensions and base params attributes respectively parameter values are not loaded into memory until accessed by the user giving the parameter class higher memory efficiency which is particularly important for workflows with models that utilize high resolution spatial grids or when accessing multiple parameter files values of a given parameter can be accessed using the parameter name as a key multi dimensional parameters are returned as multi dimensional numpy ndarrays with the shape set by the prms dimensions for example the rain adj parameter will have the shape of nhru by nmonths modification of parameter values from a parameters instance can be conducted using numpy mathematical rules including computationally efficient vectorized application of mathematical operations the write method rewrites the parameter data back into the text format for a standard prms parameter file a robust parameter plotting method plot is capable of plotting most prms physical parameters depending on their dimensions specifically single valued parameters are printed to an html table series are plotted as line plots whereas spatial parameters are plotted as images on a uniform grid three multi paged pdf documents containing plots can be quickly printed for all parameters for inspection one parameter per page including an additional html table with single valued parameter information specifics can be found in the online documentation and example jupyter notebooks 2 5 simulation and simulationseries the simulation and simulationseries classes are the most fundamental prms python implementations that manage and execute single and multiple prms simulations respectively the simulation object manages a single prms simulation its constructor takes the directory that contains prms input files and a simulation directory that will contain the simulation inputs and outputs as keyword arguments the simulation constructor creates the simulation directory if it does not exist and creates two subdirectories inputs that will contain a copy of the simulations input files and outputs for output files the simulation run method executes the model and copies output files to the outputs subdirectory under the simulation directory the class method from data of the simulation class allows a simulation object to be initialized from prms python data and parameter objects along with a path to a control file as opposed to the standard simulation initialization from a directory path that contains all input files this class method gives the user flexibility if required in the naming conventions the simulationseries class constructor takes a list of simulation objects and runs each optionally in parallel returning a dictionary that includes paths to each simulation s directory parameter file data file and statistical variable output file simulation and simulationseries objects enable no or limited tracking of simulation metadata and are designed as building blocks for more advanced programs or workflows as done within the scenario scenarioseries and optimizer classes that are discussed below 2 6 scenario and scenarioseries slightly higher level than the simulation and simulationseries the scenario and scenarioseries classes offer the user custom modification and tracking of simulation s via a build method and metadata files metadata includes titles descriptions and timing information that relate to scenarios where the user is systematically modifying the parameters of an existing prms model for example a scenario may include altering the vegetation coverage over a given area to simulate hydrologic implications of different foresting techniques or changes in land cover the scenario and scenarioseries both operate on a 3 step process initialization building and running after initialization the build method creates the simulation directory structure following the procedure from the simulation class and also applies modifications to parameters based on a keyword argument mod funs dict the mod funs dict is a user defined python dictionary that holds prms parameter names as keys and python functions to apply to the stated parameters as values calling build applies these modifications to the original parameters and makes a copy of the new parameters this is a highly flexible mechanism for adjusting parameter values in deterministic or stochastic ways that is easily documented functions given to the mapping dictionary mod funs dict are stored as text representations of the original python functions along with the scenario title description and simulation start and end date time stamps are saved to a json metadata file in the parent scenario directory analogous to the simulation directory of the simulation class after calling the run method of the scenario instance the scenarioseries class in general manages and executes multiple scenario objects in parallel the scenarioseries is initialized in a similar manner as scenario it requires the directory of prms input files the output directory and optionally a title and description that describe the entire group of scenarios next the scenarioseries like scenario has a build method that instead takes a list of python dictionaries as an argument scenarios list each dictionary has the same entries as available to an individual scenario object a scenario title description and arbitrary number of parameter names keys with corresponding python functions values to modify them by the metadata created from a scenarioseries differs from scenario it retains the same type of metadata file for each individual scenario and also includes a master metadata file series metadata json that is stored in the parent directory of all scenarios the master metadata file includes the use of universal unique identifiers uuid for each scenario individual prms simulation that map to each scenario title the uuids are used as subdirectory names under the scenario directory given upon initialization and each contains the inputs and outputs of each simulation according to the file structure set by the simulation class therefore the master metadata file can be used to map between the metadata given in the scenarios list dictionary and the directories of each scenario in the scenarioseries otherwise the individual metadata files for each scenario can be used the uuid s are used because they ensure no two scenario directories will be identical and it relieves the need for the user to imagine perhaps arbitrary names for a large number of directories similar to simulationseries the scenarioseries has a class method from parameters iter that allows initialization from a list of modification dictionaries that are normally passed in the build method a full example use of the scenarioseries class is included in the prms python documentation the example involves systematically scaling values for two parameters that determine solar radiation and potential evapotranspiration specifically the two parameters are scaled from 0 7 to 1 0 factors of their initially estimated values with grid increments of 0 1 resulting in a uniform 2 dimensional grid of parameter space after building and running the scenarioseries the metadata that maps uuid s to individual parameter modifications for each simulation is used to load results and visualize the goodness of fit for each parameter combination 2 7 optimizer the optimizer class is designed to hold routines or fundamental components of numerical methods for parameter sensitivity uncertainty analysis and optimization for example the use of probability distribution functions to sample random variables for parameter values is useful for a number of methods of model sensitivity and uncertainty analysis currently the monte carlo method is available which offers two probability distributions normal and uniform for parameter resampling that can be applied on an arbitrary parameter set i e optimization stage defined by the user the stochastic parameter resampling as offered by the optimizer class is available as a stand alone function optimizer resample or if using the monte carlo method as part of an automatic workflow that applies the resampling to an arbitrary set of parameters for an arbitrary number of samples and runs the corresponding prms simulations while tracking and generating metadata due to the large spectrum of analysis methods that use stochastic resampling procedures we choose to keep this method as a fundamental routine as opposed to an automatic parameter optimization or sensitivity uncertainty analysis routine this design choices give the user more control and ability to use the tool as a building block for a variety of parameter output analyses an example is shown in the case study section 3 1 that demonstrates a global moment independent sensitivity analysis of eight parameters related to the estimation of solar radiation the monte carlo method described here is customized for prms python however other sensitivity analysis and parameter optimization routines already exist in python e g salib and spotpy and can readily be connected with a prms model via the prms python framework houska et al 2015 herman and usher 2017 the parameter resampling method has specific rules that depend on the parameter dimension that are laid out in the documentation e g spatial parameters are resampled all at once as opposed to single or monthly parameters which are independently resampled ranges for parameter values e g according to markstrom et al 2015 must be set in the param ranges attribute of the optimizer class and can be manually adjusted if for example a user wants to resample from a subset of the parameter space using the uniform distribution the normal distribution resampling method does not simply sample from a random normal variable instead it is designed to shift the mean and variance of an existing parameter however application of bootstrap resampling directly from a random variable is straightforward using a parameters or scenario instance along with probability distribution functions provided by numpy the normal resampling method uses two keyword arguments mu factor and noise factor which for example when applied to spatial parameters scale values of the initial parameter set and defines the standard deviation of a normal random variable to add to the scaled initial parameter values for example if mu factor is set to 1 and noise factor set to 0 1 then the initial parameter values will not be scaled but a normal random variable with standard deviation 0 1 parameter allowable range will be added to the initial parameter more details and examples on the resampling rules can be found in the monte carlo parameter resampling jupyter notebook that is packaged with prms python to initialize an optimizer object and run the monte carlo method required arguments include similar arguments of the simulation class but importantly also require a list of parameter s to resample an optimization stage name and a path to a date indexed csv file that contains measured data that corresponds with the optimization stage e g measured solar radiation or stream discharge the monte carlo method also requires the statistical output variable from prms that is being optimized i e the hydrologic state variable that corresponds with the measured data for calculations of goodness of fit other useful arguments for the monte carlo method and optimizer include title description resampling method number of processors available for parallelizing prms etc metadata for monte carlo simulations are sent to a json file examples of information included in the metadata file include names of parameters adjusted optimization stage e g stream discharge the resampling method the file paths of initial and adjusted parameter files and model output runtime number of processors used and user descriptions after an optimization method e g monte carlo is run the optimizer instance will gain new attributes 1 an output list containing simulation results and metadata from the simulations and 2 a date indexed pandas series of the measured data that the parameter optimization is being conducted on e g stream discharge with multiple executions of an optimizer method on the same optimizer instance the output attribute is extended to contain the additional paths to model input and output files a plot method enables basic time series daily and monthly mean and scatter plots of the current optimizer outputs included in the time series plots daily or monthly means are the results of the current optimization simulation the measured data and results from the simulation that utilized the original parameter set 2 8 optimizationresult managing results from large simulation ensembles is critical the optimizationresult class allows for retrieving parsing and archiving the potentially large number of input and output associated with previously conducted optimizer methods on initialization the optimizationresult instance gathers metadata from json file s which were produced from optimization methods sets of simulations are tracked together via a single user defined calibration or optimization stage that is a name typically referring to simulations where the same set of prms parameters were modified or corresponding to a specific hydrologic process or prms module e g evapotranspiration therefore an optimizationresult instance operates on a single optimization stage once initialized the optimizationresult instance gains useful attributes such as the number of total simulations that were conducted for the given stage and paths to the measured data that was used for the stage currently four objective functions are available in the optimizationresult class to aid the process of ranking parameter optimizations namely the nash sutcliffe efficiency nse root mean squared error rmse percent bias pbias and the coefficient of determination coef det the result table method summarizes the top n simulations ranked using the four objective functions on measured and simulated data including results of the simulation that used the initial parameter set the input parameters to the optimizer object to map model performance between simulated and measured data the get top ranked sims method takes an optimizationresult result table and returns a dictionary with lists of input and output paths of each simulation as keys in the same order found in result table the archive method of the optimizationresult class greatly reduces the size of data that is saved to disk by prms simulations that were created via an optimizer routine while retaining important information specifically the archive method operates on an individual optimization stage by archiving each simulation s modified parameter values and how they were modified as well as each simulation s relevant output paths to original input files and other metadata as with other methods of prms python the archived results are saved to json files in an archived subdirectory by default the archive method deletes the original simulation directories and model input and output files by using the archive method in tandem with an optimizer routine such as monte carlo parameter resampling users can conduct large model ensembles with small available disk space for example the archive method reduced disk space by a factor of nearly 650 times for the case study in section 3 reducing disk storage of an average simulation from about 53 mb to 82 kb 2 9 util the util module holds python functions that may be useful for scripting with prms python or analysis of hydro climatic data for example objective functions used for parameter optimization including the nash sutcliffe efficiency root mean squared error percent bias and the coefficient of determination are found in the util module similarly we developed python functions to calculate empirical cumulative distribution functions cdfs and the kolomogorov smirnov statistic kolmogorov 1933 smirnov 1939 for the case study in section 3 and placed them in the util module included in util are two functions to access the statistical variable prms output file and the input data file which return date indexed pandas dataframe objects also included in util are two functions that help users recursively delete files one of which removes all directories and contents from optimizer routines that are not of a certain optimization stage 2 10 future work and extensions future versions of prms python includes adding important functionality to existing tools and development of distinct data structures and computational routines for example regarding parameter optimization a wider selection of optimization routines and objective functions can readily be employed either from scratch or using existing python libraries e g houska et al 2015 herman and usher 2017 new optimization routines will follow a similar template as the monte carlo routine of the optimzationresult class in order to facilitate post processing using metadata json files also the concept behind the scenario and scenarioseries will be extended to include climatic data modifications a change log for version history of prms python is available on github and any changes that affect previous versions are done in a backwards compatible manner following pep 8 guidelines new functionality that is under development includes the creation of an animation class which will contain tools for creating video animations of prms 2 dimensional spatial output through time similarly the concept behind the data and parameters classes will be extended to the prms control file further work is broad and will depend on research activity and feedback contributions from the wider hydrologic modeling community 2 11 documentation and contributions an online documentation website hosted by github http prms python github io prms python includes information on installation example workflows and a detailed reference api for most classes and functions the reference api utilizes the sphinx documentation engine and follows the google style docstrings i e the comments within the source code are formatted in a markdown language that is human readable jupyter notebooks included with the prms python package give in depth explanations and example workflows for most prms python components the getting started notebook reiterates important file naming conventions and formatting rules required by prms python two notebooks show how to use the data and parameter objects for custom workflows and visualizations another gives a detailed example of a scenarioseries workflow that directly modifies two related parameters over a uniform grid and shows the resulting model accuracy over 2 dimensional parameter space three other notebooks give detailed overview of the optimizer resample and optimizer monte carlo method and the optimizer optimizationresult object including the resampling techniques the json metadata files that are produced how to setup and run a monte carlo parameter routine and a template for the global sensitivity analysis we demonstrate in section 3 community feedback and contributions to prms python are strongly encouraged and will be acknowledged in future releases direct involvement and contributions are possible through github by either raising issues or directly contributing modifying source code and creating a pull request through github alternatively for those who have created their own python scripts classes or functions we suggest consolidating and exposing your work alongside the prms python library this is possible by creating a github repository if one does not exist that can be pinned or linked to under the prms python organization on github https github com prms python 3 case study global sensitivity analysis prms has multiple physical modules available to estimate different hydro climatic fluxes we choose as a case study to apply the prms python framework by conducting a sensitivity analysis sa on parameters of the modified degree day solar radiation routine ddsolrad in prms markstrom et al 2015 this was partially chosen because it highlights multiple uses of the prms python framework and also because solar radiation is a top level variable that influences many hydrologic processes the degree day module in prms is commonly used to estimate daily incoming shortwave solar radiation if measured solar radiation is missing the module utilizes monthly linear models that relate maximum monthly temperature to the fraction of actual to potential clear sky radiation using a coaxial relationship leaf and brink 1973 leavesley et al 1983 markstrom et al 2015 we test global sensitivity from eight parameters associated with the ddsolrad module table 1 including monthly slopes and intercepts and parameters that reduce solar radiation on days with precipitation depending on the air temperature and season the prms model used for this case study is under development as part of a gsflow model for the snow dominated dry creek experimental watershed near boise idaho fig 2 this parameter sensitivity analysis case study gives valuable insight into the degree day method in prms by factor fixing and ranking each parameter s sensitivity during months with different climatic conditions and also by illustrating the relationships between parameters and simulated shortwave solar radiation it is uncommon that prms applications explore or calibrate many of the parameters associated with ddsolrad outside of the monthly slope and intercept such as those related to the adjustments of solar radiation due to precipitation 3 1 background and significance sensitivity analysis sa describes how model output is affected by changes in model input where input may include parameters variables or model structures put another way sa describes the robustness of model predictions to changes of particular input values or model components generally sa methods are used for a wide range of model diagnostics and procedures related to parameter calibration uncertainty analysis and hypothesis testing factor fixing is a common use of sa within hydrologic modeling it involves determining which model parameters are non influential on model outputs of interest and therefore not critical for calibration or uncertainty analysis sa is also used to rank multiple input factors based on their contribution to model uncertainty and mapping regions of model input to regions of model output e g see saltelli et al 2008 other important uses of sa in hydrologic modeling include hypothesis testing analysis of model structure e g parameter interactions and classification of hydrologic processes based on sensitive parameters e g across different landscapes and climates markstrom et al 2016 similarly there is a spectrum of sa methods that range in their robustness complexity and computational cost ranging from simple qualitative plots that consider single factors over a limited range to quantitative methods that consider multiple co varying inputs over their entire domain song et al 2015 pianosi et al 2016 unfortunately many hydrologic modeling research studies omit quantifiable sa in their reporting and the studies that do repost sa are typically perfunctory mostly limited to simple methods such as one at a time local methods shin et al 2013 possible explanations for the dearth of sa analysis and documentation in hydrologic modeling applications are challenges discussed in section 1 1 including computational challenges this case study demonstrates how frameworks like prms python can reduce computational burdens and encourage advanced scientific model analysis in this case we demonstrate a global moment independent sa on multiple parameters used in a solar radiation model similar analysis aimed at evaluating the relationships and performance of model parameters climatic inputs and model structures e g different flux parameterizations is an important avenue for advancing fundamental hydrologic research clark et al 2011a b an example of the lack of comprehensive sa is the prms model itself a literature search and review of research papers on the web of science and science direct research databases using the keywords precipitation runoff modeling system and sensitivity analysis found roughly six papers that include some form of sa applied to the prms model five papers utilized simple one at a time methods and only two of the papers conducted sa on prms parameters the remaining four studies reported sa on climate input to answer climate impact related scenarios e g huang et al 2012 feng et al 2018 one of the papers reported basic quantitative sa on a lumped consideration of two prms parameters that determine soil water holding capacity hassan et al 2014 another paper indeed conducted robust global sa for 35 prms parameters on multiple model processes using a popular variance based sa method markstrom et al 2016 it is also worth noting that two other documents which were not found in the research databases however they included quantitative prms parameter sensitivity analysis 1 a paper that laid the groundwork for understanding prms parameter uncertainty for the original prms model troutman 1985 which is out of date the recent prms model releases have completely overhauled parameterizations 2 a usgs scientific report ely 2006 that employed a derivative based sa method for select prms parameters on groundwater recharge to our knowledge there are two research documents that clearly highlight prms parameter sensitivity ely 2006 markstrom et al 2016 therefore it is likely that much more is to be known about the prms model s structure and function that could be achieved through parameter sa 3 2 methods the method of sa chosen for this case study is a global moment independent method called pawn named after the authors pianosi and wagener 2015 a review of sa methods including their scope of applicability limitations and methods of application are found in song et al 2015 and pianosi et al 2016 global versus local simply refers to whether or not the model output of interest is tested for sensitivity on the entire domain versus a subset of the input domain for example in calculating global parameter sensitivity a parameter would be randomly or systematically assigned values over its entire defined or allowable range while also considering values of other parameters over their entire range which may interact with the given parameter moment independent refers to sa methods that do not attribute model uncertainty to any moment of the output probability density function pdf e g mean or variance for example the more common variance based sa methods measure changes in the variance second moment of the output pdf and attribute the output variance to model uncertainty saltelli et al 2010 kucherenko et al 2012 as such variance based approaches have been shown to not be robust in cases where the shape of the output pdfs are highly skewed borgonovo et al 2011 the pawn method falls into the subcategory of density based sa methods most density based sa methods require a single model output or statistic e g mean area weighted soil moisture as a function of model inputs i e y f x to estimate their sensitivity on next a set of model inputs that may lead to uncertainty in y are defined as x i where i 1 2 3 m in practice x i input parameters are then resampled over a range or from a distribution that is related to x i e g bootstrapping to create an empirical pdf of y first for each input parameter x i the conditional pdf f y x i is estimated where input parameter x i is left unchanged and all others are randomly sampled next the empirical unconditional pdf of y f y is estimated where all input parameters are sampled at the same time the main concept of density based sa for output y on input x i is the measure of divergence or distance between the unconditional pdf f y and the conditional pdf f y x i where one input parameter x i is fixed at a conditional value specifically 1 s i stat x i divergence f y f y x i x i where s i is a sensitivity index for model input x i stat refers to a statistic such as the median of s i when s i is calculated using more than one conditioning value for x i which is necessary for global sa density based sa methods that do not resample e g bootstrap values of the conditioning value s x i in f y x i are by definition local in scope and therefore would not require a statistic to be calculated on the divergence values similarly if f y and f y x i do not include the entire parameter space of x i where i 1 2 3 m input parameters then s i is not a global sensitivity measure divergence refers to some estimate of divergence or distance between f y and f y x i to measure divergence pawn uses the kolmogorov smirnov statistic kolmogorov 1933 smirnov 1939 2 k s x i max y f y y f y x i y where f y y is the unconditional empirical cumulative distribution function cdf of y and f y x i y is the conditional empirical cdf where x i is fixed at a conditioning value fig 3 gives a visual explanation of the kolmogorov smirnov statistic the use of the kolmogorov smirnov statistic which uses the cdfs of the output distribution as opposed to the pdfs to measure the divergence in equation 1 is the major distinguishing component of pawn from other density based sa methods in theory it takes less model simulations and is thus computationally less expensive to compute empirical cdfs than corresponding pdfs because k s x i is calculated for a constant or conditioning value s of x i the method requires resampling of x i and computation of multiple values of k s x i in order to estimate the global sensitivity of y for the input x i therefore the final measure of sensitivity for model input x i on y is defined as 3 t i stat x i k s x i where stat could be any statistic such as median or max when calculating k s x i the two cdfs are subtracting along the vertical axes therefore the resulting index is between 0 and 1 making it relatively easy to interpret in this implementation of pawn the conditioning values of x i are resampled from a uniform distribution that covers the parameter s possible range as defined in markstrom et al 2015 and shown in table 1 the number n c determines how many times x i is held constant at a random conditioning value while all other input parameters are varied to build multiple conditional cdfs f y x i y to build each conditional cdf the number of times all other parameters are resampled n is chosen the number of parameter resamples to produce the unconditional cdf f y y is defined as n u and should be substantially larger than n both n and n u need to increase with an increase in m however the authors of pawn suggest that the number of model implementations needed for convergence are less than other density based sa methods that utilize the pdfs of y as opposed to the cdfs this experimental setup used n 1 024 n u 8 192 and n c 51 for a total of n u n n c m 425 984 prms simulations we increased n u until f y y converged as shown in section 3 3 for factor fixing i e determining which parameters are influential versus non influential on a particular model output the kolmogorov smirnov test is used the null hypothesis of the two tailed test states that there is no difference between the unconditional and conditional cdfs f y y and f y x i y we can reject the null hypothesis for input x i if 4 k s x i c α n u n c n u n c where c α is the critical value for a specific significance level α we used an α 0 05 significance level i e 95 confidence for the two tailed test and referencing table a ix in wall 1996 gives a critical value of c α 0 05 1 36 as suggested by pianosi and wagener 2015 we should only reject the null hypothesis if all of the k s x i values fall below the critical value for a given input parameter for this case study we apply pawn to eight parameters used to estimate daily solar radiation in prms within the ddsolrad module each parameter including its lower and upper limits for uniform resampling are found in table 1 each simulation used in this sa was conducted on five years 2008 2012 of measured climate input daily min and max air temperature and total precipitation as forcing data shorter simulation periods would potentially reduce the significance of results particularly the uncertainty caused by parameters that relate to precipitation adjustments of solar radiation are only utilized in the modified degree day method when there is precipitation because some critical parameters in the degree day solar radiation method vary monthly i e d d a y i n t c p d d a y s l o p e p p t r a d a d j and t m a x i n d e x we defined simulated monthly mean solar radiation at a particular hydrologic response unit hru where solar radiation has been measured daily as y as a result we have 12 monthly output variables to estimate uncertainty caused by eight model parameters to better interpret results we focus on two months of highest and lowest precipitation namely march and july referred to as y 1 and y 2 which had a total of roughly 28 and 1 5 inches of precipitation respectively therefore y 1 represents mean solar radiation for cold and wet conditions and y 2 represents mean solar radiation in warm and dry conditions precipitation air temperature and solar radiation have been measured at the bogus basin snotel weather station over the five years used in each model simulation fig 2 using prms python objects particularly the optimizer monte carlo method it is straightforward to script pawn in python here is an abbreviated pseudo code for pawn omitting the assignment of initial file and directory paths image 1 the pseudo code example above consists of only nine lines of intuitive code producing all the necessary output for pawn or similar density based sa methods a jupyter notebook contains a template for the actual workflow used in this case study and is available on hydroshare volk 2018 other code not shown above are mainly related to defining and initializing inputs all prms simulations required for pawn 425 984 were ran on the grid high performance computing cluster at the university of nevada reno the same analysis was also successfully tested on four personal computers with linux and windows operating systems each with varying numbers of physical and logical cores available to parallelize prms 3 3 results and discussion the convergence of the unconditional cdf f y y and sensitivity indices t i were determined visually and quantitatively by computing them with increasing values of n u and n c the initial value of n u 8 192 turned out to be considerably higher than needed for convergence of the unconditional cdfs f y y for march and july mean solar radiation y 1 and y 2 respectively see fig 4 calculating the max absolute difference similar to the kolmogorov smirnov statistic of f y y as estimated with increasing n u we found that the largest difference in probability between f y y calculated with n u 4 000 and n u 8 000 was only 0 004 and 0 005 for y 1 and y 2 respectively therefore we had confidence that the empirical unconditional cdfs were representative total sensitivity indices t i for each input parameter were estimated for y 1 and y 2 as the median of each kolmogorov smirnov statistic for all 51 empirical conditional cdfs divergence from their respective unconditional cdf table 2 the degree day intercept and slope are clearly the most influential parameters in both cold and wet months and warm and dry months the next three parameters t m a x i n d e x p p t r a d a d j and r a d j w p p t were more influential than the remaining parameters particularly for wet months y 1 by roughly a factor of two with α 0 05 the critical value for the kolmogorov smirnov test is 0 045 median values of k s x i for several parameters lie below the critical value particularly in warm and dry months median p p t r a d a d j and r a d j w p p t were below the critical value during dry months and r a d a d j i n t c p r a d j s p p t and r a d a d j s l o p e for both wet and dry months table 2 from visual inspection it is clear that n c 51 using the uniform distribution over parameter ranges was adequate to create conditioning values x i for each parameter that span their entire range e g fig 5 results also suggest different parameter output relationships between the two output variables y 1 and y 2 across the range of conditioning values particularly for d d a y i n t c p and d d a y s l o p e and to a lesser but visible extent t m a x i n d e x and p p t r a d a d j fig 5 besides d d a y i n t c p which has a sigmoidal relationship with y 1 2 and d d a y s l o p e which has a positive linear relationship other parameters that show some clear relation to y include p p t r a d a d j and r a d j w p p t which have a positive linear relationship with small slope to y 1 but no clear relationship with y 2 also t m a x i n d e x has a step like relation to y 1 where y 1 steps down as t m a x i n d e x exceeds 35 f fig 5 this makes sense because t m a x i n d e x is a temperature index or threshold used to determine when to apply precipitation adjustments to solar radiation and in march y 1 precipitation may occur when temperatures are near 35 f we expect that in warmer or cooler climates the relationship between t m a x i n d e x and shortwave radiation would vary depending on the temperature that typically coincides with precipitation events evidence of this is also seen in t m a x i n d e x versus the kolmogorov smirnov sensitivity for warm and dry months y 2 where t m a x i n d e x produces more uncertainty in y 2 when set 70 f fig 6 generally three secondary parameters p p t r a d a d j r a d j w p p t and t m a x i n d e x are more influential on the prediction of shortwave solar radiation in cold and wet months than in warm and dry on the other hand d d a y i n t c p and d d a y s l o p e have stronger positive relationships to solar radiation in warm and dry months than their cold and wet counterparts the expected compensating interaction between the degree day intercept and slope is clearly shown as the kolmogorov smirnov statistic for both increases at low and high conditioning values fig 6 however the intercept is clearly more influential and responsible for the most uncertainty in the model perhaps due to its larger range of possible values i e x i 60 20 versus 0 2 0 9 for the slope other nuances in parameter sensitivities can be seen in p p t r a d a d j r a d j w p p t and t m a x i n d e x these parameters are associated with reducing solar radiation when precipitation exceeds a certain monthly quantity as set by p p t r a d a d j on the other hand r a d a d j i n t c p and r a d a d j s l o p e were generally non influential parameters which are responsible for further in addition to d d a y i n t c p and d d a y s l o p e adjustment of solar radiation based on air temperature further analysis and comparisons with measured climatic data would help to advance the knowledge of the modified degree day parameterization in prms for example it is unclear from this case study aimed only at parameter sensitivity as to the model s relative accuracy under different climates in particular the degree day model s assumptions about the relationship between cloud cover and precipitation events may lead to substantial error in regions that are often cloudy but have low precipitation as mentioned in the prms manual markstrom et al 2015 the method was initially developed for the rocky mountains region where cloud cover usually coincides with precipitation and days without precipitation commonly exhibit clear skies implementing pawn global sa on multiple prms parameters was straightforward using prms python objects computationally the pawn global sa was not overly expensive it took roughly 4 days to run all 425 984 simulations using 256 2 6 ghz processors visual inspection also suggests that we may have overestimated the number of bootstraps necessary to build different conditional cdfs n c 51 and may have achieved a similar result with perhaps n c 30 generalizing computational expense is difficult as it is also subject to the resolution specifically the number of active hrus of the prms model and other factors such as the length of the simulation and physical modules used the prms model used here has 72 092 hrus the optimizationresult archive method in prms python greatly reduces the disk storage required making pawn and other related model analyses that utilize monte carlo random sampling easily accessible using machines with limited disk space available such as a laptop another approach we used to avoid disk space issues when testing on personal machines is to divide the total number of simulations needed into chunks and run multiple monte carlo routines on each chunk archiving the result before moving onto the next all together the input and output needed for pawn which utilized 425 984 prms simulations was reduced from 23 tb to 50 gb of disk storage by using the prms python optimizationresult archive method 4 summary we developed prms python as an intuitive python framework to enhance modeling applications and their reproducibility involving the prms watershed model by giving access to prms data structures and offering well thought functionality prms python greatly reduces the pre and post processing necessary to conduct advanced scientific applications automatically generated metadata of modeling scenarios conducted with prms python along with its dependence on python scripting encourages documentation and sharing of model applications with the greater scientific community while enabling reproducibility as an open source software we encourage the hydrologic modeling community to use prms python contribute and to integrate it into larger software projects the global parameter sensitivity analysis case study demonstrated here shows the potential of prms python for facilitating advanced analyses that give new insight into model structures and parameterizations in prms along the same line of thought a number of well planned model based experiments that could potentially lead to advancements into fundamental hydrologic knowledge can be facilitated using the prms python framework acknowledgements this work was partially supported by the national science foundation under grant no iia 1329469 we thank dr justin huntington of the desert research institute for allowing us to use his prms model for the global sensitivity analysis case study we would like to thank the information technology department at the university of nevada reno for computing time on the high performance computing cluster we also thank dr scott tyler of the university of nevada reno for his useful comments and christine volk o d for her proofreading of this article appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 01 006 
26255,a persistent problem in numerical hydrologic modeling is tracking provenance or how particular data came to be with multiple modules available for individual flux parameterizations and over 100 parameters the precipitation runoff modeling system prms is a perfect example of why it is such a challenge to track the history of input and output of complex models we present a lightweight object oriented python framework with programmatic tools for management and visualization using prms as an example platform within this framework a modeler can write intuitive code for a myriad of basic or advanced applications the framework also includes methods that for example apply systematic or stochastic parameter modifications while simultaneously saving metadata on which parameters were varied and with what improvement in performance we include a case study that uses built in monte carlo parameter resampling for global sensitivity analysis of eight prms parameters related to estimation of shortwave solar radiation keywords python framework prms pawn parameter sensitivity software information name of software prms python developers john volk and matthew turner contact via github program language python requirements python2 7 or python3 4 windows mac os x or linux prms 3 or newer availability this software is open source bsd3 license and freely available since 2018 on github https github com prms python prms python it is also on the python package index https pypi org project prms python additional documentation an online documentation website is included at http prms python github io prms python jupyter notebooks with examples of basic and advanced workflows using prms python are included with the package 1 introduction application of distributed hydrologic models often requires knowledge of physical parameters throughout space and time as well as procedures for model development calibration and management and analysis of large datasets often these routines are opaque to the observer and tedious to the scientist hutton et al 2016 these challenges also unfortunately limit the applications of models such as sensitivity analysis and multiple hypotheses testing for example of different hydrologic flux parameterizations to enhance the reproducibility and efficiency of modeling applications we developed prms python an open source python package for the precipitation runoff modeling system prms leavesley et al 1983 markstrom et al 2015 unlike luca a graphical user interface application for step wise parameter calibration of prms hay and umemoto 2006 prms python has functionality to access prms data structures modify inputs visualize input and output and manage large model ensembles including a monte carlo parameter resampling routine management of large model ensembles includes multiple levels of self generating metadata that is useful for user management and sharing model data and procedures with the greater hydrologic research community e g on hydroshare tarboton et al 2014 if prms modelers conduct modeling workflows and analysis using prms python and utilize its self documenting metadata the challenge of reproducibility of numerical experiments can be overcome saraswat et al 2015 hutton et al 2016 the objects within prms python integrate with common scientific libraries in python and can be combined in myriad ways to conduct advanced modeling analyses our modular approach facilitates future scientific work and new software extensions both by us and we hope by others 1 1 challenges in spatially distributed hydrologic modeling the development and application of spatially distributed hydrologic models is complex involving multiple steps e g data cleaning model grid or domain development parameter estimation parameter calibration input and output management and analysis and visualization of results these steps are learned over time through hard work in addition to scientific competency in multiple domains spatially distributed hydrologic modeling applications present computational challenges that tend to limit the exploration of model features and applications mendoza et al 2015 for example the multitude of parameters in prms often with parameter to parameter interactions which need to be calibrated presents a major challenge even when applied to small watershed domains prms models may contain tens of thousands of hydrologic response units hrus each of which need to be assigned multiple parameter values commonly 30 model development and work flow challenges also arise when keeping track of inputs and outputs of many simulations e g climate change scenarios or parameter uncertainty analysis modification of model inputs and organization and analysis of inputs outputs are thus common challenges to most modeling applications which act to limit their reproducibility saraswat et al 2015 hutton et al 2016 further significant time is spent on data management related to model input and output contributing to increased potential for human error as well as taking away crucial time that could be dedicated towards scientific applications mendoza et al 2016 consequences may also include inadequate calibration and understanding of parameter uncertainty and unexplored model structures the latter is particularly relevant to the prms model which unlike some hydrologic models offers multiple parameterizations for estimating various climatic and hydrologic fluxes a unifying challenge in the field of hydrologic science has been to define individual theoretical laws that accurately represent particular physical processes at intermediate scales e g from hillslope to catchment scales with inherent spatial and temporal heterogeneity dooge 1986 as a result the subdiscipline of hydrologic numerical modeling has recently trended towards the evaluation of multiple flux parameterizations scientifically viewed as competing physical hypotheses for individual hydrologic fluxes by evaluating the effectiveness and limitations of competing parameterizations we can begin to reduce the large number of them and better classify them according to when where they are most and least appropriate this process also expands fundamental hydrologic knowledge this is the main concept behind the structure for unifying multiple modeling alternatives summa clark et al 2015a b which is a hydrologic model that allows for testing of multiple model decisions including different parameterizations of hydrologic fluxes model spatial discretizations and connectivity analogous to the concept behind summa is the prms model s modular system in which the user can choose several parameterizations for the estimation of individual hydrologic processes e g potential evapotranspiration this allows prms modelers to evaluate competing hypotheses of the underlying physics of the model clark et al 2011a b although this is seldom done in practice clark et al 2015a b analysis of competing hydrologic hypotheses using numerical models often requires large numbers of simulations and hierarchical frameworks of model modifications alongside field measurements the prms python framework alleviates many common challenges for the modeler and encourages advanced exploration of model parameters and flux hypotheses thus encouraging progress in fundamental hydrologic research 1 2 similar software applications that facilitate numerical models are common groundwater vistas gms and visual modflow are examples of proprietary user interface applications for modflow harbaugh et al 2000 the united states geological survey s usgs program for groundwater flow modeling these applications consist of a graphical user interface that is complex offering many features for data preprocessing model building parameter optimization uncertainty data management and post processing however they are proprietary and therefore in our opinion can be somewhat inflexible for certain scientific applications open source software for models like prms or modflow also exist they are typically geared for specific purposes such as model calibration or parameter uncertainty e g hay and umemoto 2006 doherty and hunt 2010 prms python is different as it is comprised of a set of python classes and functions which allow scripting of many common tasks involved with prms modeling prms python was developed with an emphasis on creating an intuitive interface between prms data structures and powerful open source well documented and well supported python scientific libraries perkel 2015 as a result prms python gives flexibility and control of prms that is limited only by the user s understanding of prms and python unlike flopy a similar python module for modflow bakker et al 2016 prms python has limited features for initial model building due to the large number of spatial parameters and optional modules in prms there is no clear and consistent set of physical data e g vegetation coverage and parameter estimation techniques for the wide range of potential prms applications mendoza et al 2016 therefore the initial development of a prms model needs to be conducted beforehand typically using a geographic information system gis the gsflow arcpy software enables creation of prms input files within a python environment gardner et al 2018 however prms python includes tools for modification and visualization of parameter and climate input data to aid the process of model input assignment and validation the flexibility of the prms python framework allows for workflows that are not explicitly written in prms python several recipes are included in the online documentation therefore components of prms python can be used to make simple scripts to conduct common scientific modeling applications or be used to develop additional software that interacts with prms for example a user with experience in spatial analysis in python e g using geopandas fiona shapely or other packages can integrate spatial analysis tools with prms python to estimate initial parameter sets for prms a potential alternative to traditional gis based approaches a key component of prms python functionality is loading prms text files into efficient memory based numpy arrays van der walt et al 2011 and pandas dataframes mckinney 2013 standard building blocks for advanced scientific computing and visualization in python oliphant 2007 1 3 design principles prms python is fundamentally an attempt to build abstract representations of both the foundational data structures of prms and the execution of the model itself these abstractions take the form of python classes that for example allow a user to get and set prms parameters as a numpy array van der walt et al 2011 like one would do with columns of a dataframe in the popular pandas library mckinney 2013 while we do use basic abstractions as building blocks to for example programmatically optimize model parameters these representations of prms data structures are useful in their own right and are designed for multiple uses because prms python allows for model input parameters and climatic forcing data as well as model output to be represented as numpy arrays and pandas dataframes many other tools from the python ecosystem can be used for example other numpy operations van der walt et al 2011 and visualization with matplotlib hunter 2007 this is the main reason for choosing python there is already a wealth of scientific and mathematical tools available in the language oliphant 2007 perkel 2015 in addition python occupies a niche where unlike java or c it is a perfect first language so future developers of prms python might include geoscience students who are new to programming perkel 2015 python is also a powerful object oriented language that is used by professional programmers the major components of prms python although flexible in their applications enforce standardization of prms simulation structure for example prms python simulations follow a strict file and directory naming and structure with only partial control given to the user these design choices were chosen for multiple reasons 1 to limit code complexity and potential for bugs and 2 to aid users so that they do not have to develop their own system a secondary benefit of this design is that a user community can share their workflows without running into compatibility issues between platforms and individual nuances in format saraswat et al 2015 hutton et al 2016 1 4 purpose and motivation we designed prms python as a lightweight object oriented python library for multiple model applications and workflows different modeling applications e g parameter calibration uncertainty analysis or climate impact experiments require many data handling management and visualization routines that vary on a case by case basis therefore we feel that a set of highly flexible tools in the form of carefully designed intuitive python objects and functions is an ideal software architecture for addressing multiple model independent prms applications additionally scripting of prms applications within the prms python framework results in reproducible numerical experiments the flexibility of model workflows and their reproducibility can be challenging when conducted with graphical user interface applications similarly the inherent connection between native prms data structures and python scientific data structures and routines is a substantial benefit of this approach an example case study in this paper demonstrates how the prms python framework can be used to conduct a global parameter sensitivity analysis a common modeling challenge however this is an arbitrary example of many potential uses of the prms python framework the structures in prms python build upon each other and can be combined in different ways e g some allow access to model inputs whereas others leverage these to conduct simulations where input is systematically modified and simulation inputs and outputs are tracked via metadata files ultimately this lightweight framework aims to facilitate scientific discovery and operational applications using the prms hydrologic model by giving the user intuitive and efficient control of model workflows and tools for data provenance and analysis 2 implementation 2 1 the precipitation runoff modeling system prms the spatially distributed watershed model prms is commonly used by hydrologists and water resource managers for predicting watershed hydrologic response to climate dynamics at multiple spatial and temporal scales e g hay et al 2011 markstrom et al 2016 maintained and updated by the usgs prms continues to be upgraded and improved markstrom et al 2015 for example the usgs has recently added new useful features including a dynamic parameter option regan and lafontaine 2017 furthermore the recent application of prms to the conterminous u s is considered the national hydrology model by the usgs markstrom et al 2016 with source code written in fortran and c prms was developed as a modular framework enabling the user to choose between multiple physical modules leavesley et al 1983 1996 markstrom et al 2015 most prms inputs and outputs are ascii files that follow simple yet strict formats prms requires inputs of daily climate forcing variables physical parameters that are dependent on the physical modules chosen and control parameters commonly used outputs include time series of simulated statistical variables e g stream discharge or soil moisture spatial output and water balance summary files 2 2 software overview prms python was developed and tested on linux and windows platforms the package is open source with a bsd 3 license and compatible with python 2 7 and python 3 4 dependencies are limited to common python modules and automatically handled when installing from the python package index using the python package installer pip the source code of prms python follows the guidelines suggested by the python enhancement proposal 8 or pep 8 e g class names backwards compatibility etc prms python is heavily object oriented resulting in a modular framework fig 1 we developed python classes to represent two input files of prms the data file which contains time series of climate variables that drive prms simulations and the parameter file which holds mostly physical model dimensions and parameters required by different process modules as a side note words herein that are italicized distinguish them as part of the prms model as opposed to part of prms python building on these primary data structures the simulation and simulationseries classes enforce basic and strict management and execution of single or multiple parallelized prms simulations in a python environment similarly the scenario and scenarioseries classes utilize the simulation and simulationseries and give the ability to modify input parameters of python simulations including more advanced post management of simulations via a metadata file the optimizer class is built on the simulationseries as well and offers routines for monte carlo parameter resampling prms python objects that execute the prms model i e simulation simulationseries scenario etc require a strict file naming convention for prms input files specifically the user must name his her prms control file as control the parameter file as parameters the data file as data and the statistical variable output file must be named statvar dat the optimizationresult class utilizes information from metadata file s that record critical information about a set of optimizations for a user defined optimization stage as described in hay et al 2006 stages or steps of calibration might include solar radiation potential evapotranspiration or multiple parameter sets that control surface and subsurface flow the optimizationresult class allows for multiple goodness of fit metrics to be calculated and used to rank optimization stage results it also includes a method to archive output from a given optimization stage greatly reducing disk storage when an optimization stage has produced large quantities of model output a module of utility functions util for miscellaneous tasks such as calculating goodness of fit metrics for model output is also included in prms python fig 1 the subsections below give more detailed descriptions of selected prms python classes that were custom built for this framework all python objects and functions in the prms python framework can be classified as custom development however they commonly transform data structures from the prms format to data structures of the numpy and pandas python libraries van der walt et al 2011 mckinney 2013 additional prms python functionality and data that is in development or otherwise not discussed in detail in this article include a cross platform command line interface cli for prms python a unit testing module and a full prms model for testing and experimenting with different prms python objects the prmspy executable gives access to prms python from the command line currently the cli offers a routine to scale pairs of prms parameters over a 2 dimensional grid run the associated simulations and produce pdf documents of the resulting goodness of fit as 2 dimensional matrix plots for an arbitrary number of parameter pairs unit tests were developed for major prms python classes using the python unittest package the tests are located in the test test prms python py module within prms python unit tests as well as other documentation examples described in subsection 2 11 utilize a functional not calibrated prms model that was developed for the lehman and baker creek watersheds in the great basin nv volk 2014 2 3 data the prms data input file contains date indexed climate variables that are used to force the hydrologic model it may also contain climate and hydrologic variables e g measured stream discharge that can be used for model evaluation the prms python data class loads the data file into python and has a class property data frame that converts the climatic forcing data to a date indexed pandas dataframe once loaded climate data can easily be adjusted and visualized in the dataframe format the modify method allows efficient function based modification of the time series hydro climatic data within the file a familiar example use is the modification of temperature forcing data to create synthetic warming scenarios a metadata property of the data class holds the hydro climatic variable names and other header data as found in the data file the data class has a write method which converts the pandas dataframe representation of the data file back to prms ascii text format if the climatic variables were accessed if not it simply copies the file for the sake of computational efficiency all information stored in a prms data is represented in two data properties metadata and data frame therefore it is possible to build a new data file using a data instance that was not initialized on a preexisting data file for example climatic data from a comma separated value file could be loaded with pandas and applied to a data instance s data frame along with the appropriate metadata to create a new data file for prms 2 4 parameters physical dimensions and parameter values of prms models are stored in the prms parameter input file the parameters class enables efficient access to model parameters for modification and visualization the parameters class manages parameters metadata such as parameter name dimensions data types and length in a manner loosely similar to that of a netcdf file dimensions of the prms model and dimensions lengths names data type float integer etc for individual parameters are stored in the dimensions and base params attributes respectively parameter values are not loaded into memory until accessed by the user giving the parameter class higher memory efficiency which is particularly important for workflows with models that utilize high resolution spatial grids or when accessing multiple parameter files values of a given parameter can be accessed using the parameter name as a key multi dimensional parameters are returned as multi dimensional numpy ndarrays with the shape set by the prms dimensions for example the rain adj parameter will have the shape of nhru by nmonths modification of parameter values from a parameters instance can be conducted using numpy mathematical rules including computationally efficient vectorized application of mathematical operations the write method rewrites the parameter data back into the text format for a standard prms parameter file a robust parameter plotting method plot is capable of plotting most prms physical parameters depending on their dimensions specifically single valued parameters are printed to an html table series are plotted as line plots whereas spatial parameters are plotted as images on a uniform grid three multi paged pdf documents containing plots can be quickly printed for all parameters for inspection one parameter per page including an additional html table with single valued parameter information specifics can be found in the online documentation and example jupyter notebooks 2 5 simulation and simulationseries the simulation and simulationseries classes are the most fundamental prms python implementations that manage and execute single and multiple prms simulations respectively the simulation object manages a single prms simulation its constructor takes the directory that contains prms input files and a simulation directory that will contain the simulation inputs and outputs as keyword arguments the simulation constructor creates the simulation directory if it does not exist and creates two subdirectories inputs that will contain a copy of the simulations input files and outputs for output files the simulation run method executes the model and copies output files to the outputs subdirectory under the simulation directory the class method from data of the simulation class allows a simulation object to be initialized from prms python data and parameter objects along with a path to a control file as opposed to the standard simulation initialization from a directory path that contains all input files this class method gives the user flexibility if required in the naming conventions the simulationseries class constructor takes a list of simulation objects and runs each optionally in parallel returning a dictionary that includes paths to each simulation s directory parameter file data file and statistical variable output file simulation and simulationseries objects enable no or limited tracking of simulation metadata and are designed as building blocks for more advanced programs or workflows as done within the scenario scenarioseries and optimizer classes that are discussed below 2 6 scenario and scenarioseries slightly higher level than the simulation and simulationseries the scenario and scenarioseries classes offer the user custom modification and tracking of simulation s via a build method and metadata files metadata includes titles descriptions and timing information that relate to scenarios where the user is systematically modifying the parameters of an existing prms model for example a scenario may include altering the vegetation coverage over a given area to simulate hydrologic implications of different foresting techniques or changes in land cover the scenario and scenarioseries both operate on a 3 step process initialization building and running after initialization the build method creates the simulation directory structure following the procedure from the simulation class and also applies modifications to parameters based on a keyword argument mod funs dict the mod funs dict is a user defined python dictionary that holds prms parameter names as keys and python functions to apply to the stated parameters as values calling build applies these modifications to the original parameters and makes a copy of the new parameters this is a highly flexible mechanism for adjusting parameter values in deterministic or stochastic ways that is easily documented functions given to the mapping dictionary mod funs dict are stored as text representations of the original python functions along with the scenario title description and simulation start and end date time stamps are saved to a json metadata file in the parent scenario directory analogous to the simulation directory of the simulation class after calling the run method of the scenario instance the scenarioseries class in general manages and executes multiple scenario objects in parallel the scenarioseries is initialized in a similar manner as scenario it requires the directory of prms input files the output directory and optionally a title and description that describe the entire group of scenarios next the scenarioseries like scenario has a build method that instead takes a list of python dictionaries as an argument scenarios list each dictionary has the same entries as available to an individual scenario object a scenario title description and arbitrary number of parameter names keys with corresponding python functions values to modify them by the metadata created from a scenarioseries differs from scenario it retains the same type of metadata file for each individual scenario and also includes a master metadata file series metadata json that is stored in the parent directory of all scenarios the master metadata file includes the use of universal unique identifiers uuid for each scenario individual prms simulation that map to each scenario title the uuids are used as subdirectory names under the scenario directory given upon initialization and each contains the inputs and outputs of each simulation according to the file structure set by the simulation class therefore the master metadata file can be used to map between the metadata given in the scenarios list dictionary and the directories of each scenario in the scenarioseries otherwise the individual metadata files for each scenario can be used the uuid s are used because they ensure no two scenario directories will be identical and it relieves the need for the user to imagine perhaps arbitrary names for a large number of directories similar to simulationseries the scenarioseries has a class method from parameters iter that allows initialization from a list of modification dictionaries that are normally passed in the build method a full example use of the scenarioseries class is included in the prms python documentation the example involves systematically scaling values for two parameters that determine solar radiation and potential evapotranspiration specifically the two parameters are scaled from 0 7 to 1 0 factors of their initially estimated values with grid increments of 0 1 resulting in a uniform 2 dimensional grid of parameter space after building and running the scenarioseries the metadata that maps uuid s to individual parameter modifications for each simulation is used to load results and visualize the goodness of fit for each parameter combination 2 7 optimizer the optimizer class is designed to hold routines or fundamental components of numerical methods for parameter sensitivity uncertainty analysis and optimization for example the use of probability distribution functions to sample random variables for parameter values is useful for a number of methods of model sensitivity and uncertainty analysis currently the monte carlo method is available which offers two probability distributions normal and uniform for parameter resampling that can be applied on an arbitrary parameter set i e optimization stage defined by the user the stochastic parameter resampling as offered by the optimizer class is available as a stand alone function optimizer resample or if using the monte carlo method as part of an automatic workflow that applies the resampling to an arbitrary set of parameters for an arbitrary number of samples and runs the corresponding prms simulations while tracking and generating metadata due to the large spectrum of analysis methods that use stochastic resampling procedures we choose to keep this method as a fundamental routine as opposed to an automatic parameter optimization or sensitivity uncertainty analysis routine this design choices give the user more control and ability to use the tool as a building block for a variety of parameter output analyses an example is shown in the case study section 3 1 that demonstrates a global moment independent sensitivity analysis of eight parameters related to the estimation of solar radiation the monte carlo method described here is customized for prms python however other sensitivity analysis and parameter optimization routines already exist in python e g salib and spotpy and can readily be connected with a prms model via the prms python framework houska et al 2015 herman and usher 2017 the parameter resampling method has specific rules that depend on the parameter dimension that are laid out in the documentation e g spatial parameters are resampled all at once as opposed to single or monthly parameters which are independently resampled ranges for parameter values e g according to markstrom et al 2015 must be set in the param ranges attribute of the optimizer class and can be manually adjusted if for example a user wants to resample from a subset of the parameter space using the uniform distribution the normal distribution resampling method does not simply sample from a random normal variable instead it is designed to shift the mean and variance of an existing parameter however application of bootstrap resampling directly from a random variable is straightforward using a parameters or scenario instance along with probability distribution functions provided by numpy the normal resampling method uses two keyword arguments mu factor and noise factor which for example when applied to spatial parameters scale values of the initial parameter set and defines the standard deviation of a normal random variable to add to the scaled initial parameter values for example if mu factor is set to 1 and noise factor set to 0 1 then the initial parameter values will not be scaled but a normal random variable with standard deviation 0 1 parameter allowable range will be added to the initial parameter more details and examples on the resampling rules can be found in the monte carlo parameter resampling jupyter notebook that is packaged with prms python to initialize an optimizer object and run the monte carlo method required arguments include similar arguments of the simulation class but importantly also require a list of parameter s to resample an optimization stage name and a path to a date indexed csv file that contains measured data that corresponds with the optimization stage e g measured solar radiation or stream discharge the monte carlo method also requires the statistical output variable from prms that is being optimized i e the hydrologic state variable that corresponds with the measured data for calculations of goodness of fit other useful arguments for the monte carlo method and optimizer include title description resampling method number of processors available for parallelizing prms etc metadata for monte carlo simulations are sent to a json file examples of information included in the metadata file include names of parameters adjusted optimization stage e g stream discharge the resampling method the file paths of initial and adjusted parameter files and model output runtime number of processors used and user descriptions after an optimization method e g monte carlo is run the optimizer instance will gain new attributes 1 an output list containing simulation results and metadata from the simulations and 2 a date indexed pandas series of the measured data that the parameter optimization is being conducted on e g stream discharge with multiple executions of an optimizer method on the same optimizer instance the output attribute is extended to contain the additional paths to model input and output files a plot method enables basic time series daily and monthly mean and scatter plots of the current optimizer outputs included in the time series plots daily or monthly means are the results of the current optimization simulation the measured data and results from the simulation that utilized the original parameter set 2 8 optimizationresult managing results from large simulation ensembles is critical the optimizationresult class allows for retrieving parsing and archiving the potentially large number of input and output associated with previously conducted optimizer methods on initialization the optimizationresult instance gathers metadata from json file s which were produced from optimization methods sets of simulations are tracked together via a single user defined calibration or optimization stage that is a name typically referring to simulations where the same set of prms parameters were modified or corresponding to a specific hydrologic process or prms module e g evapotranspiration therefore an optimizationresult instance operates on a single optimization stage once initialized the optimizationresult instance gains useful attributes such as the number of total simulations that were conducted for the given stage and paths to the measured data that was used for the stage currently four objective functions are available in the optimizationresult class to aid the process of ranking parameter optimizations namely the nash sutcliffe efficiency nse root mean squared error rmse percent bias pbias and the coefficient of determination coef det the result table method summarizes the top n simulations ranked using the four objective functions on measured and simulated data including results of the simulation that used the initial parameter set the input parameters to the optimizer object to map model performance between simulated and measured data the get top ranked sims method takes an optimizationresult result table and returns a dictionary with lists of input and output paths of each simulation as keys in the same order found in result table the archive method of the optimizationresult class greatly reduces the size of data that is saved to disk by prms simulations that were created via an optimizer routine while retaining important information specifically the archive method operates on an individual optimization stage by archiving each simulation s modified parameter values and how they were modified as well as each simulation s relevant output paths to original input files and other metadata as with other methods of prms python the archived results are saved to json files in an archived subdirectory by default the archive method deletes the original simulation directories and model input and output files by using the archive method in tandem with an optimizer routine such as monte carlo parameter resampling users can conduct large model ensembles with small available disk space for example the archive method reduced disk space by a factor of nearly 650 times for the case study in section 3 reducing disk storage of an average simulation from about 53 mb to 82 kb 2 9 util the util module holds python functions that may be useful for scripting with prms python or analysis of hydro climatic data for example objective functions used for parameter optimization including the nash sutcliffe efficiency root mean squared error percent bias and the coefficient of determination are found in the util module similarly we developed python functions to calculate empirical cumulative distribution functions cdfs and the kolomogorov smirnov statistic kolmogorov 1933 smirnov 1939 for the case study in section 3 and placed them in the util module included in util are two functions to access the statistical variable prms output file and the input data file which return date indexed pandas dataframe objects also included in util are two functions that help users recursively delete files one of which removes all directories and contents from optimizer routines that are not of a certain optimization stage 2 10 future work and extensions future versions of prms python includes adding important functionality to existing tools and development of distinct data structures and computational routines for example regarding parameter optimization a wider selection of optimization routines and objective functions can readily be employed either from scratch or using existing python libraries e g houska et al 2015 herman and usher 2017 new optimization routines will follow a similar template as the monte carlo routine of the optimzationresult class in order to facilitate post processing using metadata json files also the concept behind the scenario and scenarioseries will be extended to include climatic data modifications a change log for version history of prms python is available on github and any changes that affect previous versions are done in a backwards compatible manner following pep 8 guidelines new functionality that is under development includes the creation of an animation class which will contain tools for creating video animations of prms 2 dimensional spatial output through time similarly the concept behind the data and parameters classes will be extended to the prms control file further work is broad and will depend on research activity and feedback contributions from the wider hydrologic modeling community 2 11 documentation and contributions an online documentation website hosted by github http prms python github io prms python includes information on installation example workflows and a detailed reference api for most classes and functions the reference api utilizes the sphinx documentation engine and follows the google style docstrings i e the comments within the source code are formatted in a markdown language that is human readable jupyter notebooks included with the prms python package give in depth explanations and example workflows for most prms python components the getting started notebook reiterates important file naming conventions and formatting rules required by prms python two notebooks show how to use the data and parameter objects for custom workflows and visualizations another gives a detailed example of a scenarioseries workflow that directly modifies two related parameters over a uniform grid and shows the resulting model accuracy over 2 dimensional parameter space three other notebooks give detailed overview of the optimizer resample and optimizer monte carlo method and the optimizer optimizationresult object including the resampling techniques the json metadata files that are produced how to setup and run a monte carlo parameter routine and a template for the global sensitivity analysis we demonstrate in section 3 community feedback and contributions to prms python are strongly encouraged and will be acknowledged in future releases direct involvement and contributions are possible through github by either raising issues or directly contributing modifying source code and creating a pull request through github alternatively for those who have created their own python scripts classes or functions we suggest consolidating and exposing your work alongside the prms python library this is possible by creating a github repository if one does not exist that can be pinned or linked to under the prms python organization on github https github com prms python 3 case study global sensitivity analysis prms has multiple physical modules available to estimate different hydro climatic fluxes we choose as a case study to apply the prms python framework by conducting a sensitivity analysis sa on parameters of the modified degree day solar radiation routine ddsolrad in prms markstrom et al 2015 this was partially chosen because it highlights multiple uses of the prms python framework and also because solar radiation is a top level variable that influences many hydrologic processes the degree day module in prms is commonly used to estimate daily incoming shortwave solar radiation if measured solar radiation is missing the module utilizes monthly linear models that relate maximum monthly temperature to the fraction of actual to potential clear sky radiation using a coaxial relationship leaf and brink 1973 leavesley et al 1983 markstrom et al 2015 we test global sensitivity from eight parameters associated with the ddsolrad module table 1 including monthly slopes and intercepts and parameters that reduce solar radiation on days with precipitation depending on the air temperature and season the prms model used for this case study is under development as part of a gsflow model for the snow dominated dry creek experimental watershed near boise idaho fig 2 this parameter sensitivity analysis case study gives valuable insight into the degree day method in prms by factor fixing and ranking each parameter s sensitivity during months with different climatic conditions and also by illustrating the relationships between parameters and simulated shortwave solar radiation it is uncommon that prms applications explore or calibrate many of the parameters associated with ddsolrad outside of the monthly slope and intercept such as those related to the adjustments of solar radiation due to precipitation 3 1 background and significance sensitivity analysis sa describes how model output is affected by changes in model input where input may include parameters variables or model structures put another way sa describes the robustness of model predictions to changes of particular input values or model components generally sa methods are used for a wide range of model diagnostics and procedures related to parameter calibration uncertainty analysis and hypothesis testing factor fixing is a common use of sa within hydrologic modeling it involves determining which model parameters are non influential on model outputs of interest and therefore not critical for calibration or uncertainty analysis sa is also used to rank multiple input factors based on their contribution to model uncertainty and mapping regions of model input to regions of model output e g see saltelli et al 2008 other important uses of sa in hydrologic modeling include hypothesis testing analysis of model structure e g parameter interactions and classification of hydrologic processes based on sensitive parameters e g across different landscapes and climates markstrom et al 2016 similarly there is a spectrum of sa methods that range in their robustness complexity and computational cost ranging from simple qualitative plots that consider single factors over a limited range to quantitative methods that consider multiple co varying inputs over their entire domain song et al 2015 pianosi et al 2016 unfortunately many hydrologic modeling research studies omit quantifiable sa in their reporting and the studies that do repost sa are typically perfunctory mostly limited to simple methods such as one at a time local methods shin et al 2013 possible explanations for the dearth of sa analysis and documentation in hydrologic modeling applications are challenges discussed in section 1 1 including computational challenges this case study demonstrates how frameworks like prms python can reduce computational burdens and encourage advanced scientific model analysis in this case we demonstrate a global moment independent sa on multiple parameters used in a solar radiation model similar analysis aimed at evaluating the relationships and performance of model parameters climatic inputs and model structures e g different flux parameterizations is an important avenue for advancing fundamental hydrologic research clark et al 2011a b an example of the lack of comprehensive sa is the prms model itself a literature search and review of research papers on the web of science and science direct research databases using the keywords precipitation runoff modeling system and sensitivity analysis found roughly six papers that include some form of sa applied to the prms model five papers utilized simple one at a time methods and only two of the papers conducted sa on prms parameters the remaining four studies reported sa on climate input to answer climate impact related scenarios e g huang et al 2012 feng et al 2018 one of the papers reported basic quantitative sa on a lumped consideration of two prms parameters that determine soil water holding capacity hassan et al 2014 another paper indeed conducted robust global sa for 35 prms parameters on multiple model processes using a popular variance based sa method markstrom et al 2016 it is also worth noting that two other documents which were not found in the research databases however they included quantitative prms parameter sensitivity analysis 1 a paper that laid the groundwork for understanding prms parameter uncertainty for the original prms model troutman 1985 which is out of date the recent prms model releases have completely overhauled parameterizations 2 a usgs scientific report ely 2006 that employed a derivative based sa method for select prms parameters on groundwater recharge to our knowledge there are two research documents that clearly highlight prms parameter sensitivity ely 2006 markstrom et al 2016 therefore it is likely that much more is to be known about the prms model s structure and function that could be achieved through parameter sa 3 2 methods the method of sa chosen for this case study is a global moment independent method called pawn named after the authors pianosi and wagener 2015 a review of sa methods including their scope of applicability limitations and methods of application are found in song et al 2015 and pianosi et al 2016 global versus local simply refers to whether or not the model output of interest is tested for sensitivity on the entire domain versus a subset of the input domain for example in calculating global parameter sensitivity a parameter would be randomly or systematically assigned values over its entire defined or allowable range while also considering values of other parameters over their entire range which may interact with the given parameter moment independent refers to sa methods that do not attribute model uncertainty to any moment of the output probability density function pdf e g mean or variance for example the more common variance based sa methods measure changes in the variance second moment of the output pdf and attribute the output variance to model uncertainty saltelli et al 2010 kucherenko et al 2012 as such variance based approaches have been shown to not be robust in cases where the shape of the output pdfs are highly skewed borgonovo et al 2011 the pawn method falls into the subcategory of density based sa methods most density based sa methods require a single model output or statistic e g mean area weighted soil moisture as a function of model inputs i e y f x to estimate their sensitivity on next a set of model inputs that may lead to uncertainty in y are defined as x i where i 1 2 3 m in practice x i input parameters are then resampled over a range or from a distribution that is related to x i e g bootstrapping to create an empirical pdf of y first for each input parameter x i the conditional pdf f y x i is estimated where input parameter x i is left unchanged and all others are randomly sampled next the empirical unconditional pdf of y f y is estimated where all input parameters are sampled at the same time the main concept of density based sa for output y on input x i is the measure of divergence or distance between the unconditional pdf f y and the conditional pdf f y x i where one input parameter x i is fixed at a conditional value specifically 1 s i stat x i divergence f y f y x i x i where s i is a sensitivity index for model input x i stat refers to a statistic such as the median of s i when s i is calculated using more than one conditioning value for x i which is necessary for global sa density based sa methods that do not resample e g bootstrap values of the conditioning value s x i in f y x i are by definition local in scope and therefore would not require a statistic to be calculated on the divergence values similarly if f y and f y x i do not include the entire parameter space of x i where i 1 2 3 m input parameters then s i is not a global sensitivity measure divergence refers to some estimate of divergence or distance between f y and f y x i to measure divergence pawn uses the kolmogorov smirnov statistic kolmogorov 1933 smirnov 1939 2 k s x i max y f y y f y x i y where f y y is the unconditional empirical cumulative distribution function cdf of y and f y x i y is the conditional empirical cdf where x i is fixed at a conditioning value fig 3 gives a visual explanation of the kolmogorov smirnov statistic the use of the kolmogorov smirnov statistic which uses the cdfs of the output distribution as opposed to the pdfs to measure the divergence in equation 1 is the major distinguishing component of pawn from other density based sa methods in theory it takes less model simulations and is thus computationally less expensive to compute empirical cdfs than corresponding pdfs because k s x i is calculated for a constant or conditioning value s of x i the method requires resampling of x i and computation of multiple values of k s x i in order to estimate the global sensitivity of y for the input x i therefore the final measure of sensitivity for model input x i on y is defined as 3 t i stat x i k s x i where stat could be any statistic such as median or max when calculating k s x i the two cdfs are subtracting along the vertical axes therefore the resulting index is between 0 and 1 making it relatively easy to interpret in this implementation of pawn the conditioning values of x i are resampled from a uniform distribution that covers the parameter s possible range as defined in markstrom et al 2015 and shown in table 1 the number n c determines how many times x i is held constant at a random conditioning value while all other input parameters are varied to build multiple conditional cdfs f y x i y to build each conditional cdf the number of times all other parameters are resampled n is chosen the number of parameter resamples to produce the unconditional cdf f y y is defined as n u and should be substantially larger than n both n and n u need to increase with an increase in m however the authors of pawn suggest that the number of model implementations needed for convergence are less than other density based sa methods that utilize the pdfs of y as opposed to the cdfs this experimental setup used n 1 024 n u 8 192 and n c 51 for a total of n u n n c m 425 984 prms simulations we increased n u until f y y converged as shown in section 3 3 for factor fixing i e determining which parameters are influential versus non influential on a particular model output the kolmogorov smirnov test is used the null hypothesis of the two tailed test states that there is no difference between the unconditional and conditional cdfs f y y and f y x i y we can reject the null hypothesis for input x i if 4 k s x i c α n u n c n u n c where c α is the critical value for a specific significance level α we used an α 0 05 significance level i e 95 confidence for the two tailed test and referencing table a ix in wall 1996 gives a critical value of c α 0 05 1 36 as suggested by pianosi and wagener 2015 we should only reject the null hypothesis if all of the k s x i values fall below the critical value for a given input parameter for this case study we apply pawn to eight parameters used to estimate daily solar radiation in prms within the ddsolrad module each parameter including its lower and upper limits for uniform resampling are found in table 1 each simulation used in this sa was conducted on five years 2008 2012 of measured climate input daily min and max air temperature and total precipitation as forcing data shorter simulation periods would potentially reduce the significance of results particularly the uncertainty caused by parameters that relate to precipitation adjustments of solar radiation are only utilized in the modified degree day method when there is precipitation because some critical parameters in the degree day solar radiation method vary monthly i e d d a y i n t c p d d a y s l o p e p p t r a d a d j and t m a x i n d e x we defined simulated monthly mean solar radiation at a particular hydrologic response unit hru where solar radiation has been measured daily as y as a result we have 12 monthly output variables to estimate uncertainty caused by eight model parameters to better interpret results we focus on two months of highest and lowest precipitation namely march and july referred to as y 1 and y 2 which had a total of roughly 28 and 1 5 inches of precipitation respectively therefore y 1 represents mean solar radiation for cold and wet conditions and y 2 represents mean solar radiation in warm and dry conditions precipitation air temperature and solar radiation have been measured at the bogus basin snotel weather station over the five years used in each model simulation fig 2 using prms python objects particularly the optimizer monte carlo method it is straightforward to script pawn in python here is an abbreviated pseudo code for pawn omitting the assignment of initial file and directory paths image 1 the pseudo code example above consists of only nine lines of intuitive code producing all the necessary output for pawn or similar density based sa methods a jupyter notebook contains a template for the actual workflow used in this case study and is available on hydroshare volk 2018 other code not shown above are mainly related to defining and initializing inputs all prms simulations required for pawn 425 984 were ran on the grid high performance computing cluster at the university of nevada reno the same analysis was also successfully tested on four personal computers with linux and windows operating systems each with varying numbers of physical and logical cores available to parallelize prms 3 3 results and discussion the convergence of the unconditional cdf f y y and sensitivity indices t i were determined visually and quantitatively by computing them with increasing values of n u and n c the initial value of n u 8 192 turned out to be considerably higher than needed for convergence of the unconditional cdfs f y y for march and july mean solar radiation y 1 and y 2 respectively see fig 4 calculating the max absolute difference similar to the kolmogorov smirnov statistic of f y y as estimated with increasing n u we found that the largest difference in probability between f y y calculated with n u 4 000 and n u 8 000 was only 0 004 and 0 005 for y 1 and y 2 respectively therefore we had confidence that the empirical unconditional cdfs were representative total sensitivity indices t i for each input parameter were estimated for y 1 and y 2 as the median of each kolmogorov smirnov statistic for all 51 empirical conditional cdfs divergence from their respective unconditional cdf table 2 the degree day intercept and slope are clearly the most influential parameters in both cold and wet months and warm and dry months the next three parameters t m a x i n d e x p p t r a d a d j and r a d j w p p t were more influential than the remaining parameters particularly for wet months y 1 by roughly a factor of two with α 0 05 the critical value for the kolmogorov smirnov test is 0 045 median values of k s x i for several parameters lie below the critical value particularly in warm and dry months median p p t r a d a d j and r a d j w p p t were below the critical value during dry months and r a d a d j i n t c p r a d j s p p t and r a d a d j s l o p e for both wet and dry months table 2 from visual inspection it is clear that n c 51 using the uniform distribution over parameter ranges was adequate to create conditioning values x i for each parameter that span their entire range e g fig 5 results also suggest different parameter output relationships between the two output variables y 1 and y 2 across the range of conditioning values particularly for d d a y i n t c p and d d a y s l o p e and to a lesser but visible extent t m a x i n d e x and p p t r a d a d j fig 5 besides d d a y i n t c p which has a sigmoidal relationship with y 1 2 and d d a y s l o p e which has a positive linear relationship other parameters that show some clear relation to y include p p t r a d a d j and r a d j w p p t which have a positive linear relationship with small slope to y 1 but no clear relationship with y 2 also t m a x i n d e x has a step like relation to y 1 where y 1 steps down as t m a x i n d e x exceeds 35 f fig 5 this makes sense because t m a x i n d e x is a temperature index or threshold used to determine when to apply precipitation adjustments to solar radiation and in march y 1 precipitation may occur when temperatures are near 35 f we expect that in warmer or cooler climates the relationship between t m a x i n d e x and shortwave radiation would vary depending on the temperature that typically coincides with precipitation events evidence of this is also seen in t m a x i n d e x versus the kolmogorov smirnov sensitivity for warm and dry months y 2 where t m a x i n d e x produces more uncertainty in y 2 when set 70 f fig 6 generally three secondary parameters p p t r a d a d j r a d j w p p t and t m a x i n d e x are more influential on the prediction of shortwave solar radiation in cold and wet months than in warm and dry on the other hand d d a y i n t c p and d d a y s l o p e have stronger positive relationships to solar radiation in warm and dry months than their cold and wet counterparts the expected compensating interaction between the degree day intercept and slope is clearly shown as the kolmogorov smirnov statistic for both increases at low and high conditioning values fig 6 however the intercept is clearly more influential and responsible for the most uncertainty in the model perhaps due to its larger range of possible values i e x i 60 20 versus 0 2 0 9 for the slope other nuances in parameter sensitivities can be seen in p p t r a d a d j r a d j w p p t and t m a x i n d e x these parameters are associated with reducing solar radiation when precipitation exceeds a certain monthly quantity as set by p p t r a d a d j on the other hand r a d a d j i n t c p and r a d a d j s l o p e were generally non influential parameters which are responsible for further in addition to d d a y i n t c p and d d a y s l o p e adjustment of solar radiation based on air temperature further analysis and comparisons with measured climatic data would help to advance the knowledge of the modified degree day parameterization in prms for example it is unclear from this case study aimed only at parameter sensitivity as to the model s relative accuracy under different climates in particular the degree day model s assumptions about the relationship between cloud cover and precipitation events may lead to substantial error in regions that are often cloudy but have low precipitation as mentioned in the prms manual markstrom et al 2015 the method was initially developed for the rocky mountains region where cloud cover usually coincides with precipitation and days without precipitation commonly exhibit clear skies implementing pawn global sa on multiple prms parameters was straightforward using prms python objects computationally the pawn global sa was not overly expensive it took roughly 4 days to run all 425 984 simulations using 256 2 6 ghz processors visual inspection also suggests that we may have overestimated the number of bootstraps necessary to build different conditional cdfs n c 51 and may have achieved a similar result with perhaps n c 30 generalizing computational expense is difficult as it is also subject to the resolution specifically the number of active hrus of the prms model and other factors such as the length of the simulation and physical modules used the prms model used here has 72 092 hrus the optimizationresult archive method in prms python greatly reduces the disk storage required making pawn and other related model analyses that utilize monte carlo random sampling easily accessible using machines with limited disk space available such as a laptop another approach we used to avoid disk space issues when testing on personal machines is to divide the total number of simulations needed into chunks and run multiple monte carlo routines on each chunk archiving the result before moving onto the next all together the input and output needed for pawn which utilized 425 984 prms simulations was reduced from 23 tb to 50 gb of disk storage by using the prms python optimizationresult archive method 4 summary we developed prms python as an intuitive python framework to enhance modeling applications and their reproducibility involving the prms watershed model by giving access to prms data structures and offering well thought functionality prms python greatly reduces the pre and post processing necessary to conduct advanced scientific applications automatically generated metadata of modeling scenarios conducted with prms python along with its dependence on python scripting encourages documentation and sharing of model applications with the greater scientific community while enabling reproducibility as an open source software we encourage the hydrologic modeling community to use prms python contribute and to integrate it into larger software projects the global parameter sensitivity analysis case study demonstrated here shows the potential of prms python for facilitating advanced analyses that give new insight into model structures and parameterizations in prms along the same line of thought a number of well planned model based experiments that could potentially lead to advancements into fundamental hydrologic knowledge can be facilitated using the prms python framework acknowledgements this work was partially supported by the national science foundation under grant no iia 1329469 we thank dr justin huntington of the desert research institute for allowing us to use his prms model for the global sensitivity analysis case study we would like to thank the information technology department at the university of nevada reno for computing time on the high performance computing cluster we also thank dr scott tyler of the university of nevada reno for his useful comments and christine volk o d for her proofreading of this article appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 01 006 
26256,environmental stressors and population growth have significantly affected terraced rice ecosystems such as in the sapa district in northern vietnam the question arises how natural and socio economic components determine the amount of rice yields this study combines a hybrid neural fuzzy inference system hyfis with gis based methods to generate two models that can map suitability areas for rice cultivation at a regional scale and predict actual rice yields at a plot scale semi structured interviews the integrated valuation of ecosystem services and tradeoffs tool and different statistical models were used to investigate the impacts of eight environmental variables and three socio economic variables on rice production subsequently two hyfis models were trained with an accuracy higher than 88 because the predictive power values of the two proposed hyfis models were higher than those of benchmark models they are considered as useful tools to assess and optimize land use and related rice productivity keywords agriculture crop hyfis neural network regional scale plot scale abbreviations hyfis hybrid neural fuzzy inference system svm support vector machine glm general logistic regression gis geographical information system lulc land use and land cover gso general statistics office of vietnam fractp ratio of evapotranspiration to precipitation twi topographic wetness index irri international rice research institute 1 introduction different nature based and technological solutions have significantly reduced the dependency of rice agriculture on the vagaries of weather water and floods irri 2006 however especially the rice production in mountainous communities still faces many variations in rice yields due to environmental impacts dobermann and fairhurst 2000 meanwhile the area of agricultural lands is decreasing due to urbanization leading to land use conflicts in regard to paddy fields samranpong and pollino 2009 therefore more efforts from spatial planning and effective use of farming practices are needed in order to select appropriate areas for rice cultivation and improve yields in terraced paddy fields irri 2015 maddahi et al 2016 based on the rapid development of new mathematical and geographical methods agricultural managers can be equipped with decision supporting tools and models to optimize rice production khairunniza bejo et al 2014 in the past many yield prediction models at regional and plot scales were commonly based on statistical and machine learning methods especially at the plot scale the statistical methods such as generalized linear logistic regression models glm are more common in bio agricultural analyses such as the influence of organic farming on rice plants datta 1981 dobermann and fairhurst 2000 recently the application of machine learning methods seems to become more effective for yield prediction such as the use of support vector machines svm jaikla et al 2008 and neural networks dahikar et al 2015 jabjone and wannasang 2014 liu et al 2005 other publications integrated statistical methods remote sensing and geographical information systems gis to assess the rice suitability of areas at a regional scale maddahi et al 2016 samanta et al 2011 and to estimate potential rice yields at a plot scale huang et al 2013 noureldin et al 2013 pirmoradian and sepaskhah 2006 however these models using simple and non spatial input variables cannot represent non linear effects of the social ecological system on rice growth hence these models are limited to predicting yields with a relatively high accuracy and extrapolating the overall suitability of areas for rice cultivation in order to account for nonlinear correlations of rice yields with environmental and social components and to improve the accuracy of traditional statistical models we use the hybrid neural fuzzy inference system hyfis developed by kim and kasabov 1999 in this study this system uses a combination of fuzzy logic and the artificial neural network ann approach the fuzzy modeling system uses if then rules to separate a linear correlation between a response variable such as rice yields and related predictor variables such as environmental variables into separated independent correlations based on linguistic terms tung and quek 2009 hereby the predictor variables with crisp values are transferred into different sets of linguistic terms corresponding to if then rules thus each linguistic term provides a membership value to better adapt complex models bergmeir and ben 2015 hence in contrast to general linear models glm and support vector machine svm models the hyfis universally uses linguistic and crisp values in parallel for prognosis and diagnosis application bui et al 2017 kothamasu and huang 2007 in order to evaluate potential advantages of the hyfis system the yield predictions calculated with the hyfis approach are compared with glm and svm models in this study the nominated concepts are applied here to help solve the following general issues the rice yield to be expected depends on two major factors i the natural productivity determined by environmental components and ecosystem functions in cropping areas and ii different socio economic e g agricultural management options used to optimize rice yields irri 2006 in order to take full advantage of environmental conditions for rice growth the identification of sites and areas best suited for rice cropping becomes a prerequisite in agricultural management gupta and toole 1986 the yields harvested from areas with high crop suitability can be up to 50 higher than those harvested from unsuitable areas dang et al 2018 once the rice is cropped in favorable areas the farmers can accordingly apply appropriate farming practices to take full advantage of the maximum potential of rice yields balbi et al 2015 thus a map depicting the crop suitability areas at different levels on regional scales would be useful for agricultural planning and optimized land use decisions maddahi et al 2016 ye et al 2015 predictions for the potential of rice yields at plot scales can help farmers to assess their farming practices during each cropping season glavan et al 2014 irri 2006 a better interrelation of suitable site selection procedures based on environmental components and farming practices based on socio economic components can help to control continuous water and nutrient availabilities and thus safeguard a sustainable supply of rice products dang et al 2018 by integration of the hyfis system with gis based systems this study develops two models for mapping rice suitability areas and predicting the potential of rice yields corresponding to two scales of investigation regional and plot scales respectively the mountainous area of the sapa district in the lao cai province in vietnam was chosen as a case study area the aims of this study are i to indicate the suitability of areas for agricultural development on the regional scale ii to identify those ecosystems which potentially could be converted into arable lands and iii to better predict the potential of rice yields of particular plots eight environmental variables with their spatial databases have been chosen to assess the suitability conditions of areas for rice cropping at the regional scale additionally to these environmental variables three socio economic variables have been identified to predict the overall potential for rice yields at the plot scale in the next sections we present the methods related to data collection and the subsequent steps of the model developments based on the hyfis approach the three following research questions were guiding this study is it feasible and effective to integrate hybrid neural fuzzy inference systems with gis analyses for mapping crop suitability areas at a regional scale and for predicting potential rice yields at plot scales is the accuracy of hyfis models higher than traditional of statistical models how is the potential of agricultural development in other ecosystem types in the sapa region 2 study area the study area is located in the sapa district a narrow 15 km 15 km valley in the north west mountain range of vietnam fig 1 the altitude of this area ranges between 500 and 2800 m besides extreme weather events with frost and snow recorded in winter the climate stays comparably cool throughout the year according to the national center of the hydro meteorological forecast service in vietnam the mean sunshine hours of the research area reach 1400 h annually which is lower than in other agricultural regions about 2500 h annually the annual humidity in sapa is always higher than 85 while the temperature is lower than 24 c the typical weather with high frequencies of fog reduces the extent to which solar energy can drive photosynthesis of rice plants as basic process of rice growth furthermore due to the snow and low temperatures in winter rice harvesting in this region is only possible once a year the rice yields of 2 3 tons ha per year in sapa are usually lower than that in other agricultural regions of the lao cai province lò dieu phu pers comm 2012 according to the land use land cover lulc map interpreted from spot 5 satellite image in 2010 and provided by partners from europe and southeast asia burkhard et al 2015 the area of paddy fields in the research area is about 2700 ha this equals to 12 of the whole study area fig 1 in the san sa ho hang lao chai and ly lao chai communities in ngoi dum basin the paddy fields have been expanded to the colluvium and alluvial regions hoang 2014 in the chu lin mong sen and vu lung sung communities in the ta van basin the distribution of paddy fields is more heterogeneous nevertheless the area of paddy fields in the ta van basin has nearly doubled since the year 1993 hoang 2014 recently the increase of food demand has put pressure on the rice supply in sapa dang et al 2018 in order to meet the growing demands for food farmers can either expand the rice cropping areas or increase rice yields by implementing suitable farm management measures however narrow valleys a challenge to the local people local authorities as well as farmers when it comes to identifying additional and suitable crop areas as the number of additional farming areas is generally low farmers usually reduce the times for shifting cultivation and use more fertilizers and pesticides instead local farmers have a belief in biotechnology to optimize crop yields and they trust especially the application of fertilizers and pesticides isoda pers comm 2015 additionally farmers put less attention on environmental conditions when selecting additional sites for rice cropping which leads to an increase of soil degradation nguyen et al 2011 and an instability in rice yields isoda pers comm 2015 therefore the mapping of suitable rice cropping areas can minimize environmental risks and provide complementary knowledge and supporting tools for local farmers to stabilize rice yields 3 environmental and socio economic variables affecting rice growth 3 1 the fluctuation of rice yields in sapa rice yields for 200 paddy plots have been collated in a research project carried out by yuzuru isoda pers comm 2015 the area of each sample plot equals 100 square meters and they are located in six communities shown in fig 1 the data were collected by interviews and revealed a fluctuation of rice yields between 2010 and 2012 from 1 28 to 9 56 tons ha per year other rice yield data from the sapa region showed lower average values for the same time period 0 4 tons ha per year less according to data from the legato 1 1 land use intensity and ecological engineering assessment tools for risks and opportunities in irrigated rice based production systems http legato project net project and 0 6 tons ha per year lower according to inventories published by the general statistics office 2 2 https www gso gov vn of vietnam gso table 1 nevertheless it is important to emphasize that in the sapa district rice is cultivated on slope lands where nutrient rich soils are more scarce and the local climate is more extreme than in agricultural lands in the downstream areas of the lao cai province nguyen et al 2011 it is obvious that the rice production here is lower than the mean rice yield values in the rest of the lao cai province the rice yield data based on interviews represent the fluctuations of the upland and irrigated rice production in the sapa district according to the inventory data of irri 2006 the mean of rice yields in sapa corresponds with the rice yields in mountainous areas recorded in asian countries with fluctuations from 1 5 to 4 tons ha per year in average compared to the inventory data of gso the yields recorded in 10 paddy plots in the case study area are higher than the average yield 7 2 tons ha per year in other agricultural regions in vietnam the increase is based on the use of more intensive farming methods such as fertilization and new seed choices it is assumed that nearly 50 of the 200 paddy sample plots fig 1 with yields lower than 3 5 tons ha per year are related to poor site selection and or ineffective farm management methods 3 2 environmental variables in order to generate effective models to predict areas suitable for rice cultivation at different scales the most effective predictor variables related to environmental and socio economic conditions need to be selected this process should eliminate non relevant variables and improve the interpretability of final models bui et al 2017 the correlations of relevant non relevant variables with rice yields have been identified by a pearson comparison before any variable was used in the prediction models the eight environmental variables considered in this study include elevation meter slope degree soil erosion ton ha per year sediment retention ton ha per year length of flow meter water yield millimeter ratio of evapotranspiration aet to precipitation p and topological wetness index twi table 2 the topographical variables including elevation slope erosion and sediment retention determine the distribution of soil nutrients the hydrological variables water yield ratio of evapotranspiration to precipitation twi and length of flow describe the water resources potentially available from irrigation activities dang et al 2018 these eight environmental variables were used to define crop suitability areas at regional scales and to predict potential rice yields at plot scales the three topological variables elevation slope and length of flow fig 2 were calculated from a digital elevation model dem of the research area the dem is based on four topographical maps with a resolution of 10 m the topographical maps were collected in digital format from the vn 2000 national coordinate system the contour lines were extracted from these maps and converted to the wgs 84 coordinate system before being used to extrapolate the dem for the whole case study region three variables with special relevance in mountainous areas like the sapa region are i elevation ii slope and iii length of flow all three variables strongly influence the climatic such as temperature precipitation and humidity and topographic characteristics this again leads to indirect changes in water and nutrient availabilities for rice growth irri 1978 the variable length of flow determines the downhill runoff distance from each plot to the nearest reservoir in downstream areas tesfa et al 2009 paddy plots with low values of flow length are located near water reservoirs such as rivers and outlets in contrast high values of flow length indicate paddy plots which are located in upstream areas far from downstream reservoirs they are characterized by high flow intensities steep slopes and shallow soils mixed with pebbles and gravel chang 2003 soil nutrient enrichment in the upstream areas can be slower than those in downstream areas renaud and kuenzer 2012 thus nutrient and water availabilities in areas used as paddy plots could be inversely proportional to the length of flow in order to demonstrate the important role of this variable its correlation with rice yields is presented and discussed in detail in the result section regarding the nutrient availability in soils erosion and sediment retention fig 2 are crucial processes that strongly influence the deposition of fertile material on paddy fields in detail soil erosion is defined as the loss of top soil by wind or runoff pimentel 2006 resulting in soil degradation erosion processes can detach and move soil particles to downstream areas leading to the reduction of fertile materials in upstream areas wischmeier and smith 1958 for example steep areas with sandy soils and high precipitation become more vulnerable to erosion compared to flat areas with clay soils and low precipitation wischmeier and smith 1978 these variables have been determined by simulating the sediment retention with a sub model developed as part of the tool invest 3 0 integrated valuation of ecosystem services and tradeoffs sharp et al 2014 by dang et al 2018 the two resulting data sets have a resolution of 20 m sediment retention is the amount of materials trapped on topsoil layers retention is affected by topographical factors and land covers sharp et al 2014 because of its important role in determining the quality and quantity of nutrients in the topsoil this variable has been selected for the prediction models the amount of sediment retained can be quantified as the gap between the incoming and exported sediment on each plot vigerstol and aukema 2011 the quantity of soil nutrients retained is noticeably dependent on the type and volume of materials in the deposited sediment schmitter et al 2010 therefore the correlation of sediment retention with rice yields can be positive or negative depending on the type of incoming materials slaets et al 2015 if the amount of unfertile materials trapped in a plot is higher than the fertile ones the level of suitability for rice cultivation in that plot is lower in contrast the plots retaining more fertile materials might be more suitable for cropping rice in the research area the high amount of un weathered geologic materials maintained from the depositional processes nguyen et al 2011 can reduce the fertility of soils leading to changes in rice yields regarding hydrologic and climatic variables the water yield represents the amount of water unavailable for rice growth through both ground and surface water whereas the ratio of evapotranspiration to precipitation fractp partly explains the quality of water and nutrient transports in rice plants two variables have been simulated with a spatial resolution of 20 m 20 m with the reservoir hydropower production model in the invest 3 0 tool sharp et al 2014 water yield is known as the water extracted from a landscape that also contributes to other landscapes in downstream areas sharp et al 2014 the increase of water yield does not only erode alluvium from the topsoil but also reduces the water uptake of rice plants the amount of water yield in the whole region was calculated through a budyko curve 1974 based on the following equation 1 water yield x 1 a e t x p x p x where aet is the actual yearly evapotranspiration and p is yearly precipitation in the reservoir hydropower production model of invest the ratio fractp of actual annual evapotranspiration aet to precipitation p is calculated based on the following equation proposed by fu 1981 and zhang et al 2004 2 f r a c t p a e t x p x 1 p e t x p x 1 p e t x p x w 1 w where pet is the potential evapotranspiration of different land cover types according to local climatic conditions and w is an empirical parameter related to soil properties the potential evapotranspiration was calculated through the use of a temperature and soil database table 2 the database of soil thickness and particle sizes extracted from the soil map was used to identify the w parameter based on the expression of donohue et al 2012 integrated in the reservoir hydropower production model through the aggregation of two important climatic factors the fractp ratio has been commonly used as an indicator to assess the water energy balance in a particular land use cover over a long term timescale budyko 1974 lu et al 2005 firstly the evapotranspiration factor represents the loss of water from the soil surface by evaporation and from crop by transpiration that contributes to the transportation process of nutrients from the roots to other plant tissues allen et al 1998 doorenbos and kassam 1979 have described the positive correlation between rice yields and evapotranspiration recently various studies demonstrate that the reduction of evapotranspiration can prevent water and nutrient transports through plants leading to the reduction of rice yield in different time scales alberto et al 2011 steduto et al 2012 secondly the precipitation factor plays an important role in triggering soil erosion in slope lands sharp et al 2014 in upland rice production irrigation water from rainfalls is commonly kept in upstream reservoirs and directed toward paddy plots in downstream areas raindrops falling down in a particular paddy plot can detach and move soil particles leading to the increase of soil erosion and the decrease of topsoil nutrients wischmeier and smith 1978 according to relations between rice production and climatic factors the fractp variable was used to develop yield prediction models as an indicator of soil moisture the topographic wetness index twi has been proposed by sørensen et al 2006 this variable can represent the flow accumulation of corresponding landscapes and assesses the amount of water available for rice production in a whole region therefore it was chosen for this analysis the twi was calculated based on the following equation 3 t w i l n a t a n β where a is the accumulated flow β is the slope wetlands or floodplains have higher values of twi whereas lower values are found for example in ridges in contrast with water yields known as amount of water outputted extracted from a particular plot the flow accumulation a is the amount of water inflows from upstream regions to each downstream plot one hypothesis would be that the higher the twi is the higher the rice yield is according to the gis analysis and the invest model application the calculations of eight variables no 2 until no 7 as listed in table 2 were converted to a spatial resolution of 20 m 20 m for the whole sapa region 3 3 socio economic variables during the semi structured interviews carried out in 2010 2015 and 2016 further production related data besides rice yields were collected for the 200 sample plots fig 1 the interviewed persons were household heads of farms and their knowledge was harnessed to reveal the productivity of rice terraces in particular areas owners of terraced rice fields identified the locations of their fields on fine resolution satellite images based on the interview results three significant variables related to human activities were identified financial investments of each household and the amount of compound and straight fertilizers used in order to improve nutrient availability npk fertilizers compound fertilizers containing all three primary components nitrogen phosphorus and potassium and straight fertilizers such as nitrogen phosphorus and potassium separately that are required for healthy rice growth environ et al 2014 are applied due to extreme nitrogen shortages in the soils urea is spread as a main straight fertilizer in the case study region other types of straight fertilizers used in a few paddy plots were not considered in this study the socio economic data collected at the 200 paddy plots could only be used to predict the yield potentials at plot scales the details of using such data in yield assessments will be discussed in the next sections the location information or gps coordinates of the paddy plots corrected by authors was used to link the plots to the environmental information from available spatial data the efficiency of farming practices highly depends on the amount of fertilizers pesticides seeds and equipment used however the farmers could unfortunately not provide sufficiently detailed information on their management inputs therefore the variable financial investment was used as a bulk indicator for all kinds of additional inputs to represent the management efforts of local farmers on their paddy plots 4 modelling process the study aimed at creating a joint homogenous indicator dataset covering the whole sapa region with a spatial resolution of 20 m 20 m this dataset was used to identify sites of naturally high productivity e g indicators no 2 until no 8 table 2 these sites were expected to be promising for an efficient use of farming methods i e indicators no 9 until no 11 table 2 ensuring high probabilities for high rice yields i e indicator no 1 table 2 this homogenous dataset was available for the 200 sample plots with a size of 100 m2 the data were used as a basis to develop linguistic rules for the creation of a homogenous database for the whole sapa region altogether 75 of the basic data set was used to develop the linguistic rules and 25 of the basic data set was reserved for the validation process 4 1 background of model validation the model validation process was performed in different steps complementary to the hyfis development see section 4 2 the prediction models always need to be trained especially with the use of neural networks in machine learning processes jabjone and wannasang 2014 in order to assess the performance quality of trained models different kinds of testing indices have been developed for the validation process the combination between neural networks and fuzzy logic can be developed from statistical measures bergmeir and ben 2015 various goodness of fit tests and prediction power assessments such as overall accuracy positive predictive value ppv negative predictive value npv specificity true positivity rate or sensitivity false negative rate in equations 4 6 below can be used 4 overall accuracy acc t p t n t p t n f p f n 5 sensitivity t p t p f n specificity t n t n f p 6 ppv t p t p f p npv t n f n t n where tp is the number of correct true positive points and tn is the number of correct true negative points between predicted and observed data fp is the number of incorrect false positive points and fn is the number of incorrect false negative points between predicted and observed data these values can assess the performance of a prediction model in positive value of 1 or negative value of 0 cases fawcett 2006 in detail the value of acc represents the probability of successful predictions and is calculated as the number of points where both 0 and 1 values are predicted correctly divided by the total number of testing points compared to the total number of predicted points the positive predictive value ppv is the successful probability of prediction corresponding to the points with the 1 value whereas the negative predictive value npv is the successful probability of prediction corresponding to the points with the 0 value compared to the total number of observed points sensitivity is the probability of correct points with the 1 value whereas specificity is the probability of correct points with the 0 value newlands et al 2016 to assess the efficiency of iterative processes bui et al 2016 the receiver operating characteristic roc curve and area under the curve auc values have recently been used to validate machine learning models ajaz and campus 2015 in detail the roc curve and auc values can partly measure the predictive power of model outcomes both of them refer to the sensitivity and specificity of model outcomes that means that for example good auc values fluctuate between 0 5 and 1 auc values of 0 5 0 7 indicate a poor model auc values of 0 7 0 8 indicate a moderate model and auc values of 0 8 0 9 indicate a good model auc values of 0 9 1 indicate excellent models fawcett 2006 4 2 the training process of hybrid neural fuzzy inference systems using gis this section explains the artificial intelligence approach based on a neural fuzzy inference system that was used to define areas suitable for rice cultivation at the regional scale and to estimate potential rice yields at the plot scale corresponding to the two spatial scales of this study two hyfis models were developed with the same structure at the regional scale a site selection hyfis model abbreviated by s hyfis considers eight environmental input variables as listed in table 2 to map areas suitable for rice cultivation at the plot scale a complementary integrated hyfis model abbreviated by i hyfis considers besides the eight environmental input variables used in the s hyfis model additionally three socio economic variables as listed in table 2 to predict potential rice yields the structure of the two proposed models is shown in fig 3 the modeling procedure was carried out in five steps including database preparation 1 training 2 optimizing 3 validating models 4 and assessing the performance 5 of final models the formal hyfis models were implemented via the frbs package bergmeir and ben 2015 in the r studio environment version 1 0 136 the optimization process was based on iteration and programed by the authors the spatial analysis was carried out in arcgis 10 2 regarding the integration of the hyfis models into the gis environment all input data raster maps were converted to comma separated values containing latitude and longitude information of each pixel after all results were obtained in the hyfis models the output data were converted back to raster format to be used in arcgis 4 2 1 step 1 preparation of site selection and set up of an integrated database for the training and testing processes in the first step the predictor variables mentioned in sections 3 2 and 3 3 covering eight environmental and three socio economic variables need to be analyzed by their pearson correlations with the target variable rice yields if the predictor variables have statistical significance to explain the variance of rice yields these variables are selected for the next step after normalization to values ranging from 0 01 to 1 00 the normalization reduces the bias between the input variables used in the prediction models the correlations were analyzed with data for 200 sample plots collected in the years 2010 2012 based on the coordinates for these 200 plots all data could be linked to the maps of the eight environmental variables as described in section 3 2 hence 200 plots containing full environmental and socio economic data were analyzed to check their correlations with rice yields for the proposed modeling process based on fuzzy logic a binary classification for the rice yields variable in the two values 0 and 1 is required 0 indicates unsuitability of areas for rice cultivation in the s hyfis model and low potential for high rice yields in the i hyfis model 1 indicates suitability of areas for rice cultivation in the s hyfis model and high potential for high rice yields in the i hyfis model according to irri 2006 if farming practices such as fertilization and pesticide use are not applied the potential of yields for upland rice in asian countries is estimated to range from 3 to 3 5 tons ha per year hence the locations of 102 paddy plots where recorded yields were higher than 3 5 tons ha per year were classified by the value of 1 whereas the 98 plots with lower yields were classified with the value 0 therefore the output of the two models ranges from 0 to 1 the outcomes near 1 indicate the suitability of areas for rice cultivation in the s hyfis model or the potential for high rice yields in the i hyfis model values near 0 represent areas unsuitable for rice cultivation in the s hyfis model or low potential for high rice yields in the i hyfis model in order to test the performance of the developed models the 200 plots for which complete datasets were compiled were randomly divided into two data sets training and testing the testing data set consists of 25 or 50 plots of all plots while the training data set consists of the remaining 75 or 150 plots the testing dataset was used during the validation process because it has not been used to train the models this allowed us to compare the trained model outcomes with observations in the testing data set in order to assess the accuracy of the results liu et al 2010 4 2 2 step 2 knowledge learning and design of the fuzzy inference system in hybrid models this step focused on constructing a conceptual fuzzy inference systems integrated in hyfis models for training purposes in this study the if then rules of the fuzzy structure followed the mamdani inference model proposed by mamdani 1977 the fuzzy structure contains four layers corresponding to four components of the mamdani model fig 4 in the conceptual hyfis model functions in the fuzzy inference systems were used in this study to calculate the weights for neural networks whereas neural networks are applied to train fuzzy inference systems neural networks will automatically learn new relationship from new input data to identify suitable fuzzy rules and select suitable membership functions four layers of the fuzzy logic were replaced for unknown hidden layers as developed in traditional neural networks the first layer is designed to transform input data from crisp values to linguistic ones whereas the fourth layer produces numerous outcomes from linguistic values all input variables in the hyfis models are normalized to a same range from 0 to 1 therefore the outcome values were calculated in a range from 0 to 1 the two layers in the middle compose fuzzy rules and membership functions the inference engine of the fuzzy inference system in the s hyfis model can be explained in detail as follows layer 1 fuzzification layer in this layer the input environmental variables of the given numerical data were separated into fuzzy regions associated with linguistic terms the number of linguistic terms depends on the length of the fuzzy regions and represents the variance of rice yields then the linguistic terms were assigned to fuzzy membership values in the fuzzification process in this process the gaussian membership function in equation 7 was implemented for each input variable with two initial parameters variance and standard deviation 7 μ 1 k e x p x c 1 k 2 2 δ 1 k 2 where μ is the gaussian membership function for input variables δ is the variance parameter and c is the standard deviation of the function k is the total number of linguistic terms for eight input variables two initial parameters δ and c were adjusted by using gradient descent based learning algorithms bergmeir and ben 2015 these parameters converge to local optima and are more sensitive to membership values in the end of this layer the membership functions and values were calculated for all training data in order to minimize the number of if then rules in layer 2 and to maximize the accuracy of outcome models the number of linguistic terms was optimized through an iterative process presented in step 3 layer 2 rule antecedence layer this layer performs the appropriate fuzzy rules between input and output in training data and determines a strength value for each rule or the relative membership values the number of nodes in this layer equals the number of fuzzy if then rules generated for the training data in the preceding step for instance in layer 1 of fig 4 the input variable x1 has three linguistic terms r 1 1 r 1 2 and r 1 3 whereas the input variable x8 has two linguistic terms r 1 k 1 and r 1 k in this case the nodes r 1 1 and r 1 k 1 decide on the membership function for node r 2 1 in layer 2 which represents the outcome y1 is unsuitability areas then their connections represent the rules if x1 is r 1 1 and x8 is r 1 k 1 then y1 is unsuitability areas and if x1 is r 1 3 and x8 is r 1 k then yi is suitability areas the process was repeated for each instance of the training data to generate fuzzy rules the strengths of these rules were calculated based on the hamacher operation bergmeir and ben 2015 for instance the membership function for the first rule of layer 2 in fig 4 was as follows 8 μ 2 1 μ 1 1 μ 1 k 1 μ 1 1 μ 1 k 1 μ 1 1 μ 1 k 1 layer 3 rule consequent layer this layer yields final rules by removing redundant rules the distinct concept in this layer is the aggregation of rules created in the second layer the strength of each rule concept is decided by aggregating the strengths of membership functions in the antecedent layer in this case the maximum operation was used to delete the redundant rules having lower strengths for example in fig 4 the first two nodes r 2 1 and r 2 2 in the second layer determine the rule and the membership function of the node r 3 1 in the third layer then its activation function will be 9 μ 3 1 max μ 2 1 μ 2 2 layer 4 rule inference and defuzzification layer this process transforms linguistic terms into numerical values to create the final model output values by using the modified center of gravity cog method it also determines the final linguistic terms for the output variables for example the first two nodes r 3 1 and r 3 2 in the third layer decide the first node r 4 1 in the fourth layer then the strength of the first fourth layer node is calculated by following equation 10 μ 4 1 μ 3 1 y 3 1 μ 3 2 y 3 2 μ 3 1 μ 3 2 where the y is value of each rule consequent node the inference engine of the fuzzy inference system in the i hyfis model operates with the same layers as in the s hyfis model but the number of if then rules and weights of the i hyfis model were changed due to the additional socio economic variables that were added therefore the development of the two hyfis models was done in two different iteration processes mentioned in section 4 3 3 in four layers of the hyfis models the number of linguistic terms k and the values of two initial parameters variance and standard deviation can impact the weights of antecedent and consequent rules in layers 3 and 4 and then the accuracy of the outcome kim and kasabov 1999 in other words the values of the membership functions in four layers are dependent on the variance of two initial parameters and the number of linguistic terms and need to be learned optimized in order to obtain well designed if then rules 4 2 3 step 3 and 4 modeling optimization based on iterative processes and model evaluation once the framework of the neural fuzzy network was constructed the iterative and testing processes were launched to identify the best position and length for fuzzy regions in the first layer of step 2 in the iterative process the number of linguistic terms was tested from three to nine in order to find out the optimal value that can minimize the number of if then rules at 150 rules and maximize the performance of hyfis models at 85 the lower the number of if then rules the better is the performance of outcome models bui et al 2017 regarding the two initial parameters variance and standard deviation their values were changed based on the fluctuations of initialized fuzzy regions in each iteration leading to changes in the values of membership functions and if then rules bergmeir and ben 2015 then the testing dataset was used to assess the goodness of fit of the trained hyfis models by calculating the mean square errors and the auc values the values of mean square errors mse which are commonly used to assess the iteration process omez et al 2010 were calculated with the following equation 11 m s e 1 n i 1 n p r e i o b s i 2 where n is number of plots considered in the training data or the testing data obsi indicates observed values in the testing data and prei are the predicted values produced by the trained models in the optimal position of initial parameters and numbers of linguistic terms the gap between predicted outcomes and observed values is smallest however the mse values could not totally explain the performance of the trained models fluctuations of the auc values were found in the models that have the same mse values therefore the auc value was used for assessing the accuracy of the trained models in parallel with the mse value in each iteration the final model needed to have the highest auc value and the lowest mse value based on the mse and auc values the number of iterations was terminated at 500 to fully represent the fluctuation of the two initial parameters benmiloud 2012 in the testing process the authors could not find more accurate models in cases of higher numbers of iteration 4 2 4 step 5 assessment of final hyfis models in this step the final s hyfis and i hyfis models with the highest auc values and lowest mse values were evaluated to estimate their goodness of fit using testing data and calculating seven statistical values acc sensitivity specificity ppv npv mse and auc in order to demonstrate the advantage of the developed hyfis models these models were benchmarked with alternative models methods this included a support vector machine svm and a logistic regression model simulated as generalized linear models glm and programmed in r both models are known as powerful tools in machine learning used in agricultural and social studies ajaz and campus 2015 to explain the probability of a binary variables 1 and 0 depending on explanatory variables eight environmental explaining variables and the target variable rice yields selected from the training data were used to generate the benchmark svm and glm models all goodness of fit tests and the prediction power assessment which were used for the developed hyfis models were also applied for the svm and glm models in order to indicate the efficiency of the different models to map areas suitable for rice cultivation in the sapa region whereas the logistic regression model is commonly used to estimate the probability of binary variables in agricultural fields ali et al 2012 sattaka et al 2017 svms have been recognized as robust supervised learning models in classification and regression analysis during the last decade armstrong 2016 balakrishnan and muthukumarasamy 2016 su et al 2017 in this process the same training and testing data sets to develop the final s hyfis model were used for both logistic regression and svm models the package e1071 was used to run the svm model in r in particular the outcome of the svm models depends on the parameters in the c classification such as a cost of constraints violation c and an epsilon in the insensitive loss function karatzoglou et al 2006 the kernel type used in the training and predicting processes was radial option to select suitable parameters the testing process based on the changes of auc and mse values was implemented finally the values of c and epsilon were chosen respectively at 1 5 and 0 5 for the most effective svm model the performance of these models is shown in the results section based on the comparison between the four models the study identified two optimal models with the best goodness of fit to predict the potential of rice yields on the plot scale and to map areas suitable for rice cropping at the regional scale based on the eight environmental variables as input data table 2 the s hyfis model has extrapolated the suitability of areas from the plot scale to the regional scale the extrapolation process of the s hyfis model identified the suitability unsuitability of areas based on the similarity of environmental characteristics in the whole case study area the map of crop suitability areas was validated by 17 independent plots provided by the legato project as mentioned in section 3 1 in this project scientists collected straws and grains from 17 paddy plots and then weighed the amount of dried rice grains to calculate rice yields at each plot 14 high yield and 3 low yield plots were recorded the locations of these plots provide important data to cross check the accuracy of the s hyfis model if the outcomes of the s hyfis model is correct the high yield plots collected from the legato project need to be located in suitable areas and the low yield plots need to be located in unsuitable areas socio economic data were not collected at these plots therefore these plots can only be used to check the accuracy of the s hyfis model finally in order to assess the potential of rice expansion in the case study area the areal percentage of areas suitable unsuitable for rice cultivation predicted from the s hyfis model were counted in seven different land use cover types including the paddy fields land uses cover types having highly suitable environmental characteristics for rice cultivation can be suggested for agricultural conversion regarding the potential of rice yields predicted through the i hyfis model at the plot scale the accuracies of results were only assessed at the 200 observed plots through percent error values following this equation 12 percent error value predicted value observed value 100 percent error values higher than 50 could identify plots predicted incorrectly from the i hyfis model to make the results easy to observe each paddy plot is conveniently visualized within a single point on the map 5 results 5 1 pearson correlation between predictor variables and rice yields the input data were analyzed in order to eliminate non statistical significant variables of the chosen predictor variables to explain the rice yield as a response variable the high yield paddy plots were compared with the low yield ones by eight environmental variables and three socio economic variables through boxplots and by calculating the pearson correlation values shown in fig 5 out of the eight spatial input variables used as main inputs for the s hyfis model see table 2 the slope length of flow and sediment retention variables have the strongest correlation values of 0 4 0 34 and 0 3 respectively the variables soil erosion elevation and water yield follow with correlation values of about 0 2 the ratio of evapotranspiration to precipitation fractp and the topological wetness index twi were the poorest predictive variables with low correlation values of 0 16 and 0 11 the indicated low yield areas appeared in cases where rice was cropped on sites with high erosion susceptibility situated on steep terrains and or on high altitudes although a higher altitude for agricultural lands can be identified at 1100 m the contribution of the variable elevation does not fully and adequately explain the increase of rice yields with decreasing altitude hence farmers need to consider further environmental variables such as slope lower than 13 water yields lower than 700 mm and length of flow less than 6 km to have high probabilities to harvest higher rice yields the three socio economic variables used in the i hyfis model correlate to about 0 5 with rice yields fig 6 according to this result the additional inputs related to farm management practices have remarkably influenced the rice production especially in the case of fertilizers nevertheless the amount of investment should range from 5 to 6 million vnd equal to more than 200 eur per hectare to achieve high yields on suitable plots however the effective amount of fertilizers should be limited to 180 kg of compound fertilizers and 130 kg of urea for 1 ha for high yield plots in the case study fig 6 5 2 final s hyfis and i hyfis models table 3 depicts the structure of the two final hyfis models in the case study area eight environmental variables were considered as the inputs for the s hyfis model to assess the suitability of areas for rice cultivation three socio economic variables were added to develop the i hyfis model to predict the potential of rice yields in the iterative process the optimal number of linguistic terms in both hyfis models was chosen to be eight if the number of linguistic terms is lower higher than eight the performance of hyfis models assessed through the auc and mse values is reduced hence the s hyfis model generated 148 if then rules based on 128 initial parameters whereas the i hyfis model had 149 rules based on 176 initial parameters see more in section 4 2 2 according to the iterative processes described in section 4 2 3 and in fig 7 the optimal values of initial parameters were chosen through the values of auc and mse the mse mean of the i hyfis model from 0 07 to 0 35 in the iteration process was lower than the one of the s hyfis from 0 15 to 0 55 as shown as a linear fluctuation of the auc values the predictive ability of the i hyfis model was higher than the s hyfis model from 3 to 6 based on the goodness of fit test the chosen s hyfis model has an auc value of 0 88 and a mse value of 0 14 see table 4 the positive predictive value ppv of this model reaches 0 74 or in other words the probability of finding a suitable plot for crop cultivation value of 1 is 74 complementarily the negative predictive value npv reaches 0 96 explaining that the probability of finding a plot unsuitable for crop cultivation value of 0 is 96 the accuracy of the suitable plots was 94 as shown by the value of sensitivity whereas the accuracy in predicting unsuitable plots was 81 as shown in the value of specificity the predictive power of the s hyfis model was also illustrated by the acc value of 0 86 and the kappa index of 0 71 the best i hyfis model chosen from the iterative process has the overall accuracy acc value of 90 with an auc value of 0 9 and a mse value of 0 1 which is higher than the accuracy of the s hyfis model the probabilities of finding a plot with a high value of 1 or low value of 0 yield potential are both 88 shown in ppv and npv values of 0 88 the accuracy of each finding is 92 shown in the values of sensitivity and specificity besides the overall predictive power of the i hyfis model estimated through the acc value of 0 9 and the kappa index of 0 8 was higher than for the s hyfis model the i hyfis model can be run for the whole region or for regional scales if the socio economic variables are provided for the same scale in this study the three socio economic variables were not available for the whole sapa region therefore the i hyfis model could only predict potential rice yields at the plot scale for the mapping of the areas suitable for crop farming at the regional scale the accuracy of the final s hyfis model was compared with the accuracies of the svm and glm models the accuracies of the two benchmark models are illustrated in table 4 the predictive powers of the glm and svm models shown in the values of ppv npv acc and auc seem to be lower than those of the s hyfis model the kappa indices in the s hyfis model and the svm model were almost the same with about 0 7 in average whereas the kappa index of the glm model was 0 6 although the three models are applicable to map areas suitable for rice cropping in the whole case study area the proposed s hyfis model seemed to be the most reliable model due to its high accuracy 5 3 mapping areas suitable for rice cropping in sapa the areas suitable for rice cropping are shown in fig 8 the areas were mapped based on the application of the final s hyfis model for the whole case study area to distinguish between areas that are suitable unsuitable for rice cultivation the outcomes of the s hyfis model ranging from 0 to 1 were classified into four classes these classes include low values lower than 0 3 corresponding to 30 of the total area medium values from 0 3 to 0 8 or 26 of the total area high values from 0 8 to 0 95 or 14 of the total area and very high values higher than 0 95 or 30 of the total area suitability for rice cultivation in order to validate the results 17 independent plots provided by the legato project were used within these plots 14 high yield plots were located correctly at high and very high suitability plots whereas 3 low yield plots were located at medium and low suitability plots according to this result the areal percentage of high and very high suitability areas in the ta van basin seems to be equal to those in the ngoi dum basin the high and very high potential areas for agricultural development were found along rivers and streams in the ta van lao chai and ta phin communities areas with low potentials were found in more than 4000 ha of upstream areas in sapa center trung chai sa pả hau thao and san sa ho communities corresponding to 35 of the total area in these communities accordingly agricultural development should not be expanded to upstream areas of the mountainous communities the potentials of predicted rice yields based on the final i hyfis model were compared at 200 observed plots as shown in fig 8 because the three socio economic variables were only recorded for these 200 plots the i hyfis model was not used to estimate the potential rice yields at the regional scale potential yields at eight plots were predicted by the i hyfis model with the percent error values higher than 50 while other eight plots have errors from 5 to 50 nearly 94 of all paddy plots could be correctly identified by this model with errors lower than 5 especially with plots in the ta van basin the high percent error values more than 50 were mostly found in the ngoi dum basin according to the performance of the i hyfis model farmers can consider an appropriate amount of fertilizer about 180 kg ha per year of compound fertilizers and 130 kg ha per year of urea and investments of about 5 6 million vnd required to have good chances for high yields on high suitability plots 5 4 suitability areas for rice cultivation in different lulc types fig 9 depicts the suitability of current paddy plots and the potential of future agricultural development in other lulc types based on the calculations with the s hyfis model accordingly about 16 or 430 ha of current sites cropped with rice were classified as areas with a low suitability while about 70 or 1900 ha of the current rice fields were characterized as areas with a high and very high suitability for the production of rice though there are still areas with a size of 4100 ha classified as areas with high suitability for cropping rice the transformation of these land uses to rice cultivation should be analyzed carefully the suitability areas were identified particularly in 40 about 4600 ha of forest areas this addresses also highly low sealed surfaces where about 50 of these areas have been indicated as highly suitable for rice production these areas include houses that are distributed heterogeneously among paddy fields however the area of highly low sealed surfaces is not so large nearly 250 ha in total leading to uncertainties in the assessment that will be discussed in the next sections different rationales concerning the conversion of the land use types bare soil and meadow 40 respectively 30 classified as highly suitable are to be expected the 700 ha of meadows and bare soils could be used for agricultural development their extension is larger than the total area of water bodies highly sealed surfaces and sealed surfaces in total more than 3200 ha including the high and very high suitability areas of current paddy plots meadow and bare soil could be used for rice cultivation in comparison to the present situation with more than 2700 ha paddy fields nearly 1900 ha with high and very high suitability were identified for rice cropping the areas with low suitability calculated with the s hyfis model cover more than 5500 ha of the research area in which the forest areas occupy about 4500 ha 6 discussion 6 1 application of hyfis models compared to previous prediction models such as neural networks e g by dahikar et al 2015 and svm model by jaikla et al 2008 the hybrid neural fuzzy inference system could be a promising model or alternative option for software developers and agricultural scientists to map areas suitable for rice cropping at the regional scale and to predict potential rice yields at the plot scale as a main limitation of hyfis models the operating principle in the hyfis models seems to be more complicated than in other models the developers need to have a good understanding of the combination between neural networks fuzzy inference system and gis although different optimization methods developed in mathematics bui et al 2017 have been used to optimize the two developed hyfis models the traditional iterative method chosen in this study made the training process more effective and simple as only the value sets of two main initial parameters variance and standard deviation mentioned in section 4 2 2 that needed to be trained however the quality of the iterative process needs to be assessed by both auc and mse values allowing to determine optimal values of 0 9 and 0 1 respectively for the final models according to the calculated goodness of fit tests and prediction power values the two proposed hyfis models provide more precise results than other benchmark methods such as svm and glm both hyfis models can be used to predict potential rice yields at plot scales but the results from the i hyfis model seem to be more precise the potential of rice yields as shown in the outcome of the i hyfis model is a result of the rice cultivation in suitable unsuitable cropping areas based on environmental variables and the effective ineffective use of farming practices based on socio economic variables nevertheless both hyfis models have not fully demonstrated whether or not the farmers can reduce financial investments and fertilizer inputs if they choose more suitable areas for rice cultivation or whether they need to use more supplemental nutrients for fertilization if they want to cultivate rice plants in unsuitable areas land suitability evaluation for rice cropping mapped at the regional scale as done using the outcomes of the s hyfis model can provide better land use strategies to local famers irri 1982 the s hyfis model requires many kinds of input data such as topographic hydrologic climatic and soil databases as well as the information on farming practices however these databases can represent multidimensional impacts of the social ecological system on rice ecosystems arnáez et al 2015 hoang 2014 li et al 2015 according to the results the locations of other land uses cover types can provide a lot of useful information related to water and nutrient supplies in agricultural development and sometimes even much more than those of paddy fields many parts of the case study area that are characterized by sealed surfaces bare soils and water bodies could for instance take full advantage of rice cultivation for example more than 1200 ha of meadow and bare soil areas in the high and very high classes fig 8 could be considered as suitable rice farming places replacing more than 400 ha of paddy in the low suitability class this would not only protect the green mountainous land but also help prevent erosion and balance ecological functions the potential of land use cover change will be discussed in the following section so far the application of the i hyfis model is restricted to the 200 plots used as training and testing sites in this study therefore the i hyfis model could only be powerful in a small number of plots the use of the socio economic variables could be applied for the whole region if we would assume that the other plots with the same environmental characteristics would also have the same amounts of additional anthropogenic inputs an extrapolation from the plot scale to the regional scale would require more information about farming practices or related socio economic data which depend on financial conditions of each household and tradition and behavior of farmers under certain environmental conditions it would however be a time consuming work for managers to collect socio economic data at every paddy plot from the farmers in this case managers need to consider other ways to receive better information such as the use of the bayesian belief network approach dang et al 2018 the bayesian networks allows to use measured data from fields data from farmer interviews and expert data from scientists therefore it can be easily updated from other networks and be reproduced by new knowledge from other studies bayesian networks however could not be used for mapping at different scales that can be easily done by the hyfis models 6 2 potential of land use cover change in sapa urbanization processes with the expansion of sealed surfaces have decreased the number of suitable areas for cropping kamoshita 2007 if local managers would like to take full advantage of favorable environmental conditions in the study area bare soils in the sealed surface land use areas could be changed to appropriate urban agricultural systems focusing on rice production as proposed by sharp and smith 2003 and kamoshita 2007 the key point of the urban agricultural systems is the selection and creation of areas that have environmental characteristics favorable for crop cultivation around and within urban areas it does not only provide more rice for urban residents but also reduces costs of food transportation from outside regions to urban areas midmore and jansen 2003 mita 1993 these systems have been developed in tokyo since the 1900 s japan kamoshita 2007 muñoz vallés et al 2013 has demonstrated that a suitable urban agricultural system can help to improve food security in highly densely populated areas to decrease air temperature in urban areas and to provide recreational and educational benefits nevertheless trade offs between urbanization and agricultural development need further studies using an integrated approach if urban agricultural systems are to become more likely in the case study area regarding water bodies and forest areas the study has identified high low suitability areas for rice cultivation that were distributed rather heterogeneously rice can be well cultivated in narrow areas around water bodies such as riverbeds and riverbanks because of the high potential of water availability however rice cultivation in such types of land cover contains high risks of erosion due to increasing water levels during the rainy season especially in narrow valleys nguyen et al 2011 the allocation of forest lands for agricultural purposes needs to be done very carefully and large forest areas are actually unsuitable for rice cultivation additionally the national law in vietnam related to forest protection restricts the conversion of forest land to other land uses hence quite the contrary regulations and incentives for reforestation need to be implemented for example a conversion of nearly 500 ha unsuitable agricultural lands to forests in related communities could be a sustainable solution in the case of the current rapid urbanization in the sapa region additionally the conversion of other land use cover types to arable lands and vice versa need to consider environmental issues such as climate and erosion regulation as well as wood and freshwater provision dang et al 2018 demonstrated that many paddy fields on terraces have not been an appropriate land use to mitigate risks of soil erosion and landslides in mountainous areas the excessive use of pesticides fertilizers in rice cultivation can increase the amount of nitrate and toxic products leaching into the soil and groundwater groundwater is commonly used as a freshwater source by vietnamese people living in mountainous areas lichtenberg 2013 heong et al 2015 forest areas have been ranked as ecosystems with a high potential to slow down processes of climate change and soil degradation fao 2010 ipcc 2006 urban areas such as the town of sapa have mainly been developed for tourist and administrative purposes hoang 2014 the local people there have usually enough money to import rice instead of implementing rice expansion hence trade offs between benefits obtained from forest and urban ecosystems and rice production in mountainous areas are often not strongly considered particularly in the sapa district the local people working on areas that are unsuitable for rice cultivation can find better fields in the meadows and the bare soils or alternatively choose to import rice from other regions 6 3 uncertainties of the study this study included several assumptions as well as model and data shortcomings which need to be mentioned here and should be considered in comparable future studies firstly the socio economic variables used in this study have not depicted all types of additional anthropogenic inputs for example effects of seed choices and pesticide uses as well as other environmental impact factors need to be quantified in order to better understand variances of rice yields secondly the models were trained on data collected in upland and irrigated rice ecosystems commonly found in the mountainous areas of the sapa region thus these data are applicable only to a limited extent for lowland and flood prone rice ecosystems impacts of topographical and hydrological characteristics on rice production vary from plot to plot thus the prediction of suitable cropping areas based on the s hyfis model can be less certain in regions in which no training data for rice cultivation was available this is especially problematic in lowlands with lengths of flow less than 5 km and elevations lower than 900 m as well as in upstream regions with lengths of flow higher than 8 km and elevations lower than 1300 m thirdly some primary data were used twice to calculate input variables for the hyfis models the interaction effects between these input variables could reduce the accuracy of the prediction results the correlations analyzed in step 1 shown in section 4 2 1 ensure that these interaction effects were very low for example the precipitation data was used to estimate the two input variables including the soil erosion and the fractp ratio this did not generate interaction effects between two input variables the other chosen variables make significant additions to the developed hyfis models it is demonstrated through the lower accuracy of hyfis models trained without one in two variables compared to the accuracy of the final models from 15 to 20 although the correlation between the precipitation and the yields variables was not recorded the intensity of rainfalls indirectly affects the water and nutrient supplies for the rice plants in this case the application of bayesian belief networks could provide a graph representing complex causal relations such as links from the precipitation to the soil erosion or to the fractp ratio and the rice yields dang et al 2018 7 conclusions to conclude the three research questions raised in the introduction chapter shall be answered is it feasible and effective to integrate hybrid neural fuzzy inference systems and the gis analysis for mapping crop suitability areas at the regional scale and predicting the potential of rice yields at the plot scale yes this study successfully applied the neural fuzzy inference systems for gis analysis particularly for mapping crop suitability areas by the s hyfis model and predicting potential rice yields by the i hyfis model at both regional and plot scales the input and output data were processed in a gis environment whereas the intermediate data from the hyfis models were processed in a r environment is the accuracy of the hyfis models higher than of traditional statistical models yes it is the training process using training data with the participation of iterative processes helped to optimize the overall accuracy of the s hyfis model up to 86 and of the i hyfis model up to 90 with testing data the goodness of fit and prediction power values of these models were higher than of the two benchmark models particularly with svm and glm from 5 to 10 how is the potential of agricultural development in other ecosystems in the sapa region the results of the two models applied in the sapa region showed that paddy fields meadows and bare soil areas hold high potentials for rice agricultural developments the conversion from meadows and bare soils to paddy fields should be considered because the extension of meadow and bare soil areas suitable for rice cultivation is equal same areal extension to the extension of areas unsuitable for rice cultivation that are presently used as paddy fields in contrast the conversion of forest and water body areas to arable lands should not be encouraged areas of upstream forests should be expanded instead of rice field expansion if the ultimate goal is to support natural water and nutrient supplies for downstream paddy fields the hyfis models seem to be promising tools to find suitable areas for agricultural development and to predict rice yields however there seem to be limitations in the case of scarce data especially with regard to deficient socio economic data in this case the data collection is time consuming the bayesian belief network approach can be a promising solution by using expert experiments to clearly represent uncertainties of the impacts of social ecological system dynamics on rice ecosystems an integration of the hyfis models with a bayesian belief network can provide better information for decision making such as assessments related to the balance between rice supply and demand additionally scientific results from modelling mapping and expert knowledge should be communicated to relevant stakeholders in order to be taken up on various levels for improved and evidence based decision making acknowledgements the study was embedded in the legato land use intensity and ecological engineering assessment tools for risks and opportunities in annual crop based production systems project funded by the german ministry of research and education within their funding program sustainable land management funding no 01ll0917 we want to thank all our legato colleagues especially anika klotzbücher and isoda yuzuru for providing relevant information and data this study was co financed by the vietnamese government scholarship 911 furthermore we would like to thank our colleagues at the institute for natural resource conservation department of ecosystem management at kiel university germany we thank angie faust for language revision of the manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 01 015 
26256,environmental stressors and population growth have significantly affected terraced rice ecosystems such as in the sapa district in northern vietnam the question arises how natural and socio economic components determine the amount of rice yields this study combines a hybrid neural fuzzy inference system hyfis with gis based methods to generate two models that can map suitability areas for rice cultivation at a regional scale and predict actual rice yields at a plot scale semi structured interviews the integrated valuation of ecosystem services and tradeoffs tool and different statistical models were used to investigate the impacts of eight environmental variables and three socio economic variables on rice production subsequently two hyfis models were trained with an accuracy higher than 88 because the predictive power values of the two proposed hyfis models were higher than those of benchmark models they are considered as useful tools to assess and optimize land use and related rice productivity keywords agriculture crop hyfis neural network regional scale plot scale abbreviations hyfis hybrid neural fuzzy inference system svm support vector machine glm general logistic regression gis geographical information system lulc land use and land cover gso general statistics office of vietnam fractp ratio of evapotranspiration to precipitation twi topographic wetness index irri international rice research institute 1 introduction different nature based and technological solutions have significantly reduced the dependency of rice agriculture on the vagaries of weather water and floods irri 2006 however especially the rice production in mountainous communities still faces many variations in rice yields due to environmental impacts dobermann and fairhurst 2000 meanwhile the area of agricultural lands is decreasing due to urbanization leading to land use conflicts in regard to paddy fields samranpong and pollino 2009 therefore more efforts from spatial planning and effective use of farming practices are needed in order to select appropriate areas for rice cultivation and improve yields in terraced paddy fields irri 2015 maddahi et al 2016 based on the rapid development of new mathematical and geographical methods agricultural managers can be equipped with decision supporting tools and models to optimize rice production khairunniza bejo et al 2014 in the past many yield prediction models at regional and plot scales were commonly based on statistical and machine learning methods especially at the plot scale the statistical methods such as generalized linear logistic regression models glm are more common in bio agricultural analyses such as the influence of organic farming on rice plants datta 1981 dobermann and fairhurst 2000 recently the application of machine learning methods seems to become more effective for yield prediction such as the use of support vector machines svm jaikla et al 2008 and neural networks dahikar et al 2015 jabjone and wannasang 2014 liu et al 2005 other publications integrated statistical methods remote sensing and geographical information systems gis to assess the rice suitability of areas at a regional scale maddahi et al 2016 samanta et al 2011 and to estimate potential rice yields at a plot scale huang et al 2013 noureldin et al 2013 pirmoradian and sepaskhah 2006 however these models using simple and non spatial input variables cannot represent non linear effects of the social ecological system on rice growth hence these models are limited to predicting yields with a relatively high accuracy and extrapolating the overall suitability of areas for rice cultivation in order to account for nonlinear correlations of rice yields with environmental and social components and to improve the accuracy of traditional statistical models we use the hybrid neural fuzzy inference system hyfis developed by kim and kasabov 1999 in this study this system uses a combination of fuzzy logic and the artificial neural network ann approach the fuzzy modeling system uses if then rules to separate a linear correlation between a response variable such as rice yields and related predictor variables such as environmental variables into separated independent correlations based on linguistic terms tung and quek 2009 hereby the predictor variables with crisp values are transferred into different sets of linguistic terms corresponding to if then rules thus each linguistic term provides a membership value to better adapt complex models bergmeir and ben 2015 hence in contrast to general linear models glm and support vector machine svm models the hyfis universally uses linguistic and crisp values in parallel for prognosis and diagnosis application bui et al 2017 kothamasu and huang 2007 in order to evaluate potential advantages of the hyfis system the yield predictions calculated with the hyfis approach are compared with glm and svm models in this study the nominated concepts are applied here to help solve the following general issues the rice yield to be expected depends on two major factors i the natural productivity determined by environmental components and ecosystem functions in cropping areas and ii different socio economic e g agricultural management options used to optimize rice yields irri 2006 in order to take full advantage of environmental conditions for rice growth the identification of sites and areas best suited for rice cropping becomes a prerequisite in agricultural management gupta and toole 1986 the yields harvested from areas with high crop suitability can be up to 50 higher than those harvested from unsuitable areas dang et al 2018 once the rice is cropped in favorable areas the farmers can accordingly apply appropriate farming practices to take full advantage of the maximum potential of rice yields balbi et al 2015 thus a map depicting the crop suitability areas at different levels on regional scales would be useful for agricultural planning and optimized land use decisions maddahi et al 2016 ye et al 2015 predictions for the potential of rice yields at plot scales can help farmers to assess their farming practices during each cropping season glavan et al 2014 irri 2006 a better interrelation of suitable site selection procedures based on environmental components and farming practices based on socio economic components can help to control continuous water and nutrient availabilities and thus safeguard a sustainable supply of rice products dang et al 2018 by integration of the hyfis system with gis based systems this study develops two models for mapping rice suitability areas and predicting the potential of rice yields corresponding to two scales of investigation regional and plot scales respectively the mountainous area of the sapa district in the lao cai province in vietnam was chosen as a case study area the aims of this study are i to indicate the suitability of areas for agricultural development on the regional scale ii to identify those ecosystems which potentially could be converted into arable lands and iii to better predict the potential of rice yields of particular plots eight environmental variables with their spatial databases have been chosen to assess the suitability conditions of areas for rice cropping at the regional scale additionally to these environmental variables three socio economic variables have been identified to predict the overall potential for rice yields at the plot scale in the next sections we present the methods related to data collection and the subsequent steps of the model developments based on the hyfis approach the three following research questions were guiding this study is it feasible and effective to integrate hybrid neural fuzzy inference systems with gis analyses for mapping crop suitability areas at a regional scale and for predicting potential rice yields at plot scales is the accuracy of hyfis models higher than traditional of statistical models how is the potential of agricultural development in other ecosystem types in the sapa region 2 study area the study area is located in the sapa district a narrow 15 km 15 km valley in the north west mountain range of vietnam fig 1 the altitude of this area ranges between 500 and 2800 m besides extreme weather events with frost and snow recorded in winter the climate stays comparably cool throughout the year according to the national center of the hydro meteorological forecast service in vietnam the mean sunshine hours of the research area reach 1400 h annually which is lower than in other agricultural regions about 2500 h annually the annual humidity in sapa is always higher than 85 while the temperature is lower than 24 c the typical weather with high frequencies of fog reduces the extent to which solar energy can drive photosynthesis of rice plants as basic process of rice growth furthermore due to the snow and low temperatures in winter rice harvesting in this region is only possible once a year the rice yields of 2 3 tons ha per year in sapa are usually lower than that in other agricultural regions of the lao cai province lò dieu phu pers comm 2012 according to the land use land cover lulc map interpreted from spot 5 satellite image in 2010 and provided by partners from europe and southeast asia burkhard et al 2015 the area of paddy fields in the research area is about 2700 ha this equals to 12 of the whole study area fig 1 in the san sa ho hang lao chai and ly lao chai communities in ngoi dum basin the paddy fields have been expanded to the colluvium and alluvial regions hoang 2014 in the chu lin mong sen and vu lung sung communities in the ta van basin the distribution of paddy fields is more heterogeneous nevertheless the area of paddy fields in the ta van basin has nearly doubled since the year 1993 hoang 2014 recently the increase of food demand has put pressure on the rice supply in sapa dang et al 2018 in order to meet the growing demands for food farmers can either expand the rice cropping areas or increase rice yields by implementing suitable farm management measures however narrow valleys a challenge to the local people local authorities as well as farmers when it comes to identifying additional and suitable crop areas as the number of additional farming areas is generally low farmers usually reduce the times for shifting cultivation and use more fertilizers and pesticides instead local farmers have a belief in biotechnology to optimize crop yields and they trust especially the application of fertilizers and pesticides isoda pers comm 2015 additionally farmers put less attention on environmental conditions when selecting additional sites for rice cropping which leads to an increase of soil degradation nguyen et al 2011 and an instability in rice yields isoda pers comm 2015 therefore the mapping of suitable rice cropping areas can minimize environmental risks and provide complementary knowledge and supporting tools for local farmers to stabilize rice yields 3 environmental and socio economic variables affecting rice growth 3 1 the fluctuation of rice yields in sapa rice yields for 200 paddy plots have been collated in a research project carried out by yuzuru isoda pers comm 2015 the area of each sample plot equals 100 square meters and they are located in six communities shown in fig 1 the data were collected by interviews and revealed a fluctuation of rice yields between 2010 and 2012 from 1 28 to 9 56 tons ha per year other rice yield data from the sapa region showed lower average values for the same time period 0 4 tons ha per year less according to data from the legato 1 1 land use intensity and ecological engineering assessment tools for risks and opportunities in irrigated rice based production systems http legato project net project and 0 6 tons ha per year lower according to inventories published by the general statistics office 2 2 https www gso gov vn of vietnam gso table 1 nevertheless it is important to emphasize that in the sapa district rice is cultivated on slope lands where nutrient rich soils are more scarce and the local climate is more extreme than in agricultural lands in the downstream areas of the lao cai province nguyen et al 2011 it is obvious that the rice production here is lower than the mean rice yield values in the rest of the lao cai province the rice yield data based on interviews represent the fluctuations of the upland and irrigated rice production in the sapa district according to the inventory data of irri 2006 the mean of rice yields in sapa corresponds with the rice yields in mountainous areas recorded in asian countries with fluctuations from 1 5 to 4 tons ha per year in average compared to the inventory data of gso the yields recorded in 10 paddy plots in the case study area are higher than the average yield 7 2 tons ha per year in other agricultural regions in vietnam the increase is based on the use of more intensive farming methods such as fertilization and new seed choices it is assumed that nearly 50 of the 200 paddy sample plots fig 1 with yields lower than 3 5 tons ha per year are related to poor site selection and or ineffective farm management methods 3 2 environmental variables in order to generate effective models to predict areas suitable for rice cultivation at different scales the most effective predictor variables related to environmental and socio economic conditions need to be selected this process should eliminate non relevant variables and improve the interpretability of final models bui et al 2017 the correlations of relevant non relevant variables with rice yields have been identified by a pearson comparison before any variable was used in the prediction models the eight environmental variables considered in this study include elevation meter slope degree soil erosion ton ha per year sediment retention ton ha per year length of flow meter water yield millimeter ratio of evapotranspiration aet to precipitation p and topological wetness index twi table 2 the topographical variables including elevation slope erosion and sediment retention determine the distribution of soil nutrients the hydrological variables water yield ratio of evapotranspiration to precipitation twi and length of flow describe the water resources potentially available from irrigation activities dang et al 2018 these eight environmental variables were used to define crop suitability areas at regional scales and to predict potential rice yields at plot scales the three topological variables elevation slope and length of flow fig 2 were calculated from a digital elevation model dem of the research area the dem is based on four topographical maps with a resolution of 10 m the topographical maps were collected in digital format from the vn 2000 national coordinate system the contour lines were extracted from these maps and converted to the wgs 84 coordinate system before being used to extrapolate the dem for the whole case study region three variables with special relevance in mountainous areas like the sapa region are i elevation ii slope and iii length of flow all three variables strongly influence the climatic such as temperature precipitation and humidity and topographic characteristics this again leads to indirect changes in water and nutrient availabilities for rice growth irri 1978 the variable length of flow determines the downhill runoff distance from each plot to the nearest reservoir in downstream areas tesfa et al 2009 paddy plots with low values of flow length are located near water reservoirs such as rivers and outlets in contrast high values of flow length indicate paddy plots which are located in upstream areas far from downstream reservoirs they are characterized by high flow intensities steep slopes and shallow soils mixed with pebbles and gravel chang 2003 soil nutrient enrichment in the upstream areas can be slower than those in downstream areas renaud and kuenzer 2012 thus nutrient and water availabilities in areas used as paddy plots could be inversely proportional to the length of flow in order to demonstrate the important role of this variable its correlation with rice yields is presented and discussed in detail in the result section regarding the nutrient availability in soils erosion and sediment retention fig 2 are crucial processes that strongly influence the deposition of fertile material on paddy fields in detail soil erosion is defined as the loss of top soil by wind or runoff pimentel 2006 resulting in soil degradation erosion processes can detach and move soil particles to downstream areas leading to the reduction of fertile materials in upstream areas wischmeier and smith 1958 for example steep areas with sandy soils and high precipitation become more vulnerable to erosion compared to flat areas with clay soils and low precipitation wischmeier and smith 1978 these variables have been determined by simulating the sediment retention with a sub model developed as part of the tool invest 3 0 integrated valuation of ecosystem services and tradeoffs sharp et al 2014 by dang et al 2018 the two resulting data sets have a resolution of 20 m sediment retention is the amount of materials trapped on topsoil layers retention is affected by topographical factors and land covers sharp et al 2014 because of its important role in determining the quality and quantity of nutrients in the topsoil this variable has been selected for the prediction models the amount of sediment retained can be quantified as the gap between the incoming and exported sediment on each plot vigerstol and aukema 2011 the quantity of soil nutrients retained is noticeably dependent on the type and volume of materials in the deposited sediment schmitter et al 2010 therefore the correlation of sediment retention with rice yields can be positive or negative depending on the type of incoming materials slaets et al 2015 if the amount of unfertile materials trapped in a plot is higher than the fertile ones the level of suitability for rice cultivation in that plot is lower in contrast the plots retaining more fertile materials might be more suitable for cropping rice in the research area the high amount of un weathered geologic materials maintained from the depositional processes nguyen et al 2011 can reduce the fertility of soils leading to changes in rice yields regarding hydrologic and climatic variables the water yield represents the amount of water unavailable for rice growth through both ground and surface water whereas the ratio of evapotranspiration to precipitation fractp partly explains the quality of water and nutrient transports in rice plants two variables have been simulated with a spatial resolution of 20 m 20 m with the reservoir hydropower production model in the invest 3 0 tool sharp et al 2014 water yield is known as the water extracted from a landscape that also contributes to other landscapes in downstream areas sharp et al 2014 the increase of water yield does not only erode alluvium from the topsoil but also reduces the water uptake of rice plants the amount of water yield in the whole region was calculated through a budyko curve 1974 based on the following equation 1 water yield x 1 a e t x p x p x where aet is the actual yearly evapotranspiration and p is yearly precipitation in the reservoir hydropower production model of invest the ratio fractp of actual annual evapotranspiration aet to precipitation p is calculated based on the following equation proposed by fu 1981 and zhang et al 2004 2 f r a c t p a e t x p x 1 p e t x p x 1 p e t x p x w 1 w where pet is the potential evapotranspiration of different land cover types according to local climatic conditions and w is an empirical parameter related to soil properties the potential evapotranspiration was calculated through the use of a temperature and soil database table 2 the database of soil thickness and particle sizes extracted from the soil map was used to identify the w parameter based on the expression of donohue et al 2012 integrated in the reservoir hydropower production model through the aggregation of two important climatic factors the fractp ratio has been commonly used as an indicator to assess the water energy balance in a particular land use cover over a long term timescale budyko 1974 lu et al 2005 firstly the evapotranspiration factor represents the loss of water from the soil surface by evaporation and from crop by transpiration that contributes to the transportation process of nutrients from the roots to other plant tissues allen et al 1998 doorenbos and kassam 1979 have described the positive correlation between rice yields and evapotranspiration recently various studies demonstrate that the reduction of evapotranspiration can prevent water and nutrient transports through plants leading to the reduction of rice yield in different time scales alberto et al 2011 steduto et al 2012 secondly the precipitation factor plays an important role in triggering soil erosion in slope lands sharp et al 2014 in upland rice production irrigation water from rainfalls is commonly kept in upstream reservoirs and directed toward paddy plots in downstream areas raindrops falling down in a particular paddy plot can detach and move soil particles leading to the increase of soil erosion and the decrease of topsoil nutrients wischmeier and smith 1978 according to relations between rice production and climatic factors the fractp variable was used to develop yield prediction models as an indicator of soil moisture the topographic wetness index twi has been proposed by sørensen et al 2006 this variable can represent the flow accumulation of corresponding landscapes and assesses the amount of water available for rice production in a whole region therefore it was chosen for this analysis the twi was calculated based on the following equation 3 t w i l n a t a n β where a is the accumulated flow β is the slope wetlands or floodplains have higher values of twi whereas lower values are found for example in ridges in contrast with water yields known as amount of water outputted extracted from a particular plot the flow accumulation a is the amount of water inflows from upstream regions to each downstream plot one hypothesis would be that the higher the twi is the higher the rice yield is according to the gis analysis and the invest model application the calculations of eight variables no 2 until no 7 as listed in table 2 were converted to a spatial resolution of 20 m 20 m for the whole sapa region 3 3 socio economic variables during the semi structured interviews carried out in 2010 2015 and 2016 further production related data besides rice yields were collected for the 200 sample plots fig 1 the interviewed persons were household heads of farms and their knowledge was harnessed to reveal the productivity of rice terraces in particular areas owners of terraced rice fields identified the locations of their fields on fine resolution satellite images based on the interview results three significant variables related to human activities were identified financial investments of each household and the amount of compound and straight fertilizers used in order to improve nutrient availability npk fertilizers compound fertilizers containing all three primary components nitrogen phosphorus and potassium and straight fertilizers such as nitrogen phosphorus and potassium separately that are required for healthy rice growth environ et al 2014 are applied due to extreme nitrogen shortages in the soils urea is spread as a main straight fertilizer in the case study region other types of straight fertilizers used in a few paddy plots were not considered in this study the socio economic data collected at the 200 paddy plots could only be used to predict the yield potentials at plot scales the details of using such data in yield assessments will be discussed in the next sections the location information or gps coordinates of the paddy plots corrected by authors was used to link the plots to the environmental information from available spatial data the efficiency of farming practices highly depends on the amount of fertilizers pesticides seeds and equipment used however the farmers could unfortunately not provide sufficiently detailed information on their management inputs therefore the variable financial investment was used as a bulk indicator for all kinds of additional inputs to represent the management efforts of local farmers on their paddy plots 4 modelling process the study aimed at creating a joint homogenous indicator dataset covering the whole sapa region with a spatial resolution of 20 m 20 m this dataset was used to identify sites of naturally high productivity e g indicators no 2 until no 8 table 2 these sites were expected to be promising for an efficient use of farming methods i e indicators no 9 until no 11 table 2 ensuring high probabilities for high rice yields i e indicator no 1 table 2 this homogenous dataset was available for the 200 sample plots with a size of 100 m2 the data were used as a basis to develop linguistic rules for the creation of a homogenous database for the whole sapa region altogether 75 of the basic data set was used to develop the linguistic rules and 25 of the basic data set was reserved for the validation process 4 1 background of model validation the model validation process was performed in different steps complementary to the hyfis development see section 4 2 the prediction models always need to be trained especially with the use of neural networks in machine learning processes jabjone and wannasang 2014 in order to assess the performance quality of trained models different kinds of testing indices have been developed for the validation process the combination between neural networks and fuzzy logic can be developed from statistical measures bergmeir and ben 2015 various goodness of fit tests and prediction power assessments such as overall accuracy positive predictive value ppv negative predictive value npv specificity true positivity rate or sensitivity false negative rate in equations 4 6 below can be used 4 overall accuracy acc t p t n t p t n f p f n 5 sensitivity t p t p f n specificity t n t n f p 6 ppv t p t p f p npv t n f n t n where tp is the number of correct true positive points and tn is the number of correct true negative points between predicted and observed data fp is the number of incorrect false positive points and fn is the number of incorrect false negative points between predicted and observed data these values can assess the performance of a prediction model in positive value of 1 or negative value of 0 cases fawcett 2006 in detail the value of acc represents the probability of successful predictions and is calculated as the number of points where both 0 and 1 values are predicted correctly divided by the total number of testing points compared to the total number of predicted points the positive predictive value ppv is the successful probability of prediction corresponding to the points with the 1 value whereas the negative predictive value npv is the successful probability of prediction corresponding to the points with the 0 value compared to the total number of observed points sensitivity is the probability of correct points with the 1 value whereas specificity is the probability of correct points with the 0 value newlands et al 2016 to assess the efficiency of iterative processes bui et al 2016 the receiver operating characteristic roc curve and area under the curve auc values have recently been used to validate machine learning models ajaz and campus 2015 in detail the roc curve and auc values can partly measure the predictive power of model outcomes both of them refer to the sensitivity and specificity of model outcomes that means that for example good auc values fluctuate between 0 5 and 1 auc values of 0 5 0 7 indicate a poor model auc values of 0 7 0 8 indicate a moderate model and auc values of 0 8 0 9 indicate a good model auc values of 0 9 1 indicate excellent models fawcett 2006 4 2 the training process of hybrid neural fuzzy inference systems using gis this section explains the artificial intelligence approach based on a neural fuzzy inference system that was used to define areas suitable for rice cultivation at the regional scale and to estimate potential rice yields at the plot scale corresponding to the two spatial scales of this study two hyfis models were developed with the same structure at the regional scale a site selection hyfis model abbreviated by s hyfis considers eight environmental input variables as listed in table 2 to map areas suitable for rice cultivation at the plot scale a complementary integrated hyfis model abbreviated by i hyfis considers besides the eight environmental input variables used in the s hyfis model additionally three socio economic variables as listed in table 2 to predict potential rice yields the structure of the two proposed models is shown in fig 3 the modeling procedure was carried out in five steps including database preparation 1 training 2 optimizing 3 validating models 4 and assessing the performance 5 of final models the formal hyfis models were implemented via the frbs package bergmeir and ben 2015 in the r studio environment version 1 0 136 the optimization process was based on iteration and programed by the authors the spatial analysis was carried out in arcgis 10 2 regarding the integration of the hyfis models into the gis environment all input data raster maps were converted to comma separated values containing latitude and longitude information of each pixel after all results were obtained in the hyfis models the output data were converted back to raster format to be used in arcgis 4 2 1 step 1 preparation of site selection and set up of an integrated database for the training and testing processes in the first step the predictor variables mentioned in sections 3 2 and 3 3 covering eight environmental and three socio economic variables need to be analyzed by their pearson correlations with the target variable rice yields if the predictor variables have statistical significance to explain the variance of rice yields these variables are selected for the next step after normalization to values ranging from 0 01 to 1 00 the normalization reduces the bias between the input variables used in the prediction models the correlations were analyzed with data for 200 sample plots collected in the years 2010 2012 based on the coordinates for these 200 plots all data could be linked to the maps of the eight environmental variables as described in section 3 2 hence 200 plots containing full environmental and socio economic data were analyzed to check their correlations with rice yields for the proposed modeling process based on fuzzy logic a binary classification for the rice yields variable in the two values 0 and 1 is required 0 indicates unsuitability of areas for rice cultivation in the s hyfis model and low potential for high rice yields in the i hyfis model 1 indicates suitability of areas for rice cultivation in the s hyfis model and high potential for high rice yields in the i hyfis model according to irri 2006 if farming practices such as fertilization and pesticide use are not applied the potential of yields for upland rice in asian countries is estimated to range from 3 to 3 5 tons ha per year hence the locations of 102 paddy plots where recorded yields were higher than 3 5 tons ha per year were classified by the value of 1 whereas the 98 plots with lower yields were classified with the value 0 therefore the output of the two models ranges from 0 to 1 the outcomes near 1 indicate the suitability of areas for rice cultivation in the s hyfis model or the potential for high rice yields in the i hyfis model values near 0 represent areas unsuitable for rice cultivation in the s hyfis model or low potential for high rice yields in the i hyfis model in order to test the performance of the developed models the 200 plots for which complete datasets were compiled were randomly divided into two data sets training and testing the testing data set consists of 25 or 50 plots of all plots while the training data set consists of the remaining 75 or 150 plots the testing dataset was used during the validation process because it has not been used to train the models this allowed us to compare the trained model outcomes with observations in the testing data set in order to assess the accuracy of the results liu et al 2010 4 2 2 step 2 knowledge learning and design of the fuzzy inference system in hybrid models this step focused on constructing a conceptual fuzzy inference systems integrated in hyfis models for training purposes in this study the if then rules of the fuzzy structure followed the mamdani inference model proposed by mamdani 1977 the fuzzy structure contains four layers corresponding to four components of the mamdani model fig 4 in the conceptual hyfis model functions in the fuzzy inference systems were used in this study to calculate the weights for neural networks whereas neural networks are applied to train fuzzy inference systems neural networks will automatically learn new relationship from new input data to identify suitable fuzzy rules and select suitable membership functions four layers of the fuzzy logic were replaced for unknown hidden layers as developed in traditional neural networks the first layer is designed to transform input data from crisp values to linguistic ones whereas the fourth layer produces numerous outcomes from linguistic values all input variables in the hyfis models are normalized to a same range from 0 to 1 therefore the outcome values were calculated in a range from 0 to 1 the two layers in the middle compose fuzzy rules and membership functions the inference engine of the fuzzy inference system in the s hyfis model can be explained in detail as follows layer 1 fuzzification layer in this layer the input environmental variables of the given numerical data were separated into fuzzy regions associated with linguistic terms the number of linguistic terms depends on the length of the fuzzy regions and represents the variance of rice yields then the linguistic terms were assigned to fuzzy membership values in the fuzzification process in this process the gaussian membership function in equation 7 was implemented for each input variable with two initial parameters variance and standard deviation 7 μ 1 k e x p x c 1 k 2 2 δ 1 k 2 where μ is the gaussian membership function for input variables δ is the variance parameter and c is the standard deviation of the function k is the total number of linguistic terms for eight input variables two initial parameters δ and c were adjusted by using gradient descent based learning algorithms bergmeir and ben 2015 these parameters converge to local optima and are more sensitive to membership values in the end of this layer the membership functions and values were calculated for all training data in order to minimize the number of if then rules in layer 2 and to maximize the accuracy of outcome models the number of linguistic terms was optimized through an iterative process presented in step 3 layer 2 rule antecedence layer this layer performs the appropriate fuzzy rules between input and output in training data and determines a strength value for each rule or the relative membership values the number of nodes in this layer equals the number of fuzzy if then rules generated for the training data in the preceding step for instance in layer 1 of fig 4 the input variable x1 has three linguistic terms r 1 1 r 1 2 and r 1 3 whereas the input variable x8 has two linguistic terms r 1 k 1 and r 1 k in this case the nodes r 1 1 and r 1 k 1 decide on the membership function for node r 2 1 in layer 2 which represents the outcome y1 is unsuitability areas then their connections represent the rules if x1 is r 1 1 and x8 is r 1 k 1 then y1 is unsuitability areas and if x1 is r 1 3 and x8 is r 1 k then yi is suitability areas the process was repeated for each instance of the training data to generate fuzzy rules the strengths of these rules were calculated based on the hamacher operation bergmeir and ben 2015 for instance the membership function for the first rule of layer 2 in fig 4 was as follows 8 μ 2 1 μ 1 1 μ 1 k 1 μ 1 1 μ 1 k 1 μ 1 1 μ 1 k 1 layer 3 rule consequent layer this layer yields final rules by removing redundant rules the distinct concept in this layer is the aggregation of rules created in the second layer the strength of each rule concept is decided by aggregating the strengths of membership functions in the antecedent layer in this case the maximum operation was used to delete the redundant rules having lower strengths for example in fig 4 the first two nodes r 2 1 and r 2 2 in the second layer determine the rule and the membership function of the node r 3 1 in the third layer then its activation function will be 9 μ 3 1 max μ 2 1 μ 2 2 layer 4 rule inference and defuzzification layer this process transforms linguistic terms into numerical values to create the final model output values by using the modified center of gravity cog method it also determines the final linguistic terms for the output variables for example the first two nodes r 3 1 and r 3 2 in the third layer decide the first node r 4 1 in the fourth layer then the strength of the first fourth layer node is calculated by following equation 10 μ 4 1 μ 3 1 y 3 1 μ 3 2 y 3 2 μ 3 1 μ 3 2 where the y is value of each rule consequent node the inference engine of the fuzzy inference system in the i hyfis model operates with the same layers as in the s hyfis model but the number of if then rules and weights of the i hyfis model were changed due to the additional socio economic variables that were added therefore the development of the two hyfis models was done in two different iteration processes mentioned in section 4 3 3 in four layers of the hyfis models the number of linguistic terms k and the values of two initial parameters variance and standard deviation can impact the weights of antecedent and consequent rules in layers 3 and 4 and then the accuracy of the outcome kim and kasabov 1999 in other words the values of the membership functions in four layers are dependent on the variance of two initial parameters and the number of linguistic terms and need to be learned optimized in order to obtain well designed if then rules 4 2 3 step 3 and 4 modeling optimization based on iterative processes and model evaluation once the framework of the neural fuzzy network was constructed the iterative and testing processes were launched to identify the best position and length for fuzzy regions in the first layer of step 2 in the iterative process the number of linguistic terms was tested from three to nine in order to find out the optimal value that can minimize the number of if then rules at 150 rules and maximize the performance of hyfis models at 85 the lower the number of if then rules the better is the performance of outcome models bui et al 2017 regarding the two initial parameters variance and standard deviation their values were changed based on the fluctuations of initialized fuzzy regions in each iteration leading to changes in the values of membership functions and if then rules bergmeir and ben 2015 then the testing dataset was used to assess the goodness of fit of the trained hyfis models by calculating the mean square errors and the auc values the values of mean square errors mse which are commonly used to assess the iteration process omez et al 2010 were calculated with the following equation 11 m s e 1 n i 1 n p r e i o b s i 2 where n is number of plots considered in the training data or the testing data obsi indicates observed values in the testing data and prei are the predicted values produced by the trained models in the optimal position of initial parameters and numbers of linguistic terms the gap between predicted outcomes and observed values is smallest however the mse values could not totally explain the performance of the trained models fluctuations of the auc values were found in the models that have the same mse values therefore the auc value was used for assessing the accuracy of the trained models in parallel with the mse value in each iteration the final model needed to have the highest auc value and the lowest mse value based on the mse and auc values the number of iterations was terminated at 500 to fully represent the fluctuation of the two initial parameters benmiloud 2012 in the testing process the authors could not find more accurate models in cases of higher numbers of iteration 4 2 4 step 5 assessment of final hyfis models in this step the final s hyfis and i hyfis models with the highest auc values and lowest mse values were evaluated to estimate their goodness of fit using testing data and calculating seven statistical values acc sensitivity specificity ppv npv mse and auc in order to demonstrate the advantage of the developed hyfis models these models were benchmarked with alternative models methods this included a support vector machine svm and a logistic regression model simulated as generalized linear models glm and programmed in r both models are known as powerful tools in machine learning used in agricultural and social studies ajaz and campus 2015 to explain the probability of a binary variables 1 and 0 depending on explanatory variables eight environmental explaining variables and the target variable rice yields selected from the training data were used to generate the benchmark svm and glm models all goodness of fit tests and the prediction power assessment which were used for the developed hyfis models were also applied for the svm and glm models in order to indicate the efficiency of the different models to map areas suitable for rice cultivation in the sapa region whereas the logistic regression model is commonly used to estimate the probability of binary variables in agricultural fields ali et al 2012 sattaka et al 2017 svms have been recognized as robust supervised learning models in classification and regression analysis during the last decade armstrong 2016 balakrishnan and muthukumarasamy 2016 su et al 2017 in this process the same training and testing data sets to develop the final s hyfis model were used for both logistic regression and svm models the package e1071 was used to run the svm model in r in particular the outcome of the svm models depends on the parameters in the c classification such as a cost of constraints violation c and an epsilon in the insensitive loss function karatzoglou et al 2006 the kernel type used in the training and predicting processes was radial option to select suitable parameters the testing process based on the changes of auc and mse values was implemented finally the values of c and epsilon were chosen respectively at 1 5 and 0 5 for the most effective svm model the performance of these models is shown in the results section based on the comparison between the four models the study identified two optimal models with the best goodness of fit to predict the potential of rice yields on the plot scale and to map areas suitable for rice cropping at the regional scale based on the eight environmental variables as input data table 2 the s hyfis model has extrapolated the suitability of areas from the plot scale to the regional scale the extrapolation process of the s hyfis model identified the suitability unsuitability of areas based on the similarity of environmental characteristics in the whole case study area the map of crop suitability areas was validated by 17 independent plots provided by the legato project as mentioned in section 3 1 in this project scientists collected straws and grains from 17 paddy plots and then weighed the amount of dried rice grains to calculate rice yields at each plot 14 high yield and 3 low yield plots were recorded the locations of these plots provide important data to cross check the accuracy of the s hyfis model if the outcomes of the s hyfis model is correct the high yield plots collected from the legato project need to be located in suitable areas and the low yield plots need to be located in unsuitable areas socio economic data were not collected at these plots therefore these plots can only be used to check the accuracy of the s hyfis model finally in order to assess the potential of rice expansion in the case study area the areal percentage of areas suitable unsuitable for rice cultivation predicted from the s hyfis model were counted in seven different land use cover types including the paddy fields land uses cover types having highly suitable environmental characteristics for rice cultivation can be suggested for agricultural conversion regarding the potential of rice yields predicted through the i hyfis model at the plot scale the accuracies of results were only assessed at the 200 observed plots through percent error values following this equation 12 percent error value predicted value observed value 100 percent error values higher than 50 could identify plots predicted incorrectly from the i hyfis model to make the results easy to observe each paddy plot is conveniently visualized within a single point on the map 5 results 5 1 pearson correlation between predictor variables and rice yields the input data were analyzed in order to eliminate non statistical significant variables of the chosen predictor variables to explain the rice yield as a response variable the high yield paddy plots were compared with the low yield ones by eight environmental variables and three socio economic variables through boxplots and by calculating the pearson correlation values shown in fig 5 out of the eight spatial input variables used as main inputs for the s hyfis model see table 2 the slope length of flow and sediment retention variables have the strongest correlation values of 0 4 0 34 and 0 3 respectively the variables soil erosion elevation and water yield follow with correlation values of about 0 2 the ratio of evapotranspiration to precipitation fractp and the topological wetness index twi were the poorest predictive variables with low correlation values of 0 16 and 0 11 the indicated low yield areas appeared in cases where rice was cropped on sites with high erosion susceptibility situated on steep terrains and or on high altitudes although a higher altitude for agricultural lands can be identified at 1100 m the contribution of the variable elevation does not fully and adequately explain the increase of rice yields with decreasing altitude hence farmers need to consider further environmental variables such as slope lower than 13 water yields lower than 700 mm and length of flow less than 6 km to have high probabilities to harvest higher rice yields the three socio economic variables used in the i hyfis model correlate to about 0 5 with rice yields fig 6 according to this result the additional inputs related to farm management practices have remarkably influenced the rice production especially in the case of fertilizers nevertheless the amount of investment should range from 5 to 6 million vnd equal to more than 200 eur per hectare to achieve high yields on suitable plots however the effective amount of fertilizers should be limited to 180 kg of compound fertilizers and 130 kg of urea for 1 ha for high yield plots in the case study fig 6 5 2 final s hyfis and i hyfis models table 3 depicts the structure of the two final hyfis models in the case study area eight environmental variables were considered as the inputs for the s hyfis model to assess the suitability of areas for rice cultivation three socio economic variables were added to develop the i hyfis model to predict the potential of rice yields in the iterative process the optimal number of linguistic terms in both hyfis models was chosen to be eight if the number of linguistic terms is lower higher than eight the performance of hyfis models assessed through the auc and mse values is reduced hence the s hyfis model generated 148 if then rules based on 128 initial parameters whereas the i hyfis model had 149 rules based on 176 initial parameters see more in section 4 2 2 according to the iterative processes described in section 4 2 3 and in fig 7 the optimal values of initial parameters were chosen through the values of auc and mse the mse mean of the i hyfis model from 0 07 to 0 35 in the iteration process was lower than the one of the s hyfis from 0 15 to 0 55 as shown as a linear fluctuation of the auc values the predictive ability of the i hyfis model was higher than the s hyfis model from 3 to 6 based on the goodness of fit test the chosen s hyfis model has an auc value of 0 88 and a mse value of 0 14 see table 4 the positive predictive value ppv of this model reaches 0 74 or in other words the probability of finding a suitable plot for crop cultivation value of 1 is 74 complementarily the negative predictive value npv reaches 0 96 explaining that the probability of finding a plot unsuitable for crop cultivation value of 0 is 96 the accuracy of the suitable plots was 94 as shown by the value of sensitivity whereas the accuracy in predicting unsuitable plots was 81 as shown in the value of specificity the predictive power of the s hyfis model was also illustrated by the acc value of 0 86 and the kappa index of 0 71 the best i hyfis model chosen from the iterative process has the overall accuracy acc value of 90 with an auc value of 0 9 and a mse value of 0 1 which is higher than the accuracy of the s hyfis model the probabilities of finding a plot with a high value of 1 or low value of 0 yield potential are both 88 shown in ppv and npv values of 0 88 the accuracy of each finding is 92 shown in the values of sensitivity and specificity besides the overall predictive power of the i hyfis model estimated through the acc value of 0 9 and the kappa index of 0 8 was higher than for the s hyfis model the i hyfis model can be run for the whole region or for regional scales if the socio economic variables are provided for the same scale in this study the three socio economic variables were not available for the whole sapa region therefore the i hyfis model could only predict potential rice yields at the plot scale for the mapping of the areas suitable for crop farming at the regional scale the accuracy of the final s hyfis model was compared with the accuracies of the svm and glm models the accuracies of the two benchmark models are illustrated in table 4 the predictive powers of the glm and svm models shown in the values of ppv npv acc and auc seem to be lower than those of the s hyfis model the kappa indices in the s hyfis model and the svm model were almost the same with about 0 7 in average whereas the kappa index of the glm model was 0 6 although the three models are applicable to map areas suitable for rice cropping in the whole case study area the proposed s hyfis model seemed to be the most reliable model due to its high accuracy 5 3 mapping areas suitable for rice cropping in sapa the areas suitable for rice cropping are shown in fig 8 the areas were mapped based on the application of the final s hyfis model for the whole case study area to distinguish between areas that are suitable unsuitable for rice cultivation the outcomes of the s hyfis model ranging from 0 to 1 were classified into four classes these classes include low values lower than 0 3 corresponding to 30 of the total area medium values from 0 3 to 0 8 or 26 of the total area high values from 0 8 to 0 95 or 14 of the total area and very high values higher than 0 95 or 30 of the total area suitability for rice cultivation in order to validate the results 17 independent plots provided by the legato project were used within these plots 14 high yield plots were located correctly at high and very high suitability plots whereas 3 low yield plots were located at medium and low suitability plots according to this result the areal percentage of high and very high suitability areas in the ta van basin seems to be equal to those in the ngoi dum basin the high and very high potential areas for agricultural development were found along rivers and streams in the ta van lao chai and ta phin communities areas with low potentials were found in more than 4000 ha of upstream areas in sapa center trung chai sa pả hau thao and san sa ho communities corresponding to 35 of the total area in these communities accordingly agricultural development should not be expanded to upstream areas of the mountainous communities the potentials of predicted rice yields based on the final i hyfis model were compared at 200 observed plots as shown in fig 8 because the three socio economic variables were only recorded for these 200 plots the i hyfis model was not used to estimate the potential rice yields at the regional scale potential yields at eight plots were predicted by the i hyfis model with the percent error values higher than 50 while other eight plots have errors from 5 to 50 nearly 94 of all paddy plots could be correctly identified by this model with errors lower than 5 especially with plots in the ta van basin the high percent error values more than 50 were mostly found in the ngoi dum basin according to the performance of the i hyfis model farmers can consider an appropriate amount of fertilizer about 180 kg ha per year of compound fertilizers and 130 kg ha per year of urea and investments of about 5 6 million vnd required to have good chances for high yields on high suitability plots 5 4 suitability areas for rice cultivation in different lulc types fig 9 depicts the suitability of current paddy plots and the potential of future agricultural development in other lulc types based on the calculations with the s hyfis model accordingly about 16 or 430 ha of current sites cropped with rice were classified as areas with a low suitability while about 70 or 1900 ha of the current rice fields were characterized as areas with a high and very high suitability for the production of rice though there are still areas with a size of 4100 ha classified as areas with high suitability for cropping rice the transformation of these land uses to rice cultivation should be analyzed carefully the suitability areas were identified particularly in 40 about 4600 ha of forest areas this addresses also highly low sealed surfaces where about 50 of these areas have been indicated as highly suitable for rice production these areas include houses that are distributed heterogeneously among paddy fields however the area of highly low sealed surfaces is not so large nearly 250 ha in total leading to uncertainties in the assessment that will be discussed in the next sections different rationales concerning the conversion of the land use types bare soil and meadow 40 respectively 30 classified as highly suitable are to be expected the 700 ha of meadows and bare soils could be used for agricultural development their extension is larger than the total area of water bodies highly sealed surfaces and sealed surfaces in total more than 3200 ha including the high and very high suitability areas of current paddy plots meadow and bare soil could be used for rice cultivation in comparison to the present situation with more than 2700 ha paddy fields nearly 1900 ha with high and very high suitability were identified for rice cropping the areas with low suitability calculated with the s hyfis model cover more than 5500 ha of the research area in which the forest areas occupy about 4500 ha 6 discussion 6 1 application of hyfis models compared to previous prediction models such as neural networks e g by dahikar et al 2015 and svm model by jaikla et al 2008 the hybrid neural fuzzy inference system could be a promising model or alternative option for software developers and agricultural scientists to map areas suitable for rice cropping at the regional scale and to predict potential rice yields at the plot scale as a main limitation of hyfis models the operating principle in the hyfis models seems to be more complicated than in other models the developers need to have a good understanding of the combination between neural networks fuzzy inference system and gis although different optimization methods developed in mathematics bui et al 2017 have been used to optimize the two developed hyfis models the traditional iterative method chosen in this study made the training process more effective and simple as only the value sets of two main initial parameters variance and standard deviation mentioned in section 4 2 2 that needed to be trained however the quality of the iterative process needs to be assessed by both auc and mse values allowing to determine optimal values of 0 9 and 0 1 respectively for the final models according to the calculated goodness of fit tests and prediction power values the two proposed hyfis models provide more precise results than other benchmark methods such as svm and glm both hyfis models can be used to predict potential rice yields at plot scales but the results from the i hyfis model seem to be more precise the potential of rice yields as shown in the outcome of the i hyfis model is a result of the rice cultivation in suitable unsuitable cropping areas based on environmental variables and the effective ineffective use of farming practices based on socio economic variables nevertheless both hyfis models have not fully demonstrated whether or not the farmers can reduce financial investments and fertilizer inputs if they choose more suitable areas for rice cultivation or whether they need to use more supplemental nutrients for fertilization if they want to cultivate rice plants in unsuitable areas land suitability evaluation for rice cropping mapped at the regional scale as done using the outcomes of the s hyfis model can provide better land use strategies to local famers irri 1982 the s hyfis model requires many kinds of input data such as topographic hydrologic climatic and soil databases as well as the information on farming practices however these databases can represent multidimensional impacts of the social ecological system on rice ecosystems arnáez et al 2015 hoang 2014 li et al 2015 according to the results the locations of other land uses cover types can provide a lot of useful information related to water and nutrient supplies in agricultural development and sometimes even much more than those of paddy fields many parts of the case study area that are characterized by sealed surfaces bare soils and water bodies could for instance take full advantage of rice cultivation for example more than 1200 ha of meadow and bare soil areas in the high and very high classes fig 8 could be considered as suitable rice farming places replacing more than 400 ha of paddy in the low suitability class this would not only protect the green mountainous land but also help prevent erosion and balance ecological functions the potential of land use cover change will be discussed in the following section so far the application of the i hyfis model is restricted to the 200 plots used as training and testing sites in this study therefore the i hyfis model could only be powerful in a small number of plots the use of the socio economic variables could be applied for the whole region if we would assume that the other plots with the same environmental characteristics would also have the same amounts of additional anthropogenic inputs an extrapolation from the plot scale to the regional scale would require more information about farming practices or related socio economic data which depend on financial conditions of each household and tradition and behavior of farmers under certain environmental conditions it would however be a time consuming work for managers to collect socio economic data at every paddy plot from the farmers in this case managers need to consider other ways to receive better information such as the use of the bayesian belief network approach dang et al 2018 the bayesian networks allows to use measured data from fields data from farmer interviews and expert data from scientists therefore it can be easily updated from other networks and be reproduced by new knowledge from other studies bayesian networks however could not be used for mapping at different scales that can be easily done by the hyfis models 6 2 potential of land use cover change in sapa urbanization processes with the expansion of sealed surfaces have decreased the number of suitable areas for cropping kamoshita 2007 if local managers would like to take full advantage of favorable environmental conditions in the study area bare soils in the sealed surface land use areas could be changed to appropriate urban agricultural systems focusing on rice production as proposed by sharp and smith 2003 and kamoshita 2007 the key point of the urban agricultural systems is the selection and creation of areas that have environmental characteristics favorable for crop cultivation around and within urban areas it does not only provide more rice for urban residents but also reduces costs of food transportation from outside regions to urban areas midmore and jansen 2003 mita 1993 these systems have been developed in tokyo since the 1900 s japan kamoshita 2007 muñoz vallés et al 2013 has demonstrated that a suitable urban agricultural system can help to improve food security in highly densely populated areas to decrease air temperature in urban areas and to provide recreational and educational benefits nevertheless trade offs between urbanization and agricultural development need further studies using an integrated approach if urban agricultural systems are to become more likely in the case study area regarding water bodies and forest areas the study has identified high low suitability areas for rice cultivation that were distributed rather heterogeneously rice can be well cultivated in narrow areas around water bodies such as riverbeds and riverbanks because of the high potential of water availability however rice cultivation in such types of land cover contains high risks of erosion due to increasing water levels during the rainy season especially in narrow valleys nguyen et al 2011 the allocation of forest lands for agricultural purposes needs to be done very carefully and large forest areas are actually unsuitable for rice cultivation additionally the national law in vietnam related to forest protection restricts the conversion of forest land to other land uses hence quite the contrary regulations and incentives for reforestation need to be implemented for example a conversion of nearly 500 ha unsuitable agricultural lands to forests in related communities could be a sustainable solution in the case of the current rapid urbanization in the sapa region additionally the conversion of other land use cover types to arable lands and vice versa need to consider environmental issues such as climate and erosion regulation as well as wood and freshwater provision dang et al 2018 demonstrated that many paddy fields on terraces have not been an appropriate land use to mitigate risks of soil erosion and landslides in mountainous areas the excessive use of pesticides fertilizers in rice cultivation can increase the amount of nitrate and toxic products leaching into the soil and groundwater groundwater is commonly used as a freshwater source by vietnamese people living in mountainous areas lichtenberg 2013 heong et al 2015 forest areas have been ranked as ecosystems with a high potential to slow down processes of climate change and soil degradation fao 2010 ipcc 2006 urban areas such as the town of sapa have mainly been developed for tourist and administrative purposes hoang 2014 the local people there have usually enough money to import rice instead of implementing rice expansion hence trade offs between benefits obtained from forest and urban ecosystems and rice production in mountainous areas are often not strongly considered particularly in the sapa district the local people working on areas that are unsuitable for rice cultivation can find better fields in the meadows and the bare soils or alternatively choose to import rice from other regions 6 3 uncertainties of the study this study included several assumptions as well as model and data shortcomings which need to be mentioned here and should be considered in comparable future studies firstly the socio economic variables used in this study have not depicted all types of additional anthropogenic inputs for example effects of seed choices and pesticide uses as well as other environmental impact factors need to be quantified in order to better understand variances of rice yields secondly the models were trained on data collected in upland and irrigated rice ecosystems commonly found in the mountainous areas of the sapa region thus these data are applicable only to a limited extent for lowland and flood prone rice ecosystems impacts of topographical and hydrological characteristics on rice production vary from plot to plot thus the prediction of suitable cropping areas based on the s hyfis model can be less certain in regions in which no training data for rice cultivation was available this is especially problematic in lowlands with lengths of flow less than 5 km and elevations lower than 900 m as well as in upstream regions with lengths of flow higher than 8 km and elevations lower than 1300 m thirdly some primary data were used twice to calculate input variables for the hyfis models the interaction effects between these input variables could reduce the accuracy of the prediction results the correlations analyzed in step 1 shown in section 4 2 1 ensure that these interaction effects were very low for example the precipitation data was used to estimate the two input variables including the soil erosion and the fractp ratio this did not generate interaction effects between two input variables the other chosen variables make significant additions to the developed hyfis models it is demonstrated through the lower accuracy of hyfis models trained without one in two variables compared to the accuracy of the final models from 15 to 20 although the correlation between the precipitation and the yields variables was not recorded the intensity of rainfalls indirectly affects the water and nutrient supplies for the rice plants in this case the application of bayesian belief networks could provide a graph representing complex causal relations such as links from the precipitation to the soil erosion or to the fractp ratio and the rice yields dang et al 2018 7 conclusions to conclude the three research questions raised in the introduction chapter shall be answered is it feasible and effective to integrate hybrid neural fuzzy inference systems and the gis analysis for mapping crop suitability areas at the regional scale and predicting the potential of rice yields at the plot scale yes this study successfully applied the neural fuzzy inference systems for gis analysis particularly for mapping crop suitability areas by the s hyfis model and predicting potential rice yields by the i hyfis model at both regional and plot scales the input and output data were processed in a gis environment whereas the intermediate data from the hyfis models were processed in a r environment is the accuracy of the hyfis models higher than of traditional statistical models yes it is the training process using training data with the participation of iterative processes helped to optimize the overall accuracy of the s hyfis model up to 86 and of the i hyfis model up to 90 with testing data the goodness of fit and prediction power values of these models were higher than of the two benchmark models particularly with svm and glm from 5 to 10 how is the potential of agricultural development in other ecosystems in the sapa region the results of the two models applied in the sapa region showed that paddy fields meadows and bare soil areas hold high potentials for rice agricultural developments the conversion from meadows and bare soils to paddy fields should be considered because the extension of meadow and bare soil areas suitable for rice cultivation is equal same areal extension to the extension of areas unsuitable for rice cultivation that are presently used as paddy fields in contrast the conversion of forest and water body areas to arable lands should not be encouraged areas of upstream forests should be expanded instead of rice field expansion if the ultimate goal is to support natural water and nutrient supplies for downstream paddy fields the hyfis models seem to be promising tools to find suitable areas for agricultural development and to predict rice yields however there seem to be limitations in the case of scarce data especially with regard to deficient socio economic data in this case the data collection is time consuming the bayesian belief network approach can be a promising solution by using expert experiments to clearly represent uncertainties of the impacts of social ecological system dynamics on rice ecosystems an integration of the hyfis models with a bayesian belief network can provide better information for decision making such as assessments related to the balance between rice supply and demand additionally scientific results from modelling mapping and expert knowledge should be communicated to relevant stakeholders in order to be taken up on various levels for improved and evidence based decision making acknowledgements the study was embedded in the legato land use intensity and ecological engineering assessment tools for risks and opportunities in annual crop based production systems project funded by the german ministry of research and education within their funding program sustainable land management funding no 01ll0917 we want to thank all our legato colleagues especially anika klotzbücher and isoda yuzuru for providing relevant information and data this study was co financed by the vietnamese government scholarship 911 furthermore we would like to thank our colleagues at the institute for natural resource conservation department of ecosystem management at kiel university germany we thank angie faust for language revision of the manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 01 015 
26257,the visualization of a three dimensional 3d distribution of high density data for scientific computations with limited computing resources under a network environment is difficult this paper describes the implementation of an interactive 3d display of air pollutants in a network environment using the open source webgl class library three js a kd tree is used to find the nearest point data to interpolate the 3d grid data of pollutants because the source data are scattered which helps locate the data conveniently at the client s end the binary file format is used to save and transfer data to reduce the number of network transmissions and to improve the speed of the image display the results show that the visual effects and rendering speed are significantly improved on the web with the use of the proposed technology keywords three dimension visualization pollutant webgl interaction 1 introduction 3d visualization is commonly used to fully explore the 3d characteristics of natural phenomena because a computer screen is a 2d surface correctly displaying the data beneath the surface layer for a 3d data package is challenging as an alternative approach a cross section slice can display the exact value of each location but with a lack of 3d visual effects recently 3d visualization technology of scientific data has been widely used in medical science geologic exploration and engineering designs velayutham et al 2016 zhou et al 2015 wang et al 2014 the application of 3d visualization in the early stage mostly takes place in non web environments and requires a high performance computer or purchased developed professional 3d visualization software to obtain an acceptable performance moreover third party plug ins are needed for web environments liu et al 2012 owing to the huge differences in client environments 3d visualization for the web is likely to be blocked or difficult to upgrade therefore it is very inconvenient to use although there are currently plenty of application scenarios for 3d visualization technology for web environments alder et al 2015 jones et al 2016 interactive 3d for web environments were only integrated into the main browsers as part of the graphics processing unit gpu in 2011 but has since become popular devaux et al 2012 such visualization can be achieved in a web environment using webgl and html5 parisi 2012 without the application of plug ins webgl is a cross platform open source and plug in free 3d graphic javascript application programming interface api it can produce interactive 3d animation on the web based on an html script itself and achieve graphic rendering using low level graphics hardware acceleration webgl is therefore supported by many different hardware products and browsers the applications of webgl based 3d visualization have greatly increased in many different fields e g medicine construction and geospatial application during the past years li et al 2014 chaturvedi et al 2015 krämer et al 2015 chen luo 2016 atmospheric pollutants in china caused by urbanization have becomes extremely serious and the related environmental problems have received a significant amount of attention the spatial distributions of various pollutants are quite different cogliani 2001 guttikunda et al 2012 as the distributions depend on their chemical compositions and weather conditions the 3d distribution of pollutants features a large amount of information rapid variations over time and poor regularity and is therefore significantly different from former 3d applications former applications of webgl mainly included the display of subjects with well defined geometrical forms and only few studies have focused on atmospheric pollutants which have no fixed geometric forms and a highly variable distribution currently commonly used 3d visualization schemes for scientific data include a triangulated irregular network tin digital elevation model dem cloud representation spatial interpolation and mesh grid because they are still mainly used in non web environments gan et al 2013 the 3d visualization of pollutants for the web remains a challenge the first challenge for web based 3d visualization of pollutants comes from the limitation of local network bandwidth generally the large size of 3d data will cause inevitably delays in the uploading and browsing of 3d data even sometimes prevent the executing functions the compression of 3d data in such situation becomes quite necessary which would lead to the loss of information therefore a compromise between compression rate and data integrity is needed the second challenge is that before the webgl standard is made and generalized third party plug ins are often needed for the web based 3d visualization which would bring high costs due to the large variations in user s software and hardware conditions although the webgl standard partly solved the problem but the differences in user s hardware conditions still require a compromised solution between performance and display in the competition between network applications and desktop applications interactive visualization of scientific data has always been a shortcoming of network applications congote et al 2011 many efforts have been devoted to develop interactive graphical applications through the internet webgl provides a solution for web interactive 3d visualization similar to webgl three js is a third party open source library compiled using javascript and provides a number of 3d visualization functions with the enclosed graphic interface users can display complex 3d scenes using simple codes dirksen 2013 without an understanding of complicated graphics technical details and the complex language of webgl webgl is thus quite suitable for solving the 3d visualization problem in a web environment using 3d visualization of the extinction coefficient retrieved by an fx 3 satellite applying three js this study successfully demonstrates the interactive 3d visualization of atmospheric pollutants in a web environment and discusses the associated key technologies 2 data and methodology 2 1 data the simulated data are from the extinction coefficients ec at a height of between zero and 3 km over the east china area 23 n 39 n 113 e 123 e the data represent the spatial distributions of atmospheric pollutants in east china our data include the latitude longitude height and ec values and the valid range of ec is 0 2 km 1 the horizontal and vertical resolutions of the data are 1 km and 30 m respectively the actual data points change substantially owing to the weather conditions approximately 1 6 million on a clear day and zero under cloudy conditions 2 2 methodology the display system ds is a single page web site based on html5 css3 the interactive ui mainly works via the mouse and keyboard there is also a help label on the web which would show the keys and function instructions when clicked fig 1 shows a flowchart of ds which includes the data processing layer model display layer in client and data storage layer in server first the ds interpolates the scattered ec into the grid data and graphic files and stores them in the server to receive calls of the client which is an offline process when the client sends out a request for data the server will search the data based on the date and client requests and load the data into the client s computer memory for caching through asynchronous javascript and xml ajax garrett 2007 and therefore the model build and control of the client can be read directly from the cache the scene control display module can adjust the observed angle distance and number color and display range of the particles to reduce the computing time of the server the scattered data are gridded offline without the middle layer processes grid the client can obtain the data from the server in much less time the web can only request information for the needed grid without refreshing the entire page using ajax technology and therefore the ds is much easier and faster to use 2 2 1 data processing layer the data processing layer is responsible for the pre processing and restructuring of the data because the raw dataset is scattered with a large number of points it will take a much longer time to search therefore before the display at the client the scattered data need to be interpolated into regular grid data for a fast search of the particle location during the web page display to do so the nearest neighbor interpolation is used the spatial resolution of the raw satellite data is approximately 1 km if there are no missing data and the point density is sufficient the nearest point is searched using kd tree method bentley 1975 the kd tree is used for the offline interpolation and therefore has nothing to do with the server and the client the size of generated grid file is determined based on the type of data file and the number of grids with a valid value the standard format of a javascript exchange file is javascript object notation json or js which is a light format exchange file gao et al 2011 that is easy to write and read and is therefore commonly used on the internet however the data format is still a text type and will have large size when storing grid data to reduce the size of the file for storage and transfer an unsigned byte format with a valid value range of 0 255 is used to store and transfer the data because the value range of ec is 0 2 km 1 with one decimal place reserved we multiply the ec by 10 and then store the integer part in the file and mark the missing data with 255 2 2 2 data storage layer storage of the processed data in the server is based on the data type and date in a non structural manner including graphs and binary files after the client s request is received the server will return the data storage catalogue and the data file back to the client 2 2 3 model display layer the model display layer is responsible for the display of the model to the user specific tasks include the following 1 establishment of a basic scene this includes the map of east china and the grid lines of the latitude longitude and height the map is generated using a map file in svg format the grid lines of the latitude longitude and height are created using a three line object the title of which is loaded and created in the scene using three fontloader 2 visualization of pollutant density pd the random ball system rbs based on three spheregeometry is used to illustrate the pd and the ec of any location is represented based on the color of the corresponding ball here three spheregeometry instead of three sprites is used mainly because that three sprites is a two dimensional image which is always facing the camera and could not produce effects like shadow and lighting in contrast three spheregeometry has 3d effect and therefore we can manually chose metal effect for the ball and achieves a better performance under a lighting environment 3 visualization of section slice the detailed ec distribution can be presented well using the section slice of the rbs the section slices are usually generated in two ways a the section slices are created at different locations and directions using professional graphing software stored according to certain rules and represented when needed because a section slice is generated beforehand the loading speed will be very fast using this approach however a slice cannot be generated at any given location b generate a section slice at a user chosen location in real time in which a slice can be obtained at any given location however the computational load of the client will increase both solutions are included in the ds and can be selected by the user the location and color for the vertex of each grid are needed to apply a section slice generated in real time with three js a surface is a triangle formed by three vertices and a rectangle is the combination of two triangles the process is shown in fig 2 which takes a horizontal surface as an example a divide the section slice into an area of n the number in the latitude direction m the number in longitude direction b set up the location for each vertex in the position parameter of buffergeometry three elements are needed to represent the x y z location in the scene and nine elements are needed to form a surface c set up the color for each vertex in the color parameter of buffergeometry three elements are needed to represent r g b and nine elements are needed to form a surface d calculate the position of each vertex based on x y z and draw the color based on r b g a flowchart of this is provided in fig 3 3 results 3 1 advantage of the data format for storage and exchange fig 4 indicates the storage and exchange of binary data there are 101 blocks in height and each block includes 161 and 121 points in the latitude and longitude directions respectively each point is a 1 byte integer 0 255 therefore there are 101 161 and 121 steps for the interpolation in the vertical longitude and latitude directions respectively which generate a binary file with a size of approximate 1 88 m if the data are stored in json format all data require at least 4 bytes leading to a binary file of 7 51 m apparently the current format of the data file for storage and transfer will reduce the amount of transferred data by at least 75 and will therefore significantly increase the web page loading speed 3 2 advantage of the selected visualization method because the particles in the back layer are blocked by the particles in the front layer when using the perspective camera in any direction the particle density is not too large in the rbs therefore many locations will be easily missed however using the random location and interactive rotation the observation depth will be significantly enhanced theoretically no location will be missed when applying multiple refreshments of a random location fig 5 illustrates the difference in display between a regular and random location generation the result clearly shows that random location could display much deeper location and more highly polluted regions 3 3 advantage of interactive method in this study the server hardware is an intel r e5 2630 v2 2 60 g xeon r cpu and windows server 2008 r2 enterprise edition and apache http server are installed in the server using html5 plus javascript for the development the section slice figure png files is created using the ncar command language ncl because too many small sized png files will reduce the performance of the server we combine the files into a large png file based on the direction and use uv mapping to select the needed part for the display to enhance the experience of user interaction and the adoption of different hardware the following design is used 1 a particle in the rbs will be given a value parameter to store its ec and the range of ec for display can be chosen and changed in the display module the location information latitude longitude and height and ec for each particle will be displayed when pointed at by the mouse fig 6 2 the number of randomly generated balls in the rbs can be determined by the users according to their client performance and experience because the number of parts in the longitude widthsegments and latitude heightsegments directions for the selection of the basic elements three spheregeometry will impact the number of triangular surfaces the users should be given a suitable number a ball will appear insufficiently round with too small a number whereas the drawing speed will be too slow if the number is too large using a bandwidth of 50 m an amd phenom tm ii x4 b97 3 2g cpu 4 gb of ddr3 memory an nvidia geforce 405 and google chrome 58 0 3029 110 as the web browser the relationship between the response time and the particle number is as shown in fig 7 the display time for a particle number of up to 16 000 can be completed within 2 s when setting widthsegments and heightsegments to 8 and 4 respectively with 32 000 particles however the time increases sharply to 43 s and therefore the approximate number should be smaller than 16 000 3 the rotation and zoom in out of camera as well as the increase reduction of the particle number and the display of the section slice are all achieved using the keyboard and mouse for a concise web page the functions of the keyboard and mouse are listed in table 1 4 reorganize the rbs longitude latitude and grid into one array group subject in three js when selecting the section slice the entire rbs can be rotated by rotating the group along the x y axis the user can easily observe any angle simply by rotating the rbs with the mouse and adjusting the angle of the camera to find a suitable angle to observe any section slice fig 8 3 4 performance evaluation in order to evaluate the performance of webgl in term of its interactivity tests have been performed with different hardware configurations the hardware configurations of the computers used in evaluations are hardware configuration a ha intel r core tm i7 6700 processor 8cpus 3 40 ghz 19 6g of ram and intel r hd graphics 530 hardware configuration b hb intel r core tm i5 5200u processor 4cpus 2 20 ghz 4g of ram and intel r hd graphics 5500 hardware configuration c hc amd phenom tm ii x4 b97 processor 4cpus 3 2ghz 4g of ram and nvidia geforce 405 the client browser is google chrome v58 0 3029 110 the frame rate was recorded by chrome browser s development tool rendering fps meter for the interaction with the web we take 24 fps as the acceptable frame rate as seen in table 2 ha hardware configuration showed the best performance which can support over 6000 particles hb and hc can support up to about 4000 particles the user can adjust the number of particles to fit the different hardware configurations generally there are two rendering methods on the html5 web page canvas 2d rendering and webgl rendering canvas 2d provides many functions to draw 2d objects including a set of process based rendering interface that start and end with beginpath and closepath with low development costs it is easy to use but when there are too many objects to render or the real time interaction is required canvas 2d rendering method is unable to meet the requirements this is illustrated here by comparing the performance of the two rendering methods we apply the two rendering methods on three js with hardware configuration ha different display effects by the two method with test interface from the tool rendering fps meter are shown in fig 9 the webgl rendering method shows better three dimensional effects e g light and shadow than canvas 2d rendering method and when displaying 1000 particles the frame rate of the webgl rendering method is kept at 60 fps while that of the canvas 2d rendering method drops to 1 7 fps which is unable to satisfy the real time interaction requirement fig 10 shows changes in the frame rate of the two rendering methods corresponding to the increase of number of particles the webgl method does not fall lower than the standard requirement line until the number of particles exceeds 6000 in contrast the canvas 2d cannot meet the animation standard and it is always below 1 7 fps 4 conclusion and discussion 4 1 conclusion this paper presented a method for the interactive 3d visualization of atmospheric pollutants in web environments based on three js through the introduction and analysis of the method and key technology we have the following 1 three js can realize the interactive visualization of the 3d distribution of atmospheric pollutants and the visual effect and display speed can satisfy the user requirements 2 an option is included for the users to change the number of particles for display in the system design allowing the users to adjust and enhance their experience based on the hardware conditions of the client 3 data reorganization is very important in the process of 3d visualization the amount of data exchange between the server and front display and the calculation of data in the front display should be reduced as much as possible to increase the display speed 5 discussion using the requestanimationframe function and setinterval function in three js or a third part library e g tween js and adjusting the location of the camera or model an animation display and better 3d visual effects can be achieved if the datasets is large and the model is complex level of detail lod model hussain et al 2003 can be used to optimize the performance of animation using the object three lod in package three js such technology can also be used in the 3d display of pollutants in water meteorological data or satellite retrieval as well as other types of scientific data after setup in the server only a browser supporting webgl is required for use by the client because webgl is already supported by many different web browsers it can be easily applied in addition because gpu is used by webgl to speed up the display speed a high performance graphics card can greatly enhance the display effect this paper provides a new method for three dimensional data displaying further improvements are required in displaying multi elements that directly rendered in the foreground and better handling of large amount of data until now there are only few available toolkits based on webgl for scientific data rendering if more such toolkit is available it could save the development cost of three dimensional scientific data displaying greatly and therefore it could be the work to do next webgl can directly control the hardware devices of the client therefore how to improve the security of webgl is another important research topic acknowledgements this study was partially supported by the national natural science foundation of china nsfc grant nos 91637101 the shanghai science and technology committee research special funds grant no 16zr1431700 and the national key research and development plan grant 2017yfc1501701 we would like to thank elsevier language editing services for their language modification software availability name of software 3d air pollutant visualization for east china developers dongwei liu qianshan he yafei yan contact dongwei liu liudongwei2000 163 com 86 021 54892930 qianshan he oxeye75 163 com year first available 2017 hardware required na software required browsers that support webgl operation system required os independent program language html5 javascript program size 1 mb availability and cost open source no cost repository https github com liusir2000 visairpollutant webpage https github com liusir2000 visairpollutant 
26257,the visualization of a three dimensional 3d distribution of high density data for scientific computations with limited computing resources under a network environment is difficult this paper describes the implementation of an interactive 3d display of air pollutants in a network environment using the open source webgl class library three js a kd tree is used to find the nearest point data to interpolate the 3d grid data of pollutants because the source data are scattered which helps locate the data conveniently at the client s end the binary file format is used to save and transfer data to reduce the number of network transmissions and to improve the speed of the image display the results show that the visual effects and rendering speed are significantly improved on the web with the use of the proposed technology keywords three dimension visualization pollutant webgl interaction 1 introduction 3d visualization is commonly used to fully explore the 3d characteristics of natural phenomena because a computer screen is a 2d surface correctly displaying the data beneath the surface layer for a 3d data package is challenging as an alternative approach a cross section slice can display the exact value of each location but with a lack of 3d visual effects recently 3d visualization technology of scientific data has been widely used in medical science geologic exploration and engineering designs velayutham et al 2016 zhou et al 2015 wang et al 2014 the application of 3d visualization in the early stage mostly takes place in non web environments and requires a high performance computer or purchased developed professional 3d visualization software to obtain an acceptable performance moreover third party plug ins are needed for web environments liu et al 2012 owing to the huge differences in client environments 3d visualization for the web is likely to be blocked or difficult to upgrade therefore it is very inconvenient to use although there are currently plenty of application scenarios for 3d visualization technology for web environments alder et al 2015 jones et al 2016 interactive 3d for web environments were only integrated into the main browsers as part of the graphics processing unit gpu in 2011 but has since become popular devaux et al 2012 such visualization can be achieved in a web environment using webgl and html5 parisi 2012 without the application of plug ins webgl is a cross platform open source and plug in free 3d graphic javascript application programming interface api it can produce interactive 3d animation on the web based on an html script itself and achieve graphic rendering using low level graphics hardware acceleration webgl is therefore supported by many different hardware products and browsers the applications of webgl based 3d visualization have greatly increased in many different fields e g medicine construction and geospatial application during the past years li et al 2014 chaturvedi et al 2015 krämer et al 2015 chen luo 2016 atmospheric pollutants in china caused by urbanization have becomes extremely serious and the related environmental problems have received a significant amount of attention the spatial distributions of various pollutants are quite different cogliani 2001 guttikunda et al 2012 as the distributions depend on their chemical compositions and weather conditions the 3d distribution of pollutants features a large amount of information rapid variations over time and poor regularity and is therefore significantly different from former 3d applications former applications of webgl mainly included the display of subjects with well defined geometrical forms and only few studies have focused on atmospheric pollutants which have no fixed geometric forms and a highly variable distribution currently commonly used 3d visualization schemes for scientific data include a triangulated irregular network tin digital elevation model dem cloud representation spatial interpolation and mesh grid because they are still mainly used in non web environments gan et al 2013 the 3d visualization of pollutants for the web remains a challenge the first challenge for web based 3d visualization of pollutants comes from the limitation of local network bandwidth generally the large size of 3d data will cause inevitably delays in the uploading and browsing of 3d data even sometimes prevent the executing functions the compression of 3d data in such situation becomes quite necessary which would lead to the loss of information therefore a compromise between compression rate and data integrity is needed the second challenge is that before the webgl standard is made and generalized third party plug ins are often needed for the web based 3d visualization which would bring high costs due to the large variations in user s software and hardware conditions although the webgl standard partly solved the problem but the differences in user s hardware conditions still require a compromised solution between performance and display in the competition between network applications and desktop applications interactive visualization of scientific data has always been a shortcoming of network applications congote et al 2011 many efforts have been devoted to develop interactive graphical applications through the internet webgl provides a solution for web interactive 3d visualization similar to webgl three js is a third party open source library compiled using javascript and provides a number of 3d visualization functions with the enclosed graphic interface users can display complex 3d scenes using simple codes dirksen 2013 without an understanding of complicated graphics technical details and the complex language of webgl webgl is thus quite suitable for solving the 3d visualization problem in a web environment using 3d visualization of the extinction coefficient retrieved by an fx 3 satellite applying three js this study successfully demonstrates the interactive 3d visualization of atmospheric pollutants in a web environment and discusses the associated key technologies 2 data and methodology 2 1 data the simulated data are from the extinction coefficients ec at a height of between zero and 3 km over the east china area 23 n 39 n 113 e 123 e the data represent the spatial distributions of atmospheric pollutants in east china our data include the latitude longitude height and ec values and the valid range of ec is 0 2 km 1 the horizontal and vertical resolutions of the data are 1 km and 30 m respectively the actual data points change substantially owing to the weather conditions approximately 1 6 million on a clear day and zero under cloudy conditions 2 2 methodology the display system ds is a single page web site based on html5 css3 the interactive ui mainly works via the mouse and keyboard there is also a help label on the web which would show the keys and function instructions when clicked fig 1 shows a flowchart of ds which includes the data processing layer model display layer in client and data storage layer in server first the ds interpolates the scattered ec into the grid data and graphic files and stores them in the server to receive calls of the client which is an offline process when the client sends out a request for data the server will search the data based on the date and client requests and load the data into the client s computer memory for caching through asynchronous javascript and xml ajax garrett 2007 and therefore the model build and control of the client can be read directly from the cache the scene control display module can adjust the observed angle distance and number color and display range of the particles to reduce the computing time of the server the scattered data are gridded offline without the middle layer processes grid the client can obtain the data from the server in much less time the web can only request information for the needed grid without refreshing the entire page using ajax technology and therefore the ds is much easier and faster to use 2 2 1 data processing layer the data processing layer is responsible for the pre processing and restructuring of the data because the raw dataset is scattered with a large number of points it will take a much longer time to search therefore before the display at the client the scattered data need to be interpolated into regular grid data for a fast search of the particle location during the web page display to do so the nearest neighbor interpolation is used the spatial resolution of the raw satellite data is approximately 1 km if there are no missing data and the point density is sufficient the nearest point is searched using kd tree method bentley 1975 the kd tree is used for the offline interpolation and therefore has nothing to do with the server and the client the size of generated grid file is determined based on the type of data file and the number of grids with a valid value the standard format of a javascript exchange file is javascript object notation json or js which is a light format exchange file gao et al 2011 that is easy to write and read and is therefore commonly used on the internet however the data format is still a text type and will have large size when storing grid data to reduce the size of the file for storage and transfer an unsigned byte format with a valid value range of 0 255 is used to store and transfer the data because the value range of ec is 0 2 km 1 with one decimal place reserved we multiply the ec by 10 and then store the integer part in the file and mark the missing data with 255 2 2 2 data storage layer storage of the processed data in the server is based on the data type and date in a non structural manner including graphs and binary files after the client s request is received the server will return the data storage catalogue and the data file back to the client 2 2 3 model display layer the model display layer is responsible for the display of the model to the user specific tasks include the following 1 establishment of a basic scene this includes the map of east china and the grid lines of the latitude longitude and height the map is generated using a map file in svg format the grid lines of the latitude longitude and height are created using a three line object the title of which is loaded and created in the scene using three fontloader 2 visualization of pollutant density pd the random ball system rbs based on three spheregeometry is used to illustrate the pd and the ec of any location is represented based on the color of the corresponding ball here three spheregeometry instead of three sprites is used mainly because that three sprites is a two dimensional image which is always facing the camera and could not produce effects like shadow and lighting in contrast three spheregeometry has 3d effect and therefore we can manually chose metal effect for the ball and achieves a better performance under a lighting environment 3 visualization of section slice the detailed ec distribution can be presented well using the section slice of the rbs the section slices are usually generated in two ways a the section slices are created at different locations and directions using professional graphing software stored according to certain rules and represented when needed because a section slice is generated beforehand the loading speed will be very fast using this approach however a slice cannot be generated at any given location b generate a section slice at a user chosen location in real time in which a slice can be obtained at any given location however the computational load of the client will increase both solutions are included in the ds and can be selected by the user the location and color for the vertex of each grid are needed to apply a section slice generated in real time with three js a surface is a triangle formed by three vertices and a rectangle is the combination of two triangles the process is shown in fig 2 which takes a horizontal surface as an example a divide the section slice into an area of n the number in the latitude direction m the number in longitude direction b set up the location for each vertex in the position parameter of buffergeometry three elements are needed to represent the x y z location in the scene and nine elements are needed to form a surface c set up the color for each vertex in the color parameter of buffergeometry three elements are needed to represent r g b and nine elements are needed to form a surface d calculate the position of each vertex based on x y z and draw the color based on r b g a flowchart of this is provided in fig 3 3 results 3 1 advantage of the data format for storage and exchange fig 4 indicates the storage and exchange of binary data there are 101 blocks in height and each block includes 161 and 121 points in the latitude and longitude directions respectively each point is a 1 byte integer 0 255 therefore there are 101 161 and 121 steps for the interpolation in the vertical longitude and latitude directions respectively which generate a binary file with a size of approximate 1 88 m if the data are stored in json format all data require at least 4 bytes leading to a binary file of 7 51 m apparently the current format of the data file for storage and transfer will reduce the amount of transferred data by at least 75 and will therefore significantly increase the web page loading speed 3 2 advantage of the selected visualization method because the particles in the back layer are blocked by the particles in the front layer when using the perspective camera in any direction the particle density is not too large in the rbs therefore many locations will be easily missed however using the random location and interactive rotation the observation depth will be significantly enhanced theoretically no location will be missed when applying multiple refreshments of a random location fig 5 illustrates the difference in display between a regular and random location generation the result clearly shows that random location could display much deeper location and more highly polluted regions 3 3 advantage of interactive method in this study the server hardware is an intel r e5 2630 v2 2 60 g xeon r cpu and windows server 2008 r2 enterprise edition and apache http server are installed in the server using html5 plus javascript for the development the section slice figure png files is created using the ncar command language ncl because too many small sized png files will reduce the performance of the server we combine the files into a large png file based on the direction and use uv mapping to select the needed part for the display to enhance the experience of user interaction and the adoption of different hardware the following design is used 1 a particle in the rbs will be given a value parameter to store its ec and the range of ec for display can be chosen and changed in the display module the location information latitude longitude and height and ec for each particle will be displayed when pointed at by the mouse fig 6 2 the number of randomly generated balls in the rbs can be determined by the users according to their client performance and experience because the number of parts in the longitude widthsegments and latitude heightsegments directions for the selection of the basic elements three spheregeometry will impact the number of triangular surfaces the users should be given a suitable number a ball will appear insufficiently round with too small a number whereas the drawing speed will be too slow if the number is too large using a bandwidth of 50 m an amd phenom tm ii x4 b97 3 2g cpu 4 gb of ddr3 memory an nvidia geforce 405 and google chrome 58 0 3029 110 as the web browser the relationship between the response time and the particle number is as shown in fig 7 the display time for a particle number of up to 16 000 can be completed within 2 s when setting widthsegments and heightsegments to 8 and 4 respectively with 32 000 particles however the time increases sharply to 43 s and therefore the approximate number should be smaller than 16 000 3 the rotation and zoom in out of camera as well as the increase reduction of the particle number and the display of the section slice are all achieved using the keyboard and mouse for a concise web page the functions of the keyboard and mouse are listed in table 1 4 reorganize the rbs longitude latitude and grid into one array group subject in three js when selecting the section slice the entire rbs can be rotated by rotating the group along the x y axis the user can easily observe any angle simply by rotating the rbs with the mouse and adjusting the angle of the camera to find a suitable angle to observe any section slice fig 8 3 4 performance evaluation in order to evaluate the performance of webgl in term of its interactivity tests have been performed with different hardware configurations the hardware configurations of the computers used in evaluations are hardware configuration a ha intel r core tm i7 6700 processor 8cpus 3 40 ghz 19 6g of ram and intel r hd graphics 530 hardware configuration b hb intel r core tm i5 5200u processor 4cpus 2 20 ghz 4g of ram and intel r hd graphics 5500 hardware configuration c hc amd phenom tm ii x4 b97 processor 4cpus 3 2ghz 4g of ram and nvidia geforce 405 the client browser is google chrome v58 0 3029 110 the frame rate was recorded by chrome browser s development tool rendering fps meter for the interaction with the web we take 24 fps as the acceptable frame rate as seen in table 2 ha hardware configuration showed the best performance which can support over 6000 particles hb and hc can support up to about 4000 particles the user can adjust the number of particles to fit the different hardware configurations generally there are two rendering methods on the html5 web page canvas 2d rendering and webgl rendering canvas 2d provides many functions to draw 2d objects including a set of process based rendering interface that start and end with beginpath and closepath with low development costs it is easy to use but when there are too many objects to render or the real time interaction is required canvas 2d rendering method is unable to meet the requirements this is illustrated here by comparing the performance of the two rendering methods we apply the two rendering methods on three js with hardware configuration ha different display effects by the two method with test interface from the tool rendering fps meter are shown in fig 9 the webgl rendering method shows better three dimensional effects e g light and shadow than canvas 2d rendering method and when displaying 1000 particles the frame rate of the webgl rendering method is kept at 60 fps while that of the canvas 2d rendering method drops to 1 7 fps which is unable to satisfy the real time interaction requirement fig 10 shows changes in the frame rate of the two rendering methods corresponding to the increase of number of particles the webgl method does not fall lower than the standard requirement line until the number of particles exceeds 6000 in contrast the canvas 2d cannot meet the animation standard and it is always below 1 7 fps 4 conclusion and discussion 4 1 conclusion this paper presented a method for the interactive 3d visualization of atmospheric pollutants in web environments based on three js through the introduction and analysis of the method and key technology we have the following 1 three js can realize the interactive visualization of the 3d distribution of atmospheric pollutants and the visual effect and display speed can satisfy the user requirements 2 an option is included for the users to change the number of particles for display in the system design allowing the users to adjust and enhance their experience based on the hardware conditions of the client 3 data reorganization is very important in the process of 3d visualization the amount of data exchange between the server and front display and the calculation of data in the front display should be reduced as much as possible to increase the display speed 5 discussion using the requestanimationframe function and setinterval function in three js or a third part library e g tween js and adjusting the location of the camera or model an animation display and better 3d visual effects can be achieved if the datasets is large and the model is complex level of detail lod model hussain et al 2003 can be used to optimize the performance of animation using the object three lod in package three js such technology can also be used in the 3d display of pollutants in water meteorological data or satellite retrieval as well as other types of scientific data after setup in the server only a browser supporting webgl is required for use by the client because webgl is already supported by many different web browsers it can be easily applied in addition because gpu is used by webgl to speed up the display speed a high performance graphics card can greatly enhance the display effect this paper provides a new method for three dimensional data displaying further improvements are required in displaying multi elements that directly rendered in the foreground and better handling of large amount of data until now there are only few available toolkits based on webgl for scientific data rendering if more such toolkit is available it could save the development cost of three dimensional scientific data displaying greatly and therefore it could be the work to do next webgl can directly control the hardware devices of the client therefore how to improve the security of webgl is another important research topic acknowledgements this study was partially supported by the national natural science foundation of china nsfc grant nos 91637101 the shanghai science and technology committee research special funds grant no 16zr1431700 and the national key research and development plan grant 2017yfc1501701 we would like to thank elsevier language editing services for their language modification software availability name of software 3d air pollutant visualization for east china developers dongwei liu qianshan he yafei yan contact dongwei liu liudongwei2000 163 com 86 021 54892930 qianshan he oxeye75 163 com year first available 2017 hardware required na software required browsers that support webgl operation system required os independent program language html5 javascript program size 1 mb availability and cost open source no cost repository https github com liusir2000 visairpollutant webpage https github com liusir2000 visairpollutant 
26258,pollution caused by gaseous contaminant from waste treatment facilities such as wastewater plants municipal solid waste landfills transfer stations has elicited public concern the potential environmental impacts of gaseous emissions from waste sectors are regulated by legislations in many countries and dispersion models are powerful tools modeling of odor gas air dispersion software mododor a 3d unsteady state numerical model was developed in this study to simulate the dispersion of gaseous contaminants from waste sectors mododor overcomes the limitations of gaussian and lagrangian models when applied to unsteady state local scale gaseous dispersion from waste sectors because it adopts the numerical eulerian scheme and finite difference method particularly mododor can generate potential flow solutions associated with complex topography process different types of emission sources simulate spatiotemporal variations in meteorological conditions wind and dispersion and implement physical chemical reactions for tracking the temporal and spatial evolution of plume and managing gaseous pollution from waste sectors keywords waste treatment facility odor numerical 3d model finite difference method advection dispersion chemical reaction software availability name of software mododor modeling of odor gas air dispersion software developers hongtao wang yanjun liu hardware requirements any pc compatible with windows xp or better programming language embarcadero delphi xe2 cost free for demo version availability contact hongtao wang at htwang tsignhua edu cn 1 introduction gaseous contaminants emitted from waste treatment facilities such as wastewater and municipal solid waste msw treatment plants are eliciting public concern gaseous emissions from waste sectors especially aromatics pose significant health risks to workers and nearby neighborhoods odorous compounds such as sulfide and oxygenated compounds exert negative impacts within several kilometers of emitting facilities therefore investigating and determining the odor range and health risk impact zone are important nicell 2009 dispersion modeling is an efficient cost effective approach to assess the impacts of gaseous contaminants most odor regulations are defined through dispersion modeling capelli et al 2013 danuso et al 2015 periáñez 2005 pollutant dispersion models commonly originate from civil or industrial fields and disturbances in the type of emission source operation mode topography and climate exert significant effects on gaseous dispersion the impact distance of landfill sites in china should be determined by dispersion modeling in accordance with the standard for pollution control on the landfill site of municipal solid waste gb 16889 2008 due to the lack of specific model regular dispersion models have been used for predicting gaseous contaminant dispersion from waste facilities however a specific model with high accuracy in local scale and capability of dealing with complicated conditions is still desired most dispersion models follow gaussian lagrangian or eulerian approaches leelossy et al 2014 gaussian plume model is the most widely adopted core model in many plume atmospheric dispersion models such as aermod cimorelli et al 2005 aermod initially developed for steady state industrial point emission sources has been applied to model different source types including point area and volume sources emissions and meteorological conditions are assumed to be time invariant in gaussian models and for this reason these models are applied to model annual averages or time series of hourly concentration in addition low wind speeds calm atmospheric conditions and complex terrains limit the application of gaussian models lagrangian and eulerian grid models for dispersion simulation are more advanced than gaussian models pisso et al 2017 lagrangian models also known as particle models are stochastic and describe the motion of individual and non interacting elementary contaminants by considering random particle movements eulerian models grid models numerically solve the advection dispersion equations of wind generated turbulent flow and calculate the average concentration of pollutants in a 3d domain subdivided into grids dupont et al 2006 nguyen et al 1997 compared with lagrangian models eulerian models allow for a more accurate spatiotemporal representation and thus require more computing power the effects of gaseous contaminants from waste sectors are mainly concentrated within the vicinity normally several hundred meters to several kilometers of facilities and vary with meteorological conditions in temporal and spatial aspects variations in meteorological conditions including wind speed wind direction air humidity and rainfall exert significant effects on the dispersion process therefore small scale and high precision dispersion models that can simulate unsteady state and odorant depletion processes are required however weather conditions are considered homogeneous and stationary in gaussian models it is generally believed that commonly used steady state gaussian models are invalid when wind is weak or calm but several improvements have been proposed recently qian and venkatram 2011 calpuff a well known lagrangian model can simulate unsteady conditions during pollution transport transformation and reactions scire et al 2000 however this model was developed for long range transport scale 50 km and complex meteorological sounding data are required wang et al 2006 eulerian models provide a possible approach for dispersion simulation of gaseous contaminants at a small scale and in an unsteady state suh 2006 the average concentration of contaminants in wind generated turbulent flow is calculated in different spatial cells the results provide a more accurate spatiotemporal representation compared with the results of lagrangian models terrain features can also be simulated by setting the calculability of grids and depletion processes such as chemical reactions and depositions can be considered in the source sink term eulerian models have been developed for the calculation of the average concentrations of odorous pollutant from livestock waste in different spatial cells danuso et al 2015 however odorous dispersion from waste treatment facilities is different from livestock waste in which the source types and topography features are more complex therefore further investigations are still needed the objective of this work was to establish simple computer software for simulating and predicting the dispersion of gaseous contaminants from waste sectors to surrounding areas in relation to weather and terrain characteristics an unsteady state numerical dispersion model called modeling of odor gas air dispersion software mododor version 1 0 2014sr117141 was developed owing to the use of a numerical eulerian scheme mododor overcomes the limits of traditional dispersion models such as modeling scale unsteady state and depletion processes when applied to the simulation of gaseous contaminant dispersion from waste treatment facilities complex terrain features spatiotemporal variations in meteorological conditions chemical reactions and deposition processes can be considered in mododor multiple types of emission sources including point linear areal volumetric and their combination can also be simulated this software was used to simulate practical problems in the current work case studies of gaseous contaminants emitted from point and area sources were conducted and tested using field measurement data mododor provides a significant approach for comprehensively understanding the impacts of gaseous contaminants from waste treatment facilities 2 model description mododor is an unsteady state eulerian based model it is applicable to rural and urban areas flat and complex terrains surface and elevated releases multiple sources including point linear areal volumetric and their combination and relevant chemical transformation and deposition processes of gaseous contaminants as shown in fig 1 the main interface of the software contains three main components namely guide input and output windows the software provides a user interface 11 sheets in the input window for data entry default parameter values an automatic identification system for input errors inspection of input legitimacy function calculation for data entry graphical output interfaces and support systems for users to input parameters conveniently and efficiently 2 1 governing equations the governing equation adopted by mododor is based on the physical principles of mass conservation and the continuity of atmospheric fluid air parcels the assumptions of mododor are as follows 1 fluid is completely filled in the studied domain and incompressible 2 only gaseous pollutants that are ideally mixed with air are considered and separation due to the density difference during transportation processes is disregarded and 3 the temperature in the studied domain is homogeneous but which could vary with time the governing 3d advection diffusion differential equation is 1 c t v c d x y z g t 0 where v is the vector of wind speed in m s d is the source sink term in μg m3 s t is calculation time in second and c x y z t is the concentration of the contaminant modeled at the grid x y z and at time t in μg m3 expanding the first term on the left side of eq 1 and the source sink term as eqs 2 and 3 leads to eq 4 2 v c x k x c x y k y c y z k z c z u x c x u y c y u z c z 3 d s w k k w c 4 c t x k x c x y k y c y z k z c z u x c x u y c y u z c z w k k w c s x y z g t 0 where c is the concentration of the modeled contaminant in μg m3 k x k y and k z are diffusion coefficients in longitudinal lateral and vertical directions respectively in m2 s u x u y and u z are wind speeds in longitudinal lateral and vertical directions respectively in m s d is the source sink term in μg m3 s w is the decomposition rate of sink term in 1 s s is the source term in μg m3 s k is the rate constant for a first order chemical reaction in 1 s k w is the depletion rate of wet deposition in 1 s g is the studied domain x y and z represent the calculated positions and t is calculation time in second 2 2 finite difference discretization in temporal and spatial domains the governing equation is solved with the finite difference method by dividing the space domain into cubic grids beforehand fig 2 finite difference meshes can be equidimensional or unequidimensional the size of a cell i j l that is length width and height are marked as δx i δy j and δz l respectively the aim of mododor is to solve the concentrations in the center of each calculated grid detailed information on the simulated 3d spatial grids time steps and gaseous contaminants is inputted in the grid time sheet as shown in fig 1 the number of rows columns layers and time steps should be defined in the beginning in mododor the number of rows columns and layers should be integers in the range of 3 900 with a maximum grid number of 200 million grid size is a spatial variable in the range of 0 01 1000 m the simulation state is optional when the unsteady state is selected the model is run in time series when the steady state is selected dispersion is modeled according to the steady state statistical approach and the set of time lengths and time steps becomes invalid as shown in fig 3 topography is modeled by assigning bottom meshes as the outer meshes in mododor these bottom meshes are considered as closed boundary an impervious wall during modeling hence no mass could transport across the mesh interface only cells set as the inner meshes can be considered during modeling information on topography is entered in the mesh sheet fig a1 appendix the properties of the cells are assigned in this sheet eq 4 describes the concentration of 3d advection diffusion time independent for non isotropic plume in which wind field diffusion and depletion coefficients are variable in space and time the equation is evaluated with the crank nicolson method on the basis of the central difference in space and the trapezoidal rule in time thereby providing second order convergence in time crank and nicolson 1996 the time derivative c t is then evaluated and respective 3d fields are projected forward through a short time step δt the process is repeated over a succession of time steps to describe the evolution of concentration eqs 5a 5c are the discretization format of eq 4 5a c i j l k 1 c i j l k δ t k 1 l k c i j l l u c i j l s i j k 1 2 w i j l k i j l k w i j l c i j l k 1 w i j l k i j l k w i j l c i j l k 5b l k c i j l k x i 1 2 j l 2 δ x i δ x i 1 2 c i 1 j l k 1 c i j l k 1 c i 1 j l k c i j l k k x i 1 2 j l 2 δ x i δ x i 1 2 c i 1 j l k 1 c i j l k 1 c i 1 j l k c i j l k k y i j 1 2 l 2 δ y j δ y j 1 2 c i j 1 l k 1 c i j l k 1 c i j 1 l k c i j l k k y i j 1 2 l 2 δ y j δ y j 1 2 c i j 1 l k 1 c i j l k 1 c i j 1 l k c i j l k k z i j l 1 2 2 δ z l δ z l 1 2 c i j l 1 k 1 c i j l k 1 c i j l 1 k c i j l k k z i j l 1 2 2 δ z l δ z l 1 2 c i j l 1 k 1 c i j l k 1 c i j l 1 k c i j l k 5c l u c i j l u x i 1 2 j l c i 1 2 j l δ x i u x i 1 2 j l c i 1 2 j l δ x i u y i j 1 2 l c i j 1 2 l δ y i u y i j 1 2 l c i j 1 2 l δ y i u z i j l 1 2 c i j l 1 2 δ z i u z i j l 1 2 c i j l 1 2 δ z i there are two terms for the calculation of time one is time step which represents the minimum time scale for the finite difference diffusion advection calculation the aim of setting time step is to ensure the precise of calculation time step is decided on the basis of the peclet and courant number and background commutated by mododor the other term is time period which is decided by the users in mododor software at the main interface fig 1 time periods are composed by time steps and the sum of all the time periods makes the time domain during the simulation of mododor meteorological parameters are time dependent variable between different time periods the time domain is averagely divided into n t parts k 0 1 2 n t 1 and each part is termed as a time step δt that is δ t k 1 t k 1 t k where t k 1 and t k are the time in k 1 and k respectively and t k 0 0 the time step should be limited and sufficiently short to avoid numerical dispersion and oscillation during the solving of the convection and diffusion equation in mododor the peclet number pe and the courant number cr are limited to avoid computational instability and obtain convergent results first the peclet number is limited to values lower than 1 p e t max 1 as follows 6 p e t i j l δ t k 1 max u x i j l 2 k x i j l u y i j l 2 k y i j l u z i j l 2 k z i j l 1 therefore time step δt k 1 is limited to 7 δ t k 1 min k x i j l u x i j l 2 k y i j l u y i j l 2 k z i j l u z i j l 2 the courant number is also limited to values lower than 1 c r t max 1 as follows 8 c r t i j l δ t k 1 max u x i j l δ x i u y i j l δ y j u z i j l δ z l 1 therefore time step δt k 1 should also satisfy the constraints of 9 δ t k 1 min δ x i u x i j l δ y j u y i j l δ z l u z i j l the set of advection diffusion eq 1 is solved by using a numerical scheme with upstream weighting lu 1992 kozdon et al 2011 which is a type of eulerian model solution that is the optimum and the most accurate method when turbulent diffusion plays the key role pe 2 in gas transport however when advection is the main factor that affects the transport pe 2 the upstream weighting method might cause numerical diffusion the solution interface solution sheet is shown in fig a10 appendix a reduction in time step increases the solution accuracy in mododor a time step reduction factor in the range of 0 0001 1 with a default value of 0 05 is manually entered the successive over relaxation sor method is used to solve the finite difference equations the solution parameters namely maximum number of iterations absolute error of convergence 0 001 0 000001 and relaxation factor of sor 0 2 are optional in mododor and have default values of 10 000 0 0001 and 1 2 respectively 2 3 initial and boundary conditions for unsteady state simulation mododor allows assigning an initial concentration of the gaseous contaminants in the studied domain in the initial condition sheet fig a2 appendix eq 10 provides the calculative process of the initial condition setting the initial condition is no longer necessary for stable conditions three options are available in the initial condition sheet concentration 0 concentration constant and assign by grids 10 c x y z t t 0 c 0 x y z x y z g where c 0 x y z is the initial concentration in the studied domain in μg m3 given that the entire studied domain is a cube like space in mododor each surface is defined as a boundary and referred to as front back left right upper and lower boundaries in the boundary condition sheet as shown in fig a3 appendix the boundary property should be set as open or closed closed boundary means that no flux of gas and pollutants can flow into or out of the studied domain through the surface for open boundary mododor assumes that the inflow is clean and no pollutant enters through the boundary however pollutants could flow out of the boundary with wind and the concentrations on the surface are assumed to be similar to those of boundary grids furthermore mododor allows complex conditions to be set for open boundaries including dirichlet or first type neumann or second type and mixed boundary conditions the governing equations of the three boundaries are shown in eqs 11 13 respectively the boundary condition can be set by grids the lower boundary is set as closed and the other boundaries are set as open default in mododor the dirichlet or first type boundary condition is 11 c x y z t γ 1 c 1 x y z t x y z γ 1 t 0 the neumann or second type boundary condition is 12 k x c x cos n x k y c y cos n y k z c z cos n z γ 2 f x y z t x y z t 0 the mixed boundary condition is 13 k x c x u x c cos n x k y c y u y c cos n y k z c z u z c cos n z γ 3 g x y z t x y z t 0 where c 1 x y z t is the given concentration in the first type boundary γ1 in μg m3 f x y z t is the turbulent diffusion flux in the second type boundary γ2 in μg m2 s g x y z t is the sum of advection and turbulent flux in the boundary γ3 in μg m2 s cos n x cos n y and cos n z are direction cosines and γ is the boundary of the studied domain γ1 γ2 γ3 γ 2 4 wind field mododor provides four options for the assignment of wind field the four options are constant in the studied domain spatial variance for each grid temporal variance spatial homogeneous and the diagnostic adjustment model wind information is entered in the wind sheet fig a4 appendix when the adjustment wind field model is selected information on wind speed wind direction and location and height of observation stations are required mododor can calculate the wind field on the basis of 100 observation stations at the maximum the diagnostic adjustment wind field is assigned based on observation data montero 2001 the following steps are included 1 construction of an initial horizontal wind field 2 extraction of the vertical wind profile and 3 adjustment of the wind field by minimizing a least square function montero 2001 mocioaca et al 2009 for the horizontal wind field the sparsely observed data are interpolated at the height of the observation stations and the inverse of the squared distance between the grids and observation station is adopted as the weighting factor as shown in eq 14 14 v 0 i j 1 w i j n 1 n v n r n i j 2 n 1 n 1 r n i j 2 w i j n 1 n v n δ h n i j n 1 n 1 δ h n i j w i j 2 π n n 1 n arctan δ h n i j r n i j where v 0i j is the initial wind velocity at grid i j the subscript 0 represents the initial wind speed i j are the numbers of columns and rows respectively v n is the initial wind speed value at observation station n n is the number of observation stations r n i j is the horizontal distance between station n and grid i j δ h n i j is the absolute value of the vertical distance between station n and grid i j and w i j is the weighting factor vertical wind profiles are built according to atmospheric stability conditions wind direction turbulence temperature and temperature gradient are required meteorological observations the profile equations for wind speed are as follows 15 u z u 7 z 0 z 7 z 0 z 7 z 0 u κ ln z z 0 ψ m z l ψ m z 0 l 7 z 0 z z pbl u z pbl z z pbl where κ is the von karman constant which is usually κ 0 4 u is the friction velocity in m s l is monin obukhov length in m u is wind speed in m s z is the calculated height in m z 0 is the roughness length in m z pbl is the height of the planetary boundary layer in m and ψ m is the stability term for unstable conditions z l 0 16a ψ m z l 2 ln 1 x 2 ln 1 x 2 2 2 arctan x π 2 x 1 16 z l 1 4 16b ψ m z 0 l 2 ln 1 x 0 2 ln 1 x 0 2 2 2 arctan x 0 π 2 x 0 1 16 z 0 l 1 4 during stable conditions z l 0 ψ m is calculated from van ulden and holtslag 1985 as 17a ψ m z l 5 z l z l 1 17 1 exp 0 29 z l z l 1 17b ψ m z 0 l 5 z 0 l z l 1 17 1 exp 0 29 z 0 l z l 1 friction velocity is calculated by 18 u κ u 0 z ln z z 0 ψ m z l ψ m z 0 l 19 l ρ c p t u 3 κ g h the height of the boundary layer is calculated as 20 z pbl 0 4 u f l l 0 0 3 u f l 0 f 2 ω sin ϕ π 180 where f is the coriolis parameter ϕ is the latitude of the studied location in degrees and ω is geostrophic velocity ω 7 2921 10 5 rad s the wind field is adjusted by minimizing a least squares function 2 5 turbulence parameterization evaluations of vertical and horizontal diffusion coefficients are necessary to solve eq 1 the vertical and horizontal diffusion coefficients are entered into the diffusion sheet fig a5 appendix despite manually assigning turbulence parameters by grid mododor can calculate diffusion coefficients on the basis of atmospheric stability according to technical methods for establishing local emission standards of air pollutants epa of china 1991 if the diagnostic wind field or stability calculation of the turbulence parameters is selected then meteorological information such as temperature simulation date and time longitude and latitude of the studied location total cloud cover and low cloud cover is required in the meteorology sheet fig a6 appendix otherwise the meteorology sheet would be unavailable 2 6 source terms the information of source terms is entered in the source sheet and the interface is shown in fig a7 appendix sources are set by grids and mododor supports multiple types of sources including point areal volumetric and their combination the temporal variance of the source strength for unsteady state simulations is available in mododor and the time step should be in accordance with the grid time sheet 2 7 depletion process three plume depletion processes namely dry deposition wet deposition and chemical reaction processes can be modeled in mododor by using depletion coefficients this condition means that the physical or chemical processes involved in the removal of pollutants from plume are represented by simple proportionality between removal rates and local airborne concentration of materials surface dry deposition is easily treated in mododor as the lower boundary condition thus 21 c t u dep c z where each side represents the vertical downward flux of pollutants and u dep is the deposition velocity in 1 s the calculation of u dep has been described by noll et al 2001 mododor uses the washout coefficient method for wet deposition and assumes that removal processes are independent and irreversible 22 c t k w c where k w is the wet deposition coefficient in 1 s which is empirically in the range of 0 4 10 5 3 0 10 3 1 s k w aj b where j is the rainfall rate in mm h and a and b are parameters depending on the type of pollutant the default values of constants a and b are a 1 0 10 4 b 0 64 carrytgers et al 1994 the deposition process is assumed to be homogeneous in the domain and calculated in the sink term eq 1 information on deposition velocity u dep in eq 21 for dry deposition and the wet deposition coefficient k w in eq 22 are manually entered in the deposition sheet fig a8 for chemical reactions mododor assumes that all pollutants follow first order chemical reactions during gaseous contaminant transportation as shown in eq 23 reaction rate constant k 1 s is adapted from existing references atkinson et al 2007 2008 23 c t k c information on the reaction rate constants k is manually entered in the chemical reaction sheet fig a9 mododor offers default deposition velocities and reaction constants in the guide window 2 8 output the calculate button beside the guide window is pressed when all the parameters have been determined and entered in mododor the results are then displayed in the output window at the bottom outputting the input data and results of each time step in the results is optional in addition mododor offers the following four output formats for the results concentration of ground layer grids concentration of the selected layer concentration of all grids and concentration of the selected domain the results can be presented in a matrix or a column x y z c the interface of output sheet is shown in fig a11 mododor also provides plotting functions including vertical concentration curves and a contour map to express the results visually fig a12 3 case studies of mododor 3 1 application of mododor to gaseous contaminant dispersion from point sources odor pollution from transfer stations has elicited increased concern because such stations are usually situated in cities and are near residential districts a large transfer station for msw in beijing city was selected as the study site for the assessment of odor pollution the transfer station is a building for the temporary deposition of waste where waste are sorted and compressed before transport to the end point of disposal in a landfill or incineration the station is operated under negative pressure and gas is discharged from 15 fan equipped exhaust outlets constructed on the roof of the facility given the relatively small scale of the source odor emission from the facility was considered a point source in this study four evenly distributed exhaust outlets were selected for sampling with the sampling points located at the center of the enclosures sampling campaigns were conducted on june 24 2014 during normal operations gas samples were collected from the four sampling spots at a time interval of 20 min from 9 30 a m to 12 00 a m the outlets were approximately 15 m high above the ground a total of 12 valid samples were obtained meteorological parameters wind velocity 2 1 m s temperature 31 c and humidity 51 were also measured during sampling detailed information on the sampling campaign and gas analysis were provided in a previous work zhao et al 2015 considering odor impacts hydrogen sulfide was considered for dispersion modeling details of the input data are shown in table 1 fig 4 shows the results of the mododor simulation the evolution of hydrogen sulfide concentration with time at the ground level is shown in fig 4 a the concentration of hydrogen sulfide decreased sharply with distance comparison of the concentration in the same spot showed that the concentration gradually increased and the concentration at 600 s was nearly similar to that in 1800 s indicating that dispersion nearly reached a steady state after 10 min fig 4 b compares the concentration of hydrogen sulfide at different heights the concentration at 15 m was larger than the others and rapidly declined with distance when the exhaust outlets were 15 m high above the ground significant differences were found in the source spot among different heights but the concentrations decreased sharply near the source and gradually became consistent mododor is efficient for dispersion simulation of gaseous contaminants from point sources and the plume evolution can be tracked with the aid of unsteady state simulation 3 2 application of mododor to gaseous contaminant dispersion from surface sources working face is recognized as the major source of odor emissions in landfills lu et al 2015 liu et al 2015 mododor was further applied to the dispersion simulation of odorants from working face with practical meteorological and emission intensity data the simulated results were compared with measurement data at downwind directions of the landfill a typical large anaerobic msw landfill in beijing was selected for the study the concentrations of gaseous contaminants at ground level 1 5 m high above the ground were measured from five selected downwind positions of the landfill fig 5 field sampling was conducted on october 30 2015 and the sampling campaign was repeated three times at each spot gas samples were collected using an soc 01 sampler national key laboratory of odor pollution control of epa china tianjin and placed in a 1 l multi layer foil sampling bag dalian delin gas packing co ltd the samples were quantitatively analyzed with hapsite er inficon east syracuse usa a portable gas chromatography mass spectrometer the details of the sampling procedure and sample analysis were summarized by the authors in a previous study liu et al 2016 the model inputs for the dispersion of the surface source are shown in table 2 meteorological data were collected during sampling see table 3 an example of the evolution of limonene plume on the ground is shown in fig 6 the plume shows good agreement with the behavior of the geophysical wind field moreover the model prediction results of limonene plume were compared with the measurement data as shown in fig 6 d it was found that the downwind concentration of modeled contaminant limonene decreased sharply near the source and then gradually reached a steady state around 6 μg m 3 most of the modeling concentrations were close to the observation data except those near the emission source the upright figure of fig 6 d showed the relationship between modeling results and observation the solid line is a standard to evaluate the simulation results which represents the simulation results are equal to the observation data if the point is higher than the solid line then the mododor results are overestimated and vice versa therefore the closer the points are to the solid line the more accurate the simulation results are the dashed lines represent 50 confidence intervals it was found that most of the modeling results were within the 50 confidence intervals except a blue circle and a red triangle the two symbols represent the results near the source at a distance of 100 m relative high errors are found near the source which have also been found in the analytical solutions but the simulation results are close to observation data with the increase of downwind distance the normalized mean square error was 0 72 overall the model satisfactorily described the observed data it should be stated that detailed temporal and spatial variable meteorology data are not available hence simple assumptions on meteorology and terrain are made in the application case which are major limitations for model simulation and attribute to errors in the simulation results above all the software mododor developed in the current study is valuable mododor is meaningful in both theoretical and practical aspects with the help of user friendly software the simulation processes become easy and model calculation is simplified at the same time with the development of air dynamic theory and meteorological measurement both of the model theory and the software are progressing the limitation of meteorology information is temporary and it would become easier for the users to get a sufficient knowledge of meteorology then the modeling results would become more precise 4 conclusions mododor a 3d unsteady state numerical model was developed for the dispersion simulation of gaseous contaminants from waste management facilities the software was developed based on the eulerian approach and the finite difference method was introduced for the solution of advection diffusion equations mododor can generate potential flow solutions associated with complex terrain features and simulate spatiotemporal variations in meteorological conditions and physical chemical depletion processes mesh property topography information wind field turbulent coefficients meteorological conditions boundary conditions deposition and chemical reaction constants are required inputs mododor provides a user friendly interface for data entry after calculation the results can be plotted automatically by mododor the model was applied to pollutant dispersion of a transfer station point source and a landfill site area source environment conditions such as complex terrain and meteorological conditions are well considered in mododor moreover the unsteady state dispersion process of mododor which is considered a significant function provides a means to track plume evolution mododor can become an effective tool for environmental impact assessment and site selection of waste management facilities due to the lack of detailed spatially variable meteorology data simple assumptions on meteorology and terrain were made for the model application more realistic evaluations using high resolution input data should be conducted acknowledgment this work was financially supported by national natural science foundation of china china no 51808520 and no 51578312 appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 12 001 appendix interfaces of the mododor fig a1 interface of mesh sheet fig a1 fig a2 interface of initial condition sheet fig a2 fig a3 interface of boundary condition sheet fig a3 fig a4 interface of wind sheet fig a4 fig a5 interface of diffusion sheet fig a5 fig a6 interface of meteorology sheet fig a6 fig a7 interface of source sheet fig a7 fig a8 interface of deposition sheet fig a8 fig a9 interface of chemical reaction sheet fig a9 fig a10 interface of solution sheet fig a10 fig a11 interface of output sheet fig a11 fig a12 example of result output figures fig a12 model validation with analytical solutions analytic solution fig a13 scheme of volumetric analytical simulation fig a13 the analytic solution for continuous source in semi infinite half space is as follow a1 c x y z t 1 8 l w h 0 t s t τ f x y z τ d τ a2 f x y z t exp k t erfc x u t x 0 l 2 k x t erfc x u t x 0 2 k x t erfc y y 0 w 2 k y t erfc y y 0 2 k y t erfc y y 0 2 k y t erfc y y 0 w 2 k y t erfc z z 0 h 2 k z t erfc z z 0 2 k z t erfc z z 0 2 k z t erfc z z 0 h 2 k z t where c is concentration l w and h are the length width and height of the source respectively u is the wind speed along x axis direction t is time k y and k y are the diffusion coefficient along y and z axis direction respectively x 0 y 0 and z0 are the coordinate position of the left top point of the source x y and z are the coordinate positions of the calculated point k is the chemical reaction rate erfc is the error function 3d volumetric source scenario assume that the studied domain is clean at the beginning and the volumetric source is located at the position of x 0 102 m y 0 2 m z 0 3 m with a size of 2 m 2 m 2 m the studied domain is 260 m 18 m 18 m the emission rate of volumetric source is 1000 μg m 3s 1 dispersion coefficients are set as k x k y k z 10 m2 s 1 u x 2 m s 1 u y u z 0 no chemical reaction wet or dry depletion processes are considered e g k 0 k w 0 and w 0 analytical and numerical simulation results are plotted as follow it was recognized that mododor performs very well numerical simulation results of mododor are very close to the analytical results in all the studied domain and simulation time except the location of emission source fig a14 results comparison of mododor test with analytical solution fig a14 
26258,pollution caused by gaseous contaminant from waste treatment facilities such as wastewater plants municipal solid waste landfills transfer stations has elicited public concern the potential environmental impacts of gaseous emissions from waste sectors are regulated by legislations in many countries and dispersion models are powerful tools modeling of odor gas air dispersion software mododor a 3d unsteady state numerical model was developed in this study to simulate the dispersion of gaseous contaminants from waste sectors mododor overcomes the limitations of gaussian and lagrangian models when applied to unsteady state local scale gaseous dispersion from waste sectors because it adopts the numerical eulerian scheme and finite difference method particularly mododor can generate potential flow solutions associated with complex topography process different types of emission sources simulate spatiotemporal variations in meteorological conditions wind and dispersion and implement physical chemical reactions for tracking the temporal and spatial evolution of plume and managing gaseous pollution from waste sectors keywords waste treatment facility odor numerical 3d model finite difference method advection dispersion chemical reaction software availability name of software mododor modeling of odor gas air dispersion software developers hongtao wang yanjun liu hardware requirements any pc compatible with windows xp or better programming language embarcadero delphi xe2 cost free for demo version availability contact hongtao wang at htwang tsignhua edu cn 1 introduction gaseous contaminants emitted from waste treatment facilities such as wastewater and municipal solid waste msw treatment plants are eliciting public concern gaseous emissions from waste sectors especially aromatics pose significant health risks to workers and nearby neighborhoods odorous compounds such as sulfide and oxygenated compounds exert negative impacts within several kilometers of emitting facilities therefore investigating and determining the odor range and health risk impact zone are important nicell 2009 dispersion modeling is an efficient cost effective approach to assess the impacts of gaseous contaminants most odor regulations are defined through dispersion modeling capelli et al 2013 danuso et al 2015 periáñez 2005 pollutant dispersion models commonly originate from civil or industrial fields and disturbances in the type of emission source operation mode topography and climate exert significant effects on gaseous dispersion the impact distance of landfill sites in china should be determined by dispersion modeling in accordance with the standard for pollution control on the landfill site of municipal solid waste gb 16889 2008 due to the lack of specific model regular dispersion models have been used for predicting gaseous contaminant dispersion from waste facilities however a specific model with high accuracy in local scale and capability of dealing with complicated conditions is still desired most dispersion models follow gaussian lagrangian or eulerian approaches leelossy et al 2014 gaussian plume model is the most widely adopted core model in many plume atmospheric dispersion models such as aermod cimorelli et al 2005 aermod initially developed for steady state industrial point emission sources has been applied to model different source types including point area and volume sources emissions and meteorological conditions are assumed to be time invariant in gaussian models and for this reason these models are applied to model annual averages or time series of hourly concentration in addition low wind speeds calm atmospheric conditions and complex terrains limit the application of gaussian models lagrangian and eulerian grid models for dispersion simulation are more advanced than gaussian models pisso et al 2017 lagrangian models also known as particle models are stochastic and describe the motion of individual and non interacting elementary contaminants by considering random particle movements eulerian models grid models numerically solve the advection dispersion equations of wind generated turbulent flow and calculate the average concentration of pollutants in a 3d domain subdivided into grids dupont et al 2006 nguyen et al 1997 compared with lagrangian models eulerian models allow for a more accurate spatiotemporal representation and thus require more computing power the effects of gaseous contaminants from waste sectors are mainly concentrated within the vicinity normally several hundred meters to several kilometers of facilities and vary with meteorological conditions in temporal and spatial aspects variations in meteorological conditions including wind speed wind direction air humidity and rainfall exert significant effects on the dispersion process therefore small scale and high precision dispersion models that can simulate unsteady state and odorant depletion processes are required however weather conditions are considered homogeneous and stationary in gaussian models it is generally believed that commonly used steady state gaussian models are invalid when wind is weak or calm but several improvements have been proposed recently qian and venkatram 2011 calpuff a well known lagrangian model can simulate unsteady conditions during pollution transport transformation and reactions scire et al 2000 however this model was developed for long range transport scale 50 km and complex meteorological sounding data are required wang et al 2006 eulerian models provide a possible approach for dispersion simulation of gaseous contaminants at a small scale and in an unsteady state suh 2006 the average concentration of contaminants in wind generated turbulent flow is calculated in different spatial cells the results provide a more accurate spatiotemporal representation compared with the results of lagrangian models terrain features can also be simulated by setting the calculability of grids and depletion processes such as chemical reactions and depositions can be considered in the source sink term eulerian models have been developed for the calculation of the average concentrations of odorous pollutant from livestock waste in different spatial cells danuso et al 2015 however odorous dispersion from waste treatment facilities is different from livestock waste in which the source types and topography features are more complex therefore further investigations are still needed the objective of this work was to establish simple computer software for simulating and predicting the dispersion of gaseous contaminants from waste sectors to surrounding areas in relation to weather and terrain characteristics an unsteady state numerical dispersion model called modeling of odor gas air dispersion software mododor version 1 0 2014sr117141 was developed owing to the use of a numerical eulerian scheme mododor overcomes the limits of traditional dispersion models such as modeling scale unsteady state and depletion processes when applied to the simulation of gaseous contaminant dispersion from waste treatment facilities complex terrain features spatiotemporal variations in meteorological conditions chemical reactions and deposition processes can be considered in mododor multiple types of emission sources including point linear areal volumetric and their combination can also be simulated this software was used to simulate practical problems in the current work case studies of gaseous contaminants emitted from point and area sources were conducted and tested using field measurement data mododor provides a significant approach for comprehensively understanding the impacts of gaseous contaminants from waste treatment facilities 2 model description mododor is an unsteady state eulerian based model it is applicable to rural and urban areas flat and complex terrains surface and elevated releases multiple sources including point linear areal volumetric and their combination and relevant chemical transformation and deposition processes of gaseous contaminants as shown in fig 1 the main interface of the software contains three main components namely guide input and output windows the software provides a user interface 11 sheets in the input window for data entry default parameter values an automatic identification system for input errors inspection of input legitimacy function calculation for data entry graphical output interfaces and support systems for users to input parameters conveniently and efficiently 2 1 governing equations the governing equation adopted by mododor is based on the physical principles of mass conservation and the continuity of atmospheric fluid air parcels the assumptions of mododor are as follows 1 fluid is completely filled in the studied domain and incompressible 2 only gaseous pollutants that are ideally mixed with air are considered and separation due to the density difference during transportation processes is disregarded and 3 the temperature in the studied domain is homogeneous but which could vary with time the governing 3d advection diffusion differential equation is 1 c t v c d x y z g t 0 where v is the vector of wind speed in m s d is the source sink term in μg m3 s t is calculation time in second and c x y z t is the concentration of the contaminant modeled at the grid x y z and at time t in μg m3 expanding the first term on the left side of eq 1 and the source sink term as eqs 2 and 3 leads to eq 4 2 v c x k x c x y k y c y z k z c z u x c x u y c y u z c z 3 d s w k k w c 4 c t x k x c x y k y c y z k z c z u x c x u y c y u z c z w k k w c s x y z g t 0 where c is the concentration of the modeled contaminant in μg m3 k x k y and k z are diffusion coefficients in longitudinal lateral and vertical directions respectively in m2 s u x u y and u z are wind speeds in longitudinal lateral and vertical directions respectively in m s d is the source sink term in μg m3 s w is the decomposition rate of sink term in 1 s s is the source term in μg m3 s k is the rate constant for a first order chemical reaction in 1 s k w is the depletion rate of wet deposition in 1 s g is the studied domain x y and z represent the calculated positions and t is calculation time in second 2 2 finite difference discretization in temporal and spatial domains the governing equation is solved with the finite difference method by dividing the space domain into cubic grids beforehand fig 2 finite difference meshes can be equidimensional or unequidimensional the size of a cell i j l that is length width and height are marked as δx i δy j and δz l respectively the aim of mododor is to solve the concentrations in the center of each calculated grid detailed information on the simulated 3d spatial grids time steps and gaseous contaminants is inputted in the grid time sheet as shown in fig 1 the number of rows columns layers and time steps should be defined in the beginning in mododor the number of rows columns and layers should be integers in the range of 3 900 with a maximum grid number of 200 million grid size is a spatial variable in the range of 0 01 1000 m the simulation state is optional when the unsteady state is selected the model is run in time series when the steady state is selected dispersion is modeled according to the steady state statistical approach and the set of time lengths and time steps becomes invalid as shown in fig 3 topography is modeled by assigning bottom meshes as the outer meshes in mododor these bottom meshes are considered as closed boundary an impervious wall during modeling hence no mass could transport across the mesh interface only cells set as the inner meshes can be considered during modeling information on topography is entered in the mesh sheet fig a1 appendix the properties of the cells are assigned in this sheet eq 4 describes the concentration of 3d advection diffusion time independent for non isotropic plume in which wind field diffusion and depletion coefficients are variable in space and time the equation is evaluated with the crank nicolson method on the basis of the central difference in space and the trapezoidal rule in time thereby providing second order convergence in time crank and nicolson 1996 the time derivative c t is then evaluated and respective 3d fields are projected forward through a short time step δt the process is repeated over a succession of time steps to describe the evolution of concentration eqs 5a 5c are the discretization format of eq 4 5a c i j l k 1 c i j l k δ t k 1 l k c i j l l u c i j l s i j k 1 2 w i j l k i j l k w i j l c i j l k 1 w i j l k i j l k w i j l c i j l k 5b l k c i j l k x i 1 2 j l 2 δ x i δ x i 1 2 c i 1 j l k 1 c i j l k 1 c i 1 j l k c i j l k k x i 1 2 j l 2 δ x i δ x i 1 2 c i 1 j l k 1 c i j l k 1 c i 1 j l k c i j l k k y i j 1 2 l 2 δ y j δ y j 1 2 c i j 1 l k 1 c i j l k 1 c i j 1 l k c i j l k k y i j 1 2 l 2 δ y j δ y j 1 2 c i j 1 l k 1 c i j l k 1 c i j 1 l k c i j l k k z i j l 1 2 2 δ z l δ z l 1 2 c i j l 1 k 1 c i j l k 1 c i j l 1 k c i j l k k z i j l 1 2 2 δ z l δ z l 1 2 c i j l 1 k 1 c i j l k 1 c i j l 1 k c i j l k 5c l u c i j l u x i 1 2 j l c i 1 2 j l δ x i u x i 1 2 j l c i 1 2 j l δ x i u y i j 1 2 l c i j 1 2 l δ y i u y i j 1 2 l c i j 1 2 l δ y i u z i j l 1 2 c i j l 1 2 δ z i u z i j l 1 2 c i j l 1 2 δ z i there are two terms for the calculation of time one is time step which represents the minimum time scale for the finite difference diffusion advection calculation the aim of setting time step is to ensure the precise of calculation time step is decided on the basis of the peclet and courant number and background commutated by mododor the other term is time period which is decided by the users in mododor software at the main interface fig 1 time periods are composed by time steps and the sum of all the time periods makes the time domain during the simulation of mododor meteorological parameters are time dependent variable between different time periods the time domain is averagely divided into n t parts k 0 1 2 n t 1 and each part is termed as a time step δt that is δ t k 1 t k 1 t k where t k 1 and t k are the time in k 1 and k respectively and t k 0 0 the time step should be limited and sufficiently short to avoid numerical dispersion and oscillation during the solving of the convection and diffusion equation in mododor the peclet number pe and the courant number cr are limited to avoid computational instability and obtain convergent results first the peclet number is limited to values lower than 1 p e t max 1 as follows 6 p e t i j l δ t k 1 max u x i j l 2 k x i j l u y i j l 2 k y i j l u z i j l 2 k z i j l 1 therefore time step δt k 1 is limited to 7 δ t k 1 min k x i j l u x i j l 2 k y i j l u y i j l 2 k z i j l u z i j l 2 the courant number is also limited to values lower than 1 c r t max 1 as follows 8 c r t i j l δ t k 1 max u x i j l δ x i u y i j l δ y j u z i j l δ z l 1 therefore time step δt k 1 should also satisfy the constraints of 9 δ t k 1 min δ x i u x i j l δ y j u y i j l δ z l u z i j l the set of advection diffusion eq 1 is solved by using a numerical scheme with upstream weighting lu 1992 kozdon et al 2011 which is a type of eulerian model solution that is the optimum and the most accurate method when turbulent diffusion plays the key role pe 2 in gas transport however when advection is the main factor that affects the transport pe 2 the upstream weighting method might cause numerical diffusion the solution interface solution sheet is shown in fig a10 appendix a reduction in time step increases the solution accuracy in mododor a time step reduction factor in the range of 0 0001 1 with a default value of 0 05 is manually entered the successive over relaxation sor method is used to solve the finite difference equations the solution parameters namely maximum number of iterations absolute error of convergence 0 001 0 000001 and relaxation factor of sor 0 2 are optional in mododor and have default values of 10 000 0 0001 and 1 2 respectively 2 3 initial and boundary conditions for unsteady state simulation mododor allows assigning an initial concentration of the gaseous contaminants in the studied domain in the initial condition sheet fig a2 appendix eq 10 provides the calculative process of the initial condition setting the initial condition is no longer necessary for stable conditions three options are available in the initial condition sheet concentration 0 concentration constant and assign by grids 10 c x y z t t 0 c 0 x y z x y z g where c 0 x y z is the initial concentration in the studied domain in μg m3 given that the entire studied domain is a cube like space in mododor each surface is defined as a boundary and referred to as front back left right upper and lower boundaries in the boundary condition sheet as shown in fig a3 appendix the boundary property should be set as open or closed closed boundary means that no flux of gas and pollutants can flow into or out of the studied domain through the surface for open boundary mododor assumes that the inflow is clean and no pollutant enters through the boundary however pollutants could flow out of the boundary with wind and the concentrations on the surface are assumed to be similar to those of boundary grids furthermore mododor allows complex conditions to be set for open boundaries including dirichlet or first type neumann or second type and mixed boundary conditions the governing equations of the three boundaries are shown in eqs 11 13 respectively the boundary condition can be set by grids the lower boundary is set as closed and the other boundaries are set as open default in mododor the dirichlet or first type boundary condition is 11 c x y z t γ 1 c 1 x y z t x y z γ 1 t 0 the neumann or second type boundary condition is 12 k x c x cos n x k y c y cos n y k z c z cos n z γ 2 f x y z t x y z t 0 the mixed boundary condition is 13 k x c x u x c cos n x k y c y u y c cos n y k z c z u z c cos n z γ 3 g x y z t x y z t 0 where c 1 x y z t is the given concentration in the first type boundary γ1 in μg m3 f x y z t is the turbulent diffusion flux in the second type boundary γ2 in μg m2 s g x y z t is the sum of advection and turbulent flux in the boundary γ3 in μg m2 s cos n x cos n y and cos n z are direction cosines and γ is the boundary of the studied domain γ1 γ2 γ3 γ 2 4 wind field mododor provides four options for the assignment of wind field the four options are constant in the studied domain spatial variance for each grid temporal variance spatial homogeneous and the diagnostic adjustment model wind information is entered in the wind sheet fig a4 appendix when the adjustment wind field model is selected information on wind speed wind direction and location and height of observation stations are required mododor can calculate the wind field on the basis of 100 observation stations at the maximum the diagnostic adjustment wind field is assigned based on observation data montero 2001 the following steps are included 1 construction of an initial horizontal wind field 2 extraction of the vertical wind profile and 3 adjustment of the wind field by minimizing a least square function montero 2001 mocioaca et al 2009 for the horizontal wind field the sparsely observed data are interpolated at the height of the observation stations and the inverse of the squared distance between the grids and observation station is adopted as the weighting factor as shown in eq 14 14 v 0 i j 1 w i j n 1 n v n r n i j 2 n 1 n 1 r n i j 2 w i j n 1 n v n δ h n i j n 1 n 1 δ h n i j w i j 2 π n n 1 n arctan δ h n i j r n i j where v 0i j is the initial wind velocity at grid i j the subscript 0 represents the initial wind speed i j are the numbers of columns and rows respectively v n is the initial wind speed value at observation station n n is the number of observation stations r n i j is the horizontal distance between station n and grid i j δ h n i j is the absolute value of the vertical distance between station n and grid i j and w i j is the weighting factor vertical wind profiles are built according to atmospheric stability conditions wind direction turbulence temperature and temperature gradient are required meteorological observations the profile equations for wind speed are as follows 15 u z u 7 z 0 z 7 z 0 z 7 z 0 u κ ln z z 0 ψ m z l ψ m z 0 l 7 z 0 z z pbl u z pbl z z pbl where κ is the von karman constant which is usually κ 0 4 u is the friction velocity in m s l is monin obukhov length in m u is wind speed in m s z is the calculated height in m z 0 is the roughness length in m z pbl is the height of the planetary boundary layer in m and ψ m is the stability term for unstable conditions z l 0 16a ψ m z l 2 ln 1 x 2 ln 1 x 2 2 2 arctan x π 2 x 1 16 z l 1 4 16b ψ m z 0 l 2 ln 1 x 0 2 ln 1 x 0 2 2 2 arctan x 0 π 2 x 0 1 16 z 0 l 1 4 during stable conditions z l 0 ψ m is calculated from van ulden and holtslag 1985 as 17a ψ m z l 5 z l z l 1 17 1 exp 0 29 z l z l 1 17b ψ m z 0 l 5 z 0 l z l 1 17 1 exp 0 29 z 0 l z l 1 friction velocity is calculated by 18 u κ u 0 z ln z z 0 ψ m z l ψ m z 0 l 19 l ρ c p t u 3 κ g h the height of the boundary layer is calculated as 20 z pbl 0 4 u f l l 0 0 3 u f l 0 f 2 ω sin ϕ π 180 where f is the coriolis parameter ϕ is the latitude of the studied location in degrees and ω is geostrophic velocity ω 7 2921 10 5 rad s the wind field is adjusted by minimizing a least squares function 2 5 turbulence parameterization evaluations of vertical and horizontal diffusion coefficients are necessary to solve eq 1 the vertical and horizontal diffusion coefficients are entered into the diffusion sheet fig a5 appendix despite manually assigning turbulence parameters by grid mododor can calculate diffusion coefficients on the basis of atmospheric stability according to technical methods for establishing local emission standards of air pollutants epa of china 1991 if the diagnostic wind field or stability calculation of the turbulence parameters is selected then meteorological information such as temperature simulation date and time longitude and latitude of the studied location total cloud cover and low cloud cover is required in the meteorology sheet fig a6 appendix otherwise the meteorology sheet would be unavailable 2 6 source terms the information of source terms is entered in the source sheet and the interface is shown in fig a7 appendix sources are set by grids and mododor supports multiple types of sources including point areal volumetric and their combination the temporal variance of the source strength for unsteady state simulations is available in mododor and the time step should be in accordance with the grid time sheet 2 7 depletion process three plume depletion processes namely dry deposition wet deposition and chemical reaction processes can be modeled in mododor by using depletion coefficients this condition means that the physical or chemical processes involved in the removal of pollutants from plume are represented by simple proportionality between removal rates and local airborne concentration of materials surface dry deposition is easily treated in mododor as the lower boundary condition thus 21 c t u dep c z where each side represents the vertical downward flux of pollutants and u dep is the deposition velocity in 1 s the calculation of u dep has been described by noll et al 2001 mododor uses the washout coefficient method for wet deposition and assumes that removal processes are independent and irreversible 22 c t k w c where k w is the wet deposition coefficient in 1 s which is empirically in the range of 0 4 10 5 3 0 10 3 1 s k w aj b where j is the rainfall rate in mm h and a and b are parameters depending on the type of pollutant the default values of constants a and b are a 1 0 10 4 b 0 64 carrytgers et al 1994 the deposition process is assumed to be homogeneous in the domain and calculated in the sink term eq 1 information on deposition velocity u dep in eq 21 for dry deposition and the wet deposition coefficient k w in eq 22 are manually entered in the deposition sheet fig a8 for chemical reactions mododor assumes that all pollutants follow first order chemical reactions during gaseous contaminant transportation as shown in eq 23 reaction rate constant k 1 s is adapted from existing references atkinson et al 2007 2008 23 c t k c information on the reaction rate constants k is manually entered in the chemical reaction sheet fig a9 mododor offers default deposition velocities and reaction constants in the guide window 2 8 output the calculate button beside the guide window is pressed when all the parameters have been determined and entered in mododor the results are then displayed in the output window at the bottom outputting the input data and results of each time step in the results is optional in addition mododor offers the following four output formats for the results concentration of ground layer grids concentration of the selected layer concentration of all grids and concentration of the selected domain the results can be presented in a matrix or a column x y z c the interface of output sheet is shown in fig a11 mododor also provides plotting functions including vertical concentration curves and a contour map to express the results visually fig a12 3 case studies of mododor 3 1 application of mododor to gaseous contaminant dispersion from point sources odor pollution from transfer stations has elicited increased concern because such stations are usually situated in cities and are near residential districts a large transfer station for msw in beijing city was selected as the study site for the assessment of odor pollution the transfer station is a building for the temporary deposition of waste where waste are sorted and compressed before transport to the end point of disposal in a landfill or incineration the station is operated under negative pressure and gas is discharged from 15 fan equipped exhaust outlets constructed on the roof of the facility given the relatively small scale of the source odor emission from the facility was considered a point source in this study four evenly distributed exhaust outlets were selected for sampling with the sampling points located at the center of the enclosures sampling campaigns were conducted on june 24 2014 during normal operations gas samples were collected from the four sampling spots at a time interval of 20 min from 9 30 a m to 12 00 a m the outlets were approximately 15 m high above the ground a total of 12 valid samples were obtained meteorological parameters wind velocity 2 1 m s temperature 31 c and humidity 51 were also measured during sampling detailed information on the sampling campaign and gas analysis were provided in a previous work zhao et al 2015 considering odor impacts hydrogen sulfide was considered for dispersion modeling details of the input data are shown in table 1 fig 4 shows the results of the mododor simulation the evolution of hydrogen sulfide concentration with time at the ground level is shown in fig 4 a the concentration of hydrogen sulfide decreased sharply with distance comparison of the concentration in the same spot showed that the concentration gradually increased and the concentration at 600 s was nearly similar to that in 1800 s indicating that dispersion nearly reached a steady state after 10 min fig 4 b compares the concentration of hydrogen sulfide at different heights the concentration at 15 m was larger than the others and rapidly declined with distance when the exhaust outlets were 15 m high above the ground significant differences were found in the source spot among different heights but the concentrations decreased sharply near the source and gradually became consistent mododor is efficient for dispersion simulation of gaseous contaminants from point sources and the plume evolution can be tracked with the aid of unsteady state simulation 3 2 application of mododor to gaseous contaminant dispersion from surface sources working face is recognized as the major source of odor emissions in landfills lu et al 2015 liu et al 2015 mododor was further applied to the dispersion simulation of odorants from working face with practical meteorological and emission intensity data the simulated results were compared with measurement data at downwind directions of the landfill a typical large anaerobic msw landfill in beijing was selected for the study the concentrations of gaseous contaminants at ground level 1 5 m high above the ground were measured from five selected downwind positions of the landfill fig 5 field sampling was conducted on october 30 2015 and the sampling campaign was repeated three times at each spot gas samples were collected using an soc 01 sampler national key laboratory of odor pollution control of epa china tianjin and placed in a 1 l multi layer foil sampling bag dalian delin gas packing co ltd the samples were quantitatively analyzed with hapsite er inficon east syracuse usa a portable gas chromatography mass spectrometer the details of the sampling procedure and sample analysis were summarized by the authors in a previous study liu et al 2016 the model inputs for the dispersion of the surface source are shown in table 2 meteorological data were collected during sampling see table 3 an example of the evolution of limonene plume on the ground is shown in fig 6 the plume shows good agreement with the behavior of the geophysical wind field moreover the model prediction results of limonene plume were compared with the measurement data as shown in fig 6 d it was found that the downwind concentration of modeled contaminant limonene decreased sharply near the source and then gradually reached a steady state around 6 μg m 3 most of the modeling concentrations were close to the observation data except those near the emission source the upright figure of fig 6 d showed the relationship between modeling results and observation the solid line is a standard to evaluate the simulation results which represents the simulation results are equal to the observation data if the point is higher than the solid line then the mododor results are overestimated and vice versa therefore the closer the points are to the solid line the more accurate the simulation results are the dashed lines represent 50 confidence intervals it was found that most of the modeling results were within the 50 confidence intervals except a blue circle and a red triangle the two symbols represent the results near the source at a distance of 100 m relative high errors are found near the source which have also been found in the analytical solutions but the simulation results are close to observation data with the increase of downwind distance the normalized mean square error was 0 72 overall the model satisfactorily described the observed data it should be stated that detailed temporal and spatial variable meteorology data are not available hence simple assumptions on meteorology and terrain are made in the application case which are major limitations for model simulation and attribute to errors in the simulation results above all the software mododor developed in the current study is valuable mododor is meaningful in both theoretical and practical aspects with the help of user friendly software the simulation processes become easy and model calculation is simplified at the same time with the development of air dynamic theory and meteorological measurement both of the model theory and the software are progressing the limitation of meteorology information is temporary and it would become easier for the users to get a sufficient knowledge of meteorology then the modeling results would become more precise 4 conclusions mododor a 3d unsteady state numerical model was developed for the dispersion simulation of gaseous contaminants from waste management facilities the software was developed based on the eulerian approach and the finite difference method was introduced for the solution of advection diffusion equations mododor can generate potential flow solutions associated with complex terrain features and simulate spatiotemporal variations in meteorological conditions and physical chemical depletion processes mesh property topography information wind field turbulent coefficients meteorological conditions boundary conditions deposition and chemical reaction constants are required inputs mododor provides a user friendly interface for data entry after calculation the results can be plotted automatically by mododor the model was applied to pollutant dispersion of a transfer station point source and a landfill site area source environment conditions such as complex terrain and meteorological conditions are well considered in mododor moreover the unsteady state dispersion process of mododor which is considered a significant function provides a means to track plume evolution mododor can become an effective tool for environmental impact assessment and site selection of waste management facilities due to the lack of detailed spatially variable meteorology data simple assumptions on meteorology and terrain were made for the model application more realistic evaluations using high resolution input data should be conducted acknowledgment this work was financially supported by national natural science foundation of china china no 51808520 and no 51578312 appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 12 001 appendix interfaces of the mododor fig a1 interface of mesh sheet fig a1 fig a2 interface of initial condition sheet fig a2 fig a3 interface of boundary condition sheet fig a3 fig a4 interface of wind sheet fig a4 fig a5 interface of diffusion sheet fig a5 fig a6 interface of meteorology sheet fig a6 fig a7 interface of source sheet fig a7 fig a8 interface of deposition sheet fig a8 fig a9 interface of chemical reaction sheet fig a9 fig a10 interface of solution sheet fig a10 fig a11 interface of output sheet fig a11 fig a12 example of result output figures fig a12 model validation with analytical solutions analytic solution fig a13 scheme of volumetric analytical simulation fig a13 the analytic solution for continuous source in semi infinite half space is as follow a1 c x y z t 1 8 l w h 0 t s t τ f x y z τ d τ a2 f x y z t exp k t erfc x u t x 0 l 2 k x t erfc x u t x 0 2 k x t erfc y y 0 w 2 k y t erfc y y 0 2 k y t erfc y y 0 2 k y t erfc y y 0 w 2 k y t erfc z z 0 h 2 k z t erfc z z 0 2 k z t erfc z z 0 2 k z t erfc z z 0 h 2 k z t where c is concentration l w and h are the length width and height of the source respectively u is the wind speed along x axis direction t is time k y and k y are the diffusion coefficient along y and z axis direction respectively x 0 y 0 and z0 are the coordinate position of the left top point of the source x y and z are the coordinate positions of the calculated point k is the chemical reaction rate erfc is the error function 3d volumetric source scenario assume that the studied domain is clean at the beginning and the volumetric source is located at the position of x 0 102 m y 0 2 m z 0 3 m with a size of 2 m 2 m 2 m the studied domain is 260 m 18 m 18 m the emission rate of volumetric source is 1000 μg m 3s 1 dispersion coefficients are set as k x k y k z 10 m2 s 1 u x 2 m s 1 u y u z 0 no chemical reaction wet or dry depletion processes are considered e g k 0 k w 0 and w 0 analytical and numerical simulation results are plotted as follow it was recognized that mododor performs very well numerical simulation results of mododor are very close to the analytical results in all the studied domain and simulation time except the location of emission source fig a14 results comparison of mododor test with analytical solution fig a14 
26259,for the neighbourhood scale a decomposition of the urban heat island uhi intensity δ t into its contributing processes is suggested the approach translates individual terms of the energy balance radiation evapotranspiration heat storage and convection into temperature increments this is exemplified using micrometeorological simulations envi met for the quarter bayerischer bahnhof in leipzig germany under different wind conditions in result heat storage and convection provide the principal contributions to uhi the mapping of δ t contributions in a neighbourhood is a new tool facilitating the development of tailored measures for reduction of and adaptation to urban heat for example the δ t contributions 6 8 2 6 9 2 and 15 7 k respectively calculated for a courtyard compensate each other applying this decomposition at each individual location suitable adaptation measures can be developed considering the superposition of all local δ t contributions can support a cost benefit analysis creating optimal recommendations for city planners keywords urban heat island envi met climate adaptation leipzig 1 introduction the urban heat island uhi effect where urban areas have higher temperatures than the rural surrounding embodies one of the most significant human induced alterations to earth s surface climate zhao et al 2014 the modifications comprise changes in meteorological variables such as moisture availability e g lee 1991 kuttler et al 2007 sailor 2011 and urban rural water vapour differences holmer and eliasson 1999 temperature e g arnfield 2003 heat fluxes e g grimmond and oke 2002 and turbulence e g roth 2000 arnfield 2003 given this uhi phenomenon and the observed increase in frequency and persistence of heat waves in european cities after 1997 e g christidis et al 2015 morabito et al 2017 there is urgent need for heat mitigation and adaptation actions the development of targeted strategies requires knowledge about the local uhi structures in order to minimise costs and efforts maximise heat reduction and avoid adverse health effects on the inhabitants we define the uhi effect as surface temperature difference between an urban region and the same area without built up structures with this local uhi intensity δ t we can assess excess heat directly on a scale where adaptation is needed namely within the living environment of urban residents so far small scale spatio temporal variability of δ t x t in space x and time t has been hardly examined by observations at the neighbourhood scale because a sufficient density of measurements is very expensive and difficult to realise micrometeorological models such as miskam eichhorn j 2011 muklimo sievers and zdunkowski 1986 sievers 2012 asmus gross 2012 or envi met http www envi met com might help to close this knowledge gap also these tools provide the opportunity to improve the understanding about underlying mechanisms of δ t formation following processes contribute to urban warming compared to rural land use brazel and quatrocchi 2005 net radiation flux r n 1 a s l ε σ t 4 radiation absorption positive s l and reflection as well as emission negative a s and ε σ t 4 respectively of the surface are influenced by the urban geometry see eq 2 for variable explanations anthropogenic heat flux q a h anthropogenic heat released positive from buildings vehicles metabolism and industries sensible heat flux q h turbulent vertical transport positive is reduced in an urban canopy layer latent heat flux q l e availability of water that can evaporate positive from vegetation or and from other surfaces is reduced storage heat flux q s heat is stored positive daytime and released negative night from urban building materials having higher heat capacities than rural land and result in the surface energy balance seb 1 r n q a h q h q l e q s for an urban neighbourhood when developing adaptation strategies city planners have to quantify all the thermal impacts which raises the question of how each of the seb terms can be converted into its respective δ t contribution micrometeorological models are based on the seb so that δ t contributions cannot be directly obtained from simulation results therefore this paper aims at converting the energy terms of eq 1 into temperature differences δ t related to the energy flux differences between rural and urban land use we also provide an interpretation of the individual contributions to δ t the developed decomposition procedure for δ t is guided by a previously suggested technique lee et al 2011 on mesoscale and we demonstrate how this approach can be applied to an urban neighbourhood in particular our study aims to investigate the processes contributing to δ t in a typical central european mid size city in order to improve the development of climate adaptation strategies develop spatial maps for each δ t contribution to identify areas particularly demanding for climate adaptation measures analyse whether convection efficiency is also for neighbourhoods microscale the dominant δ t driver as was stated for whole cities and metropolitan regions mesoscale zhao et al 2014 assess how the chosen initial wind direction influences the δ t contributions 2 case study area the case study was realised for leipzig a central european mid size city with 595 952 inhabitants reference stadt leipzig 2018 the city is situated in a lowland in eastern germany 51 20 n 12 22 e and classified as cfb warm temperate with warm summers fully humid climate after köppen geiger kottek et al 2006 with mean annual temperature 9 1 c and mean annual precipitation 584 6 m m at the german weather service dwd station leipzig holzhausen because of the usually dense building structure in the urban core it is very difficult to adapt such areas to climate change a good chance for interventions arises during the planning process to revitalise urban brownfields leipzig has some of these areas whereby one amongst them the quarter around the bayerischer bahnhof was used in this study fig 1 the area encompasses 455 625 m 2 3 methodological framework our framework consists of a 3 step process firstly we calculated the spatio temporal development of environmental parameters by means of an envi met simulation version 3 1 secondly a procedure for the decomposition of δ t was developed and applied thirdly the results were visualised and comparatively discussed 3 1 micrometeorological simulations for urban and rural states envi met is a 3d micrometeorological model and a state of the art tool for microscale simulations evaluated by e g yang et al 2013 chen et al 2014 elnabawi et al 2015 lee et al 2016 roth and lim 2017 liu et al 2018 with very accurate representation of microphysical processes inside the urban boundary layer e g huttner 2012 simon 2016 it incorporates fluid mechanical hydrological atmospheric and thermodynamic processes the local thermal conditions are determined through the built up structure so that envi met is particularly suitable to investigate microscale interactions between buildings vegetation soils and the atmospheric boundary layer envi met is classified to the group of non hydrostatic models including with respect to the interactions a vegetation model and a one dimensional soil model soil vegetation atmosphere transport svat interactions and an atmosphere model including radiative transfer model bruse and fleer 1998 in the past numerous studies with envi met have been undertaken but primarily about impacts of urban structures on the microclimate e g middel et al 2014 skelhorn et al 2014 and human thermal comfort e g ali toudert and mayer 2007 salata et al 2015 taleghani et al 2015 lee et al 2016 as well as possible mitigation adaptation strategies e g green infrastructure ng et al 2012 zoelch et al 2016 for urban heat reduction middel et al 2014 skelhorn et al 2014 although some studies incorporate uhi mitigation analyses e g emmanuel and fernando 2007 o malley et al 2015 wang and akbari 2016 they do not consider the physical causes of δ t formation in detail the characteristics of the neighbourhood simulated in our study are used as input for envi met and comprise the area input file table 1 as well as the configuration file table 2 to assess the impact of urban land use on δ t two different scenarios were simulated the urban state represents the current land use and real structure of buildings in the study area these simulations were compared with a reference scenario that is the rural state characterised by grassland without any urban structure trees hedges and bushes remain unchanged for both scenarios a urban state the neighbourhood bayerischer bahnhof was used for the envi met simulations specifications can be found in table 1 visualisation in fig 2 and characterises the so called urban state the area consists of a variety of different land use types to analyse urban impacts in detail all land use data have been defined for each grid cell in the model area by help of a satellite image which was uploaded to the envi met editor as an underlying bitmap a cell can only be comprised of one object type building or vegetation and surface type e g asphalt concrete the height of the objects is derived from a 3d urban model 3d stadtmodell 2012 for our analysis we chose a warm and cloudless day 21 july 2015 to simulate a definitive uhi effect the output was stored during 48 h at each full hour the first 18 h have to be considered as initialisation phase after which a steady state is reached see preliminary tests in fig s11 in the supplementary material therefore only the second day was used for the δ t decomposition the statistical analysis of the frequency of typical wind speeds depending on wind directions showed that high wind speeds are associated with south westerly directions and low wind speeds with easterly south easterly directions fig s12 in supplementary material in order to cover the whole range we considered three different wind scenarios 103 east wind 193 south wind and 283 west wind to analyse differences in δ t contributions for typical wind directions since numerical models cannot calculate reliable values near their borders an additional grid the so called nesting cells was introduced outside of the modelled area several experiments with different numbers of nesting cells suggested that 12 cells resulted in stable simulations the horizontal and vertical grid sizes are constant over the core model area table 1 except the first vertical cell which is divided up into 5 single cells the vertical grid size of the soil model is 0 015 m near the surface and up to 0 5 m in deeper layers boundary surfaces roofs walls soils are treated separately from the prognostic differential equations and subgrid scale processes microphysics are parameterised we selected a horizontal grid size of 3 by 3 m and a vertical one of 1 m according to the size of the objects to be resolved e g trees streets or buildings to provide more realistic values for the model input we used the envi met setting of an averaged solar input this option copies the shading effect of the built up structure onto the nesting area simulating the presence of a similar urban structure b rural state for the reference scenario all urban structures buildings sealed surfaces such as asphalt or concrete were replaced by grass representing rural conditions further to get spatially constant values for the simulated parameters they were averaged over all grid cells for each time step of the rural simulation on the one hand such a mean rural state can not represent localised effects as for instance microscale turbulence or a homogenisation of the wind flow influencing just the local thermal characteristics on the other hand we achieve representative rural conditions not influenced by a subjective definition of rural model cells finally for each grid cell δ t ensues from the temperature difference between the urban state simulation and the mean of the rural scenario without any urban structures 3 2 decomposition of δ t here we use a decomposition approach described in detail in hertel and schlink 2018 and guided by lee et al 2011 and zhao et al 2014 who considered meso cities and continental scales for the neighbourhood scale we obtain a seb eq 1 2 1 a s l ε σ t 4 r n q a h 1 1 β ρ c p r a t t a q s a albedo s incoming short wave radiation l incoming long wave radiation ε surface emissivity t surface temperature ρ air density c p specific heat of air at constant pressure r a aerodynamic resistance to heat diffusion q l e eq 2 is substituted by q h β involving the dimensionless bowen ratio β assuming that t a is the temperature at a reference height spatially constant and not influenced by the urban structure we can linearise the long wave radiation term and receive 3 t t a λ 0 1 f r n q s q a h with f λ 0 ρ c p r a 1 1 β λ 0 1 4 ε σ t a 3 f is an energy redistribution factor and λ 0 coincides with the definition of the local climate sensitivity parameter roe 2009 eq 3 is applied to the temperature difference between an urban and a rural state assuming t t u and t a t r and using t u t r δ t with analogue replacements for r n r a β q s and q a h u urban state r rural state δ represents small perturbations generated by the urban structure inserting these replacements into eq 3 allows for calculating the derivatives of all quantities associated with δ resulting in the uhi intensity δ t of an urban neighbourhood neglecting higher order terms it follows for δ t 4 δ t λ 0 r 1 f r δ r n δ t r n λ 0 r 1 f r 2 r n r q s r q a h δ f 1 δ t f 1 λ 0 r 1 f r 2 r n r q s r q a h δ f 2 δ t f 2 λ 0 r 1 f r δ q s δ t q s λ 0 r 1 f r δ q a h δ t q a h with δ f 1 λ 0 r ρ c p r a r 1 1 β r δ r a r a r δ f 2 λ 0 r ρ c p r a r δ β β r 2 all required quantities can be gathered from either the urban simulation output the rural simulation output or in the case of physical constants from the literature table 3 in this case study we neglected δ t q a h q a h vanishes in all other terms which describes the effect of anthropogenic heat and can not be calculated from envi met as the storage heat flux is not directly provided by envi met we calculated δ q s x t applying eq 4 to the modelled temperature difference between urban and rural simulations δ t m o d e l t u t r 5 λ 0 r 1 f r δ q s λ 0 r 1 f r δ r n λ 0 r 1 f r 2 r n r q s r δ f 1 λ 0 1 f 2 r n r q s r δ f 2 δ t m o d e l q s r x t was derived as residual of the urban surface energy balance eq 2 for the rural state 6 q s r 1 a r s r l r ε r σ t r 4 q h r q l e r 3 3 visualisation as a result of the δ t decomposition we achieved maps of the study area for each partition of δ t to identify dominant contributions to urban heat and to give recommendations for local adaptation actions the δ t x t s were visualised and for specific locations comparatively discussed 4 results and discussion the hottest surface temperatures were simulated for 2 p m when we can expect most pronounced uhi effects fig 3 4 1 total uhi intensity δ t strong warming reddish contours in fig 3b occurs at locations without vegetation in inner courtyards asphalt streets and most parts of the brownfield cooling bluish is mostly associated with trees bushes hedges and heavily shaded places white contours see figs 4 7 are outside the scale range and represent following critical cases first if f r 1 eq 4 diverges and white countours are plotted in the δ t maps negative values of f r are only possible if β r 0 r a r 0 λ 0 r 0 for physical reasons ρ as well as c p are positive material constants a negative β denotes the so called oasis effect where a small area evaporates more than its surroundings and this is typically found within a desert or over lakes warm and dry air flows over a very wet surface resulting in a large latent heat flux directed upwards to the atmosphere this evaporation cools the surface and generates a sensible heat flux directed downwards to a lesser extent such a phenomenon can be found near single trees small vegetated areas or irrigated surfaces surrounded by very dry areas e g sealed surfaces second if q l e 0 which happens quite often over dry surfaces β becomes very large as a result δ f 2 becomes very small f r very large and so especially δ t f 2 would be close to 0 which looks like a 0 contour in fig 6 and cannot be resolved this goes along with areas where no or less evapotranspiration take place this is often the case over e g urbanised regions with a high percentage of impervious soils and especially at night due to the absence of solar radiation third for r a 0 and or β 0 f r δ f 1 and eq 4 gives infinite solutions poles as a result δ t 4 2 changes in radiation balance δ t r n the temperature increase arising from the radiation balance fig 4 responds to shading effects of buildings and vegetation shading within vegetation is primarily determined by the leaf area density lad therefore greatest cooling was found under very dense tree crowns and hedges especially within inner courtyards e g fig 4 left side residential area and next to high buildings a slight warming occurs at concrete surfaces e g main road in the south of the brownfield which can absorb more short wave radiation than natural surfaces asphalt and the open built up structure causes a warming although as soon as the road reaches a narrow street canyon in the residential area shadowing is created by the surrounding buildings due to sun height 53 23 and azimuth angle 206 39 preferably radiation can laterally penetrate into south north oriented street canyons and produces a surplus of heat shadows in fig 3a indicate the sun position the wind direction slightly modifies δ t r n since turbulent fluxes are determined by the flow field and are incorporated in fr differences occur in the magnitude of both warming and cooling while the principal patterns are the same south as well as west wind scenarios in supplementary material figs s1 and s6 respectively are only a few hundredth till tenths of a degree cooler or warmer than the east wind scenario 4 3 changes in convection efficiency δ t f 1 zhao et al 2014 observed that in humid climate zones convection efficiency in cities was lower r a higher than in their rural surroundings this is likewise valid for leipzig in temperate climate fig 5 convection efficiency slightly depends on the wind scenario and the built up structure for example in the residential area on the left side in fig 5 there is a ssw nne oriented street affected by cooling the same street shows a slight warming under south wind conditions fig s2 in supplementary material and a change between warming and cooling under west wind conditions fig s7 in supplementary material due to the nature of convection efficiency the higher r a the more turbulence with tendency to small eddies can be produced in contrast in the rural area without any buildings turbulence produces larger convection cells and therefore r a is reduced large eddies are more effective in removing heat from the surface than smaller ones under east wind conditions the flow field along the above considered street is nearly perpendicular oriented to the buildings and this causes lee eddies inside the street canyon in the south and west wind scenario the orientation of the obstacles is more various which causes more small eddies this reduces the heat removing efficiency which in turn ends up in warming besides building orientation also the wind speed controls the convection efficiency since r a interpreted as resistance of the interface against the temperature gradient decreases with increasing wind speed because of enhanced mixing of air masses the lower r a the higher q h resulting in a higher heat removing efficiency in case of channelling effects between buildings or no blocking obstacles in wind direction the wind speed is high and causes cooling for instance near some objects and street canyons directly behind the inflow edge the flow is slowed but on the other hand accelerated within the canyons the shape and dimension of the cooling contours depend on these effects which can be seen by comparing the three wind scenarios figs 5 s2 and s7 in supplementary material anyway the temperature differences are very small and again the spatial patterns are quite similar 4 4 changes in evapotranspiration δ t f 2 evapotranspiration is restricted to vegetation and unsealed surfaces sealed surfaces are impervious to water therefore at e g asphalt roads concrete surfaces and buildings no value can be calculated by the described decomposition scheme darkgrey contours in fig 6 the transpiration of vegetation depends on the lad and consequently the greatest cooling effect can be identified in the surrounding of trees with very dense crowns and hedges with high lad sand surfaces e g around a sports ground as used in envi met are situated above wet soil resulting in a constant humidity and since such a soil type is very pervious to water it produces strong cooling fig 6 the propagation of the cooling effect into surrounding cells depends on wind direction and turbulent humidity transport places with a strong cooling behind the respective inflow edge are warmer for another wind scenario warming due to δ t f 2 is dominated by surfaces with low percentage of dense vegetation only a few scrubs and bushes or grass see brownfield are situated at such locations often e g in inner courtyards vegetation is completely missing in total the differences are small 1 k 4 5 changes in heat storage δ t q s over annual periods the average storage heat flux vanishes for our study with a temporal resolution of 1 h the heat storage can reach significant magnitudes the amount of stored heat primarily depends on the surface material and its specific heat capacity thus e g asphalt roads show a strong warming fig 7 while most vegetated areas loamy and sandy soils in the brownfield or around the sports ground are cool the warming within some tree groups e g right inflow edge south of the sports ground in fig 7 is somewhat surprising cool air produced above vegetation canopies e g tree crowns can sink downwards because of its higher density and mix up with the underlying warmer air masses the denser the vegetation is the more heat can be stored under the vegetation canopy and can be used for mixing with cold air for that reason the canopy surface can be seen warmer than one would expect and creates a warming compared with the rural state the propagation of warming or cooling effects into surrounding cells depends on the wind direction where the strongest warming can be found in the main streets under east and west wind conditions fig 7 and fig s9 in supplementary material 4 6 decomposition of δ t at selected locations as a check of plausibility of the decomposition procedure we discuss the individual uhi contributions at four exemplary positions table 4 locations marked in fig 3b at location 1 there is a hot spot δ t 19 2 k the dominant driver with 18 4 k is heat storage due to high heat capacity of the asphalt surface although this place is surrounded by buildings a radiation surplus leads to a slightly positive uhi contribution δ t r n 0 7 k according to the sun position subsection 4 2 shading is not effective since a street is crossing this place from south west to north east because of scattering at surrounding objects this orientation allows for more radiation reaching the surface compared to the rural state the sky view factor is higher 0 65 than for position 2 and 4 for cooling more shading is desirable because of an impervious asphalt surface evaporation is negligible δ t f 2 0 as a consequence at location 1 an adequate strategy for climate adaptation would be to enable evaporation e g by using pervious asphalt materials e g with organic binding materials or by unsealed surfaces additionally this would reduce the large contribution to δ t q s location 2 is situated inside a courtyard under tree crowns which produce cooling δ t 2 9 k both the shadow and enhanced transpiration of vegetation are responsible for that δ t r n 0 δ t f 2 0 and the sky view factor has by far the lowest value 0 01 nearly the complete sky is obstructed convection is inefficient and provides the most dominant contribution δ t f 1 15 7 k because of low wind speed inside the courtyards and a small q h 5 4 w m 2 the other processes overcompensate this effect so that nevertheless cooling develops this example highlights how cooling can be achieved in a dense urban quarter and that it is a priori not obvious which contribution is dominant this requires detailed investigation location 3 is in a schoolyard with loamy soil and shows slight warming interestingly here the convection efficiency is increased and causes cooling δ t f 1 2 k the schoolyard is not completely enclosed with buildings so that the wind can flow undisturbed through the area high wind speed the dominant contribution to warming is the lack of evapotranspiration as the entire schoolyard has no or less vegetation δ t f 2 8 8 k although this place has an open space characteristic sky view factor 0 66 is highest radiation plays only a minor role due to shadowing by buildings this discussion highlights the strengths of the described approach in order to decide which adaptation measure is feasible in terms of a cost benefit assessment at this specific location it is clearly recommendable using irrigated grass surfaces on the one hand they can reduce surface temperatures and on the other hand pupils could use these areas for relaxing talking and playing with their friends during summertime location 4 shows warming because of the position next to a building inside a courtyard and without vegetation all contributions provide a warming even radiation because of the sun position although the sky view factor is relatively high 0 57 see subsection 4 2 the dominant contribution is δ t q s with 3 3 k the best option at this location is irrigated grass to enhance evapotranspiration and to increase albedo that reduces radiation absorption and the resulting stored heat for instance the 2 m air temperature at daytime can be reduced by up to 4 k morini et al 2018 within single neighbourhoods and on average 0 8 and 0 4 k at urban rural areas jandaghian and akbari 2018 respectively it is to be expected that the reduction for the surface temperature will be even more pronounced 5 limitations 225 by 225 cells were available for the simulation to get reasonable results and to include local structures e g streets or single trees a grid size smaller than 5 by 5 m is needed to dissolve such small objects which are important for the local uhi formation this limits the possible modelling area to approx 1125 by 1125 m local heat occurs mainly in an autochthonous weather situation as we assumed in our study to simulate this stable atmosphere initial wind speed was low 4 m s this might cause inaccurate simulations generally the uhi intensity is strongly affected by the surface material since flux divergences e g radiation from surrounding cells into the actual model cell are not taken into account by the present approach the transitions between contours are quite sharp an additional restriction is that although envi met version 3 considers shadows for radiation calculation inclination and exposition of surfaces are not included anthropogenic heat was neglected but studies like ichinose et al 1999 showed that anthropogenic heat at high resolutions can reach 800 w m 2 downtown tokyo which is why future modelling approaches should incorporate such fluxes since anthropogenic heat is originally involved in δ t f 1 and δ t f 2 only their magnitudes can be influenced but not the principal spatial patterns another issue are large values of the bowen ratio β through q l e 0 this problem cannot be neglected at the neighbourhood scale grid size within a few metres 6 conclusions we suggested an approach for the decomposition of urban warming δ t and applied it to a neighbourhood in leipzig germany the resulting maps of the individual uhi contributions as well as their discussion at places of interest demonstrated that there is no overall dominating uhi contribution nevertheless heat storage and convection efficiency dominate most parts of the quarter the greatest warming was found in streets with no or less trees over impervious surfaces such as asphalt or concrete and in general over unshaded areas with no or less vegetation brownfield parts of inner courtyards and street canyons convection efficiency that was previously presumed to be responsible for uhi in humid climates zhao et al 2014 proved to be not always the dominant driver for local uhi intensity often heat heat contributes the most to uhi the dynamic production of turbulent kinetic energy tke and their dissipation is highly influenced by wind speed and direction which in turn depends on the orientation of obstacles within the flow field therefore the convection efficiency slightly differs for the three wind scenarios east south west pronounced differences were found for the heat storage where east and west wind scenarios showed the strongest warming effect for the south wind scenario the warming at most areas is considerably smaller but in a few streets perpendicular to the wind direction it is stronger our study demonstrated that this approach can be a valuable contribution for a targeted development of mitigation and adaptation strategies to urban climate change 7 software and technical notes for micrometeorological simulations the model envi met http www envi met com was used to avoid inconsistencies in the results by using different model versions we used version 3 1 for all applications input data are achieved from a 3d city model buildings 3d stadtmodell 2012 and a meteorological measurement site institute for meteorology leipzig data http meteo physgeo uni leipzig de de wetterdaten index php visualisation conversion of envi met output data from binary format decomposition of δ t and the analysis were done with programs developed in r r core team 2015 the code also implements eqs 4 6 and is available on request from the authors acknowledgements d h was financially supported by the deutsche bundesstiftung umwelt dbu german federal environmental foundation osnabrück the authors gratefully acknowledge the help and support from the developer of envi met prof dr michael bruse in the use of this software appendix a supplementary data the following is the supplementary data to this article latex files supplementary revised latex files supplementary revised appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 11 015 
26259,for the neighbourhood scale a decomposition of the urban heat island uhi intensity δ t into its contributing processes is suggested the approach translates individual terms of the energy balance radiation evapotranspiration heat storage and convection into temperature increments this is exemplified using micrometeorological simulations envi met for the quarter bayerischer bahnhof in leipzig germany under different wind conditions in result heat storage and convection provide the principal contributions to uhi the mapping of δ t contributions in a neighbourhood is a new tool facilitating the development of tailored measures for reduction of and adaptation to urban heat for example the δ t contributions 6 8 2 6 9 2 and 15 7 k respectively calculated for a courtyard compensate each other applying this decomposition at each individual location suitable adaptation measures can be developed considering the superposition of all local δ t contributions can support a cost benefit analysis creating optimal recommendations for city planners keywords urban heat island envi met climate adaptation leipzig 1 introduction the urban heat island uhi effect where urban areas have higher temperatures than the rural surrounding embodies one of the most significant human induced alterations to earth s surface climate zhao et al 2014 the modifications comprise changes in meteorological variables such as moisture availability e g lee 1991 kuttler et al 2007 sailor 2011 and urban rural water vapour differences holmer and eliasson 1999 temperature e g arnfield 2003 heat fluxes e g grimmond and oke 2002 and turbulence e g roth 2000 arnfield 2003 given this uhi phenomenon and the observed increase in frequency and persistence of heat waves in european cities after 1997 e g christidis et al 2015 morabito et al 2017 there is urgent need for heat mitigation and adaptation actions the development of targeted strategies requires knowledge about the local uhi structures in order to minimise costs and efforts maximise heat reduction and avoid adverse health effects on the inhabitants we define the uhi effect as surface temperature difference between an urban region and the same area without built up structures with this local uhi intensity δ t we can assess excess heat directly on a scale where adaptation is needed namely within the living environment of urban residents so far small scale spatio temporal variability of δ t x t in space x and time t has been hardly examined by observations at the neighbourhood scale because a sufficient density of measurements is very expensive and difficult to realise micrometeorological models such as miskam eichhorn j 2011 muklimo sievers and zdunkowski 1986 sievers 2012 asmus gross 2012 or envi met http www envi met com might help to close this knowledge gap also these tools provide the opportunity to improve the understanding about underlying mechanisms of δ t formation following processes contribute to urban warming compared to rural land use brazel and quatrocchi 2005 net radiation flux r n 1 a s l ε σ t 4 radiation absorption positive s l and reflection as well as emission negative a s and ε σ t 4 respectively of the surface are influenced by the urban geometry see eq 2 for variable explanations anthropogenic heat flux q a h anthropogenic heat released positive from buildings vehicles metabolism and industries sensible heat flux q h turbulent vertical transport positive is reduced in an urban canopy layer latent heat flux q l e availability of water that can evaporate positive from vegetation or and from other surfaces is reduced storage heat flux q s heat is stored positive daytime and released negative night from urban building materials having higher heat capacities than rural land and result in the surface energy balance seb 1 r n q a h q h q l e q s for an urban neighbourhood when developing adaptation strategies city planners have to quantify all the thermal impacts which raises the question of how each of the seb terms can be converted into its respective δ t contribution micrometeorological models are based on the seb so that δ t contributions cannot be directly obtained from simulation results therefore this paper aims at converting the energy terms of eq 1 into temperature differences δ t related to the energy flux differences between rural and urban land use we also provide an interpretation of the individual contributions to δ t the developed decomposition procedure for δ t is guided by a previously suggested technique lee et al 2011 on mesoscale and we demonstrate how this approach can be applied to an urban neighbourhood in particular our study aims to investigate the processes contributing to δ t in a typical central european mid size city in order to improve the development of climate adaptation strategies develop spatial maps for each δ t contribution to identify areas particularly demanding for climate adaptation measures analyse whether convection efficiency is also for neighbourhoods microscale the dominant δ t driver as was stated for whole cities and metropolitan regions mesoscale zhao et al 2014 assess how the chosen initial wind direction influences the δ t contributions 2 case study area the case study was realised for leipzig a central european mid size city with 595 952 inhabitants reference stadt leipzig 2018 the city is situated in a lowland in eastern germany 51 20 n 12 22 e and classified as cfb warm temperate with warm summers fully humid climate after köppen geiger kottek et al 2006 with mean annual temperature 9 1 c and mean annual precipitation 584 6 m m at the german weather service dwd station leipzig holzhausen because of the usually dense building structure in the urban core it is very difficult to adapt such areas to climate change a good chance for interventions arises during the planning process to revitalise urban brownfields leipzig has some of these areas whereby one amongst them the quarter around the bayerischer bahnhof was used in this study fig 1 the area encompasses 455 625 m 2 3 methodological framework our framework consists of a 3 step process firstly we calculated the spatio temporal development of environmental parameters by means of an envi met simulation version 3 1 secondly a procedure for the decomposition of δ t was developed and applied thirdly the results were visualised and comparatively discussed 3 1 micrometeorological simulations for urban and rural states envi met is a 3d micrometeorological model and a state of the art tool for microscale simulations evaluated by e g yang et al 2013 chen et al 2014 elnabawi et al 2015 lee et al 2016 roth and lim 2017 liu et al 2018 with very accurate representation of microphysical processes inside the urban boundary layer e g huttner 2012 simon 2016 it incorporates fluid mechanical hydrological atmospheric and thermodynamic processes the local thermal conditions are determined through the built up structure so that envi met is particularly suitable to investigate microscale interactions between buildings vegetation soils and the atmospheric boundary layer envi met is classified to the group of non hydrostatic models including with respect to the interactions a vegetation model and a one dimensional soil model soil vegetation atmosphere transport svat interactions and an atmosphere model including radiative transfer model bruse and fleer 1998 in the past numerous studies with envi met have been undertaken but primarily about impacts of urban structures on the microclimate e g middel et al 2014 skelhorn et al 2014 and human thermal comfort e g ali toudert and mayer 2007 salata et al 2015 taleghani et al 2015 lee et al 2016 as well as possible mitigation adaptation strategies e g green infrastructure ng et al 2012 zoelch et al 2016 for urban heat reduction middel et al 2014 skelhorn et al 2014 although some studies incorporate uhi mitigation analyses e g emmanuel and fernando 2007 o malley et al 2015 wang and akbari 2016 they do not consider the physical causes of δ t formation in detail the characteristics of the neighbourhood simulated in our study are used as input for envi met and comprise the area input file table 1 as well as the configuration file table 2 to assess the impact of urban land use on δ t two different scenarios were simulated the urban state represents the current land use and real structure of buildings in the study area these simulations were compared with a reference scenario that is the rural state characterised by grassland without any urban structure trees hedges and bushes remain unchanged for both scenarios a urban state the neighbourhood bayerischer bahnhof was used for the envi met simulations specifications can be found in table 1 visualisation in fig 2 and characterises the so called urban state the area consists of a variety of different land use types to analyse urban impacts in detail all land use data have been defined for each grid cell in the model area by help of a satellite image which was uploaded to the envi met editor as an underlying bitmap a cell can only be comprised of one object type building or vegetation and surface type e g asphalt concrete the height of the objects is derived from a 3d urban model 3d stadtmodell 2012 for our analysis we chose a warm and cloudless day 21 july 2015 to simulate a definitive uhi effect the output was stored during 48 h at each full hour the first 18 h have to be considered as initialisation phase after which a steady state is reached see preliminary tests in fig s11 in the supplementary material therefore only the second day was used for the δ t decomposition the statistical analysis of the frequency of typical wind speeds depending on wind directions showed that high wind speeds are associated with south westerly directions and low wind speeds with easterly south easterly directions fig s12 in supplementary material in order to cover the whole range we considered three different wind scenarios 103 east wind 193 south wind and 283 west wind to analyse differences in δ t contributions for typical wind directions since numerical models cannot calculate reliable values near their borders an additional grid the so called nesting cells was introduced outside of the modelled area several experiments with different numbers of nesting cells suggested that 12 cells resulted in stable simulations the horizontal and vertical grid sizes are constant over the core model area table 1 except the first vertical cell which is divided up into 5 single cells the vertical grid size of the soil model is 0 015 m near the surface and up to 0 5 m in deeper layers boundary surfaces roofs walls soils are treated separately from the prognostic differential equations and subgrid scale processes microphysics are parameterised we selected a horizontal grid size of 3 by 3 m and a vertical one of 1 m according to the size of the objects to be resolved e g trees streets or buildings to provide more realistic values for the model input we used the envi met setting of an averaged solar input this option copies the shading effect of the built up structure onto the nesting area simulating the presence of a similar urban structure b rural state for the reference scenario all urban structures buildings sealed surfaces such as asphalt or concrete were replaced by grass representing rural conditions further to get spatially constant values for the simulated parameters they were averaged over all grid cells for each time step of the rural simulation on the one hand such a mean rural state can not represent localised effects as for instance microscale turbulence or a homogenisation of the wind flow influencing just the local thermal characteristics on the other hand we achieve representative rural conditions not influenced by a subjective definition of rural model cells finally for each grid cell δ t ensues from the temperature difference between the urban state simulation and the mean of the rural scenario without any urban structures 3 2 decomposition of δ t here we use a decomposition approach described in detail in hertel and schlink 2018 and guided by lee et al 2011 and zhao et al 2014 who considered meso cities and continental scales for the neighbourhood scale we obtain a seb eq 1 2 1 a s l ε σ t 4 r n q a h 1 1 β ρ c p r a t t a q s a albedo s incoming short wave radiation l incoming long wave radiation ε surface emissivity t surface temperature ρ air density c p specific heat of air at constant pressure r a aerodynamic resistance to heat diffusion q l e eq 2 is substituted by q h β involving the dimensionless bowen ratio β assuming that t a is the temperature at a reference height spatially constant and not influenced by the urban structure we can linearise the long wave radiation term and receive 3 t t a λ 0 1 f r n q s q a h with f λ 0 ρ c p r a 1 1 β λ 0 1 4 ε σ t a 3 f is an energy redistribution factor and λ 0 coincides with the definition of the local climate sensitivity parameter roe 2009 eq 3 is applied to the temperature difference between an urban and a rural state assuming t t u and t a t r and using t u t r δ t with analogue replacements for r n r a β q s and q a h u urban state r rural state δ represents small perturbations generated by the urban structure inserting these replacements into eq 3 allows for calculating the derivatives of all quantities associated with δ resulting in the uhi intensity δ t of an urban neighbourhood neglecting higher order terms it follows for δ t 4 δ t λ 0 r 1 f r δ r n δ t r n λ 0 r 1 f r 2 r n r q s r q a h δ f 1 δ t f 1 λ 0 r 1 f r 2 r n r q s r q a h δ f 2 δ t f 2 λ 0 r 1 f r δ q s δ t q s λ 0 r 1 f r δ q a h δ t q a h with δ f 1 λ 0 r ρ c p r a r 1 1 β r δ r a r a r δ f 2 λ 0 r ρ c p r a r δ β β r 2 all required quantities can be gathered from either the urban simulation output the rural simulation output or in the case of physical constants from the literature table 3 in this case study we neglected δ t q a h q a h vanishes in all other terms which describes the effect of anthropogenic heat and can not be calculated from envi met as the storage heat flux is not directly provided by envi met we calculated δ q s x t applying eq 4 to the modelled temperature difference between urban and rural simulations δ t m o d e l t u t r 5 λ 0 r 1 f r δ q s λ 0 r 1 f r δ r n λ 0 r 1 f r 2 r n r q s r δ f 1 λ 0 1 f 2 r n r q s r δ f 2 δ t m o d e l q s r x t was derived as residual of the urban surface energy balance eq 2 for the rural state 6 q s r 1 a r s r l r ε r σ t r 4 q h r q l e r 3 3 visualisation as a result of the δ t decomposition we achieved maps of the study area for each partition of δ t to identify dominant contributions to urban heat and to give recommendations for local adaptation actions the δ t x t s were visualised and for specific locations comparatively discussed 4 results and discussion the hottest surface temperatures were simulated for 2 p m when we can expect most pronounced uhi effects fig 3 4 1 total uhi intensity δ t strong warming reddish contours in fig 3b occurs at locations without vegetation in inner courtyards asphalt streets and most parts of the brownfield cooling bluish is mostly associated with trees bushes hedges and heavily shaded places white contours see figs 4 7 are outside the scale range and represent following critical cases first if f r 1 eq 4 diverges and white countours are plotted in the δ t maps negative values of f r are only possible if β r 0 r a r 0 λ 0 r 0 for physical reasons ρ as well as c p are positive material constants a negative β denotes the so called oasis effect where a small area evaporates more than its surroundings and this is typically found within a desert or over lakes warm and dry air flows over a very wet surface resulting in a large latent heat flux directed upwards to the atmosphere this evaporation cools the surface and generates a sensible heat flux directed downwards to a lesser extent such a phenomenon can be found near single trees small vegetated areas or irrigated surfaces surrounded by very dry areas e g sealed surfaces second if q l e 0 which happens quite often over dry surfaces β becomes very large as a result δ f 2 becomes very small f r very large and so especially δ t f 2 would be close to 0 which looks like a 0 contour in fig 6 and cannot be resolved this goes along with areas where no or less evapotranspiration take place this is often the case over e g urbanised regions with a high percentage of impervious soils and especially at night due to the absence of solar radiation third for r a 0 and or β 0 f r δ f 1 and eq 4 gives infinite solutions poles as a result δ t 4 2 changes in radiation balance δ t r n the temperature increase arising from the radiation balance fig 4 responds to shading effects of buildings and vegetation shading within vegetation is primarily determined by the leaf area density lad therefore greatest cooling was found under very dense tree crowns and hedges especially within inner courtyards e g fig 4 left side residential area and next to high buildings a slight warming occurs at concrete surfaces e g main road in the south of the brownfield which can absorb more short wave radiation than natural surfaces asphalt and the open built up structure causes a warming although as soon as the road reaches a narrow street canyon in the residential area shadowing is created by the surrounding buildings due to sun height 53 23 and azimuth angle 206 39 preferably radiation can laterally penetrate into south north oriented street canyons and produces a surplus of heat shadows in fig 3a indicate the sun position the wind direction slightly modifies δ t r n since turbulent fluxes are determined by the flow field and are incorporated in fr differences occur in the magnitude of both warming and cooling while the principal patterns are the same south as well as west wind scenarios in supplementary material figs s1 and s6 respectively are only a few hundredth till tenths of a degree cooler or warmer than the east wind scenario 4 3 changes in convection efficiency δ t f 1 zhao et al 2014 observed that in humid climate zones convection efficiency in cities was lower r a higher than in their rural surroundings this is likewise valid for leipzig in temperate climate fig 5 convection efficiency slightly depends on the wind scenario and the built up structure for example in the residential area on the left side in fig 5 there is a ssw nne oriented street affected by cooling the same street shows a slight warming under south wind conditions fig s2 in supplementary material and a change between warming and cooling under west wind conditions fig s7 in supplementary material due to the nature of convection efficiency the higher r a the more turbulence with tendency to small eddies can be produced in contrast in the rural area without any buildings turbulence produces larger convection cells and therefore r a is reduced large eddies are more effective in removing heat from the surface than smaller ones under east wind conditions the flow field along the above considered street is nearly perpendicular oriented to the buildings and this causes lee eddies inside the street canyon in the south and west wind scenario the orientation of the obstacles is more various which causes more small eddies this reduces the heat removing efficiency which in turn ends up in warming besides building orientation also the wind speed controls the convection efficiency since r a interpreted as resistance of the interface against the temperature gradient decreases with increasing wind speed because of enhanced mixing of air masses the lower r a the higher q h resulting in a higher heat removing efficiency in case of channelling effects between buildings or no blocking obstacles in wind direction the wind speed is high and causes cooling for instance near some objects and street canyons directly behind the inflow edge the flow is slowed but on the other hand accelerated within the canyons the shape and dimension of the cooling contours depend on these effects which can be seen by comparing the three wind scenarios figs 5 s2 and s7 in supplementary material anyway the temperature differences are very small and again the spatial patterns are quite similar 4 4 changes in evapotranspiration δ t f 2 evapotranspiration is restricted to vegetation and unsealed surfaces sealed surfaces are impervious to water therefore at e g asphalt roads concrete surfaces and buildings no value can be calculated by the described decomposition scheme darkgrey contours in fig 6 the transpiration of vegetation depends on the lad and consequently the greatest cooling effect can be identified in the surrounding of trees with very dense crowns and hedges with high lad sand surfaces e g around a sports ground as used in envi met are situated above wet soil resulting in a constant humidity and since such a soil type is very pervious to water it produces strong cooling fig 6 the propagation of the cooling effect into surrounding cells depends on wind direction and turbulent humidity transport places with a strong cooling behind the respective inflow edge are warmer for another wind scenario warming due to δ t f 2 is dominated by surfaces with low percentage of dense vegetation only a few scrubs and bushes or grass see brownfield are situated at such locations often e g in inner courtyards vegetation is completely missing in total the differences are small 1 k 4 5 changes in heat storage δ t q s over annual periods the average storage heat flux vanishes for our study with a temporal resolution of 1 h the heat storage can reach significant magnitudes the amount of stored heat primarily depends on the surface material and its specific heat capacity thus e g asphalt roads show a strong warming fig 7 while most vegetated areas loamy and sandy soils in the brownfield or around the sports ground are cool the warming within some tree groups e g right inflow edge south of the sports ground in fig 7 is somewhat surprising cool air produced above vegetation canopies e g tree crowns can sink downwards because of its higher density and mix up with the underlying warmer air masses the denser the vegetation is the more heat can be stored under the vegetation canopy and can be used for mixing with cold air for that reason the canopy surface can be seen warmer than one would expect and creates a warming compared with the rural state the propagation of warming or cooling effects into surrounding cells depends on the wind direction where the strongest warming can be found in the main streets under east and west wind conditions fig 7 and fig s9 in supplementary material 4 6 decomposition of δ t at selected locations as a check of plausibility of the decomposition procedure we discuss the individual uhi contributions at four exemplary positions table 4 locations marked in fig 3b at location 1 there is a hot spot δ t 19 2 k the dominant driver with 18 4 k is heat storage due to high heat capacity of the asphalt surface although this place is surrounded by buildings a radiation surplus leads to a slightly positive uhi contribution δ t r n 0 7 k according to the sun position subsection 4 2 shading is not effective since a street is crossing this place from south west to north east because of scattering at surrounding objects this orientation allows for more radiation reaching the surface compared to the rural state the sky view factor is higher 0 65 than for position 2 and 4 for cooling more shading is desirable because of an impervious asphalt surface evaporation is negligible δ t f 2 0 as a consequence at location 1 an adequate strategy for climate adaptation would be to enable evaporation e g by using pervious asphalt materials e g with organic binding materials or by unsealed surfaces additionally this would reduce the large contribution to δ t q s location 2 is situated inside a courtyard under tree crowns which produce cooling δ t 2 9 k both the shadow and enhanced transpiration of vegetation are responsible for that δ t r n 0 δ t f 2 0 and the sky view factor has by far the lowest value 0 01 nearly the complete sky is obstructed convection is inefficient and provides the most dominant contribution δ t f 1 15 7 k because of low wind speed inside the courtyards and a small q h 5 4 w m 2 the other processes overcompensate this effect so that nevertheless cooling develops this example highlights how cooling can be achieved in a dense urban quarter and that it is a priori not obvious which contribution is dominant this requires detailed investigation location 3 is in a schoolyard with loamy soil and shows slight warming interestingly here the convection efficiency is increased and causes cooling δ t f 1 2 k the schoolyard is not completely enclosed with buildings so that the wind can flow undisturbed through the area high wind speed the dominant contribution to warming is the lack of evapotranspiration as the entire schoolyard has no or less vegetation δ t f 2 8 8 k although this place has an open space characteristic sky view factor 0 66 is highest radiation plays only a minor role due to shadowing by buildings this discussion highlights the strengths of the described approach in order to decide which adaptation measure is feasible in terms of a cost benefit assessment at this specific location it is clearly recommendable using irrigated grass surfaces on the one hand they can reduce surface temperatures and on the other hand pupils could use these areas for relaxing talking and playing with their friends during summertime location 4 shows warming because of the position next to a building inside a courtyard and without vegetation all contributions provide a warming even radiation because of the sun position although the sky view factor is relatively high 0 57 see subsection 4 2 the dominant contribution is δ t q s with 3 3 k the best option at this location is irrigated grass to enhance evapotranspiration and to increase albedo that reduces radiation absorption and the resulting stored heat for instance the 2 m air temperature at daytime can be reduced by up to 4 k morini et al 2018 within single neighbourhoods and on average 0 8 and 0 4 k at urban rural areas jandaghian and akbari 2018 respectively it is to be expected that the reduction for the surface temperature will be even more pronounced 5 limitations 225 by 225 cells were available for the simulation to get reasonable results and to include local structures e g streets or single trees a grid size smaller than 5 by 5 m is needed to dissolve such small objects which are important for the local uhi formation this limits the possible modelling area to approx 1125 by 1125 m local heat occurs mainly in an autochthonous weather situation as we assumed in our study to simulate this stable atmosphere initial wind speed was low 4 m s this might cause inaccurate simulations generally the uhi intensity is strongly affected by the surface material since flux divergences e g radiation from surrounding cells into the actual model cell are not taken into account by the present approach the transitions between contours are quite sharp an additional restriction is that although envi met version 3 considers shadows for radiation calculation inclination and exposition of surfaces are not included anthropogenic heat was neglected but studies like ichinose et al 1999 showed that anthropogenic heat at high resolutions can reach 800 w m 2 downtown tokyo which is why future modelling approaches should incorporate such fluxes since anthropogenic heat is originally involved in δ t f 1 and δ t f 2 only their magnitudes can be influenced but not the principal spatial patterns another issue are large values of the bowen ratio β through q l e 0 this problem cannot be neglected at the neighbourhood scale grid size within a few metres 6 conclusions we suggested an approach for the decomposition of urban warming δ t and applied it to a neighbourhood in leipzig germany the resulting maps of the individual uhi contributions as well as their discussion at places of interest demonstrated that there is no overall dominating uhi contribution nevertheless heat storage and convection efficiency dominate most parts of the quarter the greatest warming was found in streets with no or less trees over impervious surfaces such as asphalt or concrete and in general over unshaded areas with no or less vegetation brownfield parts of inner courtyards and street canyons convection efficiency that was previously presumed to be responsible for uhi in humid climates zhao et al 2014 proved to be not always the dominant driver for local uhi intensity often heat heat contributes the most to uhi the dynamic production of turbulent kinetic energy tke and their dissipation is highly influenced by wind speed and direction which in turn depends on the orientation of obstacles within the flow field therefore the convection efficiency slightly differs for the three wind scenarios east south west pronounced differences were found for the heat storage where east and west wind scenarios showed the strongest warming effect for the south wind scenario the warming at most areas is considerably smaller but in a few streets perpendicular to the wind direction it is stronger our study demonstrated that this approach can be a valuable contribution for a targeted development of mitigation and adaptation strategies to urban climate change 7 software and technical notes for micrometeorological simulations the model envi met http www envi met com was used to avoid inconsistencies in the results by using different model versions we used version 3 1 for all applications input data are achieved from a 3d city model buildings 3d stadtmodell 2012 and a meteorological measurement site institute for meteorology leipzig data http meteo physgeo uni leipzig de de wetterdaten index php visualisation conversion of envi met output data from binary format decomposition of δ t and the analysis were done with programs developed in r r core team 2015 the code also implements eqs 4 6 and is available on request from the authors acknowledgements d h was financially supported by the deutsche bundesstiftung umwelt dbu german federal environmental foundation osnabrück the authors gratefully acknowledge the help and support from the developer of envi met prof dr michael bruse in the use of this software appendix a supplementary data the following is the supplementary data to this article latex files supplementary revised latex files supplementary revised appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 11 015 
