index,text
25890,generalized additive models are increasingly used to identify and describe environmental trends a major advantage of these models as compared to simpler statistical tools such as linear regression or mann kendall tests is that they provide estimates of prevailing levels and trend magnitudes at any given point in time instead of an overall measure for multiple time series this versatility has to be followed by flexible visualization methods that can summarize and visualize trend analysis results for many series simultaneously here we propose several types of visualizations and illustrate the methods by showing trends in variables related to the recovery from acidification in swedish riverine data over the period 1988 2017 by this we show that generalized additive models together with a small number of selected plots can comprehensively illustrate prevailing trends and summarize complex information from multiple series keywords generalized additive models visualization of trends surface waters acidification chemical recovery 1 introduction environmental questions are complex by nature the effects of environmental pressures are often observed on a regional scale because they are driven by large scale factors such as airborne deposition land use or climatic variables in addition policy measures are introduced on a national or international level and thereby influence many monitoring series simultaneously this requires statistical evaluations that can be applied on multiple series without a substantial modeling effort and thereby provide simple summaries that can be tabulated or visualized to reveal the essential information contained in the trend analysis in this paper we investigate the high potential of generalized additive models for trend analysis by developing a unified framework to visualizing long term nonlinear trends for multiple environmental series the overall goal is to give a comprehensive overview when where and to what extent levels of the studied variables have changed this is done using a small number of selected visualizations while retaining the possibility to extract single site model results for in depth understanding of the present data to quantify trend slopes and to identify when changes over time are significant or not linear regression might be applied however due to the complex and non linear nature of environmental trends in long time series regression methods assuming a linear increase or decrease are seldom used mann kendall tests mann 1945 hirsch and slack 1984 and sen theil slopes theil 1959 can quantify trends and trend magnitudes that are not linear as long as they are monotone i e either only increasing or only decreasing and hence these approaches are often chosen for environmental trend analysis focused on single and multiple series results of mann kendall tests on multiple series are often presented in tables or graphs for example grimvall et al 2014 presented trends in river nutrient concentrations by color coding tables of p values stoddard et al 1999 presented trends in acid anion concentrations and alkalinity in lakes and streams by using site specific seasonal kendall tests which were visualized with bar charts of estimated slopes for different regions in north america and europe similarly monteith et al 2007 used mann kendall tests and sen theil slopes to analyze dissolved organic carbon doc concentrations in lakes and streams at a number of stations in europe and north america and those investigators presented values for individual sites on a map and summarized trend slope distributions as boxplots for six larger regions futter et al 2014 also used sen theil slopes to quantify trends in water quality for acid sensitive lakes in sweden and the results of that study were reported as the median and range of slope magnitudes over 35 lakes separately for 16 variables similar to linear regression in mann kendall tests the results obtained are usually summarized as single numerical values i e p values or slope estimates unfortunately this reduces the amount of available information about the existing trends and even worse can be very dependent on the time period selected for trend analysis for example if a time series has an initial increasing trend followed by a decreasing trend linear regression and mann kendall approaches will lead to insignificant test results for the entire series but will indicate a decreasing trend if the analysis is performed only for the later part of the series leading to very different conclusions to be able to identify the structure of present trends more correctly individual time series plots are often used to complement trend tests for example futter et al 2014 presented individual time series of lake water quality together with annual minimum median and maximum values over all sites a more common approach is to present one plot per time series often in combination with a smooth curve that visualizes the structure of the long term trend curtis and simpson 2014 erlandsson et al 2008 monteith et al 2014 the estimation of a smooth trend is usually achieved using a generalized additive model gam hastie and tibshirani 1986 wood 2017 or by loess smooths cleveland 1979 several attempts based on simple tables and plots have been made to compile large amounts of information produced by such smooth trends orr et al 2015 analyzed temperature measurements at 231 stations by fitting smooth trends to each series and determining the difference between the start and the end of each estimated smooth trend for these differences 95 confidence intervals were empirically produced by sampling series from the posterior distribution for the coefficients thereafter point estimates of the differences together with the 95 confidence intervals were plotted for all stations on a geographical gradient polansky and robbins 2013 used generalized additive models to estimate levels of fruiting probabilities of several tree species and the predicted levels were illustrated in a plot presenting species as rows and time points as columns similarly response surfaces can be used to represent results from smoothing models for example wahlin and grimvall 2008 computed trend surfaces of nutrients that were smoothed in time on a yearly basis and over river sites sorted by the mean level of flow normalized concentrations to illustrate trends over a larger region also xie et al 2018 produced surface plots using empirical mode decomposition for climatic variables in general it is common to visualize modeled levels of the response variable rather than trend slope estimates several approaches to test and visualize trends at multiple stations are based on combining such series with a single trend test or trend estimate mann kendall tests can be combined using the approaches described by van belle and hughes 1984 or loftis et al 1991 as illustrated by stoddard et al 1999 in an evaluation of trends in acid deposition similarly renard et al 2008 suggested use of regional averages of mann kendal test statistics to detect regional consistency in hydrological trends over hydroclimatic regions considering generalized additive models pedersen et al 2019 explored the use of hierarchical general additive models to analyze ecological data with different smooth functions for individual groups or sites while pooling them towards a common shape many of the above mentioned attempts to achieve a common analysis of multiple series were made in the context of acidification or climate change that is in research areas in which pressures are expected to have an effect on a regional level rather than on single series considering acidification emission controlling legislations such as the convention on long range transboundary air pollution have led to reductions in factors such as airborne sulphur s deposition over the past 30 years vuorenmaa et al 2018 measurements from sweden show a pronounced gradient with decreasing acid deposition from south to north garmo et al 2014 monteith et al 2014 stoddard et al 1999 vuorenmaa et al 2018 and are therefore especially interesting to use as illustration of visualization tools that show the benefit of extensive and detailed screening of trends for follow up of regional scale environmental pressures in this paper we suggest a toolbox of specific visualizations to summarize results obtained from trend analyses done by generalized additive models their general nature and accessibility as easy to use functions in open source software allows a fast overview of environmental trends in multiple series while containing detailed information about single series which can be used for further in depth analysis 2 statistical and visualization methods 2 1 statistical methods generalized additive mixed models gamms hastie and tibshirani 1986 wood 2017 facilitate modeling of environmental series without prior definition of the shape of the trend curve a general model for trend analysis for monthly data could be y i μ f 1 t i m e i f 2 c y c l m o n t h i β x ε i i 1 n ε n 0 λ θ where the trend component f 1 t i m e i is a smooth function in time e g using a date variable modeled as a thin plate spline while the seasonal variation f 2 c y c l m o n t h i is described by a cyclic cubic regression spline with an annual period based on the month the observation is made the model can easily be adjusted to more frequent data replacing month with julian day for less frequent data the seasonal variation could be modeled using a seasonal indicator variable instead of a smooth β x denotes the influence of one or several explanatory variables estimated by a parametric function the explanatory variables can be either continuous e g run off or temperature or categorical e g describing analytical method changes or introduction of new policy measures von brömssen et al 2018 explanatory variables can also be included using smooth functions if the relationship to the response variable cannot be described parametrically the error term in a time series model is assumed to be dependent in time and thus it is necessary to include autocorrelation in the variance covariance matrix λ θ the typical choice is a continuous autoregressive process of lag 1 assuming that correlations between two different points in time is a function of the time difference it has been shown that inclusion of an autocorrelation term is important in generalized additive models because otherwise there is a risk that the trend estimates will exhibit too much wiggliness which might introduce spurious trends in a trend analysis as has been demonstrated by simpson 2018 to be able to determine when interesting changes occur in time series it is necessary to identify the uncertainty of the slope of the smooth trend curve at any time point the computation of uncertainties for smooths has been described by marra and wood 2012 and wood 2017 first derivatives of the smooth function can be computed by finite differencing and their uncertainties can be deduced from the variance covariance matrix of the original smooth e g see documentation of the predict gam function in the mgcv package wood 2019 when using these uncertainty computations a number of different confidence intervals can be constructed for smooth components model predictions or trend smooth derivatives and the most common types are component wise simultaneous and pointwise intervals simultaneous intervals ruppert et al 2003 are determined by simulating representations of the whole estimated smooth function from its posterior distribution the confidence bands determined are then required to cover 1 α of all simulated smooths component wise intervals which have been suggested by wahba 1983 and silverman 1984 cover 1 α of the smooth across the function pointwise confidence intervals represent uncertainty around the smooth at specific time points and they are constructed by adding an error margin to the modeled smooth simpson 2018 wood 2017 pointwise intervals have been shown to have good component wise coverage nychka 1988 which means that their coverage is close to the nominal level when averaged across the function as long as the variance of the smoothed function is substantially larger than the bias marra and wood 2012 have suggested an adjustment to improve the component wise coverage in situations in which the variance is small here we use confidence intervals for the derivatives of the trend smooth too identify important changes over time the trend is significantly downward if the entire confidence band of the derivative lies below zero but the trend is significantly upward if the entire confidence band lies above zero this is also described by simpson 2018 generalized additive models are fitted by the package mgcv wood 2019 derivative function and confidence intervals are computed using the package gratia simpson 2019 in addition we provide the function screeningmodeling that fits a generalized additive model to each series in the dataset seasonal variation is estimated by default as a cyclic cubic regression spline other explanatory variables are not supported by the function at present autocorrelation in the error term is estimated by a continuous autoregressive process of order 1 this can be removed by the user autocor false and is removed automatically in case the model with autocorrelation does not converge both pointwise confidence default and simultaneous simultaneous confidence intervals can be chosen the function is described in greater detail in the supplementary 2 2 visualization methods 2 2 1 visualization of single series single time series trends can be visualized by time series plots of observed data including the trend smooth using the estimated confidence intervals for the derivative of the trend smooth makes it possible to identify the periods during which the trend slope is significantly different from zero in the plot such periods can be illustrated with different colors e g red for increasing trends and blue for decreasing as has previously been done by curtis and simpson 2014 and monteith et al 2014 to elucidate trends single series plots can be produced from the output of the function screeningmodeling by using the function plot individual trend 2 2 2 trend screening plots single series plots are convenient only for a small number of different stations and variables to be able to present a large number of series simultaneously the information from the single series plots can be condensed series wise retaining the color information i e the information on during which time periods the change in the estimated spline meets the requirement for significance at the 5 level this color information for all sites is then presented in one plot using site as row indicator and time as columns while this is a common approach to illustrate mean levels at different sites wahlin and grimvall 2008 xie et al 2018 or deviations from an overall mean polansky and robbins 2013 it has to our knowledge not been used to visualize periods of change the function plot screeningtrends is applied to the output of screeningmodeling to produce a trend plot with one row for each individual series that contains the color information of when significant changes have taken place the order of the rows can be adjusted using the sorting statement to allow for different geographical or thematical orderings and the wrapparvar statement if different variabels or series should be presented in separate plots as an alternative the function plot screeningtrends pvalues presents the same model fits but illustrates significant periods by pointwise p values these p values are computed under the null hypothesis that the derivative is zero to visualize pointwise p values they are first transformed using l o g 10 p v a l u e to obtain values close to zero for high p values this means that low p values are transformed into high positive values to distinguish between positive and negative trends the transformed p values are multiplied by the sign of the derivative and color coded on a continuous scale from blue decreasing to red increasing inasmuch as single very low p values easily overshadow other trends in such plots a limit of 0 00001 is set for the p value i e all p values below that level are changed to 0 0001 2 2 3 visualization by proportion plots additional summarization of results can be useful to present comprehensive overviews the function plot proportions shows at any given time point how many of the series exhibit increasing decreasing or non significant trends at the 5 significance level in other words this function summarizes the information provided by plot screeningtrends over all series for each time point a dashed line indicates what percentage of the series have observations at the given time point 2 2 4 visualizing the magnitude of trends when trends are analyzed the magnitude of any trend that is present over a longer period is especially interesting generalized additive models allow different trend magnitudes and directions during different periods and hence it is not straightforward how to quantify an overall trend magnitude here we choose to visualize the trend magnitude by comparing levels at any given time point with a reference level set to the mean of the first three years of the series this gives an informative plot in series in which mean levels have changed markedly during the observation period the proposed plot is created by the function plot screeningtrends reference in other situations it might be more interesting to relate current levels to a reference level that for example describes pristine levels or target levels that should be reached such reference levels would be easy to implement but are not available at present another visualization that can be interesting relates the magnitude of the trend at a specific time point to the estimated level of the smooth at the same time point this approach can make it possible to identify situations in which a drastic relative change occurs such as short episodes of unusually high or low values that are due to either natural conditions e g snow melting periods or data quality issues e g instrumental errors or unaccounted discontinuities in the time series these plots are created by the function plot screeningtrends relative 2 2 5 visualization of local trends in multiple time series when trends for multiple series are visualized using the methods proposed above it is possible that similar patterns will be observed for series that are geographically close or belong to the same thematic group therefore a subsequent step in the analysis can be to look closer at trends for a number of stations on a smaller regional scale or in a thematic group or for a group of related variables at the same time if the goal is to produce an overall trend estimate within this subset hierarchical generalized additive models can be used as suggested by pedersen et al 2019 who applied a global trend function combined with series specific deviations from that global function denoted model gs visualization of such models can be done using the package gratia simpson 2019 here we modify these plots by letting the global and series specific trend smooths also include the intercept and thus represent the average level and trend as well as the series specific trends this plot is not part of the suggested toolbox but is useful for further in depth analysis on a smaller regional scale 2 3 data in this study application of the presented tools for screening of environmental trends is exemplified by the well recognized recovery from acidification since 1970 1980s e g stoddard 1999 we used time series from 37 soft water rivers for the period 1988 2017 selected from the swedish national monitoring program fölster et al 2014 in particular focusing on surface water ph and so4 concentrations considering that our aim is to explore statistical methods to visualize trends not to understand the trends themselves the dataset we use does not contain any potential drivers of variation other than seasonality no pre processing of the data has been done stations are identified by their coordinates given in the in the sweref system n s e w sweref99tm epsg 3006 where the first 7 digits number represent the latitudal gradient the water chemistry data used here are included in the swedish national program for monitoring of freshwater quality the chemical analyses were performed by the department of aquatic sciences and assessment at the swedish university of agricultural sciences all the analyses were carried out in the same laboratory over the entire study period 1988 2017 which has led to a high level of continuity historical flaws and changes in methodology are well documented so4 was analyzed using an ion chromatography and ph was assessed using a metrohm 855 autosampler with a built in ph meter in a thermostated flow cell in the visualization of trends for multiple variables 3 7 in addition to ph and so4 the data we use include alkalinity filtered absorbance acid neutralizing capacity anc dissolved base cation bc chloride as well as nitrite and nitrate all underlying chemical analyses followed standard methods and the performing laboratory is certified for all methods applicable in the present investigation https www slu se institutioner vatten miljo laboratorier vattenkemiska laboratoriet the data set is available for download at zenodo von brömssen et al 2020 3 results the following sections describe the analysis of trends in so4 and ph in sweden to show how different approaches in generalized additive models and visualizations can be applied to evaluate the trends in detail this is done by presentation of trend analysis results side by side for multiple series and several variables results are further condensed into proportion plots or by computing common trend estimates on a regional scale a first overview of the data is given in fig 1 indicating the location of the series over sweden as well as their average levels in the beginning 1988 1990 and the end 2015 2017 of the available time series average values are given in table a1 in the supplementery 3 1 visualization of local trends in multiple time series fig 2 illustrates single series plots with a trend smooth and color coding of significant periods of change in ph and so4 in the river alsterälven 6585489 420879 red sections reflect significant upward trends according to pointwise tests correspondingly blue sections show significant downward trends whereas yellow shows the fitted trend line when the trend is not significant the curves indicate an initial increase in ph from 1988 to the mid 1990s fig 2 left and a clear downward trend in so4 over most of the time period fig 2 right 3 2 trend screening plots 3 2 1 screening of significant trend periods the increase in ph and decrease in so4 apparent in the river alsterälven fig 2 are also common in many series throughout sweden using trend screening plots this information can be summarized in a combined figure retaining the data of significance at different time points for all individual sites as shown in fig 3 it can be seen that the ph increased in the late 1980s and early 1990s in all series except a few in the northernmost part of sweden whereas it has remained rather constant since the late 1990s the trends in so4 have been especially pronounced in south and mid sweden with a decrease starting in the mid 1990s and continuing until the mid or end of the 2000s the series marked end to end in red or blue are those for which a linear trend was suggested as best model fit 3 2 2 trend screening using p values if the goal is instead to retain additional information about the level of significance for trends during different time periods it can be appropriate to produce a plot like the one in fig 3 but colorized by obtained p values as illustrated in fig 4 obviously this slightly altered approach provides very similar information the increase in ph during the first years in the series is shown in different shades of red whereas the decrease in so4 is shown in stronger shades of blue indicating the more drastic decrease that occurred in the late 1990s i e the signal to noise ratio was higher for so4 than for ph again this agrees with what is observed in the example shown for the alsterälven fig 2 3 3 visualization by proportion plots by summarizing the results provided in fig 3 the proportion plot in fig 5 illustrates the percentage of stations showing upward downward and no significant trends at each time point it is apparent that in the early 1990s about 75 of all stations in our data set showed an increase in ph and equivalently about 75 of the series showed a decrease in so4 in the late 1990s since 2010 significant changes have occurred in only a few series after 2015 one and four series showed trends in ph and so4 respectively most of these series were fitted with a linear trend over the entire time range as to whether a linear trend is indeed a good fit for these series i e whether there was actually a continued increase or decrease needs to be evaluated individually for each series also in fig 5 a dashed line indicates what percentage of the series have observations at the given time point the data set used here was nearly complete with only about 3 of the series corresponding to only one series in our data missing observations during the first one and a half years fig 5 upper left corner 3 4 visualizing the magnitude of trends the magnitude of the present trends is visualized as the level of the trend smooth at a specific time point divided by a reference level which here is the mean of the first three observed years of each series fig 6 the decrease in so4 was quite dramatic in several series in the south of sweden amounting to at least 50 compared to the levels occurring in 1988 1990 the increase in ph was less pronounced with a maximum of about 7 compared to reference levels however this comparison is not informative about actual rises in ph because the increase was already ongoing during this reference period 1988 1990 choosing the first three years of each series as reference level is reasonable in this context as it is interesting to see how much ph and so4 have changed since the late 80 which was the end of a period with high deposition however to be able to compare changes between series it is necessary that all series are equally long observations at the station laxbäcken 6635190 525485 were started in august 1989 which means that about one and a half years of observations are missing compared to the other series accordingly the time period august 1989 to july 1991 is used as reference period for this station and hence trend magnitudes computed at this site are not comparable with those at other sites this is well illustrated for ph because no noticeable change in ph level at any time point can be seen for laxbäcken whereas a clear increase is apparent for most other stations in the same area 3 5 visualization of different features by adjusting site order in the illustrated plots the sites are presented in order from north to south according to latitude this approach enables the detection of trends on a geographical scale that can be associated with the gradient in acid deposition in sweden it can also be interesting to arrange sites in order according to average so4 or ph levels in fig 7 we only present trend results for so4 sorted by average values for the reference years placing sites with the lowest levels at the top of the plot it can be seen that many series with high reference levels show strongly decreasing trends however there are also series with high levels that have no trends at all for example the station visman nybble 6551023 452213 has the highest so4 level of around 1 meq l fig 1 table a1 supplementary but does not show a trend this station is a local recipient of discharge from a paper mill and is only marginally affected by deposition and therefore no changes due to decrease in airborne acidifying substances can be seen also considering so4 the stations alterälven norrfjärden 7270752 800624 and kalix älv karlsborg 7326323 872437 show no trends and have relatively high levels during the reference period 0 158 and 0 103 respectively fig 1 table a1 both of these stations are located in northern sweden which again is affected to only a limited degree by airborne deposition it is plausible that the high levels of so4 in these rivers can be attributed to the presence of acid so4 soils in these areas becher et al 2019 3 6 visualization of local trends in multiple time series the results thus far e g those shown in fig 3 suggest that there is considerable covariation in trends in southern and central sweden therefore it seems appropriate to take a closer look at trends on a smaller sub regional level to achieve this we select eight sites in värmland county and fit a hierarchical generalized additive model including an overall trend function and site specific deviations we then plot the results including the overall intercept to represent the overall fig 8 left and the site specific trends fig 8 right the eight series in this assessment exhibit a strong common trend the general trend estimate shows a mean decrease in so4 from an average of 0 107 meq l to about 0 042 meq l which indicates an average magnitude of trend of about 60 in the region of värmland over the analyzed 30 years the absolute decrease was higher at sites with high initial levels whereas the relative level of decrease was approximately 60 for all of the series an exception to this is norsälven norsbron 6586310 399589 which started with an increase in so4 and thus showed a smaller decrease of only 40 over the analyzed time period 3 7 visualization of trends for multiple variables analyzing fewer series also makes it possible to take advantage of the wrapping and sorting function for the screening plots this enables presentation of the trends for several chemical variables and several stations at the same time as shown in fig 9 for the subset of series from värmland even though this plot is quite cluttered some similarities in trends can be identified for example increasing trends early in the series can be seen for absorbance alkalinity anc bc chloride and ph at several stations whereas mainly decreasing trends can be noted for so4 as well as nitrite and nitrate a closer examination of the trend estimates concurvity could give additional information about underlying processes 3 8 visualization to identify high level episodes in the plots presenting trend magnitudes figs 6 and 7 it is apparent that one station töre älv 7334144 846887 deviates from general results by showing a sudden strong increase in so4 during a short period in the mid 2000s for that station several episodes of high so4 can be seen during the period of observation fig 10 left although only the longer episode in 2004 is seen in the trend screening plots because other episodes that were shorter and less pronounced and are not and should not be picked up by the trend estimate to better visualize such periods of drastic change we suggest an additional plot for which the estimated trend magnitude is divided by the level of the trend smooth at the same time point fig 10 in contrast to fig 6 which identifies only one high so4 episode the plot to the left in fig 10 shows several peaks for töre älv interchanging red and blue indicators implying three to four episodes of higher so4 levels that can also be observed in the single series plot to the left in fig 10 none of the other stations in this analysis show similar signs of high so4 episodes for those once again the plot to the right in fig 10 gives an indication of the sudden drop in so4 that occurred in southern and central sweden in the late 1990s which was dramatic compared to the prevailing levels 3 9 summary of trend analysis for ph and so4 the results of our assessments show that ph increased in the late 1980s and early 1990s in all series except for a few rivers in the north of sweden since the late 1990s the ph level has remained rather constant decreases in so4 concentrations started in the mid 1990s in most cases and continued until the middle or end of the 2000s these changes were observed in about 75 of all included series trends of increasing ph and decreasing so4 were stronger in the more acid sensitive rivers in south and mid sweden than in the rivers in the northern part of the country at some stations the concentrations at the end of the observation period are at a magnitude of only 40 of the prevailing levels during the late 1980s episodes with high so4 levels were observed only in a single series in the river töre älv which has acid sulphur soils in the catchment runoff from an adjacent river indicated unusually dry conditions the year before the highest peak in sulphur which can lead to oxidized soils resulting in discharge of suphuric acid for a subset of series in the region of värmland an additional analysis was done to illustrate individual and common trend magnitudes for so4 showing concordant trend curves and trend magnitudes that vary with initial so4 levels a side by side presentation of trends for 10 different variables suggested association between several of these variables 4 discussion monteith et al 2014 identified a marked decrease in so4 in lakes and rivers in the uk during the latter half of the 1990s by using first derivatives of trend smooths produced by generalized additive models such methods have a high potential for in depth statistical analysis of complex trends for long time series an issue that has not yet been satisfactorily addressed is the visualization of such long term nonlinear trends for multiple series here we propose a number of trend screening plots that allow a combined presentation of many trend analyses the overall goal of the proposed functions and plots is to give a comprehensive overview of when where and to what extent levels of the studied environmental variables have changed it is important that this information is provided in a small number of different plots using the proposed models and visualization methods addresses several of the problems with simple summaries produced by more generally used methods such as the mann kendall test and theil sen slope first results based on generalized additive modesl are not dependent on the time period of investigation but are given point wise in time mann kendall tests suffer from the subjectivity of defining specific time periods for the trend analysis which can greatly influence the conclusions drawn to determine if trends level out over time it is furthermore necessary to use distinct time periods as used by e g garmo et al 2014 who compared estimates of so4 trends in acidified lakes and rivers for the time period 1990 1999 with those for 1999 2008 similarly vuorenmaa et al 2018 computed mean annual changes in so4 in deposition and runoff in forested catchments in europe for the periods 1990 2000 and 2001 2015 using visualization plots for trend analysis based on generalized additive models we can determine in much greater detail when significant changes were observed and how long they persisted even though the trend test results do not directly depend on the length of the series some dependence remains as the smoothing parameter in the generalized additive models is determined globally i e the same amount of smoothing is used for the entire time series in series with strong trends during limited time periods adaptive smoothing can be used wood 2017 although this makes additional demands on the data and can potentially lead to overfitting issues simpson 2018 and has therefore not been investigated here a second advantage of generalized additive models and the ways we suggest to present their results is that they can be used with series of different lengths inasmuch as the model fit is data driven and the determination of significance of trends is made pointwise rather than for the entire series the results are comparable between series even if start and end times are not the same for proportion plots information about how many series contain missing values is given to allow interpretation in our proposal magnitude of trends is quantified compared to a reference period defined as the first three years of each series respectively accordingly this specific type of plot is vulnerable to series length and is difficult to interpret if start times differ between series this is not a problem in our series because they all started at approximately the same time point and thus the plot provides a good overview of the total increase or decrease over time for other applications the magnitude of trends can be interpreted for single series or compared with reference values that are not dependent on the series length or start time e g a target value we also present a plot showing the magnitude of trend at a specific time point in relation to the prevailing level of the variable at the same time point which can help identify short term episodes of high values in the time series driven by factors like snow melting periods or data quality issues such plots are not dependent on the start and end time points of the analyzed series a third advantage of the proposed methods compared to more traditional approaches is that they allow a number of different ways to sort and group sites and variables to enhance visualization of various features we use geographical ordering as well as sorting with respect to reference levels several other ways to sort series are conceivable for example depending on the context it can be possible to use mean values of drivers such as water discharge or percentage of arable soil or forest the proposed plots present similar information to what could be obtained by plots of the absolute or standardised levels but are also different in a very important aspect they focus on the time periods of change rather than when high levels are observed i e they focus on the process of ongoing pollution or recovery rather than the obtained status this is an advantage when the level itself is not of interest as is the case with our example data where levels of ph and so4 are naturally varying over the geographical gradient of sweden furthermore we also identified one locally polluted station and stations with high natural level due to acid soils where the effect of changes in deposition could not be observed the formal test of a statistical hypothesis is not a priority in this context because the focus is on exploring and finding covarying trends in larger areas or multiple chemical variables instead the trend screening can be used to generate new hypotheses especially when applied together with analysis of potential drivers such hypotheses might then be followed up on a local scale using sites that monitor these variables more intensively the suggested visualization methods are general and can be used for any types of smooth trends it could e g be interesting to illustrate trends caused by pressures or climatic changes that are more pronounced during certain seasons e g driven by agricultural or forestry practices or snow cover and snow melting periods for this trend smooths can be computed for separate seasonal series and visualized by the proposed graphs similarly in some situation it is not the main interest to model the trends in the mean of a variable but how extremes e g quantiles change over time a trend model for quantiles can be accomplished with generalized additive models and again the same visualizations can be used to summarize the results in this study we have initiated a trend analysis for so4 and ph in 37 rivers in sweden as expected our assessment indicates that most of the rivers especially those located in the southern or central parts of the country show strong decreases in river so4 and increases in ph as a consequence of reduced s deposition the results obtained distinctly describe the steeper decrease in so4 in the 1990s compared to after the 2000s as well as the increase in ph up to the mid 1990s that subsequently leveled out the time continuous feature of the trend tests used give a substantial advantage over previous investigations that used mann kendall tests where results were dependent on the selected time period e g studies on changes in riverine so4 or ph in sweden have been described by löfgren et al 2011 2009 skjelkvåle et al 2007 and fölster and wilander 2002 the use of mann kendall test also makes it more complex to investigate how strong trends are during different time periods our proposed visualizations clearly show the differences in timing and magnitude of increases in ph and decreases in so4 related to geographical location with a higher recovery rate in the more acid sensitive rivers in the south of sweden compared to the north furthermore water chemistry variables can be affected by each other or by climatic conditions which can be explored by using informative plots for multiple variables and in the process series properties such as data quality problems or high level episodes can easily be detected 5 conclusion generalized additive models provide a reliable basis for trend analysis of environmental data these flexible models in combination with a variety of plots to visualize their results constitute powerful tools for analyzing many series and many variables at the same time the present study shows that use of a small number of screening plots can comprehensively illustrate trends in so4 and ph in sweden over the time period 1988 2017 a more in depth analysis is needed to understand drivers and characteristics of the individual trends but the approach proposed here can guide users in the right direction software and data availability the data set and function code are available at https github com claudiavonbromssen trend screening and the function versions used for this article can be downloaded at zenodo von brömssen et al 2020 https doi org 10 5281 zenodo 3935305 functions are written in the freely available statistical computing software r r core team 2020 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104949 
25890,generalized additive models are increasingly used to identify and describe environmental trends a major advantage of these models as compared to simpler statistical tools such as linear regression or mann kendall tests is that they provide estimates of prevailing levels and trend magnitudes at any given point in time instead of an overall measure for multiple time series this versatility has to be followed by flexible visualization methods that can summarize and visualize trend analysis results for many series simultaneously here we propose several types of visualizations and illustrate the methods by showing trends in variables related to the recovery from acidification in swedish riverine data over the period 1988 2017 by this we show that generalized additive models together with a small number of selected plots can comprehensively illustrate prevailing trends and summarize complex information from multiple series keywords generalized additive models visualization of trends surface waters acidification chemical recovery 1 introduction environmental questions are complex by nature the effects of environmental pressures are often observed on a regional scale because they are driven by large scale factors such as airborne deposition land use or climatic variables in addition policy measures are introduced on a national or international level and thereby influence many monitoring series simultaneously this requires statistical evaluations that can be applied on multiple series without a substantial modeling effort and thereby provide simple summaries that can be tabulated or visualized to reveal the essential information contained in the trend analysis in this paper we investigate the high potential of generalized additive models for trend analysis by developing a unified framework to visualizing long term nonlinear trends for multiple environmental series the overall goal is to give a comprehensive overview when where and to what extent levels of the studied variables have changed this is done using a small number of selected visualizations while retaining the possibility to extract single site model results for in depth understanding of the present data to quantify trend slopes and to identify when changes over time are significant or not linear regression might be applied however due to the complex and non linear nature of environmental trends in long time series regression methods assuming a linear increase or decrease are seldom used mann kendall tests mann 1945 hirsch and slack 1984 and sen theil slopes theil 1959 can quantify trends and trend magnitudes that are not linear as long as they are monotone i e either only increasing or only decreasing and hence these approaches are often chosen for environmental trend analysis focused on single and multiple series results of mann kendall tests on multiple series are often presented in tables or graphs for example grimvall et al 2014 presented trends in river nutrient concentrations by color coding tables of p values stoddard et al 1999 presented trends in acid anion concentrations and alkalinity in lakes and streams by using site specific seasonal kendall tests which were visualized with bar charts of estimated slopes for different regions in north america and europe similarly monteith et al 2007 used mann kendall tests and sen theil slopes to analyze dissolved organic carbon doc concentrations in lakes and streams at a number of stations in europe and north america and those investigators presented values for individual sites on a map and summarized trend slope distributions as boxplots for six larger regions futter et al 2014 also used sen theil slopes to quantify trends in water quality for acid sensitive lakes in sweden and the results of that study were reported as the median and range of slope magnitudes over 35 lakes separately for 16 variables similar to linear regression in mann kendall tests the results obtained are usually summarized as single numerical values i e p values or slope estimates unfortunately this reduces the amount of available information about the existing trends and even worse can be very dependent on the time period selected for trend analysis for example if a time series has an initial increasing trend followed by a decreasing trend linear regression and mann kendall approaches will lead to insignificant test results for the entire series but will indicate a decreasing trend if the analysis is performed only for the later part of the series leading to very different conclusions to be able to identify the structure of present trends more correctly individual time series plots are often used to complement trend tests for example futter et al 2014 presented individual time series of lake water quality together with annual minimum median and maximum values over all sites a more common approach is to present one plot per time series often in combination with a smooth curve that visualizes the structure of the long term trend curtis and simpson 2014 erlandsson et al 2008 monteith et al 2014 the estimation of a smooth trend is usually achieved using a generalized additive model gam hastie and tibshirani 1986 wood 2017 or by loess smooths cleveland 1979 several attempts based on simple tables and plots have been made to compile large amounts of information produced by such smooth trends orr et al 2015 analyzed temperature measurements at 231 stations by fitting smooth trends to each series and determining the difference between the start and the end of each estimated smooth trend for these differences 95 confidence intervals were empirically produced by sampling series from the posterior distribution for the coefficients thereafter point estimates of the differences together with the 95 confidence intervals were plotted for all stations on a geographical gradient polansky and robbins 2013 used generalized additive models to estimate levels of fruiting probabilities of several tree species and the predicted levels were illustrated in a plot presenting species as rows and time points as columns similarly response surfaces can be used to represent results from smoothing models for example wahlin and grimvall 2008 computed trend surfaces of nutrients that were smoothed in time on a yearly basis and over river sites sorted by the mean level of flow normalized concentrations to illustrate trends over a larger region also xie et al 2018 produced surface plots using empirical mode decomposition for climatic variables in general it is common to visualize modeled levels of the response variable rather than trend slope estimates several approaches to test and visualize trends at multiple stations are based on combining such series with a single trend test or trend estimate mann kendall tests can be combined using the approaches described by van belle and hughes 1984 or loftis et al 1991 as illustrated by stoddard et al 1999 in an evaluation of trends in acid deposition similarly renard et al 2008 suggested use of regional averages of mann kendal test statistics to detect regional consistency in hydrological trends over hydroclimatic regions considering generalized additive models pedersen et al 2019 explored the use of hierarchical general additive models to analyze ecological data with different smooth functions for individual groups or sites while pooling them towards a common shape many of the above mentioned attempts to achieve a common analysis of multiple series were made in the context of acidification or climate change that is in research areas in which pressures are expected to have an effect on a regional level rather than on single series considering acidification emission controlling legislations such as the convention on long range transboundary air pollution have led to reductions in factors such as airborne sulphur s deposition over the past 30 years vuorenmaa et al 2018 measurements from sweden show a pronounced gradient with decreasing acid deposition from south to north garmo et al 2014 monteith et al 2014 stoddard et al 1999 vuorenmaa et al 2018 and are therefore especially interesting to use as illustration of visualization tools that show the benefit of extensive and detailed screening of trends for follow up of regional scale environmental pressures in this paper we suggest a toolbox of specific visualizations to summarize results obtained from trend analyses done by generalized additive models their general nature and accessibility as easy to use functions in open source software allows a fast overview of environmental trends in multiple series while containing detailed information about single series which can be used for further in depth analysis 2 statistical and visualization methods 2 1 statistical methods generalized additive mixed models gamms hastie and tibshirani 1986 wood 2017 facilitate modeling of environmental series without prior definition of the shape of the trend curve a general model for trend analysis for monthly data could be y i μ f 1 t i m e i f 2 c y c l m o n t h i β x ε i i 1 n ε n 0 λ θ where the trend component f 1 t i m e i is a smooth function in time e g using a date variable modeled as a thin plate spline while the seasonal variation f 2 c y c l m o n t h i is described by a cyclic cubic regression spline with an annual period based on the month the observation is made the model can easily be adjusted to more frequent data replacing month with julian day for less frequent data the seasonal variation could be modeled using a seasonal indicator variable instead of a smooth β x denotes the influence of one or several explanatory variables estimated by a parametric function the explanatory variables can be either continuous e g run off or temperature or categorical e g describing analytical method changes or introduction of new policy measures von brömssen et al 2018 explanatory variables can also be included using smooth functions if the relationship to the response variable cannot be described parametrically the error term in a time series model is assumed to be dependent in time and thus it is necessary to include autocorrelation in the variance covariance matrix λ θ the typical choice is a continuous autoregressive process of lag 1 assuming that correlations between two different points in time is a function of the time difference it has been shown that inclusion of an autocorrelation term is important in generalized additive models because otherwise there is a risk that the trend estimates will exhibit too much wiggliness which might introduce spurious trends in a trend analysis as has been demonstrated by simpson 2018 to be able to determine when interesting changes occur in time series it is necessary to identify the uncertainty of the slope of the smooth trend curve at any time point the computation of uncertainties for smooths has been described by marra and wood 2012 and wood 2017 first derivatives of the smooth function can be computed by finite differencing and their uncertainties can be deduced from the variance covariance matrix of the original smooth e g see documentation of the predict gam function in the mgcv package wood 2019 when using these uncertainty computations a number of different confidence intervals can be constructed for smooth components model predictions or trend smooth derivatives and the most common types are component wise simultaneous and pointwise intervals simultaneous intervals ruppert et al 2003 are determined by simulating representations of the whole estimated smooth function from its posterior distribution the confidence bands determined are then required to cover 1 α of all simulated smooths component wise intervals which have been suggested by wahba 1983 and silverman 1984 cover 1 α of the smooth across the function pointwise confidence intervals represent uncertainty around the smooth at specific time points and they are constructed by adding an error margin to the modeled smooth simpson 2018 wood 2017 pointwise intervals have been shown to have good component wise coverage nychka 1988 which means that their coverage is close to the nominal level when averaged across the function as long as the variance of the smoothed function is substantially larger than the bias marra and wood 2012 have suggested an adjustment to improve the component wise coverage in situations in which the variance is small here we use confidence intervals for the derivatives of the trend smooth too identify important changes over time the trend is significantly downward if the entire confidence band of the derivative lies below zero but the trend is significantly upward if the entire confidence band lies above zero this is also described by simpson 2018 generalized additive models are fitted by the package mgcv wood 2019 derivative function and confidence intervals are computed using the package gratia simpson 2019 in addition we provide the function screeningmodeling that fits a generalized additive model to each series in the dataset seasonal variation is estimated by default as a cyclic cubic regression spline other explanatory variables are not supported by the function at present autocorrelation in the error term is estimated by a continuous autoregressive process of order 1 this can be removed by the user autocor false and is removed automatically in case the model with autocorrelation does not converge both pointwise confidence default and simultaneous simultaneous confidence intervals can be chosen the function is described in greater detail in the supplementary 2 2 visualization methods 2 2 1 visualization of single series single time series trends can be visualized by time series plots of observed data including the trend smooth using the estimated confidence intervals for the derivative of the trend smooth makes it possible to identify the periods during which the trend slope is significantly different from zero in the plot such periods can be illustrated with different colors e g red for increasing trends and blue for decreasing as has previously been done by curtis and simpson 2014 and monteith et al 2014 to elucidate trends single series plots can be produced from the output of the function screeningmodeling by using the function plot individual trend 2 2 2 trend screening plots single series plots are convenient only for a small number of different stations and variables to be able to present a large number of series simultaneously the information from the single series plots can be condensed series wise retaining the color information i e the information on during which time periods the change in the estimated spline meets the requirement for significance at the 5 level this color information for all sites is then presented in one plot using site as row indicator and time as columns while this is a common approach to illustrate mean levels at different sites wahlin and grimvall 2008 xie et al 2018 or deviations from an overall mean polansky and robbins 2013 it has to our knowledge not been used to visualize periods of change the function plot screeningtrends is applied to the output of screeningmodeling to produce a trend plot with one row for each individual series that contains the color information of when significant changes have taken place the order of the rows can be adjusted using the sorting statement to allow for different geographical or thematical orderings and the wrapparvar statement if different variabels or series should be presented in separate plots as an alternative the function plot screeningtrends pvalues presents the same model fits but illustrates significant periods by pointwise p values these p values are computed under the null hypothesis that the derivative is zero to visualize pointwise p values they are first transformed using l o g 10 p v a l u e to obtain values close to zero for high p values this means that low p values are transformed into high positive values to distinguish between positive and negative trends the transformed p values are multiplied by the sign of the derivative and color coded on a continuous scale from blue decreasing to red increasing inasmuch as single very low p values easily overshadow other trends in such plots a limit of 0 00001 is set for the p value i e all p values below that level are changed to 0 0001 2 2 3 visualization by proportion plots additional summarization of results can be useful to present comprehensive overviews the function plot proportions shows at any given time point how many of the series exhibit increasing decreasing or non significant trends at the 5 significance level in other words this function summarizes the information provided by plot screeningtrends over all series for each time point a dashed line indicates what percentage of the series have observations at the given time point 2 2 4 visualizing the magnitude of trends when trends are analyzed the magnitude of any trend that is present over a longer period is especially interesting generalized additive models allow different trend magnitudes and directions during different periods and hence it is not straightforward how to quantify an overall trend magnitude here we choose to visualize the trend magnitude by comparing levels at any given time point with a reference level set to the mean of the first three years of the series this gives an informative plot in series in which mean levels have changed markedly during the observation period the proposed plot is created by the function plot screeningtrends reference in other situations it might be more interesting to relate current levels to a reference level that for example describes pristine levels or target levels that should be reached such reference levels would be easy to implement but are not available at present another visualization that can be interesting relates the magnitude of the trend at a specific time point to the estimated level of the smooth at the same time point this approach can make it possible to identify situations in which a drastic relative change occurs such as short episodes of unusually high or low values that are due to either natural conditions e g snow melting periods or data quality issues e g instrumental errors or unaccounted discontinuities in the time series these plots are created by the function plot screeningtrends relative 2 2 5 visualization of local trends in multiple time series when trends for multiple series are visualized using the methods proposed above it is possible that similar patterns will be observed for series that are geographically close or belong to the same thematic group therefore a subsequent step in the analysis can be to look closer at trends for a number of stations on a smaller regional scale or in a thematic group or for a group of related variables at the same time if the goal is to produce an overall trend estimate within this subset hierarchical generalized additive models can be used as suggested by pedersen et al 2019 who applied a global trend function combined with series specific deviations from that global function denoted model gs visualization of such models can be done using the package gratia simpson 2019 here we modify these plots by letting the global and series specific trend smooths also include the intercept and thus represent the average level and trend as well as the series specific trends this plot is not part of the suggested toolbox but is useful for further in depth analysis on a smaller regional scale 2 3 data in this study application of the presented tools for screening of environmental trends is exemplified by the well recognized recovery from acidification since 1970 1980s e g stoddard 1999 we used time series from 37 soft water rivers for the period 1988 2017 selected from the swedish national monitoring program fölster et al 2014 in particular focusing on surface water ph and so4 concentrations considering that our aim is to explore statistical methods to visualize trends not to understand the trends themselves the dataset we use does not contain any potential drivers of variation other than seasonality no pre processing of the data has been done stations are identified by their coordinates given in the in the sweref system n s e w sweref99tm epsg 3006 where the first 7 digits number represent the latitudal gradient the water chemistry data used here are included in the swedish national program for monitoring of freshwater quality the chemical analyses were performed by the department of aquatic sciences and assessment at the swedish university of agricultural sciences all the analyses were carried out in the same laboratory over the entire study period 1988 2017 which has led to a high level of continuity historical flaws and changes in methodology are well documented so4 was analyzed using an ion chromatography and ph was assessed using a metrohm 855 autosampler with a built in ph meter in a thermostated flow cell in the visualization of trends for multiple variables 3 7 in addition to ph and so4 the data we use include alkalinity filtered absorbance acid neutralizing capacity anc dissolved base cation bc chloride as well as nitrite and nitrate all underlying chemical analyses followed standard methods and the performing laboratory is certified for all methods applicable in the present investigation https www slu se institutioner vatten miljo laboratorier vattenkemiska laboratoriet the data set is available for download at zenodo von brömssen et al 2020 3 results the following sections describe the analysis of trends in so4 and ph in sweden to show how different approaches in generalized additive models and visualizations can be applied to evaluate the trends in detail this is done by presentation of trend analysis results side by side for multiple series and several variables results are further condensed into proportion plots or by computing common trend estimates on a regional scale a first overview of the data is given in fig 1 indicating the location of the series over sweden as well as their average levels in the beginning 1988 1990 and the end 2015 2017 of the available time series average values are given in table a1 in the supplementery 3 1 visualization of local trends in multiple time series fig 2 illustrates single series plots with a trend smooth and color coding of significant periods of change in ph and so4 in the river alsterälven 6585489 420879 red sections reflect significant upward trends according to pointwise tests correspondingly blue sections show significant downward trends whereas yellow shows the fitted trend line when the trend is not significant the curves indicate an initial increase in ph from 1988 to the mid 1990s fig 2 left and a clear downward trend in so4 over most of the time period fig 2 right 3 2 trend screening plots 3 2 1 screening of significant trend periods the increase in ph and decrease in so4 apparent in the river alsterälven fig 2 are also common in many series throughout sweden using trend screening plots this information can be summarized in a combined figure retaining the data of significance at different time points for all individual sites as shown in fig 3 it can be seen that the ph increased in the late 1980s and early 1990s in all series except a few in the northernmost part of sweden whereas it has remained rather constant since the late 1990s the trends in so4 have been especially pronounced in south and mid sweden with a decrease starting in the mid 1990s and continuing until the mid or end of the 2000s the series marked end to end in red or blue are those for which a linear trend was suggested as best model fit 3 2 2 trend screening using p values if the goal is instead to retain additional information about the level of significance for trends during different time periods it can be appropriate to produce a plot like the one in fig 3 but colorized by obtained p values as illustrated in fig 4 obviously this slightly altered approach provides very similar information the increase in ph during the first years in the series is shown in different shades of red whereas the decrease in so4 is shown in stronger shades of blue indicating the more drastic decrease that occurred in the late 1990s i e the signal to noise ratio was higher for so4 than for ph again this agrees with what is observed in the example shown for the alsterälven fig 2 3 3 visualization by proportion plots by summarizing the results provided in fig 3 the proportion plot in fig 5 illustrates the percentage of stations showing upward downward and no significant trends at each time point it is apparent that in the early 1990s about 75 of all stations in our data set showed an increase in ph and equivalently about 75 of the series showed a decrease in so4 in the late 1990s since 2010 significant changes have occurred in only a few series after 2015 one and four series showed trends in ph and so4 respectively most of these series were fitted with a linear trend over the entire time range as to whether a linear trend is indeed a good fit for these series i e whether there was actually a continued increase or decrease needs to be evaluated individually for each series also in fig 5 a dashed line indicates what percentage of the series have observations at the given time point the data set used here was nearly complete with only about 3 of the series corresponding to only one series in our data missing observations during the first one and a half years fig 5 upper left corner 3 4 visualizing the magnitude of trends the magnitude of the present trends is visualized as the level of the trend smooth at a specific time point divided by a reference level which here is the mean of the first three observed years of each series fig 6 the decrease in so4 was quite dramatic in several series in the south of sweden amounting to at least 50 compared to the levels occurring in 1988 1990 the increase in ph was less pronounced with a maximum of about 7 compared to reference levels however this comparison is not informative about actual rises in ph because the increase was already ongoing during this reference period 1988 1990 choosing the first three years of each series as reference level is reasonable in this context as it is interesting to see how much ph and so4 have changed since the late 80 which was the end of a period with high deposition however to be able to compare changes between series it is necessary that all series are equally long observations at the station laxbäcken 6635190 525485 were started in august 1989 which means that about one and a half years of observations are missing compared to the other series accordingly the time period august 1989 to july 1991 is used as reference period for this station and hence trend magnitudes computed at this site are not comparable with those at other sites this is well illustrated for ph because no noticeable change in ph level at any time point can be seen for laxbäcken whereas a clear increase is apparent for most other stations in the same area 3 5 visualization of different features by adjusting site order in the illustrated plots the sites are presented in order from north to south according to latitude this approach enables the detection of trends on a geographical scale that can be associated with the gradient in acid deposition in sweden it can also be interesting to arrange sites in order according to average so4 or ph levels in fig 7 we only present trend results for so4 sorted by average values for the reference years placing sites with the lowest levels at the top of the plot it can be seen that many series with high reference levels show strongly decreasing trends however there are also series with high levels that have no trends at all for example the station visman nybble 6551023 452213 has the highest so4 level of around 1 meq l fig 1 table a1 supplementary but does not show a trend this station is a local recipient of discharge from a paper mill and is only marginally affected by deposition and therefore no changes due to decrease in airborne acidifying substances can be seen also considering so4 the stations alterälven norrfjärden 7270752 800624 and kalix älv karlsborg 7326323 872437 show no trends and have relatively high levels during the reference period 0 158 and 0 103 respectively fig 1 table a1 both of these stations are located in northern sweden which again is affected to only a limited degree by airborne deposition it is plausible that the high levels of so4 in these rivers can be attributed to the presence of acid so4 soils in these areas becher et al 2019 3 6 visualization of local trends in multiple time series the results thus far e g those shown in fig 3 suggest that there is considerable covariation in trends in southern and central sweden therefore it seems appropriate to take a closer look at trends on a smaller sub regional level to achieve this we select eight sites in värmland county and fit a hierarchical generalized additive model including an overall trend function and site specific deviations we then plot the results including the overall intercept to represent the overall fig 8 left and the site specific trends fig 8 right the eight series in this assessment exhibit a strong common trend the general trend estimate shows a mean decrease in so4 from an average of 0 107 meq l to about 0 042 meq l which indicates an average magnitude of trend of about 60 in the region of värmland over the analyzed 30 years the absolute decrease was higher at sites with high initial levels whereas the relative level of decrease was approximately 60 for all of the series an exception to this is norsälven norsbron 6586310 399589 which started with an increase in so4 and thus showed a smaller decrease of only 40 over the analyzed time period 3 7 visualization of trends for multiple variables analyzing fewer series also makes it possible to take advantage of the wrapping and sorting function for the screening plots this enables presentation of the trends for several chemical variables and several stations at the same time as shown in fig 9 for the subset of series from värmland even though this plot is quite cluttered some similarities in trends can be identified for example increasing trends early in the series can be seen for absorbance alkalinity anc bc chloride and ph at several stations whereas mainly decreasing trends can be noted for so4 as well as nitrite and nitrate a closer examination of the trend estimates concurvity could give additional information about underlying processes 3 8 visualization to identify high level episodes in the plots presenting trend magnitudes figs 6 and 7 it is apparent that one station töre älv 7334144 846887 deviates from general results by showing a sudden strong increase in so4 during a short period in the mid 2000s for that station several episodes of high so4 can be seen during the period of observation fig 10 left although only the longer episode in 2004 is seen in the trend screening plots because other episodes that were shorter and less pronounced and are not and should not be picked up by the trend estimate to better visualize such periods of drastic change we suggest an additional plot for which the estimated trend magnitude is divided by the level of the trend smooth at the same time point fig 10 in contrast to fig 6 which identifies only one high so4 episode the plot to the left in fig 10 shows several peaks for töre älv interchanging red and blue indicators implying three to four episodes of higher so4 levels that can also be observed in the single series plot to the left in fig 10 none of the other stations in this analysis show similar signs of high so4 episodes for those once again the plot to the right in fig 10 gives an indication of the sudden drop in so4 that occurred in southern and central sweden in the late 1990s which was dramatic compared to the prevailing levels 3 9 summary of trend analysis for ph and so4 the results of our assessments show that ph increased in the late 1980s and early 1990s in all series except for a few rivers in the north of sweden since the late 1990s the ph level has remained rather constant decreases in so4 concentrations started in the mid 1990s in most cases and continued until the middle or end of the 2000s these changes were observed in about 75 of all included series trends of increasing ph and decreasing so4 were stronger in the more acid sensitive rivers in south and mid sweden than in the rivers in the northern part of the country at some stations the concentrations at the end of the observation period are at a magnitude of only 40 of the prevailing levels during the late 1980s episodes with high so4 levels were observed only in a single series in the river töre älv which has acid sulphur soils in the catchment runoff from an adjacent river indicated unusually dry conditions the year before the highest peak in sulphur which can lead to oxidized soils resulting in discharge of suphuric acid for a subset of series in the region of värmland an additional analysis was done to illustrate individual and common trend magnitudes for so4 showing concordant trend curves and trend magnitudes that vary with initial so4 levels a side by side presentation of trends for 10 different variables suggested association between several of these variables 4 discussion monteith et al 2014 identified a marked decrease in so4 in lakes and rivers in the uk during the latter half of the 1990s by using first derivatives of trend smooths produced by generalized additive models such methods have a high potential for in depth statistical analysis of complex trends for long time series an issue that has not yet been satisfactorily addressed is the visualization of such long term nonlinear trends for multiple series here we propose a number of trend screening plots that allow a combined presentation of many trend analyses the overall goal of the proposed functions and plots is to give a comprehensive overview of when where and to what extent levels of the studied environmental variables have changed it is important that this information is provided in a small number of different plots using the proposed models and visualization methods addresses several of the problems with simple summaries produced by more generally used methods such as the mann kendall test and theil sen slope first results based on generalized additive modesl are not dependent on the time period of investigation but are given point wise in time mann kendall tests suffer from the subjectivity of defining specific time periods for the trend analysis which can greatly influence the conclusions drawn to determine if trends level out over time it is furthermore necessary to use distinct time periods as used by e g garmo et al 2014 who compared estimates of so4 trends in acidified lakes and rivers for the time period 1990 1999 with those for 1999 2008 similarly vuorenmaa et al 2018 computed mean annual changes in so4 in deposition and runoff in forested catchments in europe for the periods 1990 2000 and 2001 2015 using visualization plots for trend analysis based on generalized additive models we can determine in much greater detail when significant changes were observed and how long they persisted even though the trend test results do not directly depend on the length of the series some dependence remains as the smoothing parameter in the generalized additive models is determined globally i e the same amount of smoothing is used for the entire time series in series with strong trends during limited time periods adaptive smoothing can be used wood 2017 although this makes additional demands on the data and can potentially lead to overfitting issues simpson 2018 and has therefore not been investigated here a second advantage of generalized additive models and the ways we suggest to present their results is that they can be used with series of different lengths inasmuch as the model fit is data driven and the determination of significance of trends is made pointwise rather than for the entire series the results are comparable between series even if start and end times are not the same for proportion plots information about how many series contain missing values is given to allow interpretation in our proposal magnitude of trends is quantified compared to a reference period defined as the first three years of each series respectively accordingly this specific type of plot is vulnerable to series length and is difficult to interpret if start times differ between series this is not a problem in our series because they all started at approximately the same time point and thus the plot provides a good overview of the total increase or decrease over time for other applications the magnitude of trends can be interpreted for single series or compared with reference values that are not dependent on the series length or start time e g a target value we also present a plot showing the magnitude of trend at a specific time point in relation to the prevailing level of the variable at the same time point which can help identify short term episodes of high values in the time series driven by factors like snow melting periods or data quality issues such plots are not dependent on the start and end time points of the analyzed series a third advantage of the proposed methods compared to more traditional approaches is that they allow a number of different ways to sort and group sites and variables to enhance visualization of various features we use geographical ordering as well as sorting with respect to reference levels several other ways to sort series are conceivable for example depending on the context it can be possible to use mean values of drivers such as water discharge or percentage of arable soil or forest the proposed plots present similar information to what could be obtained by plots of the absolute or standardised levels but are also different in a very important aspect they focus on the time periods of change rather than when high levels are observed i e they focus on the process of ongoing pollution or recovery rather than the obtained status this is an advantage when the level itself is not of interest as is the case with our example data where levels of ph and so4 are naturally varying over the geographical gradient of sweden furthermore we also identified one locally polluted station and stations with high natural level due to acid soils where the effect of changes in deposition could not be observed the formal test of a statistical hypothesis is not a priority in this context because the focus is on exploring and finding covarying trends in larger areas or multiple chemical variables instead the trend screening can be used to generate new hypotheses especially when applied together with analysis of potential drivers such hypotheses might then be followed up on a local scale using sites that monitor these variables more intensively the suggested visualization methods are general and can be used for any types of smooth trends it could e g be interesting to illustrate trends caused by pressures or climatic changes that are more pronounced during certain seasons e g driven by agricultural or forestry practices or snow cover and snow melting periods for this trend smooths can be computed for separate seasonal series and visualized by the proposed graphs similarly in some situation it is not the main interest to model the trends in the mean of a variable but how extremes e g quantiles change over time a trend model for quantiles can be accomplished with generalized additive models and again the same visualizations can be used to summarize the results in this study we have initiated a trend analysis for so4 and ph in 37 rivers in sweden as expected our assessment indicates that most of the rivers especially those located in the southern or central parts of the country show strong decreases in river so4 and increases in ph as a consequence of reduced s deposition the results obtained distinctly describe the steeper decrease in so4 in the 1990s compared to after the 2000s as well as the increase in ph up to the mid 1990s that subsequently leveled out the time continuous feature of the trend tests used give a substantial advantage over previous investigations that used mann kendall tests where results were dependent on the selected time period e g studies on changes in riverine so4 or ph in sweden have been described by löfgren et al 2011 2009 skjelkvåle et al 2007 and fölster and wilander 2002 the use of mann kendall test also makes it more complex to investigate how strong trends are during different time periods our proposed visualizations clearly show the differences in timing and magnitude of increases in ph and decreases in so4 related to geographical location with a higher recovery rate in the more acid sensitive rivers in the south of sweden compared to the north furthermore water chemistry variables can be affected by each other or by climatic conditions which can be explored by using informative plots for multiple variables and in the process series properties such as data quality problems or high level episodes can easily be detected 5 conclusion generalized additive models provide a reliable basis for trend analysis of environmental data these flexible models in combination with a variety of plots to visualize their results constitute powerful tools for analyzing many series and many variables at the same time the present study shows that use of a small number of screening plots can comprehensively illustrate trends in so4 and ph in sweden over the time period 1988 2017 a more in depth analysis is needed to understand drivers and characteristics of the individual trends but the approach proposed here can guide users in the right direction software and data availability the data set and function code are available at https github com claudiavonbromssen trend screening and the function versions used for this article can be downloaded at zenodo von brömssen et al 2020 https doi org 10 5281 zenodo 3935305 functions are written in the freely available statistical computing software r r core team 2020 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104949 
25891,scenario neutral climate impact assessments 4 results and discussion 4 1 selection of critical attributes 4 2 evaluating the utility of the proposed approach 4 2 1 testing for correct critical attributes 4 2 2 comparing scenario neutral climate impact assessments 5 summary and conclusions acknowledgments anghileri 2013 492 500 d anghileri 2011 2025 2038 d beachkofski 2002 1274 b aiaaasmeasceahsascstructuresstructuraldynamicsmaterialsconference improveddistributedhypercubesampling43rd bennett 2018 b foresightsystemsinsightsgenerationhydroclimatictimeseries bergstrom 1995 443 476 s hbvmodelcomputermodelswatershedhydrology boe 2007 1643 1655 j borgomeo 2015 5382 5405 e borgomeo 2015 8927 8948 e bowden 2005 75 92 g broad 2005 172 180 d broad 2015 382 395 d broad 2010 433 443 d broderick 2019 1079 1104 c brown 2012 w09537 c brown 2012 401 402 c bryant 2010 34 49 b bussi 2016 357 372 g conevski 2014 s acomprehensiveanalysisclimatechangestructuraluncertaintyacomplexwatersystemcasestudyincomomuzza culley 2019 111 122 s culley 2016 6751 6768 s deque 2007 16 26 m eckhardt 2003 244 252 k etccditccdi 2013 etccdicrdclimatechangeindicesxuebinzhang fernando 2009 165 176 t fowler 2016 1820 1846 k frey 2002 553 578 h friedman 2001 j elementsstatisticallearning galelli 2013 4295 4310 s galelli 2014 33 51 s gao 2016 154 166 l giudici 2020 104681 f giuliani 2015 04015050 m giuliani 2014 10 m introductionhbvmodel giuliani 2014 3355 3377 m groves 2007 73 85 d guillaume 2016 326 343 j guo 2017 435 454 d guo 2017 317 330 d guo 2018 877 890 d haasnoot 2013 485 498 m hadka 2015 114 129 d hamon 1960 w estimatingpotentialevapotranspiration herman 2018 39 51 j herman 2015 04015012 j herman 2014 7692 7713 j hyde 2005 278 290 k 2014 climatechange2014impactsadaptationvulnerabilitycontributionworkinggroupiififthassessmentreportintergovernmentalpanelclimatechange summaryforpolicymakers kasprzyk 2013 55 71 j kay 2014 5273 5287 a klemes 1986 13 24 v lempert 2008 r comparingalgorithmsforscenariodiscovery lempert 2007 1009 1026 r li 2015 15 29 x li 2015 78 96 x maier 2014 271 299 h maier 2019 195 213 h mastrandrea 2010 87 101 m may 2011 r reviewinputvariableselectionmethodsforartificialneuralnetworks may 2008 1312 1326 r mcphail 2018 169 191 c mcphail 2020 e2019wr026515 c nazemi 2014 a nazemi 2013 291 305 a prudhomme 2013 933 948 c prudhomme 2013 949 964 c prudhomme 2010 198 209 c quinn 2018 4638 4662 j raso 2019 267 283 l ravalico 2010 171 181 j ray 2018 168 181 p razavi 2012 s richardson 1981 182 190 c richardson 1984 c wgenamodelforgeneratingdailyweathervariables scrucca 2013 1 37 l sharma 2000 232 239 a shortridge 2016 2298 2312 j singh 2014 3409 3427 r specht 1991 568 576 d stein 1987 143 151 m steinschneider 2013 7205 7220 s steinschneider 2015 04015023 s taner 2017 34 50 m turner 2014 3553 3567 s wei 2011 2163 2171 m westra 2014 5090 5113 s wetterhall 2011 2295 2306 f whateley 2014 8944 8961 s wu 2014 108 127 w culleyx2021x104948 culleyx2021x104948xs 2022 12 17t00 00 00 000z 2022 12 17t00 00 00 000z http creativecommons org licenses by nc nd 4 0 2020 published by elsevier ltd 2020 12 25t23 18 10 520z http vtw elsevier com data voc addontypes 50 7 nlp s1364815220310057 the case study data used in this study are from agenzia regionale per la protezione dell ambiente http ita arpalombardia it ita inde and consorzio dell adda http www addaconsorzio it the authors would like to thank arpa and eng bertoli from consorzio dell adda for its provision the authors would also like to thank m giuliani and a castelletti for their contribution to this research as well as robert wilby and two anonymous reviewers for their comments which improved the manuscript details of the climate time series data produced using the foresight package https cran r project org web packages foresight index html and case study performance data used in the results can be made available upon request sam culley was supported by an australian postgraduate award item s1364 8152 20 31005 7 s1364815220310057 1 s2 0 s1364815220310057 10 1016 j envsoft 2020 104948 271872 2021 01 29t21 46 02 736382z 2021 02 01 2021 02 28 1 s2 0 s1364815220310057 main pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 main application pdf 2cbc9eefdf746ecd9e05c4880bed2a51 main pdf main pdf pdf true 6470326 main 14 1 s2 0 s1364815220310057 main 1 png https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 preview image png 789c7eb9d5e5425c4a37e6aae1417297 main 1 png main 1 png png 53919 849 656 image web pdf 1 1 s2 0 s1364815220310057 gr4 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr4 downsampled image jpeg 6bc5d278aef10a06ef60a369e861e9c6 gr4 jpg gr4 gr4 jpg jpg 149443 803 646 image downsampled 1 s2 0 s1364815220310057 gr5 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr5 downsampled image jpeg 7a2e777fec25d6ffb72e7cc0fd27fa67 gr5 jpg gr5 gr5 jpg jpg 161821 970 624 image downsampled 1 s2 0 s1364815220310057 gr2 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr2 downsampled image jpeg c634984701d6438cb5f406ed663626ef gr2 jpg gr2 gr2 jpg jpg 31530 328 548 image downsampled 1 s2 0 s1364815220310057 gr3 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr3 downsampled image jpeg cb6649c0abe88704ee83fd91005e0c5d gr3 jpg gr3 gr3 jpg jpg 238302 746 624 image downsampled 1 s2 0 s1364815220310057 gr1 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr1 downsampled image jpeg 9389028549d347ddb259f8c274742186 gr1 jpg gr1 gr1 jpg jpg 74751 505 291 image downsampled 1 s2 0 s1364815220310057 gr4 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr4 thumbnail image gif 8617e895cb73e4017f50f1dab5e01913 gr4 sml gr4 gr4 sml sml 17178 164 132 image thumbnail 1 s2 0 s1364815220310057 gr5 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr5 thumbnail image gif 4ec5187a77d8c6e7226b93da258e4d59 gr5 sml gr5 gr5 sml sml 14598 163 105 image thumbnail 1 s2 0 s1364815220310057 gr2 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr2 thumbnail image gif e406aec35ed12c77b84a3034d4149511 gr2 sml gr2 gr2 sml sml 9012 131 219 image thumbnail 1 s2 0 s1364815220310057 gr3 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr3 thumbnail image gif 3f69af9b7428bf8edaae91188c55bddb gr3 sml gr3 gr3 sml sml 23460 164 137 image thumbnail 1 s2 0 s1364815220310057 gr1 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr1 thumbnail image gif 8854b21c07adbc875d2790fd21fbed25 gr1 sml gr1 gr1 sml sml 15444 163 94 image thumbnail 1 s2 0 s1364815220310057 gr4 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr4 highres image jpeg 5a91ad789fcf46a6a63c71e9de63e1cb gr4 lrg jpg gr4 gr4 lrg jpg jpg 1014420 3558 2862 image high res 1 s2 0 s1364815220310057 gr5 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr5 highres image jpeg 02d7a5de0820f874e7613f212ad243f1 gr5 lrg jpg gr5 gr5 lrg jpg jpg 1149903 4298 2764 image high res 1 s2 0 s1364815220310057 gr2 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr2 highres image jpeg ce237552667c940aa4252cd216cc350f gr2 lrg jpg gr2 gr2 lrg jpg jpg 166615 1453 2429 image high res 1 s2 0 s1364815220310057 gr3 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr3 highres image jpeg 1ef784eb5be13cda9a9ac43d0563b72d gr3 lrg jpg gr3 gr3 lrg jpg jpg 2178074 3306 2764 image high res 1 s2 0 s1364815220310057 gr1 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr1 highres image jpeg f7173ea7420243f099dec3df44f81140 gr1 lrg jpg gr1 gr1 lrg jpg jpg 361289 2237 1288 image high res 1 s2 0 s1364815220310057 si7 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml ad477eb9c3cc60af5882dd3501f55797 si7 svg si7 si7 svg svg 54918 altimg 1 s2 0 s1364815220310057 si2 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 1e5b7a26843521770496442516c97e34 si2 svg si2 si2 svg svg 22393 altimg 1 s2 0 s1364815220310057 si6 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml b698e9ccb56c1d589b6bc1bebb1dbd75 si6 svg si6 si6 svg svg 45070 altimg 1 s2 0 s1364815220310057 si3 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 0a6cdb8dad7cdd988b374d300a232155 si3 svg si3 si3 svg svg 14598 altimg 1 s2 0 s1364815220310057 si4 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 66da10f7dfa773d0ea217ac86a6bfccb si4 svg si4 si4 svg svg 80832 altimg 1 s2 0 s1364815220310057 si1 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 043cdad556e3daf42892142cb69181d7 si1 svg si1 si1 svg svg 23542 altimg 1 s2 0 s1364815220310057 si5 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 8fe127157311cbb37c3480087478ce5a si5 svg si5 si5 svg svg 51042 altimg 1 s2 0 s1364815220310057 si8 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml d2b38f33fff50cf41ce813dd2abdfa45 si8 svg si8 si8 svg svg 75822 altimg 1 s2 0 s1364815220310057 am pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content egi 102qpv4t1tt main application pdf e896aa03eb5959ccd6d1d3aaa5f4879c am pdf am am pdf pdf false 1232425 aam pdf enso 104948 104948 s1364 8152 20 31005 7 10 1016 j envsoft 2020 104948 fig 1 main steps in proposed approach for selecting critical climate attributes fig 1 fig 2 cumulative variance explained with each additional attribute in order of significance for the two performance criteria fig 2 fig 3 pmi selection of the critical attributes and the next most significant attribute for the flood reliability criterion left and the irrigation deficit criterion right the residuals are plotted in black and the mlpnn estimation is shown in orange the order of significance of the attributes decreases from top to bottom i e the plot for the most critical attribute is shown in the top row and the plot for the least significant attribute is shown in the bottom row the function g in the axis labels represents the effect of the previous selected attributes on the attribute selected that iteration a and the outputs p for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 3 fig 4 two scenario neutral spaces delineated by success and failure of an irrigation performance criteria with climate projections overlaid one space is created using mean precipitation and temperature top and the other using the critical climate attributes bottom fig 4 fig 5 two scenario neutral spaces delineated by success and failure of a flood performance criteria with climate projections overlaid one space is created using mean precipitation and temperature top and the other using the critical climate attributes bottom fig 5 table 1 candidate climate attributes considered where the attributes are defined as the average over the simulation period table 1 attribute name description units winter total rainfall pdjf annual summation of summer rainfall mm summer total rainfall pjja annual summation of winter rainfall mm spring total rainfall pmam annual summation of spring rainfall mm autumn total rainfall pson annual summation of autumn rainfall mm 99th percentile of daily rainfall p99 volume of 99th percentile of daily rainfall event mm average wet spell duration wsd average length of consecutive wet days mm annual rainfall volume ptot annual summation of rainfall volume mm number of wet days nwet annual count of wet days days average march temperature tmar average of daily temperature in march c average june temperature tjun average of daily temperature in june c average september temperature tsep average of daily temperature in september c average december temperature tdec average of daily temperature in december c average temperature tavg annual average of daily temperature c annual temperature range trng temperature difference between 5th percentile and 95th percentile day c frost days f0 annual count of days with temperature less than 0 c days table 2 expected change in attributes from historical baseline table 2 attribute target type projections 2040 2060 attribute bounds min max min max pdjf fraction 1 22 2 10 1 0 2 2 pjja fraction 0 43 1 20 0 4 1 2 pmam fraction 0 97 1 45 1 0 1 5 pson fraction 0 70 1 21 0 7 1 3 p99 fraction 0 92 1 29 0 8 1 4 wsd fraction 0 64 0 86 0 6 1 0 ptot fraction 0 89 1 30 0 8 1 4 nwet fraction 0 89 1 03 0 8 1 1 tmar additive 0 11 8 85 0 0 9 0 tjun additive 0 43 8 41 1 0 8 5 tsep additive 1 37 11 25 0 0 11 5 tdec additive 1 53 8 25 2 0 8 5 tavg additive 1 31 6 14 0 0 6 5 trng additive 1 43 8 50 2 0 8 5 f0 additive 59 8 12 5 70 0 0 table 3 order of critical attributes and the next most significant attribute in italics obtained using the pmi algorithm for the two performance criteria considered as well as the corresponding values of cumulative variance explained cve table 3 order flood reliability irrigation deficit attribute cve attribute cve 1 f0 0 281 ptot 0 487 2 ptot 0 542 f0 0 619 3 pson 0 591 tjun 0 683 4 tdec 0 622 pjja 0 741 5 tmar 0 623 tdec 0 760 identifying critical climate conditions for use in scenario neutral climate impact assessments s culley h r maier s westra b bennett school of civil environmental and mining engineering university of adelaide adelaide south australia 5005 australia school of civil environmental and mining engineering university of adelaide adelaide south australia 5005 australia school of civil environmental and mining engineering university of adelaide adelaide south australia 5005 australia corresponding author scenario neutral climate impact assessments are being used increasingly to assess water resource system responses to possible climate changes the purpose of such assessments is to identify system sensitivity to a range of plausible climate conditions often including an evaluation of the joint effect of multiple climate stressors given the large number of climate variables and associated statistics averages seasonality intermittency extremes etc that could plausibly change and impact on system performance it is essential that scenario neutral assessments focus on those to which the system is most sensitive a generic approach to identifying these critical climate conditions is presented and tested on the lake como reservoir in northern italy considering two system objectives irrigation deficit and flood reliability results indicate that different climate conditions are critical for the two objectives and that the choice of which climate conditions to include has a significant effect on the climate impact assessment outcome keywords climate change impact assessment scenario neutral bottom up 1 introduction climate change can impact water resource systems through stresses to both supply and demand ipcc 2014 these stresses are the result of changes to atmospheric variables such as precipitation temperature and evapotranspiration which influence water resource systems via a complex set of catchment scale and system level processes that in turn are dependent on the system s geography configuration operation and performance measures understanding the possible impacts of climate change on water resource systems therefore requires mapping changes in large scale climate processes to changes in system performance accounting for the unique features of each system mastrandrea et al 2010 to this end scenario neutral climate impact assessments are being used increasingly to assess and convey the sensitivities of water resource systems to changes in climate brown and wilby 2012 prudhomme et al 2010 these assessments work by stress testing a system against a set of hydrometeorological time series that represent potential future climate conditions these time series are then run through a system model providing information on how the system responds to changes in climate conditions and identifying critical performance thresholds and other decision relevant information brown et al 2012 prudhomme et al 2010 this creates a scenario neutral space also referred to as an exposure space or a response surface that maps system performance to changes in a range of statistics e g averages seasonality intermittency variability extremes and low frequency autocorrelations of climate variables e g precipitation temperature potential evapotranspiration the combination of which is hereafter referred to as climate attributes the scenario neutral space can be coupled with climate projections to understand the likelihood and possible timing of these changes taner et al 2017 turner et al 2014 moreover scenario neutral analyses can be used to explore the robustness of different management strategies to the set of plausible future changes brown et al 2012 culley et al 2016 whateley et al 2014 the primary stages in the construction of scenario neutral spaces consist of i selection of the climate attributes against which to stress test the system this usually corresponds to the selection of the axes of the scenario neutral space ii development of a set of perturbed attribute values representing the plausible changes to be used for stress testing this is equivalent to selecting the locations in the scenario neutral space at which to assess system performance iii generation of climate perturbed hydrometeorological time series that reflect the perturbed attribute values i e generation of climate perturbed time series that represent each selected location in the scenario neutral space iv assessment of system performance at each location in the scenario neutral space by passing the climate perturbed hydrometeorological time series generated in iii through a system model and calculating the corresponding system performance a number of methods have been developed to support the above stages for stage ii different approaches have been used to determine the combinations of changes in climate attributes for which to assess system performance when the system is sensitive to only a small number of climate attributes such as only changes to annual average rainfall and temperature but not to changes in seasonality intermittency variability extremes or low frequency oscillations then it becomes possible to have a low dimensional e g 2 or 3 dimensional scenario neutral space in these cases system performance can be evaluated over a regular grid of changes to each attribute brown et al 2012 culley et al 2016 prudhomme et al 2010 steinschneider et al 2015 turner et al 2014 in contrast when the dimensionality of the scenario neutral space is high e g larger than 10 a variety of sampling techniques have been used to cover representative regions e g latin hypercube improved distributed hypercube efast as the use of a regular grid would be too computationally expensive beachkofski and grandhi 2002 gao et al 2016 kasprzyk et al 2013 stein 1987 in practice such high dimensional scenario neutral spaces thus far have only been used in cases where changes in climate attributes were combined with other factors affecting system performance such as demands and costs herman et al 2014 kasprzyk et al 2013 ray et al 2018 shortridge and guikema 2016 with the number of climate attribute dimensions considered still being small i e 2 to 3 for stage iii different approaches also have been developed and or used to generate hydroclimatic time series that represent the desired attribute changes as discussed in guo et al 2018 these time series traditionally have been obtained by applying scaling factors to historical data culley et al 2016 kasprzyk et al 2013 kay et al 2014 weiβ 2011 wetterhall et al 2011 however this approach cannot account for changes in attributes such as intermittency autocorrelation and extremes or for complex combinations of changes such as an increase in extremes coupled with a decrease in mean to address this limitation stochastic weather generators have received increased attention as they have more flexibility to simulate complex combinations of future changes borgomeo et al 2015a guo et al 2018 ray et al 2018 steinschneider and brown 2013 however estimation of stochastic weather generator parameters to simulate time series with pre determined attributes values can be a challenging task culley et al 2019 guo et al 2017b 2018 to address this guo et al 2018 introduced an inverse approach that optimizes the weather generator parameters in order to generate hydrometeorological time series with desired attribute values this approach was further formalized and refined by culley et al 2019 despite these advances a formal approach to identifying the attributes in stage i is still missing for reasons likely to include some combination of a priori judgement analytical tractability ease of interpretation and capacity to generate combinations of perturbed attributes most studies consider changes in two attributes bussi et al 2016 culley et al 2016 singh et al 2014 turner et al 2014 weiβ 2011 wetterhall et al 2011 whateley et al 2014 the selected attributes usually correspond to changes in mean precipitation and mean temperature or in some cases changes to precipitation seasonality kay et al 2014 prudhomme et al 2013a prudhomme et al 2013b and shifts in peak flows borgomeo et al 2015b nazemi et al 2013 quinn et al 2018 however it is well known that water resources systems can be affected by a much wider range climate attributes e g averages seasonality intermittency variability extremes and low frequency autocorrelation which can change both individually and in combination for example groundwater storages are less affected by evaporation than reservoirs but also subject to lower frequency variations in climate e g multi year droughts while temperature can be critical for water storages driven by snowmelt culley et al 2016 eckhardt and ulbrich 2003 ray et al 2018 importantly even for the same system the climate attributes that have the biggest influence on its performance can vary depending on the performance metrics culley et al 2016 kasprzyk et al 2013 this highlights a need to rigorously test the assumptions of stage i with omissions of important attributes at this stage potentially leading to the misinterpretation of a system s climate sensitivity the inability to identify important system failure modes and or the incorrect assessment of the relative performance of different decision alternatives given that identification of key system sensitivities is a fundamental principle that underpins scenario neutral climate impact assessments brown and wilby 2012 nazemi and wheater 2014 a formal approach for selecting the most appropriate axes of scenario neutral spaces is warranted this is because all subsequent stages in scenario neutral assessments are conditioned on this stage making it impossible to identify key sensitivities in subsequent analyses if key climate attributes are not considered in the first place so while stochastic weather generators are opening up the opportunity to simulate a much larger set of climate attributes as part of stage iii borgomeo et al 2015b guo et al 2017b 2018 herman and giuliani 2018 quinn et al 2018 for this to be effective it must be accompanied by the appropriate selection of the attributes to be perturbed in the first place as part of stage i the overarching aim of this paper is to develop an approach for identifying the most important climate attributes so that scenario neutral climate impact assessments provide accurate information on system sensitivity and the conditions that could lead to system failure broderick et al 2019 bryant and lempert 2010 culley et al 2016 lempert et al 2008 prudhomme et al 2010 this will not only help improve the accuracy of system stress tests when applied to current system configurations but can also help support assessments on the climate conditions for which an alternative system configuration sometimes referred to as an option solution or decision is preferable to another brown et al 2012 brown and wilby 2012 giudici et al 2020 groves and lempert 2007 hadka et al 2015 herman et al 2015 kasprzyk et al 2013 lempert and collins 2007 as well as the relative or absolute robustness of alternative system configurations herman et al 2015 mcphail et al 2018 mcphail et al 2020 to this end the specific objectives of this paper are i to present a general approach for identifying which climate attributes to include in scenario neutral studies for a given system and performance objectives and ii to evaluate the benefits of using the most appropriate climate attributes in a scenario neutral impact assessment the approach is demonstrated and tested using the lake como system a regulated lake in northern italy two performance criteria are considered flood reliability and irrigation deficit to highlight the importance of tailoring the approach to the system under consideration including different system objectives kasprzyk et al 2013 details of the proposed approach can be found in section 2 with a description of the case study and implementation of the proposed approach in section 3 a description of further analysis designed to test how well the proposed approach performed is also presented in section 3 as well as a demonstration of a tipping point type impact assessment brown et al 2012 frey and patil 2002 guillaume et al 2016 haasnoot et al 2013 hyde et al 2005 raso et al 2019 ravalico et al 2010 using the critical climate attributes the results of implementing and testing the proposed approach are presented in section 4 along with a discussion of its advantages and limitations conclusions are presented in section 5 2 generic approach to identifying critical climate attributes 2 1 overview the key challenge when identifying the set of critical climate attributes is to balance the need to i include all of the climate attributes that could potentially have a significant impact on system performance to ensure the resulting impact assessment is as accurate as possible and does not miss any key modes of system failure and ii keep the number of attributes as small as possible to minimize the dimensionality of the scenario neutral space so as to make it feasible to generate climate perturbed time series with the requisite changes in all climate attributes simultaneously while ensuring that this can be done within a practical timeframe and making it easier to visualize the results of the scenario neutral analysis in order to address this challenge it is proposed to use input variable selection ivs algorithms for this purpose galelli and castelletti 2013 galelli et al 2014 li et al 2015a may et al 2008 sharma 2000 as they have been specifically designed to achieve this balance galelli et al 2014 however as we are dealing with future conditions the data required to apply ivs methods needs to be generated through the use of a system model that can represent the relationship between climate and system performance the desired outcome of applying the ivs approach as part of stage i as defined in the introduction is to ensure that the most important or critical attributes are selected while keeping the dimension of the scenario natural space relatively low to ensure subsequent analyses are tractable to minimize the risk of missing important attributes in the subsequent scenario neutral analysis the basis of the approach is to start with a much larger candidate set of attributes thereby creating a high dimensional space which needs to be reduced through ivs this creates a key distinction between the ivs analysis and the traditional scenario neutral stage the ivs analysis seeks to evaluate a very high dimensional but sparsely sampled scenario natural space representing the system performance to a large number of candidate attributes in order to identify those attributes that are most important for a given system i e the critical attributes the subsequent scenario neutral impact assessment provides a detailed evaluation of the system performance and or compares the system performance across multiple configurations based on plausible variations to the identified critical attributes this approach is analogous to that used in the development of lower fidelity surrogate meta models of higher fidelity simulation models razavi et al 2012 where higher fidelity models are used to generate a relatively small sample of inputs and outputs to enable the lower fidelity surrogate models to be calibrated in both cases a small sample of higher fidelity dimensional values is generated to enable a larger number of lower fidelity dimensional values to be generated for the sake of increased computational efficiency or tractability in the case of surrogate models the generated higher fidelity samples are used to calibrate the lower fidelity model which can be used instead of the more computationally expensive higher fidelity model to generate a larger sample of inputs and corresponding outputs as part of sensitivity of optimization studies broad et al 2015 maier et al 2014 here we use a relatively small number of samples from the higher dimensional scenario neutral space to identify the critical climate attributes which can then be used to generate a larger number of samples in a lower dimensional scenario neutral space that is suitable for climate impact assessment in a computationally efficient tractable manner the main steps of the proposed approach to identifying the critical attributes for scenario neutral climate impact assessments are fig 1 1 the generation of a sparsely sampled high dimensional scenario neutral space by 1 1 selecting the candidate attributes to be considered ensuring that all attributes that could potentially have an impact on system performance are included 1 2 sampling the space of candidate attributes providing a sparse yet adequate coverage of the candidate attribute space to achieve reliable input variable selection results 1 3 generating the hydrometeorological time series exhibiting sampled attribute values 1 4 assessing system performance based on the generated hydrometeorological time series 2 the selection of critical climate attributes by 2 1 determining the relative importance of candidate attributes ensuring that both the importance of each attribute and dependence with other attributes are taken into account 2 2 selecting the set of critical attributes ensuring an adequate trade off between the inclusion of all climate attributes that have a significant impact on system performance and minimizing the dimensionality of the scenario neutral space further details of each of these steps are given in the following sub sections 2 2 step 1 generation of sparsely sampled high dimensional scenario neutral space 2 2 1 select set of candidate attributes step 1 1 a key objective of the proposed approach is to ensure that scenario neutral methods can identify all critical system sensitivities and modes of system failure as a result it is important to ensure that a wide range of potentially relevant climate attributes is identified a priori from which the attributes that best describe system performance can be determined this set is referred to as the candidate attributes a a 1 a n and the resulting space of potential values of these attributes is referred to as the attribute space a r n where n is the number of candidate attributes any prior studies and expert knowledge about the system should be considered to select the candidate attributes including consultation with relevant stakeholders where appropriate given the complexity of the response to projected climatic changes for most water resource systems and the need for the candidate set to encompass all plausible drivers of change to system performance the candidate attribute set is likely to be quite large potentially including statistics such as the average extremes seasonality intermittency variability and inter annual persistence of multiple hydrometeorological variables such as precipitation temperature and potential evapotranspiration this increases the dimensionality of the scenario neutral space making it more difficult and computationally expensive to generate the requisite hydrometeorological time series step 1 3 fig 1 consequently careful consideration should be given to the candidate attribute selection phase to exclude any candidate attributes that are known to not influence system performance it should be noted that as system performance is determined using a system model step 1 4 the candidate attributes that can be considered are limited to those that can be used as inputs to these models 2 2 2 select combined changes in candidate attributes step 1 2 as mentioned previously in order to explore system performance across the entire candidate attribute space in a computationally efficient manner a sparse sample of values from this space a 1 i a n i should be generated where i 1 s and s is the number of samples generated for the n attributes this set of generated samples is referred to as the set of attribute targets as the aim of the next step step 1 3 is to generate hydrometeorological time series that have these attribute values fig 1 as the number of attributes that could have an impact on system performance and hence the space to be explored is potentially quite large e g n 10 for many practical situations it is necessary to implement a sampling strategy that efficiently covers the attribute space methods like latin hypercube sampling and improved distributed hypercube sampling have proved to be useful for this purpose beachkofski and grandhi 2002 stein 1987 selection of the bounds on the candidate attributes subjected to sampling also requires careful consideration to maximize the likelihood that the system performance variations are captured for all plausible climate futures it is important that the bounds cover the full range of changes that might be expected however as wider bounds increase the size of the attribute space to be sampled and as the relative impact of a particular climate attribute on system performance can be a function of the selected range care needs to be taken to ensure the selected range does not extend beyond the changes that might plausibly occur one potential method for achieving this is to extend the bounds just beyond those projected by relevant climate models and or other available lines of evidence to allow for uncertainty in these models brown and wilby 2012 as mentioned previously a balance needs to be struck between having sufficient samples to adequately capture the relationship between changes to candidate attributes and corresponding system performance while keeping the number of samples as small as possible as the size of the attribute space i e number of attributes and their bounds and the nature of the relationship between changes in candidate attributes and system performance are likely to be case study dependent so is the number of samples required however based on studies in ivs for data driven models and the development of surrogate meta models a sample size s of around 10 000 is likely to provide reasonable results for an example case where approximately n 10 candidate attributes are selected broad et al 2005 broad et al 2010 li et al 2015b may et al 2008 2 2 3 generate hydrometeorological time series step 1 3 as mentioned previously given the high dimensionality of the candidate attribute space e g n 10 it is difficult to generate the hydrometeorological time series that simultaneously exhibit the various combined target attributes determined in step 1 2 currently the only systematic approach that is capable of generating the requisite time series is the inverse approach of guo et al 2018 as part of this approach the hydrometeorological time series that match the targets of the desired future climate attributes are generated with the aid of a weather generator resulting in a set of modelled targets of the desired climate attributes â 1 i â n i in order to ensure the modelled attributes â 1 i â n i are as similar as possible to the targets a 1 i a n i an appropriate optimization algorithm such as an evolutionary algorithm guo et al 2018 maier et al 2014 maier et al 2019 is used to identify the set of parameters of the stochastic weather generator θ that minimizes an objective function that measures the difference between the modelled a 1 i a n i and target â 1 i â n i values an example of such an objective function is the root mean squared error the ability to meet the targets depends on both the weather generator and the set of candidate attributes used in relation to the former many models for generating stochastic hydrometeorological time series are available each with different underpinning assumptions and model structures richardson 1981 richardson and wright 1984 simpler models may not have the degrees of freedom required to change the relevant attributes of a time series independently e g winter precipitation and summer precipitation when using a weather generator that does not simulate seasonal variability given the need to include a wide selection of attributes in the candidate set it is recommended to use a more complex weather generator with the required degrees of freedom in its parameters and structure with regard to the latter it is possible that attributes will be included in the candidate set that will co vary with other attributes due to the structure of the weather generator used resulting in an inability to meet samples formed by perturbing attributes independently more information on challenges and possible solutions related to using the inverse approach to achieve specified target attributes is provided in culley et al 2019 2 2 4 assess system performance step 1 4 the model used to calculate system performance under plausible future climate conditions can comprise a single model or a coupled set of models that take the generated hydrometeorological time series as inputs and simulates the resulting system performance as the output this enables an assessment of how system performance changes under a range of plausible climate futures it should be noted that the time step of the weather generator step 1 3 must match that of the system model so that system performance can be simulated for each climate time series the system model should be able to simulate the key processes of the investigated system so that the strength of the simulated relationship between attributes and system performance is representative of the real system this is a challenge that affects all scenario neutral impact assessments and it has recently been demonstrated that the choice of system model can lead to different conclusions about system sensitivity broderick et al 2019 guo et al 2017a a further challenge affecting all scenario neutral assessments is that models may be required to simulate system behavior outside the bounds of historical variability assessing system model performance under changed or non stationary climate regimes is an active research endeavor with possible approaches including differential split sample testing and optimizing model performance for different climate conditions fowler et al 2016 klemes 1986 westra et al 2014 2 3 step 2 selection of critical climate attributes 2 3 1 determine relative significance of candidate attributes step 2 1 using the data on the relationship between the candidate attributes and corresponding system performance obtained in step 1 the relative significance of each candidate attribute can be calculated as a key aim of step 2 is to select the smallest set of m critical attributes from the set of n candidate attributes the dependence between variations in system performance as a function of different candidate attributes has to be taken into account in addition to the significance of the relationship between each candidate attribute and corresponding system performance methods that can be used to account for variable dependence can be divided into two main groups dimensionality reduction and filtering friedman et al 2001 may et al 2011 dimensionality reduction techniques can be split into those that identify combinations of attributes that provide independent information by rotating data vectors such as principal component analysis and those that cluster attributes into groups that provide similar information and then selecting a representative attribute from each cluster bowden et al 2005 a range of clustering methods can be used for this purpose such as nearest neighbor methods regression trees and self organizing maps and representative values can be selected from clusters based on criteria such as the euclidean distance from the cluster center the most prominent example of filtering methods is stepwise partial selection as part of which the attribute that has the strongest influence on system performance is ranked first i e forwards stepwise selection followed by the attribute that has the next biggest additional impact and so on sharma 2000 this is achieved by calculating a measure of influence between each attribute and system performance with the attribute that results in the greatest variation in system performance ranked first next a model is developed using the first ranked attribute as an input and system performance as an output which can be done using regression based methods or other data driven methods such as artificial neural networks li et al 2015a sharma 2000 the attribute that is ranked second is the one with the strongest relationship with the residuals of this model this continues for all remaining attributes this enables a ranked list of attributes to be obtained as well as a measure of the influence each attribute has on system performance additional to the influence of the higher ranked attributes some of the most commonly used filtering methods in the ivs literature include partial correlation partial mutual information the iterative input variable selection iis algorithm and the gamma test galelli et al 2014 may et al 2008 a range of measures of influence significance can be used in combination with the above approaches that account for input dependence these measures can be based on correlation variance mutual information or sensitivity may et al 2008 when combined with clustering these measures are applied to the attributes that are representative of each cluster enabling these to be ranked in contrast when used as part of filtering approaches these measures are interspersed in the process used to account for dependence as discussed above the most appropriate approach for determining the relative significance of attributes for a particular application is a function of user preference and the attributes of the data e g degree of non linearity type of distribution problem dimensionality and sampling approach galelli et al 2014 however irrespective of which approach is used the key is that both dependence and significance have to be considered so that the smallest number of climate attributes that have a significant impact on system performance can be identified this ensures that the dimensionality of the scenario neutral space is reduced as much as possible while still capturing all critical modes of system performance variation 2 3 2 select critical attributes step 2 2 the set of critical climate attributes m can be selected from the candidate attribute set n by applying an appropriate selection criterion to the ranked candidate attributes obtained in the previous step step 2 1 the objectives of this step is to determine the trade off between maximizing the information on system sensitivity while minimizing the dimensionality of the scenario neutral space as discussed in section 1 this can take the form of a visual inspection of a plot of the change in the selected measure of influence with the inclusion of additional attributes the use of significance tests e g when correlation is used as the measure of influence or the use of metrics that are similar to those balancing model performance with model parsimony such as akaike s or bayes information criteria fernando et al 2009 which approach is considered most appropriate depends on a range of case specific factors such as problem dimensionality degree of dependence between attributes computational overhead associated with the system model and so forth 3 case study implementation and testing of proposed approach a case study of a regulated reservoir is used to demonstrate and test the approach outlined in section 2 the critical climate attributes are identified for two competing system objectives flood mitigation and irrigation supply to determine whether different critical attributes are identified for each section 3 1 describes the case study models and data and section 3 2 describes the specific implementation of the steps described in section 2 section 3 3 1 presents further analysis used to assess how well the approach selects critical attributes finally to demonstrate the utility of the proposed approach section 3 3 2 presents a comparison between the scenario neutral spaces generated by considering the critical attributes with those generated by considering mean precipitation and temperature as the axes of the scenario neutral space which is the approach most commonly used in the literature 3 1 case study models and data the lake como case study is located in the alpine region of northern italy anghileri et al 2013 culley et al 2016 the maximum storage volume in the lake is 254 mm3 and the lake provides water for one of the largest irrigation systems in europe the regulation of lake como is driven by two primary objectives mitigating flooding and supplying irrigation needs with an additional minimum environmental flow release constraint each day to ensure adequate conditions in the downstream adda river this study considers a simplified representation of the lake como system to illustrate the proposed approach the lake como system was selected as a large snowmelt component to annual inflows means it is likely influenced by more complex attributes than annual means and two competing objectives in the system model allows for a comparison of how the identified critical climate attributes can differ even for the same system the lake como catchment is modelled by a lumped hbv model bergström and singh 1995 the hydrometeorological inputs to the model are daily precipitation and temperature time series evaporation is calculated internally using hamon potential evapotranspiration and is dependent on temperature hamon 1960 as is the snowpack component that stores rainfall in the catchment as snow until a melting temperature is reached giuliani and herman 2014 the historical data include records of daily temperature precipitation and streamflow into the lake across the baseline period from 1965 to 1980 and are used to calibrate the hydrological model anghileri et al 2011 catchment average precipitation data are used derived from five gauges across the catchment while the daily temperature data are from one site the reservoir system is modelled with a mass balance equation at a daily time step in which there is a controlled release each day the reservoir releases vary based on the time of year and height of the reservoir in order to represent typical historical operational decisions over the baseline period the releases are simulated using a radial basis function fitted to historical operating characteristics culley et al 2016 giuliani et al 2015 giuliani et al 2014 as the actual reservoir operation rule curves were not known as this radial basis function is dependent on reservoir height it allows for some adaptation to climate variability both in and across different climate time series the annual demand pattern is held constant throughout all climate time series this does not reflect expected changes to demand as a result of changing climate regimes but this does not diminish the illustrative value of the case study in this application the system model is configured to simulate two performance criteria calculated as annual average values flood reliability and irrigation deficit the flood reliability criterion is calculated as the fraction of days the reservoir height is below the flood threshold 1 24 m above minimum storage level for the irrigation deficit criterion each daily release is compared to the irrigation demand for that day if demand is met the deficit is zero otherwise the volume of the daily deficit is recorded in kl the total annual deficit is then averaged over the number of years of simulation the twenty climate projections used in this analysis are from the eurocordex project where projections were created for europe at a 50 km resolution eur 44 and a 12 5 km resolution eur 11 both of which are used in this study conevski 2014 the projections were bias corrected using quantile mapping boé et al 2007 déqué 2007 climate projections for the period of 2040 2060 were used in this study to determine the bounds of the attribute space sections 3 2 1 3 2 implementation of proposed approach this section describes the implementation of the approach presented in section 2 sections 3 2 1 and 3 2 2 detail each of the two steps in the approach i e section 2 2 and 2 3 respectively 3 2 1 generation of a sparsely sampled high dimensional scenario neutral space the realizations of potential future climate attributes are obtained by sparsely sampling from a pre determined set of candidate attributes this set of candidate attributes is restricted to the hydrometeorological variables temperature and precipitation as these are the inputs to the system model for the case study in selecting statistics of these two variables our aim was to include a wide range of attributes including those previously unexplored in scenario neutral impact assessments the etccdi list of extreme climate indices etccdi 2013 served as a starting point for this providing attributes like the wet spell duration wsd 99th percentile of daily rainfall p99 and the number of frost days f0 several non extreme attributes were also included such as annual rainfall and average temperature which are known to be important drivers in water resource systems in practice this process can also include discussions with stakeholders and incorporation of any existing expert knowledge the full list of the fifteen candidate attributes n 15 considered for the lake como case study a a 1 a 15 is shown in table 1 candidate attribute values were then calculated from the selected climate projection time series in order to determine the bounds of the attribute space each of the candidate attribute values was averaged over the period 2040 2060 and bounds were chosen to extend slightly beyond these values table 2 precipitation attributes are described by fractional changes from historical values and temperature attributes are described by additive changes compared to the instrumental baseline of 1965 1980 it should be noted that this method of calculating the bounds does not take into account any biases in the downscaled climate projections compared to the observed record for example only decreases in wet spell durations are considered which may be due to all projections having less persistence in rainfall an alternative approach would be to compare fractional or absolute changes relative to the modelled baseline which would reduce the implications of biases since both the modelled baseline and future projections would be subject the same biases but then the changes would no longer be indicated relative to the historical instrumental record finally we have extended the attribute bounds beyond the largest projected change without removing any outliers giving large increases in temperature as bounds despite this only being projected by one 8 5 rcp model a latin hypercube sampling lhs method was chosen to sample the candidate attribute space to generate the scenario neutral space a 1 i a 15 i fifteen thousand samples were taken from within the bounds to provide reasonable coverage of the scenario neutral space while considering the high computational cost of optimizing each climate time series climate time series of precipitation and temperature were then generated using the inverse approach for the fifteen thousand sampled targets of attributes the inverse approach was implemented using the r package foresight bennett et al 2018 and required approximately 20 000 cpu hours to generate the samples the weather generators used are based on the wgen model from richardson 1981 the rainfall generation requires 12 parameters the mean amplitude and phase angle of a single harmonic for each of pwd pdd used in a 1st order markov chain α and β used in a gamma distribution to sample rainfall amount the temperature generation requires 10 parameters the mean amplitude and phase angle for a single harmonic of mean daily temperature one harmonic each for the wet and dry day standard deviation and a lag 1 coefficient of the residuals each climate time series had a length of 21 years which was selected to match the climate projection window of 2040 2060 the genetic algorithm used in foresight was used with default operators scrucca 2013 and 300 generations a single weather generator replicate was used for each target and the actual attributes that were generated â 1 i â 15 i were recorded the time series were then used as an input to the hydrological model to simulate daily flow the lake como reservoir model then used these daily flow time series to calculate the two performance criteria in response to each time series 3 2 2 selection of critical climate attributes the partial mutual information algorithm pmi algorithm input variable selection was implemented to rank the set of candidate attributes section 2 3 1 li et al 2015a sharma 2000 using the modelled values of the climate attributes â 1 i â 15 i which are different from the targets because the optimization does not find parameterizations with a perfect mapping this approach was selected because of non linearity in the system performance metrics and the need to consider co variance between climates attributes the pmi algorithm ranks candidate attributes in order of significance based on the mutual information between each of the n candidate attributes and system performance after removing the effect of higher ranked i e more important attributes the mutual information mi between two variables is a measure of how much information about one variable is gained by an observation of the other for a set of targets s the mi between each attribute a ˆ k and the measure of system performance p can be approximated by the following equation 1 i a ˆ k p 1 s i 1 s log f a ˆ k i p i f a ˆ k i f p i where k indexes the n candidate attributes i e k 1 n and f are the marginal or joint probability density functions of the attributes and system performance which are typically estimated using kernel density estimators galelli et al 2014 li et al 2015b the mi is non negative and unbounded unlike other dependence metrics e g pearson correlation spearman rank it should be noted that as the generated hydrometeorological time series are used to assess system performance via the system model fig 1 the modelled values of the climate attributes â 1 i â n i have to be used as part of the analysis to determine the m critical attributes with the aid of the pmi algorithm rather than a 1 i a n i as part of the pmi algorithm the climate attribute with the highest mi value is selected first in order to identify the climate attribute that has the next highest additional impact on system performance the influence of the selected attribute needs to be removed this is achieved by developing non linear regression relationships between the already selected attribute and both the remaining attributes and system performance the mi can then be calculated between the residuals of these models which is referred to as the pmi the required non linear regression models can be developed using kernel based methods such as general regression neural networks specht 1991 or kernel free methods such as multi layer perceptron artificial neural networks mlpanns wu et al 2014 while kernel based methods are generally more computationally efficient mlps have been found to perform better if the data are highly non gaussian li et al 2015b the iterative process outlined above is repeated until all candidate attributes have been ranked the algorithm was implemented for the two performance criteria using the software developed by li et al 2015b a conventional gaussian kernel was used with the gaussian reference bandwidth may et al 2008 to estimate the probability density functions for the partial mutual information calculation a multi layer perceptron artificial neural network mlpann model was used as the non linear regression technique to remove the influence of each selected attribute this model is limited to one hidden layer with a maximum of four nodes to avoid over fitting li et al 2015b both of these methods are recommended for use with highly non linear data sets the rankings of the candidate attributes alone are not indicative of how many should be selected to create a scenario neutral space further information is needed to select the m critical attributes from the ranked n candidate attributes input variable selection methods have established stopping criteria may et al 2011 but in this application significant emphasis is placed on selecting a small number of attributes given how challenging the visualization of system performance becomes in higher dimensions this can be achieved with the aid of the cumulative variance explained cve in system performance which is calculated for each selected attribute by 2 c v e j 1 s s e r r j s s p where s s p i 1 s p i p 2 is the total sum of squares of the system performance p for the first selected attribute j 1 the sum of squares of the residuals of the non linear regression between the first attribute and system performance is given by s s e r r j i 1 s p i p ˆ i 2 such that the cve metric equates to an r2 calculation for each additional attribute s s e r r j i 1 s p g r j i p ˆ g r j i 2 is the sum of squares of the residuals of the non linear regression between the jth attribute and system performance both of which have been updated by removing the effect of the set of j 1 previously selected attributes where g r j is the effect of the previous selected attributes r j a 1 a j 1 this is similar to an analysis of variance metric anova except that as opposed to being calculated for each attribute based on the initial sample it is calculated iteratively after each non linear regression transformation of the original sample this non linear regression is therefore a requirement of the partial approach used the relative gain in this metric with each additional attribute can be used to decide how many attributes are critical for the system under consideration as defined by the system performance metric p this is achieved by visual inspection of the plot of cumulative variance explained and number of attributes ranked in order of significance by the pmi algorithm and exclusion of the attributes after which the cve plateaus leaving the m critical attributes it should be noted that the absolute cumulative variance explained values at which the plateau occurs can provide an indication of whether all critical attributes have been included in the candidate set if a significant portion of variance in the performance is still unexplained this provides an indication that there are aspects of the climate time series investigated that are changing in a way that affects system performance but are not being measured by the candidate attributes 3 3 methods to evaluate the utility of the proposed approach 3 3 1 selection of correct critical attributes to evaluate the success of the approach to attribute selection a test was developed that investigates i how well the pmi algorithm performs in terms of ranking the candidate attributes in order of decreasing impact and ii how well the cumulative variance explained metric can be used to select critical attributes the residuals obtained after removing the effect of each additional attribute section 2 3 1 were inspected visually along with the relationship obtained from the corresponding mlpann model a decrease in the strength of the signal in the residuals as each attribute is removed indicates that the attributes are being ranked correctly such plots should be inspected for all critical attributes plus the next most significant attribute if the residuals for the next most significant attribute have no or negligible signal then this provides an indication that there is no more information left to describe and hence the correct number of critical attributes has been selected 3 3 2 scenario neutral climate impact assessments as mentioned at the beginning of section 3 to demonstrate the utility of the proposed approach two scenario neutral impact assessments are presented one with scenario neutral spaces constructed using the critical attributes identified using the proposed approach and the other with a scenario neutral space constructed using just mean precipitation and temperature as the axes of the scenario neutral space as part of the assessments the scenario neutral spaces were divided into regions of success and failure and the climate projections for the lake como region which correspond to changes in each attribute in the year 2050 were overlaid the proportions of climate projections that indicate unsuccessful performance for the two different scenario neutral impact assessments were then compared the performance thresholds were selected by considering system performance under current conditions and adding a small buffer these thresholds are used for illustrative purposes and assume that the system is currently operating successfully and there is some margin or buffer built into the system design this led to an irrigation deficit criterion of 4224 kl and a flood reliability criterion of 95 the stochastic time series for the more detailed scenario neutral analyses were created using the technique outlined in section 2 2 3 for the space using only mean precipitation and temperature target changes were set using a high resolution sample between the bounds in table 2 for the critical attribute spaces the first two dimensions were sampled in high resolution between the bounds indicated in table 2 and the third and fourth dimensions were explored using larger step changes three or four intervals depending on the width of the bounds to allow the space to be visualized in a lattice plot the r package foresight was used to stochastically generate 21 years of daily precipitation and temperature data with five weather generator replicates used for each target the system performance metrics were then calculated in response to these time series using the system model and the average performance across the five replicates is shown for each target 4 results and discussion section 4 1 presents the results for the approach detailed in section 2 this includes the pmi calculations as well as an analysis of how many critical attributes should be selected to capture system vulnerabilities for the different performance criteria section 4 2 1 presents the results of the additional analysis conducted to test how well the approach performs and section 4 2 2 presents the results of the tipping point type analysis detailed in section 3 3 2 4 1 selection of critical attributes fig 2 shows the cumulative variance explained cve metric calculated for each of the candidate attributes and for each of the two performance criteria while details of the critical and next most significant attributes are given in table 3 as can be seen from fig 2 the cve plateaus after four attributes for the flood reliability criterion the most critical attribute for the flood reliability criterion is f0 table 3 which makes sense from a physical perspective as this attribute describes the number of days on which temperatures are above and below zero degrees and thus provides an indicator of the snow storage in the year historically the largest inflows into the reservoir are in spring as the snow storage is released decreasing the number of frost days in the year means warming occurs earlier changing the timing of the snowmelt this causes more flooding events given the reservoir operation was designed for historical conditions ptot is the next most significant attribute which also makes physical sense as annual rainfall largely dictates the amount of water in the reservoir the next critical attribute is pson which when the total annual rainfall is held constant controls the seasonality in the shoulder seasons finally tdec is selected which when the number of frost days is held constant shifts the lowest temperatures into january and february and does not result in as much storage of snow in december as the reservoir does not release water during december this can cause the runoff from any high rainfall events to cause flooding where previously this runoff would have been stored as snow the addition of the next most significant attribute tmar increased the cve value by only 0 001 table 3 and so this is not considered critical for the irrigation deficit criterion four attributes are also selected as critical with a distinct gradient change in the cve value after the fourth attribute although the cve continues to increase gradually until eight attributes are selected the relative information increase caused by these four additional variables is marginal especially when traded off against the additional difficulty of producing an eight dimensional scenario neutral space as can be seen from table 3 the most significant attribute for the average height criterion is ptot which is to be expected as the irrigation deficit is primarily a function of the total amount of water in the system which is mainly affected by total annual rainfall the attribute having the second most significant impact on the average height criterion is f0 frost days which affects the snowmelt in the year as discussed above this is a large source of annual inflow for the lake como reservoir that occurs as it becomes warmer which is also when the irrigation demand increases the next two critical attributes are tjun and pjja which both control the climate when the irrigation demand is highest and affect the rainfall available and evaporation losses in that period respectively the next most significant attribute tdec impacts the timing of the snowmelt releases by shifting the days with lowest temperature however the increase in cve by including this attribute is only 0 019 compared to the 0 058 increase when selecting the fourth attribute and so it would not be worth the exponential increase in computational cost to include this fifth attribute in a scenario neutral space table 3 the cve values in fig 2 and table 3 indicate that the total amount of variance explained by the critical attributes varies for the two performance criteria overall the irrigation deficit criterion reaches 83 variance explained compared to 65 for the flood reliability criterion this suggests in both cases that there are aspects of the time series that are changing system performance yet are not accounted for in the candidate attributes and that this is more of an issue for the flood reliability criterion comparing the two performance criteria the number of flooding events is subject to greater variability in the time series than the total irrigation deficit in the year which is why it has a lower cve value a possible explanation of this result is therefore that as system criteria become more affected by variability there is a limit to the amount of system performance that can be predicted by a candidate set of attributes that mainly consists of annual and seasonal means in a real life setting this might necessitate the inclusion of a larger candidate set to ensure that all modes of system performance variability are accounted for in the scenario neutral climate impact assessment although this decision is somewhat subjective the choice to include more attributes in a candidate set to better account for system performance also needs to be balanced by the usefulness of attributes as predictors for system performance for example including the standard deviation in annual total rainfall over the simulation or monthly temperature ranges as attributes may explain some variance in performance but is likely to make it difficult to design tipping points or operational changes in response to observed changes in these attributes however the fact that even a broad set of 15 candidate attributes was not able to describe all of the variance in system performance highlights that the attributes considered in the vast majority of scenario neutral studies i e average rainfall and average temperature are unlikely to identify all the relevant modes of system failure in the type of system analyzed a comparison of the rankings of the critical attributes obtained for the different performance criteria provides a useful means of highlighting the utility and importance of using the pmi algorithm combined with the cve metric for identifying the climate attributes to which system performance is most sensitive the results of the pmi analysis clearly demonstrate that different climate attributes are critical for different performance criteria reinforcing the fundamental premise underpinning scenario neutral climate impact assessments that the axes of the scenario neutral space need to be tailored to specific systems and performance measures 4 2 evaluating the utility of the proposed approach 4 2 1 testing for correct critical attributes the results of the test designed to evaluate the utility of the proposed approach are shown in fig 3 for both the irrigation deficit and flood reliability criteria the strength of the relationship in the residuals reduces with the addition of less significant attributes at the fifth attribute the residuals are close to noise although there is still a slight relationship for the irrigation deficit criterion which confirms the findings in fig 2 this suggests that the pmi algorithm combined with the cve metric were able to successfully select the critical attributes from the fifteen candidate attributes fig 3 also demonstrates that a major difference between the two performance criteria across the 15 000 samples is that the flood reliability criterion is highly non linear whereas the irrigation deficit criterion is less so noting that both performance criteria are scaled this is due to the proximity of the former to the upper bound of 1 caused by a number of time series that only have 0 2 flood events throughout the year in contrast there is irrigation deficit in every time series and it varies much more linearly with the first selected attribute this shows how the pmi algorithm performs well with both linear and highly non linear relationships between attributes and system performance 4 2 2 comparing scenario neutral climate impact assessments for the irrigation deficit criterion there is a significant difference in the results obtained using default attributes of mean annual precipitation and temperature compared to using the critical attributes identified using the proposed approach fig 4 using the scenario neutral space of mean annual precipitation and temperature eight of the twenty climate projections suggest that the irrigation deficit will be unacceptable due to decreases in ptot and increases in tavg fig 4a in contrast when considering the scenario neutral space formed by the critical attributes only three projections suggest failure of the system projections 3 5 and 6 this difference is due to the fact that the scenario neutral space formed by the critical attributes captures a more detailed range of system performance for example the majority of climate projections indicate a decrease in summer rainfall amounts which decreases the performance of the irrigation objective given a fixed annual total however this seasonal information is not obtained when only changes in ptot and tavg are considered these results clearly show the utility of the proposed approach as adoption of the commonly used ptot and tavg scenario neutral space significantly overestimates future system failure in accordance with the irrigation deficit criterion in addition to over estimating the risk of future failure consideration of the ptot and tavg scenario neutral space could result in the adoption of ineffective adaptation strategies for example when only considering future changes in ptot and tavg adaptation strategies designed to avoid system failure would be targeted at better responses to these drivers in contrast by gaining a deeper understanding of the key modes of system failure identified with the aid of the proposed approach adaptive strategies responding to severe decreases in summer rainfall and high increases in average june temperature can be developed as illustrated by fig 5 the comparison between the ptot and tavg space and the critical climate attribute space for the flood reliability criterion also shows a difference between the number of failures obtained although this difference is not as marked as that observed for the irrigation deficit criterion in the ptot and tavg space no projections indicate a large enough decrease in flood reliability to cause unacceptable performance as this would require an increase in annual rainfall without an increase in average temperature in the critical attribute space only one projection predicts unacceptable performance projection 1 which was the projection that was the closest to unacceptable performance in the ptot and tavg space this shows that there can also be a risk of under estimating failure when not using the critical climate attributes finally as was the case for the irrigation deficit criterion adoption of the proposed approach was able to identify critical modes of system failure for example for the flood reliability criterion application of the proposed approach was able to identify that high december temperatures can cause unacceptable levels of performance which would not be detected if only ptot and tavg were considered identifying this information about system vulnerabilities is a key purpose of scenario neutral impact assessments these results indicate that these vulnerabilities can change with different system performance criteria and that these changes can only be identified by considering the climate attributes to which system performance is most sensitive 5 summary and conclusions this study presents a novel approach for selecting critical climate attributes for use in timeseries driven scenario neutral impact assessments this is necessary given that when large numbers of climate attributes are used to form high dimensional scenario neutral spaces it is extremely difficult to generate the time series that perturb each attribute in the required way this is likely to be one of the primary reasons why most scenario neutral studies that use hydrometeorological time series consider too few dimensions often defaulting to examining mean precipitation and temperature however this may mean that for many systems some important climatic changes are not considered and critical modes of failure can be missed this study therefore describes a formal approach to the identification of the attributes that contain most of the information about system performance while keeping the number of critical attributes as small as possible for computational and analytical tractability the approach identifies the critical attributes by firstly generating a sparse sample of attribute changes across a much larger candidate set of attributes then converting these changes into weather time series for input into a system model and then using the system model to convert the time series into system performance metrics an ivs algorithm is then used to rank the candidate attributes in order of significance as well as the added information content that each attribute brings to the analysis conditional on those already selected the critical attributes are identified once additional attributes no longer add information content such that as much of the system performance can be captured in as few dimensions as possible the approach was demonstrated on the lake como reservoir system using two modelled performance criteria irrigation deficit and flood reliability the approach identifies the critical attributes for each performance criterion thereby enabling the high resolution sampling of the critical climate scenario neutral space for use in subsequent applications such as scenario discovery and decision scaling this study found that one of the most commonly selected attributes in scenario neutral studies annual average precipitation was the most important attribute for only one objective irrigation deficit however three additional attributes the number of frost days summer rainfall and average june temperature were also needed to represent the irrigation deficit criterion the flood reliability criterion which was most sensitive to the number of frost days in the year also required four attributes to describe most of the variance in system performance this demonstrates the difficulty of knowing a priori which attributes are likely to be most important for a given system and thus the need for a structured analysis for identifying the critical attributes for each system and performance criterion importantly the approach produces significantly different outcomes when a scenario neutral space uses the selected critical climate attributes compared to the common defaults of annual average precipitation and temperature results indicate that the choice of attributes significantly influences the conditions for which acceptable and unacceptable levels of system performance changes occurs further the specific finding of system sensitivities to decreases in summer rainfall and increases in june temperature in addition to changes in annual means provides insights into system dynamics and potential vulnerabilities this highlights that using critical climate attributes can enable more detailed planning in response to identified system vulnerabilities which is the main purpose of scenario neutral impact assessments declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the case study data used in this study are from agenzia regionale per la protezione dell ambiente http ita arpalombardia it ita inde and consorzio dell adda http www addaconsorzio it the authors would like to thank arpa and eng bertoli from consorzio dell adda for its provision the authors would also like to thank m giuliani and a castelletti for their contribution to this research as well as robert wilby and two anonymous reviewers for their comments which improved the manuscript details of the climate time series data produced using the foresight package https cran r project org web packages foresight index html and case study performance data used in the results can be made available upon request sam culley was supported by an australian postgraduate award 
25891,scenario neutral climate impact assessments 4 results and discussion 4 1 selection of critical attributes 4 2 evaluating the utility of the proposed approach 4 2 1 testing for correct critical attributes 4 2 2 comparing scenario neutral climate impact assessments 5 summary and conclusions acknowledgments anghileri 2013 492 500 d anghileri 2011 2025 2038 d beachkofski 2002 1274 b aiaaasmeasceahsascstructuresstructuraldynamicsmaterialsconference improveddistributedhypercubesampling43rd bennett 2018 b foresightsystemsinsightsgenerationhydroclimatictimeseries bergstrom 1995 443 476 s hbvmodelcomputermodelswatershedhydrology boe 2007 1643 1655 j borgomeo 2015 5382 5405 e borgomeo 2015 8927 8948 e bowden 2005 75 92 g broad 2005 172 180 d broad 2015 382 395 d broad 2010 433 443 d broderick 2019 1079 1104 c brown 2012 w09537 c brown 2012 401 402 c bryant 2010 34 49 b bussi 2016 357 372 g conevski 2014 s acomprehensiveanalysisclimatechangestructuraluncertaintyacomplexwatersystemcasestudyincomomuzza culley 2019 111 122 s culley 2016 6751 6768 s deque 2007 16 26 m eckhardt 2003 244 252 k etccditccdi 2013 etccdicrdclimatechangeindicesxuebinzhang fernando 2009 165 176 t fowler 2016 1820 1846 k frey 2002 553 578 h friedman 2001 j elementsstatisticallearning galelli 2013 4295 4310 s galelli 2014 33 51 s gao 2016 154 166 l giudici 2020 104681 f giuliani 2015 04015050 m giuliani 2014 10 m introductionhbvmodel giuliani 2014 3355 3377 m groves 2007 73 85 d guillaume 2016 326 343 j guo 2017 435 454 d guo 2017 317 330 d guo 2018 877 890 d haasnoot 2013 485 498 m hadka 2015 114 129 d hamon 1960 w estimatingpotentialevapotranspiration herman 2018 39 51 j herman 2015 04015012 j herman 2014 7692 7713 j hyde 2005 278 290 k 2014 climatechange2014impactsadaptationvulnerabilitycontributionworkinggroupiififthassessmentreportintergovernmentalpanelclimatechange summaryforpolicymakers kasprzyk 2013 55 71 j kay 2014 5273 5287 a klemes 1986 13 24 v lempert 2008 r comparingalgorithmsforscenariodiscovery lempert 2007 1009 1026 r li 2015 15 29 x li 2015 78 96 x maier 2014 271 299 h maier 2019 195 213 h mastrandrea 2010 87 101 m may 2011 r reviewinputvariableselectionmethodsforartificialneuralnetworks may 2008 1312 1326 r mcphail 2018 169 191 c mcphail 2020 e2019wr026515 c nazemi 2014 a nazemi 2013 291 305 a prudhomme 2013 933 948 c prudhomme 2013 949 964 c prudhomme 2010 198 209 c quinn 2018 4638 4662 j raso 2019 267 283 l ravalico 2010 171 181 j ray 2018 168 181 p razavi 2012 s richardson 1981 182 190 c richardson 1984 c wgenamodelforgeneratingdailyweathervariables scrucca 2013 1 37 l sharma 2000 232 239 a shortridge 2016 2298 2312 j singh 2014 3409 3427 r specht 1991 568 576 d stein 1987 143 151 m steinschneider 2013 7205 7220 s steinschneider 2015 04015023 s taner 2017 34 50 m turner 2014 3553 3567 s wei 2011 2163 2171 m westra 2014 5090 5113 s wetterhall 2011 2295 2306 f whateley 2014 8944 8961 s wu 2014 108 127 w culleyx2021x104948 culleyx2021x104948xs 2022 12 17t00 00 00 000z 2022 12 17t00 00 00 000z http creativecommons org licenses by nc nd 4 0 2020 published by elsevier ltd 2020 12 25t23 18 10 520z http vtw elsevier com data voc addontypes 50 7 nlp s1364815220310057 the case study data used in this study are from agenzia regionale per la protezione dell ambiente http ita arpalombardia it ita inde and consorzio dell adda http www addaconsorzio it the authors would like to thank arpa and eng bertoli from consorzio dell adda for its provision the authors would also like to thank m giuliani and a castelletti for their contribution to this research as well as robert wilby and two anonymous reviewers for their comments which improved the manuscript details of the climate time series data produced using the foresight package https cran r project org web packages foresight index html and case study performance data used in the results can be made available upon request sam culley was supported by an australian postgraduate award item s1364 8152 20 31005 7 s1364815220310057 1 s2 0 s1364815220310057 10 1016 j envsoft 2020 104948 271872 2021 01 29t21 46 02 736382z 2021 02 01 2021 02 28 1 s2 0 s1364815220310057 main pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 main application pdf 2cbc9eefdf746ecd9e05c4880bed2a51 main pdf main pdf pdf true 6470326 main 14 1 s2 0 s1364815220310057 main 1 png https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 preview image png 789c7eb9d5e5425c4a37e6aae1417297 main 1 png main 1 png png 53919 849 656 image web pdf 1 1 s2 0 s1364815220310057 gr4 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr4 downsampled image jpeg 6bc5d278aef10a06ef60a369e861e9c6 gr4 jpg gr4 gr4 jpg jpg 149443 803 646 image downsampled 1 s2 0 s1364815220310057 gr5 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr5 downsampled image jpeg 7a2e777fec25d6ffb72e7cc0fd27fa67 gr5 jpg gr5 gr5 jpg jpg 161821 970 624 image downsampled 1 s2 0 s1364815220310057 gr2 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr2 downsampled image jpeg c634984701d6438cb5f406ed663626ef gr2 jpg gr2 gr2 jpg jpg 31530 328 548 image downsampled 1 s2 0 s1364815220310057 gr3 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr3 downsampled image jpeg cb6649c0abe88704ee83fd91005e0c5d gr3 jpg gr3 gr3 jpg jpg 238302 746 624 image downsampled 1 s2 0 s1364815220310057 gr1 jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr1 downsampled image jpeg 9389028549d347ddb259f8c274742186 gr1 jpg gr1 gr1 jpg jpg 74751 505 291 image downsampled 1 s2 0 s1364815220310057 gr4 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr4 thumbnail image gif 8617e895cb73e4017f50f1dab5e01913 gr4 sml gr4 gr4 sml sml 17178 164 132 image thumbnail 1 s2 0 s1364815220310057 gr5 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr5 thumbnail image gif 4ec5187a77d8c6e7226b93da258e4d59 gr5 sml gr5 gr5 sml sml 14598 163 105 image thumbnail 1 s2 0 s1364815220310057 gr2 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr2 thumbnail image gif e406aec35ed12c77b84a3034d4149511 gr2 sml gr2 gr2 sml sml 9012 131 219 image thumbnail 1 s2 0 s1364815220310057 gr3 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr3 thumbnail image gif 3f69af9b7428bf8edaae91188c55bddb gr3 sml gr3 gr3 sml sml 23460 164 137 image thumbnail 1 s2 0 s1364815220310057 gr1 sml https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr1 thumbnail image gif 8854b21c07adbc875d2790fd21fbed25 gr1 sml gr1 gr1 sml sml 15444 163 94 image thumbnail 1 s2 0 s1364815220310057 gr4 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr4 highres image jpeg 5a91ad789fcf46a6a63c71e9de63e1cb gr4 lrg jpg gr4 gr4 lrg jpg jpg 1014420 3558 2862 image high res 1 s2 0 s1364815220310057 gr5 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr5 highres image jpeg 02d7a5de0820f874e7613f212ad243f1 gr5 lrg jpg gr5 gr5 lrg jpg jpg 1149903 4298 2764 image high res 1 s2 0 s1364815220310057 gr2 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr2 highres image jpeg ce237552667c940aa4252cd216cc350f gr2 lrg jpg gr2 gr2 lrg jpg jpg 166615 1453 2429 image high res 1 s2 0 s1364815220310057 gr3 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr3 highres image jpeg 1ef784eb5be13cda9a9ac43d0563b72d gr3 lrg jpg gr3 gr3 lrg jpg jpg 2178074 3306 2764 image high res 1 s2 0 s1364815220310057 gr1 lrg jpg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 gr1 highres image jpeg f7173ea7420243f099dec3df44f81140 gr1 lrg jpg gr1 gr1 lrg jpg jpg 361289 2237 1288 image high res 1 s2 0 s1364815220310057 si7 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml ad477eb9c3cc60af5882dd3501f55797 si7 svg si7 si7 svg svg 54918 altimg 1 s2 0 s1364815220310057 si2 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 1e5b7a26843521770496442516c97e34 si2 svg si2 si2 svg svg 22393 altimg 1 s2 0 s1364815220310057 si6 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml b698e9ccb56c1d589b6bc1bebb1dbd75 si6 svg si6 si6 svg svg 45070 altimg 1 s2 0 s1364815220310057 si3 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 0a6cdb8dad7cdd988b374d300a232155 si3 svg si3 si3 svg svg 14598 altimg 1 s2 0 s1364815220310057 si4 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 66da10f7dfa773d0ea217ac86a6bfccb si4 svg si4 si4 svg svg 80832 altimg 1 s2 0 s1364815220310057 si1 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 043cdad556e3daf42892142cb69181d7 si1 svg si1 si1 svg svg 23542 altimg 1 s2 0 s1364815220310057 si5 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml 8fe127157311cbb37c3480087478ce5a si5 svg si5 si5 svg svg 51042 altimg 1 s2 0 s1364815220310057 si8 svg https s3 eu west 1 amazonaws com prod ucs content store eu west content pii s1364815220310057 stripin image svg xml d2b38f33fff50cf41ce813dd2abdfa45 si8 svg si8 si8 svg svg 75822 altimg 1 s2 0 s1364815220310057 am pdf https s3 eu west 1 amazonaws com prod ucs content store eu west content egi 102qpv4t1tt main application pdf e896aa03eb5959ccd6d1d3aaa5f4879c am pdf am am pdf pdf false 1232425 aam pdf enso 104948 104948 s1364 8152 20 31005 7 10 1016 j envsoft 2020 104948 fig 1 main steps in proposed approach for selecting critical climate attributes fig 1 fig 2 cumulative variance explained with each additional attribute in order of significance for the two performance criteria fig 2 fig 3 pmi selection of the critical attributes and the next most significant attribute for the flood reliability criterion left and the irrigation deficit criterion right the residuals are plotted in black and the mlpnn estimation is shown in orange the order of significance of the attributes decreases from top to bottom i e the plot for the most critical attribute is shown in the top row and the plot for the least significant attribute is shown in the bottom row the function g in the axis labels represents the effect of the previous selected attributes on the attribute selected that iteration a and the outputs p for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 3 fig 4 two scenario neutral spaces delineated by success and failure of an irrigation performance criteria with climate projections overlaid one space is created using mean precipitation and temperature top and the other using the critical climate attributes bottom fig 4 fig 5 two scenario neutral spaces delineated by success and failure of a flood performance criteria with climate projections overlaid one space is created using mean precipitation and temperature top and the other using the critical climate attributes bottom fig 5 table 1 candidate climate attributes considered where the attributes are defined as the average over the simulation period table 1 attribute name description units winter total rainfall pdjf annual summation of summer rainfall mm summer total rainfall pjja annual summation of winter rainfall mm spring total rainfall pmam annual summation of spring rainfall mm autumn total rainfall pson annual summation of autumn rainfall mm 99th percentile of daily rainfall p99 volume of 99th percentile of daily rainfall event mm average wet spell duration wsd average length of consecutive wet days mm annual rainfall volume ptot annual summation of rainfall volume mm number of wet days nwet annual count of wet days days average march temperature tmar average of daily temperature in march c average june temperature tjun average of daily temperature in june c average september temperature tsep average of daily temperature in september c average december temperature tdec average of daily temperature in december c average temperature tavg annual average of daily temperature c annual temperature range trng temperature difference between 5th percentile and 95th percentile day c frost days f0 annual count of days with temperature less than 0 c days table 2 expected change in attributes from historical baseline table 2 attribute target type projections 2040 2060 attribute bounds min max min max pdjf fraction 1 22 2 10 1 0 2 2 pjja fraction 0 43 1 20 0 4 1 2 pmam fraction 0 97 1 45 1 0 1 5 pson fraction 0 70 1 21 0 7 1 3 p99 fraction 0 92 1 29 0 8 1 4 wsd fraction 0 64 0 86 0 6 1 0 ptot fraction 0 89 1 30 0 8 1 4 nwet fraction 0 89 1 03 0 8 1 1 tmar additive 0 11 8 85 0 0 9 0 tjun additive 0 43 8 41 1 0 8 5 tsep additive 1 37 11 25 0 0 11 5 tdec additive 1 53 8 25 2 0 8 5 tavg additive 1 31 6 14 0 0 6 5 trng additive 1 43 8 50 2 0 8 5 f0 additive 59 8 12 5 70 0 0 table 3 order of critical attributes and the next most significant attribute in italics obtained using the pmi algorithm for the two performance criteria considered as well as the corresponding values of cumulative variance explained cve table 3 order flood reliability irrigation deficit attribute cve attribute cve 1 f0 0 281 ptot 0 487 2 ptot 0 542 f0 0 619 3 pson 0 591 tjun 0 683 4 tdec 0 622 pjja 0 741 5 tmar 0 623 tdec 0 760 identifying critical climate conditions for use in scenario neutral climate impact assessments s culley h r maier s westra b bennett school of civil environmental and mining engineering university of adelaide adelaide south australia 5005 australia school of civil environmental and mining engineering university of adelaide adelaide south australia 5005 australia school of civil environmental and mining engineering university of adelaide adelaide south australia 5005 australia corresponding author scenario neutral climate impact assessments are being used increasingly to assess water resource system responses to possible climate changes the purpose of such assessments is to identify system sensitivity to a range of plausible climate conditions often including an evaluation of the joint effect of multiple climate stressors given the large number of climate variables and associated statistics averages seasonality intermittency extremes etc that could plausibly change and impact on system performance it is essential that scenario neutral assessments focus on those to which the system is most sensitive a generic approach to identifying these critical climate conditions is presented and tested on the lake como reservoir in northern italy considering two system objectives irrigation deficit and flood reliability results indicate that different climate conditions are critical for the two objectives and that the choice of which climate conditions to include has a significant effect on the climate impact assessment outcome keywords climate change impact assessment scenario neutral bottom up 1 introduction climate change can impact water resource systems through stresses to both supply and demand ipcc 2014 these stresses are the result of changes to atmospheric variables such as precipitation temperature and evapotranspiration which influence water resource systems via a complex set of catchment scale and system level processes that in turn are dependent on the system s geography configuration operation and performance measures understanding the possible impacts of climate change on water resource systems therefore requires mapping changes in large scale climate processes to changes in system performance accounting for the unique features of each system mastrandrea et al 2010 to this end scenario neutral climate impact assessments are being used increasingly to assess and convey the sensitivities of water resource systems to changes in climate brown and wilby 2012 prudhomme et al 2010 these assessments work by stress testing a system against a set of hydrometeorological time series that represent potential future climate conditions these time series are then run through a system model providing information on how the system responds to changes in climate conditions and identifying critical performance thresholds and other decision relevant information brown et al 2012 prudhomme et al 2010 this creates a scenario neutral space also referred to as an exposure space or a response surface that maps system performance to changes in a range of statistics e g averages seasonality intermittency variability extremes and low frequency autocorrelations of climate variables e g precipitation temperature potential evapotranspiration the combination of which is hereafter referred to as climate attributes the scenario neutral space can be coupled with climate projections to understand the likelihood and possible timing of these changes taner et al 2017 turner et al 2014 moreover scenario neutral analyses can be used to explore the robustness of different management strategies to the set of plausible future changes brown et al 2012 culley et al 2016 whateley et al 2014 the primary stages in the construction of scenario neutral spaces consist of i selection of the climate attributes against which to stress test the system this usually corresponds to the selection of the axes of the scenario neutral space ii development of a set of perturbed attribute values representing the plausible changes to be used for stress testing this is equivalent to selecting the locations in the scenario neutral space at which to assess system performance iii generation of climate perturbed hydrometeorological time series that reflect the perturbed attribute values i e generation of climate perturbed time series that represent each selected location in the scenario neutral space iv assessment of system performance at each location in the scenario neutral space by passing the climate perturbed hydrometeorological time series generated in iii through a system model and calculating the corresponding system performance a number of methods have been developed to support the above stages for stage ii different approaches have been used to determine the combinations of changes in climate attributes for which to assess system performance when the system is sensitive to only a small number of climate attributes such as only changes to annual average rainfall and temperature but not to changes in seasonality intermittency variability extremes or low frequency oscillations then it becomes possible to have a low dimensional e g 2 or 3 dimensional scenario neutral space in these cases system performance can be evaluated over a regular grid of changes to each attribute brown et al 2012 culley et al 2016 prudhomme et al 2010 steinschneider et al 2015 turner et al 2014 in contrast when the dimensionality of the scenario neutral space is high e g larger than 10 a variety of sampling techniques have been used to cover representative regions e g latin hypercube improved distributed hypercube efast as the use of a regular grid would be too computationally expensive beachkofski and grandhi 2002 gao et al 2016 kasprzyk et al 2013 stein 1987 in practice such high dimensional scenario neutral spaces thus far have only been used in cases where changes in climate attributes were combined with other factors affecting system performance such as demands and costs herman et al 2014 kasprzyk et al 2013 ray et al 2018 shortridge and guikema 2016 with the number of climate attribute dimensions considered still being small i e 2 to 3 for stage iii different approaches also have been developed and or used to generate hydroclimatic time series that represent the desired attribute changes as discussed in guo et al 2018 these time series traditionally have been obtained by applying scaling factors to historical data culley et al 2016 kasprzyk et al 2013 kay et al 2014 weiβ 2011 wetterhall et al 2011 however this approach cannot account for changes in attributes such as intermittency autocorrelation and extremes or for complex combinations of changes such as an increase in extremes coupled with a decrease in mean to address this limitation stochastic weather generators have received increased attention as they have more flexibility to simulate complex combinations of future changes borgomeo et al 2015a guo et al 2018 ray et al 2018 steinschneider and brown 2013 however estimation of stochastic weather generator parameters to simulate time series with pre determined attributes values can be a challenging task culley et al 2019 guo et al 2017b 2018 to address this guo et al 2018 introduced an inverse approach that optimizes the weather generator parameters in order to generate hydrometeorological time series with desired attribute values this approach was further formalized and refined by culley et al 2019 despite these advances a formal approach to identifying the attributes in stage i is still missing for reasons likely to include some combination of a priori judgement analytical tractability ease of interpretation and capacity to generate combinations of perturbed attributes most studies consider changes in two attributes bussi et al 2016 culley et al 2016 singh et al 2014 turner et al 2014 weiβ 2011 wetterhall et al 2011 whateley et al 2014 the selected attributes usually correspond to changes in mean precipitation and mean temperature or in some cases changes to precipitation seasonality kay et al 2014 prudhomme et al 2013a prudhomme et al 2013b and shifts in peak flows borgomeo et al 2015b nazemi et al 2013 quinn et al 2018 however it is well known that water resources systems can be affected by a much wider range climate attributes e g averages seasonality intermittency variability extremes and low frequency autocorrelation which can change both individually and in combination for example groundwater storages are less affected by evaporation than reservoirs but also subject to lower frequency variations in climate e g multi year droughts while temperature can be critical for water storages driven by snowmelt culley et al 2016 eckhardt and ulbrich 2003 ray et al 2018 importantly even for the same system the climate attributes that have the biggest influence on its performance can vary depending on the performance metrics culley et al 2016 kasprzyk et al 2013 this highlights a need to rigorously test the assumptions of stage i with omissions of important attributes at this stage potentially leading to the misinterpretation of a system s climate sensitivity the inability to identify important system failure modes and or the incorrect assessment of the relative performance of different decision alternatives given that identification of key system sensitivities is a fundamental principle that underpins scenario neutral climate impact assessments brown and wilby 2012 nazemi and wheater 2014 a formal approach for selecting the most appropriate axes of scenario neutral spaces is warranted this is because all subsequent stages in scenario neutral assessments are conditioned on this stage making it impossible to identify key sensitivities in subsequent analyses if key climate attributes are not considered in the first place so while stochastic weather generators are opening up the opportunity to simulate a much larger set of climate attributes as part of stage iii borgomeo et al 2015b guo et al 2017b 2018 herman and giuliani 2018 quinn et al 2018 for this to be effective it must be accompanied by the appropriate selection of the attributes to be perturbed in the first place as part of stage i the overarching aim of this paper is to develop an approach for identifying the most important climate attributes so that scenario neutral climate impact assessments provide accurate information on system sensitivity and the conditions that could lead to system failure broderick et al 2019 bryant and lempert 2010 culley et al 2016 lempert et al 2008 prudhomme et al 2010 this will not only help improve the accuracy of system stress tests when applied to current system configurations but can also help support assessments on the climate conditions for which an alternative system configuration sometimes referred to as an option solution or decision is preferable to another brown et al 2012 brown and wilby 2012 giudici et al 2020 groves and lempert 2007 hadka et al 2015 herman et al 2015 kasprzyk et al 2013 lempert and collins 2007 as well as the relative or absolute robustness of alternative system configurations herman et al 2015 mcphail et al 2018 mcphail et al 2020 to this end the specific objectives of this paper are i to present a general approach for identifying which climate attributes to include in scenario neutral studies for a given system and performance objectives and ii to evaluate the benefits of using the most appropriate climate attributes in a scenario neutral impact assessment the approach is demonstrated and tested using the lake como system a regulated lake in northern italy two performance criteria are considered flood reliability and irrigation deficit to highlight the importance of tailoring the approach to the system under consideration including different system objectives kasprzyk et al 2013 details of the proposed approach can be found in section 2 with a description of the case study and implementation of the proposed approach in section 3 a description of further analysis designed to test how well the proposed approach performed is also presented in section 3 as well as a demonstration of a tipping point type impact assessment brown et al 2012 frey and patil 2002 guillaume et al 2016 haasnoot et al 2013 hyde et al 2005 raso et al 2019 ravalico et al 2010 using the critical climate attributes the results of implementing and testing the proposed approach are presented in section 4 along with a discussion of its advantages and limitations conclusions are presented in section 5 2 generic approach to identifying critical climate attributes 2 1 overview the key challenge when identifying the set of critical climate attributes is to balance the need to i include all of the climate attributes that could potentially have a significant impact on system performance to ensure the resulting impact assessment is as accurate as possible and does not miss any key modes of system failure and ii keep the number of attributes as small as possible to minimize the dimensionality of the scenario neutral space so as to make it feasible to generate climate perturbed time series with the requisite changes in all climate attributes simultaneously while ensuring that this can be done within a practical timeframe and making it easier to visualize the results of the scenario neutral analysis in order to address this challenge it is proposed to use input variable selection ivs algorithms for this purpose galelli and castelletti 2013 galelli et al 2014 li et al 2015a may et al 2008 sharma 2000 as they have been specifically designed to achieve this balance galelli et al 2014 however as we are dealing with future conditions the data required to apply ivs methods needs to be generated through the use of a system model that can represent the relationship between climate and system performance the desired outcome of applying the ivs approach as part of stage i as defined in the introduction is to ensure that the most important or critical attributes are selected while keeping the dimension of the scenario natural space relatively low to ensure subsequent analyses are tractable to minimize the risk of missing important attributes in the subsequent scenario neutral analysis the basis of the approach is to start with a much larger candidate set of attributes thereby creating a high dimensional space which needs to be reduced through ivs this creates a key distinction between the ivs analysis and the traditional scenario neutral stage the ivs analysis seeks to evaluate a very high dimensional but sparsely sampled scenario natural space representing the system performance to a large number of candidate attributes in order to identify those attributes that are most important for a given system i e the critical attributes the subsequent scenario neutral impact assessment provides a detailed evaluation of the system performance and or compares the system performance across multiple configurations based on plausible variations to the identified critical attributes this approach is analogous to that used in the development of lower fidelity surrogate meta models of higher fidelity simulation models razavi et al 2012 where higher fidelity models are used to generate a relatively small sample of inputs and outputs to enable the lower fidelity surrogate models to be calibrated in both cases a small sample of higher fidelity dimensional values is generated to enable a larger number of lower fidelity dimensional values to be generated for the sake of increased computational efficiency or tractability in the case of surrogate models the generated higher fidelity samples are used to calibrate the lower fidelity model which can be used instead of the more computationally expensive higher fidelity model to generate a larger sample of inputs and corresponding outputs as part of sensitivity of optimization studies broad et al 2015 maier et al 2014 here we use a relatively small number of samples from the higher dimensional scenario neutral space to identify the critical climate attributes which can then be used to generate a larger number of samples in a lower dimensional scenario neutral space that is suitable for climate impact assessment in a computationally efficient tractable manner the main steps of the proposed approach to identifying the critical attributes for scenario neutral climate impact assessments are fig 1 1 the generation of a sparsely sampled high dimensional scenario neutral space by 1 1 selecting the candidate attributes to be considered ensuring that all attributes that could potentially have an impact on system performance are included 1 2 sampling the space of candidate attributes providing a sparse yet adequate coverage of the candidate attribute space to achieve reliable input variable selection results 1 3 generating the hydrometeorological time series exhibiting sampled attribute values 1 4 assessing system performance based on the generated hydrometeorological time series 2 the selection of critical climate attributes by 2 1 determining the relative importance of candidate attributes ensuring that both the importance of each attribute and dependence with other attributes are taken into account 2 2 selecting the set of critical attributes ensuring an adequate trade off between the inclusion of all climate attributes that have a significant impact on system performance and minimizing the dimensionality of the scenario neutral space further details of each of these steps are given in the following sub sections 2 2 step 1 generation of sparsely sampled high dimensional scenario neutral space 2 2 1 select set of candidate attributes step 1 1 a key objective of the proposed approach is to ensure that scenario neutral methods can identify all critical system sensitivities and modes of system failure as a result it is important to ensure that a wide range of potentially relevant climate attributes is identified a priori from which the attributes that best describe system performance can be determined this set is referred to as the candidate attributes a a 1 a n and the resulting space of potential values of these attributes is referred to as the attribute space a r n where n is the number of candidate attributes any prior studies and expert knowledge about the system should be considered to select the candidate attributes including consultation with relevant stakeholders where appropriate given the complexity of the response to projected climatic changes for most water resource systems and the need for the candidate set to encompass all plausible drivers of change to system performance the candidate attribute set is likely to be quite large potentially including statistics such as the average extremes seasonality intermittency variability and inter annual persistence of multiple hydrometeorological variables such as precipitation temperature and potential evapotranspiration this increases the dimensionality of the scenario neutral space making it more difficult and computationally expensive to generate the requisite hydrometeorological time series step 1 3 fig 1 consequently careful consideration should be given to the candidate attribute selection phase to exclude any candidate attributes that are known to not influence system performance it should be noted that as system performance is determined using a system model step 1 4 the candidate attributes that can be considered are limited to those that can be used as inputs to these models 2 2 2 select combined changes in candidate attributes step 1 2 as mentioned previously in order to explore system performance across the entire candidate attribute space in a computationally efficient manner a sparse sample of values from this space a 1 i a n i should be generated where i 1 s and s is the number of samples generated for the n attributes this set of generated samples is referred to as the set of attribute targets as the aim of the next step step 1 3 is to generate hydrometeorological time series that have these attribute values fig 1 as the number of attributes that could have an impact on system performance and hence the space to be explored is potentially quite large e g n 10 for many practical situations it is necessary to implement a sampling strategy that efficiently covers the attribute space methods like latin hypercube sampling and improved distributed hypercube sampling have proved to be useful for this purpose beachkofski and grandhi 2002 stein 1987 selection of the bounds on the candidate attributes subjected to sampling also requires careful consideration to maximize the likelihood that the system performance variations are captured for all plausible climate futures it is important that the bounds cover the full range of changes that might be expected however as wider bounds increase the size of the attribute space to be sampled and as the relative impact of a particular climate attribute on system performance can be a function of the selected range care needs to be taken to ensure the selected range does not extend beyond the changes that might plausibly occur one potential method for achieving this is to extend the bounds just beyond those projected by relevant climate models and or other available lines of evidence to allow for uncertainty in these models brown and wilby 2012 as mentioned previously a balance needs to be struck between having sufficient samples to adequately capture the relationship between changes to candidate attributes and corresponding system performance while keeping the number of samples as small as possible as the size of the attribute space i e number of attributes and their bounds and the nature of the relationship between changes in candidate attributes and system performance are likely to be case study dependent so is the number of samples required however based on studies in ivs for data driven models and the development of surrogate meta models a sample size s of around 10 000 is likely to provide reasonable results for an example case where approximately n 10 candidate attributes are selected broad et al 2005 broad et al 2010 li et al 2015b may et al 2008 2 2 3 generate hydrometeorological time series step 1 3 as mentioned previously given the high dimensionality of the candidate attribute space e g n 10 it is difficult to generate the hydrometeorological time series that simultaneously exhibit the various combined target attributes determined in step 1 2 currently the only systematic approach that is capable of generating the requisite time series is the inverse approach of guo et al 2018 as part of this approach the hydrometeorological time series that match the targets of the desired future climate attributes are generated with the aid of a weather generator resulting in a set of modelled targets of the desired climate attributes â 1 i â n i in order to ensure the modelled attributes â 1 i â n i are as similar as possible to the targets a 1 i a n i an appropriate optimization algorithm such as an evolutionary algorithm guo et al 2018 maier et al 2014 maier et al 2019 is used to identify the set of parameters of the stochastic weather generator θ that minimizes an objective function that measures the difference between the modelled a 1 i a n i and target â 1 i â n i values an example of such an objective function is the root mean squared error the ability to meet the targets depends on both the weather generator and the set of candidate attributes used in relation to the former many models for generating stochastic hydrometeorological time series are available each with different underpinning assumptions and model structures richardson 1981 richardson and wright 1984 simpler models may not have the degrees of freedom required to change the relevant attributes of a time series independently e g winter precipitation and summer precipitation when using a weather generator that does not simulate seasonal variability given the need to include a wide selection of attributes in the candidate set it is recommended to use a more complex weather generator with the required degrees of freedom in its parameters and structure with regard to the latter it is possible that attributes will be included in the candidate set that will co vary with other attributes due to the structure of the weather generator used resulting in an inability to meet samples formed by perturbing attributes independently more information on challenges and possible solutions related to using the inverse approach to achieve specified target attributes is provided in culley et al 2019 2 2 4 assess system performance step 1 4 the model used to calculate system performance under plausible future climate conditions can comprise a single model or a coupled set of models that take the generated hydrometeorological time series as inputs and simulates the resulting system performance as the output this enables an assessment of how system performance changes under a range of plausible climate futures it should be noted that the time step of the weather generator step 1 3 must match that of the system model so that system performance can be simulated for each climate time series the system model should be able to simulate the key processes of the investigated system so that the strength of the simulated relationship between attributes and system performance is representative of the real system this is a challenge that affects all scenario neutral impact assessments and it has recently been demonstrated that the choice of system model can lead to different conclusions about system sensitivity broderick et al 2019 guo et al 2017a a further challenge affecting all scenario neutral assessments is that models may be required to simulate system behavior outside the bounds of historical variability assessing system model performance under changed or non stationary climate regimes is an active research endeavor with possible approaches including differential split sample testing and optimizing model performance for different climate conditions fowler et al 2016 klemes 1986 westra et al 2014 2 3 step 2 selection of critical climate attributes 2 3 1 determine relative significance of candidate attributes step 2 1 using the data on the relationship between the candidate attributes and corresponding system performance obtained in step 1 the relative significance of each candidate attribute can be calculated as a key aim of step 2 is to select the smallest set of m critical attributes from the set of n candidate attributes the dependence between variations in system performance as a function of different candidate attributes has to be taken into account in addition to the significance of the relationship between each candidate attribute and corresponding system performance methods that can be used to account for variable dependence can be divided into two main groups dimensionality reduction and filtering friedman et al 2001 may et al 2011 dimensionality reduction techniques can be split into those that identify combinations of attributes that provide independent information by rotating data vectors such as principal component analysis and those that cluster attributes into groups that provide similar information and then selecting a representative attribute from each cluster bowden et al 2005 a range of clustering methods can be used for this purpose such as nearest neighbor methods regression trees and self organizing maps and representative values can be selected from clusters based on criteria such as the euclidean distance from the cluster center the most prominent example of filtering methods is stepwise partial selection as part of which the attribute that has the strongest influence on system performance is ranked first i e forwards stepwise selection followed by the attribute that has the next biggest additional impact and so on sharma 2000 this is achieved by calculating a measure of influence between each attribute and system performance with the attribute that results in the greatest variation in system performance ranked first next a model is developed using the first ranked attribute as an input and system performance as an output which can be done using regression based methods or other data driven methods such as artificial neural networks li et al 2015a sharma 2000 the attribute that is ranked second is the one with the strongest relationship with the residuals of this model this continues for all remaining attributes this enables a ranked list of attributes to be obtained as well as a measure of the influence each attribute has on system performance additional to the influence of the higher ranked attributes some of the most commonly used filtering methods in the ivs literature include partial correlation partial mutual information the iterative input variable selection iis algorithm and the gamma test galelli et al 2014 may et al 2008 a range of measures of influence significance can be used in combination with the above approaches that account for input dependence these measures can be based on correlation variance mutual information or sensitivity may et al 2008 when combined with clustering these measures are applied to the attributes that are representative of each cluster enabling these to be ranked in contrast when used as part of filtering approaches these measures are interspersed in the process used to account for dependence as discussed above the most appropriate approach for determining the relative significance of attributes for a particular application is a function of user preference and the attributes of the data e g degree of non linearity type of distribution problem dimensionality and sampling approach galelli et al 2014 however irrespective of which approach is used the key is that both dependence and significance have to be considered so that the smallest number of climate attributes that have a significant impact on system performance can be identified this ensures that the dimensionality of the scenario neutral space is reduced as much as possible while still capturing all critical modes of system performance variation 2 3 2 select critical attributes step 2 2 the set of critical climate attributes m can be selected from the candidate attribute set n by applying an appropriate selection criterion to the ranked candidate attributes obtained in the previous step step 2 1 the objectives of this step is to determine the trade off between maximizing the information on system sensitivity while minimizing the dimensionality of the scenario neutral space as discussed in section 1 this can take the form of a visual inspection of a plot of the change in the selected measure of influence with the inclusion of additional attributes the use of significance tests e g when correlation is used as the measure of influence or the use of metrics that are similar to those balancing model performance with model parsimony such as akaike s or bayes information criteria fernando et al 2009 which approach is considered most appropriate depends on a range of case specific factors such as problem dimensionality degree of dependence between attributes computational overhead associated with the system model and so forth 3 case study implementation and testing of proposed approach a case study of a regulated reservoir is used to demonstrate and test the approach outlined in section 2 the critical climate attributes are identified for two competing system objectives flood mitigation and irrigation supply to determine whether different critical attributes are identified for each section 3 1 describes the case study models and data and section 3 2 describes the specific implementation of the steps described in section 2 section 3 3 1 presents further analysis used to assess how well the approach selects critical attributes finally to demonstrate the utility of the proposed approach section 3 3 2 presents a comparison between the scenario neutral spaces generated by considering the critical attributes with those generated by considering mean precipitation and temperature as the axes of the scenario neutral space which is the approach most commonly used in the literature 3 1 case study models and data the lake como case study is located in the alpine region of northern italy anghileri et al 2013 culley et al 2016 the maximum storage volume in the lake is 254 mm3 and the lake provides water for one of the largest irrigation systems in europe the regulation of lake como is driven by two primary objectives mitigating flooding and supplying irrigation needs with an additional minimum environmental flow release constraint each day to ensure adequate conditions in the downstream adda river this study considers a simplified representation of the lake como system to illustrate the proposed approach the lake como system was selected as a large snowmelt component to annual inflows means it is likely influenced by more complex attributes than annual means and two competing objectives in the system model allows for a comparison of how the identified critical climate attributes can differ even for the same system the lake como catchment is modelled by a lumped hbv model bergström and singh 1995 the hydrometeorological inputs to the model are daily precipitation and temperature time series evaporation is calculated internally using hamon potential evapotranspiration and is dependent on temperature hamon 1960 as is the snowpack component that stores rainfall in the catchment as snow until a melting temperature is reached giuliani and herman 2014 the historical data include records of daily temperature precipitation and streamflow into the lake across the baseline period from 1965 to 1980 and are used to calibrate the hydrological model anghileri et al 2011 catchment average precipitation data are used derived from five gauges across the catchment while the daily temperature data are from one site the reservoir system is modelled with a mass balance equation at a daily time step in which there is a controlled release each day the reservoir releases vary based on the time of year and height of the reservoir in order to represent typical historical operational decisions over the baseline period the releases are simulated using a radial basis function fitted to historical operating characteristics culley et al 2016 giuliani et al 2015 giuliani et al 2014 as the actual reservoir operation rule curves were not known as this radial basis function is dependent on reservoir height it allows for some adaptation to climate variability both in and across different climate time series the annual demand pattern is held constant throughout all climate time series this does not reflect expected changes to demand as a result of changing climate regimes but this does not diminish the illustrative value of the case study in this application the system model is configured to simulate two performance criteria calculated as annual average values flood reliability and irrigation deficit the flood reliability criterion is calculated as the fraction of days the reservoir height is below the flood threshold 1 24 m above minimum storage level for the irrigation deficit criterion each daily release is compared to the irrigation demand for that day if demand is met the deficit is zero otherwise the volume of the daily deficit is recorded in kl the total annual deficit is then averaged over the number of years of simulation the twenty climate projections used in this analysis are from the eurocordex project where projections were created for europe at a 50 km resolution eur 44 and a 12 5 km resolution eur 11 both of which are used in this study conevski 2014 the projections were bias corrected using quantile mapping boé et al 2007 déqué 2007 climate projections for the period of 2040 2060 were used in this study to determine the bounds of the attribute space sections 3 2 1 3 2 implementation of proposed approach this section describes the implementation of the approach presented in section 2 sections 3 2 1 and 3 2 2 detail each of the two steps in the approach i e section 2 2 and 2 3 respectively 3 2 1 generation of a sparsely sampled high dimensional scenario neutral space the realizations of potential future climate attributes are obtained by sparsely sampling from a pre determined set of candidate attributes this set of candidate attributes is restricted to the hydrometeorological variables temperature and precipitation as these are the inputs to the system model for the case study in selecting statistics of these two variables our aim was to include a wide range of attributes including those previously unexplored in scenario neutral impact assessments the etccdi list of extreme climate indices etccdi 2013 served as a starting point for this providing attributes like the wet spell duration wsd 99th percentile of daily rainfall p99 and the number of frost days f0 several non extreme attributes were also included such as annual rainfall and average temperature which are known to be important drivers in water resource systems in practice this process can also include discussions with stakeholders and incorporation of any existing expert knowledge the full list of the fifteen candidate attributes n 15 considered for the lake como case study a a 1 a 15 is shown in table 1 candidate attribute values were then calculated from the selected climate projection time series in order to determine the bounds of the attribute space each of the candidate attribute values was averaged over the period 2040 2060 and bounds were chosen to extend slightly beyond these values table 2 precipitation attributes are described by fractional changes from historical values and temperature attributes are described by additive changes compared to the instrumental baseline of 1965 1980 it should be noted that this method of calculating the bounds does not take into account any biases in the downscaled climate projections compared to the observed record for example only decreases in wet spell durations are considered which may be due to all projections having less persistence in rainfall an alternative approach would be to compare fractional or absolute changes relative to the modelled baseline which would reduce the implications of biases since both the modelled baseline and future projections would be subject the same biases but then the changes would no longer be indicated relative to the historical instrumental record finally we have extended the attribute bounds beyond the largest projected change without removing any outliers giving large increases in temperature as bounds despite this only being projected by one 8 5 rcp model a latin hypercube sampling lhs method was chosen to sample the candidate attribute space to generate the scenario neutral space a 1 i a 15 i fifteen thousand samples were taken from within the bounds to provide reasonable coverage of the scenario neutral space while considering the high computational cost of optimizing each climate time series climate time series of precipitation and temperature were then generated using the inverse approach for the fifteen thousand sampled targets of attributes the inverse approach was implemented using the r package foresight bennett et al 2018 and required approximately 20 000 cpu hours to generate the samples the weather generators used are based on the wgen model from richardson 1981 the rainfall generation requires 12 parameters the mean amplitude and phase angle of a single harmonic for each of pwd pdd used in a 1st order markov chain α and β used in a gamma distribution to sample rainfall amount the temperature generation requires 10 parameters the mean amplitude and phase angle for a single harmonic of mean daily temperature one harmonic each for the wet and dry day standard deviation and a lag 1 coefficient of the residuals each climate time series had a length of 21 years which was selected to match the climate projection window of 2040 2060 the genetic algorithm used in foresight was used with default operators scrucca 2013 and 300 generations a single weather generator replicate was used for each target and the actual attributes that were generated â 1 i â 15 i were recorded the time series were then used as an input to the hydrological model to simulate daily flow the lake como reservoir model then used these daily flow time series to calculate the two performance criteria in response to each time series 3 2 2 selection of critical climate attributes the partial mutual information algorithm pmi algorithm input variable selection was implemented to rank the set of candidate attributes section 2 3 1 li et al 2015a sharma 2000 using the modelled values of the climate attributes â 1 i â 15 i which are different from the targets because the optimization does not find parameterizations with a perfect mapping this approach was selected because of non linearity in the system performance metrics and the need to consider co variance between climates attributes the pmi algorithm ranks candidate attributes in order of significance based on the mutual information between each of the n candidate attributes and system performance after removing the effect of higher ranked i e more important attributes the mutual information mi between two variables is a measure of how much information about one variable is gained by an observation of the other for a set of targets s the mi between each attribute a ˆ k and the measure of system performance p can be approximated by the following equation 1 i a ˆ k p 1 s i 1 s log f a ˆ k i p i f a ˆ k i f p i where k indexes the n candidate attributes i e k 1 n and f are the marginal or joint probability density functions of the attributes and system performance which are typically estimated using kernel density estimators galelli et al 2014 li et al 2015b the mi is non negative and unbounded unlike other dependence metrics e g pearson correlation spearman rank it should be noted that as the generated hydrometeorological time series are used to assess system performance via the system model fig 1 the modelled values of the climate attributes â 1 i â n i have to be used as part of the analysis to determine the m critical attributes with the aid of the pmi algorithm rather than a 1 i a n i as part of the pmi algorithm the climate attribute with the highest mi value is selected first in order to identify the climate attribute that has the next highest additional impact on system performance the influence of the selected attribute needs to be removed this is achieved by developing non linear regression relationships between the already selected attribute and both the remaining attributes and system performance the mi can then be calculated between the residuals of these models which is referred to as the pmi the required non linear regression models can be developed using kernel based methods such as general regression neural networks specht 1991 or kernel free methods such as multi layer perceptron artificial neural networks mlpanns wu et al 2014 while kernel based methods are generally more computationally efficient mlps have been found to perform better if the data are highly non gaussian li et al 2015b the iterative process outlined above is repeated until all candidate attributes have been ranked the algorithm was implemented for the two performance criteria using the software developed by li et al 2015b a conventional gaussian kernel was used with the gaussian reference bandwidth may et al 2008 to estimate the probability density functions for the partial mutual information calculation a multi layer perceptron artificial neural network mlpann model was used as the non linear regression technique to remove the influence of each selected attribute this model is limited to one hidden layer with a maximum of four nodes to avoid over fitting li et al 2015b both of these methods are recommended for use with highly non linear data sets the rankings of the candidate attributes alone are not indicative of how many should be selected to create a scenario neutral space further information is needed to select the m critical attributes from the ranked n candidate attributes input variable selection methods have established stopping criteria may et al 2011 but in this application significant emphasis is placed on selecting a small number of attributes given how challenging the visualization of system performance becomes in higher dimensions this can be achieved with the aid of the cumulative variance explained cve in system performance which is calculated for each selected attribute by 2 c v e j 1 s s e r r j s s p where s s p i 1 s p i p 2 is the total sum of squares of the system performance p for the first selected attribute j 1 the sum of squares of the residuals of the non linear regression between the first attribute and system performance is given by s s e r r j i 1 s p i p ˆ i 2 such that the cve metric equates to an r2 calculation for each additional attribute s s e r r j i 1 s p g r j i p ˆ g r j i 2 is the sum of squares of the residuals of the non linear regression between the jth attribute and system performance both of which have been updated by removing the effect of the set of j 1 previously selected attributes where g r j is the effect of the previous selected attributes r j a 1 a j 1 this is similar to an analysis of variance metric anova except that as opposed to being calculated for each attribute based on the initial sample it is calculated iteratively after each non linear regression transformation of the original sample this non linear regression is therefore a requirement of the partial approach used the relative gain in this metric with each additional attribute can be used to decide how many attributes are critical for the system under consideration as defined by the system performance metric p this is achieved by visual inspection of the plot of cumulative variance explained and number of attributes ranked in order of significance by the pmi algorithm and exclusion of the attributes after which the cve plateaus leaving the m critical attributes it should be noted that the absolute cumulative variance explained values at which the plateau occurs can provide an indication of whether all critical attributes have been included in the candidate set if a significant portion of variance in the performance is still unexplained this provides an indication that there are aspects of the climate time series investigated that are changing in a way that affects system performance but are not being measured by the candidate attributes 3 3 methods to evaluate the utility of the proposed approach 3 3 1 selection of correct critical attributes to evaluate the success of the approach to attribute selection a test was developed that investigates i how well the pmi algorithm performs in terms of ranking the candidate attributes in order of decreasing impact and ii how well the cumulative variance explained metric can be used to select critical attributes the residuals obtained after removing the effect of each additional attribute section 2 3 1 were inspected visually along with the relationship obtained from the corresponding mlpann model a decrease in the strength of the signal in the residuals as each attribute is removed indicates that the attributes are being ranked correctly such plots should be inspected for all critical attributes plus the next most significant attribute if the residuals for the next most significant attribute have no or negligible signal then this provides an indication that there is no more information left to describe and hence the correct number of critical attributes has been selected 3 3 2 scenario neutral climate impact assessments as mentioned at the beginning of section 3 to demonstrate the utility of the proposed approach two scenario neutral impact assessments are presented one with scenario neutral spaces constructed using the critical attributes identified using the proposed approach and the other with a scenario neutral space constructed using just mean precipitation and temperature as the axes of the scenario neutral space as part of the assessments the scenario neutral spaces were divided into regions of success and failure and the climate projections for the lake como region which correspond to changes in each attribute in the year 2050 were overlaid the proportions of climate projections that indicate unsuccessful performance for the two different scenario neutral impact assessments were then compared the performance thresholds were selected by considering system performance under current conditions and adding a small buffer these thresholds are used for illustrative purposes and assume that the system is currently operating successfully and there is some margin or buffer built into the system design this led to an irrigation deficit criterion of 4224 kl and a flood reliability criterion of 95 the stochastic time series for the more detailed scenario neutral analyses were created using the technique outlined in section 2 2 3 for the space using only mean precipitation and temperature target changes were set using a high resolution sample between the bounds in table 2 for the critical attribute spaces the first two dimensions were sampled in high resolution between the bounds indicated in table 2 and the third and fourth dimensions were explored using larger step changes three or four intervals depending on the width of the bounds to allow the space to be visualized in a lattice plot the r package foresight was used to stochastically generate 21 years of daily precipitation and temperature data with five weather generator replicates used for each target the system performance metrics were then calculated in response to these time series using the system model and the average performance across the five replicates is shown for each target 4 results and discussion section 4 1 presents the results for the approach detailed in section 2 this includes the pmi calculations as well as an analysis of how many critical attributes should be selected to capture system vulnerabilities for the different performance criteria section 4 2 1 presents the results of the additional analysis conducted to test how well the approach performs and section 4 2 2 presents the results of the tipping point type analysis detailed in section 3 3 2 4 1 selection of critical attributes fig 2 shows the cumulative variance explained cve metric calculated for each of the candidate attributes and for each of the two performance criteria while details of the critical and next most significant attributes are given in table 3 as can be seen from fig 2 the cve plateaus after four attributes for the flood reliability criterion the most critical attribute for the flood reliability criterion is f0 table 3 which makes sense from a physical perspective as this attribute describes the number of days on which temperatures are above and below zero degrees and thus provides an indicator of the snow storage in the year historically the largest inflows into the reservoir are in spring as the snow storage is released decreasing the number of frost days in the year means warming occurs earlier changing the timing of the snowmelt this causes more flooding events given the reservoir operation was designed for historical conditions ptot is the next most significant attribute which also makes physical sense as annual rainfall largely dictates the amount of water in the reservoir the next critical attribute is pson which when the total annual rainfall is held constant controls the seasonality in the shoulder seasons finally tdec is selected which when the number of frost days is held constant shifts the lowest temperatures into january and february and does not result in as much storage of snow in december as the reservoir does not release water during december this can cause the runoff from any high rainfall events to cause flooding where previously this runoff would have been stored as snow the addition of the next most significant attribute tmar increased the cve value by only 0 001 table 3 and so this is not considered critical for the irrigation deficit criterion four attributes are also selected as critical with a distinct gradient change in the cve value after the fourth attribute although the cve continues to increase gradually until eight attributes are selected the relative information increase caused by these four additional variables is marginal especially when traded off against the additional difficulty of producing an eight dimensional scenario neutral space as can be seen from table 3 the most significant attribute for the average height criterion is ptot which is to be expected as the irrigation deficit is primarily a function of the total amount of water in the system which is mainly affected by total annual rainfall the attribute having the second most significant impact on the average height criterion is f0 frost days which affects the snowmelt in the year as discussed above this is a large source of annual inflow for the lake como reservoir that occurs as it becomes warmer which is also when the irrigation demand increases the next two critical attributes are tjun and pjja which both control the climate when the irrigation demand is highest and affect the rainfall available and evaporation losses in that period respectively the next most significant attribute tdec impacts the timing of the snowmelt releases by shifting the days with lowest temperature however the increase in cve by including this attribute is only 0 019 compared to the 0 058 increase when selecting the fourth attribute and so it would not be worth the exponential increase in computational cost to include this fifth attribute in a scenario neutral space table 3 the cve values in fig 2 and table 3 indicate that the total amount of variance explained by the critical attributes varies for the two performance criteria overall the irrigation deficit criterion reaches 83 variance explained compared to 65 for the flood reliability criterion this suggests in both cases that there are aspects of the time series that are changing system performance yet are not accounted for in the candidate attributes and that this is more of an issue for the flood reliability criterion comparing the two performance criteria the number of flooding events is subject to greater variability in the time series than the total irrigation deficit in the year which is why it has a lower cve value a possible explanation of this result is therefore that as system criteria become more affected by variability there is a limit to the amount of system performance that can be predicted by a candidate set of attributes that mainly consists of annual and seasonal means in a real life setting this might necessitate the inclusion of a larger candidate set to ensure that all modes of system performance variability are accounted for in the scenario neutral climate impact assessment although this decision is somewhat subjective the choice to include more attributes in a candidate set to better account for system performance also needs to be balanced by the usefulness of attributes as predictors for system performance for example including the standard deviation in annual total rainfall over the simulation or monthly temperature ranges as attributes may explain some variance in performance but is likely to make it difficult to design tipping points or operational changes in response to observed changes in these attributes however the fact that even a broad set of 15 candidate attributes was not able to describe all of the variance in system performance highlights that the attributes considered in the vast majority of scenario neutral studies i e average rainfall and average temperature are unlikely to identify all the relevant modes of system failure in the type of system analyzed a comparison of the rankings of the critical attributes obtained for the different performance criteria provides a useful means of highlighting the utility and importance of using the pmi algorithm combined with the cve metric for identifying the climate attributes to which system performance is most sensitive the results of the pmi analysis clearly demonstrate that different climate attributes are critical for different performance criteria reinforcing the fundamental premise underpinning scenario neutral climate impact assessments that the axes of the scenario neutral space need to be tailored to specific systems and performance measures 4 2 evaluating the utility of the proposed approach 4 2 1 testing for correct critical attributes the results of the test designed to evaluate the utility of the proposed approach are shown in fig 3 for both the irrigation deficit and flood reliability criteria the strength of the relationship in the residuals reduces with the addition of less significant attributes at the fifth attribute the residuals are close to noise although there is still a slight relationship for the irrigation deficit criterion which confirms the findings in fig 2 this suggests that the pmi algorithm combined with the cve metric were able to successfully select the critical attributes from the fifteen candidate attributes fig 3 also demonstrates that a major difference between the two performance criteria across the 15 000 samples is that the flood reliability criterion is highly non linear whereas the irrigation deficit criterion is less so noting that both performance criteria are scaled this is due to the proximity of the former to the upper bound of 1 caused by a number of time series that only have 0 2 flood events throughout the year in contrast there is irrigation deficit in every time series and it varies much more linearly with the first selected attribute this shows how the pmi algorithm performs well with both linear and highly non linear relationships between attributes and system performance 4 2 2 comparing scenario neutral climate impact assessments for the irrigation deficit criterion there is a significant difference in the results obtained using default attributes of mean annual precipitation and temperature compared to using the critical attributes identified using the proposed approach fig 4 using the scenario neutral space of mean annual precipitation and temperature eight of the twenty climate projections suggest that the irrigation deficit will be unacceptable due to decreases in ptot and increases in tavg fig 4a in contrast when considering the scenario neutral space formed by the critical attributes only three projections suggest failure of the system projections 3 5 and 6 this difference is due to the fact that the scenario neutral space formed by the critical attributes captures a more detailed range of system performance for example the majority of climate projections indicate a decrease in summer rainfall amounts which decreases the performance of the irrigation objective given a fixed annual total however this seasonal information is not obtained when only changes in ptot and tavg are considered these results clearly show the utility of the proposed approach as adoption of the commonly used ptot and tavg scenario neutral space significantly overestimates future system failure in accordance with the irrigation deficit criterion in addition to over estimating the risk of future failure consideration of the ptot and tavg scenario neutral space could result in the adoption of ineffective adaptation strategies for example when only considering future changes in ptot and tavg adaptation strategies designed to avoid system failure would be targeted at better responses to these drivers in contrast by gaining a deeper understanding of the key modes of system failure identified with the aid of the proposed approach adaptive strategies responding to severe decreases in summer rainfall and high increases in average june temperature can be developed as illustrated by fig 5 the comparison between the ptot and tavg space and the critical climate attribute space for the flood reliability criterion also shows a difference between the number of failures obtained although this difference is not as marked as that observed for the irrigation deficit criterion in the ptot and tavg space no projections indicate a large enough decrease in flood reliability to cause unacceptable performance as this would require an increase in annual rainfall without an increase in average temperature in the critical attribute space only one projection predicts unacceptable performance projection 1 which was the projection that was the closest to unacceptable performance in the ptot and tavg space this shows that there can also be a risk of under estimating failure when not using the critical climate attributes finally as was the case for the irrigation deficit criterion adoption of the proposed approach was able to identify critical modes of system failure for example for the flood reliability criterion application of the proposed approach was able to identify that high december temperatures can cause unacceptable levels of performance which would not be detected if only ptot and tavg were considered identifying this information about system vulnerabilities is a key purpose of scenario neutral impact assessments these results indicate that these vulnerabilities can change with different system performance criteria and that these changes can only be identified by considering the climate attributes to which system performance is most sensitive 5 summary and conclusions this study presents a novel approach for selecting critical climate attributes for use in timeseries driven scenario neutral impact assessments this is necessary given that when large numbers of climate attributes are used to form high dimensional scenario neutral spaces it is extremely difficult to generate the time series that perturb each attribute in the required way this is likely to be one of the primary reasons why most scenario neutral studies that use hydrometeorological time series consider too few dimensions often defaulting to examining mean precipitation and temperature however this may mean that for many systems some important climatic changes are not considered and critical modes of failure can be missed this study therefore describes a formal approach to the identification of the attributes that contain most of the information about system performance while keeping the number of critical attributes as small as possible for computational and analytical tractability the approach identifies the critical attributes by firstly generating a sparse sample of attribute changes across a much larger candidate set of attributes then converting these changes into weather time series for input into a system model and then using the system model to convert the time series into system performance metrics an ivs algorithm is then used to rank the candidate attributes in order of significance as well as the added information content that each attribute brings to the analysis conditional on those already selected the critical attributes are identified once additional attributes no longer add information content such that as much of the system performance can be captured in as few dimensions as possible the approach was demonstrated on the lake como reservoir system using two modelled performance criteria irrigation deficit and flood reliability the approach identifies the critical attributes for each performance criterion thereby enabling the high resolution sampling of the critical climate scenario neutral space for use in subsequent applications such as scenario discovery and decision scaling this study found that one of the most commonly selected attributes in scenario neutral studies annual average precipitation was the most important attribute for only one objective irrigation deficit however three additional attributes the number of frost days summer rainfall and average june temperature were also needed to represent the irrigation deficit criterion the flood reliability criterion which was most sensitive to the number of frost days in the year also required four attributes to describe most of the variance in system performance this demonstrates the difficulty of knowing a priori which attributes are likely to be most important for a given system and thus the need for a structured analysis for identifying the critical attributes for each system and performance criterion importantly the approach produces significantly different outcomes when a scenario neutral space uses the selected critical climate attributes compared to the common defaults of annual average precipitation and temperature results indicate that the choice of attributes significantly influences the conditions for which acceptable and unacceptable levels of system performance changes occurs further the specific finding of system sensitivities to decreases in summer rainfall and increases in june temperature in addition to changes in annual means provides insights into system dynamics and potential vulnerabilities this highlights that using critical climate attributes can enable more detailed planning in response to identified system vulnerabilities which is the main purpose of scenario neutral impact assessments declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the case study data used in this study are from agenzia regionale per la protezione dell ambiente http ita arpalombardia it ita inde and consorzio dell adda http www addaconsorzio it the authors would like to thank arpa and eng bertoli from consorzio dell adda for its provision the authors would also like to thank m giuliani and a castelletti for their contribution to this research as well as robert wilby and two anonymous reviewers for their comments which improved the manuscript details of the climate time series data produced using the foresight package https cran r project org web packages foresight index html and case study performance data used in the results can be made available upon request sam culley was supported by an australian postgraduate award 
25892,vrana et al 2012a presented the maximum agreement mean maxagm method which aggregates expert opinions while focusing on points of agreement although maxagm can minimize shannon entropy to optimize results it has a high level of computational and conceptual complexity yields difficult to interpret results has no indicator of accuracy and requires specialized software that is not widely available in this paper we present the best compromise mean become method as a modified maxagm method become preserves the advantages of maxagm but overcomes its limitations to enable direct comparison we applied the become method to the same flood prevention case study that was used to validate the original maxagm method become is a universal method as it can be applied to evaluate environmental and educational measures about pandemics industries and resource issues here we demonstrate the applicability of become in real life covid 19 case study decisions which needed to be rapidly and efficiently made by the czech government keywords agreement averaging operator environmental decision making multi expert decisions best compromise result covid 19 1 introduction environmental decision making problems are usually complex ill structured multi dimensional multi aspect vague and uncertain theoretical models cannot as a rule adequately describe real events or processes therefore it is often appropriate to rely on the intuition and judgment of multiple experts based on their personal experience and intuitive understanding of the problem common averaging operators like arithmetic mean weighted mean or median can be used to aggregate or average multiple recommendations when experts opinions are quantitative coherent and non conflicting unfortunately experts opinions are seldom in harmony and may be quite different from each other in such cases common averaging operators can give incorrect results and may not adequately represent all experts combined opinion statistical methods often fail too because of a lack of relevant data such as probability distributions of variables in formal models it is vital in such situations to have an averaging operator which represents a compromise of all individual opinions during the last three decades fuzzy set theory in environmental decision making has increasingly been applied to manipulate pure judgments and the vagueness of experts opinions see e g nasiri and huang 2008 barreto neto and filho 2008 paterson et al 2008 li et al 2009 and pelikán et al 2017a b the need to resolve conflicts and find compromises in individual expert judgments has also been reported e g in kangas and leskinen 2005 tastle and wierman 2007a nasiri and huang 2008 paterson et al 2008 barreto neto and filho 2008 and ritzema et al 2010 however in these types of decision making problem apparent disparity disagreement in expert opinion is not necessarily spurious it may be a really important part of any decision particularly as often needs to be done in a risk based way averaging and aggregation methods which obscure the full breadth of expert opinion may also lead to less informed decisions i e a loss of information and this should be highlighted there is a fundamental difference in averaging and combining in a robust way depending upon the application in water management researchers have considered the poor structure and fuzziness of the decision making process and utilized fuzzy experts opinions with a consensus seeking approach e g vrana et al 2012a vrana et al 2012b and kovář et al 2018 barreto neto and filho 2008 for example introduced a fuzzy rule based model to estimate the runoff in a tropical watershed by evaluating the runoff derived from fuzzy and boolean methods li et al 2009 developed a multistage fuzzy stochastic programming mfsp model for tackling uncertainties presented as fuzzy sets and probability distributions relatively few researchers in environmental decision making have considered the expert consensus refsgaard et al 2007 presented a framework and guidance for addressing uncertainty in environmental modeling processes voinov 2010 presented the concept of experts as stakeholders and focused on the different types of stakeholder modeling and compared participatory modeling to other frameworks that involve stakeholder participation several papers were dedicated to the topic of expert group decision making for solving environmental tasks in a thematic issue on expert opinion in environmental modelling and management in environmental modelling and software 2012 vol 36 papers from krueger et al 2012a 2012b oliver et al 2012 page et al 2012 and vrana et al 2012a are particularly relevant to the discussion of averaging and evaluating a range of elicited expert opinions it is also stated in the mentioned papers that experts must consider many aspects which often include conflicting evidence and interpretation and may be conflicting as seen in bardossy 1993 donga 2009 tsabadze 2006 and zhang 2009 to reach a reliable conclusion it may not be enough to simply aggregate experts opinions using common aggregation operators see vaníček et al 2009 evaluating the level of mutual agreement is also very important and useful information taking maximum of agreement as a criterion of optimality vrana et al 2012a presented a maximum agreement mean maxagm method for aggregating experts opinions based on shannon entropy which seeks to maximize their agreement however due to a numerical approximation disadvantage of the maxagm method is its high computational and conceptual complexity problems with physically interpreting the results a lack of accuracy indicators and a need for specialized software which is not commonly available that was why as a modification of the maxagm method we developed and presented a best compromise mean become method in this paper which preserves advantages of the maxagm method whilst removing the above mentioned limitations in the other words the maxagm method creates a theoretical framework for the become method besides maxagm several researches published also other methods for consensus in a group decision making below we outline aggregating expert opinions other than maxagm however they usually suffer from an excessive complexity and problems with interpretation luo and jennings 2007 explored the space of possible compromise aggregation operators for multi attribute decision making problems their paper systematically explores possible compromise operators for multi attribute decision making problems and axiomatically identifies the spectrum of such operators in terms of the properties they should satisfy and it shows the main ones that are widely used they illustrated their framework in a scenario of bidding in multi attribute auctions sanayei et al 2010 presented as an alternative to topsis method the vikor method to solve multiple criteria decision making problems with conflicting and non commensurable criteria to determine suitable suppliers in the supply chain linguistic values as trapezoidal or triangular fuzzy numbers are used to assess the ratings and weights for individual factors to express vagueness of expert proposals vahdani et al 2013 presented a compromise solution method for solving fuzzy group decision making problems the performance rating values of alternatives versus conflicting criteria and the weights of criteria are described by linguistic variables with multi judges and are converted to triangular fuzzy numbers a case study for a contractor selection problem is provided in construction industry to demonstrate the implementation process of the method pelikan et al 2014 showed that relationships among elements of ambient intelligence manufacturing applications are fully characterized by ill structuredness subjectivity and vagueness they proposed fuzzy numbers as an adequate means for expressing the vagueness kozierkiewicz hetmańska 2017 presents analysis which allows assessing the consensus quality of the expert final decision especially when big sets of input data are involved in the process the paper contains an overview of several types of possible approaches authors also analyzed possibility to determine a common and reliable opinion of a collective by analyzing the given knowledge of such collective qu et al 2019 focuses on the utilization of interval valued triangular fuzzy numbers for expressing expert opinions on group decision making to incorporate the fuzzy information provided by individual experts into group consensus opinion the reliability of the resulting priority rankings was investigated by sensitivity analysis they developed an integrated group decision making framework that can incorporate existing and emerging knowledge from different experts to identify the solution in terms of various evaluating criteria for competing factors they have applied their approach to evaluation and selection of the most desirable technology for removing low concentration cadmium ions from water basili and chateauneuf 2020 developed a method for calculating a consensus distribution as a single probability distribution for aggregation stochastic experts opinions expressed through conflicting probability distributions the aggregation based on the steiner point assumes that experts are competent experienced and independent but they have imprecise information for an easy comparison of the original maxagm method and the newly proposed become enhancement we apply the enhanced method to the same case study that was used for the original one vrana et al 2012a the software for implementing calculations is presented in appendix a and the software for visualization of results is in appendix b there are many crisis situations other than environmental disasters that require quick decision making the covid 19 pandemic for example requires the adoption of numerous measures that also have an environmental impact e g the production of large volumes of plastic waste or an excessive use of disinfectants see service 2020 and synthetic aerosols in this paper we describe typical and contentious circumstances related to the covid 19 pandemic that require a clear decision making process and how the best compromise mean become method can be used to quickly find the best compromise solution in order to enable easier navigation throughout the paper we gradually presented in a logical sequence the following topics outlined principles of fuzzy agreement approach in section 2 based on section 2 principles used in the improved fuzzy agreement approach are described in section 3 details of the become as an improved approximation of the optimum group decision making method are described in section 4 results of the maxagm and become methods when applied on the same flood impact mitigation case study are compared in section 5 in section 6 the become was developed for a group decision making situations that necessitate the skill of quick decision making amid uncertainty environmental disasters like floods droughts earthquakes and others typically represent such situations but become can help in the myriad decisions also beyond environmental field e g in the covid 19 pandemic which requires the adoption of numerous measures in various fields such as medical care health prevention transportation and tourism some measures also have a strong environmental impact that is why we dedicate section 6 to outline a very broad potential of become this section is not about covid 19 but about demonstrating potential of become the software of become is described in appendices in order to avoid interrupting a fluent description of used principles 2 fuzzy agreement approach vrana et al 2012a presented the maxagm optimum aggregation operator which provides a best compromise solution for multi expert decision making under fuzzy conditions based on the shannon theory of entropy it presents a metric for the level of agreement between experts judgments depending on the specific decision problem the method addresses two basic decision making situations a when experts provide a binary yes no response to the research question along with its associated uncertainty and b when individual experts assess the value of a certain parameter of the solution as a real number a fuzzy number or a fuzzy interval the method enables the comparison and aggregation of expert opinions even though these opinions might be diverse or even opposing an application of the maxagm method was demonstrated in a flood risk management case study vrana 2012a the experts assess a value for a certain parameter of the decision problem where x is a vector of m individual experts opinions x i x min x max i 1 2 m for each finally adopted conclusion where τ is a common opinion from x the consensus agreement of this conclusion is a value in interval 0 1 that determines the level of agreement for the m expert opinions consensus is equal to 1 when the opinions of all experts coincide and is equal to zero when half of the experts have one opinion and the other half have the opposite extreme opinion for each τ its τ agreement agr x τ is given by the formula 1 a g r w x τ 1 1 i n w i i 1 n w i log 2 1 x i τ 2 d x where wi are the weight coefficients which can eventually express the different degrees of importance of the individual experts standpoints such a differentiation of the experts standpoints might be needed to reflect e g different qualifications different numbers of representatives from individual categories etc formula 1 represents the averaging operator τ agreement agr x τ which places the value τ into a relationship with m individual experts opinions x i i 1 2 m agr x τ is a continuous concave function in the interval x min x max and is smooth except for n points x 1 x 2 x n where its first derivative does not exist such a function reaches its maximum in the interval x min x max the best compromise aggregation of n individual experts opinions x i is that value of τ for which agr x τ reaches its maximum therefore the vrana optimum averaging operator defined the best compromise collective opinion maxagm as the value ofτ for which τ agreement agr x τ reaches its maximum thus this averaging operator represents a value τ for which the best collective agreement of all estimates is achieved it generally holds that maxagm is from the closed interval bordered by the median and the arithmetic mean of x the maxagm operator was successfully applied in several case studies e g vrana et al 2012b and kovář et al 2018 note the above mentioned optimum vrana method where the averaging operator maxagm provides the best compromise aggregation of m individual experts opinions will be referred to as the maxagm method throughout this paper as shown in vrana 2012a agr x τ is a continuous concave function in interval x min x max see fig 1 below the maxagm is defined as that value τ for which τ agreement agr x τ reaches its maximum thus this averaging operator represents a value τ for which the best collective agreement of all estimates is achieved the task of determining the best aggregation of experts opinions determining the best collective opinion turns into finding the maximum of formula 1 it is relatively easy to calculate maxagm using 1 in the cases when the experts judgments are crisp when these judgments are not crisp but are rather in the form of fuzzy numbers or fuzzy intervals it is analogically possible to define maxagm as a fuzzy set where corresponding analytical operations are performed with fuzzy numbers or fuzzy intervals direct computation with fuzzy numbers is generally not suitable because it deals with equations that cannot be solved algebraically in a final closed analytical form using some formula an efficient stepwise numerical approximation of the membership function was proposed in vrana et al 2012a which requires specialized maxagr software the application of this best compromise expert group decision making was demonstrated using a flood prevention case study discussed further in section 5 using the shannon entropy theory which laid foundations of information theory introducing amount of information disorder and surprise the optimum maxagm method aggregates experts opinions and maximizes their agreement although it provides close to optimum results this method has several limitations high conceptual and computational complexity difficult physical interpretation of results no accuracy indicators and the need for specialized software the aim of the present study is to modify the optimum maxagm method to preserve its advantages and remove or reduce its limitations we propose an enhanced approximation of the maxagm method that 1 is easy to compute 2 is conceptually clear 3 is easy to interpret 4 provides accuracy indicators and 5 does not need any specialized software for an easy comparison of the results of the original method and the newly proposed enhancements we shall apply the enhanced method to the same flood prevention case study that was used for the original method to facilitate the understanding of this paper for readers who are not familiar with fuzzy set theory we note that its basic concepts are briefly outlined in appendix a of vrana et al 2012a 3 improved fuzzy agreement approach let us assume a vector x of m individual experts opinions x min x max i 1 2 m to assess a value for a certain model parameter of the decision task individual x i quantities are crisp or fuzzy numbers with triangular membership functions acb according to vrana et al 2012a the best compromise aggregation of m individual experts opinions xi is the value τ for which agr x τ reaches its maximum maxagm whilst maxagm is from the closed interval between the median ω x and the arithmetic mean γ x the optimum value of maxagm is situated between the arithmetic mean γ of all expert opinions and their statistic median ω i e the middle value separating the greater and lesser portions of a dataset of all expert decisions these two quantities create boundaries for the optimum decision therefore let us introduce a new approximation γω mean of the optimum value maxagm as the arithmetic mean of these two bounds 2 γωmean γ ω 2 now we shall describe how to obtain the arithmetic mean and the statistical median of a set of triangular fuzzy numbers for easier interpretation and calculations we shall place the base of the triangles on the axis x then we can consider only the x coordinates of all vertices a b and c thus the evaluation of the ith expert as a triangular membership function aicibi is considered as follows aibi is the base of a triangle situated on the real axis and ci is a projection of the triangle s vertex c i on the axis x see fig 2 experts can express their ambiguous proposals by fuzzy quantities with a triangular membership function this expression has the following easy interpretation the triangle vertex c in fig 2 coincides with the expert s confidence central value that is the value x c is the most preferred value of the expert proposal the amount of confidence with a certain value x of the proposal is proportional to the y coordinate of the triangle side that means that the proposed value must not be below a or above b according to vaníček et al 2009 the arithmetic mean γ αγβ of m experts judgments is again a fuzzy number with a triangular membership function where individual vertices α γ and β of the resulting membership function are the arithmetic means of the vertices of partial membership functions ai ci bi thus 3 α 1 m k 1 m a k β 1 m k 1 m b k γ 1 m k 1 m c k the statistical median ω ρωσ of m experts fuzzy judgments is again a fuzzy number with a triangular membership function with vertices ρ ω and σ it separates the higher half of the m experts fuzzy judgments from the lower half to determine the statistical median according to vaníček et al 2009 individual fuzzy numbers from our set should be arranged along the real number line x with respect to the positions of their membership functions later we shall describe how each triangular fuzzy number aicibi from our set of m fuzzy numbers is assigned a real number yi which determines the position of triangle aicibi on the real number line the higher yi is the higher is triangle aicibi on the real number line then we can rank the individual judgments with respect to their yi values by arranging the fuzzy numbers along a real number line and assigning an integer number zi to each yi i 1 m we assign zi 1 to the smallest yi and zi m to the biggest yi thus we obtain a sequence of integers 1 2 m if the number m of experts is odd i e m 2n 1 the center of our set of triangular fuzzy numbers aicibi belongs to that i where zi n 1 we denote this central i as q in this case the statistical median ω ρωσ of our set of m fuzzy numbers aicibi i 1 m is the fuzzy number aqcqbq where 4 ρ aq ω cq and σ bq when m 2n is an even number the center of our set of triangular fuzzy numbers aicibi lies between fuzzy numbers apcpbp and arcrbr where p refers to zi n and r refers to zi n 1 the median is the arithmetic mean of fuzzy numbers apcpbp and arcrbr in this case ρ ap ar 2 σ bp br 2 5 ω cp cr 2 objective of this paper is to find the best compromise aggregation of individual experts opinions equations 3 5 show how to calculate result of such best compromise aggregation when experts expressed their answers by fuzzy numbers however there may exist also other fuzzy operators for combining expert opinions which may be useful in some situations where focusing on agreement isn t a priority now we describe how to find the real number yi that determines the center of the triangle and the position of triangular membership function aicibi on a real number line in geometry the triangle center is a certain point in a triangle with a clear physical interpretation for example centroid circumcenter incenter and orthocenter were already familiar to the ancient greeks and can be obtained by simple constructions let us assume a fuzzy number acb with a triangular membership function in the x y plane the x coordinates of this fuzzy number are described by triple real numbers a c b where a and b correspond to the vertices of the triangle base and c is the opposite vertex see fig 2 weisstein 2009 describes over 32 000 methods of expressing a triangle center and its position on the x axis we shall mention some of the most relevant ones see fig 3 a circumcenter the center of a triangle s circumscribed circle i e the circle that passes through all triangle vertices a projection on the x axis corresponds to the center of a base a b 2 see fig 3a b position of the vertex c c incenter the center of a triangle s inscribed circle it is the intersection of the angle bisectors see fig 3c d centroid in geometry the geometric median of a triangle is a line segment that joins a vertex to the midpoint of the opposite side this geometric median is different from the above mentioned statistical median the centroid is the intersection of all three triangle medians i e straight lines between the triangle vertices and the centers of the opposite edges this also corresponds to the center of mass g see fig 3d its projection on the x axis is 6 gx a b c 3 the centroid g is particularly useful for finding the real number yi that determines the center of a triangle and the position of a triangular membership function aicibi on the real number line for each expert to select a statistical median ρωσ from the set of membership functions from all experts we select the membership function of the expert whose center of mass centroid is situated in the middle of the centroids from all experts therefore it has a very simple and suitable physical interpretation 7 gx median ρ ω σ 3 4 become improved approximation of the optimum group decision making method according to vrana et al 2012a the optimum value of the group decision maxagm is situated between the arithmetic mean γ αγβ of all expert decisions αγβ and their statistical median ω ρωσ thus we define the arithmetic mean of these two bounds γωmean as the enhanced approximation γωmean πϕξ γ ω 2 of the optimum decision maxagm i e 8 π α ρ 2 1 2 m k 1 m a k ρ 2 φ γ ω 2 1 2 m k 1 m b k ω 2 ξ β σ 2 1 2 m k 1 m c k σ 2 where m is the number of experts aibi is the base edge and ci is the vertex of a triangular membership function of the ith expert judgment i 1 m ρ ω is the base edge and σ is a vertex of the statistical median membership function it is easy to estimate the possible accuracy of this approximation the maximum error δmax of our approximation γωmean cannot exceed one half of the difference between both borders i e between the arithmetic mean of all expert decisions γ αγβ and their statistical median ω ρωσ thus 9 δmax abs αγβ ρωσ 2 in addition to proximity of γωmean to the optimum agreement decision maxagm and the possibility to estimate the maximum error a great advantage of this newly proposed approximation γωmean is its conceptual clarity and computational simplicity because this new averaging operator brings results representing the best possible compromise of experts standpoints we shall denote this method the become the best compromise mean the become method and its instruments provide a solution to both crucial aspects speed and reliability of decision making in ambiguous conditions experts answers should assess a certain quantitative parameter or qualitative aspect of the proposed solution e g number of days of quarantine experts can express their standpoints in three ways 1 as a crisp number 2 as a fuzzy number in a format preferable value lower limit upper limit and 3 as a quantity in the likert scale strongly disagree rather disagree neutral rather agree strongly agree or a similar linguistic scale the result of the become method πϕξ can be calculated in the following steps as depicted by the flowchart in fig 4 1 collect the triangular experts judgments aicibi 2 calculate arithmetic mean γ αγβ according to 3 3 calculate center of mass gx centroid for each triangle aicibi according to 6 4 rank experts with respect to their centroids 5 select median ω ρωσ as the triangle that is in the middle of all triangles aicibi according to 4 or 5 6 calculate γωmean πϕξ according to 8 7 calculate maximum error δmax according to 9 the proposals of individual experts have been inserted into a spreadsheet where a the best compromise solution and b the accuracy i e maximum error of estimate are immediately displayed instructions on how to apply the become method and some illustrative examples of its utilization have been made available become can be downloaded at https covid19 become pef czu cz en 5 flood impact mitigation case study as mentioned in section 1 we apply this enhanced method to the same flood prevention case study that was used for the original maxagm method to enable an easy comparison of the results first let us briefly describe the situation in the case study the downstream part of the nemcicky catchment situated in central moravia czech republic was frequently exposed to floods mainly because of its low infiltration capacity rate and the small town of sloup often suffered damage from the flooding the presented case study of the nemcicky catchment is a practical example of integrated water resource management to reduce the harmful impacts of floods see fig 5 the main problem with the catchment is its extended arable land area 52 9 which has high curve number cn values and is increasingly a source area for direct runoff instead of infiltrating into the soil two types of flood prevention measures have been identified non structural and structural in the non structural flood prevention measures the major cn parameters in the kinfil rainfall runoff model woodward et al 2003 kovar et al 2002 can be effectively decreased to diminish the peak flow the cn crucially depends on the arable land reduction see e g vrana et al 2012a however opinions about the size of the arable land reduction are very point of view sensitive and may vary with respect to different stakeholder categories therefore a team of 13 experts was established to negotiate this topic the team was composed of the following expert categories hydrology and water resource management 2x nature protection 1x risk management 1x land use 1x civil service 1x municipality 2x economist 1x rescue team coordinator 1x and landowner 3x in addition to other information all team members received design inflow outflow hydrographs pre calculated for time recurrences of n 10 years and n 100 years and for two scenarios corresponding to 15 and 30 reductions of arable land in favor of permanent grassland see fig 6 this provided the experts with information on the impact of the arable land reduction on the resulting flood prevention hence their judgments were based on formal hydrologic models in addition to intuition keeping flood prevention measures in mind the team members were given the same instruction propose the proper amount of arable land to be converted to grassland as a measure for reducing the risk of flooding express your proposal in percentages in the range of 0 50 and indicate the recommended upper and lower limits of your proposal this means that the experts expressed their proposals as fuzzy numbers with a triangular membership function their proposals are shown in table 1 5 1 original maxagm method in the original method the proposed numbers were aggregated by having the maxagr software to apply the aggregating maxagm method this software calculated the value of arable land reduction for which the agreement reached its maximum maxagm 13 if the expert proposals were considered as crisp values at the peak of their triangular membership functions then maxagm 14 some experts expressed their concern that the results could somehow be skewed because some aspect categories were represented by several experts whilst others had only a single expert thus the individual experts were assigned weights see tastle and wierman 2007b to achieve the same overall weight of 1 for every category the aggregated arable land reduction value was also calculated for this weighted situation with a result of maxagm 15 for fuzzy input data and maxagm 14 for crisp input data in all considered decision situations the maximum agreement was achieved for a reduction of arable land in the range of 13 15 which rests between the median 8 and the arithmetic mean 20 38 5 2 become method following the flowchart in fig 4 we apply the new enhanced method to the previous case study 1 the collected triangular experts judgments aicibi are the same as in the previous case study see table 1 2 the arithmetic mean γ αγβ was calculated according to 3 for individual vertices a c and b of the triangular membership functions with the following results α 17 8 β 23 38 and γ 20 38 3 the center of mass gx centroid for each triangle aicibi was calculated according to 6 the results of steps 1 through 3 are shown in table 2 in table 2 unlike table 1 the experts triangular membership functions are expressed by vertex coordinates a b and c instead of vertex c and deviations a and b 4 we ranked the experts with respect to the values of their centroids gx 5 as a median ω ρωσ we selected the triangle with ranking 7 which is in the middle of all triangles aicibi according to 4 or 5 thus ρ 6 σ 11 and ω 8 as expressed in bold letters in table 2 6 we calculated the final decision γωmean πϕξ according to 8 with the following results π 11 54 ξ 17 19 and ϕ 14 19 7 we calculated that the maximum error δmax 5 97 according to 9 the simple excel spreadsheet software for accomplishing all these calculations is presented in appendix a the individual experts judgments their distribution along the x axis with highlighted arithmetic mean γ median ω and the final decision γωmean are visually expressed in fig 7 a simple algorithm source code for this graphical visualization is presented in appendix b we also applied the new enhanced method to the weighted situation when individual decision making aspects have the same value to achieve that we introduced new virtual experts for the aspects that were judged by several experts i e 2x hydrologists 2x municipalities and 3x landowners the judgments of these virtual experts were the arithmetic means of the original experts the modified input data as well as the resulting arithmetic mean γ αγβ centroids gx ranking and median ω are presented in table 3 the final decision γωmean πφξ according to 8 was π 14 01 ξ 22 44 and φ 17 70 with the maximum error δmax 1 69 the individual experts judgments their distribution along the x axis with highlighted arithmetic mean γ median ω and final decision γωmean are visually expressed in fig 8 when we consider the experts judgments as crisp values for vertex c the enhanced method gives the following results see table 4 in addition to the original scenario our case study also experimented with the scenario where one aspect of the decision problem is more important than the others in such cases the judgment of the expert representing that aspect should be more influential for example the financial aspect of many anti flood measures can be crucial for the feasibility of a project therefore we experimentally considered that the economist s opinion should have a weight of 5 this was accomplished by substituting five virtual economists for the economist expert where each of them had the same judgment as the original single economist see table 5 the final decision γωmean πφξ according to 8 was π 12 77 ξ 21 69 and φ 16 56 with the maximum error δmax 2 67 the results of become application to a flood prevention case study were in good agreement with the results obtained by using the original optimized maximum agreement mean maxagm method the deviations were small and remained within an acceptable range of accuracy δmax this confirms the high accuracy of the become method 6 covid 19 case study crisis situations that necessitate the skill of quick decision making amid uncertainty are not limited to floods droughts earthquakes and other environmental disasters see e g pearson and clair 1998 mitroff 2004 tichy and bennis 2007 and hannah et al 2010 the covid 19 pandemic requires the adoption of numerous measures in various fields such as medical care health prevention transportation and tourism some measures are likely to have a negative environmental impact e g excessive use of disinfectants service 2020 and synthetic aerosols and the production of large volumes of plastic waste unfortunately the global community has minimal experience with finding adequate solutions to such problems or determining their parameters nevertheless quick decisions are vital to save lives there is not enough time to construct sophisticated analytical models because there is a lack of general experience and relevant empirical experience decision makers are often required to rely on expert opinions which should be collectively evaluated to establish a consensus a team of experts with diverse and relevant experience is typically appointed in times of crisis the role of each expert in this process was to express their opinions and make recommendations regarding certain aspects of the crisis or the parameters of the discussed solution the experts may rank individually discussed alternatives support or reject some of the proposed solutions or present their opinion on the value of a certain parameter in such situations a well justified and rapid method to determine the best compromise solutions is extremely valuable to decision makers through a covid 19 case study we shall illustrate how the become method can be utilized to make decisions under very complex and ambiguous conditions the aim of this case study is not to comprehensively describe this pandemic or its adopted measures instead by applying become to several typical covid 19 crisis management situations that were observed in the czech republic we shall demonstrate the potential of the become method as a means of searching for the best compromise solutions in each of these decision situations a team of experts with diverse expertise was appointed the expert teams engaged in secret ballot voting to preserve the anonymity of individual actors e g the crisis board members experts and other stakeholders thus we have substituted real actors standpoints with their virtual equivalents in this case study we demonstrate the application of the become method in the following three typical covid 19 crisis management situations case a selection of a desirable parameter value under the condition that suggested values are in the form of fuzzy numbers case b selection of the most convenient option among several possibilities case c establishment of binary yes no decisions from linguistic term expert proposals to begin let us briefly describe how covid 19 has affected various fields e g medical financial organizational educational cultural social political and environmental fields the priority of the czech government has been to avoid the rapid and uncontrolled propagation of covid 19 as failure to do so may result in numerous deaths and heavily burden the healthcare system we collected data on covid 19 cases from the covid 19 data repository of the center for systems science and engineering at johns hopkins university usa and from the open data repository of the national health information system of the regional hygiene stations which is a branch of the ministry of health of the czech republic all of the data on confirmed covid 19 cases and deaths that have been reported by selected affected countries were collected from the period of january 22 to march 12 2020 fig 9 clearly shows how covid 19 gradually spread moving from china to italy germany austria and eventually to the cr the trends illustrating the spread of covid 19 were similar in all of the aforementioned countries thus individual curves were only time shifted the warnings about the coming risks related to covid 19 were clear flaxman et al 2020 it is for this reason that crisis management teams had to be created the mission of each of these teams was to design and gradually implement a series of efficient measures to maintain control of the situation fig 10 6 1 case a selection of desirable value for the reproduction number r because there is no direct way to calculate or determine the value of a viral reproduction number r a team of experts had to propose a certain strategy and its corresponding measures to establish an r value a team of 15 stakeholders was established with individual members being experts in the following fields epidemiology medicine and healthcare hygiene internal affairs law enforcement foreign affairs industry and trade transportation labor and social affairs finance tourism and environment protection the propagation of covid 19 can be described by the epidemiological susceptible exposed infected removed recovered seir model which is frequently used by epidemiologists for this purpose the seir model describes a typical infectious epidemic disease by focusing on the following four characteristic phases prem et al 2020 lin et al 2020 1 susceptible s represents the portion of the unaffected population that is at high risk 2 exposed e represents the number of individuals who have been exposed to the virus i e those who are still within the incubation time 3 infected i represents the number of currently infected people who are displaying symptoms and can potentially infect the population s and 4 recovered removed r represents the number of recovered people who are believed to have developed immunity the seir model is based on the following differential equations 10 d s d t β i s d e d t β i s α e d i d t α e γ i d r d t γ i where n is the size of the population and s t e t i t r t n the speed of the spread is dependent on the parameter β i e the transmission rate which is the rate at which the virus spreads among susceptible individuals this parameter may differ for individual countries and can also vary during the pandemic according to the currently implemented measures β 1 32 was used in our case study the parameter α represents the incubation time which is defined as the period between the time of exposure and confirmed infection it is generally estimated to be 5 6 d the parameter γ i e the mean recovery rate represents the period of time between confirmed infection and recovery r β γ the comsol multiphysics tool was used to construct and simulate our epidemiological seir model based on the short term prediction of the office for medical information and statistics in the cr uzis we implemented various values of the reproduction number r which serves as an indicator of the propagation speed fig 11 there are two types of curves in the epidemiologic model illustrated in fig 11 1 the solid line curves represent people who have been exposed to the virus but are not infected 2 the dashed line curves represent infectious people as previously mentioned we varied the reproduction number r to simulate different circumstances that require decisions based on the short term prediction of the uzis r0 2 64 represents the initial reproduction number which corresponds to the conditions under which the government had not taken any measures to reduce the speed of propagation or before any measures were implemented the results show that nearly half of the population would have been exposed within a 3 wk period if the government had not taken any measures to reduce the speed of propagation r 1 84 corresponds to the conditions under which the people coming from italy and austria are quarantined r 1 28 corresponds to the conditions under which schools are closed and a state of emergency has been declared r 1 00 corresponds to the conditions under which the freedom of movement of persons has been restricted and there is a governmental mandate to wear a mask r 0 70 corresponds to the assumption of a stable state covid 19 pandemic models can also be viewed as having two time dimensions i e the present and the distant future specifically the costs and level of efficiency may be dependent on individual measures there are three basic components of cost 1 a direct financial component e g the costs of medicaments cures medical aid and security services 2 indirect financial costs e g unemployment support financial compensation for companies and individuals bankruptcy and social contributions and 3 non financial costs e g restricted mobility limited or restricted shopping restricted access to cultural and sporting events and restricted traveling and tourism some measures also strongly impact the environment examples include the excessive use of disinfectants see service 2020 and synthetic aerosols and the production of large volumes of plastic waste furthermore the willingness to accept certain types of costs is not the same for all people specifically this willingness can vary broadly depending on the priorities of individuals all of the above mentioned aspects are correlated but there is no historical precedent for determining these relationships nevertheless all of these aspects must be considered in the decisions on which measures to adopt and how to implement them moreover political and mercenary interests can also be projected into the crisis decision making process thus decisions should be based on the personal experience of experts and their intuition despite the fact that they may have diverse and or controversial standpoints therefore it is vital that compromise solutions are found given all of the above information the experts s1 s15 had to suggest the most reasonable r value that will lead to the adoption of the necessary corresponding measures table 6 presents the suggested values of r in the form of fuzzy numbers these r values were implemented in the become method the following results were obtained best compromise r 1 23 accuracy of estimate 0 03 the experts suggested that r 1 23 will lead to the adoption of adequate measures fig 12 shows the distribution of the expert proposals as well as the results which were integrated into the decision making process 6 2 case b selection of the most reasonable alternative to reduce the number of newly confirmed covid 19 cases all travel from italy germany or austria to the cr was prohibited beginning on march 14 2020 nevertheless a higher rate of infection continued to persist near the border regions because of the cross border workers these workers have permanent residence in the cr but must travel between germany or austria and the cr daily for their jobs because these people were considered to be potential carriers of covid 19 the relevant experts discussed how to reduce this risk a team of 13 experts s1 s13 was appointed to represent the following fields epidemiology hygiene medical care internal affairs law enforcement foreign affairs industry and trade transportation labor and social affairs finance education environment protection agriculture and regional authority all participating experts were updated on the state of the pandemic in the cr as discussed in the earlier part of this paragraph and illustrated in figs 9 and 11 the following options were evaluated a1 prevent all cross border commuting a2 allow daily cross border commuting but with certain restrictions a3 allow unrestricted cross border commuting experts s1 s13 were asked to express their support for individual options by assigning a percentage to each of them such that the total is 100 table 7 then the become method was applied to evaluate the experts responses for each option the options were ranked as given in table 8 a2 was the most preferred option with 41 41 of support followed by a3 with 30 10 of support and a1 with 26 22 of support consequently cross border workers were allowed to travel between countries on a daily basis under certain restrictions 6 3 case c binary yes no decisions the cr has been facing the covid 19 epidemic since march 2020 at the beginning the cr government introduced a number of important measures to manage the spread of the virus this strategy has worked well by the end of april 2020 the number of new daily confirmed covid 19 cases had dropped significantly below 100 specifically to 59 by april 28 the value of the reproduction number r had decreased to 0 7 and 3096 patients 40 had fully recovered in response to these results the cr ministry of health prepared a plan for the gradual return to normal daily life however this plan was conditioned on the continuation of this positive trend the seir model which was constructed based on uzis data was used to predict the following three possible scenarios for the summer and autumn seasons fig 13 sc 1 the zero scenario which corresponds to no change to the current epidemiological state sc 2 slight deterioration of the current epidemiological situation r 1 1 sc 3 moderate deterioration of the epidemiological situation r 1 3 this was the most desirable scenario it was difficult to predict how the covid 19 pandemic will have developed by the autumn season of 2020 thus a team of 11 experts e1 e11 was appointed to represent the following fields of expertise epidemiology healthcare education foreign affairs industry and trade transportation finance agriculture environment protection and internal affairs all participating experts were familiar with the data related to the above mentioned three scenarios the team members were asked the same question do you agree that there will be moderate deterioration of the state of the epidemic sc 3 a likert scale was used to evaluate the expert opinions where strongly disagree 0 rather disagree 25 neutral 50 rather agree 75 and strongly agree 100 table 9 presents the individual responses applying the become method to these responses yielded the following results best compromise 26 14 which is close to the value corresponding to rather disagree accuracy of the result maximum error 1 14 consequently the hypothesis of sc 3 was rejected 7 discussion theoretical models often cannot adequately describe real events for actual environmental decision making processes because such problems are typically ambiguous multifaceted complex and ill structured therefore project managers frequently need to rely on the intuition and judgments of multiple experts who have relevant personal experience and an intuitive understanding of the problem the opinions of individual experts typically represent the different viewpoints of many stakeholders however their opinions may be very diverse and even opposing under such conditions aggregating the opinions of experts can be extremely difficult there exist many aggregation operators see e g vaníček 2009 the common aggregation operators like arithmetic mean and median for example often fail and provide distorted and not reliable results for such ill structured decision situations vrana et al 2012a developed the maxagm method this method included an optimized aggregation operator τ agreement i e agr x τ which was used to determine the best compromise solution for multi expert decision making under fuzzy conditions the application of this best compromise expert group decision making process was demonstrated through its application to a flood prevention case study the τ agreement agr x τ aggregation operator yields close to optimum results by using a numeric approximation for the optimum analytical function however the maxagm method is associated with a high level of computational and conceptual complexity difficult to interpret results the absence of accuracy indicators and a need for specialized software that is not widely available in this paper we introduced the become method as an alternative version of the maxagm method which preserves its advantages and overcomes or minimizes its limitations in difference to the maxagm method the become has a low level of computational complexity is conceptually clear and easy to interpret it includes indicators of the agreement accuracy and it does not require any specialized software to enable direct comparison to the results of the original maxagm method we applied the become method to the same flood prevention case study ambiguity of expert proposals could be expressed by fuzzy numbers with a triangular membership function a median of such proposals is calculated as one step of the become method thus individual fuzzy numbers with a triangular membership function have been ranked with respect to their triangle center weisstein 2009 describes over 32 000 methods of expressing a triangle center the most common of which are circumcenter incenter vertex and centroid as mentioned in chapter 3 in this article we have selected centroid to express a triangle center because it has an obvious and clear physical interpretation as the center of mass sensitivity tests of such option confirmed in our case studies that selection of centroid brings only negligible marginal differences in the resulting median with respect to circumcenter incenter and vertex alternatives we calculated value of the final decision γωmean and the maximum error δmax for the following decision making circumstances a non weighted expert judgments expressed by fuzzy numbers with triangular membership functions b non weighted expert judgments expressed as real numbers c weighted expert judgments that ensured the same impact for all individual aspects of the decision making problem note that the expert judgments were expressed as fuzzy numbers with triangular membership functions d weighted expert judgments where the expert judgments were expressed as real numbers for all of the above described circumstances the become method yielded results which were in good agreement with those obtained by using the original optimized maxagm method specifically the deviations were small and remained within an acceptable range of accuracy as denoted by δmax which demonstrated the high accuracy of the become method the case studies presented here clearly show that the become method is a simple and efficient way to combine expert opinion where the focus is on consensus and agreement and in that sense it is a suitable method that can facilitate the decision making process for even ill structured and ambiguous problems such as those arising from the covid 19 pandemic the main concern related to the covid 19 pandemic is healthcare however the concerns related to the impact of covid 19 are wide ranging for example as previously mentioned the attempt to cope with covid 19 has been associated with an excessive production of plastic waste and higher levels of environmental contamination by synthetic aerosols and other disinfectants it is for this reason that environmentalists were included as members of the expert teams and that their opinions needed to be considered in overall decision making 8 conclusions the become method is a general and broadly applicable method which has been proven to be an effective tool for solving ill structured ambiguous and multi dimensional decision making problems related to the environment it also has applicability in various other fields as demonstrated by the covid 19 case study the become method is superior to methods that use generalized averaging operators in particular it has the following advantages 1 it can yield the best possible theoretical compromise 2 in addition to providing quantitative results it can be used to qualitatively assess the aspects of the problem that cannot be quantified it can also be used to select the most suitable solution among several presented options 3 the experts can express their opinions by using real numbers fuzzy numbers or by using likert linguistic terms 4 the time cost is minimized as a final solution can be immediately obtained following input of the variables 5 the most important advantage of the become method over the original optimized maxagm method is its simplicity as all of the decision making process parameters can be easily calculated without any specialized software more specifically all necessary calculations can be performed by using a microsoft excel spreadsheet see appendix a a direct consequence of this simplicity is the conceptual clarity of the become method as it yields easy to interpret results the results can also be graphically represented thereby making them easier to visualize and interpret 6 the become method software is open source and can be downloaded from https covid19 become pef czu cz en funding this work was conducted within the project ambient intelligence in decision making problems in uncertain conditions 2019b0008 funded through the iga foundation of the faculty of economics and management czech university of life sciences prague czech republic declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment authors thank to mudr pavel lindovský ph d from the medlin prague and to ing jan borák ph d from the czech university of life sciences in prague for their introduction to a work style of crisis management teams appendix a the software for all calculations in the become method as an excel spreadsheet program is presented for two possible situations even or odd number of experts after entering input data into gray cells of the appropriate even odd spreadsheet all calculations are performed automatically results of these calculations for the considered case study see in fig 14 fig 14 excel program for calculating arithmetic mean centroid gx median γωmean and maxerr for odd number of experts the data are entered into column c a and b used to generate the results calculations of formulas for cells in excel program see in tables 10 and 11 fig 14 table 10 calculations of formulas for odd number of experts table 10 cell n formula cell n formula b6 sum c6 e6 3 c20 vlookup g5 b6 e18 2 false b7 sum c7 e7 3 d20 vlookup g5 b6 e18 3 false b8 sum c8 e8 3 e20 vlookup g5 b6 e18 4 false b9 sum c9 e9 3 c22 sum c6 c18 13 b10 sum c10 e10 3 d23 sum d6 d18 13 b11 sum c11 e11 3 e24 sum e6 e18 13 b12 sum c12 e12 3 c28 c22 c20 2 b13 sum c13 e13 3 d26 d23 d20 2 b14 sum c14 e14 3 e27 e24 e20 2 b15 sum c15 e15 3 g25 g5 b16 sum c16 e16 3 h25 c22 d23 e24 3 b17 sum c17 e17 3 i25 c28 d26 e27 3 b18 sum c18 e18 3 j25 abs h25 g25 2 g5 median b6 b18 table 11 calculations of formulas for even number of experts table 11 cell n formula cell n formula b32 sum c32 e32 3 c45 vlookup g 32 b32 e43 2 false b33 sum c33 e33 3 d45 vlookup g 32 b32 e43 3 false b34 sum c34 e34 3 e45 vlookup g 32 b32 e43 4 false b35 sum c35 e35 3 c46 vlookup g 33 b33 e44 2 false b36 sum c36 e36 3 d46 vlookup g 33 b33 e44 3 false b37 sum c37 e37 3 e46 vlookup g 33 b33 e44 4 false b38 sum c38 e38 3 c47 c45 c46 2 b39 sum c39 e39 3 d47 d45 d46 2 b40 sum c40 e40 3 e47 e45 e46 2 b41 sum c41 e41 3 c49 sum c32 c43 12 b42 sum c42 e42 3 d50 sum d32 d43 12 b43 sum c43 e43 3 e51 sum e32 e43 12 c55 c49 c47 2 g31 median b32 b43 d53 d50 d47 2 g32 max if b32 b43 g 31 b32 b43 e54 e51 e47 2 g33 min if b33 b44 g 31 b33 b44 g52 g31 h52 c49 d50 e51 3 i52 c55 d53 e54 3 appendix b simple software in r language for the graphical visualization of results is presented below the r language is an open source programming language and free software environment for statistical computing and data visualization that is supported by the r foundation for statistical computing currently there are two software packages of calculator for fuzzy numbers fuzzynumbers and calculator lr fns which were published on cran parchami 2019 we use the fuzzynumber package with official title tools to deal with fuzzy numbers in our code we use the as piecewise linear fuzzynumber method which converts an object to a piecewise linear fuzzy number coroianu et al 2019 with arguments object a fuzzy number or a single numeric value crisp number or vector of length two interval knot n the number of knots knot alpha knot n alpha cut values at knots defaults to uniformly distributed knots we create a triangular fuzzy number according to the triangularfuzzynumber function with arguments a1 a number specifying left bound of the support amid a number specifying the core and a4 a number specifying right bound of the support the data are entered manually for triangularfuzzynumber according to table 2 or table 3 or excel spreadsheet respectively r code for fuzzy number plot fig 7 image 1 r code for fuzzy number plot fig 8 image 3 
25892,vrana et al 2012a presented the maximum agreement mean maxagm method which aggregates expert opinions while focusing on points of agreement although maxagm can minimize shannon entropy to optimize results it has a high level of computational and conceptual complexity yields difficult to interpret results has no indicator of accuracy and requires specialized software that is not widely available in this paper we present the best compromise mean become method as a modified maxagm method become preserves the advantages of maxagm but overcomes its limitations to enable direct comparison we applied the become method to the same flood prevention case study that was used to validate the original maxagm method become is a universal method as it can be applied to evaluate environmental and educational measures about pandemics industries and resource issues here we demonstrate the applicability of become in real life covid 19 case study decisions which needed to be rapidly and efficiently made by the czech government keywords agreement averaging operator environmental decision making multi expert decisions best compromise result covid 19 1 introduction environmental decision making problems are usually complex ill structured multi dimensional multi aspect vague and uncertain theoretical models cannot as a rule adequately describe real events or processes therefore it is often appropriate to rely on the intuition and judgment of multiple experts based on their personal experience and intuitive understanding of the problem common averaging operators like arithmetic mean weighted mean or median can be used to aggregate or average multiple recommendations when experts opinions are quantitative coherent and non conflicting unfortunately experts opinions are seldom in harmony and may be quite different from each other in such cases common averaging operators can give incorrect results and may not adequately represent all experts combined opinion statistical methods often fail too because of a lack of relevant data such as probability distributions of variables in formal models it is vital in such situations to have an averaging operator which represents a compromise of all individual opinions during the last three decades fuzzy set theory in environmental decision making has increasingly been applied to manipulate pure judgments and the vagueness of experts opinions see e g nasiri and huang 2008 barreto neto and filho 2008 paterson et al 2008 li et al 2009 and pelikán et al 2017a b the need to resolve conflicts and find compromises in individual expert judgments has also been reported e g in kangas and leskinen 2005 tastle and wierman 2007a nasiri and huang 2008 paterson et al 2008 barreto neto and filho 2008 and ritzema et al 2010 however in these types of decision making problem apparent disparity disagreement in expert opinion is not necessarily spurious it may be a really important part of any decision particularly as often needs to be done in a risk based way averaging and aggregation methods which obscure the full breadth of expert opinion may also lead to less informed decisions i e a loss of information and this should be highlighted there is a fundamental difference in averaging and combining in a robust way depending upon the application in water management researchers have considered the poor structure and fuzziness of the decision making process and utilized fuzzy experts opinions with a consensus seeking approach e g vrana et al 2012a vrana et al 2012b and kovář et al 2018 barreto neto and filho 2008 for example introduced a fuzzy rule based model to estimate the runoff in a tropical watershed by evaluating the runoff derived from fuzzy and boolean methods li et al 2009 developed a multistage fuzzy stochastic programming mfsp model for tackling uncertainties presented as fuzzy sets and probability distributions relatively few researchers in environmental decision making have considered the expert consensus refsgaard et al 2007 presented a framework and guidance for addressing uncertainty in environmental modeling processes voinov 2010 presented the concept of experts as stakeholders and focused on the different types of stakeholder modeling and compared participatory modeling to other frameworks that involve stakeholder participation several papers were dedicated to the topic of expert group decision making for solving environmental tasks in a thematic issue on expert opinion in environmental modelling and management in environmental modelling and software 2012 vol 36 papers from krueger et al 2012a 2012b oliver et al 2012 page et al 2012 and vrana et al 2012a are particularly relevant to the discussion of averaging and evaluating a range of elicited expert opinions it is also stated in the mentioned papers that experts must consider many aspects which often include conflicting evidence and interpretation and may be conflicting as seen in bardossy 1993 donga 2009 tsabadze 2006 and zhang 2009 to reach a reliable conclusion it may not be enough to simply aggregate experts opinions using common aggregation operators see vaníček et al 2009 evaluating the level of mutual agreement is also very important and useful information taking maximum of agreement as a criterion of optimality vrana et al 2012a presented a maximum agreement mean maxagm method for aggregating experts opinions based on shannon entropy which seeks to maximize their agreement however due to a numerical approximation disadvantage of the maxagm method is its high computational and conceptual complexity problems with physically interpreting the results a lack of accuracy indicators and a need for specialized software which is not commonly available that was why as a modification of the maxagm method we developed and presented a best compromise mean become method in this paper which preserves advantages of the maxagm method whilst removing the above mentioned limitations in the other words the maxagm method creates a theoretical framework for the become method besides maxagm several researches published also other methods for consensus in a group decision making below we outline aggregating expert opinions other than maxagm however they usually suffer from an excessive complexity and problems with interpretation luo and jennings 2007 explored the space of possible compromise aggregation operators for multi attribute decision making problems their paper systematically explores possible compromise operators for multi attribute decision making problems and axiomatically identifies the spectrum of such operators in terms of the properties they should satisfy and it shows the main ones that are widely used they illustrated their framework in a scenario of bidding in multi attribute auctions sanayei et al 2010 presented as an alternative to topsis method the vikor method to solve multiple criteria decision making problems with conflicting and non commensurable criteria to determine suitable suppliers in the supply chain linguistic values as trapezoidal or triangular fuzzy numbers are used to assess the ratings and weights for individual factors to express vagueness of expert proposals vahdani et al 2013 presented a compromise solution method for solving fuzzy group decision making problems the performance rating values of alternatives versus conflicting criteria and the weights of criteria are described by linguistic variables with multi judges and are converted to triangular fuzzy numbers a case study for a contractor selection problem is provided in construction industry to demonstrate the implementation process of the method pelikan et al 2014 showed that relationships among elements of ambient intelligence manufacturing applications are fully characterized by ill structuredness subjectivity and vagueness they proposed fuzzy numbers as an adequate means for expressing the vagueness kozierkiewicz hetmańska 2017 presents analysis which allows assessing the consensus quality of the expert final decision especially when big sets of input data are involved in the process the paper contains an overview of several types of possible approaches authors also analyzed possibility to determine a common and reliable opinion of a collective by analyzing the given knowledge of such collective qu et al 2019 focuses on the utilization of interval valued triangular fuzzy numbers for expressing expert opinions on group decision making to incorporate the fuzzy information provided by individual experts into group consensus opinion the reliability of the resulting priority rankings was investigated by sensitivity analysis they developed an integrated group decision making framework that can incorporate existing and emerging knowledge from different experts to identify the solution in terms of various evaluating criteria for competing factors they have applied their approach to evaluation and selection of the most desirable technology for removing low concentration cadmium ions from water basili and chateauneuf 2020 developed a method for calculating a consensus distribution as a single probability distribution for aggregation stochastic experts opinions expressed through conflicting probability distributions the aggregation based on the steiner point assumes that experts are competent experienced and independent but they have imprecise information for an easy comparison of the original maxagm method and the newly proposed become enhancement we apply the enhanced method to the same case study that was used for the original one vrana et al 2012a the software for implementing calculations is presented in appendix a and the software for visualization of results is in appendix b there are many crisis situations other than environmental disasters that require quick decision making the covid 19 pandemic for example requires the adoption of numerous measures that also have an environmental impact e g the production of large volumes of plastic waste or an excessive use of disinfectants see service 2020 and synthetic aerosols in this paper we describe typical and contentious circumstances related to the covid 19 pandemic that require a clear decision making process and how the best compromise mean become method can be used to quickly find the best compromise solution in order to enable easier navigation throughout the paper we gradually presented in a logical sequence the following topics outlined principles of fuzzy agreement approach in section 2 based on section 2 principles used in the improved fuzzy agreement approach are described in section 3 details of the become as an improved approximation of the optimum group decision making method are described in section 4 results of the maxagm and become methods when applied on the same flood impact mitigation case study are compared in section 5 in section 6 the become was developed for a group decision making situations that necessitate the skill of quick decision making amid uncertainty environmental disasters like floods droughts earthquakes and others typically represent such situations but become can help in the myriad decisions also beyond environmental field e g in the covid 19 pandemic which requires the adoption of numerous measures in various fields such as medical care health prevention transportation and tourism some measures also have a strong environmental impact that is why we dedicate section 6 to outline a very broad potential of become this section is not about covid 19 but about demonstrating potential of become the software of become is described in appendices in order to avoid interrupting a fluent description of used principles 2 fuzzy agreement approach vrana et al 2012a presented the maxagm optimum aggregation operator which provides a best compromise solution for multi expert decision making under fuzzy conditions based on the shannon theory of entropy it presents a metric for the level of agreement between experts judgments depending on the specific decision problem the method addresses two basic decision making situations a when experts provide a binary yes no response to the research question along with its associated uncertainty and b when individual experts assess the value of a certain parameter of the solution as a real number a fuzzy number or a fuzzy interval the method enables the comparison and aggregation of expert opinions even though these opinions might be diverse or even opposing an application of the maxagm method was demonstrated in a flood risk management case study vrana 2012a the experts assess a value for a certain parameter of the decision problem where x is a vector of m individual experts opinions x i x min x max i 1 2 m for each finally adopted conclusion where τ is a common opinion from x the consensus agreement of this conclusion is a value in interval 0 1 that determines the level of agreement for the m expert opinions consensus is equal to 1 when the opinions of all experts coincide and is equal to zero when half of the experts have one opinion and the other half have the opposite extreme opinion for each τ its τ agreement agr x τ is given by the formula 1 a g r w x τ 1 1 i n w i i 1 n w i log 2 1 x i τ 2 d x where wi are the weight coefficients which can eventually express the different degrees of importance of the individual experts standpoints such a differentiation of the experts standpoints might be needed to reflect e g different qualifications different numbers of representatives from individual categories etc formula 1 represents the averaging operator τ agreement agr x τ which places the value τ into a relationship with m individual experts opinions x i i 1 2 m agr x τ is a continuous concave function in the interval x min x max and is smooth except for n points x 1 x 2 x n where its first derivative does not exist such a function reaches its maximum in the interval x min x max the best compromise aggregation of n individual experts opinions x i is that value of τ for which agr x τ reaches its maximum therefore the vrana optimum averaging operator defined the best compromise collective opinion maxagm as the value ofτ for which τ agreement agr x τ reaches its maximum thus this averaging operator represents a value τ for which the best collective agreement of all estimates is achieved it generally holds that maxagm is from the closed interval bordered by the median and the arithmetic mean of x the maxagm operator was successfully applied in several case studies e g vrana et al 2012b and kovář et al 2018 note the above mentioned optimum vrana method where the averaging operator maxagm provides the best compromise aggregation of m individual experts opinions will be referred to as the maxagm method throughout this paper as shown in vrana 2012a agr x τ is a continuous concave function in interval x min x max see fig 1 below the maxagm is defined as that value τ for which τ agreement agr x τ reaches its maximum thus this averaging operator represents a value τ for which the best collective agreement of all estimates is achieved the task of determining the best aggregation of experts opinions determining the best collective opinion turns into finding the maximum of formula 1 it is relatively easy to calculate maxagm using 1 in the cases when the experts judgments are crisp when these judgments are not crisp but are rather in the form of fuzzy numbers or fuzzy intervals it is analogically possible to define maxagm as a fuzzy set where corresponding analytical operations are performed with fuzzy numbers or fuzzy intervals direct computation with fuzzy numbers is generally not suitable because it deals with equations that cannot be solved algebraically in a final closed analytical form using some formula an efficient stepwise numerical approximation of the membership function was proposed in vrana et al 2012a which requires specialized maxagr software the application of this best compromise expert group decision making was demonstrated using a flood prevention case study discussed further in section 5 using the shannon entropy theory which laid foundations of information theory introducing amount of information disorder and surprise the optimum maxagm method aggregates experts opinions and maximizes their agreement although it provides close to optimum results this method has several limitations high conceptual and computational complexity difficult physical interpretation of results no accuracy indicators and the need for specialized software the aim of the present study is to modify the optimum maxagm method to preserve its advantages and remove or reduce its limitations we propose an enhanced approximation of the maxagm method that 1 is easy to compute 2 is conceptually clear 3 is easy to interpret 4 provides accuracy indicators and 5 does not need any specialized software for an easy comparison of the results of the original method and the newly proposed enhancements we shall apply the enhanced method to the same flood prevention case study that was used for the original method to facilitate the understanding of this paper for readers who are not familiar with fuzzy set theory we note that its basic concepts are briefly outlined in appendix a of vrana et al 2012a 3 improved fuzzy agreement approach let us assume a vector x of m individual experts opinions x min x max i 1 2 m to assess a value for a certain model parameter of the decision task individual x i quantities are crisp or fuzzy numbers with triangular membership functions acb according to vrana et al 2012a the best compromise aggregation of m individual experts opinions xi is the value τ for which agr x τ reaches its maximum maxagm whilst maxagm is from the closed interval between the median ω x and the arithmetic mean γ x the optimum value of maxagm is situated between the arithmetic mean γ of all expert opinions and their statistic median ω i e the middle value separating the greater and lesser portions of a dataset of all expert decisions these two quantities create boundaries for the optimum decision therefore let us introduce a new approximation γω mean of the optimum value maxagm as the arithmetic mean of these two bounds 2 γωmean γ ω 2 now we shall describe how to obtain the arithmetic mean and the statistical median of a set of triangular fuzzy numbers for easier interpretation and calculations we shall place the base of the triangles on the axis x then we can consider only the x coordinates of all vertices a b and c thus the evaluation of the ith expert as a triangular membership function aicibi is considered as follows aibi is the base of a triangle situated on the real axis and ci is a projection of the triangle s vertex c i on the axis x see fig 2 experts can express their ambiguous proposals by fuzzy quantities with a triangular membership function this expression has the following easy interpretation the triangle vertex c in fig 2 coincides with the expert s confidence central value that is the value x c is the most preferred value of the expert proposal the amount of confidence with a certain value x of the proposal is proportional to the y coordinate of the triangle side that means that the proposed value must not be below a or above b according to vaníček et al 2009 the arithmetic mean γ αγβ of m experts judgments is again a fuzzy number with a triangular membership function where individual vertices α γ and β of the resulting membership function are the arithmetic means of the vertices of partial membership functions ai ci bi thus 3 α 1 m k 1 m a k β 1 m k 1 m b k γ 1 m k 1 m c k the statistical median ω ρωσ of m experts fuzzy judgments is again a fuzzy number with a triangular membership function with vertices ρ ω and σ it separates the higher half of the m experts fuzzy judgments from the lower half to determine the statistical median according to vaníček et al 2009 individual fuzzy numbers from our set should be arranged along the real number line x with respect to the positions of their membership functions later we shall describe how each triangular fuzzy number aicibi from our set of m fuzzy numbers is assigned a real number yi which determines the position of triangle aicibi on the real number line the higher yi is the higher is triangle aicibi on the real number line then we can rank the individual judgments with respect to their yi values by arranging the fuzzy numbers along a real number line and assigning an integer number zi to each yi i 1 m we assign zi 1 to the smallest yi and zi m to the biggest yi thus we obtain a sequence of integers 1 2 m if the number m of experts is odd i e m 2n 1 the center of our set of triangular fuzzy numbers aicibi belongs to that i where zi n 1 we denote this central i as q in this case the statistical median ω ρωσ of our set of m fuzzy numbers aicibi i 1 m is the fuzzy number aqcqbq where 4 ρ aq ω cq and σ bq when m 2n is an even number the center of our set of triangular fuzzy numbers aicibi lies between fuzzy numbers apcpbp and arcrbr where p refers to zi n and r refers to zi n 1 the median is the arithmetic mean of fuzzy numbers apcpbp and arcrbr in this case ρ ap ar 2 σ bp br 2 5 ω cp cr 2 objective of this paper is to find the best compromise aggregation of individual experts opinions equations 3 5 show how to calculate result of such best compromise aggregation when experts expressed their answers by fuzzy numbers however there may exist also other fuzzy operators for combining expert opinions which may be useful in some situations where focusing on agreement isn t a priority now we describe how to find the real number yi that determines the center of the triangle and the position of triangular membership function aicibi on a real number line in geometry the triangle center is a certain point in a triangle with a clear physical interpretation for example centroid circumcenter incenter and orthocenter were already familiar to the ancient greeks and can be obtained by simple constructions let us assume a fuzzy number acb with a triangular membership function in the x y plane the x coordinates of this fuzzy number are described by triple real numbers a c b where a and b correspond to the vertices of the triangle base and c is the opposite vertex see fig 2 weisstein 2009 describes over 32 000 methods of expressing a triangle center and its position on the x axis we shall mention some of the most relevant ones see fig 3 a circumcenter the center of a triangle s circumscribed circle i e the circle that passes through all triangle vertices a projection on the x axis corresponds to the center of a base a b 2 see fig 3a b position of the vertex c c incenter the center of a triangle s inscribed circle it is the intersection of the angle bisectors see fig 3c d centroid in geometry the geometric median of a triangle is a line segment that joins a vertex to the midpoint of the opposite side this geometric median is different from the above mentioned statistical median the centroid is the intersection of all three triangle medians i e straight lines between the triangle vertices and the centers of the opposite edges this also corresponds to the center of mass g see fig 3d its projection on the x axis is 6 gx a b c 3 the centroid g is particularly useful for finding the real number yi that determines the center of a triangle and the position of a triangular membership function aicibi on the real number line for each expert to select a statistical median ρωσ from the set of membership functions from all experts we select the membership function of the expert whose center of mass centroid is situated in the middle of the centroids from all experts therefore it has a very simple and suitable physical interpretation 7 gx median ρ ω σ 3 4 become improved approximation of the optimum group decision making method according to vrana et al 2012a the optimum value of the group decision maxagm is situated between the arithmetic mean γ αγβ of all expert decisions αγβ and their statistical median ω ρωσ thus we define the arithmetic mean of these two bounds γωmean as the enhanced approximation γωmean πϕξ γ ω 2 of the optimum decision maxagm i e 8 π α ρ 2 1 2 m k 1 m a k ρ 2 φ γ ω 2 1 2 m k 1 m b k ω 2 ξ β σ 2 1 2 m k 1 m c k σ 2 where m is the number of experts aibi is the base edge and ci is the vertex of a triangular membership function of the ith expert judgment i 1 m ρ ω is the base edge and σ is a vertex of the statistical median membership function it is easy to estimate the possible accuracy of this approximation the maximum error δmax of our approximation γωmean cannot exceed one half of the difference between both borders i e between the arithmetic mean of all expert decisions γ αγβ and their statistical median ω ρωσ thus 9 δmax abs αγβ ρωσ 2 in addition to proximity of γωmean to the optimum agreement decision maxagm and the possibility to estimate the maximum error a great advantage of this newly proposed approximation γωmean is its conceptual clarity and computational simplicity because this new averaging operator brings results representing the best possible compromise of experts standpoints we shall denote this method the become the best compromise mean the become method and its instruments provide a solution to both crucial aspects speed and reliability of decision making in ambiguous conditions experts answers should assess a certain quantitative parameter or qualitative aspect of the proposed solution e g number of days of quarantine experts can express their standpoints in three ways 1 as a crisp number 2 as a fuzzy number in a format preferable value lower limit upper limit and 3 as a quantity in the likert scale strongly disagree rather disagree neutral rather agree strongly agree or a similar linguistic scale the result of the become method πϕξ can be calculated in the following steps as depicted by the flowchart in fig 4 1 collect the triangular experts judgments aicibi 2 calculate arithmetic mean γ αγβ according to 3 3 calculate center of mass gx centroid for each triangle aicibi according to 6 4 rank experts with respect to their centroids 5 select median ω ρωσ as the triangle that is in the middle of all triangles aicibi according to 4 or 5 6 calculate γωmean πϕξ according to 8 7 calculate maximum error δmax according to 9 the proposals of individual experts have been inserted into a spreadsheet where a the best compromise solution and b the accuracy i e maximum error of estimate are immediately displayed instructions on how to apply the become method and some illustrative examples of its utilization have been made available become can be downloaded at https covid19 become pef czu cz en 5 flood impact mitigation case study as mentioned in section 1 we apply this enhanced method to the same flood prevention case study that was used for the original maxagm method to enable an easy comparison of the results first let us briefly describe the situation in the case study the downstream part of the nemcicky catchment situated in central moravia czech republic was frequently exposed to floods mainly because of its low infiltration capacity rate and the small town of sloup often suffered damage from the flooding the presented case study of the nemcicky catchment is a practical example of integrated water resource management to reduce the harmful impacts of floods see fig 5 the main problem with the catchment is its extended arable land area 52 9 which has high curve number cn values and is increasingly a source area for direct runoff instead of infiltrating into the soil two types of flood prevention measures have been identified non structural and structural in the non structural flood prevention measures the major cn parameters in the kinfil rainfall runoff model woodward et al 2003 kovar et al 2002 can be effectively decreased to diminish the peak flow the cn crucially depends on the arable land reduction see e g vrana et al 2012a however opinions about the size of the arable land reduction are very point of view sensitive and may vary with respect to different stakeholder categories therefore a team of 13 experts was established to negotiate this topic the team was composed of the following expert categories hydrology and water resource management 2x nature protection 1x risk management 1x land use 1x civil service 1x municipality 2x economist 1x rescue team coordinator 1x and landowner 3x in addition to other information all team members received design inflow outflow hydrographs pre calculated for time recurrences of n 10 years and n 100 years and for two scenarios corresponding to 15 and 30 reductions of arable land in favor of permanent grassland see fig 6 this provided the experts with information on the impact of the arable land reduction on the resulting flood prevention hence their judgments were based on formal hydrologic models in addition to intuition keeping flood prevention measures in mind the team members were given the same instruction propose the proper amount of arable land to be converted to grassland as a measure for reducing the risk of flooding express your proposal in percentages in the range of 0 50 and indicate the recommended upper and lower limits of your proposal this means that the experts expressed their proposals as fuzzy numbers with a triangular membership function their proposals are shown in table 1 5 1 original maxagm method in the original method the proposed numbers were aggregated by having the maxagr software to apply the aggregating maxagm method this software calculated the value of arable land reduction for which the agreement reached its maximum maxagm 13 if the expert proposals were considered as crisp values at the peak of their triangular membership functions then maxagm 14 some experts expressed their concern that the results could somehow be skewed because some aspect categories were represented by several experts whilst others had only a single expert thus the individual experts were assigned weights see tastle and wierman 2007b to achieve the same overall weight of 1 for every category the aggregated arable land reduction value was also calculated for this weighted situation with a result of maxagm 15 for fuzzy input data and maxagm 14 for crisp input data in all considered decision situations the maximum agreement was achieved for a reduction of arable land in the range of 13 15 which rests between the median 8 and the arithmetic mean 20 38 5 2 become method following the flowchart in fig 4 we apply the new enhanced method to the previous case study 1 the collected triangular experts judgments aicibi are the same as in the previous case study see table 1 2 the arithmetic mean γ αγβ was calculated according to 3 for individual vertices a c and b of the triangular membership functions with the following results α 17 8 β 23 38 and γ 20 38 3 the center of mass gx centroid for each triangle aicibi was calculated according to 6 the results of steps 1 through 3 are shown in table 2 in table 2 unlike table 1 the experts triangular membership functions are expressed by vertex coordinates a b and c instead of vertex c and deviations a and b 4 we ranked the experts with respect to the values of their centroids gx 5 as a median ω ρωσ we selected the triangle with ranking 7 which is in the middle of all triangles aicibi according to 4 or 5 thus ρ 6 σ 11 and ω 8 as expressed in bold letters in table 2 6 we calculated the final decision γωmean πϕξ according to 8 with the following results π 11 54 ξ 17 19 and ϕ 14 19 7 we calculated that the maximum error δmax 5 97 according to 9 the simple excel spreadsheet software for accomplishing all these calculations is presented in appendix a the individual experts judgments their distribution along the x axis with highlighted arithmetic mean γ median ω and the final decision γωmean are visually expressed in fig 7 a simple algorithm source code for this graphical visualization is presented in appendix b we also applied the new enhanced method to the weighted situation when individual decision making aspects have the same value to achieve that we introduced new virtual experts for the aspects that were judged by several experts i e 2x hydrologists 2x municipalities and 3x landowners the judgments of these virtual experts were the arithmetic means of the original experts the modified input data as well as the resulting arithmetic mean γ αγβ centroids gx ranking and median ω are presented in table 3 the final decision γωmean πφξ according to 8 was π 14 01 ξ 22 44 and φ 17 70 with the maximum error δmax 1 69 the individual experts judgments their distribution along the x axis with highlighted arithmetic mean γ median ω and final decision γωmean are visually expressed in fig 8 when we consider the experts judgments as crisp values for vertex c the enhanced method gives the following results see table 4 in addition to the original scenario our case study also experimented with the scenario where one aspect of the decision problem is more important than the others in such cases the judgment of the expert representing that aspect should be more influential for example the financial aspect of many anti flood measures can be crucial for the feasibility of a project therefore we experimentally considered that the economist s opinion should have a weight of 5 this was accomplished by substituting five virtual economists for the economist expert where each of them had the same judgment as the original single economist see table 5 the final decision γωmean πφξ according to 8 was π 12 77 ξ 21 69 and φ 16 56 with the maximum error δmax 2 67 the results of become application to a flood prevention case study were in good agreement with the results obtained by using the original optimized maximum agreement mean maxagm method the deviations were small and remained within an acceptable range of accuracy δmax this confirms the high accuracy of the become method 6 covid 19 case study crisis situations that necessitate the skill of quick decision making amid uncertainty are not limited to floods droughts earthquakes and other environmental disasters see e g pearson and clair 1998 mitroff 2004 tichy and bennis 2007 and hannah et al 2010 the covid 19 pandemic requires the adoption of numerous measures in various fields such as medical care health prevention transportation and tourism some measures are likely to have a negative environmental impact e g excessive use of disinfectants service 2020 and synthetic aerosols and the production of large volumes of plastic waste unfortunately the global community has minimal experience with finding adequate solutions to such problems or determining their parameters nevertheless quick decisions are vital to save lives there is not enough time to construct sophisticated analytical models because there is a lack of general experience and relevant empirical experience decision makers are often required to rely on expert opinions which should be collectively evaluated to establish a consensus a team of experts with diverse and relevant experience is typically appointed in times of crisis the role of each expert in this process was to express their opinions and make recommendations regarding certain aspects of the crisis or the parameters of the discussed solution the experts may rank individually discussed alternatives support or reject some of the proposed solutions or present their opinion on the value of a certain parameter in such situations a well justified and rapid method to determine the best compromise solutions is extremely valuable to decision makers through a covid 19 case study we shall illustrate how the become method can be utilized to make decisions under very complex and ambiguous conditions the aim of this case study is not to comprehensively describe this pandemic or its adopted measures instead by applying become to several typical covid 19 crisis management situations that were observed in the czech republic we shall demonstrate the potential of the become method as a means of searching for the best compromise solutions in each of these decision situations a team of experts with diverse expertise was appointed the expert teams engaged in secret ballot voting to preserve the anonymity of individual actors e g the crisis board members experts and other stakeholders thus we have substituted real actors standpoints with their virtual equivalents in this case study we demonstrate the application of the become method in the following three typical covid 19 crisis management situations case a selection of a desirable parameter value under the condition that suggested values are in the form of fuzzy numbers case b selection of the most convenient option among several possibilities case c establishment of binary yes no decisions from linguistic term expert proposals to begin let us briefly describe how covid 19 has affected various fields e g medical financial organizational educational cultural social political and environmental fields the priority of the czech government has been to avoid the rapid and uncontrolled propagation of covid 19 as failure to do so may result in numerous deaths and heavily burden the healthcare system we collected data on covid 19 cases from the covid 19 data repository of the center for systems science and engineering at johns hopkins university usa and from the open data repository of the national health information system of the regional hygiene stations which is a branch of the ministry of health of the czech republic all of the data on confirmed covid 19 cases and deaths that have been reported by selected affected countries were collected from the period of january 22 to march 12 2020 fig 9 clearly shows how covid 19 gradually spread moving from china to italy germany austria and eventually to the cr the trends illustrating the spread of covid 19 were similar in all of the aforementioned countries thus individual curves were only time shifted the warnings about the coming risks related to covid 19 were clear flaxman et al 2020 it is for this reason that crisis management teams had to be created the mission of each of these teams was to design and gradually implement a series of efficient measures to maintain control of the situation fig 10 6 1 case a selection of desirable value for the reproduction number r because there is no direct way to calculate or determine the value of a viral reproduction number r a team of experts had to propose a certain strategy and its corresponding measures to establish an r value a team of 15 stakeholders was established with individual members being experts in the following fields epidemiology medicine and healthcare hygiene internal affairs law enforcement foreign affairs industry and trade transportation labor and social affairs finance tourism and environment protection the propagation of covid 19 can be described by the epidemiological susceptible exposed infected removed recovered seir model which is frequently used by epidemiologists for this purpose the seir model describes a typical infectious epidemic disease by focusing on the following four characteristic phases prem et al 2020 lin et al 2020 1 susceptible s represents the portion of the unaffected population that is at high risk 2 exposed e represents the number of individuals who have been exposed to the virus i e those who are still within the incubation time 3 infected i represents the number of currently infected people who are displaying symptoms and can potentially infect the population s and 4 recovered removed r represents the number of recovered people who are believed to have developed immunity the seir model is based on the following differential equations 10 d s d t β i s d e d t β i s α e d i d t α e γ i d r d t γ i where n is the size of the population and s t e t i t r t n the speed of the spread is dependent on the parameter β i e the transmission rate which is the rate at which the virus spreads among susceptible individuals this parameter may differ for individual countries and can also vary during the pandemic according to the currently implemented measures β 1 32 was used in our case study the parameter α represents the incubation time which is defined as the period between the time of exposure and confirmed infection it is generally estimated to be 5 6 d the parameter γ i e the mean recovery rate represents the period of time between confirmed infection and recovery r β γ the comsol multiphysics tool was used to construct and simulate our epidemiological seir model based on the short term prediction of the office for medical information and statistics in the cr uzis we implemented various values of the reproduction number r which serves as an indicator of the propagation speed fig 11 there are two types of curves in the epidemiologic model illustrated in fig 11 1 the solid line curves represent people who have been exposed to the virus but are not infected 2 the dashed line curves represent infectious people as previously mentioned we varied the reproduction number r to simulate different circumstances that require decisions based on the short term prediction of the uzis r0 2 64 represents the initial reproduction number which corresponds to the conditions under which the government had not taken any measures to reduce the speed of propagation or before any measures were implemented the results show that nearly half of the population would have been exposed within a 3 wk period if the government had not taken any measures to reduce the speed of propagation r 1 84 corresponds to the conditions under which the people coming from italy and austria are quarantined r 1 28 corresponds to the conditions under which schools are closed and a state of emergency has been declared r 1 00 corresponds to the conditions under which the freedom of movement of persons has been restricted and there is a governmental mandate to wear a mask r 0 70 corresponds to the assumption of a stable state covid 19 pandemic models can also be viewed as having two time dimensions i e the present and the distant future specifically the costs and level of efficiency may be dependent on individual measures there are three basic components of cost 1 a direct financial component e g the costs of medicaments cures medical aid and security services 2 indirect financial costs e g unemployment support financial compensation for companies and individuals bankruptcy and social contributions and 3 non financial costs e g restricted mobility limited or restricted shopping restricted access to cultural and sporting events and restricted traveling and tourism some measures also strongly impact the environment examples include the excessive use of disinfectants see service 2020 and synthetic aerosols and the production of large volumes of plastic waste furthermore the willingness to accept certain types of costs is not the same for all people specifically this willingness can vary broadly depending on the priorities of individuals all of the above mentioned aspects are correlated but there is no historical precedent for determining these relationships nevertheless all of these aspects must be considered in the decisions on which measures to adopt and how to implement them moreover political and mercenary interests can also be projected into the crisis decision making process thus decisions should be based on the personal experience of experts and their intuition despite the fact that they may have diverse and or controversial standpoints therefore it is vital that compromise solutions are found given all of the above information the experts s1 s15 had to suggest the most reasonable r value that will lead to the adoption of the necessary corresponding measures table 6 presents the suggested values of r in the form of fuzzy numbers these r values were implemented in the become method the following results were obtained best compromise r 1 23 accuracy of estimate 0 03 the experts suggested that r 1 23 will lead to the adoption of adequate measures fig 12 shows the distribution of the expert proposals as well as the results which were integrated into the decision making process 6 2 case b selection of the most reasonable alternative to reduce the number of newly confirmed covid 19 cases all travel from italy germany or austria to the cr was prohibited beginning on march 14 2020 nevertheless a higher rate of infection continued to persist near the border regions because of the cross border workers these workers have permanent residence in the cr but must travel between germany or austria and the cr daily for their jobs because these people were considered to be potential carriers of covid 19 the relevant experts discussed how to reduce this risk a team of 13 experts s1 s13 was appointed to represent the following fields epidemiology hygiene medical care internal affairs law enforcement foreign affairs industry and trade transportation labor and social affairs finance education environment protection agriculture and regional authority all participating experts were updated on the state of the pandemic in the cr as discussed in the earlier part of this paragraph and illustrated in figs 9 and 11 the following options were evaluated a1 prevent all cross border commuting a2 allow daily cross border commuting but with certain restrictions a3 allow unrestricted cross border commuting experts s1 s13 were asked to express their support for individual options by assigning a percentage to each of them such that the total is 100 table 7 then the become method was applied to evaluate the experts responses for each option the options were ranked as given in table 8 a2 was the most preferred option with 41 41 of support followed by a3 with 30 10 of support and a1 with 26 22 of support consequently cross border workers were allowed to travel between countries on a daily basis under certain restrictions 6 3 case c binary yes no decisions the cr has been facing the covid 19 epidemic since march 2020 at the beginning the cr government introduced a number of important measures to manage the spread of the virus this strategy has worked well by the end of april 2020 the number of new daily confirmed covid 19 cases had dropped significantly below 100 specifically to 59 by april 28 the value of the reproduction number r had decreased to 0 7 and 3096 patients 40 had fully recovered in response to these results the cr ministry of health prepared a plan for the gradual return to normal daily life however this plan was conditioned on the continuation of this positive trend the seir model which was constructed based on uzis data was used to predict the following three possible scenarios for the summer and autumn seasons fig 13 sc 1 the zero scenario which corresponds to no change to the current epidemiological state sc 2 slight deterioration of the current epidemiological situation r 1 1 sc 3 moderate deterioration of the epidemiological situation r 1 3 this was the most desirable scenario it was difficult to predict how the covid 19 pandemic will have developed by the autumn season of 2020 thus a team of 11 experts e1 e11 was appointed to represent the following fields of expertise epidemiology healthcare education foreign affairs industry and trade transportation finance agriculture environment protection and internal affairs all participating experts were familiar with the data related to the above mentioned three scenarios the team members were asked the same question do you agree that there will be moderate deterioration of the state of the epidemic sc 3 a likert scale was used to evaluate the expert opinions where strongly disagree 0 rather disagree 25 neutral 50 rather agree 75 and strongly agree 100 table 9 presents the individual responses applying the become method to these responses yielded the following results best compromise 26 14 which is close to the value corresponding to rather disagree accuracy of the result maximum error 1 14 consequently the hypothesis of sc 3 was rejected 7 discussion theoretical models often cannot adequately describe real events for actual environmental decision making processes because such problems are typically ambiguous multifaceted complex and ill structured therefore project managers frequently need to rely on the intuition and judgments of multiple experts who have relevant personal experience and an intuitive understanding of the problem the opinions of individual experts typically represent the different viewpoints of many stakeholders however their opinions may be very diverse and even opposing under such conditions aggregating the opinions of experts can be extremely difficult there exist many aggregation operators see e g vaníček 2009 the common aggregation operators like arithmetic mean and median for example often fail and provide distorted and not reliable results for such ill structured decision situations vrana et al 2012a developed the maxagm method this method included an optimized aggregation operator τ agreement i e agr x τ which was used to determine the best compromise solution for multi expert decision making under fuzzy conditions the application of this best compromise expert group decision making process was demonstrated through its application to a flood prevention case study the τ agreement agr x τ aggregation operator yields close to optimum results by using a numeric approximation for the optimum analytical function however the maxagm method is associated with a high level of computational and conceptual complexity difficult to interpret results the absence of accuracy indicators and a need for specialized software that is not widely available in this paper we introduced the become method as an alternative version of the maxagm method which preserves its advantages and overcomes or minimizes its limitations in difference to the maxagm method the become has a low level of computational complexity is conceptually clear and easy to interpret it includes indicators of the agreement accuracy and it does not require any specialized software to enable direct comparison to the results of the original maxagm method we applied the become method to the same flood prevention case study ambiguity of expert proposals could be expressed by fuzzy numbers with a triangular membership function a median of such proposals is calculated as one step of the become method thus individual fuzzy numbers with a triangular membership function have been ranked with respect to their triangle center weisstein 2009 describes over 32 000 methods of expressing a triangle center the most common of which are circumcenter incenter vertex and centroid as mentioned in chapter 3 in this article we have selected centroid to express a triangle center because it has an obvious and clear physical interpretation as the center of mass sensitivity tests of such option confirmed in our case studies that selection of centroid brings only negligible marginal differences in the resulting median with respect to circumcenter incenter and vertex alternatives we calculated value of the final decision γωmean and the maximum error δmax for the following decision making circumstances a non weighted expert judgments expressed by fuzzy numbers with triangular membership functions b non weighted expert judgments expressed as real numbers c weighted expert judgments that ensured the same impact for all individual aspects of the decision making problem note that the expert judgments were expressed as fuzzy numbers with triangular membership functions d weighted expert judgments where the expert judgments were expressed as real numbers for all of the above described circumstances the become method yielded results which were in good agreement with those obtained by using the original optimized maxagm method specifically the deviations were small and remained within an acceptable range of accuracy as denoted by δmax which demonstrated the high accuracy of the become method the case studies presented here clearly show that the become method is a simple and efficient way to combine expert opinion where the focus is on consensus and agreement and in that sense it is a suitable method that can facilitate the decision making process for even ill structured and ambiguous problems such as those arising from the covid 19 pandemic the main concern related to the covid 19 pandemic is healthcare however the concerns related to the impact of covid 19 are wide ranging for example as previously mentioned the attempt to cope with covid 19 has been associated with an excessive production of plastic waste and higher levels of environmental contamination by synthetic aerosols and other disinfectants it is for this reason that environmentalists were included as members of the expert teams and that their opinions needed to be considered in overall decision making 8 conclusions the become method is a general and broadly applicable method which has been proven to be an effective tool for solving ill structured ambiguous and multi dimensional decision making problems related to the environment it also has applicability in various other fields as demonstrated by the covid 19 case study the become method is superior to methods that use generalized averaging operators in particular it has the following advantages 1 it can yield the best possible theoretical compromise 2 in addition to providing quantitative results it can be used to qualitatively assess the aspects of the problem that cannot be quantified it can also be used to select the most suitable solution among several presented options 3 the experts can express their opinions by using real numbers fuzzy numbers or by using likert linguistic terms 4 the time cost is minimized as a final solution can be immediately obtained following input of the variables 5 the most important advantage of the become method over the original optimized maxagm method is its simplicity as all of the decision making process parameters can be easily calculated without any specialized software more specifically all necessary calculations can be performed by using a microsoft excel spreadsheet see appendix a a direct consequence of this simplicity is the conceptual clarity of the become method as it yields easy to interpret results the results can also be graphically represented thereby making them easier to visualize and interpret 6 the become method software is open source and can be downloaded from https covid19 become pef czu cz en funding this work was conducted within the project ambient intelligence in decision making problems in uncertain conditions 2019b0008 funded through the iga foundation of the faculty of economics and management czech university of life sciences prague czech republic declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment authors thank to mudr pavel lindovský ph d from the medlin prague and to ing jan borák ph d from the czech university of life sciences in prague for their introduction to a work style of crisis management teams appendix a the software for all calculations in the become method as an excel spreadsheet program is presented for two possible situations even or odd number of experts after entering input data into gray cells of the appropriate even odd spreadsheet all calculations are performed automatically results of these calculations for the considered case study see in fig 14 fig 14 excel program for calculating arithmetic mean centroid gx median γωmean and maxerr for odd number of experts the data are entered into column c a and b used to generate the results calculations of formulas for cells in excel program see in tables 10 and 11 fig 14 table 10 calculations of formulas for odd number of experts table 10 cell n formula cell n formula b6 sum c6 e6 3 c20 vlookup g5 b6 e18 2 false b7 sum c7 e7 3 d20 vlookup g5 b6 e18 3 false b8 sum c8 e8 3 e20 vlookup g5 b6 e18 4 false b9 sum c9 e9 3 c22 sum c6 c18 13 b10 sum c10 e10 3 d23 sum d6 d18 13 b11 sum c11 e11 3 e24 sum e6 e18 13 b12 sum c12 e12 3 c28 c22 c20 2 b13 sum c13 e13 3 d26 d23 d20 2 b14 sum c14 e14 3 e27 e24 e20 2 b15 sum c15 e15 3 g25 g5 b16 sum c16 e16 3 h25 c22 d23 e24 3 b17 sum c17 e17 3 i25 c28 d26 e27 3 b18 sum c18 e18 3 j25 abs h25 g25 2 g5 median b6 b18 table 11 calculations of formulas for even number of experts table 11 cell n formula cell n formula b32 sum c32 e32 3 c45 vlookup g 32 b32 e43 2 false b33 sum c33 e33 3 d45 vlookup g 32 b32 e43 3 false b34 sum c34 e34 3 e45 vlookup g 32 b32 e43 4 false b35 sum c35 e35 3 c46 vlookup g 33 b33 e44 2 false b36 sum c36 e36 3 d46 vlookup g 33 b33 e44 3 false b37 sum c37 e37 3 e46 vlookup g 33 b33 e44 4 false b38 sum c38 e38 3 c47 c45 c46 2 b39 sum c39 e39 3 d47 d45 d46 2 b40 sum c40 e40 3 e47 e45 e46 2 b41 sum c41 e41 3 c49 sum c32 c43 12 b42 sum c42 e42 3 d50 sum d32 d43 12 b43 sum c43 e43 3 e51 sum e32 e43 12 c55 c49 c47 2 g31 median b32 b43 d53 d50 d47 2 g32 max if b32 b43 g 31 b32 b43 e54 e51 e47 2 g33 min if b33 b44 g 31 b33 b44 g52 g31 h52 c49 d50 e51 3 i52 c55 d53 e54 3 appendix b simple software in r language for the graphical visualization of results is presented below the r language is an open source programming language and free software environment for statistical computing and data visualization that is supported by the r foundation for statistical computing currently there are two software packages of calculator for fuzzy numbers fuzzynumbers and calculator lr fns which were published on cran parchami 2019 we use the fuzzynumber package with official title tools to deal with fuzzy numbers in our code we use the as piecewise linear fuzzynumber method which converts an object to a piecewise linear fuzzy number coroianu et al 2019 with arguments object a fuzzy number or a single numeric value crisp number or vector of length two interval knot n the number of knots knot alpha knot n alpha cut values at knots defaults to uniformly distributed knots we create a triangular fuzzy number according to the triangularfuzzynumber function with arguments a1 a number specifying left bound of the support amid a number specifying the core and a4 a number specifying right bound of the support the data are entered manually for triangularfuzzynumber according to table 2 or table 3 or excel spreadsheet respectively r code for fuzzy number plot fig 7 image 1 r code for fuzzy number plot fig 8 image 3 
25893,interwave analyzer is an open source software that provides detailed characterization of the dynamics of internal waves in lakes and reservoirs it is based on well established theories and empirical knowledge on internal waves and lake mixing and facilitates a general physical classification of lakes and reservoirs as input data the program requires time series of water temperature from various depths and meteorological data which can be obtained from measurements or numerical models interwave analyzer performs an in depth analysis of periodic motion by spectral analysis to identify predominant internal wave periods to facilitate the identification of wave modes the software is coupled with a multi layer model interwave analyzer is a powerful easily accessible and universal tool which can be used for obtaining detailed understanding lake hydrodynamics not only in physical sciences but also in the context of water quality ecological interactions and biogeochemical fluxes in aquatic ecosystems keywords interwave analyzer lake modeling instrumented buoy internal wave spectrum spectral analysis isotherm fluctuation internal wave model lake mixing software availability software name interwave analyzer version 1 00 3 hardware requirements pc system requirements windows linux mac program language python program size 360 kb license mit availability https github com buenorc interwaveanalyzer git 1 introduction although reservoirs and lakes are often classified as standing or stagnant water bodies the water in these ecosystem is not motionless there are numerous forces that can generate water motion mortimer 1974 imberger 2013 osborne 2000 wüest and lorke 2003 fig 1 wind stress at the water surface can excite propagating surface waves and near surface drift currents surface cooling results in convective flows and the inflow of water having a different temperature may promote the formation and propagation of gravity currents water currents and mixing processes in lakes and reservoirs interact with vertical density stratification which may develop in response to surface heating and inflows having different temperature or salinity boehrer and schultze 2008 while stable density stratification suppresses vertical turbulent mixing and the exchange of heat and solutes between layers having different density it gives rise to an additional type of flow baroclinic flows which depend on vertical variations of water density often occur as internal waves which cause a periodic displacement of layers with different density mortimer 1974 internal waves are generated by wind shear and are among the most important phenomena that drive water currents in the interior of stratified lakes and reservoirs mortimer 1952 umlauf and lemmin 2005 bouffard et al 2012 although just a small fraction of the total wind energy crosses the surface boundary layer wetzel 2001 wüest and lorke 2003 wüest et al 2000 roughly 20 of energy that passes through the surface boundary layer can be found in internal wave motions in closed water bodies bouffard and boegman 2012 these waves are often excited in the form of basin scale standing waves also called internal seiches saggio and imberger 1998 wang et al 2000 internal waves have been demonstrated to affect aquatic ecosystems and biogeochemical cycling in stratified lakes and reservoirs by displacing phytoplankton and zooplankton organisms mortimer and horn 1982 rinke et al 2007 causing sediment resuspension sakai et al 2002 and regulating the availability of oxygen in the water column umlauf and lemmin 2005 as well as in the sediment lorke et al 2003 frindte et al 2013 laboratory experiments and field observations revealed that internal wave energy is cascaded to smaller scales of turbulence due to the interaction with the bathymetry and nonlinear steepening of internal seiches generating trains of nonlinear internal waves boegman et al 2003 2005 this energy flux path is considered as an important component of mixing processes in stratified lakes although basin scale internal waves can contain more than 98 of the wave energy shoaling and breaking of internal waves and generation of turbulence is practically restricted to high frequency waves observations in thermally stratified lakes have suggested that more than 80 of the available potential energy of large scale internal waves is transferred to high frequency waves or dissipated into heat during the first wave period stevens et al 1996 water motions in stratified systems are often analyzed in terms of dimensionless numbers which describe dynamic equilibria between the kinetic energy and inertial forces associated with water currents in relation to the potential energy or the buoyancy forces caused by vertical density stratification shintani et al 2010 the required parameters can be obtained in the field using instrumented buoys such as thermistor chains and meteorological stations or they can be obtained from numerical models recent advances in sensor technology and numerical models lead to more widespread availability of high frequency data which can be used to detect internal waves and to estimate or to predict their implications for water quality lorke et al 2006 bouffard and lemmin 2013 simpson et al 2011 although a variety of numbers and parameters describing the baroclinic response of stratified lakes have been formulated based on well established theories and empirical relations many details of their application to field observations are site specific a unified framework for processing field observations and for a quantitative characterization of internal wave activity is currently lacking only recently a powerful open source tool for calculating lake mixing and stratification indices the lake analyzer has been developed read et al 2011 while the lake analyzer provides a broad range of different physical parameters it does not include the characterization of internal waves the aim of this paper is to describe and to demonstrate the efficiency of a new open source tool the interwave analyzer the software provides a detailed characterization of lake mixing and internal wave activity by deriving important physical indices and lake classification based on well established theories horn et al 2001 boegman et al 2005 spigel and imberger 1980 de carvalho bueno et al 2020a the interwave analyzer facilitates a consistent methodology for analyzing data from lake monitoring buoys and numerical models periodic motions are explored by fourier and wavelet transforms which have been widely used in studies on internal waves in lakes de carvalho bueno et al 2020a hutter 2011 münnich et al 1992 interwave analyzer provides a general classification of lake mixing dynamics de carvalho bueno et al 2020a spigel and imberger 1980 which can be used without special knowledge in fluid dynamics e g in interdisciplinary studies analyzing links between internal wave dynamics with water quality and biogeochemical studies for users specialized in environmental fluid dynamics the program analyses wind resonance phenomena münnich et al 1992 vidal and casamitjana 2008 internal seiche growth energy distribution in the internal wave spectrum excitation of higher vertical modes degeneration of internal seiches horn et al 2001 boegman et al 2005 and density inversions in section 2 we present the theoretical background that is implemented in the software including details about established theories and internal wave models we provide information about the program structure input data data processing and output results in section 3 the application and the physical interpretation of results provided by the software are described for two case studies in section 4 the first case study demonstrates the efficiency of the interwave analyzer to describe the evolution of basin scale internal waves using data from a three dimensional numerical model delft3d flow delft hydraulics 2003 in a second case study we processed field measurements from a reservoir and provide more detailed explanations of the influence of user defined parameters on the final results generated by the interwave analyzer 2 internal wave dynamics and mixing classification 2 1 modal model for basin scale internal waves basin scale internal waves internal seiches in a stratified fluid can be approximated by a finite number of eigenvalues having characteristic periods t n m münnich et al 1992 the different periods belong to different patterns of standing waves having n nodes in the vertical and m nodes along the horizontal direction of an idealized rectangular basin commonly referred as v n h m internal wave vertical density stratification is approximated by a number of layers of thickness h i with each having a constant density ρ i where the number of layers determines the maximum number of vertical modes fig 2 the possible periods of standing basin scale internal waves in such idealized system can be obtained by numerical solution of the corresponding eigenvalues by further applying the shallow water and the hydrostatic pressure approximations münnich et al 1992 this solution is presented in appendix a 5 in large basins and at high latitudes internal waves can be affected by coriolis force lemmin et al 2005 bernhardt and kirillin 2013 the potential effect is described by the burger number which represents the squared ratio of the internal rossby radius of deformation r d c p f o where c p is the internal seiche phase speed f o is the coriolis frequency and the basin length l 1 b u r d l 2 for a burger number larger than unity gravity force dominates and the modal model described above is fully applicable for burger numbers smaller than unity the internal waves are affected by earth s rotation and the mathematical formulation of the multi layer system has to be extended sutherland 2010 2 2 wave generation and mixing the stability of stratified shear flows is described by the dimensionless richardson number r i which relates buoyancy to shear forces for small r i 1 the system is susceptible to mixing since work against buoyancy force is small compared to the production turbulent kinetic energy large values of r i indicate that the flow is more stable and consequently less susceptible to vertical mixing depending on the scale and the type of flow r i can be expressed in a variety of different formulations when it is related to the wind stress applied at the water surface of a two layers of constant density epilimnion and hypolimnion it is expressed as the bulk mixed layer richardson number as 2 r i g h e κ w 2 in which h e is the epilimnion thickness w is the friction velocity of the wind and κ 0 4 is the von kármán constant g g δ ρ ρ h is the reduced gravity where g is the acceleration of gravity ρ h is the hypolimnion water density and δ ρ is the density difference between the hypolimnion and epilimnion the bulk richardson number has been found to be a good indicator of baroclinic activity in stratified lakes and reservoirs spigel and imberger 1980 shintani et al 2010 de carvalho bueno et al 2020a based on the richardson number thompson 1980 proposed a normalization to account for the finite longitudinal dimension of the basin the normalization was named the wedderburn number and is expressed as 3 w r i h e l in which h e is the epilimnion thickness and l is the basin length that is aligned with the wind direction the wedderburn number represents the ratio between the wind stress and horizontal pressure gradients due to vertical displacement of the thermocline i e the interface between the two layers of constant density it is related to the longitudinal tilt of the thermocline in response to wind shear the wedderburn number formed the basis of a classification scheme of lake dynamics in terms of four different regimes spigel and imberger 1980 strong mixing steep tilt of the thermocline followed by mixing higher amplitude internal waves dominance and buoyancy dominance fig 3a when w h e l strong mixing regime r i 1 mixing occurs faster than the time required for the formation of billows however observations in different lakes have identified complete mixing events even when w h e l steep thermocline tilt followed by mixing mortimer 1952 1955 thorpe 1978 in this intermediate regime although the mixing does not occur instantaneously vertical displacement is accompanied by billows and interfacial shear that eventually leads to complete mixing of the system this regime persists until w 0 5 h h h for larger values of w the lake remains stably stratified despite the formation of basin scale internal waves in the buoyancy dominated regime i e if 4 w l h 4 h e h h the density stratification is too strong to support larger vertical displacement of the thermocline and only small amplitude internal waves are susceptible to be excited observations have identified that high amplitude internal seiches are often generated between w 1 and 20 stevens et al 1996 roget et al 1993 heaps and ramsbottom 1966 stevens and lawrence 1997 münnich et al 1992 the wedderburn number has also be used to characterize the degeneration of internal seiches horn et al 1998 2001 boegman et al 2005 dorostkar and boegman 2013 the disintegration of basin scale internal waves can be classified into five different regimes damped linear wave degeneration into propagating solitary internal waves kelvin helmholtz instabilities bores and billows and super flow fig 3a each regime is based on the analysis of timescales if the amplitude of an internal seiche is too small for strong shear instability and supercritical regime it is damped by viscosity or by nonlinear effects including wave steepening which can result into the generation of propagating solitary internal waves the transition from damped linear waves to the formation of solitary internal waves regimes occurs when the dissipative timescale is proportional to the steepening timescale which gives that 5 ζ h e ν t v 1 h 1 3 h π ν t v 1 h 1 1 h e h 2 1 δ h h e h 1 2 h e h in which ζ is the initial wave amplitude h e is the epilimnion thickness ν is the kinematic viscosity t v 1 h 1 is the fundamental internal seiche period h is the total water depth and δ h is the metalimnion thickness if the amplitude of the basin scale internal wave is large and its period long compared to the timescale of supercritical flow the flow may become supercritical with froude number f r 1 the transition is characterized by hydraulic jumps bores which are accompanied by strong vertical mixing the formation of supercritical flows that degenerate the basin scale internal waves into bores occurs if 6 ζ h e 1 h e h 2 h e h 3 1 h e h 3 large amplitude internal waves for which the instability timescale is smaller than the internal wave period the shear across the thermocline may generate kelvin helmholtz billows if the local r i is lower than 0 25 the ratio of the stability timescale to the internal wave period can be expressed as 7 ζ h e 2 δ h h h h e 1 if equations 6 and 7 are satisfied both degeneration mechanisms can occur simultaneously which leads to formation of bores and kelvin helmholtz billows fig 3a based on field observations laboratory experiments numerical and theoretical models the wedderburn number has been related for predicting the initial vertical displacement of the thermocline in a two layer system exposed to a steady wind thompson 1980 8 ζ k h e w in which k o 1 is a constant where often k 0 5 stevens and lawrence 1997 the amplitude of the basin scale internal wave ζ eq 8 which corresponds to the maximum displacement of the thermocline is related to the maximum displacement of the water surface initial surface seiche amplitude η o fig 2 9 η o ζ δ ρ ρ h where δ ρ ρ h ρ e is the difference between the density of the epilimnion ρ e and the density in the hypolimnion ρ h eq 8 has been extended to account for total water depth and the effects of the lake boundaries lake bottom and water surface de carvalho bueno et al 2020a 10 ζ o h e k 1 exp w k 2 2 f 2 in which k 1 0 1 and k 2 6 are empirical constants and f is a non dimensional function of the total water depth h and epilimnion and hypolimnion thickness de carvalho bueno et al 2020a 11 f h e h α h e h exp h e h 2 0 125 where α 12 h e h 3 15 7 h e h 2 2 8 h e h 2 1 and was determined empirically the extended equation improves the parameterization of the basin scale internal waves in cases of w 5 fig 3b resonance effects can play an important role on the amplitudes of internal seiches if the period of a basin scale interval wave is similar to that of a periodic wind forcing e g diel variations in wind velocity resonance with wind forcing have been also suggested as a facilitator to generate higher amplitude waves and higher vertical modes münnich et al 1992 antenucci and imberger 2003 boegman and ivey 2012 these effects however are not accounted for in the above parameterizations a parameter that characterizes the vertical mixing events in measured temperature profiles with fast response thermistors is the thorpe displacement length d t thorpe 1977 12 d t z i z j in which z i is the depth of the monotonically decreasing vertical temperature profile and z j is the depth of the measured water temperature it provides indication of periods larger scale vertical overturns as they occur in strong billows although small scale temperature inversions resulting from overturning motions are difficult to be resolved due to slow response time of thermistors their absolute measurement accuracy critical for most temperature loggers and coarse vertical distribution of sensors the thorpe scale can provide information about the convective mixing observed near the water surface brainerd and gregg 1995 3 methods 3 1 input data processing the water density is calculated from user provided time series of water temperature measured at fixed depths using the equation of state for freshwater chen and millero 1986 the contribution of salinity suspended particles and pressure on water density are neglected this simplification has been used in many studies investigating internal wave activity in thermally stratified lakes and reservoirs mortimer 1979 vidal et al 2007 bernhardt and kirillin 2013 guyennon et al 2014 based on the vertical profile of mean density the software divides the water column into different layers for a two layer internal wave model the water column is divided into two layers of constant density in which the density gradient at the interface between both layers is defined as the thermocline the thermocline depth is calculated by weighting the magnitudes of the difference between the maximum calculated density change and the adjacent measurements this method has been described in detailed by read et al 2011 and significantly improves the initial guess that the thermocline is located in the middle between of the two sampling depths with the largest density difference similarly based on the temperature gradients between two neighboring thermistors the program estimates the metalimnion thickness to divide the water column into three distinct layers these procedures are described in detail in appendix a 2 for analysis with more than 3 layers the density profile is divided based on nodes found by the mode decomposition model for more details see appendix a 6 the maximum number of layers is corresponds to the number of sampling depths divided by two for each layer the average water density is calculated internal seiche period is calculated by solving the modal multi layer model the model is presented in details in appendix a 5 the interwave analyzer provides solutions for different vertical and horizontal modes considering different division of the vertical density profile interwave analyzer also provides a sensitivity analysis to evaluate how the internal wave periods are changing due to the variation of the thickness and water density in the layers during the measured time series the algorithm computes the deviation of internal wave periods considering variations of ρ h ρ h ρ e 4 and h e h h h 0 1 interwave analyzer also indicates the maximum and minimum variability of layer thickness and water density considering the analyzed data in addition the program provides a sensitivity analysis for the user provided value of metalimnion threshold this parameter is used to specify the minimum density gradient to define the metalimnion boundaries used to estimate the three layer system appendix a 2 provides a schematic representation of the metalimnion threshold parameter the sensitivity analysis of this parameter provides an indication on how this parameter may influence the period of the second vertical mode interwave analyzer uses two methods of spectral analysis fourier and wavelet transforms to identify internal wave periods in temperature time series and in time series of isothermal depths isothermal depths are determined for specified temperatures by linear interpolation of temperature signals measured at different depths power spectral density is estimated using welch s method thomson and emery 2014 prior to fourier analysis and spectral averaging segments of the time series are weighted by a window function hamming hanning blackman or flattop window functions the segment size can be specified by the user but can also be calculated automatically according to the fundamental internal wave period estimated by the internal wave model in this case the program considers a segment length corresponding to 10 times the v1h1 period for fourier analysis this automatic analysis is just recommended to detect internal seiches of the first vertical mode the overlap percentage between neighboring segments is defined as 50 for all window functions the significance of the spectral peaks is estimated by comparing their amplitude to the mean red noise spectrum estimated from the time series through a qui square test with 95 confidence interval bernhardt and kirillin 2013 interwave analyzer also offers methods to detect coherence and phase shifts of isotherm displacements cross spectral density of two selected isotherms which facilitates the identification of higher vertical modes and internal wave resonance with the wind pannard et al 2011 antenucci et al 2000 vidal et al 2005 saggio and imberger 1998 a band pass filter is used in the program to isolate frequency components of variations in isothermal depth a fourth order butterworth filter is implemented as a series of second order filters with transpose direct form ii smith 2007 the cutoff frequencies which define the frequency bandwidth of interest must be specified by the user the program also identifies the most energetic fluctuation of the analyzed isotherms however depending on the specified isotherms and measurement location the amplitude provided by the program can be strongly underestimated the wavelet transform is used to facilitate analyses of isothermal depth and temperature time series in the time and the frequency domain simultaneously the procedure is applied according to techniques described by torrence and compo 1998 three options of mother wavelet functions are implemented morlet paul and dog more details about the calculation procedures used to identify internal waves through spectral analysis is presented in appendix a 7 since the period of internal seiche is fetch dependent and wind fetch may also vary according to the wind direction interwave analyzer calculates the wind fetch as time series based on the wind direction and the basin length along this direction the program calculates the mean wind direction and based on a user specified range of directions around this mean value it identifies the variability of wind fetch for the analyzed period the maximum and minimum values of the wind fetch are used to compute a range of internal wave periods to facilitate the identification and analyses of internal seiches all physical indices described in section 2 2 are calculated the wedderburn number w eq 3 is considered wind fetch dependent and described as a mean value as well as time series previous studies showed that the consistency of wind direction and speed are crucial for describing the formation of internal seiche stevens and imberger 1996 valerio et al 2017 gaudard et al 2017 observations have suggested that the wedderburn number is underestimated to describe the formation of internal seiche because of variations in wind direction the program includes a filter for the identification of homogeneous wind events the filtered values of w implemented in the interwave analyzer takes into account the calculated periods of consecutive wind events based on wind direction contribution the software indicates periods of constant wind events which could be a potential period for internal seiche activity the interwave analyzer identifies wind events based on the wind tolerance angle specified by users to avoid an influence of temporal resolution of wind measurements the homogeneous wind events are computed through a convolution based on the internal seiche period 1 8 t v 1 h 1 based in the same principle the program also estimates an effective wedderburn number which takes into account the mean direction of the wind event w efe gaudard et al 2017 13 w efe w f dur 2 in which f dur 2 4 t wind t v 1 h 1 is the duration factor t wind is the duration of homogeneous wind events t v 1 h 1 the fundamental internal wave period l is the basin length that is aligned with the wind direction h e is the epilimnion thickness and w is the non filtered wedderburn number the internal seiche amplitudes are estimated following de carvalho bueno et al 2020a and spigel and imberger 1980 the corresponding surface seiche amplitude is computed eq 9 thorpe scales are calculated according to eq 12 the most important calculations provided by the interwave analyzer are summarized in table 1 3 2 input data and configuration the interwave analyzer requires a minimum of four input files including time series of water temperature tem wind direction and wind speed met water surface elevation can be defined as a fixed value or provided as an input file containing a time series of surface elevation in which a reference level altitude must be defined by the user default value is zero the temporal resolution of all input parameters are linearly interpolated to match the timing and temporal resolution of the temperature measurements the user has the options to define a fixed basin length or to provide a file with the basin length for a range of directions fet wind direction is specified as the angle measured relative to true north positive clockwise and refers to the direction from which wind is coming from the depth of each water temperature sensor is defined in a separate text file sen the program allows users to choose if sensors were anchored at the lake bottom then depth will be defined as the distance between the sensor and the lake bottom or if it was attached to a floating buoy then the depth is defined as the distance between the sensor and the water surface all input data files must be tab delimited ascii files with a single header line which must be also tab delimited with the same number of columns of the file for more details about the input formats see the interwave analyzer s user manual de carvalho bueno et al 2020b additional parameters must be defined by the user in a graphical user interface gui these include the height of the wind measurements to compute the wind stress see appendix a 1 basin latitude to analyze the contribution of earth rotation on the internal seiche evolution eq 1 and a 15 and the reference altitude of the basin bottom a parameter just used for plotting purposes e g to facilitate referencing the water level to sea level height in addition the metalimnion threshold must be specified to define the criterion to divide the system into three distinct layers user adjustable parameters for filtering and spectral analysis include cutoff frequencies for band pass filters default value is the maximum and minimum internal wave frequency obtained by the multi layer model considering the fundamental internal seiche fourier window function default window is hamming and size default value is 3 days as well as the wavelet mother function default function is morlet an analysis of how these parameters may influence results of the internal wave analysis is provided in section 4 1 2 the setting defined in the gui can be saved to a file set and be imported for a new run with similar parameter definitions see the interwave analyzer s user manual for more details de carvalho bueno et al 2020b 3 3 overview and program structure interwave analyzer is an open source software that investigates the occurrence of internal waves and mixing regimes in thermal stratified basins implemented in python it calculates the physical indices listed in table 1 and plots several graphical results the program is structured into seven modules table 2 including a graphical user interface gui all information provided by the user are transferred to the main module interwave analyzer py where physical parameters are calculated and analyzed the modeling internalwave py module contains a multi layer hydrostatic linear model with free surface and shallow water assumption in which it solves problems to the first three vertical modes in addition the subprogram also provides a correction of internal wave periods caused by the coriolis effect for low frequency internal waves all results are passed over to the graph package graph package py that provides graphical output output is provided as graphs and as text files containing the parameters listed in table 1 in addition the program also provides the interwave analyzer s report a document pdf that contains an overview on physical indices and most important graphs examples of the interwave analyzer s report are presented in section 4 and a full documentation can be found in the additional material the complete source code of the interwave analyzer is available in the repository on github 1 1 https github com buenorc interwaveanalyzer and distributed under mit license the executable version available only for windows operating system can be downloaded in the interwave analyzer website 2 2 https sites google com view interwaveanalyzer interwave analyzer 4 results and discussions 4 1 case studies 4 1 1 rectangular shaped box to demonstrate the capabilities of the interwave analyzer in describing the hydrodynamics of thermally stratified water bodies forced by wind a numerical simulation of an idealized rectangular shaped basin 4 0 km long 450 m wide and 15 m deep was performed with the 3d hydrodynamic model delft3d flow which solves the shallow water momentum equations using the hydrostatic assumption delft hydraulics 2003 delft3d model has been successfully used to describe internal seiche in thermally stratified lakes dissanayake et al 2019 even though due to the reynolds averaged navier stokes approach and the hydrostatic approximation the model fails to reproduce internal wave breaking and propagating nonlinear internal waves the implemented model operated in a horizontal cartesian grid cells of 30 m 30 m and 50 fixed vertical layers eddy diffusivity and eddy viscosity were calculated using the k ε turbulence closure model the coefficients of background vertical and horizontal viscosity and diffusivity were considered as calibration coefficients and were kept fixed during the simulation heat flux at the water surface was neglected a time step of 0 1 min was used to simulate a period of 6 days the water level was kept constant along the entire basin with a two layer temperature stratification as initial condition 23 c in the epilimnion and 17 c at hypolimnion the thermocline was set located at mid depth fig 4 b we applied a wind event with a maximum speed of 10 m s blowing from east to west direction during the first hours of simulation inset figure from fig 4a the wind event lasted for 7 h and was kept 1 5 h blowing with maximum speed fig 4a the wind speed started from zero and increased linearly with a rate of 3 6 m s per hour during 2 75 h and decreasing afterwards with the same rate simulating a smooth variation of the wind at the analyzed location st fig 4 the thermocline was displaced downward during the wind event with a maximum vertical displacement of approximately 2 5 m fig 4b as soon as the wind stopped the thermocline relaxed and periodical vertical displacements with decreasing amplitude were observed during the entire period of the simulation fig 4b the temperature oscillation observed over the water column fig 4b are analyzed in terms of the temporal dynamics of isotherms the vertical displacement of the 20 c isotherm which was initially located at mid depth of the reservoir had an initial amplitude of 2 5 m just after the wind event fig 5 a the increased spreading of isotherms i e the increasing thickness of the metalimnion indicates turbulent diffusion fig 5a the temporarily averaged temperature profile shows substantial deviations from both the two layer and three layer approximations that are used for internal wave analysis fig 5b power spectral density of isotherms showed maximum spectral energy at a frequency of 2 72 10 5 hz 10 21 h the spectral peak is higher than the mean red noise spectrum for the time series at a 95 confidence level indicating a significant peak fig 6 a the temporal averaged layered profile fig 5b was used to estimate the theoretical periods of different internal wave modes using the multi layered hydrostatic model for different vertical and horizontal modes presented in section 2 1 the energetic peak observed in the power spectra was close within 7 to the theoretical period calculated for the fundamental basin scale internal wave in a two layer water column v1h1 11 h 0 6 h the estimated variability of the wave period corresponds to the variability in the basin length based on the direction of wind event the theoretical estimates of the internal wave periods are based on the temporarily averaged vertical temperature profile approximated by a multilayer structure fig 5 b the actual vertical temperature structure varies over time which causes variations in internal wave periods the sensitivity of the multi layer model to variation in water density and layer thicknesses is illustrated in fig 6b the discrepancy of 7 between observed and predicted internal wave period may be explained by the variability of thermal stratification since the density difference between the layers is lower for the averaged two layer structure the period of the internal wave is overestimated fig 6b thus for periods in which thermal stratification changes constantly the sensitivity analysis may help to identify deviation of theoretical periods of internal waves based on the wedderburn number eq 3 the program provides a classification according to the thermal stratification conditions of lakes and indicates periods at which basin scale internal seiches are more susceptible to be excited during the analyzed wind event the wedderburn number decreased to a minimum value of 1 83 when the wind is maximal indicating a regime of high amplitude internal wave activity fig 7 based on wedderburn number layer thickness and eq 10 the maximum vertical displacement associated with the wind event was estimated to be around 3 6 m this theoretical result is slightly higher than the vertical displacement observed in isotherms time series figs 5 and 7a which has a vertical displacement of approximately 2 2 m the internal seiche amplitude can be underestimated depending on the longitudinal location of the sampling point as the maximum amplitudes occur only at the boundaries in a horizontal mode one wave the theoretically estimated amplitude of the surface seiche eq 9 was 1 60 mm and agree well with amplitudes estimated by the numerical model 1 65 mm although the numerical model did not completely resolve the degeneration processes of the basin scale internal wave the degeneration regime analysis showed that the internal wave was within two regimes of degeneration viscous and nonlinear regime fig 7b this analysis indicates that internal waves could be damped by viscosity or degenerate into a train of internal solitary waves based on the analysis of temperature observations made at a single location in the simulated basin we may conclude that baroclinic effects were responsible for the observed large scale water motion and that a fundamental mode internal seiche was excited during the wind event this conclusion is confirmed by the spatially resolved thermal structure provided by the three dimensional numerical model fig 8 the shear stress exerted by the wind pushed the water surface toward the leeward shore resulting in a surface displacement due to the increase of the horizontal pressure the hypolimnion was accelerated toward the upwind direction characterizing an out of phase response between the thermocline and the water surface the following oscillatory motion matches with theoretical periods identified by the interwave analyzer fig 8 other variables and physical indices calculated by the interwave analyzer are available in the final report see additional material it should be noted that the numerical model delft3d is based on reynolds averaged navier stokes equations and cannot accurately describe turbulent fluctuations and individual overturns as they are estimated by the thorpe scale analysis the hypothetical reservoir simulated in this case study was located near the equator latitude of 5 n where internal waves are only marginally affected by earth s rotation burger number b u 11 1 considering similar stratification and geometrical conditions we tested at which latitude the interwave analyzer would indicate that earth rotation would start to play an important role on the simulated internal wave activity internal waves would start to be influenced by earth rotation just for latitude higher than 70 n or lower than 70 s where b u 1 note that this is valid only for the specific conditions considered here for a smaller density gradient the period of the internal seiche would be higher and the earth rotation effect would become important already at lower latitudes 4 1 2 vossoroca reservoir in this section we apply the interwave analyzer to observations in a subtropical reservoir the main goal is to demonstrate additional feature and to describe the influence of additional parameters that have not been presented in the previous case study vossoroca reservoir is a monomictic reservoir with an irregular dendritic shape located in south brazil 25 49 31 s 49 3 60 w it has a maximum depth of 17 m and a volume of 35 7 10 6 m 3 see de carvalho bueno 2019 for additional details water temperature was recorded every 15 min during april 2013 in the deepest region of the reservoir using seven thermistors accuracy 0 1 c the sensors were deployed at water depths of 1 3 5 7 9 and 11 m an additional sensor was anchored 1 m above the reservoir bottom fig 9 b wind speed and direction were measured with a young wind monitor accuracy 2 and 0 3 m s fig 9a the meteorological station was positioned 10 m above the water surface and data was recorded at 30 min intervals water level was sampled every 15 min in contrast to the hypothetical case analyzed in section 4 1 1 where a two layer system was forced by a single wind event in real data it is difficult to distinguish individual wind events and to relate them to internal wave activity to overcome the difficulty to classify wind events that could favor the excitation of internal seiche the analysis based on wedderburn number is useful to identify periods of potential baroclinic activity fig 10 although the classification of spigel and imberger 1980 indicates many periods of potential internal wave activity homogeneous wind events with w 20 were mainly observed on a single day april 9 fig 10 the differences between homogeneous wind events fig 10 illustrate the influence of the wind direction contribution parameter on the identification of such events the parameter must be defined by the user default is 20 c and indicates the deviation of mean wind direction that may contribute to excite internal seiches the wind speed is just added into a homogeneous wind event if the criteria of internal wave formation proposed by spigel and imberger 1980 is satisfied the increase of wind direction contribution leads to longer homogeneous wind events the choice of the value for the wind direction contribution also affects the calculation of the wedderburn number since it influences the lake length that is aligned with the wind directions varying the angle of the wind direction contribution from 5 to 40 we observed an average lake length of 2625 m 81 m corresponding to a variation of the mean wedderburn number that falls into the internal wave regime between 46 and 47 compared to variations of w between wind events it represents a small difference since w can be reduced more than 10 times after a strong wind event the period of internal wave excitation during the beginning of april 9 reduced w by 97 a variation much larger than the change associated with the uncertainty of the longitudinal extend of the basin since the wind direction contribution parameter also influences the computed wind fetch the internal wave period estimated by the hydrostatic internal seiche model also may present variation of the wave periods due to the wind fetch dependency fig 11 the power spectrum of the isotherms showed significant peaks at frequencies corresponding to period of 10 28 h the analysis was been conducted with two different fourier window functions flattop fig 11a and hamming fig 11b and c although the flattop has a broader shape both windows presented a reliable estimation of the oscillatory response of isotherms with exception of fig 11c which has poor frequency and spectral resolution due to the length of the window size chosen to analyze the influence of window size on spectral results we applied window size of 3 fig 11a and b and 1 fig 11c corresponding to frequency resolutions of 2 77 10 3 and 1 38 10 3 1 16 10 5 hz respectively to analyze more in detail high frequency spectral variance users can reduce the window size to average more numbers of segments note that this could lead to an energy loss in low frequency band depending on data length fig 11c in general a sufficient spectral resolution may be obtained with a window size of at least 7 times the analyzed oscillatory response the window can be choose according to the expected internal wave frequencies excited in the system however if the wave characteristics are not known a first candidate can be the hanning window function which has good balance between spectral energy and frequency accuracy the results from the interwave analyzer suggest that the predominant response of the reservoir to variable wind forcing is the excitation of an internal wave of the second vertical mode v2h1 fig 11 to better analyze the isotherm displacements associated with higher vertical modes interwave analyzer provides analysis of coherence and phase shift between specified isotherms fig 12 the coherence analysis between 20 c and 17 5 c isotherms indicates high coherence 0 6 near the period of the internal wave with a phase difference of 147 the small deviation from the executed phase difference of 180 could be related to the coarse spectral resolution resulting from the short period of baroclinic activity the counter cyclic displacement of the two isotherms which is indicative of an internal wave of higher vertical mode is illustrated in fig 12 based on the temperature profiles the interwave analyzer approximated the vertical temperature profile by two and three layers fig 12b to obtain the internal wave periods associated with different modes based on spigel and imberger 1980 the interwave analyzer indicates that the reservoir is under two regimes of lake mixing during the period of analysis periods of internal seiche dominance is interspersed with periods of strong stability which may not support large vertical displacement of isotherms based on horn et al 1998 the program also indicates that the excited internal seiche is more susceptible to be degenerated into a train of solitary internal waves the relatively long sampling interval of thermistors 15 min did not allow for resolving high frequency internal waves thus the suggested degeneration mechanism could not be confirmed for this data set the thorpe scale analysis did not identify temperature inversion except for near the water surface during convective mixing the lack of vertical overturns associated with internal wave breaking however could be related to the coarse vertical and temporal resolution of the thermistors the final report generated by the interwave analyzer for the analyzed period is provided in additional material 4 2 software availability and performance the interwave analyzer is free to download 3 3 https sites google com view interwaveanalyzer interwave analyzer under the mit general public licence the algorithm has been implemented in python scripting language and is available in https github com buenorc interwaveanalyzer an executable version of the code is available for windows operating systems which requires 0 72 gb of disk space and does not require installation of additional packages this version may be downloaded in interwave analyzer s website to run the python scripts the algorithm requires a minimum version number of python 3 7 and the packages numpy 1 16 3 datetime 4 0 1 reportlab 3 5 19 scipy 1 2 1 nitime 0 7 matplotlib 3 1 0 and tk tkinter 8 6 8 or compatibles versions for anaconda users anaconda software distribution 2016 the only packages that need to be installed are nitime and reportlab in appendix b we provide a step by step guide on how to install interwave analyzer the pre compiled version can be obtained in the interwave analyzer website the interwave analyzer for the case studies were ran on an intel r core tm i7 1065g7 cpu 1 30 ghz processor with 32 gb of ram we used a version number of python 3 7 6 bundled with anaconda 3 0 running the program in the ipython console version 7 16 1 the analysis of the rectangular shaped basin presented in section 4 1 1 analyzed 5 days of simulation with a temporal resolution of 1 min and 50 layers and took 5 min to analyze and generate the output data for field data from vossoroca reservoir the program took a total of 4 min to analyze a period of 9 days with 15 min time resolution the program loaded 16 mb of data including the time series files tem met niv sen the program provided 16 mb of results including graphs figures and one report initially we ran the script directly in the anaconda distribution the processing took less than 2 min for the same configuration we also tested the executable version which took approximately 1 min to complete other tests were ran to identify the program performance for larger data sets for an analysis of two and three months of data recorded from vossoroca reservoir the program took 27 min and 1 h 45 min respectively 5 conclusion an open software tool with an intuitive graphical user interface for investigating internal waves in lakes and reservoir has been presented the interwave analyzer provides a set of tools for estimating physical indices from time series of water temperature and wind velocity the analysis reveals information about internal seiche formation including higher vertical modes wind wave resonance internal wave amplitude internal seiche degeneration lake mixing wedderburn number including an effective wedderburn number which is filtered by the wind direction users without access to a python interpreter can also use the software through a pre compiled version exe which requires only the input files for the analysis we demonstrated potential applications of the interwave analyzer as a post processing tool for numerical simulations and for analyzing field measurements the interwave analyzer has been designed to increase the accessibility to state of the art theoretical and empirical knowledge on physical limnology the analysis results can make important contributions to interdisciplinary studies analyzing linkages between internal wave dynamics and water quality or biogeochemical cycling in aquatic ecosystems declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was financed in part by the coordenacão de aperfeiçoamento de pessoas de nivel superior brasil capes finance code 001 rcb thanks capes for the scholarships tb acknowledges the productivity stipend from the national council for scientific and technological development cnpq grant no 308758 2017 0 call 12 2017 appendix additional calculation a 1 wind parameters the friction velocity of the wind is computed as in read et al 2011 a 1 u σ w ρ e in which the ρ e is the mean water density in the epilimnion kg m 3 and σ w is the wind shear stress n m 2 the shear stress can be estimated from bulk atmospheric scaling as wüest and lorke 2003 a 2 σ w c d ρ a i r u 10 2 in which ρ air 1 225 kg m 3 is the density of air u 10 is the wind speed measured at 10 m above the water surface and c d is the surface drag coefficient c d 1 0 10 3 for u 5 m s c d 1 5 10 3 for u 5 m s a 2 thermocline depth and metalimnion boundaries the thermocline depth z τ is estimated using a similar procedure as described by read et al 2011 which is based on the vertical derivative of measured temperature profiles a 3 z τ z j 1 γ γ γ z j γ γ γ in which a 4 γ z j z j 2 2 ρ j 1 ρ j z j z j 1 ρ j 2 ρ j 1 z j 1 z j 2 and a 5 γ z j 1 z j 1 2 ρ j 1 ρ j z j z j 1 ρ j ρ j 1 z j 1 z j in which the index j index refers to that position of discrete measurements along the vertical profile for which the maximum density gradient was observed between j and j 1 ρ j and z j indicates the density and depth of discrete measurements as an initial guess the upper boundary of the metalimnion is defined as the depth at which the observed density gradients fall below the metalimnion threshold value δ min for the first time starting from the thermocline depth upward the value is subsequently refined by taking the density gradients at the upper and lower boundary into account a 6 z e z i z i 1 2 0 5 δ min ϱ ˆ z i 1 z i 1 δ ϱ e ˆ in which δ ϱ e ˆ ϱ ˆ ρ i 1 ρ i z i 1 z i and ϱ ˆ ρ i ρ i 1 z i z i 1 similarly the lower boundary of the metalimnion is defined by the same procedure as for the upper boundary except that the first occurrence of density gradients below the metalimnion threshold is estimated from the thermocline depth downward a 7 z h z i 1 z i 2 2 0 5 δ m i n δ ϱ h ˆ ϱ ˆ z i z i 2 δ ϱ h ˆ in which ϱ h ˆ is given as δ ϱ h ˆ ϱ ˆ ρ i 1 ρ i 2 z i 1 z i 2 a 3 mean wind direction the wind direction is averaged following grange 2014 firstly the wind vector components is calculated by u t u sin θ t v t u sin θ t in which u is the wind speed θ is the wind direction adjusted from the nautical coordination radians and t indicates the time average the mean wind direction θ is obtained as a 8 θ arctan u v f in which f 180 when the first argument of equation a 8 is lower than 180 and f 180 when the first argument is grater than 180 a 4 equation of state water density is calculated according to chen and millero 1986 assuming negligible contributions of pressure and solutes a 9 ρ τ a 0 a 1 τ a 2 τ 2 a 3 τ 3 a 4 τ 4 a 5 τ 5 in which ρ is the water density expressed in kg m 3 τ is the water temperature in c and a 0 999 84 kg m 3 a 1 6 794 kg m 3 c a 2 9 095 kg m 3 c 2 a 3 1 002 kg m 3 c 3 a 4 1 120 kg m 3 c 4 a 5 6 536 kg m 3 c 5 a 5 multi layer internal wave model the inviscid linearized one dimensional momentum equation for layer i is given by a 10 u i t 1 ρ i p i x 0 in which ρ is the water density p is the hydrostatic pressure and the subscript i varies between 1 and n where n is the maximum layer number the linearized equation describing mass conservation in layer i is obtained through the expansion the non dimensional mass conservation equation in a taylor series considering a i λ where a is the wave amplitude and λ is the wave length a 11 1 j 1 t ζ i ζ i 1 h i u i x 0 in which ζ is the interfacial displacement and h i and u i are the thickness and long velocity of layer i respectively the subscript j is used to account the contribution of other layers on layer i combining equations 23 and 24 to eliminate u gives a 12 2 t 2 ζ i ζ i 1 g h i n j 1 ρ i j ρ i 2 x 2 ζ i ζ i 1 0 where ρ i j is the density of the layer i when j i whilst for j i the ρ i j ρ j the wave equation a 12 is a second order partial differential equation system by simplification the equation reduces to a second order linear ordinary differential equation which is a classical sturm liouville eigenvalue problem combining the horizontal eigenvalue problem with the phase speed yields the dispersion relation a 13 ω n m 2 c p 2 4 π 2 λ m 2 where ω is the angular frequency of the wave c p 2 g β n is the phase speed of vertical mode n and the λ m is the wave length of horizontal mode m considering the lateral boundary condition of a basin the dispersion relation equation a 13 in terms of the internal wave period t n m becomes a 14 t n m λ c p 2 l m g β n in which l is the basin length that is aligned with the wind direction and λ 2 l m is the wave length obtained from the vertical boundaries conditions each solution of equation a 14 represents a different vertical n and horizontal m mode interwave analyzer just presents solutions for the first three vertical baroclinic modes considering the system division explained in appendixes a 2 and a 6 to account for the effect of coriolis force a correction for the eigenfrequencies of the basin is applied sutherland 2010 a 15 ω n m 2 g β n k x 2 k y 2 ω o 2 in which ω o 2 ωsin φ is the inertial angular frequency where ω 7 2921 10 5 rad s is the rotation rate of the earth and φ is the latitude k x and k y are the wave numbers for x and y component respectively a 6 decomposition model the model decomposition is used to define the thermal structure for higher vertical modes v 2 the solution is obtained through the linear internal wave equation a 16 2 φ z 2 k 2 n 2 z ω 2 ω 2 φ 0 in which φ is the potential velocity n is the buoyancy frequency k is the wavenumber and ω is the wave frequency equation a 16 is solved considering the rigid lid boundary conditions in which φ 0 at vertical boundaries the discretized version can be write with a tri diagonal matrix d a 17 d φ c 2 φ where c is the eigenvalues to be determined the solution provides theoretical velocity structure for basin scale internal wave modes based on vertical nodes v 0 the program calculates the thickness of each layer the number of internal seiche modes is limited by the number of sensor deployed in the thermistor chain a 7 spectral analysis interwave analyzer estimates the power spectral density based on welch s method welch 1967 which computes an estimate of the psd by dividing the time series into overlapping segments the psd can be obtained though the ratio of sampling frequency and the mean square power spectrum of each segment which is obtained though the fourier transform of the auto covariance function a 18 φ f f ω φ f f t s t s n f f n 2 in which φ f f ω is the psd of the function f n φ f f is mean square power spectrum of the function f n t s is the sampling period and n is the signal length to obtain the psd the φ f f ω is averaged powered by two and normalized by the frequency bandwidth to obtain the power spectral density of the signal the coherence and phase lag between two signals can be obtained using the mean square power spectrum of each signal and the cross power spectrum φ f g considering two signals f and g the coherence is given as a 19 c f g ω φ f g ω φ f f ω φ g g ω 2 0 1 in which φ f g is the cross power spectral density cpsd of signal f n and g n and φ f f and φ g g are the mean square power spectrum of functions f n and g n respectively the phase lag between two signals f and g in radians for each frequency is estimated by the cross power spectrum φ f g a 20 p f g ω r φ f g i φ f g π π b running interwave analyzer in a python interpreter the steps below describes the installation instruction for anaconda s users we recommend the use of the anaconda distribution since it automatically installs almost all required additional python packages interwave analyzer also can be ran through other python interpreters but additional packages must be installed for more details and other ways to install and run interwave analyzer see the interwave analyzer user manual de carvalho bueno et al 2020b to run interwave analyzer s scripts directly in anaconda interpreter first download the anaconda distribution for python 3 x go to anaconda website https www anaconda com and find the option for anaconda distribution choose the python 3 x graphical installer version note that there are three options for operating system windows macos and linux install the anaconda interpreter after the installation open the anaconda prompt as administrator and install the following packages that are used by interwave analyzer and are not available in anaconda nitime 0 7 or compatible conda install c conda forge nitime reportlab 3 5 or compatible conda install c anaconda reportlab attention if you already have anaconda installed in your computer make sure that the above packages are installed and the anaconda version has python 3 x if you use another interpreter make sure that the following packages are installed in the your python interpreter numpy 1 16 3 datetime 4 0 1 reportlab 3 5 19 scipy 1 2 1 nitime 0 7 matplotlib 3 1 0 and tk tkinter 8 6 8 or compatibles versions after the installation go to interwave analyzer website and click on code repository or access directly our repository 4 4 https github com buenorc interwaveanalyzer download all files py available to download including the raster graphics file format 0interwave png and interwave ico put everything in the same folder and run the script called guiexecuter py a graphical user interface gui should be launched in seconds we recommend you to download the example files 5 5 available at https sites google com view interwaveanalyzer interwave analyzer on the download example used in this publication to have a first hands on experience in use interwave analyzer for a detailed tutorial to run interwave analyzer with these files see the interwave analyzer s user manual 
25893,interwave analyzer is an open source software that provides detailed characterization of the dynamics of internal waves in lakes and reservoirs it is based on well established theories and empirical knowledge on internal waves and lake mixing and facilitates a general physical classification of lakes and reservoirs as input data the program requires time series of water temperature from various depths and meteorological data which can be obtained from measurements or numerical models interwave analyzer performs an in depth analysis of periodic motion by spectral analysis to identify predominant internal wave periods to facilitate the identification of wave modes the software is coupled with a multi layer model interwave analyzer is a powerful easily accessible and universal tool which can be used for obtaining detailed understanding lake hydrodynamics not only in physical sciences but also in the context of water quality ecological interactions and biogeochemical fluxes in aquatic ecosystems keywords interwave analyzer lake modeling instrumented buoy internal wave spectrum spectral analysis isotherm fluctuation internal wave model lake mixing software availability software name interwave analyzer version 1 00 3 hardware requirements pc system requirements windows linux mac program language python program size 360 kb license mit availability https github com buenorc interwaveanalyzer git 1 introduction although reservoirs and lakes are often classified as standing or stagnant water bodies the water in these ecosystem is not motionless there are numerous forces that can generate water motion mortimer 1974 imberger 2013 osborne 2000 wüest and lorke 2003 fig 1 wind stress at the water surface can excite propagating surface waves and near surface drift currents surface cooling results in convective flows and the inflow of water having a different temperature may promote the formation and propagation of gravity currents water currents and mixing processes in lakes and reservoirs interact with vertical density stratification which may develop in response to surface heating and inflows having different temperature or salinity boehrer and schultze 2008 while stable density stratification suppresses vertical turbulent mixing and the exchange of heat and solutes between layers having different density it gives rise to an additional type of flow baroclinic flows which depend on vertical variations of water density often occur as internal waves which cause a periodic displacement of layers with different density mortimer 1974 internal waves are generated by wind shear and are among the most important phenomena that drive water currents in the interior of stratified lakes and reservoirs mortimer 1952 umlauf and lemmin 2005 bouffard et al 2012 although just a small fraction of the total wind energy crosses the surface boundary layer wetzel 2001 wüest and lorke 2003 wüest et al 2000 roughly 20 of energy that passes through the surface boundary layer can be found in internal wave motions in closed water bodies bouffard and boegman 2012 these waves are often excited in the form of basin scale standing waves also called internal seiches saggio and imberger 1998 wang et al 2000 internal waves have been demonstrated to affect aquatic ecosystems and biogeochemical cycling in stratified lakes and reservoirs by displacing phytoplankton and zooplankton organisms mortimer and horn 1982 rinke et al 2007 causing sediment resuspension sakai et al 2002 and regulating the availability of oxygen in the water column umlauf and lemmin 2005 as well as in the sediment lorke et al 2003 frindte et al 2013 laboratory experiments and field observations revealed that internal wave energy is cascaded to smaller scales of turbulence due to the interaction with the bathymetry and nonlinear steepening of internal seiches generating trains of nonlinear internal waves boegman et al 2003 2005 this energy flux path is considered as an important component of mixing processes in stratified lakes although basin scale internal waves can contain more than 98 of the wave energy shoaling and breaking of internal waves and generation of turbulence is practically restricted to high frequency waves observations in thermally stratified lakes have suggested that more than 80 of the available potential energy of large scale internal waves is transferred to high frequency waves or dissipated into heat during the first wave period stevens et al 1996 water motions in stratified systems are often analyzed in terms of dimensionless numbers which describe dynamic equilibria between the kinetic energy and inertial forces associated with water currents in relation to the potential energy or the buoyancy forces caused by vertical density stratification shintani et al 2010 the required parameters can be obtained in the field using instrumented buoys such as thermistor chains and meteorological stations or they can be obtained from numerical models recent advances in sensor technology and numerical models lead to more widespread availability of high frequency data which can be used to detect internal waves and to estimate or to predict their implications for water quality lorke et al 2006 bouffard and lemmin 2013 simpson et al 2011 although a variety of numbers and parameters describing the baroclinic response of stratified lakes have been formulated based on well established theories and empirical relations many details of their application to field observations are site specific a unified framework for processing field observations and for a quantitative characterization of internal wave activity is currently lacking only recently a powerful open source tool for calculating lake mixing and stratification indices the lake analyzer has been developed read et al 2011 while the lake analyzer provides a broad range of different physical parameters it does not include the characterization of internal waves the aim of this paper is to describe and to demonstrate the efficiency of a new open source tool the interwave analyzer the software provides a detailed characterization of lake mixing and internal wave activity by deriving important physical indices and lake classification based on well established theories horn et al 2001 boegman et al 2005 spigel and imberger 1980 de carvalho bueno et al 2020a the interwave analyzer facilitates a consistent methodology for analyzing data from lake monitoring buoys and numerical models periodic motions are explored by fourier and wavelet transforms which have been widely used in studies on internal waves in lakes de carvalho bueno et al 2020a hutter 2011 münnich et al 1992 interwave analyzer provides a general classification of lake mixing dynamics de carvalho bueno et al 2020a spigel and imberger 1980 which can be used without special knowledge in fluid dynamics e g in interdisciplinary studies analyzing links between internal wave dynamics with water quality and biogeochemical studies for users specialized in environmental fluid dynamics the program analyses wind resonance phenomena münnich et al 1992 vidal and casamitjana 2008 internal seiche growth energy distribution in the internal wave spectrum excitation of higher vertical modes degeneration of internal seiches horn et al 2001 boegman et al 2005 and density inversions in section 2 we present the theoretical background that is implemented in the software including details about established theories and internal wave models we provide information about the program structure input data data processing and output results in section 3 the application and the physical interpretation of results provided by the software are described for two case studies in section 4 the first case study demonstrates the efficiency of the interwave analyzer to describe the evolution of basin scale internal waves using data from a three dimensional numerical model delft3d flow delft hydraulics 2003 in a second case study we processed field measurements from a reservoir and provide more detailed explanations of the influence of user defined parameters on the final results generated by the interwave analyzer 2 internal wave dynamics and mixing classification 2 1 modal model for basin scale internal waves basin scale internal waves internal seiches in a stratified fluid can be approximated by a finite number of eigenvalues having characteristic periods t n m münnich et al 1992 the different periods belong to different patterns of standing waves having n nodes in the vertical and m nodes along the horizontal direction of an idealized rectangular basin commonly referred as v n h m internal wave vertical density stratification is approximated by a number of layers of thickness h i with each having a constant density ρ i where the number of layers determines the maximum number of vertical modes fig 2 the possible periods of standing basin scale internal waves in such idealized system can be obtained by numerical solution of the corresponding eigenvalues by further applying the shallow water and the hydrostatic pressure approximations münnich et al 1992 this solution is presented in appendix a 5 in large basins and at high latitudes internal waves can be affected by coriolis force lemmin et al 2005 bernhardt and kirillin 2013 the potential effect is described by the burger number which represents the squared ratio of the internal rossby radius of deformation r d c p f o where c p is the internal seiche phase speed f o is the coriolis frequency and the basin length l 1 b u r d l 2 for a burger number larger than unity gravity force dominates and the modal model described above is fully applicable for burger numbers smaller than unity the internal waves are affected by earth s rotation and the mathematical formulation of the multi layer system has to be extended sutherland 2010 2 2 wave generation and mixing the stability of stratified shear flows is described by the dimensionless richardson number r i which relates buoyancy to shear forces for small r i 1 the system is susceptible to mixing since work against buoyancy force is small compared to the production turbulent kinetic energy large values of r i indicate that the flow is more stable and consequently less susceptible to vertical mixing depending on the scale and the type of flow r i can be expressed in a variety of different formulations when it is related to the wind stress applied at the water surface of a two layers of constant density epilimnion and hypolimnion it is expressed as the bulk mixed layer richardson number as 2 r i g h e κ w 2 in which h e is the epilimnion thickness w is the friction velocity of the wind and κ 0 4 is the von kármán constant g g δ ρ ρ h is the reduced gravity where g is the acceleration of gravity ρ h is the hypolimnion water density and δ ρ is the density difference between the hypolimnion and epilimnion the bulk richardson number has been found to be a good indicator of baroclinic activity in stratified lakes and reservoirs spigel and imberger 1980 shintani et al 2010 de carvalho bueno et al 2020a based on the richardson number thompson 1980 proposed a normalization to account for the finite longitudinal dimension of the basin the normalization was named the wedderburn number and is expressed as 3 w r i h e l in which h e is the epilimnion thickness and l is the basin length that is aligned with the wind direction the wedderburn number represents the ratio between the wind stress and horizontal pressure gradients due to vertical displacement of the thermocline i e the interface between the two layers of constant density it is related to the longitudinal tilt of the thermocline in response to wind shear the wedderburn number formed the basis of a classification scheme of lake dynamics in terms of four different regimes spigel and imberger 1980 strong mixing steep tilt of the thermocline followed by mixing higher amplitude internal waves dominance and buoyancy dominance fig 3a when w h e l strong mixing regime r i 1 mixing occurs faster than the time required for the formation of billows however observations in different lakes have identified complete mixing events even when w h e l steep thermocline tilt followed by mixing mortimer 1952 1955 thorpe 1978 in this intermediate regime although the mixing does not occur instantaneously vertical displacement is accompanied by billows and interfacial shear that eventually leads to complete mixing of the system this regime persists until w 0 5 h h h for larger values of w the lake remains stably stratified despite the formation of basin scale internal waves in the buoyancy dominated regime i e if 4 w l h 4 h e h h the density stratification is too strong to support larger vertical displacement of the thermocline and only small amplitude internal waves are susceptible to be excited observations have identified that high amplitude internal seiches are often generated between w 1 and 20 stevens et al 1996 roget et al 1993 heaps and ramsbottom 1966 stevens and lawrence 1997 münnich et al 1992 the wedderburn number has also be used to characterize the degeneration of internal seiches horn et al 1998 2001 boegman et al 2005 dorostkar and boegman 2013 the disintegration of basin scale internal waves can be classified into five different regimes damped linear wave degeneration into propagating solitary internal waves kelvin helmholtz instabilities bores and billows and super flow fig 3a each regime is based on the analysis of timescales if the amplitude of an internal seiche is too small for strong shear instability and supercritical regime it is damped by viscosity or by nonlinear effects including wave steepening which can result into the generation of propagating solitary internal waves the transition from damped linear waves to the formation of solitary internal waves regimes occurs when the dissipative timescale is proportional to the steepening timescale which gives that 5 ζ h e ν t v 1 h 1 3 h π ν t v 1 h 1 1 h e h 2 1 δ h h e h 1 2 h e h in which ζ is the initial wave amplitude h e is the epilimnion thickness ν is the kinematic viscosity t v 1 h 1 is the fundamental internal seiche period h is the total water depth and δ h is the metalimnion thickness if the amplitude of the basin scale internal wave is large and its period long compared to the timescale of supercritical flow the flow may become supercritical with froude number f r 1 the transition is characterized by hydraulic jumps bores which are accompanied by strong vertical mixing the formation of supercritical flows that degenerate the basin scale internal waves into bores occurs if 6 ζ h e 1 h e h 2 h e h 3 1 h e h 3 large amplitude internal waves for which the instability timescale is smaller than the internal wave period the shear across the thermocline may generate kelvin helmholtz billows if the local r i is lower than 0 25 the ratio of the stability timescale to the internal wave period can be expressed as 7 ζ h e 2 δ h h h h e 1 if equations 6 and 7 are satisfied both degeneration mechanisms can occur simultaneously which leads to formation of bores and kelvin helmholtz billows fig 3a based on field observations laboratory experiments numerical and theoretical models the wedderburn number has been related for predicting the initial vertical displacement of the thermocline in a two layer system exposed to a steady wind thompson 1980 8 ζ k h e w in which k o 1 is a constant where often k 0 5 stevens and lawrence 1997 the amplitude of the basin scale internal wave ζ eq 8 which corresponds to the maximum displacement of the thermocline is related to the maximum displacement of the water surface initial surface seiche amplitude η o fig 2 9 η o ζ δ ρ ρ h where δ ρ ρ h ρ e is the difference between the density of the epilimnion ρ e and the density in the hypolimnion ρ h eq 8 has been extended to account for total water depth and the effects of the lake boundaries lake bottom and water surface de carvalho bueno et al 2020a 10 ζ o h e k 1 exp w k 2 2 f 2 in which k 1 0 1 and k 2 6 are empirical constants and f is a non dimensional function of the total water depth h and epilimnion and hypolimnion thickness de carvalho bueno et al 2020a 11 f h e h α h e h exp h e h 2 0 125 where α 12 h e h 3 15 7 h e h 2 2 8 h e h 2 1 and was determined empirically the extended equation improves the parameterization of the basin scale internal waves in cases of w 5 fig 3b resonance effects can play an important role on the amplitudes of internal seiches if the period of a basin scale interval wave is similar to that of a periodic wind forcing e g diel variations in wind velocity resonance with wind forcing have been also suggested as a facilitator to generate higher amplitude waves and higher vertical modes münnich et al 1992 antenucci and imberger 2003 boegman and ivey 2012 these effects however are not accounted for in the above parameterizations a parameter that characterizes the vertical mixing events in measured temperature profiles with fast response thermistors is the thorpe displacement length d t thorpe 1977 12 d t z i z j in which z i is the depth of the monotonically decreasing vertical temperature profile and z j is the depth of the measured water temperature it provides indication of periods larger scale vertical overturns as they occur in strong billows although small scale temperature inversions resulting from overturning motions are difficult to be resolved due to slow response time of thermistors their absolute measurement accuracy critical for most temperature loggers and coarse vertical distribution of sensors the thorpe scale can provide information about the convective mixing observed near the water surface brainerd and gregg 1995 3 methods 3 1 input data processing the water density is calculated from user provided time series of water temperature measured at fixed depths using the equation of state for freshwater chen and millero 1986 the contribution of salinity suspended particles and pressure on water density are neglected this simplification has been used in many studies investigating internal wave activity in thermally stratified lakes and reservoirs mortimer 1979 vidal et al 2007 bernhardt and kirillin 2013 guyennon et al 2014 based on the vertical profile of mean density the software divides the water column into different layers for a two layer internal wave model the water column is divided into two layers of constant density in which the density gradient at the interface between both layers is defined as the thermocline the thermocline depth is calculated by weighting the magnitudes of the difference between the maximum calculated density change and the adjacent measurements this method has been described in detailed by read et al 2011 and significantly improves the initial guess that the thermocline is located in the middle between of the two sampling depths with the largest density difference similarly based on the temperature gradients between two neighboring thermistors the program estimates the metalimnion thickness to divide the water column into three distinct layers these procedures are described in detail in appendix a 2 for analysis with more than 3 layers the density profile is divided based on nodes found by the mode decomposition model for more details see appendix a 6 the maximum number of layers is corresponds to the number of sampling depths divided by two for each layer the average water density is calculated internal seiche period is calculated by solving the modal multi layer model the model is presented in details in appendix a 5 the interwave analyzer provides solutions for different vertical and horizontal modes considering different division of the vertical density profile interwave analyzer also provides a sensitivity analysis to evaluate how the internal wave periods are changing due to the variation of the thickness and water density in the layers during the measured time series the algorithm computes the deviation of internal wave periods considering variations of ρ h ρ h ρ e 4 and h e h h h 0 1 interwave analyzer also indicates the maximum and minimum variability of layer thickness and water density considering the analyzed data in addition the program provides a sensitivity analysis for the user provided value of metalimnion threshold this parameter is used to specify the minimum density gradient to define the metalimnion boundaries used to estimate the three layer system appendix a 2 provides a schematic representation of the metalimnion threshold parameter the sensitivity analysis of this parameter provides an indication on how this parameter may influence the period of the second vertical mode interwave analyzer uses two methods of spectral analysis fourier and wavelet transforms to identify internal wave periods in temperature time series and in time series of isothermal depths isothermal depths are determined for specified temperatures by linear interpolation of temperature signals measured at different depths power spectral density is estimated using welch s method thomson and emery 2014 prior to fourier analysis and spectral averaging segments of the time series are weighted by a window function hamming hanning blackman or flattop window functions the segment size can be specified by the user but can also be calculated automatically according to the fundamental internal wave period estimated by the internal wave model in this case the program considers a segment length corresponding to 10 times the v1h1 period for fourier analysis this automatic analysis is just recommended to detect internal seiches of the first vertical mode the overlap percentage between neighboring segments is defined as 50 for all window functions the significance of the spectral peaks is estimated by comparing their amplitude to the mean red noise spectrum estimated from the time series through a qui square test with 95 confidence interval bernhardt and kirillin 2013 interwave analyzer also offers methods to detect coherence and phase shifts of isotherm displacements cross spectral density of two selected isotherms which facilitates the identification of higher vertical modes and internal wave resonance with the wind pannard et al 2011 antenucci et al 2000 vidal et al 2005 saggio and imberger 1998 a band pass filter is used in the program to isolate frequency components of variations in isothermal depth a fourth order butterworth filter is implemented as a series of second order filters with transpose direct form ii smith 2007 the cutoff frequencies which define the frequency bandwidth of interest must be specified by the user the program also identifies the most energetic fluctuation of the analyzed isotherms however depending on the specified isotherms and measurement location the amplitude provided by the program can be strongly underestimated the wavelet transform is used to facilitate analyses of isothermal depth and temperature time series in the time and the frequency domain simultaneously the procedure is applied according to techniques described by torrence and compo 1998 three options of mother wavelet functions are implemented morlet paul and dog more details about the calculation procedures used to identify internal waves through spectral analysis is presented in appendix a 7 since the period of internal seiche is fetch dependent and wind fetch may also vary according to the wind direction interwave analyzer calculates the wind fetch as time series based on the wind direction and the basin length along this direction the program calculates the mean wind direction and based on a user specified range of directions around this mean value it identifies the variability of wind fetch for the analyzed period the maximum and minimum values of the wind fetch are used to compute a range of internal wave periods to facilitate the identification and analyses of internal seiches all physical indices described in section 2 2 are calculated the wedderburn number w eq 3 is considered wind fetch dependent and described as a mean value as well as time series previous studies showed that the consistency of wind direction and speed are crucial for describing the formation of internal seiche stevens and imberger 1996 valerio et al 2017 gaudard et al 2017 observations have suggested that the wedderburn number is underestimated to describe the formation of internal seiche because of variations in wind direction the program includes a filter for the identification of homogeneous wind events the filtered values of w implemented in the interwave analyzer takes into account the calculated periods of consecutive wind events based on wind direction contribution the software indicates periods of constant wind events which could be a potential period for internal seiche activity the interwave analyzer identifies wind events based on the wind tolerance angle specified by users to avoid an influence of temporal resolution of wind measurements the homogeneous wind events are computed through a convolution based on the internal seiche period 1 8 t v 1 h 1 based in the same principle the program also estimates an effective wedderburn number which takes into account the mean direction of the wind event w efe gaudard et al 2017 13 w efe w f dur 2 in which f dur 2 4 t wind t v 1 h 1 is the duration factor t wind is the duration of homogeneous wind events t v 1 h 1 the fundamental internal wave period l is the basin length that is aligned with the wind direction h e is the epilimnion thickness and w is the non filtered wedderburn number the internal seiche amplitudes are estimated following de carvalho bueno et al 2020a and spigel and imberger 1980 the corresponding surface seiche amplitude is computed eq 9 thorpe scales are calculated according to eq 12 the most important calculations provided by the interwave analyzer are summarized in table 1 3 2 input data and configuration the interwave analyzer requires a minimum of four input files including time series of water temperature tem wind direction and wind speed met water surface elevation can be defined as a fixed value or provided as an input file containing a time series of surface elevation in which a reference level altitude must be defined by the user default value is zero the temporal resolution of all input parameters are linearly interpolated to match the timing and temporal resolution of the temperature measurements the user has the options to define a fixed basin length or to provide a file with the basin length for a range of directions fet wind direction is specified as the angle measured relative to true north positive clockwise and refers to the direction from which wind is coming from the depth of each water temperature sensor is defined in a separate text file sen the program allows users to choose if sensors were anchored at the lake bottom then depth will be defined as the distance between the sensor and the lake bottom or if it was attached to a floating buoy then the depth is defined as the distance between the sensor and the water surface all input data files must be tab delimited ascii files with a single header line which must be also tab delimited with the same number of columns of the file for more details about the input formats see the interwave analyzer s user manual de carvalho bueno et al 2020b additional parameters must be defined by the user in a graphical user interface gui these include the height of the wind measurements to compute the wind stress see appendix a 1 basin latitude to analyze the contribution of earth rotation on the internal seiche evolution eq 1 and a 15 and the reference altitude of the basin bottom a parameter just used for plotting purposes e g to facilitate referencing the water level to sea level height in addition the metalimnion threshold must be specified to define the criterion to divide the system into three distinct layers user adjustable parameters for filtering and spectral analysis include cutoff frequencies for band pass filters default value is the maximum and minimum internal wave frequency obtained by the multi layer model considering the fundamental internal seiche fourier window function default window is hamming and size default value is 3 days as well as the wavelet mother function default function is morlet an analysis of how these parameters may influence results of the internal wave analysis is provided in section 4 1 2 the setting defined in the gui can be saved to a file set and be imported for a new run with similar parameter definitions see the interwave analyzer s user manual for more details de carvalho bueno et al 2020b 3 3 overview and program structure interwave analyzer is an open source software that investigates the occurrence of internal waves and mixing regimes in thermal stratified basins implemented in python it calculates the physical indices listed in table 1 and plots several graphical results the program is structured into seven modules table 2 including a graphical user interface gui all information provided by the user are transferred to the main module interwave analyzer py where physical parameters are calculated and analyzed the modeling internalwave py module contains a multi layer hydrostatic linear model with free surface and shallow water assumption in which it solves problems to the first three vertical modes in addition the subprogram also provides a correction of internal wave periods caused by the coriolis effect for low frequency internal waves all results are passed over to the graph package graph package py that provides graphical output output is provided as graphs and as text files containing the parameters listed in table 1 in addition the program also provides the interwave analyzer s report a document pdf that contains an overview on physical indices and most important graphs examples of the interwave analyzer s report are presented in section 4 and a full documentation can be found in the additional material the complete source code of the interwave analyzer is available in the repository on github 1 1 https github com buenorc interwaveanalyzer and distributed under mit license the executable version available only for windows operating system can be downloaded in the interwave analyzer website 2 2 https sites google com view interwaveanalyzer interwave analyzer 4 results and discussions 4 1 case studies 4 1 1 rectangular shaped box to demonstrate the capabilities of the interwave analyzer in describing the hydrodynamics of thermally stratified water bodies forced by wind a numerical simulation of an idealized rectangular shaped basin 4 0 km long 450 m wide and 15 m deep was performed with the 3d hydrodynamic model delft3d flow which solves the shallow water momentum equations using the hydrostatic assumption delft hydraulics 2003 delft3d model has been successfully used to describe internal seiche in thermally stratified lakes dissanayake et al 2019 even though due to the reynolds averaged navier stokes approach and the hydrostatic approximation the model fails to reproduce internal wave breaking and propagating nonlinear internal waves the implemented model operated in a horizontal cartesian grid cells of 30 m 30 m and 50 fixed vertical layers eddy diffusivity and eddy viscosity were calculated using the k ε turbulence closure model the coefficients of background vertical and horizontal viscosity and diffusivity were considered as calibration coefficients and were kept fixed during the simulation heat flux at the water surface was neglected a time step of 0 1 min was used to simulate a period of 6 days the water level was kept constant along the entire basin with a two layer temperature stratification as initial condition 23 c in the epilimnion and 17 c at hypolimnion the thermocline was set located at mid depth fig 4 b we applied a wind event with a maximum speed of 10 m s blowing from east to west direction during the first hours of simulation inset figure from fig 4a the wind event lasted for 7 h and was kept 1 5 h blowing with maximum speed fig 4a the wind speed started from zero and increased linearly with a rate of 3 6 m s per hour during 2 75 h and decreasing afterwards with the same rate simulating a smooth variation of the wind at the analyzed location st fig 4 the thermocline was displaced downward during the wind event with a maximum vertical displacement of approximately 2 5 m fig 4b as soon as the wind stopped the thermocline relaxed and periodical vertical displacements with decreasing amplitude were observed during the entire period of the simulation fig 4b the temperature oscillation observed over the water column fig 4b are analyzed in terms of the temporal dynamics of isotherms the vertical displacement of the 20 c isotherm which was initially located at mid depth of the reservoir had an initial amplitude of 2 5 m just after the wind event fig 5 a the increased spreading of isotherms i e the increasing thickness of the metalimnion indicates turbulent diffusion fig 5a the temporarily averaged temperature profile shows substantial deviations from both the two layer and three layer approximations that are used for internal wave analysis fig 5b power spectral density of isotherms showed maximum spectral energy at a frequency of 2 72 10 5 hz 10 21 h the spectral peak is higher than the mean red noise spectrum for the time series at a 95 confidence level indicating a significant peak fig 6 a the temporal averaged layered profile fig 5b was used to estimate the theoretical periods of different internal wave modes using the multi layered hydrostatic model for different vertical and horizontal modes presented in section 2 1 the energetic peak observed in the power spectra was close within 7 to the theoretical period calculated for the fundamental basin scale internal wave in a two layer water column v1h1 11 h 0 6 h the estimated variability of the wave period corresponds to the variability in the basin length based on the direction of wind event the theoretical estimates of the internal wave periods are based on the temporarily averaged vertical temperature profile approximated by a multilayer structure fig 5 b the actual vertical temperature structure varies over time which causes variations in internal wave periods the sensitivity of the multi layer model to variation in water density and layer thicknesses is illustrated in fig 6b the discrepancy of 7 between observed and predicted internal wave period may be explained by the variability of thermal stratification since the density difference between the layers is lower for the averaged two layer structure the period of the internal wave is overestimated fig 6b thus for periods in which thermal stratification changes constantly the sensitivity analysis may help to identify deviation of theoretical periods of internal waves based on the wedderburn number eq 3 the program provides a classification according to the thermal stratification conditions of lakes and indicates periods at which basin scale internal seiches are more susceptible to be excited during the analyzed wind event the wedderburn number decreased to a minimum value of 1 83 when the wind is maximal indicating a regime of high amplitude internal wave activity fig 7 based on wedderburn number layer thickness and eq 10 the maximum vertical displacement associated with the wind event was estimated to be around 3 6 m this theoretical result is slightly higher than the vertical displacement observed in isotherms time series figs 5 and 7a which has a vertical displacement of approximately 2 2 m the internal seiche amplitude can be underestimated depending on the longitudinal location of the sampling point as the maximum amplitudes occur only at the boundaries in a horizontal mode one wave the theoretically estimated amplitude of the surface seiche eq 9 was 1 60 mm and agree well with amplitudes estimated by the numerical model 1 65 mm although the numerical model did not completely resolve the degeneration processes of the basin scale internal wave the degeneration regime analysis showed that the internal wave was within two regimes of degeneration viscous and nonlinear regime fig 7b this analysis indicates that internal waves could be damped by viscosity or degenerate into a train of internal solitary waves based on the analysis of temperature observations made at a single location in the simulated basin we may conclude that baroclinic effects were responsible for the observed large scale water motion and that a fundamental mode internal seiche was excited during the wind event this conclusion is confirmed by the spatially resolved thermal structure provided by the three dimensional numerical model fig 8 the shear stress exerted by the wind pushed the water surface toward the leeward shore resulting in a surface displacement due to the increase of the horizontal pressure the hypolimnion was accelerated toward the upwind direction characterizing an out of phase response between the thermocline and the water surface the following oscillatory motion matches with theoretical periods identified by the interwave analyzer fig 8 other variables and physical indices calculated by the interwave analyzer are available in the final report see additional material it should be noted that the numerical model delft3d is based on reynolds averaged navier stokes equations and cannot accurately describe turbulent fluctuations and individual overturns as they are estimated by the thorpe scale analysis the hypothetical reservoir simulated in this case study was located near the equator latitude of 5 n where internal waves are only marginally affected by earth s rotation burger number b u 11 1 considering similar stratification and geometrical conditions we tested at which latitude the interwave analyzer would indicate that earth rotation would start to play an important role on the simulated internal wave activity internal waves would start to be influenced by earth rotation just for latitude higher than 70 n or lower than 70 s where b u 1 note that this is valid only for the specific conditions considered here for a smaller density gradient the period of the internal seiche would be higher and the earth rotation effect would become important already at lower latitudes 4 1 2 vossoroca reservoir in this section we apply the interwave analyzer to observations in a subtropical reservoir the main goal is to demonstrate additional feature and to describe the influence of additional parameters that have not been presented in the previous case study vossoroca reservoir is a monomictic reservoir with an irregular dendritic shape located in south brazil 25 49 31 s 49 3 60 w it has a maximum depth of 17 m and a volume of 35 7 10 6 m 3 see de carvalho bueno 2019 for additional details water temperature was recorded every 15 min during april 2013 in the deepest region of the reservoir using seven thermistors accuracy 0 1 c the sensors were deployed at water depths of 1 3 5 7 9 and 11 m an additional sensor was anchored 1 m above the reservoir bottom fig 9 b wind speed and direction were measured with a young wind monitor accuracy 2 and 0 3 m s fig 9a the meteorological station was positioned 10 m above the water surface and data was recorded at 30 min intervals water level was sampled every 15 min in contrast to the hypothetical case analyzed in section 4 1 1 where a two layer system was forced by a single wind event in real data it is difficult to distinguish individual wind events and to relate them to internal wave activity to overcome the difficulty to classify wind events that could favor the excitation of internal seiche the analysis based on wedderburn number is useful to identify periods of potential baroclinic activity fig 10 although the classification of spigel and imberger 1980 indicates many periods of potential internal wave activity homogeneous wind events with w 20 were mainly observed on a single day april 9 fig 10 the differences between homogeneous wind events fig 10 illustrate the influence of the wind direction contribution parameter on the identification of such events the parameter must be defined by the user default is 20 c and indicates the deviation of mean wind direction that may contribute to excite internal seiches the wind speed is just added into a homogeneous wind event if the criteria of internal wave formation proposed by spigel and imberger 1980 is satisfied the increase of wind direction contribution leads to longer homogeneous wind events the choice of the value for the wind direction contribution also affects the calculation of the wedderburn number since it influences the lake length that is aligned with the wind directions varying the angle of the wind direction contribution from 5 to 40 we observed an average lake length of 2625 m 81 m corresponding to a variation of the mean wedderburn number that falls into the internal wave regime between 46 and 47 compared to variations of w between wind events it represents a small difference since w can be reduced more than 10 times after a strong wind event the period of internal wave excitation during the beginning of april 9 reduced w by 97 a variation much larger than the change associated with the uncertainty of the longitudinal extend of the basin since the wind direction contribution parameter also influences the computed wind fetch the internal wave period estimated by the hydrostatic internal seiche model also may present variation of the wave periods due to the wind fetch dependency fig 11 the power spectrum of the isotherms showed significant peaks at frequencies corresponding to period of 10 28 h the analysis was been conducted with two different fourier window functions flattop fig 11a and hamming fig 11b and c although the flattop has a broader shape both windows presented a reliable estimation of the oscillatory response of isotherms with exception of fig 11c which has poor frequency and spectral resolution due to the length of the window size chosen to analyze the influence of window size on spectral results we applied window size of 3 fig 11a and b and 1 fig 11c corresponding to frequency resolutions of 2 77 10 3 and 1 38 10 3 1 16 10 5 hz respectively to analyze more in detail high frequency spectral variance users can reduce the window size to average more numbers of segments note that this could lead to an energy loss in low frequency band depending on data length fig 11c in general a sufficient spectral resolution may be obtained with a window size of at least 7 times the analyzed oscillatory response the window can be choose according to the expected internal wave frequencies excited in the system however if the wave characteristics are not known a first candidate can be the hanning window function which has good balance between spectral energy and frequency accuracy the results from the interwave analyzer suggest that the predominant response of the reservoir to variable wind forcing is the excitation of an internal wave of the second vertical mode v2h1 fig 11 to better analyze the isotherm displacements associated with higher vertical modes interwave analyzer provides analysis of coherence and phase shift between specified isotherms fig 12 the coherence analysis between 20 c and 17 5 c isotherms indicates high coherence 0 6 near the period of the internal wave with a phase difference of 147 the small deviation from the executed phase difference of 180 could be related to the coarse spectral resolution resulting from the short period of baroclinic activity the counter cyclic displacement of the two isotherms which is indicative of an internal wave of higher vertical mode is illustrated in fig 12 based on the temperature profiles the interwave analyzer approximated the vertical temperature profile by two and three layers fig 12b to obtain the internal wave periods associated with different modes based on spigel and imberger 1980 the interwave analyzer indicates that the reservoir is under two regimes of lake mixing during the period of analysis periods of internal seiche dominance is interspersed with periods of strong stability which may not support large vertical displacement of isotherms based on horn et al 1998 the program also indicates that the excited internal seiche is more susceptible to be degenerated into a train of solitary internal waves the relatively long sampling interval of thermistors 15 min did not allow for resolving high frequency internal waves thus the suggested degeneration mechanism could not be confirmed for this data set the thorpe scale analysis did not identify temperature inversion except for near the water surface during convective mixing the lack of vertical overturns associated with internal wave breaking however could be related to the coarse vertical and temporal resolution of the thermistors the final report generated by the interwave analyzer for the analyzed period is provided in additional material 4 2 software availability and performance the interwave analyzer is free to download 3 3 https sites google com view interwaveanalyzer interwave analyzer under the mit general public licence the algorithm has been implemented in python scripting language and is available in https github com buenorc interwaveanalyzer an executable version of the code is available for windows operating systems which requires 0 72 gb of disk space and does not require installation of additional packages this version may be downloaded in interwave analyzer s website to run the python scripts the algorithm requires a minimum version number of python 3 7 and the packages numpy 1 16 3 datetime 4 0 1 reportlab 3 5 19 scipy 1 2 1 nitime 0 7 matplotlib 3 1 0 and tk tkinter 8 6 8 or compatibles versions for anaconda users anaconda software distribution 2016 the only packages that need to be installed are nitime and reportlab in appendix b we provide a step by step guide on how to install interwave analyzer the pre compiled version can be obtained in the interwave analyzer website the interwave analyzer for the case studies were ran on an intel r core tm i7 1065g7 cpu 1 30 ghz processor with 32 gb of ram we used a version number of python 3 7 6 bundled with anaconda 3 0 running the program in the ipython console version 7 16 1 the analysis of the rectangular shaped basin presented in section 4 1 1 analyzed 5 days of simulation with a temporal resolution of 1 min and 50 layers and took 5 min to analyze and generate the output data for field data from vossoroca reservoir the program took a total of 4 min to analyze a period of 9 days with 15 min time resolution the program loaded 16 mb of data including the time series files tem met niv sen the program provided 16 mb of results including graphs figures and one report initially we ran the script directly in the anaconda distribution the processing took less than 2 min for the same configuration we also tested the executable version which took approximately 1 min to complete other tests were ran to identify the program performance for larger data sets for an analysis of two and three months of data recorded from vossoroca reservoir the program took 27 min and 1 h 45 min respectively 5 conclusion an open software tool with an intuitive graphical user interface for investigating internal waves in lakes and reservoir has been presented the interwave analyzer provides a set of tools for estimating physical indices from time series of water temperature and wind velocity the analysis reveals information about internal seiche formation including higher vertical modes wind wave resonance internal wave amplitude internal seiche degeneration lake mixing wedderburn number including an effective wedderburn number which is filtered by the wind direction users without access to a python interpreter can also use the software through a pre compiled version exe which requires only the input files for the analysis we demonstrated potential applications of the interwave analyzer as a post processing tool for numerical simulations and for analyzing field measurements the interwave analyzer has been designed to increase the accessibility to state of the art theoretical and empirical knowledge on physical limnology the analysis results can make important contributions to interdisciplinary studies analyzing linkages between internal wave dynamics and water quality or biogeochemical cycling in aquatic ecosystems declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was financed in part by the coordenacão de aperfeiçoamento de pessoas de nivel superior brasil capes finance code 001 rcb thanks capes for the scholarships tb acknowledges the productivity stipend from the national council for scientific and technological development cnpq grant no 308758 2017 0 call 12 2017 appendix additional calculation a 1 wind parameters the friction velocity of the wind is computed as in read et al 2011 a 1 u σ w ρ e in which the ρ e is the mean water density in the epilimnion kg m 3 and σ w is the wind shear stress n m 2 the shear stress can be estimated from bulk atmospheric scaling as wüest and lorke 2003 a 2 σ w c d ρ a i r u 10 2 in which ρ air 1 225 kg m 3 is the density of air u 10 is the wind speed measured at 10 m above the water surface and c d is the surface drag coefficient c d 1 0 10 3 for u 5 m s c d 1 5 10 3 for u 5 m s a 2 thermocline depth and metalimnion boundaries the thermocline depth z τ is estimated using a similar procedure as described by read et al 2011 which is based on the vertical derivative of measured temperature profiles a 3 z τ z j 1 γ γ γ z j γ γ γ in which a 4 γ z j z j 2 2 ρ j 1 ρ j z j z j 1 ρ j 2 ρ j 1 z j 1 z j 2 and a 5 γ z j 1 z j 1 2 ρ j 1 ρ j z j z j 1 ρ j ρ j 1 z j 1 z j in which the index j index refers to that position of discrete measurements along the vertical profile for which the maximum density gradient was observed between j and j 1 ρ j and z j indicates the density and depth of discrete measurements as an initial guess the upper boundary of the metalimnion is defined as the depth at which the observed density gradients fall below the metalimnion threshold value δ min for the first time starting from the thermocline depth upward the value is subsequently refined by taking the density gradients at the upper and lower boundary into account a 6 z e z i z i 1 2 0 5 δ min ϱ ˆ z i 1 z i 1 δ ϱ e ˆ in which δ ϱ e ˆ ϱ ˆ ρ i 1 ρ i z i 1 z i and ϱ ˆ ρ i ρ i 1 z i z i 1 similarly the lower boundary of the metalimnion is defined by the same procedure as for the upper boundary except that the first occurrence of density gradients below the metalimnion threshold is estimated from the thermocline depth downward a 7 z h z i 1 z i 2 2 0 5 δ m i n δ ϱ h ˆ ϱ ˆ z i z i 2 δ ϱ h ˆ in which ϱ h ˆ is given as δ ϱ h ˆ ϱ ˆ ρ i 1 ρ i 2 z i 1 z i 2 a 3 mean wind direction the wind direction is averaged following grange 2014 firstly the wind vector components is calculated by u t u sin θ t v t u sin θ t in which u is the wind speed θ is the wind direction adjusted from the nautical coordination radians and t indicates the time average the mean wind direction θ is obtained as a 8 θ arctan u v f in which f 180 when the first argument of equation a 8 is lower than 180 and f 180 when the first argument is grater than 180 a 4 equation of state water density is calculated according to chen and millero 1986 assuming negligible contributions of pressure and solutes a 9 ρ τ a 0 a 1 τ a 2 τ 2 a 3 τ 3 a 4 τ 4 a 5 τ 5 in which ρ is the water density expressed in kg m 3 τ is the water temperature in c and a 0 999 84 kg m 3 a 1 6 794 kg m 3 c a 2 9 095 kg m 3 c 2 a 3 1 002 kg m 3 c 3 a 4 1 120 kg m 3 c 4 a 5 6 536 kg m 3 c 5 a 5 multi layer internal wave model the inviscid linearized one dimensional momentum equation for layer i is given by a 10 u i t 1 ρ i p i x 0 in which ρ is the water density p is the hydrostatic pressure and the subscript i varies between 1 and n where n is the maximum layer number the linearized equation describing mass conservation in layer i is obtained through the expansion the non dimensional mass conservation equation in a taylor series considering a i λ where a is the wave amplitude and λ is the wave length a 11 1 j 1 t ζ i ζ i 1 h i u i x 0 in which ζ is the interfacial displacement and h i and u i are the thickness and long velocity of layer i respectively the subscript j is used to account the contribution of other layers on layer i combining equations 23 and 24 to eliminate u gives a 12 2 t 2 ζ i ζ i 1 g h i n j 1 ρ i j ρ i 2 x 2 ζ i ζ i 1 0 where ρ i j is the density of the layer i when j i whilst for j i the ρ i j ρ j the wave equation a 12 is a second order partial differential equation system by simplification the equation reduces to a second order linear ordinary differential equation which is a classical sturm liouville eigenvalue problem combining the horizontal eigenvalue problem with the phase speed yields the dispersion relation a 13 ω n m 2 c p 2 4 π 2 λ m 2 where ω is the angular frequency of the wave c p 2 g β n is the phase speed of vertical mode n and the λ m is the wave length of horizontal mode m considering the lateral boundary condition of a basin the dispersion relation equation a 13 in terms of the internal wave period t n m becomes a 14 t n m λ c p 2 l m g β n in which l is the basin length that is aligned with the wind direction and λ 2 l m is the wave length obtained from the vertical boundaries conditions each solution of equation a 14 represents a different vertical n and horizontal m mode interwave analyzer just presents solutions for the first three vertical baroclinic modes considering the system division explained in appendixes a 2 and a 6 to account for the effect of coriolis force a correction for the eigenfrequencies of the basin is applied sutherland 2010 a 15 ω n m 2 g β n k x 2 k y 2 ω o 2 in which ω o 2 ωsin φ is the inertial angular frequency where ω 7 2921 10 5 rad s is the rotation rate of the earth and φ is the latitude k x and k y are the wave numbers for x and y component respectively a 6 decomposition model the model decomposition is used to define the thermal structure for higher vertical modes v 2 the solution is obtained through the linear internal wave equation a 16 2 φ z 2 k 2 n 2 z ω 2 ω 2 φ 0 in which φ is the potential velocity n is the buoyancy frequency k is the wavenumber and ω is the wave frequency equation a 16 is solved considering the rigid lid boundary conditions in which φ 0 at vertical boundaries the discretized version can be write with a tri diagonal matrix d a 17 d φ c 2 φ where c is the eigenvalues to be determined the solution provides theoretical velocity structure for basin scale internal wave modes based on vertical nodes v 0 the program calculates the thickness of each layer the number of internal seiche modes is limited by the number of sensor deployed in the thermistor chain a 7 spectral analysis interwave analyzer estimates the power spectral density based on welch s method welch 1967 which computes an estimate of the psd by dividing the time series into overlapping segments the psd can be obtained though the ratio of sampling frequency and the mean square power spectrum of each segment which is obtained though the fourier transform of the auto covariance function a 18 φ f f ω φ f f t s t s n f f n 2 in which φ f f ω is the psd of the function f n φ f f is mean square power spectrum of the function f n t s is the sampling period and n is the signal length to obtain the psd the φ f f ω is averaged powered by two and normalized by the frequency bandwidth to obtain the power spectral density of the signal the coherence and phase lag between two signals can be obtained using the mean square power spectrum of each signal and the cross power spectrum φ f g considering two signals f and g the coherence is given as a 19 c f g ω φ f g ω φ f f ω φ g g ω 2 0 1 in which φ f g is the cross power spectral density cpsd of signal f n and g n and φ f f and φ g g are the mean square power spectrum of functions f n and g n respectively the phase lag between two signals f and g in radians for each frequency is estimated by the cross power spectrum φ f g a 20 p f g ω r φ f g i φ f g π π b running interwave analyzer in a python interpreter the steps below describes the installation instruction for anaconda s users we recommend the use of the anaconda distribution since it automatically installs almost all required additional python packages interwave analyzer also can be ran through other python interpreters but additional packages must be installed for more details and other ways to install and run interwave analyzer see the interwave analyzer user manual de carvalho bueno et al 2020b to run interwave analyzer s scripts directly in anaconda interpreter first download the anaconda distribution for python 3 x go to anaconda website https www anaconda com and find the option for anaconda distribution choose the python 3 x graphical installer version note that there are three options for operating system windows macos and linux install the anaconda interpreter after the installation open the anaconda prompt as administrator and install the following packages that are used by interwave analyzer and are not available in anaconda nitime 0 7 or compatible conda install c conda forge nitime reportlab 3 5 or compatible conda install c anaconda reportlab attention if you already have anaconda installed in your computer make sure that the above packages are installed and the anaconda version has python 3 x if you use another interpreter make sure that the following packages are installed in the your python interpreter numpy 1 16 3 datetime 4 0 1 reportlab 3 5 19 scipy 1 2 1 nitime 0 7 matplotlib 3 1 0 and tk tkinter 8 6 8 or compatibles versions after the installation go to interwave analyzer website and click on code repository or access directly our repository 4 4 https github com buenorc interwaveanalyzer download all files py available to download including the raster graphics file format 0interwave png and interwave ico put everything in the same folder and run the script called guiexecuter py a graphical user interface gui should be launched in seconds we recommend you to download the example files 5 5 available at https sites google com view interwaveanalyzer interwave analyzer on the download example used in this publication to have a first hands on experience in use interwave analyzer for a detailed tutorial to run interwave analyzer with these files see the interwave analyzer s user manual 
25894,in the majority of eu member states agricultural land is expected to decrease not only due to land use changes in favour of urban expansion and afforestation but also to land abandonment processes the knowledge on location and extent of agricultural land abandonment is relevant for estimating local external effects and adapting policy interventions currently multi level land use models are able to capture determined processes of demand driven redevelopment however land abandonment is much more difficult to capture because of its more ambiguous definition and the lack of data on its spatial distribution this paper presents a method to explicitly model agricultural abandonment as a choice of disinvestment which in turn is embedded in a utility based land use modelling framework that projects land use changes for the eu and the uk validation exercises using observed spatial distribution of abandoned farmland show that the proposed method allows to model abandonment with acceptable accuracy keywords agricultural land abandonment territorial modelling eu reference scenario european risk map validation 1 introduction in europe the abandonment of agricultural lands has been an important land use change process at least since the 19th century mather 2001 it still is a topical issue reflecting the post war and post soviet trends of rural depopulation and loss of competitive advantages in the rural economy baldock et al 1996 prishchepov et al 2012 and is particularly problematic in mountainous remote and semiarid areas macdonald et al 2000 benayas et al 2007 a problem that is pervasive in the land abandonment literature is the difficulty of defining identifying and observing the process at hand indeed agricultural land abandonment can be defined in many different ways 1 1 see for instance definition of abandoned agricultural land in hart et al 2013 referred to actual abandonment semi abandonment or hidden abandonment and transitional abandonment pointereau et al 2008 or corbelle rico and crecente maseda 2008 in terres et al 2015 farmland abandonment was defined as a cessassion of land management which leads to undesirable changes in biodiversity and ecosystems services but commonly refers to land that was previously used to grow crops or for grazing does not have farming functions anymore i e a total cessation of agricultural activities and has not been converted to forest or artificial areas either hart et al 2013 pointereau et al 2008 fao 2006 many factors are involved in this complex and multi dimensional phenomenon that is primarily triggered by low productivity and land degradation and occurs more often in remote and mountainous regions with soil or climate conditions that are unfavourable for agriculture secondary drivers such as rural depopulation socio economic factors policies or inefficient farm structure can further accelerate land abandonment van der zanden et al 2017 lasanta et al 2016 the abandonment of agricultural land can cause undesirable environmental socio economic and landscape impacts for instance biodiversity loss landscape homogenization increased fire risk soil erosion and soil degradation as well as increase of the area of agriculture intensification keenleyside and tucker 2010 hart et al 2013 lasanta et al 2016 however agricultural abandonment does not only entail a higher pressure on biodiversity and natural resources but also causes decline of local agricultural incomes and employment and is thus directly linked to population dynamics especially in mountainous or remote rural areas the loss of agricultural income aggravates often already weak economic and social structures european union 2013 in addition agricultural land abandonment is linked to the loss of local agricultural practices and knowledge gellrich et al 2007 baldock et al 1996 on the other hand where agricultural abandonment coincides with favourable climate and soil conditions it can lead to environmentally valuable natural succession this re vegetation process may entail important positive benefits such as improving soil organic matter content stabilisation of soils carbon sequestration regulation of water flow and habitat restoration with an improvement in species number and biodiversity corbelle rico and crecente maseda 2008 estel et al 2015 all in all the trade offs between positive or negative impacts that can result from abandoning agricultural land are largely site specific depending on the geographic location and related biophysical conditions cultural heritage environmental political and socio economic preferences hart et al 2013 verburg et al 2009 in many countries in europe the potentially negative impacts of agricultural abandonment have been addressed via a broader set of policy instruments that aim to alleviate the negative consequences or even reverse abandonment trends in its early stages for decades the european union eu has been intervening in agricultural markets with specific payment schemes dedicated to marginal farming areas eliasson et al 2010 keenleyside and tucker 2010 koomen et al 2008 the less favoured areas lfa and more recently the areas facing natural or other specific constraints anc support schemes have been providing compensation to farmers who continue to farm despite unfavourable conditions ec 2005 eu 2013 in addition supportive national legislations are crucial to tackle the land abandonment problem as national legislators are typically more informed on local characteristics and needs corbelle rico and crecente maseda 2008 during the last decades considerable effort has been put in mapping quantifying and assessing the major impacts and drivers that entail abandonment land processes some studies on land abandonment focused on concepts and drivers highlighting the importance of environmental socio economic and farm management factors corbelle rico and crecente maseda 2008 fao 2006 benayas et al 2007 garcía ruiz and lana renault 2011 keenleyside and tucker 2010 terres et al 2015 lasanta et al 2016 while others have been centred on the efficiency of policy measures macdonald et al 2000 walford 2002 renwick et al 2013 corbelle rico and crecente maseda 2014 positive and negative consequences of land abandonment as already mentioned are another recurrent topic baldock et al 1996 macdonald et al 2000 van der zanden et al 2017 nainggolan et al 2012 often applied to case studies located in mediterranean europe 2 2 spain italy france greece portugal although it is possible to find studies on land abandonment in most of the eu countries germany the netherlands poland etc which refer to local or regional scales and mountainous areas falcucci et al 2007 poyatos et al 2003 etienne et al 2003 lasanta et al 2016 macdonald et al 2000 corbelle rico et al 2012 recently other studies have used remote sensing estel et al 2018 alcantara et al 2013 to distinguish productive fallow and recultivated farmland those studies have done so at european and global scales respectively by calculating ndvi time series from different satellite sensors at high spatial resolution given the political relevance of agricultural abandonment in europe an estimate of where and how much abandonment will happen in the future would be useful unfortunately so far less attention has been given to modelling techniques to obtain estimates of future abandonment locations typically developed in existing spatially dynamic modelling systems previous studies built different scenarios in order to explore possible future developments and impacts and were based mostly on econometric techniques nowicki et al 2006 westhoek et al 2006 verburg and overmars 2009 meiyappan et al 2014 price et al 2015 van der zanden et al 2017 these existing models mainly attempt to analyse trends and changes in landscape and spatial patterns over time but are relatively limited with regard to the representation of the agricultural land abandonment process keenleyside and tucker 2010 other location models for farmland abandonment are based on the assumption that abandonment likely occurs where local suitability for agricultural practices is relatively low verburg and overmars 2009 meiyappan et al 2014 recent works suggest however that marginalization of agriculture is not only driven by poor biophysical characteristics or lack of demand for produce abandonment of agricultural land as an economic resource typically occurs when it has ceased to generate sufficient income flows and the available options within the restraints of farmers knowledge and capacities for adjusting resource use farming practices or farm structure have been exhausted macdonald et al 2000 thus other structural and monetary factors that affect farmers income and abilities also play a decisive role for instance the farmers age and qualification existing subsidy schemes and differential competitive advantages among rural regions a more refined method to model locations of farmland abandonment is called for the paper at hand presents a method to explicitly model future local agricultural abandonment processes as a result of economic decisions on the use of land within an integrative spatially dynamic land use modelling framework the implementation of the method is illustrated with the luisa territorial modelling platform a model that dynamically simulates population land use and accessibility changes across the eu and the uk the united kingdom at a 100 m resolution in order to assess local and cross policy externalities future land use trends and major drivers of land abandonment are simulated under the eu territorial reference scenario 2017 jacobs crisioni et al 2017 the territorial assessment of agricultural abandonment trends and its associated impacts is presented at national regional nuts3 and grid level for all eu countries and the uk up to 2030 in addition a method to quantify land use cover flows is used to represent the main transitions between land uses that are simulated in particular this paper presents aggregated land conversions that according to the introduced model procedure supersede agricultural abandonment perpiña castillo et al 2018 2019 the rest of this paper is structured as follows firstly we briefly introduce the general land use modelling framework of luisa section 2 1 then we further describe the method for deriving the european risk map of agricultural land abandonment section 2 2 section 2 3 describes agricultural abandonment as part of a utility based land use modelling framework as well as outlines the future projections for agricultural land abandonment up to 2030 section 2 4 describes the method for validating the proposed modelling approach in section 3 the main outcomes of the study are presented and analysed and finally section 4 and 5 summarises and discusses the main points of the proposed method versus other studies 2 material and methods within the luisa modelling framework land abandonment is thus conceptualised as a temporary phenomenon that may happening even without demand reduction as a consequence of a transition of the agricultural production system towards an optimal spatial distribution section 2 1 and 2 2 a combination of factors is assumed to be involved in agricultural land abandonment land use competition biophysical conditions agricultural economics farm structure demographic and geographical factors are all expected to play a role section 2 3 1 2 3 2 and 2 3 3 these individual factors are first represented in maps using a variety of data sources and then integrated together to build a composite map of agricultural land abandonment risk for the whole eu and the uk at a fine resolution from 2015 to 2030 section 2 3 4 this risk map is then used within the luisa model as a compound local driver for simulating agricultural abandonment processes given a set of regional demands for land based functions and activities as it is explained in the next section 2 1 luisa territorial modelling platform agricultural land and its abandonment luisa is a pan european modelling platform 3 3 links to luisa web platform european commission joint research centre urban data platform http urban jrc ec europa eu territorial dashboard http urban jrc ec europa eu t board index htmlstrat board http urban jrc ec europa eu strat boardt pedia http urban jrc ec europa eu t pedia that provides alternative scenarios of territorial development in order to understand the local impacts and externalities of eu trends and policies the current configuration the eu territorial reference scenario 2017 integrates the most recent and accurate information available including past and future time series of socio economic and environmental aspects it also accounts for existing european policies and legislation e g common agricultural policy renewable energies trans european transport network eu biodiversity strategies and protection of natura 2000 areas for a more detailed account on luisa modelling framework and data sources we refer to jacobs crisioni et al 2017 for a comprehensive description of luisa s territorial reference scenario 2017 see appendix a discrete land use changes in luisa are modelled by optimizing the expected local utility values for land uses optimization is constrained by the available land in a region and by input expectations on total land area in the region that is needed by the modelled land uses a key input thus considers projected regional demand for agricultural land these demand projections are obtained from the 2016 capri baseline 4 4 2016 capri baseline was provided by the ec jrc directorate sustainable resource economics of agriculture unit jrc d 04 which integrates main policy macro economic and market assumptions up to 2030 while being consistent with the eu agricultural outlook 2016 2026 european commission 2016 agricultural demand is imposed in luisa as land area required for the expected production of food feed and energy crops and is expressed through a number of agricultural land classes that are aggregations of capri commodities the following systems are identified arable farming including rice livestock grazing systems mixed crop livestock production permanent crops and bioenergy crops jacobs crisioni et al 2017 perpiña castillo et al 2016 given regional demand for agricultural land and other land uses a dedicated discrete allocation mechanism available in the open source geodms software 2019 iteratively adapts the local utility until land use distributions are found that satisfy the modelling constraints hilferink and rietveld 1999 the underlying assumption is that grid cells function as implicit agents who change the use of their land if opportune in terms of utility and regional demand choosing from the bounded set of land use options that are modelled land based functions require investments with a long term time horizon utility is therefore computed as the net present value npv 5 5 npv is a standard method used in capital budgeting to appraise long term investments by measuring discounted time series of expected cash inflows and outflows while taking into account the time value of money of that land cover at a specific location to be regarded as economically attractive an investment should have a strictly non negative npv for all land uses utility is estimated in a spatially explicit way given local and global parameters similarly to the approach proposed by koomen et al 2015 and diogo et al 2015 1 n p v r i t y n r r t c t 1 d t y where i are the initial investment costs in ha e g land clearing demolition costs building costs acquiring agricultural machinery r r t are the annual gross revenues for raster cell r in year t in ha obtained from e g rental income revenues from selling crops subsidies c t are annual costs in ha e g maintenance costs field operations in agriculture n is the investment time horizon in years d is the discount rate the time horizon annual costs and discount rates are held fixed in the model regardless of location and modelling time initial investment costs do depend on the existing land cover in a specific location as the existing physical make up of a location may call for clearing or demolition operations revenues are highly dependent on location being calculated as follows 2 r r t s r t max r t where s r t the local suitability i e the percentage of maximum revenue to be obtained from a specific land use at a given location defined as the probability that a particular land cover exists given a set of geographic variable values and estimated through binomial logistic regression analyses on observed land cover patterns per country max r t is the maximum revenues in ha i e the annual revenues that are assumed to be obtained from a particular land use in case the local suitability is optimal i e s r t 100 the computed npvs are implemented in the allocation algorithm by employing a logit type approach derived from discrete choice theory mcfadden 1978 discrete choice theory aims to explain and predict the outcome of decision making process of economic agents when choosing among mutually exclusive alternatives the discrete choice model assigns probabilities for the different alternatives according to the utility of those alternatives in relation to the total utility of all alternatives when applying this model in a spatially explicit way the probability of choosing among mutually exclusive land based activities in a given location is computed as follows 3 x r i e β u r i k 1 k e β u r k where x r i is the probability of alternative land use i being chosen in raster cell r u r i is the utility of alternative i in raster cell r i e the npv of that activity in that particular location u k i is the utility of alternative k in raster cell r k is a finite number of mutually exclusive alternatives for land based activities and β is a parameter to adjust the model sensitivity typically 1 as default value 2 2 modelling future agricultural land abandonment in luisa the extent location and timing of farmland abandonment is modelled in three separate classes namely through abandoned arable crops permanent crops and fields used for livestock to do so both local likeliness and regional expectations of abandonment need to be provided for every 5 years model step expectations on future regional agricultural abandonment are dynamically quantified for each modelled country separately based on expected shares of land abandonment those were quantified based on per annum percentual losses of utilized agricultural area uaa as observed in corine land cover between 2000 and 2012 and are further supported by the reference values taken from the modelling exercises presented in van der zanden et al 2017 in every modelling time step percentage loss is converted into an absolute expected loss of area using prior total agricultural area and assigned a maximum and minimum value range in order to have sufficient degrees of freedom for the model to find an optimal solution at the local level abandonment is simulated in luisa s utility optimization approach as an alternative choice available to all grid cells that are currently used as agricultural land this approach thus considers abandonment a separate disinvestment decision that may be the highest utility outcome in specific locations and contexts so called allow rules govern which transitions between land uses are permitted within the simulation they are imputed in the model by imposing that the npv values for a non allowed transition are below the minimum threshold of the discrete allocation method so that effectively disallowed transitions are not considered through such allow rules only agricultural land types can become abandoned agricultural land while previously abandoned agricultural land can be converted into any land use type residential forestry etc save other abandoned land classes in a subsequent time step agricultural revenue and cost estimates were obtained from ustaoglu et al 2016 abandonment is modelled through assuming zero cost and a small fraction of the agricultural revenue to proxy revenues from disinvestment as a comprehensive eu wide map of agricultural abandonment is unavailable similar functions could not be induced for abandonment probability from empirically observed land use patterns an agricultural abandonment risk map has therefore been deduced by quantifying and mapping relationships found in previous studies see next section 2 3 2 3 european risk map of agricultural land abandonment the risk map 6 6 the risk map of agricultural land abandonment represents the probability of occurrence in terms of modelling is considered as suitability map and however partially responsible of the spatial allocation of future abandonment the risk map covers the eu and the uk of agricultural land abandonment is created by combining many factors into three groups related to biophysical agricultural socio economical and demographic and geographic factors table 1 these factor groups are defined by adapting and combining several methods from the recent literature benayas et al 2007 pointereau et al 2008 confalonieri et al 2014 terres et al 2015 lasanta et al 2016 levers et al 2018 each factor corresponds to a spatial thematic layer or statistical information at regional level from different data sources see appendix b table b 1 table b 2 and table b 3 the factor groups are further detailed in the next sections 2 3 1 biophysical factors a set of nine factors dealing with soil climate and terrain criteria 7 7 see table b1 appendix b for more detailed information is selected to determine where constraining natural conditions occur reflecting guidelines from eu regulation no 1305 2013 european union 2013 eliasson et al 2010 annex iii biophysical criteria for delimitation of areas facing natural constraints for generic agricultural activities the selected constraining conditions are expected to increase the risk of land abandonment this is spatially represented by merging the nine factors as a composite map of biophysical risk of abandonment appendix c fig c 1 the selection of these criteria is supported by many studies as described in alonso sarria et al 2016 and corbelle rico and crecente maseda 2014 variables such as slope precipitation and irrigated areas are relevant variables for abandonment in fact water availability is an important factor linked directly with agricultural profitability where even irrigated plots partially rely on precipitation land use is considered an important variable in relation with land abandonment in the sense that rainfed crops are more prone to abandonment than irrigated crops garcía ruiz 2010 nadal romero et al 2016 in relation to soil properties soils characterized by low nutrient content high salinity high proportion of clay and shallow soils are more prone to abandonment alonso sarría et al 2016 romero díaz et al 2017 negative multiplication effects among constraining conditions are also taken into account as proposed by terres et al 2014 although in a simplified way here locations where at least two severe limiting conditions coincide are considered to suffer severe limitations for agricultural activity thus having higher abandonment risk the values of these variables are held fixed throughout the simulation period 2 3 2 socio economic and farm structure factors economic and farm structure agricultural data is used to represent the stability viability and performance of regional agricultural systems indicating resilience against farmland abandonment these datasets are mainly gathered from fadn 8 8 the farm accountancy data network fadn is an instrument for evaluating the income of agricultural holdings and the impacts of the common agricultural policy the concept of the fadn was launched in 1965 when council regulation 79 65 established the legal basis for the organization of the network it consists of an annual survey carried out by the member states of the european union the services responsible in the union for the operation of the fadn 3 94 collect every year accountancy data from a sample of the agricultural holdings in the european union derived from national surveys the fadn is the only source of microeconomic data that is harmonized i e the bookkeeping principles are the same in all countries farm accountancy data network and dg eurostat fss 9 9 farm structure survey fss covers all agricultural holdings with an uaa of at least 1 ha or using market production as a threshold the main purpose of fss is to obtain reliable data at regular timing intervals two three years on the structure of agricultural holdings in the european union in particular in land use livestock and labour force the first time conducted was in 1966 67 approximately every ten years the fss is conducted in the form of agricultural census providing more detailed geographical levels mss transmit individual micro data to eurostat where they are stored in a database eurofarm the legal basis for the fss is regulation ec no1166 2008 of 19 november 2008 farm structure survey a harmonization exercise 10 10 harmonization process consist mainly of 1 filling gaps missing nuts3 data are filled by scaling up data from sub regions extrapolation and interpolation according to the variable 2 matching nuts3 regions between fss and fadn due to version discrepancies specifically fss used nuts3 v 2006 and fadn used v 2003 is necessary to merge fadn and fss data in a complete and consistent database the values of all variables selected here are averaged over the period 2005 2010 and subsequently considered static throughout the simulation period a normalization process is applied to facilitate comparison of results between countries table b 2 appendix b shows the main characteristics description and data source of the eight factors involved figure c 2 appendix c shows the spatial combination of economic and farm structure factors while in figure c 3 appendix c each factor is mapped individually 2 3 3 demographic and geographic regional factors two dichotomous variables are used to flag demographic and geographic factors that increase agricultural abandonment risk those variables indicate places with low population density and places that are remote appendix b table b 3 appendix c fig c 4 and c 5 areas with a population density below 50 inhabitants km2 are considered very low density areas terres et al 2015 remote areas are identified as areas that are more than 60 min driving away from the closest city or town dijkstra and poelman 2008 several studies corbelle rico and crecente maseda 2014 corbelle rico et al 2012 gellrich and zimmermann 2007 lange et al 2013 also highlight the fact that low population density and remoteness increase abandonment risk in low density areas infrastructure and public services are scarce and presumably relatively inefficient remote areas are characterized by limited economic opportunities and greater difficulties to reach markets thus agricultural activities there face higher transport cost and reduced competitiveness in luisa both local population densities a model output and travel times based on expected infrastructure investments typically change throughout the simulation period so that the demographic and geographic aspects in the compound abandonment risk map are not held fixed in the model 2 3 4 creating a compound risk map the last step for creating a compound agricultural abandonment risk map is the combination of the factor maps described in this section as table 1 shows the spatial combination is done through weighted linear addition wla with scores and weights assigned to each criterion particularly the biophysical risk map is assigned the highest weight 11 11 the biophysical factors receives the highest weight 0 4 out of 1 compared to the other two groups 0 3 out of 1 for each group following the assumption that natural constrains set the primary pre conditions for agricultural abandonment the values of the final composite risk map ranking from 0 to 100 is classified into five categories of abandonment risk following equal intervals very low 0 20 low 20 40 moderate 40 60 high 60 80 and very high 80 100 2 4 validation of the european risk map and the agricultural land abandonment a number of validation procedures were applied with the main purpose of evaluating the quality of the map in identifying either the risk of abandonment fig 1 or the projected abandonment in a specific location appendix d fig d 1 three different strategies were applied in this validation exercise a first approach entailed a comparison between the lucas 12 12 lucas land use cover area frame survey provides and harmonized land use cover statistics collected by eurostat in cooperation with the member states across the whole european union s territory in 2009 a soil module was included by the european commission tended to construct a topsoil database based on samples carried out every three years by surveyors in the field http ec europa eu eurostat web lucas data it should be noticed that in the lucas database no abandonment is observed in austria belgium denmark estonia croatia ireland the netherlands sweden and slovenia lucas database 2015 and the abandonment risk map observed abandoned land points from lucas database 389 points were overlapped with the five abandonment risk classes from the risk map in addition non abandoned agricultural points from lucas 79 769 points were also analysed in order to identify the potential abandonment risk of those furthermore the local extent of agricultural abandonment as reported in lasanta et al 2016 was compared with aggregated municipal agricultural abandonment extents as modelled in luisa lastly to verify the assumed relevance of the factor effects of which the abandonment risk map is composed a multivariate explanatory model is fitted to quantify the contribution of the selected factors to agricultural abandonment to do so all agricultural points both abandoned and not abandoned are selected from the lucas database the risk of abandonment in that subset is subsequently explained using the point values of all biophysical and economic factors table 1 with which the abandonment risk map is composed a binomial logit model eq 4 is used to estimate the effects of all variables so that 4 p a b a n d o n e d 1 exp β 0 β k x k ε where p refers to the probability of abandonment β 0 refers to the intercept β k is a vector of coefficients effect to be estimated x k refers to the independent variables and ε is the error term thus the contribution of all factors towards agricultural abandonment is quantified explicitly here all variables are defined as boolean factors where 1 true variables meet the criteria represents severe risk of agricultural abandonment and 0 represents no risk to make spatially compatible our variables in the model prediction all variables were transformed on a pixel basis 100 m resolution in raster layers 3 results 3 1 european risk map of agricultural land abandonment in 2030 almost 183 million ha of agricultural land are projected to be under different levels of potential risk of abandonment in the eu and the uk fig 1 the very large majority of that agricultural land will nevertheless be under very low 25 and low 50 risk of abandonment about 14 of the agricultural land is estimated to be under moderate risk of land abandonment this still leaves 11 and 0 4 700 kha of the agricultural land under high and very high potential risk of abandonment respectively abandonment prone areas are dispersed across europe linked to variation in the presence of risk factors biophysical factors appendix c fig c 1 appear to be the leading factor in large areas of austria poland greece spain estonia and latvia northern parts of sweden finland italy ireland southern parts of france and bulgaria particularly in regions with a mountainous character the apennines pyrenees alps dolomites carpathians the central massif in france or the iberian and cantabrian mountains considerable abandonment risk due to climate limitations is mostly found in mediterranean countries where soils suffer from drought like in greece italy spain but also in the united kingdom and scandinavia due to conditions promoting acidic and waterlogged soil conditions remoteness and low population density appear to be the major drivers of abandonment risk in the inner part of spain the middle and northern areas of sweden finland and ireland the northern and eastern parts of romania and partially in estonia latvia and lithuania hungary and cyprus appendix c fig c 4 and fig c 5 economic and structural farm factors appendix c fig c 2 and fig c 3 are primary causes for the high agricultural abandonment risk in many regions of spain the north of france greece and italy the central and northern parts of sweden and finland eastern bulgaria as well as in estonia latvia lithuania and hungary fig 2 shows shares of land under moderate high and very high risk of abandonment in proportion to regional area clearly the risk of land abandonment is not limited to mountainous areas and other vulnerable regions can be identified several regions accounting for more than 60 of the total surface under a high risk we identified in the northern part of portugal spain italy latvia estonia sweden finland austria and bulgaria 3 2 projections of agricultural land abandonment in luisa from european to local scale in the eu and the uk agricultural land is projected to be abandoned at an average rate of 373 kha per year reaching roughly 5 6 mha and accounting for approximately 3 6 of total agricultural land by 2030 arable land is expected to be the most prone to abandonment accounting for more than 70 of all abandonment in 2030 4 mha pastoral land 20 1 2 mha and permanent crops 7 400 kha make up smaller portions of total abandoned land almost a quarter 1 38 mha of all agricultural abandonment will most likely occur in mountainous areas 13 13 mountain areas have been spatially identified using the less favoured areas lfa classification map corresponding to the class named totally mountain hill areas from the spatial dataset 2000 2006 based on gisco communes version 2 4 where arable land would be the most affected agriculture system 974 kha i e 70 of all mountainous abandonment fig 3 presents absolute and relative extents of agricultural land abandonment between 2015 and 2030 spain and poland are likely to endure the most agricultural land abandonment both in absolute and relative terms spain is the only studied country expected to lose more than 1 million ha alone accounting for about 20 of all simulated losses in terms of absolute figures france germany and italy complement spain and poland in the group of the largest agricultural land abandonment in the eu altogether responsible for more than 70 of all losses conversely due to their relatively smaller total agricultural land the netherlands portugal finland greece and especially slovakia are expected to be above the 3 eu average landscapes and agricultural production systems vary considerably among eu mss and as a consequence so are national compositions of abandonment fig 4 abandonment of arable land is expected to be leading mode of abandonment in bulgaria cyprus denmark finland hungary lithuania and slovakia while abandonment of pastures will be predominant in ireland the netherlands and luxembourg permanent crops will account for a significant share albeit not predominant in southern european countries at the regional level fig 5 presents the projections of abandoned agricultural land as share of total agricultural land aggregated at nuts3 level in 2030 it confirms that spain is expected to face the biggest challenges in the eu especially in its north northwest other regions in southern europe are also likely to face significant land abandonment such as northern portugal 14 14 with the highest absolute loss of more than 27 thousand ha expected in terras de trás os montes pt11e southeastern france 15 15 nationwide the largest absolute loss of about 33 thousand ha is however projected for aveyron fr622 in southern france sardinia 16 16 projected about 48 thousand ha for sassari itg25 and 35 thousand ha for nuoro itg26 in italy and greece 17 17 korinthia el652 on the peloponnese peninsula and the island of lefkada el624 in central and northern europe substantial agricultural land abandonment is projected for western germany as well as in the northern hungary and southeastern poland where the largest absolute projected loss is found for the chelmsko zamojski region more than 85 thousand ha it is also worth noting that single regions in western austria innsbruck at332 and southern netherlands zuid limburg nl423 are expected to undergo a significant more than 30 agricultural land abandonment though this trend is not likely to spread to the surrounding regions the modelling exercise allows us to analyse agriculture land abandonment at the local scale for the whole eu territory fig 6 for illustrative purposes two zones where selected to exemplify areas affected by abandonment in spain murcia and greece karditsa northwestern from murcia city fig 6a a substantial amount of fruit trees the predominant permanent crop are expected to be abandoned however arable land is also abandoned in particular close to urban centres which is possibly related to modelled urban expansion a combination of factors seems to drive abandonment processes in this region some of the agricultural land is relatively remote more than 60 min to access the nearest town particularly in the western part this part of the region is also considered partially mountainous according to less favoured area criteria further adding to abandonment risk the murcia region is also characterized by areas with high salinity concentration and low annual precipitation the karditsa region fig 6b is characterized by farms with a moderate stability and viability increasing abandonment risk the areas of this region that are most prone to be abandoned are remote and partially or totally mountainous and in addition combine at least three biophysical factors slope higher than the range 15 30 heavy clay texture and low length of growing period that increase the risk of being abandoned this leads to substantial expected abandonment in the region mostly affecting arable land along with occasional patches of permanent crops vineyards 3 3 flows of land from agricultural land abandonment to other aggregated land uses trends of agricultural land vs abandonment analysing land use cover flows illustrate the main land use trajectories that are projected to occur within the simulation period fig 7 reveals that the conversion from agricultural land into abandoned land 4 8 mha or 2 7 of total agricultural land will dominate the inverse conversion of abandoned land for agricultural purposes 200 kha or 0 11 of abandoned land leaving a net conversion of about 4 8 million ha as loss of agriculture land at 600 kha the conversion from abandoned land into forest and natural areas is projected to be much larger entailing more than 10 of recuperation the creation of new built up areas is likely to be much less important recovering just 18 thousand ha about 0 3 of abandoned agricultural land between 2015 and 2030 comparing differences in shares agricultural land vs agricultural land abandonment from 2015 to 2030 provides important findings at the country level fig 8 some countries show simultaneous agricultural land increase and abandonment especially in portugal france greece malta spain croatia latvia cyprus and luxembourg this might indicate that agricultural production is being displaced to more productive areas within these countries however in austria czech republic germany lithuania the netherlands poland or slovakia there will be a net decrease of land occupied by agriculture so that abandoned land is not offset by increases elsewhere 3 4 validation of the european risk map of agricultural land abandonment as described in section 2 4 three different validation strategies are applied for the work at hand first we compare the risk map with observed abandoned agricultural land according to the lucas database this comparison yields that 67 7 of the total abandoned points from lucas falls within moderate high and very high categories 263 points while the remaining 32 2 corresponds to low or very low categories 126 taking into account that from the 79 769 observed non abandoned agricultural points in the lucas database only 3 6 are in high or very high risk areas it seems clear that agricultural abandonment is more likely in areas considered prone to abandonment risk second we compare local abandonment hotspots compiled by lasanta et al 2016 18 18 reported local shares of abandonment refers to the 35 study areas appendix e fig e 1 and areas modelled by luisa appendix d fig d 1 yielding considerable correspondence a summary table of the shares of land abandonment is elaborated to easily compare measured and modelled values appendix e table e 1 though herein a detailed explanation per each country is given in france 19 19 abandonment hotspots numbered as 1 2 5 8 and 10 covering the alps pre alps and central pyrenees accounting for 79 97 and 84 1 of abandonment shares respectively examples of local abandonment shares from luisa montjustin 94 ourdon 90 aspin aure 90 grust 91 claix 93 séchilienne 88 saint sigismond 95 thônes 91 avignonet 79 fouillouse 81 jarjayes 86 chèze 77 etc nuts3 regions that spatially overlap the reported mountainous areas are located in alps fr821 20 20 20 for the whole section we represent in brackets the code number of the nuts3 region or lau2 municipality and the associated abandonment share vaucluse fr826 7 hautes alpes fr822 18 hautes pyrenees fr626 4 and isere fr714 14 at municipality level lau2 the shares of abandonment dramatically increase up to 96 in sigoyer hautes alpes and the model is able to locally capture the extend and location of the reported hotspots of abandonment out of 34 overlapped municipalities 16 have an abandonment share greater than 80 similar to the abandonment reported hotspots spain 21 21 abandonment hotspots numbered as 12 13 14 15 16 18 19 21 22 and 23 are located across the cantabrian mountain central system sistema betico central pyrenees catalan prelitoral and iberian range gathers the major number of case study areas mainly due to the large distribution of mountain ranges from the north to the south within the iberian peninsula the set of nuts3 regions overlapping those reported abandonment hotspots are asturias es12 15 22 22 abandonment hotspots 12 13 and 22 with shares between 40 and 80 that correspond to the municipalities of allande teverga aller camaleño polaciones valdeolea and san roque de riomiera ranging from 38 to 53 of abandonment from luisa cantabria es13 14 guipúzcoa es212 20 madrid es300 9 23 23 abandonment hotspots numbered as 14 and 15 with shares between 75 and 89 that correspond to the municipalities of puentes viejas navarredonda y san mamés lozoyuela manzanares el real san ildefonso narrillos del álamo orihuela medinilla la carrera and piedrahita ranging from 42 to 81 shares from luisa ávila es411 8 salamanca es415 7 1 lleida es513 4 5 24 24 abandonment hotspots numbered as 18 and 21 with shares between 40 and 71 that correspond to the municipalities of torre de cabdella sort les valls d aguilar prullans la vansa i fórnols el pont de suert valderrobres monroyo castellote and villarluengo ranging from 31 to 85 rioja es230 17 5 25 25 abandonment hotspots numbered as 19 and 20 with shares between 42 and 99 that correspond to the municipalities of san asensio cenicero sotés haro tarazona borja ainzón fuendejalón and morata de jalón ranging from 33 to 81 of abandonment from luisa zaragoza es243 7 málaga es617 10 26 26 abandonment hotspots numbered as 16 and 23 with shares between 36 and 70 that correspond to the municipalities of villaluenga del rosario ronda alpujarra de la sierra nevada albondón torvizcón fiñana fondón felix lubrín macael oria and chirivel ranging from 45 to 74 of abandonment from luisa granada es614 12 almería es611 20 5 58 municipalities are analysed at local level in which abandonment shares ranging from 30 to 84 with the highest affected areas by abandonment in lleida el pont de suert 84 north of madrid navarredonda san mames and puentes viejas 80 and zaragoza borja and ainzon 80 and 81 respectively in the case of poland carpathian mountains and their surroundings areas beskid maly as well as the regions of mazovia podkarpacikie and podlaskie are identified as abandonment hotspots areas in particular nuts3 regions of chełmsko zamojski pl312 17 27 27 abandonment hotspots numbered as 6 9 32 and 36 with shares between 18 and 33 that correspond to the municipalities of skierbieszów krzczonów leśniowice krynice rybnik lyski godów proszowice koniusza and łapanów ranging from 31 to 64 of abandonment from luisa rybnicki pl227 17 5 and krakowski pl214 9 are spatially located over those areas with the greatest shares of abandonment projected by luisa focusing on agricultural abandonment at local scale 17 municipalities are assessed with shares accounting for from 32 to 66 the latter corresponds to lubycza królewska althought italy is one of the countries more affected by land abandonment this fact is not reflected in the number of reported study areas 28 28 abandonment hotspots numbered as 26 27 and 28 with 11 7 40 and 26 6 shares respectively that correspond to the municipalities of sondalo sernio valdidentro tirano colorina berbenno di valtellina baselga di pinè pergine valsugana vigolo vattaro sant orsola terme bedollo terlago micigliano borona antrodoco petrella ranging from 8 to 67 in italy from luisa outcomes the austrian municipalities in the point 27 and 11 are tux gerlos krimml absam gshnitz zirl and vals ranging from 21 to 61 of abandonment from luisa these areas are mainly located in the northeastern side of the italian alps belluno province and central apennines riete province limiting with austrian alps innsbruck at332 41 and tiroler unterland at335 8 3 in italy only sondrio itc44 3 and trento ith20 6 5 in the north and riete iti42 6 located in the central side showed spatial coincidence between the two sources at local level 17 municipalities are found to have a good match in relation to the abandonment shares exceptions are sondalo and sernio above 30 compared to 11 7 in riete region municipalities affected by abandonment are in the range of the reported hotspots by 30 local share except in micigliano that reaches 67 abandonment share in slovakia we can assess only one point number 7 placed in the carpathian mountains over the regions of prešovský kraj sk041 11 29 29 the abandonment hotspot numbered as 7 has a 20 share of local abandonment that corresponds to the municipalities in jakubova voľa ďurková drienica fričovce rokycany vyšný medzev medzev háj and bôrka ranging from 25 to 95 of abandonment from luisa and south narodny park slovensky kras sk042 5 at local level luisa reports much higher shares in all the municipalities evaluated 10 than the shares from the literature with the highest abandonment share in medzev 521671 at about 95 the opposite situation occurs in romania where only one point number 2 is observed in the area of arges region ro311 1 and its municipalities mostly present abandonment shares lower than 10 in baltics countries 30 30 there is not any studied abandonment area hotspot for lithuania reported from the consulted literature especially estonia and latvia several sites modestly reveals moderate low abandonment shares in estonia the region laane eesti ee004 3 31 31 abandonment hotspots numbered as 33 4 34 5 and 35 6 with shares between 10 1 and 50 that correspond to the municipalities of viimsi ikšķiles novads salaspils novads and cesvaines novads ranging from 11 to 40 of abandonment from luisa haapsalu and surju have the highest shares 40 and 28 respectively is the most affected by land abandonment in line with what it is stated by the literature however it is difficult to find modelled abandonment shares greater than 6 shares in latvia are even smaller but with some local picks in the central part of vidzeme lv008 3 5 reaching 50 abandonment shares in some areas as well as nearby latgale region lv007 5 2 due to the location of the daugava river basin and the presence of forestry and natural areas the last two south european countries greece and portugal also have assigned few studied abandonment points only two points each agricultural abandonment in greece are observed in the nisyros and lesvos islands that spatially overlap the άνδρος el422 10 32 32 abandonment hotspots numbered as 29 and 30 with shares between 20 and 77 in greece correspond to the greek island municipalities where the highest abandonment shares ranging from 4 to 5 up to 52 with the maximum values in νισύρου 8119 and κέας ιουλίδος 8209 accounting for 52 and 37 respectively though most of the shares are below 10 and λέσβος λήμνος el411 2 regions which means that luisa capture lower values in these islands in portugal the study areas were located in central inland near the river côa and alentejo whose nuts3 regions concur with beiras e serra da estrela pt16j 3 and alentejo litoral pt181 0 6 a set of municipalities lau2 33 33 abandonment hotspots numbered as 24 and 25 portugal with abandonment shares of 40 and 77 respectively correspond to the municipalities where the highest abandonment shares ranging from 6 up to 34 though most of the shares are below 5 were assessed yielding much lower modelled abandonment shares from luisa than the observed areas finally a logit expression see eq 4 is used to quantify the effect of selected abandonment risk factors table 1 on observed agricultural abandonment the results table 2 indicate a model with a high goodness of fit indicating that the selected factors can be used to accurately predict the presence of abandonment most of the estimators have significant effects with small p values in particular slope drainage precipitation lgp root depth farm age fa farm investment fi are considered the most relevant variables followed by farmer qualification remoteness and population density most of the estimators with low p values have the expected sign thus abandonment probability is greater with steeper slope more precipitation higher soil ph longer root depth older mean famer age poor famer qualification and in remote areas and abandonment risk is greater with less farm investment lower total subsidies and in areas with higher population density the estimators for soil drainage and length growing period significantly yield signs that are contrary to our expectations this can be explained due to the fact that both layers present a low spatial variability for which the highly localised abandonment data is not sufficiently detailed moreover better results could be obtained by the integration of irrigation maps as an economic factor which presumably reduces the risk of abandonment locally especially in semi arid regions 4 discussion even though agricultural land abandonment is a sizeable process in europe a wide overview and future outlook of abandonment are missing for the continent previous contributions covered case studies and partial aspects of the process garcía ruiz and lana renault 2011 lasanta et al 2016 which due to the considerable spatial heterogeneity of economic biophysical and climatic conditions cannot easily be generalized for a greater geography determining the extent and location of agricultural abandonment requires not only agreed upon definitions driving forces and potential impacts but also precise observed data and knowledge about the transformation and subsequent dynamics of the natural revegetation keenleyside and tucker 2010 verburg and overmars 2009 clearly the lack of an existing continuous and harmonized database inventory of land abandonment mars deeper more accurate analysis estel et al 2015 levers et al 2018 34 34 only lucas land use cover area frame survey 2015 version covers some member states with roughly 389 observations this is the information that we have used for the second strategy of validation the way to model agricultural abandonment by the luisa model differs substantially from previous abandonment modelling exercises in terms of assumptions spatial and thematic resolution and reference land use data to estimate the extent and locations of future abandonment luisa attempts to endogenously model agricultural land abandonment as a choice of disinvestment using a map of induced abandonment risk to capture the most likely locations of abandonment while taking into account the spatial heterogeneity of europe s farming conditions the most recent available data and information were used to compose that risk map however a set of uncertainties are intrinsically part of this type of modelling coming into play through choices such as thematic spatial and temporal resolution data availability geographical coverage assumptions and aggregation methods estel et al 2015 price et al 2015 for instance when examining factors table 1 by which the risk map is composed it is evident that both the lack of higher resolution for some spatial layers for instance length growing period or drainage and the low accuracy and spatial variability of some factors salinity and sodicity reduces the quality of the final results as is evident in the validation exercises another example is posed by agroeconomic variables which are available as regional averages clearly land abandonment depends on farm specific characteristics and therefore regional statistics offer a limited approximation for determining the precise location of farms at risk an extensive exercise has been executed to validate the inclusion of the agricultural abandonment model we find that the introduced agricultural risk map coincides with abandonment observed in the lucas database modelled abandonment coincides with the abandonment shares reported by lasanta et al 2016 although discrepancies can be found especially in spain portugal italy poland slovakia and latvia those discrepancies can be explained by to the fact that the abandonment hotspots reported in lasanta et al were measured very locally more than two decades ago a logit model has been used to verify whether the factors selected for the potential risk map contribute to a higher likeliness of observing abandoned agricultural areas according to the lucas definition this exercise corroborates that slope low precipitation poor drainage population density travel times and distance to farms increase likeliness of abandonment alonso sarría et al 2016 corbelle rico and crecente maseda 2014 regional farmer qualifications shares of older farmers farm investments and subsidies are also found to have the expected structural effect on abandonment likeliness confirming many previous results keenleyside and tucker 2010 prishchepov et al 2013 terres et al 2015 lasanta et al 2016 levers et al 2018 other variables did not yield significant effects or the expected signs which may be due to the limited amount of initial observations possibly agricultural areas where the condition at hand exists are already abandoned or local strategies were applied to overcome the difficulties caused by the condition that the variable describes agroeconomic regional variables such as farm size rental price farm income and share of rented land did not yield significant results no doubt because the local variation of those variables is substantial within a region these variables are nevertheless included in the potential risk map as they do assist in pinpointing in which regions abandonment is more likely to occur the variables indicating poor soil drainage and high levels of soil organic matter som yielded counterintuitive effects the results from som entail a paradox as fertile soil with high organic matter is in fact less prone to be abandoned agricultural areas with poor drainage may be compensated by irrigation systems thus raising sunk costs in the farm operation and making abandonment likeliness lower unfortunately the data necessary to verify this more thoroughly is unavailable or insufficient despite the many differences between prior modelling approaches luisa s abandonment results corroborate many of the findings of previous works the total abandonment share expected here is very similar to the 3 7 from the most moderate scenario reported by van der zanden et al 2017 however estimates of the amount of abandonment differ substantially recently estel et al 2015 and levers et al 2018 mapped active cropland fallow land and farmland abandonment with abandoned values ranging between 0 2 and 1 4 of the total farmland assuming high global competitiveness and lacking public support for farming keenleyside and tucker 2010 expect much more abandonment at a rate of 7 in terms of pinpointing the locations of abandonment again luisa corroborates many previous results similar to verburg and overmars 2009 and renwick et al 2013 substantial abandonment is expected here in mountainous areas however luisa also captures hotspots outside mountainous areas particularly in the northwestern spain galicia corsica northwestern and central part of portugal 35 35 in the surroundings of lisbon and oporto where some municipalities show the highest abandoned shares ranging from 56 to 85 as well as near the national park of peneda with abandonment shares around 50 baltic s countries 36 36 in the southern and northwestern part of latvia can be found some municipalities that show the highest abandoned shares near 15 such as aknīstes novads 0560800 rojas novads 0888301 or mērsraga novads 0887600 including new detected abandoned areas in lithuania 37 37 as alcantara et al 2013 identified luisa is able to find in lithuania lt00a 2 lt009 5 especially in the municipalities such as antakalnio seniūnija 1301 panerių seniūnija 1309 vidiškių seniūnija 4504 salako seniūnija 4348 etc where the highest abandonment shares range from 10 to 26 northwest of france northeaster and western part of poland 38 38 in olsztyński pl622 11 and szczecinecko pyrzycki pl427 9 5 some municipalities show abandoned shares ranging from 37 to 50 north of the national park nizke tatry slovakia 39 39 in nizke tatry žilinský kraj sk031 10 some municipalities show abandoned shares ranging from 25 to 95 and in the western side of the carpathians immediately in the north of arges region 40 40 especially in harghita ro12 7 mures ro125 6 3 or sibiu ro126 4 3 regions other sources are not definite on where abandonment would happen outside mountainous regions the luisa results are in line with locations reported by lasanta et al 2016 41 41 kuemmerle et al 2008 keenleyside and tucker 2010 kozak et al 2004 and pointereau et al 2008 in poland muller and kummerle et al 2009 in romania peterson and aunap 1998 nikodemus et al 2005 ruskule et al 2013 and van dijk et al 2005 in baltics countries pinto correia 1993 in portugal gomez moreno 1989 alonso sarría et al 2016 and perpiña castillo et al 2020 in the southeastern part of spain and occur especially in poland romania baltics countries the southeast of spain and the south of portugal estel et al 2015 and levers et al 2018 expect abandonment outside mountainous areas to occur in very different places casting some doubt on the luisa outcomes specifically for the iberian peninsula their predictions are not completely coincident with regional local studies carried out by many authors alonso sarría et al 2016 lasanta et al 2016 arnáez et al 2011 corbelle rico et al 2012 pinto correia 1993 nunes et al 2011 however a more comprehensive comparison of modelling approaches and results is called for here lastly due to its thematic detail and interactions between land uses luisa projects dynamics between land abandonment and other land uses e g residential industrial areas that are expected to occur in particular around main capital cities such as in paris madrid berlin or warsaw there in the simulations agricultural land becomes abandoned possibly as a precursor for urban expansion or urban sprawl these land conversions deserve further studies since they are likely related to the concept of land reservoir van der zanden et al 2017 grădinaru et al 2015 paul and tonts 2005 price et al 2015 when an abandonment process occurs it affects not only the abandoned area itself but also its local population and the whole society in terms of production of goods e g foods feed fibre and biomass production as well as other services provided by the multifunctionality of the agricultural land elbersen et al 2014 one of the most important function of agriculture is to feed the eu population and likely the food security can be one of the major challenges for the future of the eu especially for the rural economy terres et al 2015 for many regions in europe the agricultural sector still plays a significant economic role ecorys 2010 and its eventual decline due to massive abandonment among other factors might cause a loss of jobs in the agricultural and related sectors out migration of young people and a decline in the management of agroecosystems lasanta et al 2005 the decrease in agricultural land influences agricultural outputs and management practices changes in management practices such as agricultural intensification and specialization lead to high productivity in more fertile areas while causing marginalisation and abandonment in others baumann et al 2011 5 conclusion agricultural land abandonment is the largest land use change process in europe and it is expected to continue during the next decades land abandonment has been analysed in european mountainous and remote areas since the earlier decades of the 20th century but less effort has focused on other vulnerable areas this study therefore presents a comprehensive european spatially explicit exercise to model agricultural land abandonment this was done within the luisa territorial platform from the period 2015 2030 at a high spatial resolution for all eu countries and the uk abandonment is considered a dis investment decision and the location of abandonment is defined by an abandonment risk map deduced from previous findings in the literature that risk map was composed by combining a set of factors that presumably drive agricultural abandonment highlighting the importance of biophysical conditions agricultural socio economics farm structure demographics and geography by 2030 results reveals that the total abandonment is projected to reach more than 3 5 6 million ha of the total agricultural land while at the same time the decrease of agricultural land over the same period of time is an evident fact in most eu countries and the uk spain and poland are likely to account for one third of the eu total land abandonment whereas france germany and italy complement the leading group altogether responsible for more than 70 of the total abandonment this abandonment share is not equally spread across eu countries ranging from less than 2 to more than 50 at the regional level areas that are hot spots of undesirable abandonment might be particularly aimed at by policymakers in order to prevent or minimize present and future negative consequences and our results can be a valuable spatial and quantitative source of information to this end modelling dynamic indicators require a set of geospatial and statistical data whose availability accessibility and resolution are often limited potentially affecting the reliability of the data produced multiple strategies were followed in order to validate the implemented approach we need to emphasize the challenge of direct comparison with other sources because for instance temporal coverage data assumptions abandonment definitions and spatial location vary among all those studies despite differences in location and extent we stress the considerable spatial overlapping between luisa and other datasets and model results definitively luisa projections of abandonment however seems to be conservative but in line with european average figures when compared to case studies based on policy scenarios and modelling disclaimer the views expressed are purely those of the author and may not in any circumstances be regarded as stating an official position of the european commission declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a description of luisa luisa coherently links specialised macro economic demographic and geospatial models with other thematic spatial statics databases in order to simulate the local allocation of land functions i e housing transport food production or ecosystem services land claims are provided by those models that govern the starting stage of the simulation primarily based on dg ecfin 42 42 directorate general for economic and financial affairs of the european commission projections in particular demographic projections rely on europop 2013 43 43 dg eurostat 2013 for the period 2015 2060 at national level capri model britz and witzke 2012 provides future agricultural land demands aiming at modelling changes in cap common agricultural policy policies economic projections are derived from the gem e3 and the rhomolo model while energy projections depend on the jrc eu times model the reference spatial map named the luisa base map 2012 44 44 the luisa base map 2012 is an enriched version of corine land cover 2012 but with a significantly higher spatial and thematic resolution mainly owing to the integration of relevant land use cover information from multiple compatible geodata sources copernicus high resolution layers urban atlas european settlement maps etc jacobs crisioni et al 2017 is an enriched version of corine land cover 2012 but with a significantly higher spatial and thematic resolution mainly owing to the integration of relevant land use cover information from multiple compatible geodata sources 45 45 copernicus high resolution layers urban atlas european settlement maps etc model run therefore provides outcomes at local scale 100 m resolution with a temporal resolution of 5 years for all eu countries and the uk throughout a simulation period currently up to 2030 sectoral claims are allocated over the land according to their specific location and recent land use class land suitability restrictions of spatial policies transition rules neighbourhood effects etc more information about luisa application key components modular structure and methods can be found in jacobs crisioni et al 2017 baranzelli et al 2016 and lavalle 2017 figure a 1 shows a simplified scheme of the luisa platform in order to reflect top down dynamics in modelling agricultural land abandonment while competing with other land uses fig a 1 adapted and simplified luisa scheme to illustrate the workflow and main components for modelling specifically agricultural land abandonment fig a 1 the allocation mechanism is located at the core of the luisa s modelling platform as a system of equations that repeats itself every five years until the end of the simulation period is reached typically in 2050 following the next steps as shows figure a 2 1 describe the geographical context of every modelled region and grid cell by mapping a large breadth of exogenous and endogenous external factors 2 describe function pressures in particular what is considered as the population pressure or the intrinsic attractiveness of a grid cell for human settlement 3 reallocate the physical manifestation of land uses based on a special case of the doubly constrained land use optimization mechanisms described in hilferink and rietveld 1999 and land use specific local utility estimates computed as described in koomen et al 2015 and lastly 4 redistribute land based functions in particular population based on environmental characteristics and reallocated land use maps fig a 2 luisa modelling framework for simulation of land use change following pressures for the provision of land based functions adapted from jacobs crisioni et al 2017 fig a 2 appendix b description and data sources of the factors that drive agricultural abandonment table b 1 selected biophysical criteria for identifying severe natural conditions for generic agricultural activities their description and main reference table b 1 biophysical land suitability factor description reference length of growing period the number of days when the average daily temperature is above a certain temperature threshold lgpt5 is selected establishing 5 c as threshold spatial resolution 8 km grades arc iiasa fao 2013 a organic matter topsoil 0 30 cm organic matter content spatial and temporal resolution 1 km processed in 2012 hiederer 2016 based on esdb and hwsd iiasa fao isric isscas jrc 2012 soil drainage it refers to the maintenance of the gaseous phase in soil pores by removal of water imperfect poor and very poorly drained soils are considered not favourable for crop growth spatial resolution 1 km sinfo project b eurostat european commission 2013 which is based on esdb c precipitation the total mean annual precipitation is calculated as the sum of the mean monthly precipitation the mean annual precipitation in mm was divided into seven classes with 200 mm intervals from 0 to 1000 mm spatial resolution 1 km processed in 2012 efsa d eurostat european commission 2013 hiederer r 2016 soil ph spatial layer of topsoil ph which represent the ph given for the dominant soil soil ph exceeding 9 or below 4 extreme values is considered not favourable for crop growth spatial resolution 1 km efsa eurostat european commission 2013 based on hwsd e iiasa fao isric isscas jrc 2012 root depth to ensure maximum root development due to the presence of specifics horizon that cannot be penetrated by the roots this spatial layer is divided into eight classes from 10 to 120 cm spatial resolution 1 km sinfo project f eurostat european commission 2013 which is based on esdb g soil texture five classes were defined coarse medium medium fine fine and very fine soil texture with less than 18 clay more than 65 sand or which have stones boulders or rock at the surface are considered not favourable for crop growth spatial resolution 1 km sinfo project eurostat european commission 2013 which is based on esdb slope derived from the elevation was divided into six classes flat areas or with a slope 8 are the most appropriated for crop growth slopes in excess of 16 will provide difficulty for harvesting machinery spatial and temporal resolution 100 m 2013 shuttle radar topographic mission nasa 2013 salinity medium or high salinity concentration areas are proposed as unfavourable agricultural conditions producing significant losses of production and serious damage to the crop spatial resolution 1 km sinfo project eurostat european commission 2013 which is based on esdb sodicity soil sodicity is a land characteristic for which the proportion of absorbed sodium in the soil clay fraction is too high for plants to perform or survive spatial resolution 1 km sinfo project eurostat european commission 2013 which is based on esdb a iiasa international institute for applied systems analysis and fao food and agricultural organization of the united nations b sinfo project soil information system for the mars crop yield forecasting system c esdb european soil data base d efsa european food safety authority spatial data version 1 1 e hwsd harmonized world soil database f sinfo project soil information system for the mars crop yield forecasting system g esdb european soil data base table b 2 main farm structure and agricultural viability factors that drives agricultural land abandonment their description and main reference table b 2 economic viability of agricultural production description reference age of farmers it is computed as a share by taking into account the number of farmers 65 year old over the total number of farmers it is assumed that abandonment is more likely to occur when the farmer is close to the retirement age factor interpretation the higher the share of farmers older than 65 years old the higher the abandonment risk spatial resolution nuts3 level eurostat fss eurostat european commission 2017 data holders above 65 ef r farm2007 xls farmer qualification three different levels of training of farm managers are specified with only practical experience basic and full agricultural training it is computed as a share of farmers with practical experience with regard to the total number of trained farmers farmer with high qualification invest more in human capital knowledge etc thus preventing farmland abandonment factor interpretation the higher the share of farmer no qualified only practical experience the higher the abandonment risk spatial resolution nuts0 level eurostat eurostat european commission 2017 data total ef mptrainman xls practicalexperience ef mptrainman xls farm size share of farms uaa under 50 of the average size region nuts3 the rationale behind is that larger farms can share agricultural resources machinery inputs buildings etc and thus reducing production costs in this way large farms compared to small fragmented farms are usually more competitive and viable from an economic point of view factor interpretation the higher the share the higher the abandonment risk spatial resolution nuts3 level eurostat fss eurostat european commission 2017 data size and type ef r farm 3 xls rent paid rent paid se375 a for farmland and buildings and rental charges b rent paid is used as a proxy of the strength or weakness of the land market it is assuming that high rental prices leads to high demand for agricultural land and therefore a low risk of abandonment units euro factor interpretation the lower the rental price the higher the abandonment risk spatial resolution nuts samples fadn dataset and dg agri rica especial request rented uaa utilized agricultural areas rented se025 by the holder under a tenancy agreement for a period of at least one year remuneration in cash or in kind it is expressed in hectares 10 000 m2 5 it is computed as a share of the rented uaa over the total uaa the average is calculated for the years 2005 2010 for each holding in the database units hafactor interpretation the lower the rented uaa the higher the abandonment risk spatial resolution nuts samples fadn dataset and dg agri rica especial request farm income farm net value added se425 expressed per agricultural work unit takes into account any differences in the labour force to be remunerated per holding 5 this variable is used as a proxy of economic performance compared to the gross domestic product gdp per capita from the period 2005 2010 national gdp is a proxy of national income units euro factor interpretation the lower the income the higher the abandonment risk spatial resolution of gdp nuts0spatial resolution of farm net value added nuts samples fadn dataset and dg agri rica especial request eurostat eurostat european commission 2017 data nama gdp c xls euros capita at market price farm investment net investment se521 is defined as gross investment depreciation 5 this variable is normalized by the size of the farm uaa c at sample level this can be interpreted as a proxy of improving new machinery new technics and continuing farm activities hence reducing the risk of abandonment units euro factor interpretation the lower the investment the higher the abandonment risk spatial resolution nuts samples fadn dataset and dg agri rica especial request farm scheme subsidies subsidies on current operations linked to production not investments interest subsidies and payments for cessation of farming activities are therefore not included5 the indicator is computed by using the variable farm subsidies se605 normalize by the uaa sample area units euro factor interpretation the lower the subsidies the higher the abandonment risk spatial resolution nuts samples fadn dataset and dg agri rica especial request a codes assigned by fadn for the selected variables b defined by fadn european commission 2000 c uaa not include areas used for mushrooms land rented for less than one year woodland and the other farm areas roads ponds non farmed areas etc it is made up of land in owner occupation rented land land in sharecropping remuneration linked to output from land made available it includes agricultural land temporarily not under cultivation for agricultural reasons or as a result of being withdrawn from production as part of agricultural policy measures table b 3 main demographic risk factors favouring farmland abandonment low population density and remote areas table b 3 demographic and regional context description reference low population density areas population density below 50 inhabitants km2 is considered low populated areas in our study being much lower than the threshold used in other methods 150 inhabitants km2 several dynamic test were done to set up this cut off value in order to better capture rural areas with very low population density the modelling mechanism counts for each cell the allocated residents within a surrounding kernel with an area of approximately 1 km2 then it is possible to identify the cells with less than 50 inhabitants inside the surrounding kernel luisa population density map based on europop2013 nuts3 level terres et al 2015 remoteness remote areas are represented as a dynamic map of travelling time to nearest town town access is defined as dynamic map of travelling time to the nearest town couple with access to the nearest town this indicator also takes into account changes in travelling times between time steps thus remote areas are identify as those that are further than 60 min away from towns dijkstra and poelman 2008 terres et al 2015 appendix c individual maps of biophysical agricultural economy and demographic and regional context fig c 1 number of biophysical factors spatially concurring for classifying land suitability for agricultural generic activities in the eu countries and the uk fig c 1 fig c 2 map combining economic and farm structure drivers of agricultural land abandonment in the eu countries and the uk period 2005 2010 fig c 2 fig c 3 individual economic and farm structural factors for determining the stability and viability of farming activities for preventing agricultural land abandonment in the eu countries and the uk a share of farmers older than 65 years old b share of farmer with only practical experience c share of farms under 50 of the average size region d rental price e farm income f share of rented uaa g total subsidies and h farm investment fig c 3 fig c 4 map of remote areas computed at member state level adding also the uk 2015 fig c 4 fig c 5 map depicting low population density areas in the eu countries and the uk 2015 fig c 5 appendix d map of the projected agricultural land abandonment in the eu and the uk fig d 1 future projections of agricultural land abandonment at grid level 100 m resolution in the eu and the uk 2030 fig d 1 appendix e farmland abandonment in the european mountains fig e 1 distribution of the reported local shares of abandonment hotspots refers to the 35 study areas identified in lasanta et al 2016 table e 1 simplified version of the table from lasanta et al 2016 first five columns combined with the luisa results regional and local level in 2030 last two columns additional hotspots abandonment areas captured by luisa are also reported in bold table e 1 code country locations share of farmland abandonment reference regional nuts3 share of abandonment from luisa 2030 local lau2 share of abandonment from luisa 2030 1 france alps briançonnais 79 in lasanta et al 2016 alps fr821 20 52 61 2 pre alps provence 97 in lasanta et al 2016 vaucluse fr826 7 hautes alpes fr822 18 53 94 50 96 5 central pyrenees 84 1 in lasanta et al 2016 hautes pyrenees fr626 4 64 91 8 pre alps 20 in lasanta et al 2016 isere fr714 12 60 88 32 3 mazovia podkarpacikie and podlaskie 17 6 keenleyside and tucker 2010 chełmsko zamojski pl312 17 43 66 36 7 poland beskid maly 33 rybnicki pl227 17 5 34 51 6 1 slovakia poland and ukraine carpathian mountainscarpathian mountains and surroundings 20 20 7 13 9 and 13 3 in lasanta et al 2016 krakowski pl214 9 31 41 9 8 luisa platform olsztyński pl622 11 szczecinecko pl427 9 5 38 50 37 43 7 slovakia carpathian mountains 20 in lasanta et al 2016 prešovský kraj sk041 11 south narodny park slovensky kras sk042 5 61 90 61 91 luisa platform national park nizke tatry north žilinský kraj sk031 10 25 95 10 italy austria france germany switzerland alps 20 70 in lasanta et al 2016 haute savoie fr718 10 4 26 95 11 austria italy eastern central alps 40 in lasanta et al 2016 innsbruck at332 41 and tiroler unterland at335 8 5 31 61 12 spain cantabrian mountain south 40 in lasanta et al 2016 asturias es120 15 2 cantabria es130 14 país vasco montes vascos 20 43 53 38 48 32 63 13 spain cantabrian mountain nord 50 in lasanta et al 2016 22 spain cantabrian mountain 80 in lasanta et al 2016 14 spain central system 89 in lasanta et al 2016 sierra de ayllon and north of madrid es300 8 7 42 80 15 spain central system 75 in lasanta et al 2016 ávila es411 and salamanca es415 salamanca 7 1 31 78 16 spain sistema bético 36 in lasanta et al 2016 malaga es617 3 8 10 18 spain central pyrenees 71 in lasanta et al 2016 lleida es513 4 5 teruel es242 9 3 tarragona es514 8 7 53 85 21 spain catalan prelitoral mountain 40 in lasanta et al 2016 31 65 19 20 spain iberian range and iberian range 99 42 arnáez et al 2011 in lasanta et al 2016 rioja es230 17 5 zaragoza es243 7 33 57 31 81 23 spain sistema bético alpujarras 70 in lasanta et al 2016 sierra nevada es614 12 almeria es611 20 5 53 74 54 64 es spain macizo galaico y montes de leon luisa platform north of portugal lugo es112 44 ourense es113 41 pontevedra 114 26 a coruña es111 30 es spain catalan prelitoral mountain luisa platform navarra es220 6 guipuzcoa es212 29 and es spain iberian range and iberian range luisa platform teruel es242 9 3 and castellon es522 9 in the south of iberian range 24 portugal central inland 80 nunes et al 2011 beiras e serra estrela pt16j 3 20 60 25 portugal alentejo 40 pinto correia 1993 alto alentejo pt186 1 5 6 pt portugal lisbon luisa platform lisboa pt170 10 parque nacional de peneda c cávado pt112 20 and ave pt119 21 oporto pt11a 21 56 85 50 65 43 49 26 italy alps 11 7 in lasanta et al 2016 sondrio itc44 3 8 37 27 italy eastern alps 40 in lasanta et al 2016 trento ith20 10 29 48 28 italy apennines 26 6 in lasanta et al 2016 rieti iti42 6 25 67 it italy torino sicilia luisa platform teramo itf12 5 7 napoli itf33 5 avellino itf34 9 torino itc11 1 3 messina itg13 6 catania itg17 5 reggio di calabria itf65 3 4 31 66 31 68 33 83 29 greece nisyros island 76 4 in lasanta et al 2016 κάλυμνος κάρπαθος κως ρόδος el421 3 4 52 30 el greece greece lesvos island north and central greece central peloponeso 20 in lasanta et al 2016 luisa platform λέσβος λήμνος el411 2 κορινθία el652 20 αργολίδα αρκαδία el651 9 καρδίτσα τρίκαλα el611 5 38 45 37 71 28 41 6 42 90 31 2 romania arges county 21 in lasanta et al 2016 arges ro311 1 romania central romania luisa platform 33 4 estonia several sites 10 1 and 30 in lasanta et al 2016 lääne eesti ee004 3 western and southwestern part 28 40 34 5 latvia latgale and other regions 10 3 21 1 and 50 in lasanta et al 2016 pieriga lv007 5 2 river 6 11 35 6 latvia vidzeme 25 35 in lasanta et al 2016 vidzeme lv008 3 5 15 lv latvia luisa platform zemgale lv009 2 6 south kurzeme lv003 2 7 west 12 12 16 codes represent the studied abandoned areas in fig e 1 share of abandonment represents the minimum and maximum local value within the corresponding nuts3 region overlapping the studied abandoned point hotspot areas from lasanta et al 2016 
25894,in the majority of eu member states agricultural land is expected to decrease not only due to land use changes in favour of urban expansion and afforestation but also to land abandonment processes the knowledge on location and extent of agricultural land abandonment is relevant for estimating local external effects and adapting policy interventions currently multi level land use models are able to capture determined processes of demand driven redevelopment however land abandonment is much more difficult to capture because of its more ambiguous definition and the lack of data on its spatial distribution this paper presents a method to explicitly model agricultural abandonment as a choice of disinvestment which in turn is embedded in a utility based land use modelling framework that projects land use changes for the eu and the uk validation exercises using observed spatial distribution of abandoned farmland show that the proposed method allows to model abandonment with acceptable accuracy keywords agricultural land abandonment territorial modelling eu reference scenario european risk map validation 1 introduction in europe the abandonment of agricultural lands has been an important land use change process at least since the 19th century mather 2001 it still is a topical issue reflecting the post war and post soviet trends of rural depopulation and loss of competitive advantages in the rural economy baldock et al 1996 prishchepov et al 2012 and is particularly problematic in mountainous remote and semiarid areas macdonald et al 2000 benayas et al 2007 a problem that is pervasive in the land abandonment literature is the difficulty of defining identifying and observing the process at hand indeed agricultural land abandonment can be defined in many different ways 1 1 see for instance definition of abandoned agricultural land in hart et al 2013 referred to actual abandonment semi abandonment or hidden abandonment and transitional abandonment pointereau et al 2008 or corbelle rico and crecente maseda 2008 in terres et al 2015 farmland abandonment was defined as a cessassion of land management which leads to undesirable changes in biodiversity and ecosystems services but commonly refers to land that was previously used to grow crops or for grazing does not have farming functions anymore i e a total cessation of agricultural activities and has not been converted to forest or artificial areas either hart et al 2013 pointereau et al 2008 fao 2006 many factors are involved in this complex and multi dimensional phenomenon that is primarily triggered by low productivity and land degradation and occurs more often in remote and mountainous regions with soil or climate conditions that are unfavourable for agriculture secondary drivers such as rural depopulation socio economic factors policies or inefficient farm structure can further accelerate land abandonment van der zanden et al 2017 lasanta et al 2016 the abandonment of agricultural land can cause undesirable environmental socio economic and landscape impacts for instance biodiversity loss landscape homogenization increased fire risk soil erosion and soil degradation as well as increase of the area of agriculture intensification keenleyside and tucker 2010 hart et al 2013 lasanta et al 2016 however agricultural abandonment does not only entail a higher pressure on biodiversity and natural resources but also causes decline of local agricultural incomes and employment and is thus directly linked to population dynamics especially in mountainous or remote rural areas the loss of agricultural income aggravates often already weak economic and social structures european union 2013 in addition agricultural land abandonment is linked to the loss of local agricultural practices and knowledge gellrich et al 2007 baldock et al 1996 on the other hand where agricultural abandonment coincides with favourable climate and soil conditions it can lead to environmentally valuable natural succession this re vegetation process may entail important positive benefits such as improving soil organic matter content stabilisation of soils carbon sequestration regulation of water flow and habitat restoration with an improvement in species number and biodiversity corbelle rico and crecente maseda 2008 estel et al 2015 all in all the trade offs between positive or negative impacts that can result from abandoning agricultural land are largely site specific depending on the geographic location and related biophysical conditions cultural heritage environmental political and socio economic preferences hart et al 2013 verburg et al 2009 in many countries in europe the potentially negative impacts of agricultural abandonment have been addressed via a broader set of policy instruments that aim to alleviate the negative consequences or even reverse abandonment trends in its early stages for decades the european union eu has been intervening in agricultural markets with specific payment schemes dedicated to marginal farming areas eliasson et al 2010 keenleyside and tucker 2010 koomen et al 2008 the less favoured areas lfa and more recently the areas facing natural or other specific constraints anc support schemes have been providing compensation to farmers who continue to farm despite unfavourable conditions ec 2005 eu 2013 in addition supportive national legislations are crucial to tackle the land abandonment problem as national legislators are typically more informed on local characteristics and needs corbelle rico and crecente maseda 2008 during the last decades considerable effort has been put in mapping quantifying and assessing the major impacts and drivers that entail abandonment land processes some studies on land abandonment focused on concepts and drivers highlighting the importance of environmental socio economic and farm management factors corbelle rico and crecente maseda 2008 fao 2006 benayas et al 2007 garcía ruiz and lana renault 2011 keenleyside and tucker 2010 terres et al 2015 lasanta et al 2016 while others have been centred on the efficiency of policy measures macdonald et al 2000 walford 2002 renwick et al 2013 corbelle rico and crecente maseda 2014 positive and negative consequences of land abandonment as already mentioned are another recurrent topic baldock et al 1996 macdonald et al 2000 van der zanden et al 2017 nainggolan et al 2012 often applied to case studies located in mediterranean europe 2 2 spain italy france greece portugal although it is possible to find studies on land abandonment in most of the eu countries germany the netherlands poland etc which refer to local or regional scales and mountainous areas falcucci et al 2007 poyatos et al 2003 etienne et al 2003 lasanta et al 2016 macdonald et al 2000 corbelle rico et al 2012 recently other studies have used remote sensing estel et al 2018 alcantara et al 2013 to distinguish productive fallow and recultivated farmland those studies have done so at european and global scales respectively by calculating ndvi time series from different satellite sensors at high spatial resolution given the political relevance of agricultural abandonment in europe an estimate of where and how much abandonment will happen in the future would be useful unfortunately so far less attention has been given to modelling techniques to obtain estimates of future abandonment locations typically developed in existing spatially dynamic modelling systems previous studies built different scenarios in order to explore possible future developments and impacts and were based mostly on econometric techniques nowicki et al 2006 westhoek et al 2006 verburg and overmars 2009 meiyappan et al 2014 price et al 2015 van der zanden et al 2017 these existing models mainly attempt to analyse trends and changes in landscape and spatial patterns over time but are relatively limited with regard to the representation of the agricultural land abandonment process keenleyside and tucker 2010 other location models for farmland abandonment are based on the assumption that abandonment likely occurs where local suitability for agricultural practices is relatively low verburg and overmars 2009 meiyappan et al 2014 recent works suggest however that marginalization of agriculture is not only driven by poor biophysical characteristics or lack of demand for produce abandonment of agricultural land as an economic resource typically occurs when it has ceased to generate sufficient income flows and the available options within the restraints of farmers knowledge and capacities for adjusting resource use farming practices or farm structure have been exhausted macdonald et al 2000 thus other structural and monetary factors that affect farmers income and abilities also play a decisive role for instance the farmers age and qualification existing subsidy schemes and differential competitive advantages among rural regions a more refined method to model locations of farmland abandonment is called for the paper at hand presents a method to explicitly model future local agricultural abandonment processes as a result of economic decisions on the use of land within an integrative spatially dynamic land use modelling framework the implementation of the method is illustrated with the luisa territorial modelling platform a model that dynamically simulates population land use and accessibility changes across the eu and the uk the united kingdom at a 100 m resolution in order to assess local and cross policy externalities future land use trends and major drivers of land abandonment are simulated under the eu territorial reference scenario 2017 jacobs crisioni et al 2017 the territorial assessment of agricultural abandonment trends and its associated impacts is presented at national regional nuts3 and grid level for all eu countries and the uk up to 2030 in addition a method to quantify land use cover flows is used to represent the main transitions between land uses that are simulated in particular this paper presents aggregated land conversions that according to the introduced model procedure supersede agricultural abandonment perpiña castillo et al 2018 2019 the rest of this paper is structured as follows firstly we briefly introduce the general land use modelling framework of luisa section 2 1 then we further describe the method for deriving the european risk map of agricultural land abandonment section 2 2 section 2 3 describes agricultural abandonment as part of a utility based land use modelling framework as well as outlines the future projections for agricultural land abandonment up to 2030 section 2 4 describes the method for validating the proposed modelling approach in section 3 the main outcomes of the study are presented and analysed and finally section 4 and 5 summarises and discusses the main points of the proposed method versus other studies 2 material and methods within the luisa modelling framework land abandonment is thus conceptualised as a temporary phenomenon that may happening even without demand reduction as a consequence of a transition of the agricultural production system towards an optimal spatial distribution section 2 1 and 2 2 a combination of factors is assumed to be involved in agricultural land abandonment land use competition biophysical conditions agricultural economics farm structure demographic and geographical factors are all expected to play a role section 2 3 1 2 3 2 and 2 3 3 these individual factors are first represented in maps using a variety of data sources and then integrated together to build a composite map of agricultural land abandonment risk for the whole eu and the uk at a fine resolution from 2015 to 2030 section 2 3 4 this risk map is then used within the luisa model as a compound local driver for simulating agricultural abandonment processes given a set of regional demands for land based functions and activities as it is explained in the next section 2 1 luisa territorial modelling platform agricultural land and its abandonment luisa is a pan european modelling platform 3 3 links to luisa web platform european commission joint research centre urban data platform http urban jrc ec europa eu territorial dashboard http urban jrc ec europa eu t board index htmlstrat board http urban jrc ec europa eu strat boardt pedia http urban jrc ec europa eu t pedia that provides alternative scenarios of territorial development in order to understand the local impacts and externalities of eu trends and policies the current configuration the eu territorial reference scenario 2017 integrates the most recent and accurate information available including past and future time series of socio economic and environmental aspects it also accounts for existing european policies and legislation e g common agricultural policy renewable energies trans european transport network eu biodiversity strategies and protection of natura 2000 areas for a more detailed account on luisa modelling framework and data sources we refer to jacobs crisioni et al 2017 for a comprehensive description of luisa s territorial reference scenario 2017 see appendix a discrete land use changes in luisa are modelled by optimizing the expected local utility values for land uses optimization is constrained by the available land in a region and by input expectations on total land area in the region that is needed by the modelled land uses a key input thus considers projected regional demand for agricultural land these demand projections are obtained from the 2016 capri baseline 4 4 2016 capri baseline was provided by the ec jrc directorate sustainable resource economics of agriculture unit jrc d 04 which integrates main policy macro economic and market assumptions up to 2030 while being consistent with the eu agricultural outlook 2016 2026 european commission 2016 agricultural demand is imposed in luisa as land area required for the expected production of food feed and energy crops and is expressed through a number of agricultural land classes that are aggregations of capri commodities the following systems are identified arable farming including rice livestock grazing systems mixed crop livestock production permanent crops and bioenergy crops jacobs crisioni et al 2017 perpiña castillo et al 2016 given regional demand for agricultural land and other land uses a dedicated discrete allocation mechanism available in the open source geodms software 2019 iteratively adapts the local utility until land use distributions are found that satisfy the modelling constraints hilferink and rietveld 1999 the underlying assumption is that grid cells function as implicit agents who change the use of their land if opportune in terms of utility and regional demand choosing from the bounded set of land use options that are modelled land based functions require investments with a long term time horizon utility is therefore computed as the net present value npv 5 5 npv is a standard method used in capital budgeting to appraise long term investments by measuring discounted time series of expected cash inflows and outflows while taking into account the time value of money of that land cover at a specific location to be regarded as economically attractive an investment should have a strictly non negative npv for all land uses utility is estimated in a spatially explicit way given local and global parameters similarly to the approach proposed by koomen et al 2015 and diogo et al 2015 1 n p v r i t y n r r t c t 1 d t y where i are the initial investment costs in ha e g land clearing demolition costs building costs acquiring agricultural machinery r r t are the annual gross revenues for raster cell r in year t in ha obtained from e g rental income revenues from selling crops subsidies c t are annual costs in ha e g maintenance costs field operations in agriculture n is the investment time horizon in years d is the discount rate the time horizon annual costs and discount rates are held fixed in the model regardless of location and modelling time initial investment costs do depend on the existing land cover in a specific location as the existing physical make up of a location may call for clearing or demolition operations revenues are highly dependent on location being calculated as follows 2 r r t s r t max r t where s r t the local suitability i e the percentage of maximum revenue to be obtained from a specific land use at a given location defined as the probability that a particular land cover exists given a set of geographic variable values and estimated through binomial logistic regression analyses on observed land cover patterns per country max r t is the maximum revenues in ha i e the annual revenues that are assumed to be obtained from a particular land use in case the local suitability is optimal i e s r t 100 the computed npvs are implemented in the allocation algorithm by employing a logit type approach derived from discrete choice theory mcfadden 1978 discrete choice theory aims to explain and predict the outcome of decision making process of economic agents when choosing among mutually exclusive alternatives the discrete choice model assigns probabilities for the different alternatives according to the utility of those alternatives in relation to the total utility of all alternatives when applying this model in a spatially explicit way the probability of choosing among mutually exclusive land based activities in a given location is computed as follows 3 x r i e β u r i k 1 k e β u r k where x r i is the probability of alternative land use i being chosen in raster cell r u r i is the utility of alternative i in raster cell r i e the npv of that activity in that particular location u k i is the utility of alternative k in raster cell r k is a finite number of mutually exclusive alternatives for land based activities and β is a parameter to adjust the model sensitivity typically 1 as default value 2 2 modelling future agricultural land abandonment in luisa the extent location and timing of farmland abandonment is modelled in three separate classes namely through abandoned arable crops permanent crops and fields used for livestock to do so both local likeliness and regional expectations of abandonment need to be provided for every 5 years model step expectations on future regional agricultural abandonment are dynamically quantified for each modelled country separately based on expected shares of land abandonment those were quantified based on per annum percentual losses of utilized agricultural area uaa as observed in corine land cover between 2000 and 2012 and are further supported by the reference values taken from the modelling exercises presented in van der zanden et al 2017 in every modelling time step percentage loss is converted into an absolute expected loss of area using prior total agricultural area and assigned a maximum and minimum value range in order to have sufficient degrees of freedom for the model to find an optimal solution at the local level abandonment is simulated in luisa s utility optimization approach as an alternative choice available to all grid cells that are currently used as agricultural land this approach thus considers abandonment a separate disinvestment decision that may be the highest utility outcome in specific locations and contexts so called allow rules govern which transitions between land uses are permitted within the simulation they are imputed in the model by imposing that the npv values for a non allowed transition are below the minimum threshold of the discrete allocation method so that effectively disallowed transitions are not considered through such allow rules only agricultural land types can become abandoned agricultural land while previously abandoned agricultural land can be converted into any land use type residential forestry etc save other abandoned land classes in a subsequent time step agricultural revenue and cost estimates were obtained from ustaoglu et al 2016 abandonment is modelled through assuming zero cost and a small fraction of the agricultural revenue to proxy revenues from disinvestment as a comprehensive eu wide map of agricultural abandonment is unavailable similar functions could not be induced for abandonment probability from empirically observed land use patterns an agricultural abandonment risk map has therefore been deduced by quantifying and mapping relationships found in previous studies see next section 2 3 2 3 european risk map of agricultural land abandonment the risk map 6 6 the risk map of agricultural land abandonment represents the probability of occurrence in terms of modelling is considered as suitability map and however partially responsible of the spatial allocation of future abandonment the risk map covers the eu and the uk of agricultural land abandonment is created by combining many factors into three groups related to biophysical agricultural socio economical and demographic and geographic factors table 1 these factor groups are defined by adapting and combining several methods from the recent literature benayas et al 2007 pointereau et al 2008 confalonieri et al 2014 terres et al 2015 lasanta et al 2016 levers et al 2018 each factor corresponds to a spatial thematic layer or statistical information at regional level from different data sources see appendix b table b 1 table b 2 and table b 3 the factor groups are further detailed in the next sections 2 3 1 biophysical factors a set of nine factors dealing with soil climate and terrain criteria 7 7 see table b1 appendix b for more detailed information is selected to determine where constraining natural conditions occur reflecting guidelines from eu regulation no 1305 2013 european union 2013 eliasson et al 2010 annex iii biophysical criteria for delimitation of areas facing natural constraints for generic agricultural activities the selected constraining conditions are expected to increase the risk of land abandonment this is spatially represented by merging the nine factors as a composite map of biophysical risk of abandonment appendix c fig c 1 the selection of these criteria is supported by many studies as described in alonso sarria et al 2016 and corbelle rico and crecente maseda 2014 variables such as slope precipitation and irrigated areas are relevant variables for abandonment in fact water availability is an important factor linked directly with agricultural profitability where even irrigated plots partially rely on precipitation land use is considered an important variable in relation with land abandonment in the sense that rainfed crops are more prone to abandonment than irrigated crops garcía ruiz 2010 nadal romero et al 2016 in relation to soil properties soils characterized by low nutrient content high salinity high proportion of clay and shallow soils are more prone to abandonment alonso sarría et al 2016 romero díaz et al 2017 negative multiplication effects among constraining conditions are also taken into account as proposed by terres et al 2014 although in a simplified way here locations where at least two severe limiting conditions coincide are considered to suffer severe limitations for agricultural activity thus having higher abandonment risk the values of these variables are held fixed throughout the simulation period 2 3 2 socio economic and farm structure factors economic and farm structure agricultural data is used to represent the stability viability and performance of regional agricultural systems indicating resilience against farmland abandonment these datasets are mainly gathered from fadn 8 8 the farm accountancy data network fadn is an instrument for evaluating the income of agricultural holdings and the impacts of the common agricultural policy the concept of the fadn was launched in 1965 when council regulation 79 65 established the legal basis for the organization of the network it consists of an annual survey carried out by the member states of the european union the services responsible in the union for the operation of the fadn 3 94 collect every year accountancy data from a sample of the agricultural holdings in the european union derived from national surveys the fadn is the only source of microeconomic data that is harmonized i e the bookkeeping principles are the same in all countries farm accountancy data network and dg eurostat fss 9 9 farm structure survey fss covers all agricultural holdings with an uaa of at least 1 ha or using market production as a threshold the main purpose of fss is to obtain reliable data at regular timing intervals two three years on the structure of agricultural holdings in the european union in particular in land use livestock and labour force the first time conducted was in 1966 67 approximately every ten years the fss is conducted in the form of agricultural census providing more detailed geographical levels mss transmit individual micro data to eurostat where they are stored in a database eurofarm the legal basis for the fss is regulation ec no1166 2008 of 19 november 2008 farm structure survey a harmonization exercise 10 10 harmonization process consist mainly of 1 filling gaps missing nuts3 data are filled by scaling up data from sub regions extrapolation and interpolation according to the variable 2 matching nuts3 regions between fss and fadn due to version discrepancies specifically fss used nuts3 v 2006 and fadn used v 2003 is necessary to merge fadn and fss data in a complete and consistent database the values of all variables selected here are averaged over the period 2005 2010 and subsequently considered static throughout the simulation period a normalization process is applied to facilitate comparison of results between countries table b 2 appendix b shows the main characteristics description and data source of the eight factors involved figure c 2 appendix c shows the spatial combination of economic and farm structure factors while in figure c 3 appendix c each factor is mapped individually 2 3 3 demographic and geographic regional factors two dichotomous variables are used to flag demographic and geographic factors that increase agricultural abandonment risk those variables indicate places with low population density and places that are remote appendix b table b 3 appendix c fig c 4 and c 5 areas with a population density below 50 inhabitants km2 are considered very low density areas terres et al 2015 remote areas are identified as areas that are more than 60 min driving away from the closest city or town dijkstra and poelman 2008 several studies corbelle rico and crecente maseda 2014 corbelle rico et al 2012 gellrich and zimmermann 2007 lange et al 2013 also highlight the fact that low population density and remoteness increase abandonment risk in low density areas infrastructure and public services are scarce and presumably relatively inefficient remote areas are characterized by limited economic opportunities and greater difficulties to reach markets thus agricultural activities there face higher transport cost and reduced competitiveness in luisa both local population densities a model output and travel times based on expected infrastructure investments typically change throughout the simulation period so that the demographic and geographic aspects in the compound abandonment risk map are not held fixed in the model 2 3 4 creating a compound risk map the last step for creating a compound agricultural abandonment risk map is the combination of the factor maps described in this section as table 1 shows the spatial combination is done through weighted linear addition wla with scores and weights assigned to each criterion particularly the biophysical risk map is assigned the highest weight 11 11 the biophysical factors receives the highest weight 0 4 out of 1 compared to the other two groups 0 3 out of 1 for each group following the assumption that natural constrains set the primary pre conditions for agricultural abandonment the values of the final composite risk map ranking from 0 to 100 is classified into five categories of abandonment risk following equal intervals very low 0 20 low 20 40 moderate 40 60 high 60 80 and very high 80 100 2 4 validation of the european risk map and the agricultural land abandonment a number of validation procedures were applied with the main purpose of evaluating the quality of the map in identifying either the risk of abandonment fig 1 or the projected abandonment in a specific location appendix d fig d 1 three different strategies were applied in this validation exercise a first approach entailed a comparison between the lucas 12 12 lucas land use cover area frame survey provides and harmonized land use cover statistics collected by eurostat in cooperation with the member states across the whole european union s territory in 2009 a soil module was included by the european commission tended to construct a topsoil database based on samples carried out every three years by surveyors in the field http ec europa eu eurostat web lucas data it should be noticed that in the lucas database no abandonment is observed in austria belgium denmark estonia croatia ireland the netherlands sweden and slovenia lucas database 2015 and the abandonment risk map observed abandoned land points from lucas database 389 points were overlapped with the five abandonment risk classes from the risk map in addition non abandoned agricultural points from lucas 79 769 points were also analysed in order to identify the potential abandonment risk of those furthermore the local extent of agricultural abandonment as reported in lasanta et al 2016 was compared with aggregated municipal agricultural abandonment extents as modelled in luisa lastly to verify the assumed relevance of the factor effects of which the abandonment risk map is composed a multivariate explanatory model is fitted to quantify the contribution of the selected factors to agricultural abandonment to do so all agricultural points both abandoned and not abandoned are selected from the lucas database the risk of abandonment in that subset is subsequently explained using the point values of all biophysical and economic factors table 1 with which the abandonment risk map is composed a binomial logit model eq 4 is used to estimate the effects of all variables so that 4 p a b a n d o n e d 1 exp β 0 β k x k ε where p refers to the probability of abandonment β 0 refers to the intercept β k is a vector of coefficients effect to be estimated x k refers to the independent variables and ε is the error term thus the contribution of all factors towards agricultural abandonment is quantified explicitly here all variables are defined as boolean factors where 1 true variables meet the criteria represents severe risk of agricultural abandonment and 0 represents no risk to make spatially compatible our variables in the model prediction all variables were transformed on a pixel basis 100 m resolution in raster layers 3 results 3 1 european risk map of agricultural land abandonment in 2030 almost 183 million ha of agricultural land are projected to be under different levels of potential risk of abandonment in the eu and the uk fig 1 the very large majority of that agricultural land will nevertheless be under very low 25 and low 50 risk of abandonment about 14 of the agricultural land is estimated to be under moderate risk of land abandonment this still leaves 11 and 0 4 700 kha of the agricultural land under high and very high potential risk of abandonment respectively abandonment prone areas are dispersed across europe linked to variation in the presence of risk factors biophysical factors appendix c fig c 1 appear to be the leading factor in large areas of austria poland greece spain estonia and latvia northern parts of sweden finland italy ireland southern parts of france and bulgaria particularly in regions with a mountainous character the apennines pyrenees alps dolomites carpathians the central massif in france or the iberian and cantabrian mountains considerable abandonment risk due to climate limitations is mostly found in mediterranean countries where soils suffer from drought like in greece italy spain but also in the united kingdom and scandinavia due to conditions promoting acidic and waterlogged soil conditions remoteness and low population density appear to be the major drivers of abandonment risk in the inner part of spain the middle and northern areas of sweden finland and ireland the northern and eastern parts of romania and partially in estonia latvia and lithuania hungary and cyprus appendix c fig c 4 and fig c 5 economic and structural farm factors appendix c fig c 2 and fig c 3 are primary causes for the high agricultural abandonment risk in many regions of spain the north of france greece and italy the central and northern parts of sweden and finland eastern bulgaria as well as in estonia latvia lithuania and hungary fig 2 shows shares of land under moderate high and very high risk of abandonment in proportion to regional area clearly the risk of land abandonment is not limited to mountainous areas and other vulnerable regions can be identified several regions accounting for more than 60 of the total surface under a high risk we identified in the northern part of portugal spain italy latvia estonia sweden finland austria and bulgaria 3 2 projections of agricultural land abandonment in luisa from european to local scale in the eu and the uk agricultural land is projected to be abandoned at an average rate of 373 kha per year reaching roughly 5 6 mha and accounting for approximately 3 6 of total agricultural land by 2030 arable land is expected to be the most prone to abandonment accounting for more than 70 of all abandonment in 2030 4 mha pastoral land 20 1 2 mha and permanent crops 7 400 kha make up smaller portions of total abandoned land almost a quarter 1 38 mha of all agricultural abandonment will most likely occur in mountainous areas 13 13 mountain areas have been spatially identified using the less favoured areas lfa classification map corresponding to the class named totally mountain hill areas from the spatial dataset 2000 2006 based on gisco communes version 2 4 where arable land would be the most affected agriculture system 974 kha i e 70 of all mountainous abandonment fig 3 presents absolute and relative extents of agricultural land abandonment between 2015 and 2030 spain and poland are likely to endure the most agricultural land abandonment both in absolute and relative terms spain is the only studied country expected to lose more than 1 million ha alone accounting for about 20 of all simulated losses in terms of absolute figures france germany and italy complement spain and poland in the group of the largest agricultural land abandonment in the eu altogether responsible for more than 70 of all losses conversely due to their relatively smaller total agricultural land the netherlands portugal finland greece and especially slovakia are expected to be above the 3 eu average landscapes and agricultural production systems vary considerably among eu mss and as a consequence so are national compositions of abandonment fig 4 abandonment of arable land is expected to be leading mode of abandonment in bulgaria cyprus denmark finland hungary lithuania and slovakia while abandonment of pastures will be predominant in ireland the netherlands and luxembourg permanent crops will account for a significant share albeit not predominant in southern european countries at the regional level fig 5 presents the projections of abandoned agricultural land as share of total agricultural land aggregated at nuts3 level in 2030 it confirms that spain is expected to face the biggest challenges in the eu especially in its north northwest other regions in southern europe are also likely to face significant land abandonment such as northern portugal 14 14 with the highest absolute loss of more than 27 thousand ha expected in terras de trás os montes pt11e southeastern france 15 15 nationwide the largest absolute loss of about 33 thousand ha is however projected for aveyron fr622 in southern france sardinia 16 16 projected about 48 thousand ha for sassari itg25 and 35 thousand ha for nuoro itg26 in italy and greece 17 17 korinthia el652 on the peloponnese peninsula and the island of lefkada el624 in central and northern europe substantial agricultural land abandonment is projected for western germany as well as in the northern hungary and southeastern poland where the largest absolute projected loss is found for the chelmsko zamojski region more than 85 thousand ha it is also worth noting that single regions in western austria innsbruck at332 and southern netherlands zuid limburg nl423 are expected to undergo a significant more than 30 agricultural land abandonment though this trend is not likely to spread to the surrounding regions the modelling exercise allows us to analyse agriculture land abandonment at the local scale for the whole eu territory fig 6 for illustrative purposes two zones where selected to exemplify areas affected by abandonment in spain murcia and greece karditsa northwestern from murcia city fig 6a a substantial amount of fruit trees the predominant permanent crop are expected to be abandoned however arable land is also abandoned in particular close to urban centres which is possibly related to modelled urban expansion a combination of factors seems to drive abandonment processes in this region some of the agricultural land is relatively remote more than 60 min to access the nearest town particularly in the western part this part of the region is also considered partially mountainous according to less favoured area criteria further adding to abandonment risk the murcia region is also characterized by areas with high salinity concentration and low annual precipitation the karditsa region fig 6b is characterized by farms with a moderate stability and viability increasing abandonment risk the areas of this region that are most prone to be abandoned are remote and partially or totally mountainous and in addition combine at least three biophysical factors slope higher than the range 15 30 heavy clay texture and low length of growing period that increase the risk of being abandoned this leads to substantial expected abandonment in the region mostly affecting arable land along with occasional patches of permanent crops vineyards 3 3 flows of land from agricultural land abandonment to other aggregated land uses trends of agricultural land vs abandonment analysing land use cover flows illustrate the main land use trajectories that are projected to occur within the simulation period fig 7 reveals that the conversion from agricultural land into abandoned land 4 8 mha or 2 7 of total agricultural land will dominate the inverse conversion of abandoned land for agricultural purposes 200 kha or 0 11 of abandoned land leaving a net conversion of about 4 8 million ha as loss of agriculture land at 600 kha the conversion from abandoned land into forest and natural areas is projected to be much larger entailing more than 10 of recuperation the creation of new built up areas is likely to be much less important recovering just 18 thousand ha about 0 3 of abandoned agricultural land between 2015 and 2030 comparing differences in shares agricultural land vs agricultural land abandonment from 2015 to 2030 provides important findings at the country level fig 8 some countries show simultaneous agricultural land increase and abandonment especially in portugal france greece malta spain croatia latvia cyprus and luxembourg this might indicate that agricultural production is being displaced to more productive areas within these countries however in austria czech republic germany lithuania the netherlands poland or slovakia there will be a net decrease of land occupied by agriculture so that abandoned land is not offset by increases elsewhere 3 4 validation of the european risk map of agricultural land abandonment as described in section 2 4 three different validation strategies are applied for the work at hand first we compare the risk map with observed abandoned agricultural land according to the lucas database this comparison yields that 67 7 of the total abandoned points from lucas falls within moderate high and very high categories 263 points while the remaining 32 2 corresponds to low or very low categories 126 taking into account that from the 79 769 observed non abandoned agricultural points in the lucas database only 3 6 are in high or very high risk areas it seems clear that agricultural abandonment is more likely in areas considered prone to abandonment risk second we compare local abandonment hotspots compiled by lasanta et al 2016 18 18 reported local shares of abandonment refers to the 35 study areas appendix e fig e 1 and areas modelled by luisa appendix d fig d 1 yielding considerable correspondence a summary table of the shares of land abandonment is elaborated to easily compare measured and modelled values appendix e table e 1 though herein a detailed explanation per each country is given in france 19 19 abandonment hotspots numbered as 1 2 5 8 and 10 covering the alps pre alps and central pyrenees accounting for 79 97 and 84 1 of abandonment shares respectively examples of local abandonment shares from luisa montjustin 94 ourdon 90 aspin aure 90 grust 91 claix 93 séchilienne 88 saint sigismond 95 thônes 91 avignonet 79 fouillouse 81 jarjayes 86 chèze 77 etc nuts3 regions that spatially overlap the reported mountainous areas are located in alps fr821 20 20 20 for the whole section we represent in brackets the code number of the nuts3 region or lau2 municipality and the associated abandonment share vaucluse fr826 7 hautes alpes fr822 18 hautes pyrenees fr626 4 and isere fr714 14 at municipality level lau2 the shares of abandonment dramatically increase up to 96 in sigoyer hautes alpes and the model is able to locally capture the extend and location of the reported hotspots of abandonment out of 34 overlapped municipalities 16 have an abandonment share greater than 80 similar to the abandonment reported hotspots spain 21 21 abandonment hotspots numbered as 12 13 14 15 16 18 19 21 22 and 23 are located across the cantabrian mountain central system sistema betico central pyrenees catalan prelitoral and iberian range gathers the major number of case study areas mainly due to the large distribution of mountain ranges from the north to the south within the iberian peninsula the set of nuts3 regions overlapping those reported abandonment hotspots are asturias es12 15 22 22 abandonment hotspots 12 13 and 22 with shares between 40 and 80 that correspond to the municipalities of allande teverga aller camaleño polaciones valdeolea and san roque de riomiera ranging from 38 to 53 of abandonment from luisa cantabria es13 14 guipúzcoa es212 20 madrid es300 9 23 23 abandonment hotspots numbered as 14 and 15 with shares between 75 and 89 that correspond to the municipalities of puentes viejas navarredonda y san mamés lozoyuela manzanares el real san ildefonso narrillos del álamo orihuela medinilla la carrera and piedrahita ranging from 42 to 81 shares from luisa ávila es411 8 salamanca es415 7 1 lleida es513 4 5 24 24 abandonment hotspots numbered as 18 and 21 with shares between 40 and 71 that correspond to the municipalities of torre de cabdella sort les valls d aguilar prullans la vansa i fórnols el pont de suert valderrobres monroyo castellote and villarluengo ranging from 31 to 85 rioja es230 17 5 25 25 abandonment hotspots numbered as 19 and 20 with shares between 42 and 99 that correspond to the municipalities of san asensio cenicero sotés haro tarazona borja ainzón fuendejalón and morata de jalón ranging from 33 to 81 of abandonment from luisa zaragoza es243 7 málaga es617 10 26 26 abandonment hotspots numbered as 16 and 23 with shares between 36 and 70 that correspond to the municipalities of villaluenga del rosario ronda alpujarra de la sierra nevada albondón torvizcón fiñana fondón felix lubrín macael oria and chirivel ranging from 45 to 74 of abandonment from luisa granada es614 12 almería es611 20 5 58 municipalities are analysed at local level in which abandonment shares ranging from 30 to 84 with the highest affected areas by abandonment in lleida el pont de suert 84 north of madrid navarredonda san mames and puentes viejas 80 and zaragoza borja and ainzon 80 and 81 respectively in the case of poland carpathian mountains and their surroundings areas beskid maly as well as the regions of mazovia podkarpacikie and podlaskie are identified as abandonment hotspots areas in particular nuts3 regions of chełmsko zamojski pl312 17 27 27 abandonment hotspots numbered as 6 9 32 and 36 with shares between 18 and 33 that correspond to the municipalities of skierbieszów krzczonów leśniowice krynice rybnik lyski godów proszowice koniusza and łapanów ranging from 31 to 64 of abandonment from luisa rybnicki pl227 17 5 and krakowski pl214 9 are spatially located over those areas with the greatest shares of abandonment projected by luisa focusing on agricultural abandonment at local scale 17 municipalities are assessed with shares accounting for from 32 to 66 the latter corresponds to lubycza królewska althought italy is one of the countries more affected by land abandonment this fact is not reflected in the number of reported study areas 28 28 abandonment hotspots numbered as 26 27 and 28 with 11 7 40 and 26 6 shares respectively that correspond to the municipalities of sondalo sernio valdidentro tirano colorina berbenno di valtellina baselga di pinè pergine valsugana vigolo vattaro sant orsola terme bedollo terlago micigliano borona antrodoco petrella ranging from 8 to 67 in italy from luisa outcomes the austrian municipalities in the point 27 and 11 are tux gerlos krimml absam gshnitz zirl and vals ranging from 21 to 61 of abandonment from luisa these areas are mainly located in the northeastern side of the italian alps belluno province and central apennines riete province limiting with austrian alps innsbruck at332 41 and tiroler unterland at335 8 3 in italy only sondrio itc44 3 and trento ith20 6 5 in the north and riete iti42 6 located in the central side showed spatial coincidence between the two sources at local level 17 municipalities are found to have a good match in relation to the abandonment shares exceptions are sondalo and sernio above 30 compared to 11 7 in riete region municipalities affected by abandonment are in the range of the reported hotspots by 30 local share except in micigliano that reaches 67 abandonment share in slovakia we can assess only one point number 7 placed in the carpathian mountains over the regions of prešovský kraj sk041 11 29 29 the abandonment hotspot numbered as 7 has a 20 share of local abandonment that corresponds to the municipalities in jakubova voľa ďurková drienica fričovce rokycany vyšný medzev medzev háj and bôrka ranging from 25 to 95 of abandonment from luisa and south narodny park slovensky kras sk042 5 at local level luisa reports much higher shares in all the municipalities evaluated 10 than the shares from the literature with the highest abandonment share in medzev 521671 at about 95 the opposite situation occurs in romania where only one point number 2 is observed in the area of arges region ro311 1 and its municipalities mostly present abandonment shares lower than 10 in baltics countries 30 30 there is not any studied abandonment area hotspot for lithuania reported from the consulted literature especially estonia and latvia several sites modestly reveals moderate low abandonment shares in estonia the region laane eesti ee004 3 31 31 abandonment hotspots numbered as 33 4 34 5 and 35 6 with shares between 10 1 and 50 that correspond to the municipalities of viimsi ikšķiles novads salaspils novads and cesvaines novads ranging from 11 to 40 of abandonment from luisa haapsalu and surju have the highest shares 40 and 28 respectively is the most affected by land abandonment in line with what it is stated by the literature however it is difficult to find modelled abandonment shares greater than 6 shares in latvia are even smaller but with some local picks in the central part of vidzeme lv008 3 5 reaching 50 abandonment shares in some areas as well as nearby latgale region lv007 5 2 due to the location of the daugava river basin and the presence of forestry and natural areas the last two south european countries greece and portugal also have assigned few studied abandonment points only two points each agricultural abandonment in greece are observed in the nisyros and lesvos islands that spatially overlap the άνδρος el422 10 32 32 abandonment hotspots numbered as 29 and 30 with shares between 20 and 77 in greece correspond to the greek island municipalities where the highest abandonment shares ranging from 4 to 5 up to 52 with the maximum values in νισύρου 8119 and κέας ιουλίδος 8209 accounting for 52 and 37 respectively though most of the shares are below 10 and λέσβος λήμνος el411 2 regions which means that luisa capture lower values in these islands in portugal the study areas were located in central inland near the river côa and alentejo whose nuts3 regions concur with beiras e serra da estrela pt16j 3 and alentejo litoral pt181 0 6 a set of municipalities lau2 33 33 abandonment hotspots numbered as 24 and 25 portugal with abandonment shares of 40 and 77 respectively correspond to the municipalities where the highest abandonment shares ranging from 6 up to 34 though most of the shares are below 5 were assessed yielding much lower modelled abandonment shares from luisa than the observed areas finally a logit expression see eq 4 is used to quantify the effect of selected abandonment risk factors table 1 on observed agricultural abandonment the results table 2 indicate a model with a high goodness of fit indicating that the selected factors can be used to accurately predict the presence of abandonment most of the estimators have significant effects with small p values in particular slope drainage precipitation lgp root depth farm age fa farm investment fi are considered the most relevant variables followed by farmer qualification remoteness and population density most of the estimators with low p values have the expected sign thus abandonment probability is greater with steeper slope more precipitation higher soil ph longer root depth older mean famer age poor famer qualification and in remote areas and abandonment risk is greater with less farm investment lower total subsidies and in areas with higher population density the estimators for soil drainage and length growing period significantly yield signs that are contrary to our expectations this can be explained due to the fact that both layers present a low spatial variability for which the highly localised abandonment data is not sufficiently detailed moreover better results could be obtained by the integration of irrigation maps as an economic factor which presumably reduces the risk of abandonment locally especially in semi arid regions 4 discussion even though agricultural land abandonment is a sizeable process in europe a wide overview and future outlook of abandonment are missing for the continent previous contributions covered case studies and partial aspects of the process garcía ruiz and lana renault 2011 lasanta et al 2016 which due to the considerable spatial heterogeneity of economic biophysical and climatic conditions cannot easily be generalized for a greater geography determining the extent and location of agricultural abandonment requires not only agreed upon definitions driving forces and potential impacts but also precise observed data and knowledge about the transformation and subsequent dynamics of the natural revegetation keenleyside and tucker 2010 verburg and overmars 2009 clearly the lack of an existing continuous and harmonized database inventory of land abandonment mars deeper more accurate analysis estel et al 2015 levers et al 2018 34 34 only lucas land use cover area frame survey 2015 version covers some member states with roughly 389 observations this is the information that we have used for the second strategy of validation the way to model agricultural abandonment by the luisa model differs substantially from previous abandonment modelling exercises in terms of assumptions spatial and thematic resolution and reference land use data to estimate the extent and locations of future abandonment luisa attempts to endogenously model agricultural land abandonment as a choice of disinvestment using a map of induced abandonment risk to capture the most likely locations of abandonment while taking into account the spatial heterogeneity of europe s farming conditions the most recent available data and information were used to compose that risk map however a set of uncertainties are intrinsically part of this type of modelling coming into play through choices such as thematic spatial and temporal resolution data availability geographical coverage assumptions and aggregation methods estel et al 2015 price et al 2015 for instance when examining factors table 1 by which the risk map is composed it is evident that both the lack of higher resolution for some spatial layers for instance length growing period or drainage and the low accuracy and spatial variability of some factors salinity and sodicity reduces the quality of the final results as is evident in the validation exercises another example is posed by agroeconomic variables which are available as regional averages clearly land abandonment depends on farm specific characteristics and therefore regional statistics offer a limited approximation for determining the precise location of farms at risk an extensive exercise has been executed to validate the inclusion of the agricultural abandonment model we find that the introduced agricultural risk map coincides with abandonment observed in the lucas database modelled abandonment coincides with the abandonment shares reported by lasanta et al 2016 although discrepancies can be found especially in spain portugal italy poland slovakia and latvia those discrepancies can be explained by to the fact that the abandonment hotspots reported in lasanta et al were measured very locally more than two decades ago a logit model has been used to verify whether the factors selected for the potential risk map contribute to a higher likeliness of observing abandoned agricultural areas according to the lucas definition this exercise corroborates that slope low precipitation poor drainage population density travel times and distance to farms increase likeliness of abandonment alonso sarría et al 2016 corbelle rico and crecente maseda 2014 regional farmer qualifications shares of older farmers farm investments and subsidies are also found to have the expected structural effect on abandonment likeliness confirming many previous results keenleyside and tucker 2010 prishchepov et al 2013 terres et al 2015 lasanta et al 2016 levers et al 2018 other variables did not yield significant effects or the expected signs which may be due to the limited amount of initial observations possibly agricultural areas where the condition at hand exists are already abandoned or local strategies were applied to overcome the difficulties caused by the condition that the variable describes agroeconomic regional variables such as farm size rental price farm income and share of rented land did not yield significant results no doubt because the local variation of those variables is substantial within a region these variables are nevertheless included in the potential risk map as they do assist in pinpointing in which regions abandonment is more likely to occur the variables indicating poor soil drainage and high levels of soil organic matter som yielded counterintuitive effects the results from som entail a paradox as fertile soil with high organic matter is in fact less prone to be abandoned agricultural areas with poor drainage may be compensated by irrigation systems thus raising sunk costs in the farm operation and making abandonment likeliness lower unfortunately the data necessary to verify this more thoroughly is unavailable or insufficient despite the many differences between prior modelling approaches luisa s abandonment results corroborate many of the findings of previous works the total abandonment share expected here is very similar to the 3 7 from the most moderate scenario reported by van der zanden et al 2017 however estimates of the amount of abandonment differ substantially recently estel et al 2015 and levers et al 2018 mapped active cropland fallow land and farmland abandonment with abandoned values ranging between 0 2 and 1 4 of the total farmland assuming high global competitiveness and lacking public support for farming keenleyside and tucker 2010 expect much more abandonment at a rate of 7 in terms of pinpointing the locations of abandonment again luisa corroborates many previous results similar to verburg and overmars 2009 and renwick et al 2013 substantial abandonment is expected here in mountainous areas however luisa also captures hotspots outside mountainous areas particularly in the northwestern spain galicia corsica northwestern and central part of portugal 35 35 in the surroundings of lisbon and oporto where some municipalities show the highest abandoned shares ranging from 56 to 85 as well as near the national park of peneda with abandonment shares around 50 baltic s countries 36 36 in the southern and northwestern part of latvia can be found some municipalities that show the highest abandoned shares near 15 such as aknīstes novads 0560800 rojas novads 0888301 or mērsraga novads 0887600 including new detected abandoned areas in lithuania 37 37 as alcantara et al 2013 identified luisa is able to find in lithuania lt00a 2 lt009 5 especially in the municipalities such as antakalnio seniūnija 1301 panerių seniūnija 1309 vidiškių seniūnija 4504 salako seniūnija 4348 etc where the highest abandonment shares range from 10 to 26 northwest of france northeaster and western part of poland 38 38 in olsztyński pl622 11 and szczecinecko pyrzycki pl427 9 5 some municipalities show abandoned shares ranging from 37 to 50 north of the national park nizke tatry slovakia 39 39 in nizke tatry žilinský kraj sk031 10 some municipalities show abandoned shares ranging from 25 to 95 and in the western side of the carpathians immediately in the north of arges region 40 40 especially in harghita ro12 7 mures ro125 6 3 or sibiu ro126 4 3 regions other sources are not definite on where abandonment would happen outside mountainous regions the luisa results are in line with locations reported by lasanta et al 2016 41 41 kuemmerle et al 2008 keenleyside and tucker 2010 kozak et al 2004 and pointereau et al 2008 in poland muller and kummerle et al 2009 in romania peterson and aunap 1998 nikodemus et al 2005 ruskule et al 2013 and van dijk et al 2005 in baltics countries pinto correia 1993 in portugal gomez moreno 1989 alonso sarría et al 2016 and perpiña castillo et al 2020 in the southeastern part of spain and occur especially in poland romania baltics countries the southeast of spain and the south of portugal estel et al 2015 and levers et al 2018 expect abandonment outside mountainous areas to occur in very different places casting some doubt on the luisa outcomes specifically for the iberian peninsula their predictions are not completely coincident with regional local studies carried out by many authors alonso sarría et al 2016 lasanta et al 2016 arnáez et al 2011 corbelle rico et al 2012 pinto correia 1993 nunes et al 2011 however a more comprehensive comparison of modelling approaches and results is called for here lastly due to its thematic detail and interactions between land uses luisa projects dynamics between land abandonment and other land uses e g residential industrial areas that are expected to occur in particular around main capital cities such as in paris madrid berlin or warsaw there in the simulations agricultural land becomes abandoned possibly as a precursor for urban expansion or urban sprawl these land conversions deserve further studies since they are likely related to the concept of land reservoir van der zanden et al 2017 grădinaru et al 2015 paul and tonts 2005 price et al 2015 when an abandonment process occurs it affects not only the abandoned area itself but also its local population and the whole society in terms of production of goods e g foods feed fibre and biomass production as well as other services provided by the multifunctionality of the agricultural land elbersen et al 2014 one of the most important function of agriculture is to feed the eu population and likely the food security can be one of the major challenges for the future of the eu especially for the rural economy terres et al 2015 for many regions in europe the agricultural sector still plays a significant economic role ecorys 2010 and its eventual decline due to massive abandonment among other factors might cause a loss of jobs in the agricultural and related sectors out migration of young people and a decline in the management of agroecosystems lasanta et al 2005 the decrease in agricultural land influences agricultural outputs and management practices changes in management practices such as agricultural intensification and specialization lead to high productivity in more fertile areas while causing marginalisation and abandonment in others baumann et al 2011 5 conclusion agricultural land abandonment is the largest land use change process in europe and it is expected to continue during the next decades land abandonment has been analysed in european mountainous and remote areas since the earlier decades of the 20th century but less effort has focused on other vulnerable areas this study therefore presents a comprehensive european spatially explicit exercise to model agricultural land abandonment this was done within the luisa territorial platform from the period 2015 2030 at a high spatial resolution for all eu countries and the uk abandonment is considered a dis investment decision and the location of abandonment is defined by an abandonment risk map deduced from previous findings in the literature that risk map was composed by combining a set of factors that presumably drive agricultural abandonment highlighting the importance of biophysical conditions agricultural socio economics farm structure demographics and geography by 2030 results reveals that the total abandonment is projected to reach more than 3 5 6 million ha of the total agricultural land while at the same time the decrease of agricultural land over the same period of time is an evident fact in most eu countries and the uk spain and poland are likely to account for one third of the eu total land abandonment whereas france germany and italy complement the leading group altogether responsible for more than 70 of the total abandonment this abandonment share is not equally spread across eu countries ranging from less than 2 to more than 50 at the regional level areas that are hot spots of undesirable abandonment might be particularly aimed at by policymakers in order to prevent or minimize present and future negative consequences and our results can be a valuable spatial and quantitative source of information to this end modelling dynamic indicators require a set of geospatial and statistical data whose availability accessibility and resolution are often limited potentially affecting the reliability of the data produced multiple strategies were followed in order to validate the implemented approach we need to emphasize the challenge of direct comparison with other sources because for instance temporal coverage data assumptions abandonment definitions and spatial location vary among all those studies despite differences in location and extent we stress the considerable spatial overlapping between luisa and other datasets and model results definitively luisa projections of abandonment however seems to be conservative but in line with european average figures when compared to case studies based on policy scenarios and modelling disclaimer the views expressed are purely those of the author and may not in any circumstances be regarded as stating an official position of the european commission declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a description of luisa luisa coherently links specialised macro economic demographic and geospatial models with other thematic spatial statics databases in order to simulate the local allocation of land functions i e housing transport food production or ecosystem services land claims are provided by those models that govern the starting stage of the simulation primarily based on dg ecfin 42 42 directorate general for economic and financial affairs of the european commission projections in particular demographic projections rely on europop 2013 43 43 dg eurostat 2013 for the period 2015 2060 at national level capri model britz and witzke 2012 provides future agricultural land demands aiming at modelling changes in cap common agricultural policy policies economic projections are derived from the gem e3 and the rhomolo model while energy projections depend on the jrc eu times model the reference spatial map named the luisa base map 2012 44 44 the luisa base map 2012 is an enriched version of corine land cover 2012 but with a significantly higher spatial and thematic resolution mainly owing to the integration of relevant land use cover information from multiple compatible geodata sources copernicus high resolution layers urban atlas european settlement maps etc jacobs crisioni et al 2017 is an enriched version of corine land cover 2012 but with a significantly higher spatial and thematic resolution mainly owing to the integration of relevant land use cover information from multiple compatible geodata sources 45 45 copernicus high resolution layers urban atlas european settlement maps etc model run therefore provides outcomes at local scale 100 m resolution with a temporal resolution of 5 years for all eu countries and the uk throughout a simulation period currently up to 2030 sectoral claims are allocated over the land according to their specific location and recent land use class land suitability restrictions of spatial policies transition rules neighbourhood effects etc more information about luisa application key components modular structure and methods can be found in jacobs crisioni et al 2017 baranzelli et al 2016 and lavalle 2017 figure a 1 shows a simplified scheme of the luisa platform in order to reflect top down dynamics in modelling agricultural land abandonment while competing with other land uses fig a 1 adapted and simplified luisa scheme to illustrate the workflow and main components for modelling specifically agricultural land abandonment fig a 1 the allocation mechanism is located at the core of the luisa s modelling platform as a system of equations that repeats itself every five years until the end of the simulation period is reached typically in 2050 following the next steps as shows figure a 2 1 describe the geographical context of every modelled region and grid cell by mapping a large breadth of exogenous and endogenous external factors 2 describe function pressures in particular what is considered as the population pressure or the intrinsic attractiveness of a grid cell for human settlement 3 reallocate the physical manifestation of land uses based on a special case of the doubly constrained land use optimization mechanisms described in hilferink and rietveld 1999 and land use specific local utility estimates computed as described in koomen et al 2015 and lastly 4 redistribute land based functions in particular population based on environmental characteristics and reallocated land use maps fig a 2 luisa modelling framework for simulation of land use change following pressures for the provision of land based functions adapted from jacobs crisioni et al 2017 fig a 2 appendix b description and data sources of the factors that drive agricultural abandonment table b 1 selected biophysical criteria for identifying severe natural conditions for generic agricultural activities their description and main reference table b 1 biophysical land suitability factor description reference length of growing period the number of days when the average daily temperature is above a certain temperature threshold lgpt5 is selected establishing 5 c as threshold spatial resolution 8 km grades arc iiasa fao 2013 a organic matter topsoil 0 30 cm organic matter content spatial and temporal resolution 1 km processed in 2012 hiederer 2016 based on esdb and hwsd iiasa fao isric isscas jrc 2012 soil drainage it refers to the maintenance of the gaseous phase in soil pores by removal of water imperfect poor and very poorly drained soils are considered not favourable for crop growth spatial resolution 1 km sinfo project b eurostat european commission 2013 which is based on esdb c precipitation the total mean annual precipitation is calculated as the sum of the mean monthly precipitation the mean annual precipitation in mm was divided into seven classes with 200 mm intervals from 0 to 1000 mm spatial resolution 1 km processed in 2012 efsa d eurostat european commission 2013 hiederer r 2016 soil ph spatial layer of topsoil ph which represent the ph given for the dominant soil soil ph exceeding 9 or below 4 extreme values is considered not favourable for crop growth spatial resolution 1 km efsa eurostat european commission 2013 based on hwsd e iiasa fao isric isscas jrc 2012 root depth to ensure maximum root development due to the presence of specifics horizon that cannot be penetrated by the roots this spatial layer is divided into eight classes from 10 to 120 cm spatial resolution 1 km sinfo project f eurostat european commission 2013 which is based on esdb g soil texture five classes were defined coarse medium medium fine fine and very fine soil texture with less than 18 clay more than 65 sand or which have stones boulders or rock at the surface are considered not favourable for crop growth spatial resolution 1 km sinfo project eurostat european commission 2013 which is based on esdb slope derived from the elevation was divided into six classes flat areas or with a slope 8 are the most appropriated for crop growth slopes in excess of 16 will provide difficulty for harvesting machinery spatial and temporal resolution 100 m 2013 shuttle radar topographic mission nasa 2013 salinity medium or high salinity concentration areas are proposed as unfavourable agricultural conditions producing significant losses of production and serious damage to the crop spatial resolution 1 km sinfo project eurostat european commission 2013 which is based on esdb sodicity soil sodicity is a land characteristic for which the proportion of absorbed sodium in the soil clay fraction is too high for plants to perform or survive spatial resolution 1 km sinfo project eurostat european commission 2013 which is based on esdb a iiasa international institute for applied systems analysis and fao food and agricultural organization of the united nations b sinfo project soil information system for the mars crop yield forecasting system c esdb european soil data base d efsa european food safety authority spatial data version 1 1 e hwsd harmonized world soil database f sinfo project soil information system for the mars crop yield forecasting system g esdb european soil data base table b 2 main farm structure and agricultural viability factors that drives agricultural land abandonment their description and main reference table b 2 economic viability of agricultural production description reference age of farmers it is computed as a share by taking into account the number of farmers 65 year old over the total number of farmers it is assumed that abandonment is more likely to occur when the farmer is close to the retirement age factor interpretation the higher the share of farmers older than 65 years old the higher the abandonment risk spatial resolution nuts3 level eurostat fss eurostat european commission 2017 data holders above 65 ef r farm2007 xls farmer qualification three different levels of training of farm managers are specified with only practical experience basic and full agricultural training it is computed as a share of farmers with practical experience with regard to the total number of trained farmers farmer with high qualification invest more in human capital knowledge etc thus preventing farmland abandonment factor interpretation the higher the share of farmer no qualified only practical experience the higher the abandonment risk spatial resolution nuts0 level eurostat eurostat european commission 2017 data total ef mptrainman xls practicalexperience ef mptrainman xls farm size share of farms uaa under 50 of the average size region nuts3 the rationale behind is that larger farms can share agricultural resources machinery inputs buildings etc and thus reducing production costs in this way large farms compared to small fragmented farms are usually more competitive and viable from an economic point of view factor interpretation the higher the share the higher the abandonment risk spatial resolution nuts3 level eurostat fss eurostat european commission 2017 data size and type ef r farm 3 xls rent paid rent paid se375 a for farmland and buildings and rental charges b rent paid is used as a proxy of the strength or weakness of the land market it is assuming that high rental prices leads to high demand for agricultural land and therefore a low risk of abandonment units euro factor interpretation the lower the rental price the higher the abandonment risk spatial resolution nuts samples fadn dataset and dg agri rica especial request rented uaa utilized agricultural areas rented se025 by the holder under a tenancy agreement for a period of at least one year remuneration in cash or in kind it is expressed in hectares 10 000 m2 5 it is computed as a share of the rented uaa over the total uaa the average is calculated for the years 2005 2010 for each holding in the database units hafactor interpretation the lower the rented uaa the higher the abandonment risk spatial resolution nuts samples fadn dataset and dg agri rica especial request farm income farm net value added se425 expressed per agricultural work unit takes into account any differences in the labour force to be remunerated per holding 5 this variable is used as a proxy of economic performance compared to the gross domestic product gdp per capita from the period 2005 2010 national gdp is a proxy of national income units euro factor interpretation the lower the income the higher the abandonment risk spatial resolution of gdp nuts0spatial resolution of farm net value added nuts samples fadn dataset and dg agri rica especial request eurostat eurostat european commission 2017 data nama gdp c xls euros capita at market price farm investment net investment se521 is defined as gross investment depreciation 5 this variable is normalized by the size of the farm uaa c at sample level this can be interpreted as a proxy of improving new machinery new technics and continuing farm activities hence reducing the risk of abandonment units euro factor interpretation the lower the investment the higher the abandonment risk spatial resolution nuts samples fadn dataset and dg agri rica especial request farm scheme subsidies subsidies on current operations linked to production not investments interest subsidies and payments for cessation of farming activities are therefore not included5 the indicator is computed by using the variable farm subsidies se605 normalize by the uaa sample area units euro factor interpretation the lower the subsidies the higher the abandonment risk spatial resolution nuts samples fadn dataset and dg agri rica especial request a codes assigned by fadn for the selected variables b defined by fadn european commission 2000 c uaa not include areas used for mushrooms land rented for less than one year woodland and the other farm areas roads ponds non farmed areas etc it is made up of land in owner occupation rented land land in sharecropping remuneration linked to output from land made available it includes agricultural land temporarily not under cultivation for agricultural reasons or as a result of being withdrawn from production as part of agricultural policy measures table b 3 main demographic risk factors favouring farmland abandonment low population density and remote areas table b 3 demographic and regional context description reference low population density areas population density below 50 inhabitants km2 is considered low populated areas in our study being much lower than the threshold used in other methods 150 inhabitants km2 several dynamic test were done to set up this cut off value in order to better capture rural areas with very low population density the modelling mechanism counts for each cell the allocated residents within a surrounding kernel with an area of approximately 1 km2 then it is possible to identify the cells with less than 50 inhabitants inside the surrounding kernel luisa population density map based on europop2013 nuts3 level terres et al 2015 remoteness remote areas are represented as a dynamic map of travelling time to nearest town town access is defined as dynamic map of travelling time to the nearest town couple with access to the nearest town this indicator also takes into account changes in travelling times between time steps thus remote areas are identify as those that are further than 60 min away from towns dijkstra and poelman 2008 terres et al 2015 appendix c individual maps of biophysical agricultural economy and demographic and regional context fig c 1 number of biophysical factors spatially concurring for classifying land suitability for agricultural generic activities in the eu countries and the uk fig c 1 fig c 2 map combining economic and farm structure drivers of agricultural land abandonment in the eu countries and the uk period 2005 2010 fig c 2 fig c 3 individual economic and farm structural factors for determining the stability and viability of farming activities for preventing agricultural land abandonment in the eu countries and the uk a share of farmers older than 65 years old b share of farmer with only practical experience c share of farms under 50 of the average size region d rental price e farm income f share of rented uaa g total subsidies and h farm investment fig c 3 fig c 4 map of remote areas computed at member state level adding also the uk 2015 fig c 4 fig c 5 map depicting low population density areas in the eu countries and the uk 2015 fig c 5 appendix d map of the projected agricultural land abandonment in the eu and the uk fig d 1 future projections of agricultural land abandonment at grid level 100 m resolution in the eu and the uk 2030 fig d 1 appendix e farmland abandonment in the european mountains fig e 1 distribution of the reported local shares of abandonment hotspots refers to the 35 study areas identified in lasanta et al 2016 table e 1 simplified version of the table from lasanta et al 2016 first five columns combined with the luisa results regional and local level in 2030 last two columns additional hotspots abandonment areas captured by luisa are also reported in bold table e 1 code country locations share of farmland abandonment reference regional nuts3 share of abandonment from luisa 2030 local lau2 share of abandonment from luisa 2030 1 france alps briançonnais 79 in lasanta et al 2016 alps fr821 20 52 61 2 pre alps provence 97 in lasanta et al 2016 vaucluse fr826 7 hautes alpes fr822 18 53 94 50 96 5 central pyrenees 84 1 in lasanta et al 2016 hautes pyrenees fr626 4 64 91 8 pre alps 20 in lasanta et al 2016 isere fr714 12 60 88 32 3 mazovia podkarpacikie and podlaskie 17 6 keenleyside and tucker 2010 chełmsko zamojski pl312 17 43 66 36 7 poland beskid maly 33 rybnicki pl227 17 5 34 51 6 1 slovakia poland and ukraine carpathian mountainscarpathian mountains and surroundings 20 20 7 13 9 and 13 3 in lasanta et al 2016 krakowski pl214 9 31 41 9 8 luisa platform olsztyński pl622 11 szczecinecko pl427 9 5 38 50 37 43 7 slovakia carpathian mountains 20 in lasanta et al 2016 prešovský kraj sk041 11 south narodny park slovensky kras sk042 5 61 90 61 91 luisa platform national park nizke tatry north žilinský kraj sk031 10 25 95 10 italy austria france germany switzerland alps 20 70 in lasanta et al 2016 haute savoie fr718 10 4 26 95 11 austria italy eastern central alps 40 in lasanta et al 2016 innsbruck at332 41 and tiroler unterland at335 8 5 31 61 12 spain cantabrian mountain south 40 in lasanta et al 2016 asturias es120 15 2 cantabria es130 14 país vasco montes vascos 20 43 53 38 48 32 63 13 spain cantabrian mountain nord 50 in lasanta et al 2016 22 spain cantabrian mountain 80 in lasanta et al 2016 14 spain central system 89 in lasanta et al 2016 sierra de ayllon and north of madrid es300 8 7 42 80 15 spain central system 75 in lasanta et al 2016 ávila es411 and salamanca es415 salamanca 7 1 31 78 16 spain sistema bético 36 in lasanta et al 2016 malaga es617 3 8 10 18 spain central pyrenees 71 in lasanta et al 2016 lleida es513 4 5 teruel es242 9 3 tarragona es514 8 7 53 85 21 spain catalan prelitoral mountain 40 in lasanta et al 2016 31 65 19 20 spain iberian range and iberian range 99 42 arnáez et al 2011 in lasanta et al 2016 rioja es230 17 5 zaragoza es243 7 33 57 31 81 23 spain sistema bético alpujarras 70 in lasanta et al 2016 sierra nevada es614 12 almeria es611 20 5 53 74 54 64 es spain macizo galaico y montes de leon luisa platform north of portugal lugo es112 44 ourense es113 41 pontevedra 114 26 a coruña es111 30 es spain catalan prelitoral mountain luisa platform navarra es220 6 guipuzcoa es212 29 and es spain iberian range and iberian range luisa platform teruel es242 9 3 and castellon es522 9 in the south of iberian range 24 portugal central inland 80 nunes et al 2011 beiras e serra estrela pt16j 3 20 60 25 portugal alentejo 40 pinto correia 1993 alto alentejo pt186 1 5 6 pt portugal lisbon luisa platform lisboa pt170 10 parque nacional de peneda c cávado pt112 20 and ave pt119 21 oporto pt11a 21 56 85 50 65 43 49 26 italy alps 11 7 in lasanta et al 2016 sondrio itc44 3 8 37 27 italy eastern alps 40 in lasanta et al 2016 trento ith20 10 29 48 28 italy apennines 26 6 in lasanta et al 2016 rieti iti42 6 25 67 it italy torino sicilia luisa platform teramo itf12 5 7 napoli itf33 5 avellino itf34 9 torino itc11 1 3 messina itg13 6 catania itg17 5 reggio di calabria itf65 3 4 31 66 31 68 33 83 29 greece nisyros island 76 4 in lasanta et al 2016 κάλυμνος κάρπαθος κως ρόδος el421 3 4 52 30 el greece greece lesvos island north and central greece central peloponeso 20 in lasanta et al 2016 luisa platform λέσβος λήμνος el411 2 κορινθία el652 20 αργολίδα αρκαδία el651 9 καρδίτσα τρίκαλα el611 5 38 45 37 71 28 41 6 42 90 31 2 romania arges county 21 in lasanta et al 2016 arges ro311 1 romania central romania luisa platform 33 4 estonia several sites 10 1 and 30 in lasanta et al 2016 lääne eesti ee004 3 western and southwestern part 28 40 34 5 latvia latgale and other regions 10 3 21 1 and 50 in lasanta et al 2016 pieriga lv007 5 2 river 6 11 35 6 latvia vidzeme 25 35 in lasanta et al 2016 vidzeme lv008 3 5 15 lv latvia luisa platform zemgale lv009 2 6 south kurzeme lv003 2 7 west 12 12 16 codes represent the studied abandoned areas in fig e 1 share of abandonment represents the minimum and maximum local value within the corresponding nuts3 region overlapping the studied abandoned point hotspot areas from lasanta et al 2016 
