index,text
25800,climate change poses increasing challenges to aquaculture resulting in the need to develop appropriate tools to assess these challenges and support decision making we present climegreaq a software based decision support system dss co created with stakeholders to support the adaptation of greek aquaculture to climate change the dss is based on an integrated modeling approach which links a biological and an economic model in order to simulate the effects of climate drivers on greek aquaculture in a spatially heterogeneous manner the tool may be used by stakeholders including farmers producer organizations regional administrations and national authorities to support decision making on questions ranging from selecting appropriate farming locations to designating zones for aquaculture activities to developing national climate adaptation plans along with a description of the dss design process its structure and the constituent models key results are presented relating to stakeholder involvement the user interface and several application examples keywords climate change adaptation aquaculture decision support system stakeholder co creation bio economic model 1 introduction food production systems are increasingly under pressure at a global scale from threats stemming from climate change marine aquaculture in particular faces special challenges due to the nature of the activity which allows little control over environmental conditions at the rearing sites this may relate to threats regarding the biology of the farmed species such as reduced growth and survivability but it can also include financial implications for individual farms like increases in the various costs which in turn lead to lower profitability in fact it has been postulated that climate change may have profound implications for aquaculture production the livelihoods of its associated communities and consequently for national economies brander et al 2018 rosa et al 2012 a case in point is greece one of the main producers of european seabass dicentrarchus labrax and gilthead sea bream sparus aurata in europe representing over 60 of the total european production feap 2017 these species are predominantly farmed in marine cages which therefore renders marine aquaculture the focus of this article moreover aquaculture products rank amongst the most important agricultural exports for greece and thus make a significant contribution to the national economy fgm 2019 it is therefore crucially important that potential threats as well as opportunities arising from climate change are assessed and adaptation actions are taken where needed however assessing the effects of climate change on aquaculture production is rarely self intuitive for decision makers this is due to the multitude of environmental drivers associated with climate change temperature acidification extreme events shifts in ocean circulation and harmful algal blooms habs among others their complex interactions with the production systems as well as among them and the knowledge gaps regarding the biological responses of farmed fish to these drivers dabbadie et al 2018 wells et al 2020 as a result developing strategies to adapt to climate change remains cumbersome for decision makers one option to support and facilitate decision making in this context is the development of appropriate tools that can aid decision making these tools which are referred to as decision support systems dss must be able to provide supporting information to decision makers so that management and policy makers can take strategic decisions to promote sustainability of the industry in the coming decades in addition these tools must achieve a balance between the information they contain and user friendliness to make them easily accessible to decision makers wenkel et al 2013 in this paper we present such a dss climegreaq developed to support decision making for greek marine finfish aquaculture under climate change in general dss are information systems designed to facilitate decision making in relation to complex problems their main functionality lies in allowing users to test specific management objectives by comparing alternative states of their system recent achievements in computer science have spurred the development of novel interactive software based systems capalbo et al 2017 holzworth et al 2015 with some of them focusing on impacts of environmental changes on food production cobo et al 2019 hermawan and syafrani 2015 sturm et al 2018 wätzold et al 2016 with respect to the specific challenge of climate change several dss have also been developed ranging from risk assessments using scenario based approaches han et al 2017 lieske 2015 schweizer 2019 to more sophisticated interactive tools that tackle issues related to the management of water and energy resources land use and biodiversity kašpar et al 2018 kazak 2018 pierleoni et al 2014 ziaja 2019 in addition long term environmental impacts have been simulated for pond aquaculture with the objective of establishing a comprehensive background for the subsequent development of a dss varga et al 2020 however the connection between climate change and aquaculture in a dss form remains elusive overall decision support systems in aquaculture are scarce despite the substantial number of such systems produced in other domains nevertheless a few dss exist in aquaculture which are increasingly adopting software based approaches in an effort to tackle the highly complex and multifactorial nature of farming and its interactions with the natural environment casini et al 2015 for instance the inclusion of geographical information systems in tools that support decisions in fish farming has been suggested falconer et al 2018 while other technologies such as particle swarm optimization techniques have already been developed for other applications cobo et al 2019 other approaches include multi criteria decision making methodologies as in the case of a gilthead seabream dss for feeding strategies luna et al 2019 and the development of dss for optimizing site selection according to the prevailing environmental conditions halide et al 2009 nobre et al 2009 stelzenmüller et al 2017 yet as has been highlighted by mathisen et al 2016 most of these efforts fail to capture the complexities required for decision making in aquaculture since they are generally focused on a small number of drivers and species moreover there are significant gaps related to decision support in a climate change context as none of the existing dss for aquaculture deals specifically with future projections of climate drivers responding to the need to develop tools for informed management in aquaculture under a changing climate this article describes climegreaq a software based dss for greek aquaculture the aim of climegreaq is to simulate and visualize biological effects of climate change on typical farmed fish species and their repercussions on farm economic indicators for greek aquaculture under different climate scenarios and over distinct future periods extending up to the year 2050 this includes effects of climate drivers such as temperature and wind velocity in several areas throughout greece which allows the consideration of spatial heterogeneities across the country caused by differences in the projected climate conditions moreover in addition to simulating and visualizing climate change impacts the dss includes an optimization module for some farming parameters by doing so it allows its users to investigate alternative what if scenarios in a changing climate and support strategic decisions based on the relative differences between the possible outcomes in order to consider links between biological and economic impacts a bio economic modeling procedure drechsler 2020 was adopted for its development following established practices for investigating the effects of changing environmental conditions in aquaculture systems besson et al 2016 cobo et al 2019 the dss was developed in collaboration with stakeholders in the context of the eu project horizon 2020 climefish https climefish eu following the co creation suggestions of the european commission european commission 2014 the co creation approach aims at increasing the relevance of the generated products for their users in this case greek aquaculture stakeholders such as farmers producer organizations as well as regional and national authorities in that way the dss may be useful for supporting decisions at small scales such as the management of farms in terms of selecting appropriate seeding schemes and farming locations but also at medium and larger scales by aiding policy makers in designating or modifying aquaculture activity zones or in developing climate adaptation plans at a national level for this reason the implementation of climegreaq occurred in stages between which stakeholder feedback was gathered and taken into consideration for its further development a prototype version of the dss produced in the early stages of the project has already been presented in stavrakidis zachou et al 2018 since then substantial changes additions and refinements have been implemented the software based dss presented in this article is the final version of the climefish dss for aquaculture stakeholders in greece it contains all the updates and new functions that have been implemented into the software and particularly the stakeholder suggestions that emerged during the co creation process specifically compared to the earliest version presented in stavrakidis zachou et al 2018 the tool contains improved biological forecasting in terms of key biological parameters such as fish growth and feed consumption for the 2020 2050 period the forecasting has been obtained using downscaled climate projections at a higher spatial resolution than before moreover the spatial extent of the analysis is enlarged from pilot regions to the entire country while effects of extreme weather events such as heatwaves and storms on fish growth and biomass production are also incorporated additionally to those of temperature in terms of further methodological advancement an optimization module has been implemented moreover the tool includes an additional species a risk assessment updated maps and other visualizations and finally secondary windows and info boxes for user orientation the risk assessment is ignored in the following as it is based on a different methodology and was included in the software to provide stakeholders with one single platform where they could access all climefish tools further information about the risk assessment can be found in the manual and in the case study description of the climefish toolbox http 136 144 228 39 8080 climefish 2 methods 2 1 process of software design and experimental testing climegreaq was developed applying a co creation approach which implies close interactions between scientists and stakeholders throughout the different stages of dss development as highlighted by mcintosh et al 2011 engaging stakeholders as early as possible in a co creation process is crucial for ensuring the relevance of the generated tools for the users as well as their longevity beyond a project s lifetime regular meetings with stakeholders are necessary to present the dss idea as well as preliminary and final results the purpose of such meetings is to gather feedback for the improvement of the dss in terms of relevance of proposed parameters adequacy for addressing the problem of climate change impacts on greek aquaculture user friendliness and model validation this feedback shall then be taken into account in the further development of the dss and the underlying model fig 1 illustrates this process 2 2 overview of the structure climegreaq utilizes biological and economic information to simulate and visualize the effects of selected climate drivers on greek aquaculture production climegreaq differentiates between nine greek regions and considers for each region inshore and offshore production resulting in eighteen representative farms its core structure is a coupled biological and farm economic model the biological model is integrated in the dss through a local mysql database while the farm economic model is implemented into the software in addition the interactions of these components with the user occur via a user interface fig 2 the decision support capacity of the software lies in allowing users to create and compare a wide range of alternative future climate change and management scenarios to accomplish that a model farm approach was adopted which targets representative farms throughout the greek territory as the basis of the analysis such an approach appears to have increasing relevance for aquaculture as indicated by current research besson et al 2016 cobo et al 2019 piedecausa et al 2010 for the various climate scenarios the biological model for the model farm simulates a production cycle for a group of fish and reports several parameters of interest such as time to market size feed consumption and biomass at a harvest size specified by the user subsequently the farm economic model uses the output of the biological component as well as other economic data input to estimate relevant farm economic parameters due to considerable computational time the biological simulations are not done by the software but comprise a selection of precomputed scenarios which are stored in the local database all other computations happen in real time 2 3 biological model and simulations this section provides an overview of the biological model including the overall framework it is based on and the main linkages among its components as well as a description of the data and scenarios used for the simulations for a detailed description of the biological model and the development process the parameters and the formulae used in the simulations we refer to stavrakidis zachou et al 2021 and the respective supplemental electronic material 2 3 1 the deb model the biological model is based on dynamic energy budget deb theory via the deb framework the bioenergetics of an individual fish can be described as a function of temperature and food availability by following certain rules for the uptake of energy and its utilization by the organism kooijman 2010 according to this framework the weight of an individual comprises of structure reserve and in the case of adults also of reproductive biomass the various metabolic processes are fueled by mobilized reserve which is formed during the process of assimilation during feeding part of the food consumed by the organism is assimilated into reserve while the rest is lost through defecation at any given time a fraction of the mobilized reserve κ is used for growth and the rest 1 κ for maturation or reproduction purposes specifically growth is incorporated as increase in the structural biomass structure of the organism after maintenance costs have been paid on the other hand maturation represents investments in development with life stage transitions occurring at specific maturation thresholds and in the case of reproducing adults the production of gonads after subtraction of the respective maintenance costs all these processes are governed by temperature with the temperature effect on the various physiological rates being quantified via the arrhenius relationship in the deb context aguera et al 2015 kooijman 2010 stavrakidis zachou et al 2019 in this framework changes in measurable quantities such as weight and feed consumption for a single fish can be predicted as a function of temperature and food availability which can be provided as inputs moreover this process can be repeated for many individuals thus extrapolating the output to the population level an overview of the biological model scheme and the general method including the inputs and outputs of the model is provided in fig 3 deb models were developed for two species the e seabass dicentrarchus labrax and the meagre argyrosomus regius and were validated against production data from farms the parametrization of the models was done according to the procedure described in marques et al 2019 using information from published literature as well as experimental work conducted at the hellenic center for marine research hcmr for model validation eight datasets growth measured as the evolution of weight over time and feed consumption from greek farms at various locations were used after simulating the temperature and feeding conditions at those locations the model predictions were compared with the farm data a close overlap of model predictions with farm observations indicated that growth was captured accurately by the model while there was a slight tendency towards underestimating feed consumption specifically in all cases the weight and feed consumption values predicted by the model did not deviate more than 20 from the observed data coefficient of variation 0 2 further details on the parameterization and validation of the two models can be found in previous publications stavrakidis zachou et al 2019 2021 2 3 2 simulations simulations were performed for nine greek regions and for three time periods denoting short mid and long term effects 2015 25 2025 35 and 2045 55 under the ipcc intergovernmental panel on climate change climate scenarios rcp4 5 and rcp8 5 for these scenarios the projections of temperature and wind velocity were forced on a group of fish to simulate a three year production cycle at farm level the environmental variables comprised of downscaled 10 10 km projections of the global climate model ichec ec earth via the coupled polcom ersem ecosystem model proudman oceanographic laboratory coastal ocean modeling system and the plymouth marine laboratory european regional seas ecosystem model in addition for each region two farms were considered one inshore and one offshore this was done to assess effects on exposed locations since offshore aquaculture has been recognized to have great potential for the future of mediterranean finfish aquaculture porporato et al 2019 furthermore adapted seeding planning was incorporated into the simulations via the inclusion of three seeding months march june september predictions of growth in terms of the time needed to reach a specified market size the number of fish the total biomass the cumulative feed consumption and the feed conversion ratio fcr were then computed for the different climate and management scenarios the latter referring to the various production options such as site selection and seeding time and size moreover a preliminary assessment was done to determine the sensitivity of simulation outputs such as growth to climate model uncertainties specifically bootstrap samples of temperature and wind velocity time series were generated within each time period as described in stavrakidis zachou et al 2021 and were used to run simulations for an individual fish overall climate uncertainty produced little variability in all considered climate scenarios as indicated by the narrow width of the grey shaded area coefficient of variation 0 05 for this simulation fig 4 our model focuses on temperature as the main climate driver modeling other drivers explicitly would have been difficult due to a lack of supporting data on environmental projections inadequate spatial resolutions and significant knowledge gaps regarding the biological species specific effects of other drivers however in line with recommendations from stakeholders who emphasized the need to include additional drivers an indirect approach was followed to incorporate effects of winds and extremely high temperatures heatwaves on feeding and mortality the model considered the effects of wind on feed consumption and therefore on growth by incorporating non feeding days when wind velocity exceeded predefined thresholds this was done to simulate restricted farm accessibility or adverse weather conditions that hinder feeding operations e g high waves moreover extreme events such as storms and heatwaves were included as additional causes of mortality the rationale was that storms can damage the cages and cause equipment failure thus leading to escapee events while prolonged high temperatures are tied to disease outbursts both of which are incorporated as mortality losses in aquaculture terms specifically changes in the number of fish during the simulations were calculated as d n d t μ μ t μ s n with n being the number of fish μ a background mortality rate μ t and μ s mortality rates related to storms and heatwaves respectively both μ t and μ s were set to zero during the production cycle except for the days extreme events occurred at specified wind and temperature thresholds stavrakidis zachou et al 2021 quantitative information on mortality losses from storms and heatwaves is currently not available on the spatial scale required by the software and the perception of the relevance of these risks may be highly subjective therefore we leave information on all mortality values including μ t and μ s as user input in climegreaq to allow further experimentation according to the users perception 2 4 farm economic model the farm economic model has been implemented as an add on to the biological model and its core function is to estimate relevant business parameters of a single model farm to do so it uses the outputs of the biological model and user defined economic input variables to derive the main costs and the profit for the farm under various climate and management scenarios table 1 contains the input variables needed for the operation of the model along with typical values for the various prices and costs these values have been compiled in collaboration with the federation of greek maricultures fgm it should be noted however that these values do not represent official statistics for the industry and serve solely for dss user orientation the values may vary considerably depending on farm characteristics and location the farm economic model has been developed by syntesa syntesa 2020 for simplicity it is assumed that all prices provided in table 1 remain unchanged during the production period based on the user input for these variables the total costs per production cycle for feed juveniles labor depreciation and other costs are then calculated according to equations 1 5 table 2 the rationale for selecting these variables for the farm economic calculations is that they follow the general cost structure for aquaculture feed and feeding represent the most important operational costs for the industry baki and yücel 2017 and are followed by costs related to wages and the number of hired personnel while maintenance costs and the initial expenses for obtaining stock juveniles or equipment also comprise a significant portion of the budget koçak and tathdil 2004 for climegreaq all these variables are user defined and therefore allow great flexibility for testing alternative economic scenarios the inclusion of other costs further contributes to that by allowing the inclusion of costs like maintenance repairs fuel consumption and others that may have not been accounted for in aquaculture the production cycle is relatively long compared to other forms of farming and it exceeds 1 5 years for most mediterranean species moreover farmers often resort to taking loans to support the initial installation of specialized farming infrastructures as well as for maintaining them consequently debt is an important factor for the industry since costs tend to accumulate during the production cycle until revenue is generated by selling the fish after the harvest engle 2010 for this reason an accumulated debt has been incorporated into the economic model equation 6 using equations 1 5 which is then used for the calculation of the bank interest as price interest rate x accumulated debt it is assumed that all costs during production are financed by a credit which holds for most small and medium sized companies therefore the accumulated debt for a given production period equals the sum of the current production costs the debt of the previous period and the bank interest of that debt however the bank interest can be set to zero by the climegreaq user finally based on equations 1 6 the total costs and the generated income can be calculated which allow the derivation of the total profit for the farm for the selected scenario equations 7 9 2 5 optimization a numerical optimization combining results of the biological model with resulting economic predictions and user market goals enables users to compute optimal seeding schemes the numerical optimization calculates for a given climate scenario farm setting mortalities and production goals all combinations of possible seeding schemes the optimization calculates the total amount of fish to seed based on the targeted production the requested market size and the mortality function the different possible seeding schemes are calculated by distributing the total amount of seeded fish to the three possible seeding months permuting the distribution and changing the number of seeded fish per seeding month in steps relevant for fish farming i e 50 000 individuals while keeping the total number per seeding scheme constant for example for a total amount of 900 000 seeded fish needed the different seeding schemes would be all combinations of distributing the total amount of seeded fish in steps of 50 000 individuals to the three seeding months comparing total feed and time to market size for all these options the optimization minimizes the sum of these two parameters the resulting optimal seeding scheme provides for the given parameters the minimum combination of total feed and total time to market size 3 results 3 1 stakeholder involvement and its impact stakeholder involvement proved constructive not only for the initial development of climegreaq but also for its refinement and validation throughout the project s timeframe this was enabled by the multiple loop approach which entailed developing climegreaq and its underlying model in several iterations fig 1 after each loop the dss including the underlying model were presented to the stakeholders at a dedicated stakeholder meeting and their feedback was taken into account for its further development effort was made not only to include representatives from industry administration and academia but also to ensure a high overlap of participants between the meetings in order to have fruitful discussions and to receive consistent input during the project phases sturm et al 2018 first outlines of climegreaq and the underlying model concepts were presented to the stakeholders along with a clear description of their capabilities and limitations at a kick off stakeholder workshop only six months after the beginning of the project the specific challenges for aquaculture under climate change were discussed as well as the features of the dss to be developed once the first round of biological simulations and the first version climegreaq were developed a first stakeholder workshop took place a year after the kick off meeting there the preliminary version of the tool and the underlying models were presented along with a clear description of their capabilities and limitations during that meeting stakeholders provided valuable feedback which related to the content and output of models and the dss as well as the appearance of the dss specifically key parameters were reconsidered and discarded or added accordingly the stakeholder feedback and model validation crystallized the necessity to include the effects of additional climate drivers other than temperature in the biological model eventually resulting in the incorporation of extreme events in the second loop simulations moreover changes in visualization were discussed the most notable being the suggestion to include a comparison window to allow simultaneous comparison of multiple scenarios the second stakeholder workshop took place a year later once the agreed changes were incorporated into the software and the final biological simulations were completed the updated tool was presented along with its new features such as the comparison window and a preliminary optimization function and the stakeholders were given the chance to test it themselves in designated computers this generated further feedback comments and validation of the main outputs the feedback mainly focused on appearance issues such as the form and position of graphs and axes or suggestions regarding the info boxes and the user manual these comments were implemented in the refinement of the software during the subsequent months the final version of climegreaq as well as other decision support systems developed in climefish were presented to stakeholders and academia at the final workshop of the climefish project 3 2 user interface the first window that users see when starting climegreaq is the main user interface it allows interaction with the various components of the dss and is the gateway through which secondary windows and supporting information can be accessed fig 5 to investigate the different environmental management and economic scenarios the users must first select the climate scenario rcp4 5 or rcp8 5 the species e seabass or meagre the timeframe short mid long the location inshore or offshore and the region r1 r9 of their choice from the respective drop down menu for the selection of the region a map is provided which contains the positions of the model farms next mortalities are assigned and seeding values number of individuals are given for the available seeding periods following this the system retrieves the selected biological predictions from the database the interface then enables the user to select different market sizes and insert values for the economic variables this allows the calculation of the costs and profits of each market size in relation to the selected farm setting the various outputs including the total biomass the time to market size total feed consumption costs and profits are computed and provided numerically but can also be visualized in graphs the graphs can be exported as images for later use and comparisons the main menu also offers four additional options seen on the top which redirect the user to secondary windows the first three options open new interactive windows while the last one termed background opens a popup window with additional background information for the parameters used in the calculations and the constituent models as an additional option by selecting the compare rcp inshore offshore window the user can illustrate the modeled farm production results for all rcp inshore offshore combinations this enables the user to compare the influence of the climate scenario and the farm setting while the other production parameters remain the same finally the optimizing seeding window enables the user to calculate the best seeding scenario for a chosen market size and production goal under different climate scenarios fig 6 for user orientation info boxes with supporting information such as descriptions of the input and output variables and their units are incorporated into the software these boxes appear once the user hovers above a selected variable and provide guidance on filling in the respective input values 3 3 application examples in order to allow comparisons between many scenarios we have considered multiple dimensions for the biological forecasting incorporating two climate scenarios nine regions inshore and offshore locations three seeding months and two fish species a comprehensive analysis of the effects of the simulated climate drivers temperature and wind on indicators such as the time required to reach common market sizes and the total biomass produced across these scenarios has been presented elsewhere stavrakidis zachou et al 2021 in this section we use specific examples to highlight the main capabilities of the software and its potential applications and also summarize results from the aforementioned study where appropriate in order to provide context the environmental profile of a simulation in terms of temperature and wind determines the growth performance for the fish consequently parameters that affect the environmental profile such as the location of a farm the climate scenario the time period of the projection and the region are expected to have effects on growth from these effects future shifts in variables such as time to market size and biomass production are among the most important for decision making since they provide information that may point to potential mitigation and adaptation measures as shown in fig 7 climegreaq can provide such critical information in the example and for the region and climate scenario considered there appears to be a positive shift in growth as we move forwards in time with fish growing faster and reaching typical market sizes faster in the long term compared to now as a response to higher future temperatures in fact the trend for time to market size to decrease in the future is consistent across all scenarios table 3 specifically table 3 shows the relative change in the time to market size 800 g in the future compared to the present f u t u r e p r e s e n t p r e s e n t it is evident that fish will grow faster in the future since the relative change is negative across all cases moreover meagre will benefit more compared to e seabass as depicted by the higher absolute values while the trend will be more pronounced under the rcp8 5 compared to rcp4 5 in addition for both species fish growth will be higher in the inshore farms compared to their offshore counterparts while differences will also be exhibited at different seeding months within each climate scenario finally as reflected by the variability in the mean values considerable differences will also appear between regions in fact it has been shown that even within the same climate scenario and seeding month the time to market size may differ substantially among regions with fish in the southern thus warmer regions reaching the same size up to three months faster than in northern ones stavrakidis zachou et al 2021 in addition to evaluating shifts in individual growth the effects of the considered climate drivers at the population level can also be analyzed due to the frequency and intensity of extreme events being different across the environmental scenarios differences in the mortality levels and therefore in the total biomass can be derived in turn losses in biomass inevitably translate to losses in profit which can be estimated and visualized in climegreaq an example of this can be found in fig 8 where the biomass production and profit of two farms that differ in their environmental profiles are compared for the selected comparison the two regions differ latitudinally with r1 being a northern and r9 a southern warmer region as mentioned in the previous paragraph southern regions typically exhibit higher individual growth as a direct positive effect of increased temperatures on fish metabolism however this gain is not depicted at the population level since the total biomass production is lower in r9 compared to r1 this is due to the higher frequency of heatwaves in the south which cause substantial mortalities as a result the profitability of these farms is similarly affected with the profits in r9 being lower than r1 and even negative for the march seeding furthermore similar differences in biomass and profit could also be assessed within the same region for inshore and offshore locations via the secondary windows of the software not shown since the environmental conditions between inshore and offshore locations differ not only in terms of the overall temperature profile but also regarding the frequency of extreme events this provides a range of possible outcomes within a region which may provide useful information for evaluating the option of farm translocation as a potential adaptation measure indeed with respect to inshore and offshore locations it has been shown that the frequency of heatwaves will be higher for the former compared to their offshore counterparts but the opposite trend will hold for storms across all regions stavrakidis zachou et al 2021 moreover heatwave frequency will progressively increase as we project forwards in the future while the frequency of storm events will not differ substantially compared to present levels as a result offshore farms will generally be less afflicted by extreme events in the future and will register fewer biomass and profit losses up to 20 depending on region and climate scenario compared to inshore farms thus pointing to potential benefits for expanding farming offshore as a potential climate adaptation measure however such an assessment should be interpreted with caution since it is sensitive to the severity one assigns to extreme events while it makes no assumptions for technological advancements in the sector which may mitigate the adverse effects of extreme weather events in the future in fact the severity of extreme events and particularly heatwaves is among the most defining parameters for farm profitability as demonstrated by the relevant sensitivity analysis fig 9 in this analysis the default climegreaq values for the various input variables were used to calculate the profit for a farm averaged over all regions and climate scenarios next the relative changes in profit were calculated comparatively to that value for a 10 change in all input variables individually the analysis showed that heatwave mortality had the highest impact on profitability followed by the sales price interest and seeding size feeding and mortality natural or due to storms also had a substantial influence on profit while it was less affected by the various costs such as those of labor and maintenance precisely due to the critical role of perceived extreme event severity for profitability extreme event mortality has been left as an input parameter in the dss allowing users to further investigate climate change impacts on a scenario basis for instance a scenario based approach to analyze the severity of extreme events across the dimensions considered here regions climate scenarios stocking months inshore offshore locations has been presented in stavrakidis zachou et al 2021 in that study it was shown that scenarios of high and moderate severity for extreme events may lead to profit losses as high as 80 in the future rendering farming a financially unviable activity for many regions moreover even for scenarios of mild severity profit losses could be substantial by 2050 in the order of 20 40 compared to present values therefore although such an assessment may be prone to subjectivity it may be still useful for detecting severe climate threats in the present the dss achieves this by allowing investigation of extreme event scenarios according to the user s perception thus increasing the overall flexibility of the tool finally an important factor for aquaculture is the seasonality of growth which is determined by the seasonal changes in temperature and the species specific thermal preferences specifically throughout the year environmental conditions fluctuate in a way that creates species specific optimal time windows for growth followed by periods when growth declines or completely ceases consequently considering these optimal growth periods is crucial when deciding the seeding strategy of a farm since this strategy determines the time required for fish to reach specific sizes in fact as shown in table 3 specific seeding months may be preferable for growth depending on the choice of species and climate scenario arguably the choice of the harvest size has large economic implications in terms of both operational costs and sales prices therefore the optimization of seeding is crucial in order to achieve specific production goals for selected market sizes under different climate scenarios climegreaq provides a tool to investigate this via the optimization window and we show an example of suggested seeding for three market sizes under the same environmental scenario fig 10 the effect of the market size is considerable since it progresses from a balanced suggestion among the three seeding months for smaller sized e seabass to a sole preference for a specific seeding month for larger sizes in particular while september seems to be the optimal seeding month for 400 g march and june tend to be preferable for bigger sizes however this effect pertains to the region time period and climate scenario investigated and therefore may differ considerably under different conditions 4 discussion collaboration between scientists and stakeholders is crucial for the sustainable management of marine resources and the development of decision support österblom et al 2020 in that regard climegreaq has been developed in collaboration with its intended users aquaculture stakeholders this process has not only ensured that crucial elements relevant for the users have been incorporated but also that the tool is user friendly while this is important for all types of decision support systems it is particularly important for aquaculture because the complex interactions of the natural environment with the biology of the farmed fish as well as the rearing practices pose challenges in identifying key parameters for decision making in fact such relevant parameters are often missing in many dss mathisen et al 2016 unlike simpler systems decision making in aquaculture must integrate biological economic and environmental elements while at the same time accounting for farming practices and management drivers cobo et al 2019 in this study effort was made to incorporate several of these factors including parameters that are linked to the environmental conditions during rearing such as the seeding month the location inshore of offshore and the region as well as population parameters seeding size and mortality and farm economics while the inclusion of such parameters was not exhaustive the co creation approach ensured the incorporation of key parameters that are able to capture some of the complexities required for decision making in aquaculture moreover in line with stakeholder recommendations an approach not based on explicit modeling was adopted to include additional climate drivers extreme events other than temperature this contributed to increasing the versatility of the software and allows a more comprehensive evaluation of climate change effects finally another advantage of the presented dss is that its biological predictions are based on rigorous modeling that has been validated against production data stavrakidis zachou et al 2019 2021 being explicit about the capabilities as well as limitations of a dss is fundamental to its correct use erroneous usage or misplaced expectations are counter productive and may lead to loss of trust or reduced acceptance of such tools brauner et al 2019 therefore it is important to acknowledge that any prediction of the future will carry inherent uncertainties for climegreaq as indicated by the validation results the uncertainty of the biological predictions is small and within the range reported for farmed finfish lupatsch et al 2003 navarro martín et al 2009 however climegreaq faces the uncertainty typically encountered in climate modeling due to the selection of the global climate model the ipcc scenario and the downscaling method kay et al 2008 for example rcp4 5 was considered the most likely climate scenario when the development of climegreaq started yet according to recent reports we are now heading closer to rcp8 5 teske 2019 therefore the selection of the climate scenario alone is a major source of uncertainty that influences the predictions of the dss similarly predicting trends in economic variables remains highly speculative and thus the economic data input provided by the user adds to the overall uncertainty however these sources of uncertainty do not impede the functionality of the tool since its purpose is to provide a range of possible future outcomes and not to predict the future in fact comparing alternative future states and interpreting trends which the dss can facilitate while understanding the limitations of predictions is fundamental for developing evidence based yet flexible climate adaptation strategies in that regard it is also important that the dss is presented and used as an aid to decision making that does not nor should replace human decisions sturm et al 2018 throughout the project and during the stakeholder meetings care was taken to provide clarity about the limitations of the tool and ensure its appropriate application with respect to the limitations environmental drivers associated with climate change such as acidification salinity habs and changes in water circulation patterns were not considered for the biological simulations while extreme weather events were included but their underlying mechanisms not explicitly modeled therefore climegreaq is not a suitable tool for studying the effects of these drivers directly nor the interactions between them however users could potentially explore their effects on farm economics indirectly by incorporating them as changes in mortality or associated costs moreover the spatial analysis of climegreaq is limited by the resolution of the available climate models consequently while it is appropriate for detecting large scale trends its application to fine spatial scales may be compromised another limitation is that the tool relies on precomputed biological simulations although significant effort was made to cover a large number of scenarios these simulations are finite and thus set a limit to the range of scenarios that can be investigated finally the dss has been developed as an aid for making strategic decisions but not as an operational tool to be used for the day to day operations of a farm while the software contains elements that could be used for this purpose it has not been validated and calibrated to accommodate such needs and this is communicated in the disclaimers found in the dss an example of this is the daily feeding operations of a farm although climegreaq simulates the feed consumption for the fish population it should not be used as a reliable tool for calculating the daily feeding scheme for a farm since important variables relating to feeding such as the feed composition or the meal distribution over the day have not been explicitly modeled in such cases dedicated tools should be used instead cobo et al 2019 on the other hand climegreaq considers climatic effects at a wide spatiotemporal scale while also accounting for husbandry and economic indicators and thus it may be used to investigate alternative what if scenarios for the future and support strategic decisions related to climate change adaptation as explained above climegreaq can capture changes in biological performance at the individual and population levels suggest optimal seeding schemes and translate biological input into changes in profitability under different climate scenarios and time horizons furthermore based on the user s perception of how relevant farm economic parameters may develop in the future under the various ipcc scenarios a whole new range of scenarios can be tested and visualized by adjusting the corresponding farm economic variables this information can then be used by aquaculture stakeholders to serve their specific decision making needs for a producer this type of information could contribute to decisions that make better use of the projected environmental changes in order to grow fish faster and at a lower cost these decisions may relate to the seeding scheme timing and size the selection of favorable sites for expansion or translocation of the farming activity offshore and the choice of target species and profitable market sizes on the other hand the administrative authorities could use the dss as a tool to investigate shifts in production capacity at a regional scale in order to designate new zones of organized development of aquaculture z o d a in a way that promotes the sustainable expansion of fish farming in greece under climate change finally the supporting information on the related risks and potential adaptation measures could further contribute to shifts in farming practices or the development of national climate adaptation strategies for aquaculture although climegreaq has been delivered in its final form future needs may necessitate changes in order for the tool to remain relevant in the long term lines of future research could incorporate the effects of additional climate drivers such as acidification habs and oxygen limitations other updates could entail new biological simulations based on updated climate models both in terms of reliability and spatiotemporal resolution furthermore as already mentioned climegreaq in its present form relies on precomputed simulations and although this does not limit its functionality a modified version could potentially include the model itself thus allowing the simulation of additional scenarios moreover the tool could be updated to include additional aquaculture species and new regions if relevant data becomes available finally from an economic perspective climegreaq could provide a basis for a tool to assess how climate change and appropriate adaptation strategies might impact the gross value added of greek aquaculture as a whole 5 conclusion in conclusion the software based dss presented here aims to support decision making in greek aquaculture under climate change by simulating and visualizing climate impacts on biological and farm economic indicators based on a bio economic approach and developed in collaboration with stakeholders it incorporates key variables that are able to capture some of the complexities of the industry which renders it suitable for supporting strategic decisions in aquaculture to our knowledge this is the first case of an interactive tool developed for marine aquaculture that specifically tackles climate change challenges thus it has the capacity to contribute greatly to the adaptation of marine aquaculture to climate change and thus the sustainable growth of the sector in the future software and data availability the dss was developed in the context of the eu project climefish https climefish eu regarding its technical implementation it is available for microsoft windows open source software was used for the various components while the programming language was c regarding the local database where all information is stored including the biological pre computed simulations and supporting farm economic data and parameters it uses a free version of the mysql community server release 8 0 2 which was deemed sufficient to support the dss functions an executable of the software can be freely accessed via the climefish community at zenodo https zenodo org record 3627546 xonxuxjs82w or in the climefish toolbox http 136 144 228 39 8080 climefish along with supporting information such as instructions and a user manual to operate the dss prior installation of the mysql https zenodo org record 3627369 xonxahjs82w is required which can also be performed with open source software xampp 2020 funding this work was supported by the european union horizon 2020 project climefish 677039 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
25800,climate change poses increasing challenges to aquaculture resulting in the need to develop appropriate tools to assess these challenges and support decision making we present climegreaq a software based decision support system dss co created with stakeholders to support the adaptation of greek aquaculture to climate change the dss is based on an integrated modeling approach which links a biological and an economic model in order to simulate the effects of climate drivers on greek aquaculture in a spatially heterogeneous manner the tool may be used by stakeholders including farmers producer organizations regional administrations and national authorities to support decision making on questions ranging from selecting appropriate farming locations to designating zones for aquaculture activities to developing national climate adaptation plans along with a description of the dss design process its structure and the constituent models key results are presented relating to stakeholder involvement the user interface and several application examples keywords climate change adaptation aquaculture decision support system stakeholder co creation bio economic model 1 introduction food production systems are increasingly under pressure at a global scale from threats stemming from climate change marine aquaculture in particular faces special challenges due to the nature of the activity which allows little control over environmental conditions at the rearing sites this may relate to threats regarding the biology of the farmed species such as reduced growth and survivability but it can also include financial implications for individual farms like increases in the various costs which in turn lead to lower profitability in fact it has been postulated that climate change may have profound implications for aquaculture production the livelihoods of its associated communities and consequently for national economies brander et al 2018 rosa et al 2012 a case in point is greece one of the main producers of european seabass dicentrarchus labrax and gilthead sea bream sparus aurata in europe representing over 60 of the total european production feap 2017 these species are predominantly farmed in marine cages which therefore renders marine aquaculture the focus of this article moreover aquaculture products rank amongst the most important agricultural exports for greece and thus make a significant contribution to the national economy fgm 2019 it is therefore crucially important that potential threats as well as opportunities arising from climate change are assessed and adaptation actions are taken where needed however assessing the effects of climate change on aquaculture production is rarely self intuitive for decision makers this is due to the multitude of environmental drivers associated with climate change temperature acidification extreme events shifts in ocean circulation and harmful algal blooms habs among others their complex interactions with the production systems as well as among them and the knowledge gaps regarding the biological responses of farmed fish to these drivers dabbadie et al 2018 wells et al 2020 as a result developing strategies to adapt to climate change remains cumbersome for decision makers one option to support and facilitate decision making in this context is the development of appropriate tools that can aid decision making these tools which are referred to as decision support systems dss must be able to provide supporting information to decision makers so that management and policy makers can take strategic decisions to promote sustainability of the industry in the coming decades in addition these tools must achieve a balance between the information they contain and user friendliness to make them easily accessible to decision makers wenkel et al 2013 in this paper we present such a dss climegreaq developed to support decision making for greek marine finfish aquaculture under climate change in general dss are information systems designed to facilitate decision making in relation to complex problems their main functionality lies in allowing users to test specific management objectives by comparing alternative states of their system recent achievements in computer science have spurred the development of novel interactive software based systems capalbo et al 2017 holzworth et al 2015 with some of them focusing on impacts of environmental changes on food production cobo et al 2019 hermawan and syafrani 2015 sturm et al 2018 wätzold et al 2016 with respect to the specific challenge of climate change several dss have also been developed ranging from risk assessments using scenario based approaches han et al 2017 lieske 2015 schweizer 2019 to more sophisticated interactive tools that tackle issues related to the management of water and energy resources land use and biodiversity kašpar et al 2018 kazak 2018 pierleoni et al 2014 ziaja 2019 in addition long term environmental impacts have been simulated for pond aquaculture with the objective of establishing a comprehensive background for the subsequent development of a dss varga et al 2020 however the connection between climate change and aquaculture in a dss form remains elusive overall decision support systems in aquaculture are scarce despite the substantial number of such systems produced in other domains nevertheless a few dss exist in aquaculture which are increasingly adopting software based approaches in an effort to tackle the highly complex and multifactorial nature of farming and its interactions with the natural environment casini et al 2015 for instance the inclusion of geographical information systems in tools that support decisions in fish farming has been suggested falconer et al 2018 while other technologies such as particle swarm optimization techniques have already been developed for other applications cobo et al 2019 other approaches include multi criteria decision making methodologies as in the case of a gilthead seabream dss for feeding strategies luna et al 2019 and the development of dss for optimizing site selection according to the prevailing environmental conditions halide et al 2009 nobre et al 2009 stelzenmüller et al 2017 yet as has been highlighted by mathisen et al 2016 most of these efforts fail to capture the complexities required for decision making in aquaculture since they are generally focused on a small number of drivers and species moreover there are significant gaps related to decision support in a climate change context as none of the existing dss for aquaculture deals specifically with future projections of climate drivers responding to the need to develop tools for informed management in aquaculture under a changing climate this article describes climegreaq a software based dss for greek aquaculture the aim of climegreaq is to simulate and visualize biological effects of climate change on typical farmed fish species and their repercussions on farm economic indicators for greek aquaculture under different climate scenarios and over distinct future periods extending up to the year 2050 this includes effects of climate drivers such as temperature and wind velocity in several areas throughout greece which allows the consideration of spatial heterogeneities across the country caused by differences in the projected climate conditions moreover in addition to simulating and visualizing climate change impacts the dss includes an optimization module for some farming parameters by doing so it allows its users to investigate alternative what if scenarios in a changing climate and support strategic decisions based on the relative differences between the possible outcomes in order to consider links between biological and economic impacts a bio economic modeling procedure drechsler 2020 was adopted for its development following established practices for investigating the effects of changing environmental conditions in aquaculture systems besson et al 2016 cobo et al 2019 the dss was developed in collaboration with stakeholders in the context of the eu project horizon 2020 climefish https climefish eu following the co creation suggestions of the european commission european commission 2014 the co creation approach aims at increasing the relevance of the generated products for their users in this case greek aquaculture stakeholders such as farmers producer organizations as well as regional and national authorities in that way the dss may be useful for supporting decisions at small scales such as the management of farms in terms of selecting appropriate seeding schemes and farming locations but also at medium and larger scales by aiding policy makers in designating or modifying aquaculture activity zones or in developing climate adaptation plans at a national level for this reason the implementation of climegreaq occurred in stages between which stakeholder feedback was gathered and taken into consideration for its further development a prototype version of the dss produced in the early stages of the project has already been presented in stavrakidis zachou et al 2018 since then substantial changes additions and refinements have been implemented the software based dss presented in this article is the final version of the climefish dss for aquaculture stakeholders in greece it contains all the updates and new functions that have been implemented into the software and particularly the stakeholder suggestions that emerged during the co creation process specifically compared to the earliest version presented in stavrakidis zachou et al 2018 the tool contains improved biological forecasting in terms of key biological parameters such as fish growth and feed consumption for the 2020 2050 period the forecasting has been obtained using downscaled climate projections at a higher spatial resolution than before moreover the spatial extent of the analysis is enlarged from pilot regions to the entire country while effects of extreme weather events such as heatwaves and storms on fish growth and biomass production are also incorporated additionally to those of temperature in terms of further methodological advancement an optimization module has been implemented moreover the tool includes an additional species a risk assessment updated maps and other visualizations and finally secondary windows and info boxes for user orientation the risk assessment is ignored in the following as it is based on a different methodology and was included in the software to provide stakeholders with one single platform where they could access all climefish tools further information about the risk assessment can be found in the manual and in the case study description of the climefish toolbox http 136 144 228 39 8080 climefish 2 methods 2 1 process of software design and experimental testing climegreaq was developed applying a co creation approach which implies close interactions between scientists and stakeholders throughout the different stages of dss development as highlighted by mcintosh et al 2011 engaging stakeholders as early as possible in a co creation process is crucial for ensuring the relevance of the generated tools for the users as well as their longevity beyond a project s lifetime regular meetings with stakeholders are necessary to present the dss idea as well as preliminary and final results the purpose of such meetings is to gather feedback for the improvement of the dss in terms of relevance of proposed parameters adequacy for addressing the problem of climate change impacts on greek aquaculture user friendliness and model validation this feedback shall then be taken into account in the further development of the dss and the underlying model fig 1 illustrates this process 2 2 overview of the structure climegreaq utilizes biological and economic information to simulate and visualize the effects of selected climate drivers on greek aquaculture production climegreaq differentiates between nine greek regions and considers for each region inshore and offshore production resulting in eighteen representative farms its core structure is a coupled biological and farm economic model the biological model is integrated in the dss through a local mysql database while the farm economic model is implemented into the software in addition the interactions of these components with the user occur via a user interface fig 2 the decision support capacity of the software lies in allowing users to create and compare a wide range of alternative future climate change and management scenarios to accomplish that a model farm approach was adopted which targets representative farms throughout the greek territory as the basis of the analysis such an approach appears to have increasing relevance for aquaculture as indicated by current research besson et al 2016 cobo et al 2019 piedecausa et al 2010 for the various climate scenarios the biological model for the model farm simulates a production cycle for a group of fish and reports several parameters of interest such as time to market size feed consumption and biomass at a harvest size specified by the user subsequently the farm economic model uses the output of the biological component as well as other economic data input to estimate relevant farm economic parameters due to considerable computational time the biological simulations are not done by the software but comprise a selection of precomputed scenarios which are stored in the local database all other computations happen in real time 2 3 biological model and simulations this section provides an overview of the biological model including the overall framework it is based on and the main linkages among its components as well as a description of the data and scenarios used for the simulations for a detailed description of the biological model and the development process the parameters and the formulae used in the simulations we refer to stavrakidis zachou et al 2021 and the respective supplemental electronic material 2 3 1 the deb model the biological model is based on dynamic energy budget deb theory via the deb framework the bioenergetics of an individual fish can be described as a function of temperature and food availability by following certain rules for the uptake of energy and its utilization by the organism kooijman 2010 according to this framework the weight of an individual comprises of structure reserve and in the case of adults also of reproductive biomass the various metabolic processes are fueled by mobilized reserve which is formed during the process of assimilation during feeding part of the food consumed by the organism is assimilated into reserve while the rest is lost through defecation at any given time a fraction of the mobilized reserve κ is used for growth and the rest 1 κ for maturation or reproduction purposes specifically growth is incorporated as increase in the structural biomass structure of the organism after maintenance costs have been paid on the other hand maturation represents investments in development with life stage transitions occurring at specific maturation thresholds and in the case of reproducing adults the production of gonads after subtraction of the respective maintenance costs all these processes are governed by temperature with the temperature effect on the various physiological rates being quantified via the arrhenius relationship in the deb context aguera et al 2015 kooijman 2010 stavrakidis zachou et al 2019 in this framework changes in measurable quantities such as weight and feed consumption for a single fish can be predicted as a function of temperature and food availability which can be provided as inputs moreover this process can be repeated for many individuals thus extrapolating the output to the population level an overview of the biological model scheme and the general method including the inputs and outputs of the model is provided in fig 3 deb models were developed for two species the e seabass dicentrarchus labrax and the meagre argyrosomus regius and were validated against production data from farms the parametrization of the models was done according to the procedure described in marques et al 2019 using information from published literature as well as experimental work conducted at the hellenic center for marine research hcmr for model validation eight datasets growth measured as the evolution of weight over time and feed consumption from greek farms at various locations were used after simulating the temperature and feeding conditions at those locations the model predictions were compared with the farm data a close overlap of model predictions with farm observations indicated that growth was captured accurately by the model while there was a slight tendency towards underestimating feed consumption specifically in all cases the weight and feed consumption values predicted by the model did not deviate more than 20 from the observed data coefficient of variation 0 2 further details on the parameterization and validation of the two models can be found in previous publications stavrakidis zachou et al 2019 2021 2 3 2 simulations simulations were performed for nine greek regions and for three time periods denoting short mid and long term effects 2015 25 2025 35 and 2045 55 under the ipcc intergovernmental panel on climate change climate scenarios rcp4 5 and rcp8 5 for these scenarios the projections of temperature and wind velocity were forced on a group of fish to simulate a three year production cycle at farm level the environmental variables comprised of downscaled 10 10 km projections of the global climate model ichec ec earth via the coupled polcom ersem ecosystem model proudman oceanographic laboratory coastal ocean modeling system and the plymouth marine laboratory european regional seas ecosystem model in addition for each region two farms were considered one inshore and one offshore this was done to assess effects on exposed locations since offshore aquaculture has been recognized to have great potential for the future of mediterranean finfish aquaculture porporato et al 2019 furthermore adapted seeding planning was incorporated into the simulations via the inclusion of three seeding months march june september predictions of growth in terms of the time needed to reach a specified market size the number of fish the total biomass the cumulative feed consumption and the feed conversion ratio fcr were then computed for the different climate and management scenarios the latter referring to the various production options such as site selection and seeding time and size moreover a preliminary assessment was done to determine the sensitivity of simulation outputs such as growth to climate model uncertainties specifically bootstrap samples of temperature and wind velocity time series were generated within each time period as described in stavrakidis zachou et al 2021 and were used to run simulations for an individual fish overall climate uncertainty produced little variability in all considered climate scenarios as indicated by the narrow width of the grey shaded area coefficient of variation 0 05 for this simulation fig 4 our model focuses on temperature as the main climate driver modeling other drivers explicitly would have been difficult due to a lack of supporting data on environmental projections inadequate spatial resolutions and significant knowledge gaps regarding the biological species specific effects of other drivers however in line with recommendations from stakeholders who emphasized the need to include additional drivers an indirect approach was followed to incorporate effects of winds and extremely high temperatures heatwaves on feeding and mortality the model considered the effects of wind on feed consumption and therefore on growth by incorporating non feeding days when wind velocity exceeded predefined thresholds this was done to simulate restricted farm accessibility or adverse weather conditions that hinder feeding operations e g high waves moreover extreme events such as storms and heatwaves were included as additional causes of mortality the rationale was that storms can damage the cages and cause equipment failure thus leading to escapee events while prolonged high temperatures are tied to disease outbursts both of which are incorporated as mortality losses in aquaculture terms specifically changes in the number of fish during the simulations were calculated as d n d t μ μ t μ s n with n being the number of fish μ a background mortality rate μ t and μ s mortality rates related to storms and heatwaves respectively both μ t and μ s were set to zero during the production cycle except for the days extreme events occurred at specified wind and temperature thresholds stavrakidis zachou et al 2021 quantitative information on mortality losses from storms and heatwaves is currently not available on the spatial scale required by the software and the perception of the relevance of these risks may be highly subjective therefore we leave information on all mortality values including μ t and μ s as user input in climegreaq to allow further experimentation according to the users perception 2 4 farm economic model the farm economic model has been implemented as an add on to the biological model and its core function is to estimate relevant business parameters of a single model farm to do so it uses the outputs of the biological model and user defined economic input variables to derive the main costs and the profit for the farm under various climate and management scenarios table 1 contains the input variables needed for the operation of the model along with typical values for the various prices and costs these values have been compiled in collaboration with the federation of greek maricultures fgm it should be noted however that these values do not represent official statistics for the industry and serve solely for dss user orientation the values may vary considerably depending on farm characteristics and location the farm economic model has been developed by syntesa syntesa 2020 for simplicity it is assumed that all prices provided in table 1 remain unchanged during the production period based on the user input for these variables the total costs per production cycle for feed juveniles labor depreciation and other costs are then calculated according to equations 1 5 table 2 the rationale for selecting these variables for the farm economic calculations is that they follow the general cost structure for aquaculture feed and feeding represent the most important operational costs for the industry baki and yücel 2017 and are followed by costs related to wages and the number of hired personnel while maintenance costs and the initial expenses for obtaining stock juveniles or equipment also comprise a significant portion of the budget koçak and tathdil 2004 for climegreaq all these variables are user defined and therefore allow great flexibility for testing alternative economic scenarios the inclusion of other costs further contributes to that by allowing the inclusion of costs like maintenance repairs fuel consumption and others that may have not been accounted for in aquaculture the production cycle is relatively long compared to other forms of farming and it exceeds 1 5 years for most mediterranean species moreover farmers often resort to taking loans to support the initial installation of specialized farming infrastructures as well as for maintaining them consequently debt is an important factor for the industry since costs tend to accumulate during the production cycle until revenue is generated by selling the fish after the harvest engle 2010 for this reason an accumulated debt has been incorporated into the economic model equation 6 using equations 1 5 which is then used for the calculation of the bank interest as price interest rate x accumulated debt it is assumed that all costs during production are financed by a credit which holds for most small and medium sized companies therefore the accumulated debt for a given production period equals the sum of the current production costs the debt of the previous period and the bank interest of that debt however the bank interest can be set to zero by the climegreaq user finally based on equations 1 6 the total costs and the generated income can be calculated which allow the derivation of the total profit for the farm for the selected scenario equations 7 9 2 5 optimization a numerical optimization combining results of the biological model with resulting economic predictions and user market goals enables users to compute optimal seeding schemes the numerical optimization calculates for a given climate scenario farm setting mortalities and production goals all combinations of possible seeding schemes the optimization calculates the total amount of fish to seed based on the targeted production the requested market size and the mortality function the different possible seeding schemes are calculated by distributing the total amount of seeded fish to the three possible seeding months permuting the distribution and changing the number of seeded fish per seeding month in steps relevant for fish farming i e 50 000 individuals while keeping the total number per seeding scheme constant for example for a total amount of 900 000 seeded fish needed the different seeding schemes would be all combinations of distributing the total amount of seeded fish in steps of 50 000 individuals to the three seeding months comparing total feed and time to market size for all these options the optimization minimizes the sum of these two parameters the resulting optimal seeding scheme provides for the given parameters the minimum combination of total feed and total time to market size 3 results 3 1 stakeholder involvement and its impact stakeholder involvement proved constructive not only for the initial development of climegreaq but also for its refinement and validation throughout the project s timeframe this was enabled by the multiple loop approach which entailed developing climegreaq and its underlying model in several iterations fig 1 after each loop the dss including the underlying model were presented to the stakeholders at a dedicated stakeholder meeting and their feedback was taken into account for its further development effort was made not only to include representatives from industry administration and academia but also to ensure a high overlap of participants between the meetings in order to have fruitful discussions and to receive consistent input during the project phases sturm et al 2018 first outlines of climegreaq and the underlying model concepts were presented to the stakeholders along with a clear description of their capabilities and limitations at a kick off stakeholder workshop only six months after the beginning of the project the specific challenges for aquaculture under climate change were discussed as well as the features of the dss to be developed once the first round of biological simulations and the first version climegreaq were developed a first stakeholder workshop took place a year after the kick off meeting there the preliminary version of the tool and the underlying models were presented along with a clear description of their capabilities and limitations during that meeting stakeholders provided valuable feedback which related to the content and output of models and the dss as well as the appearance of the dss specifically key parameters were reconsidered and discarded or added accordingly the stakeholder feedback and model validation crystallized the necessity to include the effects of additional climate drivers other than temperature in the biological model eventually resulting in the incorporation of extreme events in the second loop simulations moreover changes in visualization were discussed the most notable being the suggestion to include a comparison window to allow simultaneous comparison of multiple scenarios the second stakeholder workshop took place a year later once the agreed changes were incorporated into the software and the final biological simulations were completed the updated tool was presented along with its new features such as the comparison window and a preliminary optimization function and the stakeholders were given the chance to test it themselves in designated computers this generated further feedback comments and validation of the main outputs the feedback mainly focused on appearance issues such as the form and position of graphs and axes or suggestions regarding the info boxes and the user manual these comments were implemented in the refinement of the software during the subsequent months the final version of climegreaq as well as other decision support systems developed in climefish were presented to stakeholders and academia at the final workshop of the climefish project 3 2 user interface the first window that users see when starting climegreaq is the main user interface it allows interaction with the various components of the dss and is the gateway through which secondary windows and supporting information can be accessed fig 5 to investigate the different environmental management and economic scenarios the users must first select the climate scenario rcp4 5 or rcp8 5 the species e seabass or meagre the timeframe short mid long the location inshore or offshore and the region r1 r9 of their choice from the respective drop down menu for the selection of the region a map is provided which contains the positions of the model farms next mortalities are assigned and seeding values number of individuals are given for the available seeding periods following this the system retrieves the selected biological predictions from the database the interface then enables the user to select different market sizes and insert values for the economic variables this allows the calculation of the costs and profits of each market size in relation to the selected farm setting the various outputs including the total biomass the time to market size total feed consumption costs and profits are computed and provided numerically but can also be visualized in graphs the graphs can be exported as images for later use and comparisons the main menu also offers four additional options seen on the top which redirect the user to secondary windows the first three options open new interactive windows while the last one termed background opens a popup window with additional background information for the parameters used in the calculations and the constituent models as an additional option by selecting the compare rcp inshore offshore window the user can illustrate the modeled farm production results for all rcp inshore offshore combinations this enables the user to compare the influence of the climate scenario and the farm setting while the other production parameters remain the same finally the optimizing seeding window enables the user to calculate the best seeding scenario for a chosen market size and production goal under different climate scenarios fig 6 for user orientation info boxes with supporting information such as descriptions of the input and output variables and their units are incorporated into the software these boxes appear once the user hovers above a selected variable and provide guidance on filling in the respective input values 3 3 application examples in order to allow comparisons between many scenarios we have considered multiple dimensions for the biological forecasting incorporating two climate scenarios nine regions inshore and offshore locations three seeding months and two fish species a comprehensive analysis of the effects of the simulated climate drivers temperature and wind on indicators such as the time required to reach common market sizes and the total biomass produced across these scenarios has been presented elsewhere stavrakidis zachou et al 2021 in this section we use specific examples to highlight the main capabilities of the software and its potential applications and also summarize results from the aforementioned study where appropriate in order to provide context the environmental profile of a simulation in terms of temperature and wind determines the growth performance for the fish consequently parameters that affect the environmental profile such as the location of a farm the climate scenario the time period of the projection and the region are expected to have effects on growth from these effects future shifts in variables such as time to market size and biomass production are among the most important for decision making since they provide information that may point to potential mitigation and adaptation measures as shown in fig 7 climegreaq can provide such critical information in the example and for the region and climate scenario considered there appears to be a positive shift in growth as we move forwards in time with fish growing faster and reaching typical market sizes faster in the long term compared to now as a response to higher future temperatures in fact the trend for time to market size to decrease in the future is consistent across all scenarios table 3 specifically table 3 shows the relative change in the time to market size 800 g in the future compared to the present f u t u r e p r e s e n t p r e s e n t it is evident that fish will grow faster in the future since the relative change is negative across all cases moreover meagre will benefit more compared to e seabass as depicted by the higher absolute values while the trend will be more pronounced under the rcp8 5 compared to rcp4 5 in addition for both species fish growth will be higher in the inshore farms compared to their offshore counterparts while differences will also be exhibited at different seeding months within each climate scenario finally as reflected by the variability in the mean values considerable differences will also appear between regions in fact it has been shown that even within the same climate scenario and seeding month the time to market size may differ substantially among regions with fish in the southern thus warmer regions reaching the same size up to three months faster than in northern ones stavrakidis zachou et al 2021 in addition to evaluating shifts in individual growth the effects of the considered climate drivers at the population level can also be analyzed due to the frequency and intensity of extreme events being different across the environmental scenarios differences in the mortality levels and therefore in the total biomass can be derived in turn losses in biomass inevitably translate to losses in profit which can be estimated and visualized in climegreaq an example of this can be found in fig 8 where the biomass production and profit of two farms that differ in their environmental profiles are compared for the selected comparison the two regions differ latitudinally with r1 being a northern and r9 a southern warmer region as mentioned in the previous paragraph southern regions typically exhibit higher individual growth as a direct positive effect of increased temperatures on fish metabolism however this gain is not depicted at the population level since the total biomass production is lower in r9 compared to r1 this is due to the higher frequency of heatwaves in the south which cause substantial mortalities as a result the profitability of these farms is similarly affected with the profits in r9 being lower than r1 and even negative for the march seeding furthermore similar differences in biomass and profit could also be assessed within the same region for inshore and offshore locations via the secondary windows of the software not shown since the environmental conditions between inshore and offshore locations differ not only in terms of the overall temperature profile but also regarding the frequency of extreme events this provides a range of possible outcomes within a region which may provide useful information for evaluating the option of farm translocation as a potential adaptation measure indeed with respect to inshore and offshore locations it has been shown that the frequency of heatwaves will be higher for the former compared to their offshore counterparts but the opposite trend will hold for storms across all regions stavrakidis zachou et al 2021 moreover heatwave frequency will progressively increase as we project forwards in the future while the frequency of storm events will not differ substantially compared to present levels as a result offshore farms will generally be less afflicted by extreme events in the future and will register fewer biomass and profit losses up to 20 depending on region and climate scenario compared to inshore farms thus pointing to potential benefits for expanding farming offshore as a potential climate adaptation measure however such an assessment should be interpreted with caution since it is sensitive to the severity one assigns to extreme events while it makes no assumptions for technological advancements in the sector which may mitigate the adverse effects of extreme weather events in the future in fact the severity of extreme events and particularly heatwaves is among the most defining parameters for farm profitability as demonstrated by the relevant sensitivity analysis fig 9 in this analysis the default climegreaq values for the various input variables were used to calculate the profit for a farm averaged over all regions and climate scenarios next the relative changes in profit were calculated comparatively to that value for a 10 change in all input variables individually the analysis showed that heatwave mortality had the highest impact on profitability followed by the sales price interest and seeding size feeding and mortality natural or due to storms also had a substantial influence on profit while it was less affected by the various costs such as those of labor and maintenance precisely due to the critical role of perceived extreme event severity for profitability extreme event mortality has been left as an input parameter in the dss allowing users to further investigate climate change impacts on a scenario basis for instance a scenario based approach to analyze the severity of extreme events across the dimensions considered here regions climate scenarios stocking months inshore offshore locations has been presented in stavrakidis zachou et al 2021 in that study it was shown that scenarios of high and moderate severity for extreme events may lead to profit losses as high as 80 in the future rendering farming a financially unviable activity for many regions moreover even for scenarios of mild severity profit losses could be substantial by 2050 in the order of 20 40 compared to present values therefore although such an assessment may be prone to subjectivity it may be still useful for detecting severe climate threats in the present the dss achieves this by allowing investigation of extreme event scenarios according to the user s perception thus increasing the overall flexibility of the tool finally an important factor for aquaculture is the seasonality of growth which is determined by the seasonal changes in temperature and the species specific thermal preferences specifically throughout the year environmental conditions fluctuate in a way that creates species specific optimal time windows for growth followed by periods when growth declines or completely ceases consequently considering these optimal growth periods is crucial when deciding the seeding strategy of a farm since this strategy determines the time required for fish to reach specific sizes in fact as shown in table 3 specific seeding months may be preferable for growth depending on the choice of species and climate scenario arguably the choice of the harvest size has large economic implications in terms of both operational costs and sales prices therefore the optimization of seeding is crucial in order to achieve specific production goals for selected market sizes under different climate scenarios climegreaq provides a tool to investigate this via the optimization window and we show an example of suggested seeding for three market sizes under the same environmental scenario fig 10 the effect of the market size is considerable since it progresses from a balanced suggestion among the three seeding months for smaller sized e seabass to a sole preference for a specific seeding month for larger sizes in particular while september seems to be the optimal seeding month for 400 g march and june tend to be preferable for bigger sizes however this effect pertains to the region time period and climate scenario investigated and therefore may differ considerably under different conditions 4 discussion collaboration between scientists and stakeholders is crucial for the sustainable management of marine resources and the development of decision support österblom et al 2020 in that regard climegreaq has been developed in collaboration with its intended users aquaculture stakeholders this process has not only ensured that crucial elements relevant for the users have been incorporated but also that the tool is user friendly while this is important for all types of decision support systems it is particularly important for aquaculture because the complex interactions of the natural environment with the biology of the farmed fish as well as the rearing practices pose challenges in identifying key parameters for decision making in fact such relevant parameters are often missing in many dss mathisen et al 2016 unlike simpler systems decision making in aquaculture must integrate biological economic and environmental elements while at the same time accounting for farming practices and management drivers cobo et al 2019 in this study effort was made to incorporate several of these factors including parameters that are linked to the environmental conditions during rearing such as the seeding month the location inshore of offshore and the region as well as population parameters seeding size and mortality and farm economics while the inclusion of such parameters was not exhaustive the co creation approach ensured the incorporation of key parameters that are able to capture some of the complexities required for decision making in aquaculture moreover in line with stakeholder recommendations an approach not based on explicit modeling was adopted to include additional climate drivers extreme events other than temperature this contributed to increasing the versatility of the software and allows a more comprehensive evaluation of climate change effects finally another advantage of the presented dss is that its biological predictions are based on rigorous modeling that has been validated against production data stavrakidis zachou et al 2019 2021 being explicit about the capabilities as well as limitations of a dss is fundamental to its correct use erroneous usage or misplaced expectations are counter productive and may lead to loss of trust or reduced acceptance of such tools brauner et al 2019 therefore it is important to acknowledge that any prediction of the future will carry inherent uncertainties for climegreaq as indicated by the validation results the uncertainty of the biological predictions is small and within the range reported for farmed finfish lupatsch et al 2003 navarro martín et al 2009 however climegreaq faces the uncertainty typically encountered in climate modeling due to the selection of the global climate model the ipcc scenario and the downscaling method kay et al 2008 for example rcp4 5 was considered the most likely climate scenario when the development of climegreaq started yet according to recent reports we are now heading closer to rcp8 5 teske 2019 therefore the selection of the climate scenario alone is a major source of uncertainty that influences the predictions of the dss similarly predicting trends in economic variables remains highly speculative and thus the economic data input provided by the user adds to the overall uncertainty however these sources of uncertainty do not impede the functionality of the tool since its purpose is to provide a range of possible future outcomes and not to predict the future in fact comparing alternative future states and interpreting trends which the dss can facilitate while understanding the limitations of predictions is fundamental for developing evidence based yet flexible climate adaptation strategies in that regard it is also important that the dss is presented and used as an aid to decision making that does not nor should replace human decisions sturm et al 2018 throughout the project and during the stakeholder meetings care was taken to provide clarity about the limitations of the tool and ensure its appropriate application with respect to the limitations environmental drivers associated with climate change such as acidification salinity habs and changes in water circulation patterns were not considered for the biological simulations while extreme weather events were included but their underlying mechanisms not explicitly modeled therefore climegreaq is not a suitable tool for studying the effects of these drivers directly nor the interactions between them however users could potentially explore their effects on farm economics indirectly by incorporating them as changes in mortality or associated costs moreover the spatial analysis of climegreaq is limited by the resolution of the available climate models consequently while it is appropriate for detecting large scale trends its application to fine spatial scales may be compromised another limitation is that the tool relies on precomputed biological simulations although significant effort was made to cover a large number of scenarios these simulations are finite and thus set a limit to the range of scenarios that can be investigated finally the dss has been developed as an aid for making strategic decisions but not as an operational tool to be used for the day to day operations of a farm while the software contains elements that could be used for this purpose it has not been validated and calibrated to accommodate such needs and this is communicated in the disclaimers found in the dss an example of this is the daily feeding operations of a farm although climegreaq simulates the feed consumption for the fish population it should not be used as a reliable tool for calculating the daily feeding scheme for a farm since important variables relating to feeding such as the feed composition or the meal distribution over the day have not been explicitly modeled in such cases dedicated tools should be used instead cobo et al 2019 on the other hand climegreaq considers climatic effects at a wide spatiotemporal scale while also accounting for husbandry and economic indicators and thus it may be used to investigate alternative what if scenarios for the future and support strategic decisions related to climate change adaptation as explained above climegreaq can capture changes in biological performance at the individual and population levels suggest optimal seeding schemes and translate biological input into changes in profitability under different climate scenarios and time horizons furthermore based on the user s perception of how relevant farm economic parameters may develop in the future under the various ipcc scenarios a whole new range of scenarios can be tested and visualized by adjusting the corresponding farm economic variables this information can then be used by aquaculture stakeholders to serve their specific decision making needs for a producer this type of information could contribute to decisions that make better use of the projected environmental changes in order to grow fish faster and at a lower cost these decisions may relate to the seeding scheme timing and size the selection of favorable sites for expansion or translocation of the farming activity offshore and the choice of target species and profitable market sizes on the other hand the administrative authorities could use the dss as a tool to investigate shifts in production capacity at a regional scale in order to designate new zones of organized development of aquaculture z o d a in a way that promotes the sustainable expansion of fish farming in greece under climate change finally the supporting information on the related risks and potential adaptation measures could further contribute to shifts in farming practices or the development of national climate adaptation strategies for aquaculture although climegreaq has been delivered in its final form future needs may necessitate changes in order for the tool to remain relevant in the long term lines of future research could incorporate the effects of additional climate drivers such as acidification habs and oxygen limitations other updates could entail new biological simulations based on updated climate models both in terms of reliability and spatiotemporal resolution furthermore as already mentioned climegreaq in its present form relies on precomputed simulations and although this does not limit its functionality a modified version could potentially include the model itself thus allowing the simulation of additional scenarios moreover the tool could be updated to include additional aquaculture species and new regions if relevant data becomes available finally from an economic perspective climegreaq could provide a basis for a tool to assess how climate change and appropriate adaptation strategies might impact the gross value added of greek aquaculture as a whole 5 conclusion in conclusion the software based dss presented here aims to support decision making in greek aquaculture under climate change by simulating and visualizing climate impacts on biological and farm economic indicators based on a bio economic approach and developed in collaboration with stakeholders it incorporates key variables that are able to capture some of the complexities of the industry which renders it suitable for supporting strategic decisions in aquaculture to our knowledge this is the first case of an interactive tool developed for marine aquaculture that specifically tackles climate change challenges thus it has the capacity to contribute greatly to the adaptation of marine aquaculture to climate change and thus the sustainable growth of the sector in the future software and data availability the dss was developed in the context of the eu project climefish https climefish eu regarding its technical implementation it is available for microsoft windows open source software was used for the various components while the programming language was c regarding the local database where all information is stored including the biological pre computed simulations and supporting farm economic data and parameters it uses a free version of the mysql community server release 8 0 2 which was deemed sufficient to support the dss functions an executable of the software can be freely accessed via the climefish community at zenodo https zenodo org record 3627546 xonxuxjs82w or in the climefish toolbox http 136 144 228 39 8080 climefish along with supporting information such as instructions and a user manual to operate the dss prior installation of the mysql https zenodo org record 3627369 xonxahjs82w is required which can also be performed with open source software xampp 2020 funding this work was supported by the european union horizon 2020 project climefish 677039 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
25801,significant subsidence is susceptible to groundwater level variations in aquifer systems the relation between groundwater level change and global positioning system gps estimated subsidence is spatially variable time dependent spatial regression can be used for the estimation of groundwater level changes using gps based deformation data furthermore the model can be validated using observed hydraulic head data from available monitoring stations this study uses gps station data to estimate the monthly groundwater levels in the west central taiwan for the period 2016 17 time dependent spatial regression provides a more realistic estimation of groundwater level changes in response to highly heterogeneous aquifer properties than other methods the high correlation r 0 95 between observed and estimated groundwater levels shows that gps estimated deformations represent an alternative approach for estimating seasonal groundwater changes due to availability of spatially broad low cost gps data compared to the sparse availability groundwater monitoring stations the use of gps data represents a powerful solution for future monitoring of estimated seasonal groundwater level changes in areas where only few groundwater observations are available keywords groundwater gps based deformation time dependent spatial regression seasonal variation 1 introduction groundwater is a valuable resource representing approximately 99 of all accessible freshwater and is globally utilized mostly for agriculture industry and domestic usage alley et al 2002 worldwide many cities rely exclusively on groundwater for daily water usage boretti and rosa 2019 during periods of drought an increased utilization of groundwater is common particularly in localities that also previously utilized surface water effective and strategic groundwater management particularly during periods of drought requires real time knowledge of groundwater levels and storage changes evans et al 2020 effective models can provide the necessary information required to make informed decisions about groundwater resources and other environmental concerns theodossiou and latinopoulos 2006 varouchakis and hristopulos 2013 the most common deleterious effect of long time groundwater extraction and subsequent water level decline from unconsolidated aquifer systems in urban areas is land subsidence morris et al 2003 bell et al 2008 over exploited aquifers undergo excessive stress due to the loss of storage and often results in problematic land subsidence doll et al 2012 famiglietti 2014 a management plan that leads to sustainable utilization of groundwater resources is needed in these urban environments the first step in such a plan is effective continuous monitoring of groundwater levels different geodetic techniques for monitoring groundwater levels have been applied in various studies one valid technique is the application of global positioning systems gps which can provide high temporal resolution deformation measurements fu et al 2012 zou et al 2015 the displacement data based on continuous gps measurements provide an effective way for estimating the elastic seasonal and inelastic deformation related to hydraulic head changes within the aquifer system wang et al 2011 and for estimating the confined aquifer storage changes burbey 2003 2006 béjar pizarro et al 2017 jia et al 2018 abidin et al 2008 conducted gps based land deformation monitoring in jakarta from 1997 to 2005 and found a correlation between land deformation and groundwater extraction in addition reeves et al 2014 chen et al 2016 and béjar pizarro et al 2017 used insar based land deformation in different studies to estimate the variations in confined hydraulic head data these studies involved using monthly vertical displacements to reconstruct the head variations in the aquifer system amelung et al 1999 used interferograms from ers 1 and ers 2 data to estimate the seasonal elastic deformation associated with large pumping volumes in las vegas valley nevada chen et al 2010 investigated central taiwan with the aim of correlating gps based vertical deformation to hydraulic heads and found that groundwater overdraft is a major contributor for land subsidence ji and herring 2012 studied horizontal displacements using gps data from 11 sites in gabriel valley california to evaluate the correlation between surface deformations and hydraulic head variations and found that a high correlation exists between these two variables chew and small 2014 estimated terrestrial water storage response to the 2012 drought from gps deformations in the high plains of the central u s argus et al 2014 estimated seasonal variations in water storage from gps based vertical deformation data argus et al 2014 in recent decades many studies have begun to focus on showing the relation between the confined aquifer stress to nonrecoverable inelastic subsidence or in some cases recoverable subsidence smith et al 2017 jia et al 2018 rezaei et al 2019 2020 chen et al 2016 estimated the spatial relation between aquifer heads and displacements from insar data rezaei et al 2020 estimated heads based only on gps displacement data to improve the resolution of historical head measurements these studies all focus on the direct correlation or estimation of point based groundwater level changes but do not consider the spatial varying relation between head change and deformation tsai and hsu 2018 considering the spatially heterogenous properties of aquifers and geohydrologic factors using spatial models is a more robust and effective way for estimating hydraulic head variations from land deformation data at the regional scale this study aims to develop regional hydraulic head estimations from gps estimated land deformations in this study we consider the spatial relation between gps based monthly deformations and groundwater variations from monitoring wells this study involves 1 comparing the compaction measured from deformation monitoring wells with gps based deformation data 2 estimating the temporal variation of land subsidence to monitored groundwater levels 3 determining the relation between head changes and surface deformations stress strain relation 4 estimating the spatial distribution of hydraulic head change data from gps derived deformation and 5 validating the model by comparing the results to observed groundwater monitoring data 1 1 study area in taiwan groundwater usage surpasses surface water usage particularly in west central taiwan where agricultural usage of groundwater is high and in southern taiwan where industrial and aquacultural consumption of groundwater is extensive tung and hu 2012 the study area covers 1800 km2 of yunlin and changhua counties in west central taiwan as the westward flowing choushui river bisects these two counties into a northern and southern area elevation of the area ranges from sea level in the far western part of the study ocean boundary to about 100 m in the eastern proximal margin of the alluvial fan the choushui river alluvial fan sediments originate from the rock developments in the eastern upstream watershed and are comprised of mudstone slate sandstone and shale liu et al 2004 during dry seasons due to inadequate surface water in the alluvial fan of choushui river inhabitants in the area extract large quantities of groundwater to meet local demands for agriculture and domestic usage in the study area agriculture and domestic usage represent a majority of the groundwater usage with agricultural usage totaling approximately 3 3 billion cubic meters annually lee et al 2018 due to decades of excessive groundwater pumping land subsidence has become a serious environmental problem in both counties yunlin and changhua the prominence of fine grained deposits silt and clay within the alluvial fan is responsible for a large majority of the land subsidence in the region creating a substantial geologic hazard particularly for the high speed rail system that extends north south through the study area and through the region of greatest measured land subsidence fig 1 includes a location map 1a showing the distribution of groundwater monitoring wells 1b and gps stations and station numbers 1c in the study area 1c 2 material and methods 2 1 datasets data collected for this study collected extend from jan 2016 to dec 2018 in the study area gps station data and compaction well data are used for monitoring surface deformations at different time scales the bernese was used to calculate weekly movements at 11 gps stations the vertical precision can be less than 1 cm if the gps signals are not blocked and the gps record length is sufficiently long hung et al 2010 hsu et al 2015 monthly compaction well data are available from 31 wells in the study area to compare the compaction well data with the gps data the weekly gps data is converted to mean monthly data hydraulic head observation data are also used in this study hourly hydraulic head data collected by the national water agency were collected from 55 monitoring wells open to the second aquifer fig 1 in yunlin and changhua counties more than two decades of hydraulic head data are available in the study area with the number of monitoring wells increasing with the passage of time the data sets are divided into two sets i e a training set and a testing set that are independent of each other the gps subsidence and interpolated hydraulic heads at the gps stations are used as the training data set and the observed hydraulic heads at groundwater monitoring stations are used as the validation data set 3 methods the process of this investigation from data collection to analysis and assessment is shown in flowchart form in fig 2 firstly the gps and compaction well data are collected and used for comparison with the land deformation sensor data gps is a low cost sensor and the deformation performance accuracy and precision is similar to that of the compaction wells secondly a time series analysis is performed to check the temporal pattern of monthly groundwater and gps deformation changes which provide further information on the seasonal variations in the study area finally the spatio temporal model is built to estimate the regional hydraulic heads using the gps data definition of head change and deformation stress strain the gps based deformation data that is converted to mean monthly values from the original data of weekly observations are compared with the compaction well data monthly monitoring stations to identify the correlation between both monitoring sensors the deformation and head change for each time step t is expressed as 1 δ s t s t 1 s t 2 δ h t h t 1 h t where δ s t is the deformation measured at the monitoring wells and δ h t is the head change measured at the monitoring wells s t 1 and s t are the deformation for time step t 1 and t h t 1 and h t are the hydraulic heads for time step t 1 and t in this analysis two years of monthly averaged gps based deformations are used to calculate the land subsidence change with respect to groundwater variations this approach is identical to the stress strain methodology developed by riley 1969 the correlation between land subsidence and groundwater level change is evaluated for the two years of data 3 1 spatial temporal deformation estimation the spatial estimation of groundwater level changes is one of the important factors for finding the spatial distribution of deformation variations since we have 11 spatially distributed gps stations for monitoring land subsidence the inverse distance weighted idw interpolation technique is used here to create the spatial distribution map of the land deformation because it provides a more accurate realization of spatially independent observations an independent interpolation is conducted for every month of land deformation then the deformation monthly change δ s t can be determined 3 2 spatial temporal model for estimating hydraulic heads the time dependent spatial regression technique is used to model the relation between the temporal and spatial groundwater level changes and land deformation in the model coefficients are varying over the spatial dimension weighted least squares is used to estimate the head change in the model which is expressed as 3 δ h ˆ t i β t 0 u i v i β t 1 u i v i δ s t i where β t 0 u i v i is the intercept at every location u i v i and β t 1 u i v i is the coefficient comprising the latitude and longitude location i in this equation the gps data represent the prediction variables while the groundwater level change δ h t i is the estimated variable δ s t i is the deformation change at observation i and time t the estimated parameter matrix β ˆ t u i v i is derived from 4 β ˆ t u i v i x t t w u i v i x t 1 x t t w u i v i y t where β ˆ t u i v i β ˆ t 0 u i v i β ˆ t 1 u i v i t y t δ h ˆ t 1 δ h ˆ t n t x t 1 δ s t 1 1 δ s t n w u i v i is a spatial weight matrix which is formulated from the gaussian and euclidean distance functions the gaussian decay based function commonly used as a kernel is defined as e d i j h 2 where h is the non negative bandwidth the parameter dij is the distance between the observed points i and j in the space domain which is defined as dij u i u j 2 v i v j 2 considering the initial head h t the future hydraulic head is estimated using equation 3 as 5 h ˆ t 1 i h t i δ h ˆ t i to check the accuracy of the model the correlation between estimated and observed hydraulic heads is used for validation 4 results and discussion 4 1 comparing deformation from gps and compaction well data fig 3 compares the deformation data plots from gps and compaction wells over a 24 month period the correlation of gps and compaction well data are for the mid fan and distal fan areas fig 3 a shows the subsidence correlation line that indicates both compaction values and uplift values occur during monthly monitoring the maximum uplift for the gps data is about 1 cm per month r square of 0 71 occurs in yunlin county in the area with the greatest subsidence about 7 cm annually hsu et al 2015 fig 3 b and c compare the gps and compaction well data near the coastal region and in the northern area the average r square for four locations in this region is greater than 0 7 the highest correlation is 0 87 in the coast region fig 3 b indicating that compaction well and gps data are highly correlated this correlation is useful because of the low cost of gps sensors compared to compaction monitoring wells 4 2 time series of head change deformation fig 4 shows the monthly deformation land subsidence changes obtained from the 11 gps stations over the 24 month study period the greatest subsidence for all the stations is shown to occur from february through april each year this pattern of subsidence largely coincides with the results of chu et al 2020 who determined that pumping extraction is highest from feb may each year due to high groundwater demand for irrigation the lone exception to this is april 2016 when precipitation was unusually high resulting in greatly reduced subsidence the greatest uplift of 1 5 cm occurs in october 2016 at the station nearest the coast the 2017 data are similar to 2016 with large subsidence occurring from feb to april and uplift occurring in june and july 2017 associated with high recharge rates from the summer monsoon season fig 5 shows the monthly groundwater level change positive drawdown the pattern of the groundwater change is more highly correlated with the gps deformation data especially in the distal fan table 1 the plain area exhibits a high correlation between groundwater and deformation but the stations in mountainous area exhibits a low correlation of 0 2708 according to our observations and previous investigations deckert and bolstad 1996 forested mountainous area with steep terrains create obstacles for vertical accuracy and unbiasedness obtained from gps data in addition the vertical surface displacement is controlled mainly by the effect of water mass loading associated with large storage coefficients of the unconfined aquifers in the proximal fan lu et al 2020 the correlation between land subsidence and groundwater level change indicates that the soil materials in this area exhibit a high elasticity chu et al 2021 many studies have confirmed this relationship using different approaches to show this direct or indirect temporal change relationship lu et al 2020 showed the relationship between hydraulic head change and land subsidence at different monitoring stations and found that the proximal fan area behaved differently negative correlation between water levels and subsidence than the mid fan area positive correlation between water levels and subsidence which is similar to the findings in this investigation 4 3 the relation between head change and land subsidence the stress strain relationship between the monthly land subsidence strain and groundwater level change stress is shown at different locations in fig 6 the four plots are taken at different positions within the fan and consequently exhibit different correlation characteristics for example fig 6 a shows that the correlation in the coastal study area yields an r square of 0 67 fig 6 a is a coastal location in the southern area and exhibits a slope of 0 195 the slope indicates that a 1 m decrease in groundwater level would result in 0 195 cm of land subsidence fig 6 b is also a coastal location north of the previous graph and exhibits higher slope slope 0 36 higher potential for subsidence land subsidence is not significant in these two coastal areas and surface rebound is significant during the recharge season the slope of the regression line in fig 6 c is 0 33 in the inland area the slope of the regression line in fig 6 d is 0 39 and the r square is 0 62 which is lower compared to other locations the less head change and the less subsidence in fig 6 d the correlation between the vertical surface displacement and the hydraulic head change is consistently positive lu et al 2020 ji and herring 2012 however it is interpreted that the alluvial fan sequence in the subsurface is not fully homogenous which also matches our findings we now apply the time dependent spatial regression to simulate the spatial relation between deformation and groundwater level change 4 4 spatial mapping of groundwater level changes from observed deformation mapping of the spatial distribution of vertical deformation is performed from the monthly gps data using eqs 3 and 4 fig 7 shows the monthly changes in vertical deformation eq 1 produced from the 11 gps stations using the interpolation method i e inverse distance weighting idw the monthly vertical deformation maps show both subsidence positive values and uplift negative values over the study area however in general the largest subsidence occurs in localized bowls whereas the uplift tends to occur regionally the greatest subsidence of up to 1 4 cm occurs in march at the same localities that other studies also identified for having severe land subsidence hsu et al 2015 ali et al 2020 the figure shows that locally serious monthly subsidence of 0 6 0 8 cm occurs in the study area the greatest subsidence occurs during the early part of the year when recharge is low and groundwater extraction for agricultural irrigation is high chu et al 2020 the spatial distribution of land subsidence indicates that the monthly groundwater level change fig 8 is accurately predicted using the time dependent spatial regression model the monthly spatial distribution estimation maps reveal that the hotspots of large groundwater declines and subsequent land subsidence occur most notably in the mid and distal fan regions and result matches the previous study ali et al 2020 the estimated groundwater decline is as high as 3 0 m in these areas the monthly change maps also reveal that the southeast corner of the area undergoes significant seasonal water level changes showing that the overall discharge rate is quite high in february to april but undergoes significant recharge and subsequent recovery in the summer rainy season however the recharge from precipitation in april 2016 reduced subsidence significantly finally the figures clearly reveal the location of the subsidence bowls where drawdowns are greatest these maps are useful as tools for water managers responsible for monitoring and strategizing the mitigation of land subsidence 4 5 model validation and spatiotemporal result fig 9 shows the regional map of calculated monthly hydraulic heads from our model the southwest coastal area has negative values of up to 20 m while the mountainous areas in the east have hydraulic heads of as great as 100 m the spatial and temporal variations in groundwater levels is estimated using the gps based deformation at different spatial locations the model estimates hydraulic heads using gps based deformation and further for validation are shown in fig 10 for the 24 month study period randomly selected eight locations for visualization validation results reveal a strong correlation between the gps based estimated hydraulic heads and observed hydraulic heads the high correlation r 0 95 shows between observed and estimated groundwater levels these results confirm the conclusions of bonì et al 2016 who determined that sar data can be used to estimate groundwater level changes at the regional scale for the london area in this study we found that the estimated hydraulic heads can be estimated from limited gps deformation data eqs 3 and 4 the previous studies applied the insar method to detect land deformation time series to estimate the resulting hydraulic head time series bonì et al 2016 jiang et al 2018 in this study we validated that gps deformation can indeed be used for estimating monthly hydraulic heads 4 6 model limitation the previous studies bonì et al 2016 jiang et al 2018 focused on estimating the storage coefficients the total deformation could ultimately be separated into recoverable and nonrecoverable components however the separation of storage elastic vs inelastic components was not part of this investigation in addition the future study will consider machine learning for modelling jang et al 2020 5 conclusions the relations between monthly variations in groundwater levels and land subsidence are identified for the 2016 17 time period using compaction well data gps deformation and water level observation data the analyses show a higher correlation between monthly gps deformation data and groundwater level data than the compaction well data this strong correlation between monthly temporal gps based deformations strain and groundwater level variations stress indicates that the aquifer system in the study area exhibits an elastic deformation response to groundwater level change this study reveals that the spatial distribution of correlation varies by location for example the correlation in mountainous areas is much lower than in the plain or coastal regions the spatio temporal hydraulic heads are identified using the time dependent spatial regression approach groundwater level changes are occurring in both counties yunlin and chunghwa of the study site moreover the hydraulic heads have been estimated from gps derived deformation with a correlation of 0 95 when compared with the observed groundwater monitoring data results show that gps based deformation can be used to accurately estimate monthly hydraulic heads this study proves that regional water levels and land subsidence can be estimated from even a small number of gps and groundwater monitoring stations highly informative spatial monthly based groundwater level change maps can be generated from gps derived deformations software availability the models included in this paper are open source the function code can be found at https mybox ncku edu tw navigate s 8c2cc71ee161465589dc4a306d469becgsy the gwr and idw are originally developed by james p lesage and simone fatichi we combined both into the modified ones the main m is the main function in the code for data loading regression models between gps deformation and groundwater level change groundwater level mapping validation and visualization model output from the system is implemented declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we acknowledge the financial support from the most ministry of science and technology taiwan this research was funded by most taiwan grant number 105 2621 m 006 011 and 109 2621 m 006 003 we thank the central geological survey and water resources agency in taiwan for providing valuable geological survey data groundwater monitoring records multi level compaction monitoring records precise leveling data and drilling data of groundwater stations that were used in this study we also thank water resources agency and institute of earth sciences academia sinica taiwan for gps displacement data support supplementary data the following is the supplementary data to this article https mybox ncku edu tw navigate s b22b645f768e41ddac5e75221ea89de5gsy appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105123 
25801,significant subsidence is susceptible to groundwater level variations in aquifer systems the relation between groundwater level change and global positioning system gps estimated subsidence is spatially variable time dependent spatial regression can be used for the estimation of groundwater level changes using gps based deformation data furthermore the model can be validated using observed hydraulic head data from available monitoring stations this study uses gps station data to estimate the monthly groundwater levels in the west central taiwan for the period 2016 17 time dependent spatial regression provides a more realistic estimation of groundwater level changes in response to highly heterogeneous aquifer properties than other methods the high correlation r 0 95 between observed and estimated groundwater levels shows that gps estimated deformations represent an alternative approach for estimating seasonal groundwater changes due to availability of spatially broad low cost gps data compared to the sparse availability groundwater monitoring stations the use of gps data represents a powerful solution for future monitoring of estimated seasonal groundwater level changes in areas where only few groundwater observations are available keywords groundwater gps based deformation time dependent spatial regression seasonal variation 1 introduction groundwater is a valuable resource representing approximately 99 of all accessible freshwater and is globally utilized mostly for agriculture industry and domestic usage alley et al 2002 worldwide many cities rely exclusively on groundwater for daily water usage boretti and rosa 2019 during periods of drought an increased utilization of groundwater is common particularly in localities that also previously utilized surface water effective and strategic groundwater management particularly during periods of drought requires real time knowledge of groundwater levels and storage changes evans et al 2020 effective models can provide the necessary information required to make informed decisions about groundwater resources and other environmental concerns theodossiou and latinopoulos 2006 varouchakis and hristopulos 2013 the most common deleterious effect of long time groundwater extraction and subsequent water level decline from unconsolidated aquifer systems in urban areas is land subsidence morris et al 2003 bell et al 2008 over exploited aquifers undergo excessive stress due to the loss of storage and often results in problematic land subsidence doll et al 2012 famiglietti 2014 a management plan that leads to sustainable utilization of groundwater resources is needed in these urban environments the first step in such a plan is effective continuous monitoring of groundwater levels different geodetic techniques for monitoring groundwater levels have been applied in various studies one valid technique is the application of global positioning systems gps which can provide high temporal resolution deformation measurements fu et al 2012 zou et al 2015 the displacement data based on continuous gps measurements provide an effective way for estimating the elastic seasonal and inelastic deformation related to hydraulic head changes within the aquifer system wang et al 2011 and for estimating the confined aquifer storage changes burbey 2003 2006 béjar pizarro et al 2017 jia et al 2018 abidin et al 2008 conducted gps based land deformation monitoring in jakarta from 1997 to 2005 and found a correlation between land deformation and groundwater extraction in addition reeves et al 2014 chen et al 2016 and béjar pizarro et al 2017 used insar based land deformation in different studies to estimate the variations in confined hydraulic head data these studies involved using monthly vertical displacements to reconstruct the head variations in the aquifer system amelung et al 1999 used interferograms from ers 1 and ers 2 data to estimate the seasonal elastic deformation associated with large pumping volumes in las vegas valley nevada chen et al 2010 investigated central taiwan with the aim of correlating gps based vertical deformation to hydraulic heads and found that groundwater overdraft is a major contributor for land subsidence ji and herring 2012 studied horizontal displacements using gps data from 11 sites in gabriel valley california to evaluate the correlation between surface deformations and hydraulic head variations and found that a high correlation exists between these two variables chew and small 2014 estimated terrestrial water storage response to the 2012 drought from gps deformations in the high plains of the central u s argus et al 2014 estimated seasonal variations in water storage from gps based vertical deformation data argus et al 2014 in recent decades many studies have begun to focus on showing the relation between the confined aquifer stress to nonrecoverable inelastic subsidence or in some cases recoverable subsidence smith et al 2017 jia et al 2018 rezaei et al 2019 2020 chen et al 2016 estimated the spatial relation between aquifer heads and displacements from insar data rezaei et al 2020 estimated heads based only on gps displacement data to improve the resolution of historical head measurements these studies all focus on the direct correlation or estimation of point based groundwater level changes but do not consider the spatial varying relation between head change and deformation tsai and hsu 2018 considering the spatially heterogenous properties of aquifers and geohydrologic factors using spatial models is a more robust and effective way for estimating hydraulic head variations from land deformation data at the regional scale this study aims to develop regional hydraulic head estimations from gps estimated land deformations in this study we consider the spatial relation between gps based monthly deformations and groundwater variations from monitoring wells this study involves 1 comparing the compaction measured from deformation monitoring wells with gps based deformation data 2 estimating the temporal variation of land subsidence to monitored groundwater levels 3 determining the relation between head changes and surface deformations stress strain relation 4 estimating the spatial distribution of hydraulic head change data from gps derived deformation and 5 validating the model by comparing the results to observed groundwater monitoring data 1 1 study area in taiwan groundwater usage surpasses surface water usage particularly in west central taiwan where agricultural usage of groundwater is high and in southern taiwan where industrial and aquacultural consumption of groundwater is extensive tung and hu 2012 the study area covers 1800 km2 of yunlin and changhua counties in west central taiwan as the westward flowing choushui river bisects these two counties into a northern and southern area elevation of the area ranges from sea level in the far western part of the study ocean boundary to about 100 m in the eastern proximal margin of the alluvial fan the choushui river alluvial fan sediments originate from the rock developments in the eastern upstream watershed and are comprised of mudstone slate sandstone and shale liu et al 2004 during dry seasons due to inadequate surface water in the alluvial fan of choushui river inhabitants in the area extract large quantities of groundwater to meet local demands for agriculture and domestic usage in the study area agriculture and domestic usage represent a majority of the groundwater usage with agricultural usage totaling approximately 3 3 billion cubic meters annually lee et al 2018 due to decades of excessive groundwater pumping land subsidence has become a serious environmental problem in both counties yunlin and changhua the prominence of fine grained deposits silt and clay within the alluvial fan is responsible for a large majority of the land subsidence in the region creating a substantial geologic hazard particularly for the high speed rail system that extends north south through the study area and through the region of greatest measured land subsidence fig 1 includes a location map 1a showing the distribution of groundwater monitoring wells 1b and gps stations and station numbers 1c in the study area 1c 2 material and methods 2 1 datasets data collected for this study collected extend from jan 2016 to dec 2018 in the study area gps station data and compaction well data are used for monitoring surface deformations at different time scales the bernese was used to calculate weekly movements at 11 gps stations the vertical precision can be less than 1 cm if the gps signals are not blocked and the gps record length is sufficiently long hung et al 2010 hsu et al 2015 monthly compaction well data are available from 31 wells in the study area to compare the compaction well data with the gps data the weekly gps data is converted to mean monthly data hydraulic head observation data are also used in this study hourly hydraulic head data collected by the national water agency were collected from 55 monitoring wells open to the second aquifer fig 1 in yunlin and changhua counties more than two decades of hydraulic head data are available in the study area with the number of monitoring wells increasing with the passage of time the data sets are divided into two sets i e a training set and a testing set that are independent of each other the gps subsidence and interpolated hydraulic heads at the gps stations are used as the training data set and the observed hydraulic heads at groundwater monitoring stations are used as the validation data set 3 methods the process of this investigation from data collection to analysis and assessment is shown in flowchart form in fig 2 firstly the gps and compaction well data are collected and used for comparison with the land deformation sensor data gps is a low cost sensor and the deformation performance accuracy and precision is similar to that of the compaction wells secondly a time series analysis is performed to check the temporal pattern of monthly groundwater and gps deformation changes which provide further information on the seasonal variations in the study area finally the spatio temporal model is built to estimate the regional hydraulic heads using the gps data definition of head change and deformation stress strain the gps based deformation data that is converted to mean monthly values from the original data of weekly observations are compared with the compaction well data monthly monitoring stations to identify the correlation between both monitoring sensors the deformation and head change for each time step t is expressed as 1 δ s t s t 1 s t 2 δ h t h t 1 h t where δ s t is the deformation measured at the monitoring wells and δ h t is the head change measured at the monitoring wells s t 1 and s t are the deformation for time step t 1 and t h t 1 and h t are the hydraulic heads for time step t 1 and t in this analysis two years of monthly averaged gps based deformations are used to calculate the land subsidence change with respect to groundwater variations this approach is identical to the stress strain methodology developed by riley 1969 the correlation between land subsidence and groundwater level change is evaluated for the two years of data 3 1 spatial temporal deformation estimation the spatial estimation of groundwater level changes is one of the important factors for finding the spatial distribution of deformation variations since we have 11 spatially distributed gps stations for monitoring land subsidence the inverse distance weighted idw interpolation technique is used here to create the spatial distribution map of the land deformation because it provides a more accurate realization of spatially independent observations an independent interpolation is conducted for every month of land deformation then the deformation monthly change δ s t can be determined 3 2 spatial temporal model for estimating hydraulic heads the time dependent spatial regression technique is used to model the relation between the temporal and spatial groundwater level changes and land deformation in the model coefficients are varying over the spatial dimension weighted least squares is used to estimate the head change in the model which is expressed as 3 δ h ˆ t i β t 0 u i v i β t 1 u i v i δ s t i where β t 0 u i v i is the intercept at every location u i v i and β t 1 u i v i is the coefficient comprising the latitude and longitude location i in this equation the gps data represent the prediction variables while the groundwater level change δ h t i is the estimated variable δ s t i is the deformation change at observation i and time t the estimated parameter matrix β ˆ t u i v i is derived from 4 β ˆ t u i v i x t t w u i v i x t 1 x t t w u i v i y t where β ˆ t u i v i β ˆ t 0 u i v i β ˆ t 1 u i v i t y t δ h ˆ t 1 δ h ˆ t n t x t 1 δ s t 1 1 δ s t n w u i v i is a spatial weight matrix which is formulated from the gaussian and euclidean distance functions the gaussian decay based function commonly used as a kernel is defined as e d i j h 2 where h is the non negative bandwidth the parameter dij is the distance between the observed points i and j in the space domain which is defined as dij u i u j 2 v i v j 2 considering the initial head h t the future hydraulic head is estimated using equation 3 as 5 h ˆ t 1 i h t i δ h ˆ t i to check the accuracy of the model the correlation between estimated and observed hydraulic heads is used for validation 4 results and discussion 4 1 comparing deformation from gps and compaction well data fig 3 compares the deformation data plots from gps and compaction wells over a 24 month period the correlation of gps and compaction well data are for the mid fan and distal fan areas fig 3 a shows the subsidence correlation line that indicates both compaction values and uplift values occur during monthly monitoring the maximum uplift for the gps data is about 1 cm per month r square of 0 71 occurs in yunlin county in the area with the greatest subsidence about 7 cm annually hsu et al 2015 fig 3 b and c compare the gps and compaction well data near the coastal region and in the northern area the average r square for four locations in this region is greater than 0 7 the highest correlation is 0 87 in the coast region fig 3 b indicating that compaction well and gps data are highly correlated this correlation is useful because of the low cost of gps sensors compared to compaction monitoring wells 4 2 time series of head change deformation fig 4 shows the monthly deformation land subsidence changes obtained from the 11 gps stations over the 24 month study period the greatest subsidence for all the stations is shown to occur from february through april each year this pattern of subsidence largely coincides with the results of chu et al 2020 who determined that pumping extraction is highest from feb may each year due to high groundwater demand for irrigation the lone exception to this is april 2016 when precipitation was unusually high resulting in greatly reduced subsidence the greatest uplift of 1 5 cm occurs in october 2016 at the station nearest the coast the 2017 data are similar to 2016 with large subsidence occurring from feb to april and uplift occurring in june and july 2017 associated with high recharge rates from the summer monsoon season fig 5 shows the monthly groundwater level change positive drawdown the pattern of the groundwater change is more highly correlated with the gps deformation data especially in the distal fan table 1 the plain area exhibits a high correlation between groundwater and deformation but the stations in mountainous area exhibits a low correlation of 0 2708 according to our observations and previous investigations deckert and bolstad 1996 forested mountainous area with steep terrains create obstacles for vertical accuracy and unbiasedness obtained from gps data in addition the vertical surface displacement is controlled mainly by the effect of water mass loading associated with large storage coefficients of the unconfined aquifers in the proximal fan lu et al 2020 the correlation between land subsidence and groundwater level change indicates that the soil materials in this area exhibit a high elasticity chu et al 2021 many studies have confirmed this relationship using different approaches to show this direct or indirect temporal change relationship lu et al 2020 showed the relationship between hydraulic head change and land subsidence at different monitoring stations and found that the proximal fan area behaved differently negative correlation between water levels and subsidence than the mid fan area positive correlation between water levels and subsidence which is similar to the findings in this investigation 4 3 the relation between head change and land subsidence the stress strain relationship between the monthly land subsidence strain and groundwater level change stress is shown at different locations in fig 6 the four plots are taken at different positions within the fan and consequently exhibit different correlation characteristics for example fig 6 a shows that the correlation in the coastal study area yields an r square of 0 67 fig 6 a is a coastal location in the southern area and exhibits a slope of 0 195 the slope indicates that a 1 m decrease in groundwater level would result in 0 195 cm of land subsidence fig 6 b is also a coastal location north of the previous graph and exhibits higher slope slope 0 36 higher potential for subsidence land subsidence is not significant in these two coastal areas and surface rebound is significant during the recharge season the slope of the regression line in fig 6 c is 0 33 in the inland area the slope of the regression line in fig 6 d is 0 39 and the r square is 0 62 which is lower compared to other locations the less head change and the less subsidence in fig 6 d the correlation between the vertical surface displacement and the hydraulic head change is consistently positive lu et al 2020 ji and herring 2012 however it is interpreted that the alluvial fan sequence in the subsurface is not fully homogenous which also matches our findings we now apply the time dependent spatial regression to simulate the spatial relation between deformation and groundwater level change 4 4 spatial mapping of groundwater level changes from observed deformation mapping of the spatial distribution of vertical deformation is performed from the monthly gps data using eqs 3 and 4 fig 7 shows the monthly changes in vertical deformation eq 1 produced from the 11 gps stations using the interpolation method i e inverse distance weighting idw the monthly vertical deformation maps show both subsidence positive values and uplift negative values over the study area however in general the largest subsidence occurs in localized bowls whereas the uplift tends to occur regionally the greatest subsidence of up to 1 4 cm occurs in march at the same localities that other studies also identified for having severe land subsidence hsu et al 2015 ali et al 2020 the figure shows that locally serious monthly subsidence of 0 6 0 8 cm occurs in the study area the greatest subsidence occurs during the early part of the year when recharge is low and groundwater extraction for agricultural irrigation is high chu et al 2020 the spatial distribution of land subsidence indicates that the monthly groundwater level change fig 8 is accurately predicted using the time dependent spatial regression model the monthly spatial distribution estimation maps reveal that the hotspots of large groundwater declines and subsequent land subsidence occur most notably in the mid and distal fan regions and result matches the previous study ali et al 2020 the estimated groundwater decline is as high as 3 0 m in these areas the monthly change maps also reveal that the southeast corner of the area undergoes significant seasonal water level changes showing that the overall discharge rate is quite high in february to april but undergoes significant recharge and subsequent recovery in the summer rainy season however the recharge from precipitation in april 2016 reduced subsidence significantly finally the figures clearly reveal the location of the subsidence bowls where drawdowns are greatest these maps are useful as tools for water managers responsible for monitoring and strategizing the mitigation of land subsidence 4 5 model validation and spatiotemporal result fig 9 shows the regional map of calculated monthly hydraulic heads from our model the southwest coastal area has negative values of up to 20 m while the mountainous areas in the east have hydraulic heads of as great as 100 m the spatial and temporal variations in groundwater levels is estimated using the gps based deformation at different spatial locations the model estimates hydraulic heads using gps based deformation and further for validation are shown in fig 10 for the 24 month study period randomly selected eight locations for visualization validation results reveal a strong correlation between the gps based estimated hydraulic heads and observed hydraulic heads the high correlation r 0 95 shows between observed and estimated groundwater levels these results confirm the conclusions of bonì et al 2016 who determined that sar data can be used to estimate groundwater level changes at the regional scale for the london area in this study we found that the estimated hydraulic heads can be estimated from limited gps deformation data eqs 3 and 4 the previous studies applied the insar method to detect land deformation time series to estimate the resulting hydraulic head time series bonì et al 2016 jiang et al 2018 in this study we validated that gps deformation can indeed be used for estimating monthly hydraulic heads 4 6 model limitation the previous studies bonì et al 2016 jiang et al 2018 focused on estimating the storage coefficients the total deformation could ultimately be separated into recoverable and nonrecoverable components however the separation of storage elastic vs inelastic components was not part of this investigation in addition the future study will consider machine learning for modelling jang et al 2020 5 conclusions the relations between monthly variations in groundwater levels and land subsidence are identified for the 2016 17 time period using compaction well data gps deformation and water level observation data the analyses show a higher correlation between monthly gps deformation data and groundwater level data than the compaction well data this strong correlation between monthly temporal gps based deformations strain and groundwater level variations stress indicates that the aquifer system in the study area exhibits an elastic deformation response to groundwater level change this study reveals that the spatial distribution of correlation varies by location for example the correlation in mountainous areas is much lower than in the plain or coastal regions the spatio temporal hydraulic heads are identified using the time dependent spatial regression approach groundwater level changes are occurring in both counties yunlin and chunghwa of the study site moreover the hydraulic heads have been estimated from gps derived deformation with a correlation of 0 95 when compared with the observed groundwater monitoring data results show that gps based deformation can be used to accurately estimate monthly hydraulic heads this study proves that regional water levels and land subsidence can be estimated from even a small number of gps and groundwater monitoring stations highly informative spatial monthly based groundwater level change maps can be generated from gps derived deformations software availability the models included in this paper are open source the function code can be found at https mybox ncku edu tw navigate s 8c2cc71ee161465589dc4a306d469becgsy the gwr and idw are originally developed by james p lesage and simone fatichi we combined both into the modified ones the main m is the main function in the code for data loading regression models between gps deformation and groundwater level change groundwater level mapping validation and visualization model output from the system is implemented declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we acknowledge the financial support from the most ministry of science and technology taiwan this research was funded by most taiwan grant number 105 2621 m 006 011 and 109 2621 m 006 003 we thank the central geological survey and water resources agency in taiwan for providing valuable geological survey data groundwater monitoring records multi level compaction monitoring records precise leveling data and drilling data of groundwater stations that were used in this study we also thank water resources agency and institute of earth sciences academia sinica taiwan for gps displacement data support supplementary data the following is the supplementary data to this article https mybox ncku edu tw navigate s b22b645f768e41ddac5e75221ea89de5gsy appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105123 
25802,increasing wildfire activity globally has become an urgent issue with enormous ecological and social impacts in this work we focus on analyzing and quantifying the influence of landscape topology understood as the spatial structure and interaction of multiple land covers in an area on fire ignition we propose a deep learning framework deep fire topology to estimate and predict wildfire ignition risk we focus on understanding the impact of these topological attributes and the rationale behind the results to provide interpretable knowledge for territorial planning considering wildfire ignition uncertainty we demonstrate the high performance and interpretability of the framework in a case study accurately detecting risky areas by exploiting spatial patterns this work reveals the strong potential of landscape topology in wildfire occurrence prediction and its implications to develop robust landscape management plans we discuss potential extensions and applications of the proposed method available as an open source software keywords deep learning machine learning landscape topology wildfire ignition risk wildfire management territorial planning 1 introduction wildfires are a unique disturbance that can potentially affect every earth system component with notorious effects on large scale biosphere atmosphere interaction increasing greenhouse gas emissions due to wildfires could lead to positive feedback with global warming impacting human well being because of its consequences in climate change economic losses or environmental and biodiversity damage bowman et al 2020 kelly et al 2020 fire regime is changing in the anthropocene because of complex fire human climatic interactions but mainly shaped by increasing human activity in all biomes bowman et al 2011 moritz et al 2014 the future fire regime is uncertain however no evidence supports a decrease in fire activity bowman et al 2020 potential increase in wildfire activity across the globe has become an issue of real urgency with the most apparent impacts being the enormous number of structures and lives lost in places like california brazil australia greece chile and portugal bowman et al 2019 chen and mcaneney 2004 kramer et al 2018 radeloff et al 2018 and its impacts in biodiversity and greenhouse gas emissions andela et al 2019 liu et al 2020 moritz et al 2014 these events reveal the need for new approaches to understand this complex phenomenon and develop preventive plans to mitigate their impact accounting for a warmer future landscape planning could be one of the most effective ways for local adaptation to increased fire activity bowman et al 2020 moreira et al 2020 the wildfire regime depends on and interacts with the spatial and temporal patterns of the landscapes mckenzie et al 2011 landscape attributes quantified by the land cover structure composition heterogeneity spatial distribution and interactions between its components could influence fire activity potentially perturbing multiple processes such as fire ignition frequency spread the energy released and severity in fire prone ecosystems ganteaume and syphard 2018 moreira et al 2010 2011 van wagtendonk 2006 given climate change scenarios human coexistence with wildfires will necessitate informed decision making to minimize fire risk bowman et al 2020 calkin et al 2014 keeley and syphard 2019 moreira et al 2020 moritz et al 2014 moreover historical fire occurrence is an empirical manifestation of the local spatial interaction between fire and fire prone ecosystems therefore understanding these phenomena could help produce an informed fire risk evaluation and evidence based effective territorial planning argañaraz et al 2017 ganteaume and syphard 2018 miranda et al 2020 the analysis of spatial patterns at large scales has evolved with geographic information systems remote sensing and computational science capabilities gustafson 2019 this co evolution allows multidisciplinary thinking to integrates into one framework a large amount of data from different sources and high computational consuming analysis to solve old problems hypotheses with new techniques costanza et al 2019 in this line deep learning dl models have started a revolution in multiple areas with a significant contribution in intensive computer vision tasks such as large scale geographic data processing and inference interest in dl methods has grown recently owing to their remarkable success in various domains specifically this interest is because of technical aspects and their effective application to problems that have not been efficiently addressed the availability of large volumes of training data affordable computing power and the development of new algorithms to automatically adjust crucial parameters of the models bisong 2019 has led to the rebirth of these techniques since their early emergence in the 1980s their successful application in image recognition zhang et al 2017 speech recognition lecun et al 2015 text analytics kadhim 2019 and self driving cars hoang et al 2019 among several others has increased the popularity of these systems dl can be a crucial tool for numerous ecological applications owing to the complexity of ecological data and the ever growing size of ecological datasets christin et al 2019 recently dl techniques have been applied in the field of ecology specifically species identification norouzzadeh et al 2018 animal behavior classification and biodiversity estimation for large datasets such as camera trap images rovero et al 2013 2014 audio recordings and videos sevilla and glotin 2017 are some examples in the wildfire applications context dl models trained for fire detection sousa et al 2020 and wildfire spread prediction hodges and lattimer 2019 are some examples found in the literature jain et al 2020 however to the best of our knowledge only a few studies and applications of dl have been reported for understanding the effect of landscape patterns on fire activity gustafson 2019 being the closest application the one presented in zhang et al 2019 for fire susceptibility mapping landscape metrics such as proximity connectivity adjacency or composition index among others that are typically used in landscape ecology as a measure of structural characterization do not change significantly over time gustafson 2019 these metrics are widely used with the assumption that spatial patterns can explain ecological processes and functions in a landscape however summarizing the spatial patterns with one or a few metrics can leave out much information limiting the understanding of landscape patterns interactions and processes the study of fire occurrence focuses on measuring the chance that a fire might start in a region given a set of conditions factors previous studies have considered risk factors derived from weather danger indices physiography land cover or socioeconomic variables de montis et al 2017 mckenzie et al 2011 which are usually represented by a collection of individual and potentially correlated numerical or categorical variables ganteaume and syphard 2018 the machine learning field has provided useful tools and methods for modeling fire ignition techniques such as classification and regression trees amatulli et al 2006 fuzzy metaheuristic ensembles moayedi et al 2020 support vector machines ghorbanzadeh et al 2019 random forests leuenberger et al 2018 massada et al 2013 oliveira et al 2012 and so forth have been successfully applied as alternatives to traditional statistical methods topological aspects understood as the spatial structure and interaction between several components of the land e g land cover are captured by constructing and extracting selected indexes of landscape structure and composition for example lloret et al 2002 includes patch density mean patch size mean distance to the nearest neighbor of the same category edge density and the shannon diversity index for modeling the burned area in the eastern iberian peninsula similarly the work by ricotta et al 2018 studies the impact of the interaction between roads and land cover on fire ignition by constructing a selectivity index there is sufficient evidence that the spatial configuration of these elements can influence fire regimes especially under no extreme weather condition alencar et al 2015 mckenzie et al 2011 moreira et al 2011 from our point of view this aspect of the landscapes has been challenging to study and difficult to understand due to i the difficulty of explicitly extracting metrics that can capture aspects of the landscape topology generally requiring more computational resources and time and ii the non spatial nature of traditional statistical and machine learning models e g random forest that rely on the inclusion of multiple variables such as those previously mentioned to explain the phenomenon and improve the predictive performance of the model land cover data represent the basic information for landscape analysis at a pixel level of the primary land uses in a geographically delimited territory this two dimensional representation of the landscape also captures an intrinsic relationship between adjacency and connectivity of its components which can be studied to understand landscape phenomena and complex patterns and processes in the context of wildfire effectively capturing extracting and interpreting this topological information can play a fundamental role in future prevention and mitigation strategies sakellariou et al 2020 similarly it could inform the optimal allocation of resources across regions and the development of effective and sustainable risk management policies therefore we observe an opportunity to apply new effective methods techniques such as dl to try to isolate quantify and understand the impact of landscape topology as a predictor of fire ignition motivating the present study moreover given the current open access to huge global datasets on cloud services and the massive computational power that allows fast training cycles of the models the scalability and potential impact of such a model are unbounded in this paper we introduce deep fire topology dft a comprehensive framework available as open source software for landscape topology analysis landscape topology understood as the spatial structure and interaction of multiple land covers in an area of study is extracted by training a dl model while focusing on understanding the rationale behind the results a crucial element to the applicability of the model we present an application on the landscape ecology of wildfire to evaluate the land cover topology as a predictor of the fire occurrence probability we use a convolutional neural network cnn based model without considering additional information such as population density or weather information which are generally used as variables de montis et al 2017 ganteaume and syphard 2018 to isolate and assess the impact of different spatial patterns in fire ignition i e to observe how different spatial configurations of land cover could give us valuable information regarding the susceptibility of future wildfire ignitions in the area dft use a supervised learning approach where land cover images are labeled as fire or no fire representing the presence absence of an ignition in contrast to previous studies focused on generating susceptibility maps where each pixel is associated with an ignition probability we focus on identifying the joint effect of multiple cells to estimate the ignition risk of the whole area under analysis we also open the dl black box by including state of the art visualization and statistical techniques aimed at understanding the results this with the aim of informing and supporting landscape managers to minimize fire risk or improve the effectiveness of suppression strategies by optimizing the allocation of resources in high risk areas and potentially support the development of new landscape managing and protection policies 2 material and methods 2 1 data mining processing and inputs data can be provided to the framework using two main approaches i automatic collection and processing of online assets in google earth engine gee to generate a ready to use dataset and ii local data provided by the user for training prediction the first method is integrated into our framework via scripts and can be used as an independent module for queries in the first approach users can provide a set of ignition and negative sample points in a latitude longitude format starting from our data mining and processing module the landscape data are automatically gathered from gee generating a square buffer of area a km2 a 1 by default centered at the given points if other layers or metadata are required for example temperature or road density users can execute the module independently and include any relevant source available at the gee to be stacked as an extra band of the sampled image finally the data are automatically downloaded to a cloud account or local hard drive although global public datasets are already available in gee users would need to provide and upload their high resolution regional datasets to take complete advantage of our framework alternatively users provide unclassified data consisting of images rgb or grayscale with or without metadata as extra input features of the model all samples are automatically resized and scaled to match the dimensions required by the classification model 32 32 normalized pixels by default and are recorded locally the dataset is subsequently used for training a custom model or processed for prediction by pre trained models parameters such as the training validation proportion or classification labels can be modified 2 2 study area we tested our approach using south central chile as a case study fig 1 a it includes eight administrative regions 212 000 km2 corresponding to 28 of the national territory it covers an area from 32 to 43 8 s 2 750 km which accounts for 98 5 of the national historical fire occurrence gonzález et al 2018 the northern part of our study area has a semi arid and mediterranean type climate with precipitations concentrated during the austral winter a long dry season and peak temperatures over 30 c the southern part 38 s is dominated by a temperate climatic regime with higher precipitation values toward the andean range in the last five decades central and southern chile has had a highly dynamic land use and land cover change with different temporal and geographic variability and patterns miranda et al 2017 in central 33 34 s and southern 40 42 s chile the conversion of native forest to shrublands has been the main pattern with 45 being changed thus far from el maule 35 s to los ríos regions 40 s the expansion of dense exotic forest plantations has been for pulp and paper production creating a highly homogeneous and flammable landscape mcwethy et al 2018 2 2 1 wildfire data we used a temporal subset of the public database of wildfires provided by the chilean forest service that includes the ignition point coordinates for each fire from 0 01 ha of the burned area since 1985 this database considers all type of fires with a 99 7 human caused fires occurrence conaf 1 1 www conaf cl conaf seccion stadisticas historicas html the temporal wildfire subset includes all fires from january 2013 to december 2015 we used this temporal window because the country s most accurate land cover map was developed in 2014 zhao et al 2016 this subset includes 19 413 ignition points with a total burned area of 245 815 ha from these fires 70 were less than 1 ha 23 from 1 to 10 ha 6 from 10 to 200 ha and only 1 over 200 ha among those fires we select fires located within a distance of less than 2 km around each city accounting for 5 of the national territory but concentrating more than 50 of fire ignitions the selected fires represent less than 20 of total national burned area miranda et al 2020 the selected ignition points are associated with fires within this perimeter buffer zone to minimize landscape changes for the study period due to burned areas by wildfires 2 2 2 land cover data we used landsat 8 oli derived land cover with a spatial resolution of 30 m from zhao et al 2016 these land cover data are in a raster grid that includes ten classes croplands native forest forest plantation grasslands meadows shrublands bushes wetlands water bodies and other land covers including impervious surfaces barren land bare floor and snow ice the native forest includes primary and secondary forests of mediterranean and temperate types forest plantation is an industrial tree plantation with a commercial purpose with exotic species of pinus and eucalyptus in this study area the impervious surface is represented mainly by urban and industrial infrastructure the landscapes are mainly composed of shrublands bushes 29 croplands 23 grasslands meadows 21 native forests 10 forest plantations 8 and impervious surfaces 6 2 2 3 wildfire and land cover data integration the association of the wildfire data with land cover raster data was carried out in gee within the buffer of 2 km around each city we extracted 20 000 randomly selected square areas images of 1 km2 fig 1 b we eliminate those square areas with a low proportion of fire prone classes deleting those with more than 30 of their pixels within wetlands water bodies barren land and snow or ice land covers for each square area we count the total number of fires observed within the 2013 2015 period labeling them as fire positive 1 if at least one fire was experienced or negative 0 otherwise observations fig 1 c in addition metadata e g fire duration size and perimeter are registered and associated with each area for reference and posterior evaluation interpretation of the results not being used as inputs of the model 2 3 dl framework dl methods are a part of machine learning techniques a subset of the methods used in artificial intelligence ai dl provides a set of techniques whose mechanism is inspired by the structure of neural networks in the human brain lecun et al 2015 and is mathematically modeled with multiple layers of neurons each layer builds new variables from the previous features which are especially useful when analyzing unstructured data such as audio or image signals the ability of dl to develop models at different levels of abstraction has allowed the construction of complex systems such as automatic voice recognition or object identification in images with a performance similar to that achieved by animals and humans lecun et al 2015 dft is a framework and open source software that specializes in understanding and analyzing the role of landscape topology in fire ignition by applying state of the art dl techniques using a supervised learning approach where land images are classified as fire positive or negative our model predicts future wildfire ignition risk within a region of interest by exploiting the topological information of land cover with a significant focus on the interpretability of results which is one of the biggest challenges in the ai field castelvecchi 2016 the framework generates crucial outputs to understand the risk assessment process answering the why question and providing the logic behind the results together the analysis and interpretation of these outputs allow the users to investigate i the propensity of spatial configurations patterns to wildfire ignition ii the creation of novel risk indexes based on topological characteristics for landscape management and iii the support and development of new urban policies by default classification models are trained by randomly splitting the datasets into training and validation sets representing 75 and 25 of the images respectively this is naturally extended to custom models including metadata as features by keeping track of the image and their associated vector of numerical variables 2 3 1 convolutional neural network convolutional neural network cnn models have become the state of the art dl models in computer vision for image analysis since their introduction in lecun et al 1989 and are used by researchers in many fields with remarkable success liu et al 2017 cnn based models exploit and extract implicit information from complex spatial patterns given their contextual based exploration by applying a series of filters within spatial windows a cnn can discover crucial features by capturing multiple levels of representations from spatial data that cannot be easily detected by alternative models moreover cnn models are insensitive to changes in orientation making them particularly robust for analyzing and extracting topological features from raster data zhang et al 2018 understood as the spatial structure and interaction between several components of an image e g the position and proportion of different pixels we implemented a computer vision algorithm based on a cnn model for assessing the future risk of wildfire given the land cover raster of a region the proposed cnn was designed and optimized to improve the prediction accuracy and performance validation metrics of the model while maintaining a reasonable size and an end to end training time fig 2 it is composed of a total of 6 convolutional layers 6 batch normalization layers 3 pooling layers 3 dropout layers and 2 dense layers like the popular visual geometry group vggnet architecture simonyan and zisserman 2014 our net stacks multiple 6 3 3 filters with a stride of 1 pixel per dimension to extract topological features on top of each other before performing max pooling operations a total of 32 64 64 128 128 and 128 kernels with uniform kernel sizes of 3 3 are used in each convolutional layer respectively depthwise separable convolutions chollet 2017 are used instead of standard convolution layers to decrease the model complexity without significantly sacrificing its performance these layers are more efficient because they require less memory and computation given that the number of estimated parameters is reduced by several orders of magnitude if used effectively the performance is not significantly impacted which allows for the easy training and deployment of the model with reasonable computational resources we applied a zero padding approach to keep the consistency of the dimensions through the network each convolutional layer is followed by a rectified linear unit relu activation function moreover we include batch normalization layers ioffe and szegedy 2015 after each activation layer to improve the convergence of the model we group the convolutional activation and batch normalization layers into three main blocks by stacking 1 the unique layer of 32 kernels 2 the two layers of 64 kernels and 3 the three layers of 128 kernels each block is then followed by 2 2 pooling layers performing a max pooling operation with a stride of 2 pixels then dropout zaremba et al 2014 layers with a probability of 25 of disconnecting neurons are included after each convolutional block i e after the pooling layer to avoid over fitting of the model then two dense layers are connected to process the image embedding before the final activation layer the first one has 256 neurons followed by a relu activation batch normalization and dropout layers and the last one is composed of 2 neurons finally a softmax activation function is used at the end of the network normalizing the outputs to obtain p i the predicted probability of ignition and its complement higher values of p i indicate a higher wildfire ignition risk in the area following the previous structure the network is characterized by a total of 447 019 trainable parameters weights updated according to the loss function value by using the adam optimizer kingma and ba 2014 during the backpropagation algorithm we performed an exhaustive grid search of the most relevant hyper parameters of the model learning rate batch size and the number of layers to maximize its performance in our study area we provide the user with a compact and easy to train but powerful classification model that can be naturally extended to multiple applications 2 3 2 imbalanced data the problem of learning from imbalanced data where certain classes such as fire observations are underrepresented in the dataset has attracted the attention of both academia and industry he and garcia 2009 this is also true with cnns where this phenomenon has a significant impact on the model performance huang et al 2016 to address this issue our framework includes state of the art sampling methods proposed in the literature e g synthetic minority oversampling technique smote chawla et al 2002 and custom weights on the loss function of the model to penalize certain classification errors in this study we apply the smote where new synthetic observations mimicking the distribution of the original ones from the minority class are generated increasing the proportion of these observations in practice synthetic examples are generated by randomly selecting an observation from the minority class select its k generally 5 nearest neighbors based on a distance metric e g euclidean and create a new observation by randomly selecting an observation in the feature space of one of these neighbors and the initial observation moreover we exploit the data augmentation capabilities of our dl framework we improve the model performance by generating variations of the original images provided to the classification model applying a series of transformations within the context of our study including rotation horizontal vertical flips or shifts we expand the training samples to obtain a more general and robust model from the original 19 413 images we exclude those landscapes covered by more than 30 of water or unknown land cover types the final dataset comprises 17 579 images with the initial ratio of positive to negative cases being 1 4 we use the smote to account for imbalanced data in the training set 75 of the full dataset consisting of 13 185 images with 10 521 non fire and 2 664 fire positive observations respectively using this procedure on the training data we obtained a balanced set of 10 567 burned from the original 2 664 images and 10 521 non burned the original negative observations sample landscapes 2 3 3 understanding the results a critical aspect of ai models is their interpretability castelvecchi 2016 despite the development of algorithms with remarkable performance researchers and practitioners often fail to understand the logic behind the outputs instead they use them as an efficient black box this approach leads to several limitations such as erroneous conclusions unfair discriminative results and overfitted or shortsighted models focused on specific or non relevant characteristics of the samples among others dl models are not an exception some authors have focused their attention on understanding and visualizing the outputs from different layers of the model to identify relevant patterns tan et al 2015 zhang and zhu 2018 to address this challenge in our framework we implemented three of the most effective visualization techniques to understand the outputs from cnn networks these techniques are i gradient weighted class activation gradcam that exploits the gradients of the final layers of the network to generate attention maps highlighting the portions of the images where the network focuses for the prediction selvaraju et al 2017 ii guided backpropagation shrikumar et al 2017 a technique focused on the pixel space gradient visualizations and iii guided gradcam combining the previous two ideas the analysis of these outputs provides insights into the information that the model focuses on to predict the most likely class of a sample that is the topological configurations that are associated with fires or non fires the role of discontinuities within the landscape and the proportion of different land covers among others to exploit and study the outputs generated from these visualization techniques we implement a zonal statistic analysis procedure attention maps can be understood as heatmaps where darker areas represent those sections of the image with a stronger impact on the model s predictions conversely lighter areas indicate that the patterns observed in those sections are not strongly affecting the outcome of the predictive model in an extreme case some sections of the image could not provide any relevant information e g null data to the model completely ignoring them during the predictive phase therefore we can use these heatmaps to filter the original image at different density levels capturing and analyzing the specific topological patterns affecting the results of the model we filter images at four α density levels 0 30 50 and 70 meaning that we filter out all pixels with heatmap values below α once an image is filtered we compute zonal statistics including the proportion fragmentation and local landscape metrics within the attention maps hotspots thus we can quantitatively compare the components of the landscape at different attention levels focusing on relevant areas for the prediction while improving the interpretability of the results specifically we calculated for each filtered image the landscape composition defined as the proportion of the landscape occupied by each land cover number of components the number of homogeneous patches in the area the mean area of the individual patches mn and the simpson s diversity index to quantify the proportionality of the distribution of land occupation among the different class types within an area mcgarigal 1995 the analysis is implemented as a series of automatic scripts that can be used as part of our framework or as an independent custom post processing tool allowing the planner to define custom α thresholds to perform the analysis to understand and interpret the results of the model we ordered the observations by their predicted probability of ignition p i splitting them into three classes high risk p i 0 7 medium risk 0 3 p i 0 7 and low risk p i 0 3 the rationale behind these thresholds is two fold first they provide natural breaks in our results as major differences in spatial distribution and composition of land cover types are observed between the images associated with those p i values see section 3 second they allow us to simplify the exposition of our results and their discussion as we compare them with previous studies using similar categories 2 3 4 evaluating the model we evaluate the model performance by calculating conventional metrics on the validation set including accuracy correctly classified observations precision true positive over total positive predictions specificity proportion of negative cases correctly identified and sensitivity recall proportion of positive cases correctly identified as well as by analyzing the confusion matrix receiver operating characteristics roc area under the curve auc and total training time owing to the aim of our study where type ii classification errors false negatives should be avoided models with high recall and roc auc are prioritized over high accuracy models to this end we provide custom loss functions to optimize the performance of the model in specific directions in addition we evaluate the generalization performance of the model in a completely independent datasets named testing sets 1 and 2 they are composed of 4 663 and 7 713 images respectively not included in the training and validation sets with a proportion of positive to negative cases equal to 1 5 2 4 computational implementation the framework is implemented in python using numpy keras and tensorflow libraries for the training and prediction of the cnn model the performance metric functions are obtained from the scikit learn package the imblearn package provides specialized algorithms for dealing with imbalanced data image and raster manipulations are performed using opencv and rasterio packages cloud data gathering and processing are performed using the gee api our current implementation can be found at https github com cpaismz89 deepfiretopology where we provide a step by step tutorial examples pre trained models and the case study dataset all scripts can be used directly regardless of the os it should be noted that each component of the framework can be used independently thereby allowing the users to construct their dataset train a custom model from scratch and predict their dataset using pre trained models we ran all experiments on an intel core i7 3 4 ghz machine with 16 gb ram rtx 2080 8 gb nvidia gpu and windows 10 os twenty minutes of training time were required for the entire dataset 17 579 images using optimal hyper parameters on average all outputs generated at the prediction module required a total of 12 s per image pre trained models including weights are significantly compact approximately 7 megabytes because of the proposed cnn structure 3 results and discussion 3 1 classification dft predicted the correct fire class of each landscape with an accuracy of 91 85 in the validation set after 50 training epochs auc 0 98 specificity 0 91 sensitivity 0 96 a similar performance was obtained when deploying the trained model over the entire dataset auc 0 98 specificity 0 95 sensitivity 0 95 and accuracy 92 4 and the independent testing sets 1 auc 0 89 specificity 0 91 sensitivity 0 81 and accuracy 89 4 2 auc 0 95 specificity 0 90 sensitivity 0 99 and accuracy 91 78 following the analysis on the validation set false negative 186 cases and false positive 1 150 cases misclassification errors only represented 5 57 and 8 9 of their classes respectively these results agree with our goal of achieving a high sensitivity if false positive errors are not as harmful as false negative cases to prepare a mitigation strategy against the ignition risk of a landscape as expected the inclusion of smote and data augmentation techniques section 2 3 2 had a strong impact on the model performance significantly boosting the original results accuracy 82 7 sensitivity 0 65 and auc 0 61 and improving the convergence of the algorithm from 200 to 50 epochs a similar performance was obtained when training the model using single channel grayscale or rgb images not significantly affecting the training times or optimal hyper parameters although training times were increased no significant impact on the performance metrics was observed when training the model with larger image sizes e g 64 64 pixels analyzing the performance of the model across the three categories defined by the ignition probability p i section 2 3 3 we observe similar performance metrics from the results summarized in the top right panel of fig 3 we note that all performance metrics of the model tend to be stable across these groups obtaining the best overall performance with the high risk group accuracy 100 followed by the medium risk accuracy 93 and low risk accuracy 91 categories we observe similar values for the precision 98 89 and 88 respectively and almost identical performance when comparing the auc per group 97 100 and 100 respectively from these numbers we note how the model can successfully learn and identify relevant spatial patterns from land cover images to explain why a specific area represented as an array of pixels is more less likely to suffer a fire ignition with only land cover data dft reaches higher accuracy than other fire ignition risk models incorporating human activity topography or climatic data miranda et al 2020 achieved an 89 3 global accuracy using a bagged decision tree method with the same binomial response variable altamirano et al 2013 reached only a 65 accuracy fitting a logistic regression model this ability of dft to accurately predict risky landscapes represents a unique opportunity to understand the combination of the landscape attributes that increase the risk of fire ignition in terms of its composition spatial structure and interaction between different land covers it also reveals that fires occur in very identifiable conditions in the area of study reflected in dft reaching high prediction accuracy given this performance the main challenge is to unravel those patterns to provide relevant insights for both practitioners and researchers 3 2 opening the black box in this section we focus our efforts on understanding the outputs of the model and the rationale behind them for this we try to answer some of the following questions why an image is classified as a fire positive negative sample which land covers proportions distributions are translated into higher lower p i values how are these differences being captured by some of the existing landscape metrics what does the model observe when classifying an image and how is the end to end evolution of the inputs during the inference process focusing our attention on the outputs of the model we can provide an initial assessment and identify the main characteristics of the images in each group fig 3 top left panel for interpretation purposes we complement this evaluation using metadata associated with each image including variables such as population and road densities based on the results dft classifies the fire positive and negative observations accurately moreover it shows a consistent performance when assigning the observations to the auxiliary risk categories defined as a function of p i section 2 3 3 leading to accurate predictions within these categories this is reflected in distinctive and characteristic proportions and spatial structures of land covers for each group aligned with previous studies from different regions of the world viedma et al 2006 lloret et al 2002 moreira et al 2011 steel et al 2018 and also in chile altamirano et al 2013 mcwethy et al 2018 miranda et al 2020 the effect of different land cover types on fire risk in chile has been evaluated in previous studies mcwethy et al 2018 gómez gonzález et al 2019 miranda et al 2020 sarricolea et al 2020 however the interaction between land covers continuity and heterogeneity of the landscape concerning fire risk assessment is empirically evaluated for the first time using dl and the proposed topological interpretation framework observing the results figs 3 5 we analyzed different landscape structures and compositions to understand why each image is classified as high medium or low risk images with high risk p i values are mainly composed of areas covered by a significant percentage of urban land covers and forest plantations or high roads density in rural areas they are also less diverse i e fewer land cover types per sample than other categories expressed in lower simpson s index values table 1 samples belonging to the medium risk interval present an even proportion of the most common land covers in the study area and low population density on the other hand observations with low p i values are characterized by the presence of crops and the absence of human settlements and proportionally fewer forest plantations more than 99 of wildfires in chile are human caused fires gonzález et al 2018 therefore fire frequency is closely related to zones with a human footprint such as cities or other highly human populated areas and roads and agricultural or forest plantation industry mcwethy et al 2018 gómez gonzález et al 2019 considering this evidence our model classified high risk landscapes as those with land cover dominated by industrial activities such as forest plantation or agricultural activities and with a high population density represented by urban areas and high road density conversely low risk landscapes are those with a homogeneous land cover but mainly covered by native forests and represented by a low human population density the model trained in dft with the complete dataset coincided with these criteria this result is significant as it indicates that the model assigns higher or lower p i values to those landscapes that are known considering the historical evidence to be more fire prone based on their ecological environmental social or economic aspect by only capturing land cover spatial patterns as an example we observe how the forest plantation cover increases from 6 2 low risk to 12 9 in high risk landscapes in agreement with the findings in mcwethy et al 2018 and miranda et al 2020 however these landscapes have a relatively stable proportion of the other land cover types the detailed distribution of land covers and their proportion within each category are shown in fig 3 bottom right panel although we found some differences in land cover composition those differences are low for the majority of the land covers less than 5 on average with the main difference being in the crops and forest plantation covers between high and low risk areas with 15 9 and 12 9 versus 26 5 and 6 2 respectively this suggests that spatial patterns or the arrangement and interaction of land covers within the landscape could be crucial knowledge for land planning another differentiating pattern is the average number of patches fig 5 in the risk categories following an increasing trend from 88 low risk to 118 high risk components the number of patches is not only a proxy of landscape fragmentation but also of landscape heterogeneity this result shows that continuous and homogeneous landscape decrease the ignition risk in contrast to e g spread risk if our response variable were the burned area or fire size the continuity of land cover could increase fire propagation associated with larger wildfires therefore the interpretation must be cautious gustafson 2019 because certain patterns may be caused by different landscape processes depending on the predominant land cover types climate or anthropogenic influence in wildfire regime thus practitioners should have prior knowledge of the landscape processes and dynamics for a correct interpretation of the models based on machine learning algorithms portelli 2020portelli 2020 as in the analysis of the full image insights obtained from the attention maps are consistent with the reality of the area of study where human caused fires represent more than 99 of fire ignitions gonzález et al 2018 moreover this reduced wildland urban interface area less than 2 km from cities produces one half of the total fires miranda et al 2020 mainly associated with the human footprint expressed as human population or road density in combination with productive land covers such as agriculture and forest plantations gómez gonzález et al 2018 2019 on the other hand the lack of these spatial patterns and the significant presence of non flammable land covers such as water bodies or rocky areas next to urban areas are translated into lower ignition probability values similarly attention maps indicate that the model observes areas covered by large sections of homogeneous native forest patches without human presence to further decrease the estimated probability aligned with our initial assessments therefore our analysis for chile shows that a more homogeneous landscape reflected in fewer components and large patch areas are associated with low risk areas for ignitions however important is to note that this conclusion could be land cover or bioclimatic zone dependent as suggested by mcwethy et al 2018 that proposes that the preference of fire varies in a latitudinal gradient but it is consistent with the fact that forest plantation is the preferred land cover for fire in chile for example we can observe the attention maps generated for a high risk landscape characterized by an urban area connected to a road and the presence of flammable grasslands and forest plantations in fig 4 the classified images were filtered using the masks generated from these attention maps at different density levels we then calculated zonal statistics see section 2 3 3 starting with the complete attention map up to the selection of its densest area red hotspots characterizing the most relevant areas for the model during the classification process from the plots we note how both the road and city land cover pixels are highlighted in the majority of the attention maps warmer colors indicating the main components of the image used by the deep learning model to estimate the ignition probability of the area as we increase the filtering threshold we notice how the model ends up focusing its attention on the bottom left section of the image mainly composed of human related land covers and roads interacting with adjacent grasslands and forest plantations the example also shows that the model mainly focuses its attention on the road s insertion area in the city instead of the city or roads independently this could suggest that increased traffic into wildlands from dense human populated areas as represented by this insertion point could indicate a higher ignition risk similar results are observed across the entire dataset despite the previously mentioned differences in general patterns between the risk categories identified by dft the landscape metrics that compare the complete image against the hottest attention map areas also show clear differences between the categories fig 5 table 1 these metrics showed that more fragmented but less diverse landscapes are classified as high risk which is reflected in more components and a lower simpson s index mcgarigal 1995 these differences help improve the identification of the most relevant patterns in a landscape that affect the propensity of fire ignition having the same trend in both the complete image and the hot spots again the results agree with the regions of certain human caused fires with fire ignition mainly associated with a highly fragmented wildland urban interface syphard and keeley 2015 the attention maps also provide a clear assessment of which land cover requires more attention to classify the images in the risk categories at different stages of the net giving us insights into the learning process of the model for this purpose we select ten images at random close to p i 1 high risk ten with p i near 0 5 medium risk and ten close to p i 0 low risk to highlight the differences between landscape attributes across categories in table s1 and fig s1 we show that different layers of the network i e where convolutions and filters are applied pay attention to different land cover types in the original image the dominant land cover for the high risk hr image is forest plantation 47 however for the first layer dft focused on non vegetated areas the areas represented by urban land covers and roads non vegetated dominate the hottest pixels by 38 while the proportion of forest plantations is only a 21 the attention paid by dft in non vegetated areas even increases when filtering the landscape by the 75 hot spot covering 73 of the hottest pixels the middle layer of the model still paid more attention to non vegetated areas but in combination with grassland as it is the second dominant land cover among the hottest pixels 75 threshold deeper in the net last block dft focused on the effect of forest plantations showing patterns similar to some recent findings miranda et al 2020 the combined layers can provide a general overview of the interaction among land covers that boosts the propensity of fire ignition besides users can see where the most critical interactions occur however understanding the individual layer attention maps and their internal patterns opens the black box of ai thereby unraveling different landscape patterns that could provide a deeper understanding of the ecological processes as well as support crucial management decisions in the context of landscape and urban planning policies to illustrate this knowledge discovery process we follow the complete path of one image in our end to end classification model to understand the model functioning and help in interpreting the results fig 6 the outputs obtained at each step of the workflow show the most relevant topological attributes of the landscape for decision making in this case we analyze the same hr landscape of fig 4 and s1 composed of each risky land cover type such as forest plantations human settlements and roads the dft model highlights the different topological attributes of the landscape in the first convolutional layer the results mainly highlight the highways and a combination of roads and highly populated areas represented by urban land covers thereby focusing not only on their presence but also their continuity because isolated pixels or small patches of roads and cities get less attention than large and continuous components in the second convolutional layer the model focuses on forest plantations near a town and roads especially where roads and highly populated areas are adjacent to a forest plantation as we move towards the final layers the attention moves on the presence of continuous patches and their interaction with urban related land covers using this information the model calculates p i in its final layer using a threshold p i 0 5 by default to determine if the sample is labeled as a fire positive or negative observation 3 3 an open challenge landscape metrics measure the structural or functional characteristics of a delimited territory to quantify its spatial patterns and changes through space and time these metrics are widely used in ecology following the assumption that spatial patterns can explain ecological processes and functions in a landscape turner and gardner 1991 this pattern process hypothesis is the basis of several landscape metrics derived mostly from categorical maps that describe the composition and spatial distribution of each land use or land cover uuemaa et al 2013 however the analysis and interpretation of landscape topology have received little attention as a novel metric of landscape patterns and as a crucial indicator to advance informed territorial planning also incorporating land cover dynamic or landscape spatial pattern change as a predictor of fire regime could expand its applications and allows a better understanding of present future drivers and scenarios of land cover and climate change in fire risk viedma et al 2006 ricotta et al 2012 computer vision has become essential in the analysis and extraction of relevant features and patterns from images and multidimensional data advances in this field have achieved remarkable results in multiple scientific studies and applications however interpreting and understanding the performance of models and sometimes surprisingly and counter intuitively learning processes have remained an open and active research challenge sejnowski 2020 in this study we propose a flexible and customizable end to end dl framework integrated with an automatic online data gathering and processing modules to characterize and study the role of land topology in understanding a future wildfire ignition risk by following a supervised learning approach focusing on the interpretability of the results we implement multiple visualizations and statistical techniques to understand the model outcomes in the field of landscape planning aimed at fire protection this novel methodology is a step towards decreasing fire ignition risk avoiding dangerous land covers their spatial patterns and interactions moreover dft could be a valuable resource for the prevention of fires in risky areas as well as support suppression planning strategies e g by allocating relevant resources according to the risk associated with the detected topological patterns of the area this would be reflected in more efficient and effective wildfire suppression strategies in addition to providing supporting insights when developing landscape treatment plans e g fuel treatment prescribed fires or thinning that aim to minimize the impact of future wildfires in general however the proposed methodology could be an essential development in landscape pattern and process interpretation in a broader sense for different ecological disciplines although a step forward in the understanding of the learning mechanism of these methods and improve their outputs interpretability more efforts are required in this direction to continue opening the artificial intelligence black box to exploit the full potential of these powerful models 3 4 framework advantages and limitations the main advantages of our framework in addition to its performance are its scalability flexibility of customization and interpretability the seamless interaction with cutting edge planetary scale data cloud services allows the framework to easily scale complex and challenging global studies enabling users to train and test state of the art models without regional limitations with thousands of high quality datasets being available in gee and the option of providing in house data the possibilities are limitless integrating our method with effective rebalancing methods combined with a light cnn model that can be trained saved and deployed in daily use hardware provides our project with useful tools for various applications although our example consists of a binary classification problem the framework supports both classification binary or multi class and regression models in this regard custom models with different research objectives can be tested e g classify the landscapes into multiple predefined classes based on the type of ignition or even by the expected area burned after an ignition while taking advantage of the framework s pipeline moreover pre trained models provided with its code can be adjusted with new training samples by adjusting the weights of the layers depending on the characteristics and similarities of the dataset and the one used during training this method can provide high quality results while reducing the training time in addition the features generated by the implemented models can be extracted as numerical variables to analyze and use them in alternative formulations such as feeding a classification model e g random forest or support vector machine and train it with an enriched dataset in a form of transfer learning approach implementations of baseline ml models such as random forests and logistic regression ready to exploit these inputs are provided in the project s repository as open source code illustrating how our framework can interact with alternative models and methodologies the generalization of the model to different realities e g where the human factor is not as critical in fire ignitions as in our case study is an open research question that we expect to cover in future studies potentially incorporating extra layers of information into our framework previous studies such as zhang et al 2019 have effectively used a cnn model to study the fire susceptibility of china s yunnan province by combining a variety of features e g temperature topography with different resolutions into a unique multi layer picture however this study is not oriented to understand and interpret the outputs and logic behind the proposed cnn model because of its structure but focused on maximizing the performance of the model by including a wide range of attributes to accurately estimate wildfire susceptibility in contrast we focus our study on what we call learning to understand the model we provide the possibility of observing what the model sees and understand interpret the rationale behind the results supported by techniques that generate relevant visualizations and statistics therefore the clear pipeline flexibility and customization of the proposed framework allow its adaptation to multiple studies where the interpretability of results is critical to assess the performance of the model and support decision making processes such as landscape planning under wildfire risk and the optimal allocation of suppression resources among others the framework is simple to use allowing researchers and practitioners to save significant time and resources 4 conclusions we developed and tested a comprehensive dl framework in the future wildfire ignition risk assessment of landscapes exploiting topological information defined as the spatial distribution and interaction of the data derived from land cover maps dft provides state of the art tools that can be used to collect multidimensional data at a large scale train custom models and understand the results by interpreting the model learning it significantly decreases the training evaluation and model deployment cycle and provides users with limitless and complex research questions with an efficient framework and software the proposed methodology adequately assesses the fire occurrence risk of a given area using only digital information on land cover furthermore it reveals that a cnn architecture can capture drivers from the spatial configuration of landscape showing that topology could be a key to the development of landscapes resistant to wildfire or at least prepare them to minimize consequences due to future wildfires this is translated into a huge potential to provide landscape managers with crucial evaluations and insights during the decision making process the model is able to identify and determine the risk of wildfire ignition in multiple areas by exploiting information about the interaction continuity and frequency of different land covers providing managerial insights for examples see supplementary material given the high interpretability of the results from both statistical and visual perspectives we note that the model may become a valuable resource to effectively guide fire risk mitigation and management plans potentially informing the development of urban policies by taking into account the impact of topological patterns in the design and protection of the land this research can be extended in several important ways first the model can be generalized incorporating a series of relevant layers representing other components of the landscape e g topographic characteristics such as elevation however this incorporation should be performed with caution to avoid obscuring the interpretability of the results measuring the impact of new layers in the predictions the incorporation and quantification of these effects are relevant to a variety of applications in the fire ecology field being an interesting future research direction second the framework could be used to generate novel landscape metrics summarizing the topological information from the image for this the weights of the network and their impact at different layers of the cnn could be analyzed in detail to understand the end to end transformation from inputs into a real valued function describing the area of study third a modified version of the framework could be used to predict other fire behavior phenomena such as the expected rate of spread perimeter average flame length intensity among other options depending on the application the original framework could be complemented with analytical models exploiting state of the art formulations fourth an interesting future direction could be to extend the framework to provide effective landscape management recommendations in the context of wildfire ignition risk given a set of high risk landscapes a generative model e g using generative adversarial networks creswell et al 2018 could be developed to provide ideal modifications in the landscape to reduce the overall risk of the area we plan to expand our initial research in this direction in a near future finally the framework can be applied in similar computer vision studies requiring a high level of interpretability flexibility and customization for this potential modifications to the original cnn could be pertinent e g number or type of layers it could also be combined with other ml models for example the model could be extended to incorporate parallel deep neural networks processing different layers of information being part of an ensemble model including other ml models such as random forests to study complex ecological phenomena among several options the paper has outlined a new dl framework in the context of wildfire ignition risk prediction incorporating analytical and visualization techniques to understand and exploit the results of the complex dl black box it is however only the beginning of future research in this direction declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments a m thanks anid fondap 15110009 and anid postdoctoral fondecyt project 3210101 j c acknowledges the support of the national commission for scientific and technological research conicyt chile through funding from the complex engineering systems institute pia basal afb180003 and acknowledges the support of the agencia nacional de investigación y desarrollo anid chile through funding postdoctoral fondecyt project 3210311 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105122 
25802,increasing wildfire activity globally has become an urgent issue with enormous ecological and social impacts in this work we focus on analyzing and quantifying the influence of landscape topology understood as the spatial structure and interaction of multiple land covers in an area on fire ignition we propose a deep learning framework deep fire topology to estimate and predict wildfire ignition risk we focus on understanding the impact of these topological attributes and the rationale behind the results to provide interpretable knowledge for territorial planning considering wildfire ignition uncertainty we demonstrate the high performance and interpretability of the framework in a case study accurately detecting risky areas by exploiting spatial patterns this work reveals the strong potential of landscape topology in wildfire occurrence prediction and its implications to develop robust landscape management plans we discuss potential extensions and applications of the proposed method available as an open source software keywords deep learning machine learning landscape topology wildfire ignition risk wildfire management territorial planning 1 introduction wildfires are a unique disturbance that can potentially affect every earth system component with notorious effects on large scale biosphere atmosphere interaction increasing greenhouse gas emissions due to wildfires could lead to positive feedback with global warming impacting human well being because of its consequences in climate change economic losses or environmental and biodiversity damage bowman et al 2020 kelly et al 2020 fire regime is changing in the anthropocene because of complex fire human climatic interactions but mainly shaped by increasing human activity in all biomes bowman et al 2011 moritz et al 2014 the future fire regime is uncertain however no evidence supports a decrease in fire activity bowman et al 2020 potential increase in wildfire activity across the globe has become an issue of real urgency with the most apparent impacts being the enormous number of structures and lives lost in places like california brazil australia greece chile and portugal bowman et al 2019 chen and mcaneney 2004 kramer et al 2018 radeloff et al 2018 and its impacts in biodiversity and greenhouse gas emissions andela et al 2019 liu et al 2020 moritz et al 2014 these events reveal the need for new approaches to understand this complex phenomenon and develop preventive plans to mitigate their impact accounting for a warmer future landscape planning could be one of the most effective ways for local adaptation to increased fire activity bowman et al 2020 moreira et al 2020 the wildfire regime depends on and interacts with the spatial and temporal patterns of the landscapes mckenzie et al 2011 landscape attributes quantified by the land cover structure composition heterogeneity spatial distribution and interactions between its components could influence fire activity potentially perturbing multiple processes such as fire ignition frequency spread the energy released and severity in fire prone ecosystems ganteaume and syphard 2018 moreira et al 2010 2011 van wagtendonk 2006 given climate change scenarios human coexistence with wildfires will necessitate informed decision making to minimize fire risk bowman et al 2020 calkin et al 2014 keeley and syphard 2019 moreira et al 2020 moritz et al 2014 moreover historical fire occurrence is an empirical manifestation of the local spatial interaction between fire and fire prone ecosystems therefore understanding these phenomena could help produce an informed fire risk evaluation and evidence based effective territorial planning argañaraz et al 2017 ganteaume and syphard 2018 miranda et al 2020 the analysis of spatial patterns at large scales has evolved with geographic information systems remote sensing and computational science capabilities gustafson 2019 this co evolution allows multidisciplinary thinking to integrates into one framework a large amount of data from different sources and high computational consuming analysis to solve old problems hypotheses with new techniques costanza et al 2019 in this line deep learning dl models have started a revolution in multiple areas with a significant contribution in intensive computer vision tasks such as large scale geographic data processing and inference interest in dl methods has grown recently owing to their remarkable success in various domains specifically this interest is because of technical aspects and their effective application to problems that have not been efficiently addressed the availability of large volumes of training data affordable computing power and the development of new algorithms to automatically adjust crucial parameters of the models bisong 2019 has led to the rebirth of these techniques since their early emergence in the 1980s their successful application in image recognition zhang et al 2017 speech recognition lecun et al 2015 text analytics kadhim 2019 and self driving cars hoang et al 2019 among several others has increased the popularity of these systems dl can be a crucial tool for numerous ecological applications owing to the complexity of ecological data and the ever growing size of ecological datasets christin et al 2019 recently dl techniques have been applied in the field of ecology specifically species identification norouzzadeh et al 2018 animal behavior classification and biodiversity estimation for large datasets such as camera trap images rovero et al 2013 2014 audio recordings and videos sevilla and glotin 2017 are some examples in the wildfire applications context dl models trained for fire detection sousa et al 2020 and wildfire spread prediction hodges and lattimer 2019 are some examples found in the literature jain et al 2020 however to the best of our knowledge only a few studies and applications of dl have been reported for understanding the effect of landscape patterns on fire activity gustafson 2019 being the closest application the one presented in zhang et al 2019 for fire susceptibility mapping landscape metrics such as proximity connectivity adjacency or composition index among others that are typically used in landscape ecology as a measure of structural characterization do not change significantly over time gustafson 2019 these metrics are widely used with the assumption that spatial patterns can explain ecological processes and functions in a landscape however summarizing the spatial patterns with one or a few metrics can leave out much information limiting the understanding of landscape patterns interactions and processes the study of fire occurrence focuses on measuring the chance that a fire might start in a region given a set of conditions factors previous studies have considered risk factors derived from weather danger indices physiography land cover or socioeconomic variables de montis et al 2017 mckenzie et al 2011 which are usually represented by a collection of individual and potentially correlated numerical or categorical variables ganteaume and syphard 2018 the machine learning field has provided useful tools and methods for modeling fire ignition techniques such as classification and regression trees amatulli et al 2006 fuzzy metaheuristic ensembles moayedi et al 2020 support vector machines ghorbanzadeh et al 2019 random forests leuenberger et al 2018 massada et al 2013 oliveira et al 2012 and so forth have been successfully applied as alternatives to traditional statistical methods topological aspects understood as the spatial structure and interaction between several components of the land e g land cover are captured by constructing and extracting selected indexes of landscape structure and composition for example lloret et al 2002 includes patch density mean patch size mean distance to the nearest neighbor of the same category edge density and the shannon diversity index for modeling the burned area in the eastern iberian peninsula similarly the work by ricotta et al 2018 studies the impact of the interaction between roads and land cover on fire ignition by constructing a selectivity index there is sufficient evidence that the spatial configuration of these elements can influence fire regimes especially under no extreme weather condition alencar et al 2015 mckenzie et al 2011 moreira et al 2011 from our point of view this aspect of the landscapes has been challenging to study and difficult to understand due to i the difficulty of explicitly extracting metrics that can capture aspects of the landscape topology generally requiring more computational resources and time and ii the non spatial nature of traditional statistical and machine learning models e g random forest that rely on the inclusion of multiple variables such as those previously mentioned to explain the phenomenon and improve the predictive performance of the model land cover data represent the basic information for landscape analysis at a pixel level of the primary land uses in a geographically delimited territory this two dimensional representation of the landscape also captures an intrinsic relationship between adjacency and connectivity of its components which can be studied to understand landscape phenomena and complex patterns and processes in the context of wildfire effectively capturing extracting and interpreting this topological information can play a fundamental role in future prevention and mitigation strategies sakellariou et al 2020 similarly it could inform the optimal allocation of resources across regions and the development of effective and sustainable risk management policies therefore we observe an opportunity to apply new effective methods techniques such as dl to try to isolate quantify and understand the impact of landscape topology as a predictor of fire ignition motivating the present study moreover given the current open access to huge global datasets on cloud services and the massive computational power that allows fast training cycles of the models the scalability and potential impact of such a model are unbounded in this paper we introduce deep fire topology dft a comprehensive framework available as open source software for landscape topology analysis landscape topology understood as the spatial structure and interaction of multiple land covers in an area of study is extracted by training a dl model while focusing on understanding the rationale behind the results a crucial element to the applicability of the model we present an application on the landscape ecology of wildfire to evaluate the land cover topology as a predictor of the fire occurrence probability we use a convolutional neural network cnn based model without considering additional information such as population density or weather information which are generally used as variables de montis et al 2017 ganteaume and syphard 2018 to isolate and assess the impact of different spatial patterns in fire ignition i e to observe how different spatial configurations of land cover could give us valuable information regarding the susceptibility of future wildfire ignitions in the area dft use a supervised learning approach where land cover images are labeled as fire or no fire representing the presence absence of an ignition in contrast to previous studies focused on generating susceptibility maps where each pixel is associated with an ignition probability we focus on identifying the joint effect of multiple cells to estimate the ignition risk of the whole area under analysis we also open the dl black box by including state of the art visualization and statistical techniques aimed at understanding the results this with the aim of informing and supporting landscape managers to minimize fire risk or improve the effectiveness of suppression strategies by optimizing the allocation of resources in high risk areas and potentially support the development of new landscape managing and protection policies 2 material and methods 2 1 data mining processing and inputs data can be provided to the framework using two main approaches i automatic collection and processing of online assets in google earth engine gee to generate a ready to use dataset and ii local data provided by the user for training prediction the first method is integrated into our framework via scripts and can be used as an independent module for queries in the first approach users can provide a set of ignition and negative sample points in a latitude longitude format starting from our data mining and processing module the landscape data are automatically gathered from gee generating a square buffer of area a km2 a 1 by default centered at the given points if other layers or metadata are required for example temperature or road density users can execute the module independently and include any relevant source available at the gee to be stacked as an extra band of the sampled image finally the data are automatically downloaded to a cloud account or local hard drive although global public datasets are already available in gee users would need to provide and upload their high resolution regional datasets to take complete advantage of our framework alternatively users provide unclassified data consisting of images rgb or grayscale with or without metadata as extra input features of the model all samples are automatically resized and scaled to match the dimensions required by the classification model 32 32 normalized pixels by default and are recorded locally the dataset is subsequently used for training a custom model or processed for prediction by pre trained models parameters such as the training validation proportion or classification labels can be modified 2 2 study area we tested our approach using south central chile as a case study fig 1 a it includes eight administrative regions 212 000 km2 corresponding to 28 of the national territory it covers an area from 32 to 43 8 s 2 750 km which accounts for 98 5 of the national historical fire occurrence gonzález et al 2018 the northern part of our study area has a semi arid and mediterranean type climate with precipitations concentrated during the austral winter a long dry season and peak temperatures over 30 c the southern part 38 s is dominated by a temperate climatic regime with higher precipitation values toward the andean range in the last five decades central and southern chile has had a highly dynamic land use and land cover change with different temporal and geographic variability and patterns miranda et al 2017 in central 33 34 s and southern 40 42 s chile the conversion of native forest to shrublands has been the main pattern with 45 being changed thus far from el maule 35 s to los ríos regions 40 s the expansion of dense exotic forest plantations has been for pulp and paper production creating a highly homogeneous and flammable landscape mcwethy et al 2018 2 2 1 wildfire data we used a temporal subset of the public database of wildfires provided by the chilean forest service that includes the ignition point coordinates for each fire from 0 01 ha of the burned area since 1985 this database considers all type of fires with a 99 7 human caused fires occurrence conaf 1 1 www conaf cl conaf seccion stadisticas historicas html the temporal wildfire subset includes all fires from january 2013 to december 2015 we used this temporal window because the country s most accurate land cover map was developed in 2014 zhao et al 2016 this subset includes 19 413 ignition points with a total burned area of 245 815 ha from these fires 70 were less than 1 ha 23 from 1 to 10 ha 6 from 10 to 200 ha and only 1 over 200 ha among those fires we select fires located within a distance of less than 2 km around each city accounting for 5 of the national territory but concentrating more than 50 of fire ignitions the selected fires represent less than 20 of total national burned area miranda et al 2020 the selected ignition points are associated with fires within this perimeter buffer zone to minimize landscape changes for the study period due to burned areas by wildfires 2 2 2 land cover data we used landsat 8 oli derived land cover with a spatial resolution of 30 m from zhao et al 2016 these land cover data are in a raster grid that includes ten classes croplands native forest forest plantation grasslands meadows shrublands bushes wetlands water bodies and other land covers including impervious surfaces barren land bare floor and snow ice the native forest includes primary and secondary forests of mediterranean and temperate types forest plantation is an industrial tree plantation with a commercial purpose with exotic species of pinus and eucalyptus in this study area the impervious surface is represented mainly by urban and industrial infrastructure the landscapes are mainly composed of shrublands bushes 29 croplands 23 grasslands meadows 21 native forests 10 forest plantations 8 and impervious surfaces 6 2 2 3 wildfire and land cover data integration the association of the wildfire data with land cover raster data was carried out in gee within the buffer of 2 km around each city we extracted 20 000 randomly selected square areas images of 1 km2 fig 1 b we eliminate those square areas with a low proportion of fire prone classes deleting those with more than 30 of their pixels within wetlands water bodies barren land and snow or ice land covers for each square area we count the total number of fires observed within the 2013 2015 period labeling them as fire positive 1 if at least one fire was experienced or negative 0 otherwise observations fig 1 c in addition metadata e g fire duration size and perimeter are registered and associated with each area for reference and posterior evaluation interpretation of the results not being used as inputs of the model 2 3 dl framework dl methods are a part of machine learning techniques a subset of the methods used in artificial intelligence ai dl provides a set of techniques whose mechanism is inspired by the structure of neural networks in the human brain lecun et al 2015 and is mathematically modeled with multiple layers of neurons each layer builds new variables from the previous features which are especially useful when analyzing unstructured data such as audio or image signals the ability of dl to develop models at different levels of abstraction has allowed the construction of complex systems such as automatic voice recognition or object identification in images with a performance similar to that achieved by animals and humans lecun et al 2015 dft is a framework and open source software that specializes in understanding and analyzing the role of landscape topology in fire ignition by applying state of the art dl techniques using a supervised learning approach where land images are classified as fire positive or negative our model predicts future wildfire ignition risk within a region of interest by exploiting the topological information of land cover with a significant focus on the interpretability of results which is one of the biggest challenges in the ai field castelvecchi 2016 the framework generates crucial outputs to understand the risk assessment process answering the why question and providing the logic behind the results together the analysis and interpretation of these outputs allow the users to investigate i the propensity of spatial configurations patterns to wildfire ignition ii the creation of novel risk indexes based on topological characteristics for landscape management and iii the support and development of new urban policies by default classification models are trained by randomly splitting the datasets into training and validation sets representing 75 and 25 of the images respectively this is naturally extended to custom models including metadata as features by keeping track of the image and their associated vector of numerical variables 2 3 1 convolutional neural network convolutional neural network cnn models have become the state of the art dl models in computer vision for image analysis since their introduction in lecun et al 1989 and are used by researchers in many fields with remarkable success liu et al 2017 cnn based models exploit and extract implicit information from complex spatial patterns given their contextual based exploration by applying a series of filters within spatial windows a cnn can discover crucial features by capturing multiple levels of representations from spatial data that cannot be easily detected by alternative models moreover cnn models are insensitive to changes in orientation making them particularly robust for analyzing and extracting topological features from raster data zhang et al 2018 understood as the spatial structure and interaction between several components of an image e g the position and proportion of different pixels we implemented a computer vision algorithm based on a cnn model for assessing the future risk of wildfire given the land cover raster of a region the proposed cnn was designed and optimized to improve the prediction accuracy and performance validation metrics of the model while maintaining a reasonable size and an end to end training time fig 2 it is composed of a total of 6 convolutional layers 6 batch normalization layers 3 pooling layers 3 dropout layers and 2 dense layers like the popular visual geometry group vggnet architecture simonyan and zisserman 2014 our net stacks multiple 6 3 3 filters with a stride of 1 pixel per dimension to extract topological features on top of each other before performing max pooling operations a total of 32 64 64 128 128 and 128 kernels with uniform kernel sizes of 3 3 are used in each convolutional layer respectively depthwise separable convolutions chollet 2017 are used instead of standard convolution layers to decrease the model complexity without significantly sacrificing its performance these layers are more efficient because they require less memory and computation given that the number of estimated parameters is reduced by several orders of magnitude if used effectively the performance is not significantly impacted which allows for the easy training and deployment of the model with reasonable computational resources we applied a zero padding approach to keep the consistency of the dimensions through the network each convolutional layer is followed by a rectified linear unit relu activation function moreover we include batch normalization layers ioffe and szegedy 2015 after each activation layer to improve the convergence of the model we group the convolutional activation and batch normalization layers into three main blocks by stacking 1 the unique layer of 32 kernels 2 the two layers of 64 kernels and 3 the three layers of 128 kernels each block is then followed by 2 2 pooling layers performing a max pooling operation with a stride of 2 pixels then dropout zaremba et al 2014 layers with a probability of 25 of disconnecting neurons are included after each convolutional block i e after the pooling layer to avoid over fitting of the model then two dense layers are connected to process the image embedding before the final activation layer the first one has 256 neurons followed by a relu activation batch normalization and dropout layers and the last one is composed of 2 neurons finally a softmax activation function is used at the end of the network normalizing the outputs to obtain p i the predicted probability of ignition and its complement higher values of p i indicate a higher wildfire ignition risk in the area following the previous structure the network is characterized by a total of 447 019 trainable parameters weights updated according to the loss function value by using the adam optimizer kingma and ba 2014 during the backpropagation algorithm we performed an exhaustive grid search of the most relevant hyper parameters of the model learning rate batch size and the number of layers to maximize its performance in our study area we provide the user with a compact and easy to train but powerful classification model that can be naturally extended to multiple applications 2 3 2 imbalanced data the problem of learning from imbalanced data where certain classes such as fire observations are underrepresented in the dataset has attracted the attention of both academia and industry he and garcia 2009 this is also true with cnns where this phenomenon has a significant impact on the model performance huang et al 2016 to address this issue our framework includes state of the art sampling methods proposed in the literature e g synthetic minority oversampling technique smote chawla et al 2002 and custom weights on the loss function of the model to penalize certain classification errors in this study we apply the smote where new synthetic observations mimicking the distribution of the original ones from the minority class are generated increasing the proportion of these observations in practice synthetic examples are generated by randomly selecting an observation from the minority class select its k generally 5 nearest neighbors based on a distance metric e g euclidean and create a new observation by randomly selecting an observation in the feature space of one of these neighbors and the initial observation moreover we exploit the data augmentation capabilities of our dl framework we improve the model performance by generating variations of the original images provided to the classification model applying a series of transformations within the context of our study including rotation horizontal vertical flips or shifts we expand the training samples to obtain a more general and robust model from the original 19 413 images we exclude those landscapes covered by more than 30 of water or unknown land cover types the final dataset comprises 17 579 images with the initial ratio of positive to negative cases being 1 4 we use the smote to account for imbalanced data in the training set 75 of the full dataset consisting of 13 185 images with 10 521 non fire and 2 664 fire positive observations respectively using this procedure on the training data we obtained a balanced set of 10 567 burned from the original 2 664 images and 10 521 non burned the original negative observations sample landscapes 2 3 3 understanding the results a critical aspect of ai models is their interpretability castelvecchi 2016 despite the development of algorithms with remarkable performance researchers and practitioners often fail to understand the logic behind the outputs instead they use them as an efficient black box this approach leads to several limitations such as erroneous conclusions unfair discriminative results and overfitted or shortsighted models focused on specific or non relevant characteristics of the samples among others dl models are not an exception some authors have focused their attention on understanding and visualizing the outputs from different layers of the model to identify relevant patterns tan et al 2015 zhang and zhu 2018 to address this challenge in our framework we implemented three of the most effective visualization techniques to understand the outputs from cnn networks these techniques are i gradient weighted class activation gradcam that exploits the gradients of the final layers of the network to generate attention maps highlighting the portions of the images where the network focuses for the prediction selvaraju et al 2017 ii guided backpropagation shrikumar et al 2017 a technique focused on the pixel space gradient visualizations and iii guided gradcam combining the previous two ideas the analysis of these outputs provides insights into the information that the model focuses on to predict the most likely class of a sample that is the topological configurations that are associated with fires or non fires the role of discontinuities within the landscape and the proportion of different land covers among others to exploit and study the outputs generated from these visualization techniques we implement a zonal statistic analysis procedure attention maps can be understood as heatmaps where darker areas represent those sections of the image with a stronger impact on the model s predictions conversely lighter areas indicate that the patterns observed in those sections are not strongly affecting the outcome of the predictive model in an extreme case some sections of the image could not provide any relevant information e g null data to the model completely ignoring them during the predictive phase therefore we can use these heatmaps to filter the original image at different density levels capturing and analyzing the specific topological patterns affecting the results of the model we filter images at four α density levels 0 30 50 and 70 meaning that we filter out all pixels with heatmap values below α once an image is filtered we compute zonal statistics including the proportion fragmentation and local landscape metrics within the attention maps hotspots thus we can quantitatively compare the components of the landscape at different attention levels focusing on relevant areas for the prediction while improving the interpretability of the results specifically we calculated for each filtered image the landscape composition defined as the proportion of the landscape occupied by each land cover number of components the number of homogeneous patches in the area the mean area of the individual patches mn and the simpson s diversity index to quantify the proportionality of the distribution of land occupation among the different class types within an area mcgarigal 1995 the analysis is implemented as a series of automatic scripts that can be used as part of our framework or as an independent custom post processing tool allowing the planner to define custom α thresholds to perform the analysis to understand and interpret the results of the model we ordered the observations by their predicted probability of ignition p i splitting them into three classes high risk p i 0 7 medium risk 0 3 p i 0 7 and low risk p i 0 3 the rationale behind these thresholds is two fold first they provide natural breaks in our results as major differences in spatial distribution and composition of land cover types are observed between the images associated with those p i values see section 3 second they allow us to simplify the exposition of our results and their discussion as we compare them with previous studies using similar categories 2 3 4 evaluating the model we evaluate the model performance by calculating conventional metrics on the validation set including accuracy correctly classified observations precision true positive over total positive predictions specificity proportion of negative cases correctly identified and sensitivity recall proportion of positive cases correctly identified as well as by analyzing the confusion matrix receiver operating characteristics roc area under the curve auc and total training time owing to the aim of our study where type ii classification errors false negatives should be avoided models with high recall and roc auc are prioritized over high accuracy models to this end we provide custom loss functions to optimize the performance of the model in specific directions in addition we evaluate the generalization performance of the model in a completely independent datasets named testing sets 1 and 2 they are composed of 4 663 and 7 713 images respectively not included in the training and validation sets with a proportion of positive to negative cases equal to 1 5 2 4 computational implementation the framework is implemented in python using numpy keras and tensorflow libraries for the training and prediction of the cnn model the performance metric functions are obtained from the scikit learn package the imblearn package provides specialized algorithms for dealing with imbalanced data image and raster manipulations are performed using opencv and rasterio packages cloud data gathering and processing are performed using the gee api our current implementation can be found at https github com cpaismz89 deepfiretopology where we provide a step by step tutorial examples pre trained models and the case study dataset all scripts can be used directly regardless of the os it should be noted that each component of the framework can be used independently thereby allowing the users to construct their dataset train a custom model from scratch and predict their dataset using pre trained models we ran all experiments on an intel core i7 3 4 ghz machine with 16 gb ram rtx 2080 8 gb nvidia gpu and windows 10 os twenty minutes of training time were required for the entire dataset 17 579 images using optimal hyper parameters on average all outputs generated at the prediction module required a total of 12 s per image pre trained models including weights are significantly compact approximately 7 megabytes because of the proposed cnn structure 3 results and discussion 3 1 classification dft predicted the correct fire class of each landscape with an accuracy of 91 85 in the validation set after 50 training epochs auc 0 98 specificity 0 91 sensitivity 0 96 a similar performance was obtained when deploying the trained model over the entire dataset auc 0 98 specificity 0 95 sensitivity 0 95 and accuracy 92 4 and the independent testing sets 1 auc 0 89 specificity 0 91 sensitivity 0 81 and accuracy 89 4 2 auc 0 95 specificity 0 90 sensitivity 0 99 and accuracy 91 78 following the analysis on the validation set false negative 186 cases and false positive 1 150 cases misclassification errors only represented 5 57 and 8 9 of their classes respectively these results agree with our goal of achieving a high sensitivity if false positive errors are not as harmful as false negative cases to prepare a mitigation strategy against the ignition risk of a landscape as expected the inclusion of smote and data augmentation techniques section 2 3 2 had a strong impact on the model performance significantly boosting the original results accuracy 82 7 sensitivity 0 65 and auc 0 61 and improving the convergence of the algorithm from 200 to 50 epochs a similar performance was obtained when training the model using single channel grayscale or rgb images not significantly affecting the training times or optimal hyper parameters although training times were increased no significant impact on the performance metrics was observed when training the model with larger image sizes e g 64 64 pixels analyzing the performance of the model across the three categories defined by the ignition probability p i section 2 3 3 we observe similar performance metrics from the results summarized in the top right panel of fig 3 we note that all performance metrics of the model tend to be stable across these groups obtaining the best overall performance with the high risk group accuracy 100 followed by the medium risk accuracy 93 and low risk accuracy 91 categories we observe similar values for the precision 98 89 and 88 respectively and almost identical performance when comparing the auc per group 97 100 and 100 respectively from these numbers we note how the model can successfully learn and identify relevant spatial patterns from land cover images to explain why a specific area represented as an array of pixels is more less likely to suffer a fire ignition with only land cover data dft reaches higher accuracy than other fire ignition risk models incorporating human activity topography or climatic data miranda et al 2020 achieved an 89 3 global accuracy using a bagged decision tree method with the same binomial response variable altamirano et al 2013 reached only a 65 accuracy fitting a logistic regression model this ability of dft to accurately predict risky landscapes represents a unique opportunity to understand the combination of the landscape attributes that increase the risk of fire ignition in terms of its composition spatial structure and interaction between different land covers it also reveals that fires occur in very identifiable conditions in the area of study reflected in dft reaching high prediction accuracy given this performance the main challenge is to unravel those patterns to provide relevant insights for both practitioners and researchers 3 2 opening the black box in this section we focus our efforts on understanding the outputs of the model and the rationale behind them for this we try to answer some of the following questions why an image is classified as a fire positive negative sample which land covers proportions distributions are translated into higher lower p i values how are these differences being captured by some of the existing landscape metrics what does the model observe when classifying an image and how is the end to end evolution of the inputs during the inference process focusing our attention on the outputs of the model we can provide an initial assessment and identify the main characteristics of the images in each group fig 3 top left panel for interpretation purposes we complement this evaluation using metadata associated with each image including variables such as population and road densities based on the results dft classifies the fire positive and negative observations accurately moreover it shows a consistent performance when assigning the observations to the auxiliary risk categories defined as a function of p i section 2 3 3 leading to accurate predictions within these categories this is reflected in distinctive and characteristic proportions and spatial structures of land covers for each group aligned with previous studies from different regions of the world viedma et al 2006 lloret et al 2002 moreira et al 2011 steel et al 2018 and also in chile altamirano et al 2013 mcwethy et al 2018 miranda et al 2020 the effect of different land cover types on fire risk in chile has been evaluated in previous studies mcwethy et al 2018 gómez gonzález et al 2019 miranda et al 2020 sarricolea et al 2020 however the interaction between land covers continuity and heterogeneity of the landscape concerning fire risk assessment is empirically evaluated for the first time using dl and the proposed topological interpretation framework observing the results figs 3 5 we analyzed different landscape structures and compositions to understand why each image is classified as high medium or low risk images with high risk p i values are mainly composed of areas covered by a significant percentage of urban land covers and forest plantations or high roads density in rural areas they are also less diverse i e fewer land cover types per sample than other categories expressed in lower simpson s index values table 1 samples belonging to the medium risk interval present an even proportion of the most common land covers in the study area and low population density on the other hand observations with low p i values are characterized by the presence of crops and the absence of human settlements and proportionally fewer forest plantations more than 99 of wildfires in chile are human caused fires gonzález et al 2018 therefore fire frequency is closely related to zones with a human footprint such as cities or other highly human populated areas and roads and agricultural or forest plantation industry mcwethy et al 2018 gómez gonzález et al 2019 considering this evidence our model classified high risk landscapes as those with land cover dominated by industrial activities such as forest plantation or agricultural activities and with a high population density represented by urban areas and high road density conversely low risk landscapes are those with a homogeneous land cover but mainly covered by native forests and represented by a low human population density the model trained in dft with the complete dataset coincided with these criteria this result is significant as it indicates that the model assigns higher or lower p i values to those landscapes that are known considering the historical evidence to be more fire prone based on their ecological environmental social or economic aspect by only capturing land cover spatial patterns as an example we observe how the forest plantation cover increases from 6 2 low risk to 12 9 in high risk landscapes in agreement with the findings in mcwethy et al 2018 and miranda et al 2020 however these landscapes have a relatively stable proportion of the other land cover types the detailed distribution of land covers and their proportion within each category are shown in fig 3 bottom right panel although we found some differences in land cover composition those differences are low for the majority of the land covers less than 5 on average with the main difference being in the crops and forest plantation covers between high and low risk areas with 15 9 and 12 9 versus 26 5 and 6 2 respectively this suggests that spatial patterns or the arrangement and interaction of land covers within the landscape could be crucial knowledge for land planning another differentiating pattern is the average number of patches fig 5 in the risk categories following an increasing trend from 88 low risk to 118 high risk components the number of patches is not only a proxy of landscape fragmentation but also of landscape heterogeneity this result shows that continuous and homogeneous landscape decrease the ignition risk in contrast to e g spread risk if our response variable were the burned area or fire size the continuity of land cover could increase fire propagation associated with larger wildfires therefore the interpretation must be cautious gustafson 2019 because certain patterns may be caused by different landscape processes depending on the predominant land cover types climate or anthropogenic influence in wildfire regime thus practitioners should have prior knowledge of the landscape processes and dynamics for a correct interpretation of the models based on machine learning algorithms portelli 2020portelli 2020 as in the analysis of the full image insights obtained from the attention maps are consistent with the reality of the area of study where human caused fires represent more than 99 of fire ignitions gonzález et al 2018 moreover this reduced wildland urban interface area less than 2 km from cities produces one half of the total fires miranda et al 2020 mainly associated with the human footprint expressed as human population or road density in combination with productive land covers such as agriculture and forest plantations gómez gonzález et al 2018 2019 on the other hand the lack of these spatial patterns and the significant presence of non flammable land covers such as water bodies or rocky areas next to urban areas are translated into lower ignition probability values similarly attention maps indicate that the model observes areas covered by large sections of homogeneous native forest patches without human presence to further decrease the estimated probability aligned with our initial assessments therefore our analysis for chile shows that a more homogeneous landscape reflected in fewer components and large patch areas are associated with low risk areas for ignitions however important is to note that this conclusion could be land cover or bioclimatic zone dependent as suggested by mcwethy et al 2018 that proposes that the preference of fire varies in a latitudinal gradient but it is consistent with the fact that forest plantation is the preferred land cover for fire in chile for example we can observe the attention maps generated for a high risk landscape characterized by an urban area connected to a road and the presence of flammable grasslands and forest plantations in fig 4 the classified images were filtered using the masks generated from these attention maps at different density levels we then calculated zonal statistics see section 2 3 3 starting with the complete attention map up to the selection of its densest area red hotspots characterizing the most relevant areas for the model during the classification process from the plots we note how both the road and city land cover pixels are highlighted in the majority of the attention maps warmer colors indicating the main components of the image used by the deep learning model to estimate the ignition probability of the area as we increase the filtering threshold we notice how the model ends up focusing its attention on the bottom left section of the image mainly composed of human related land covers and roads interacting with adjacent grasslands and forest plantations the example also shows that the model mainly focuses its attention on the road s insertion area in the city instead of the city or roads independently this could suggest that increased traffic into wildlands from dense human populated areas as represented by this insertion point could indicate a higher ignition risk similar results are observed across the entire dataset despite the previously mentioned differences in general patterns between the risk categories identified by dft the landscape metrics that compare the complete image against the hottest attention map areas also show clear differences between the categories fig 5 table 1 these metrics showed that more fragmented but less diverse landscapes are classified as high risk which is reflected in more components and a lower simpson s index mcgarigal 1995 these differences help improve the identification of the most relevant patterns in a landscape that affect the propensity of fire ignition having the same trend in both the complete image and the hot spots again the results agree with the regions of certain human caused fires with fire ignition mainly associated with a highly fragmented wildland urban interface syphard and keeley 2015 the attention maps also provide a clear assessment of which land cover requires more attention to classify the images in the risk categories at different stages of the net giving us insights into the learning process of the model for this purpose we select ten images at random close to p i 1 high risk ten with p i near 0 5 medium risk and ten close to p i 0 low risk to highlight the differences between landscape attributes across categories in table s1 and fig s1 we show that different layers of the network i e where convolutions and filters are applied pay attention to different land cover types in the original image the dominant land cover for the high risk hr image is forest plantation 47 however for the first layer dft focused on non vegetated areas the areas represented by urban land covers and roads non vegetated dominate the hottest pixels by 38 while the proportion of forest plantations is only a 21 the attention paid by dft in non vegetated areas even increases when filtering the landscape by the 75 hot spot covering 73 of the hottest pixels the middle layer of the model still paid more attention to non vegetated areas but in combination with grassland as it is the second dominant land cover among the hottest pixels 75 threshold deeper in the net last block dft focused on the effect of forest plantations showing patterns similar to some recent findings miranda et al 2020 the combined layers can provide a general overview of the interaction among land covers that boosts the propensity of fire ignition besides users can see where the most critical interactions occur however understanding the individual layer attention maps and their internal patterns opens the black box of ai thereby unraveling different landscape patterns that could provide a deeper understanding of the ecological processes as well as support crucial management decisions in the context of landscape and urban planning policies to illustrate this knowledge discovery process we follow the complete path of one image in our end to end classification model to understand the model functioning and help in interpreting the results fig 6 the outputs obtained at each step of the workflow show the most relevant topological attributes of the landscape for decision making in this case we analyze the same hr landscape of fig 4 and s1 composed of each risky land cover type such as forest plantations human settlements and roads the dft model highlights the different topological attributes of the landscape in the first convolutional layer the results mainly highlight the highways and a combination of roads and highly populated areas represented by urban land covers thereby focusing not only on their presence but also their continuity because isolated pixels or small patches of roads and cities get less attention than large and continuous components in the second convolutional layer the model focuses on forest plantations near a town and roads especially where roads and highly populated areas are adjacent to a forest plantation as we move towards the final layers the attention moves on the presence of continuous patches and their interaction with urban related land covers using this information the model calculates p i in its final layer using a threshold p i 0 5 by default to determine if the sample is labeled as a fire positive or negative observation 3 3 an open challenge landscape metrics measure the structural or functional characteristics of a delimited territory to quantify its spatial patterns and changes through space and time these metrics are widely used in ecology following the assumption that spatial patterns can explain ecological processes and functions in a landscape turner and gardner 1991 this pattern process hypothesis is the basis of several landscape metrics derived mostly from categorical maps that describe the composition and spatial distribution of each land use or land cover uuemaa et al 2013 however the analysis and interpretation of landscape topology have received little attention as a novel metric of landscape patterns and as a crucial indicator to advance informed territorial planning also incorporating land cover dynamic or landscape spatial pattern change as a predictor of fire regime could expand its applications and allows a better understanding of present future drivers and scenarios of land cover and climate change in fire risk viedma et al 2006 ricotta et al 2012 computer vision has become essential in the analysis and extraction of relevant features and patterns from images and multidimensional data advances in this field have achieved remarkable results in multiple scientific studies and applications however interpreting and understanding the performance of models and sometimes surprisingly and counter intuitively learning processes have remained an open and active research challenge sejnowski 2020 in this study we propose a flexible and customizable end to end dl framework integrated with an automatic online data gathering and processing modules to characterize and study the role of land topology in understanding a future wildfire ignition risk by following a supervised learning approach focusing on the interpretability of the results we implement multiple visualizations and statistical techniques to understand the model outcomes in the field of landscape planning aimed at fire protection this novel methodology is a step towards decreasing fire ignition risk avoiding dangerous land covers their spatial patterns and interactions moreover dft could be a valuable resource for the prevention of fires in risky areas as well as support suppression planning strategies e g by allocating relevant resources according to the risk associated with the detected topological patterns of the area this would be reflected in more efficient and effective wildfire suppression strategies in addition to providing supporting insights when developing landscape treatment plans e g fuel treatment prescribed fires or thinning that aim to minimize the impact of future wildfires in general however the proposed methodology could be an essential development in landscape pattern and process interpretation in a broader sense for different ecological disciplines although a step forward in the understanding of the learning mechanism of these methods and improve their outputs interpretability more efforts are required in this direction to continue opening the artificial intelligence black box to exploit the full potential of these powerful models 3 4 framework advantages and limitations the main advantages of our framework in addition to its performance are its scalability flexibility of customization and interpretability the seamless interaction with cutting edge planetary scale data cloud services allows the framework to easily scale complex and challenging global studies enabling users to train and test state of the art models without regional limitations with thousands of high quality datasets being available in gee and the option of providing in house data the possibilities are limitless integrating our method with effective rebalancing methods combined with a light cnn model that can be trained saved and deployed in daily use hardware provides our project with useful tools for various applications although our example consists of a binary classification problem the framework supports both classification binary or multi class and regression models in this regard custom models with different research objectives can be tested e g classify the landscapes into multiple predefined classes based on the type of ignition or even by the expected area burned after an ignition while taking advantage of the framework s pipeline moreover pre trained models provided with its code can be adjusted with new training samples by adjusting the weights of the layers depending on the characteristics and similarities of the dataset and the one used during training this method can provide high quality results while reducing the training time in addition the features generated by the implemented models can be extracted as numerical variables to analyze and use them in alternative formulations such as feeding a classification model e g random forest or support vector machine and train it with an enriched dataset in a form of transfer learning approach implementations of baseline ml models such as random forests and logistic regression ready to exploit these inputs are provided in the project s repository as open source code illustrating how our framework can interact with alternative models and methodologies the generalization of the model to different realities e g where the human factor is not as critical in fire ignitions as in our case study is an open research question that we expect to cover in future studies potentially incorporating extra layers of information into our framework previous studies such as zhang et al 2019 have effectively used a cnn model to study the fire susceptibility of china s yunnan province by combining a variety of features e g temperature topography with different resolutions into a unique multi layer picture however this study is not oriented to understand and interpret the outputs and logic behind the proposed cnn model because of its structure but focused on maximizing the performance of the model by including a wide range of attributes to accurately estimate wildfire susceptibility in contrast we focus our study on what we call learning to understand the model we provide the possibility of observing what the model sees and understand interpret the rationale behind the results supported by techniques that generate relevant visualizations and statistics therefore the clear pipeline flexibility and customization of the proposed framework allow its adaptation to multiple studies where the interpretability of results is critical to assess the performance of the model and support decision making processes such as landscape planning under wildfire risk and the optimal allocation of suppression resources among others the framework is simple to use allowing researchers and practitioners to save significant time and resources 4 conclusions we developed and tested a comprehensive dl framework in the future wildfire ignition risk assessment of landscapes exploiting topological information defined as the spatial distribution and interaction of the data derived from land cover maps dft provides state of the art tools that can be used to collect multidimensional data at a large scale train custom models and understand the results by interpreting the model learning it significantly decreases the training evaluation and model deployment cycle and provides users with limitless and complex research questions with an efficient framework and software the proposed methodology adequately assesses the fire occurrence risk of a given area using only digital information on land cover furthermore it reveals that a cnn architecture can capture drivers from the spatial configuration of landscape showing that topology could be a key to the development of landscapes resistant to wildfire or at least prepare them to minimize consequences due to future wildfires this is translated into a huge potential to provide landscape managers with crucial evaluations and insights during the decision making process the model is able to identify and determine the risk of wildfire ignition in multiple areas by exploiting information about the interaction continuity and frequency of different land covers providing managerial insights for examples see supplementary material given the high interpretability of the results from both statistical and visual perspectives we note that the model may become a valuable resource to effectively guide fire risk mitigation and management plans potentially informing the development of urban policies by taking into account the impact of topological patterns in the design and protection of the land this research can be extended in several important ways first the model can be generalized incorporating a series of relevant layers representing other components of the landscape e g topographic characteristics such as elevation however this incorporation should be performed with caution to avoid obscuring the interpretability of the results measuring the impact of new layers in the predictions the incorporation and quantification of these effects are relevant to a variety of applications in the fire ecology field being an interesting future research direction second the framework could be used to generate novel landscape metrics summarizing the topological information from the image for this the weights of the network and their impact at different layers of the cnn could be analyzed in detail to understand the end to end transformation from inputs into a real valued function describing the area of study third a modified version of the framework could be used to predict other fire behavior phenomena such as the expected rate of spread perimeter average flame length intensity among other options depending on the application the original framework could be complemented with analytical models exploiting state of the art formulations fourth an interesting future direction could be to extend the framework to provide effective landscape management recommendations in the context of wildfire ignition risk given a set of high risk landscapes a generative model e g using generative adversarial networks creswell et al 2018 could be developed to provide ideal modifications in the landscape to reduce the overall risk of the area we plan to expand our initial research in this direction in a near future finally the framework can be applied in similar computer vision studies requiring a high level of interpretability flexibility and customization for this potential modifications to the original cnn could be pertinent e g number or type of layers it could also be combined with other ml models for example the model could be extended to incorporate parallel deep neural networks processing different layers of information being part of an ensemble model including other ml models such as random forests to study complex ecological phenomena among several options the paper has outlined a new dl framework in the context of wildfire ignition risk prediction incorporating analytical and visualization techniques to understand and exploit the results of the complex dl black box it is however only the beginning of future research in this direction declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments a m thanks anid fondap 15110009 and anid postdoctoral fondecyt project 3210101 j c acknowledges the support of the national commission for scientific and technological research conicyt chile through funding from the complex engineering systems institute pia basal afb180003 and acknowledges the support of the agencia nacional de investigación y desarrollo anid chile through funding postdoctoral fondecyt project 3210311 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105122 
25803,the united states power sector uses immense quantities of water and is vulnerable to drought water mismanagement and climate change integrated management of energy and water systems is therefore critical yet is hindered by disparate and delayed information we present the energy water emissions dashboard ewed as an integrative modeling approach and exemplary web based user interface displaying monthly generation water withdrawal and consumption and greenhouse gas emissions at nearly 10 000 u s power plants from 2003 to the most recent data available ewed users may view aggregated results at larger spatial scales including watersheds where they are compared to modeled water availability data ewed also models projections out to 2050 based on a range of energy and climate scenarios finding that water resources will continue to play a critical role in energy sector transitions as such ewed supports efforts to integrate decision making on immediate and long term management challenges at energy water climate nexus graphical abstract image 1 keywords energy water nexus electricity power systems greenhouse gas emissions integrated water resources management software and data availability 1 introduction 1 1 background electricity production requires immense volumes of water for cooling thermoelectric power plants spinning hydroelectric turbines and other uses the united states thermoelectric power sector alone was estimated to withdraw 184 billion cubic meters of water in 2015 and has consistently over the past half century withdrawn more water than any other sector including agriculture dieter et al 2018 despite this outsized share of water use far less scientific and policy attention has been given to water issues in the power sector for instance the united states geologic survey reports national thermoelectric water use only every five years and there are at best sporadic efforts at the state or regional levels to track it on a more regular basis by contrast agricultural water use is tracked at far greater temporal and spatial resolutions by all major agricultural states evenson et al 2018 nevertheless the interdependence of energy and water systems is an increasingly important focus in environmental management and the term energy water nexus has been used to draw attention to these connections healy et al 2015 the electric power sector s dependence on sufficient water resources makes it vulnerable to shocks from water mismanagement competing uses droughts and long term climatic changes mu et al 2020 tidwell et al 2016 van vliet et al 2016 voisin et al 2016 2020 nearly every year water quantity or quality constraints compel u s power plants to reduce or halt power output mccall et al 2016 these curtailments especially over the scale of regions can pose significant challenges to the reliability and economics of power systems furthermore water supply and climate disruptions can set back important environmental goals in power system management including greenhouse gas reduction strategies intended to mitigate such climate disruptions in the first place fulton and cooley 2015 gleick 2017 curtailments aside expected power sector water demands can pose outsized impacts to water systems the management of which is increasingly challenged by climate change peer and sanders 2018 electricity generation in the u s is projected to increase by 30 by mid century under base case scenarios and could increase further under conditions of high economic growth and expanded electrification of transportation useia 2020a the electric power sector s mix of energy sources has changed rapidly in recent years and is expected to be increasingly dominated by natural gas and renewable energy sources in coming decades driven primarily by market conditions and state level greenhouse gas mitigation policies such as renewable portfolio standards some of these projected technologies such as gas turbines and photovoltaics use very little water while others such as hydropower and geothermal will continue to depend on large quantities of water tracking emissions alongside water use is therefore useful to see when and where decarbonization strategies might be working synergistically or at cross purposes with water management tarroja et al 2020 the water demands and impacts as well as emissions of an expanding and dynamic power sector are thus critical for the sustainability of the u s power sector at various scales yet remain highly uncertain and under examined given this gap in understanding as well as the important vulnerability and impacts that power systems face with respect to water resources at various scales this paper focuses on the role of information modeling and visualization to support more integrated management at the energy water climate nexus integrative modeling of disparate systems and data sources can yield important insights on tradeoffs and synergies among management options abdallah and rosenberg 2019 escriva bou et al 2018 porse 2018 in the remainder of this introduction we first describe ideal data attributes for modeling the relationship between electric power systems and water systems and then review the existing grey and peer reviewed literature for such information we then present the methods and findings of the energy water emissions dashboard ewed which builds on existing literatures using computer applications to fill data gaps with novel modeling techniques and ultimately provide better spatial and temporal resolution we conclude by discussing how such a modeling and visualization tool might better support the needs of current and future integrated energy water management 1 2 ideal energy water emissions data attributes modeling past and future water demands and impacts from the electric power sector requires detailed information on power plants and how they relate to water systems fig 1 there are nearly 10 000 power plants in the u s with a 1 mw mw or larger generation capacity and each one of them is unique the us energy information administration eia collects dozens of data points on each power plant every month from these data attributes of power plants that are strong determinants of water use include fuel type generation type and cooling system type the major variations of these technologies are given in fig 1 any single power plant may use multiple fuel types generation types and cooling system types and these technology mixes may change from month to month and from year to year thus it is helpful to track these attributes on a monthly basis and to characterize dominant attributes over the longer term for example by using electric generation for each attribute combination it is also helpful and required by law to monitor power plant greenhouse gas emissions as they are an increasingly important driver of power system dynamics predicting future technology mixes requires more complex modeling based on the economic policy and physical attributes generation capacities transmission and load balancing of power systems not depicted in fig 1 see e g miara et al 2019 voisin et al 2020 power plants withdraw discharge and consume water for a variety of purposes from and to a variety of water resource types cooling systems use water in conjunction with closed loop steam turbine systems to condense water vapor into liquid where it is again reheated using one or more thermal fuel types typical once through cooling systems withdraw water from a water source such as a river and discharge nearly all of it albeit at a higher temperature typical recirculating cooling systems rely on evaporative cooling in cooling towers or ponds where nearly all withdrawn water is eventually consumed through evaporation to the atmosphere thus power plants with once through cooling systems typically have very large water withdrawal rates but very low water consumption rates where consumption refers to the portion of withdrawn water not returned to its source power plants with recirculating cooling systems meanwhile have lower withdrawal rates but much higher consumption rates additionally thermal pollution from once through systems and mineral concentration in blowdown water discharged from recirculating systems both pose water quality concerns for receiving water bodies attributes of both water supply sources and receiving water bodies are thus useful for understanding how power plants both affect and are affected by water systems typically power plants rely on neighboring water resources these may include freshwater from rivers lakes artificial reservoirs groundwater aquifers municipal supplies or reused wastewater as well as saltwater from oceans or saline groundwater equally important is how using these waters for supply and discharge interact with local hydrology water quality and the competing needs of ecological and economic systems healy et al 2015 it is therefore helpful to consider water systems at the various spatial scales at which water is managed including watersheds water supply and sanitation districts counties and states attributes at these scales for modeling energy water interactions may include quantities and qualities of available water as well as water scarcity and ecosystem health indicators 1 3 existing energy water emissions studies given the complexity and magnitude of these ideal data requirements only partial aspects of energy water interactions have been assessed and published to date in the u s most national scale studies focus as does this one on assessing quantitative water withdrawal and consumption rather than qualitative ecological or economic impacts of water use and discharge which are often more local in nature table 1 compares the defining metadata of several such backward looking u s level quantitative assessments as well as our dashboard tool presented below in sections 2 and 3 the selected publications are by no means comprehensive of energy water assessments but define the strengths and limitations of dominant approaches further engagement with the energy water literature including more forward looking assessments is discussed in section 4 the usgs estimate mentioned in section 1 1 is published every 5 years as part of a national compilation of water use estimates across all major sectors dieter et al 2018 these data cover thermoelectric water use and are compiled at the county scale using a combination of surveying and modeling methods usgs data differentiate water withdrawal and consumption by once through and recirculating cooling types as well as by water source including fresh saline surface and ground waters other water attributes at different water management scales are not reported the usgs has also developed a parallel effort to model thermoelectric water use based on thermodynamics of power plants as well as source and discharge waters harris and diehl 2019 these dynamics are modeled for 1122 individual power plants on a monthly basis but reported on a national scale and only for years that can help validate or fill gaps in the usgs bi decadal compilation while these parallel assessments make the overall usgs approach more robust the aggregated spatial and temporal resolutions of these datasets are important limitations the usgs sources do not report greenhouse gas emissions in the power sector the eia collects and reports monthly water use data for large over 100 mw in capacity thermoelectric power plants that use steam as a prime mover and fossil nuclear biomass and solar fuel types useia 2018 these surveys also include all attributes of water resource type listed in fig 1 because eia also collects other power plant attributes cooling water data can be cross referenced with specific generation types and cooling system types the eia cooling water data thus provide higher system spatial and temporal resolutions two shortcomings are its limitation to larger power plants and the delay in reporting surveyed data which are typically published around october for the previous calendar year greenhouse gas emissions are not reported along with cooling water data although elsewhere eia calculates yearly plant level co2 emissions based on fossil fuel use the most comprehensive energy water assessment to date is by grubert and sanders 2018 referred to in table 1 as ucb usc study who conducted an exhaustive review of the energy water literature for all fuel types and across their life cycle transformation into energy products including electricity derived withdrawal discharge and consumption coefficients were developed for all water resource types and applied to the entire 2014 u s energy system while this study resulted in the first ever comprehensive inventory of water use in the u s energy system not just electricity and provides useful coefficients to complement other life cycle water assessments e g of emissions the study does not assess emissions the data are limited by their spatial national and temporal year resolutions a follow up study by peer et al 2019 provided electricity grid scale coefficients which varied greatly and highlight the need to regionalize such data but were limited to a 2014 snapshot and to water consumption only still these studies provide a useful 2014 baseline from which to assess more recent or future technology changes and at finer spatial and temporal resolutions the objective of the energy water emissions dashboard ewed is to build on the achievements of these existing assessments and to overcome their shortcomings using advances in computer science specifically in data integration and web design core to this objective is improving the coverage of power plants as well as the spatial and temporal resolutions at which data are collected processed and presented computer science is leveraged to address the complexity and timeliness of energy water emissions assessment aspects which also highlight the disconnect between such assessments and integrated management the following section outlines the methods used to achieve this objective 2 methods our design of ewed follows a typical three tier architecture relational database layer application server layer and presentation layer fig 2 ewed uses microsoft sql server as the database management system and stores data in base tables a java based web application middleware is deployed as the application server layer to support the communication between the database and the presentation layer in this paper we use back end to refer to the database layer and the application server layer the presentation layer presents a web based graphical user interface ui referred to as front end in this paper the following section presents how each of these layers was designed implemented and related to each other within ewed s programming environment additional methods and data sources as well as raw data files can be found in fulton and jin 2021 currently in review with data in brief 2 1 database layer the backend includes a relational database of 108 base tables that were populated from heterogeneous data sources covering power plant facility attributes generation activity water use water availability and greenhouse gas emissions it also includes 12 database stored procedures and 31 database views for data cleaning and processing data we create database views to integrate the data from different source tables at the facility scale and monthly time step at run time we aggregate the data from the database views to produce data at different spatial and temporal scales per the requirements of the application section 2 2 the following subsections describe how data were sourced and transformed to populate the database tables 2 1 1 power plant facilities table general information on power plants is sourced from the epa s facilities registry service frs rest service usepa 2020a power plants in frs are indicated in the program acronym field by pgm sys acrnm eia 860 which refers to the eia program that reports facility data to the epa query results include power plant attributes including frs id registry id name facility name eia plant code pgm sys id latitude latitude83 and longitude longitude83 other locational attributes were found to be incomplete and are not stored instead latitude longitude coordinates are used in a geographic information system gis to locate power plants within watershed county and state shapefiles uscb 2020 usfs 2020 along with this locating comes the assumption that power plants withdraw water from adjacent water sources which in reality is not always the case for example some plants source water from aqueducts that transfer water between watersheds and regions while this assumption is used to aggregate regional water use more accurate plant level details on reported water sources are collected see section 2 1 3 and provided in the ewed user interface power plants are also located within north american electric reliability corporation nerc subregions usdhhs 2020 for use in ewed s projection feature as described in sections 2 1 2 to 2 1 5 because of these extra steps of assigning geographical attributes ewed s facilities table is updated both using computer program written in python and manually cleaning the data at the time of submitting this article for publication there were 9961 facilities stored in ewed s database 2 1 2 generation tables monthly power plant electricity generation data are sourced from the eia s api useia 2020c for plant level data using the plant code pgm sys id given in ewed s facilities table generation data are published monthly via the api for power plants that report generation and there is often a lag time of several months for some power plants thus more recent data in ewed are incomplete and aggregated statistics for recent months should be used with caution in addition to monthly plant level generation ewed also queries yearly generation by fuel type and generation type prime mover combinations the dominant fuel type generation type combination for a given year is used to characterize the power plant for calculating water use at plants that do not report it because they are not larger than 100 mw and don t use fossil nuclear biomass and solar fuel types see section 2 1 3 for example total electricity generation at a single power plant may be dominated by natural gas gas turbines one year and then coal steam turbines the next year characterizing the power plant by its dominant generation from year to year allows for the categorization necessary to use appropriate water use coefficients as well as modeling future generation as explained in the next paragraph these characterizations are also used on the front end allowing the ui to both report plant types and filter by fuel type see section 2 2 1 ewed models projected monthly generation from 2020 to 2050 at individual power plants using the most recent set of plants currently 9961 and based on their dominant fuel type and monthly generation profile from the most recent complete calendar year currently 2018 annual projected generation data are sourced from the eia s apis for annual energy outlook 2019 which breaks down electricity generation into 14 fuel types solar is broken down by photovoltaic and thermal generation type 22 nerc subregions eia electricity market module regions across the contiguous u s conus and eight projection scenarios called cases in eia these annual generation values are first disaggregated to the monthly scale based on the most recent available e g 2018 monthly combined generation profile of all power plants of the corresponding fuel type and nerc subregion as in p r o j e c t e d m o n t h l y r e g i o n a l g e n e r a t i o n y m i j g e n y m i j g e n y i j g e n y i j where y and m are the future month and year respectively y and m are the most recent known month and year i is the fuel type of interest and j is the nerc subregion of interest these projected monthly generation regional pmrg values are then disaggregated to the power plant level according to each plant s most recent available contribution percentage for the corresponding future month as in p r o j e c t e d m o n t h l y p o w e r p l a n t g e n e r a t i o n y m i j k g e n y m i j k g e n y m i j p m r g y m i j where k is the power plant of interest while total generation by fuel type and region are thus consistent with eia projections we do not attempt to model any changes within these constraints more sophisticated power systems modeling efforts other than eia s capture individual power plant retirements additions and technology modifications based on projected market regulatory transmission and environmental factors eia s models do account for many of these factors in their various cases so the range of ewed s projections also capture this variability at the scale of emm regions still we see synergistic opportunities in future work to link ewed s water modeling environment with other power systems models that examine broader ranges of scenarios 2 1 3 water use tables monthly water withdrawal and consumption for individual power plants are assigned using one of three sources raw data dynamic coefficients or static coefficients flags of 0 1 or 2 are used in the database to indicate which method was used for each entry raw data are sourced from eia s thermoelectric cooling water data ms excel files 1 1 these files are prepared by eia to combine self reported data from power plants on eia forms 860 and 923 for water withdrawal and consumption values these files contain positive zero negative and blank entries including for different months for the same generator after consulting with eia staff we elected to only change blank entries to zero when a generator had a reported value in other months so that coefficient calculations would not result in mathematical errors useia 2020b which have not yet been made available via their api these monthly withdrawal and consumption values are assigned to power plants using plant code and the corresponding year and month flag 0 ewed also stores the eia reported values for cooling system type water type water source type and water source name which are viewable for individual power plants in the user interface as these eia water use files are only released yearly and with nearly a year of delay ewed also calculates more recent water use using generation based coefficients which are dynamically created using a database stored procedure for each power plant and all stored years that data are available flag 1 as an example for a power plant that has january 2019 generation data and sporadic eia water withdrawal data j a n 2019 w a t e r w i t h d r a w a l j a n 2019 g e n e r a t i o n s u m o f w a t e r w i t h d r a w a l f o r m o n t h s w i t h f l a g 0 s u m o f g e n e r a t i o n f o r c o r r e s p o n d i n g m o n t h s w i t h f l a g 0 likewise as these raw data only go back to 2014 prior water withdrawal and consumption values 2003 2013 are calculated using the dynamic coefficient for power plants which exist in the eia water use files as noted in table 1 eia water use data are limited to large power plants of certain fuel types resulting in less than 10 coverage of the total power plants in the u s for the remaining 90 of power plants ewed uses fuel type specific static withdrawal and consumption coefficients flag 2 derived from grubert and sanders 2018 discussed in section 1 3 for all fuel types except water i e hydropower we summed their lifecycle coefficients of water uses that take place at the power plant including where applicable conversion of all fuels to electricity i e cooling post conversion waste management for coal nuclear and biomass fuels as well as production of wind blade washing geothermal well augmentation solar pv panel washing and solar thermal mirror washing ewed s hydropower coefficients are based on previous work by grubert 2016 showing high regional variation in net evaporative losses from hydropower reservoirs their centroid based coefficients are assigned to ewed power plants based on location in a gis also following their logic that hydropower water withdrawal is qualitatively different from other power system withdrawals i e storing water temporarily and passing it through turbines versus withdrawing water and either consuming it heating it significantly ewed sets hydropower water withdrawal coefficients equal to consumption for the 90 of plants that use static flag 2 withdrawal and consumption coefficients generalized to fuel type not differentiated by prime mover or cooling type we had to characterize mixed technology power plants by their dominant fuel type as described in section 2 1 2 this generalization creates uncertainty in our water use estimates at the plant and regional scales for example a plant whose generation is dominated by natural gas turbines would be assigned a very low water use coefficient for all of its generation possibly masking intensive water use by a lesser generating technology like coal steam turbine some studies e g diehl and harris 2014 peer et al 2019 have assessed water use at the more specific generator level for individual years but likewise create uncertainty in applying coefficients from those sometimes very few known generators to others of similar technology this uncertainty is greatest for individual power plants and is somewhat limited in ewed by our application of fuel type specific coefficients to only smaller 100mw power plants which generally do not have as many generators of different types as larger power plants we expect that aggregating over larger spatial scales e g total water use within watersheds may reduce this uncertainty further additional uncertainty comes from applying static coefficients over all months while in reality withdrawal and consumption rates vary seasonally in reality summer rates tend to be higher due to lower thermal efficiencies and evaporation rates than in winter so our static coefficients likely underestimate summer water withdrawal and consumption values this uncertainty can be seen as a conservative underestimation when compared to water availability ewed models projected monthly withdrawal and consumption from 2020 to 2050 in the conus at individual power plants as the product of its projected generation section 2 1 2 and its most recent dynamic flag 1 or static flag 2 withdrawal and consumption coefficient this assumes unconstrained water availability which is of course not true in many cases but rather does allow for assessing the water demands of particular future regional generation portfolios based on recent performance these results can be used to verify and focus other power systems modeling efforts in places where projected increases in water use might be of concern 2 1 4 water availability tables to provide context for water withdrawal and consumption volumes at the watershed scale ewed sources water availability data from the u s forest service s water supply stress index model wassi wassi is a coupled water balance and ecosystem productivity model that provides monthly water supply and demand values at the 8 digit hydrologic unit code huc 8 scale termed watershed here across the conus caldwell et al 2019 duan et al 2019 the field flwout mm3 mo is used to describe huc 8 water availability which in this case means total monthly outflow after subtracting for consumptive water uses and including inflows from upstream watersheds ewed uses historic water availability data for 2003 2015 with thermoelectric water uses removed set to 100 in model inputs since ewed itself models power sector water use years 2016 2019 were not available from wassi at the time of this writing due to a lack of updated precipitation data needed to run the model ewed also sources future water availability data from wassi based on its use of statistically downscaled projections from 20 global climate models gcms used under the 5th climate model intercomparison project cmip5 caldwell et al 2019 each model contains results using two scenarios for future atmospheric greenhouse gas concentrations representative concentration pathways rcp 4 5 and 8 5 we also calculated a 20 model average for rcp 4 5 and rcp 8 5 making a total of 42 different monthly water availability projections for each conus watershed region 2 1 5 ghg emissions tables ewed sources greenhouse gas ghg emissions data from the epa s ghg restful data service usepa 2020b epa s ghg reporting program ghgrp has since 2011 collected yearly greenhouse gas co2 ch4 and n2o emissions data which are self reported by power plants and other direct sources that emit at least 25 000 metric tons of carbon dioxide equivalent co2e per year ghgrp facilities are identified by a unique ghgrp facility id and in only some instances reference an frs id that can be linked to ewed s facility table thus to connect the emissions tables to facilities tables we rely on a ghgrp facility to power plant crosswalk provided by the ghgrp usepa 2020c as new power plant facilities are added to ewed s facilities table we update the crosswalk by cross referencing plant names and other attributes with ghgrp tables yearly ghg emissions quantities for each power plant are disaggregated to monthly emissions by creating a yearly generation based emissions coefficient that is again multiplied by monthly generation emissions coefficients are also used to model monthly emissions before 2011 and after the most recently available data currently 2018 ewed s dynamic emissions coefficient procedure creates coefficients for the minimum and maximum years that a power plant exists in the ghgrp sourced emissions table any previous or subsequent respectively monthly generation for that power plant is multiplied by the min or max year coefficient to produce monthly emissions values similar to the water use tables ewed models projected monthly ghg emissions from 2020 to 2050 in the conus at individual power plants as the product of their projected generation section 2 1 2 and the max year dynamic emissions coefficient currently 2018 2 2 application server layer the application server layer was built as a dynamic web application using spring boot spring 2020 communication between the presentation layer and the application server layer is through representational state transfer rest application programming interfaces apis the application server layer transposes the rest request into database queries and returns the query results to the presentation layer we use a database oriented approach in the design and implementation of ewed we have evaluated different processing weight assignments between application server layer and the database server layer based on a comparison of time for executing a task we found out that using database queries for computation such as aggregation at the database layer are more efficient than using java programming to do the same task at the application layer as a result we delegated most of the computation to the database system we designed database queries that calculate values join multiple database tables group results and order outputs we avoided allocating computations especially complex computations to the application server at static time stored procedures and views are used to clean data calculate derived data and update data at run time to render the presentation according to ui inputs a request is sent from the presentation layer to the application layer by calling a rest end point the application layer converts the requests into database queries once the query result returns the application layer wraps the result and return it to the presentation layer 2 2 1 apis communication between the front end and the back end is enabled through rest apis the presentation layer sends get requests to the back end based on a user s input from the ui the application server processes the requests and forms database queries upon the results returned from the database the application server sends the results of the get request back to the presentation layer the main advantage of this approach is that it allows the design and implementation of different architecture components to be loosely coupled i e the front end and the back end could be developed concurrently this set of apis mainly serves the purpose of internal communication among architectural components which therefore provides more details than what the user needs in addition we built a public facing web service via a virtual node provided by the project funder the us epa exchange network this web service provides plant level data including power plant attributes from the facilities table as well as monthly generation emission water consumption and water withdrawal as described above the api provided by the web service allows users to filter the data by various parameters such as month year state huc and plant name ewed 2020 users can further aggregate the plant level monthly data to any other level such as huc state for any time duration 2 3 presentation layer the front end is designed and implemented using typescript based on the angular framework which is a component based web development environment angular 2020 our design consists of a combination of the waterfall model and the agile method in our agile development process potential user requirements of the ui were collected and modified through many sprints from using paper adobe xd to a prototype using javascript in the agile method requirements can be changed added and deleted due to the new understanding of the system the changes are reflected in the sequence of sprint implementations the javascript version is the final product of the agile development after the javascript version was deployed and tested feedback from potential users was collected and incorporated once the user requirements were finalized design implementation and testing were performed following the waterfall model the final presentation layer discarded the javascript prototype implementation and it was built using angular 10 2 4 system testing we conducted testing following sommerville 2016 including both white box and black box testing unit testing integration testing release testing performance testing and regression testing white box testing generally is a procedure that tests the internal structure of the computer program while black box testing tests the functionality without knowing the programming details unit testing generally is performed on an individual unit or component of a system we unit tested the database layer by testing the functionality of the views and the processing logic of the stored procedures by data comparison and verification with the actual values stored in the database we also unit tested at the application layer by creating various requests to all end points and verifying them with database query results we further unit tested at the presentation layer by exercising each functionality and all user input conditions integration testing generally tests the combination of individual components our integration testing focused on communications between different architectural components centered with https get requests release testing generally tests a system outside of the development team for the purpose of releasing the system to users our release testing not only covers the testing of functionalities but also heavily on boundary testing and invalid inputs performance testing generally tests if the system can process its intended load within an acceptable range execution time because of the diversity in software applications within the discipline there is no specified threshold for acceptable performance in addition differences in the hardware e g cpu memory size that hosts the software affect software performance our performance testing was conducted both at the component level and immediately after components were integrated which identified improvement potential in our overall system we modified our system accordingly to improve the performance to our satisfaction regression testing generally ensures software continues to perform after making changes our regression testing was performed at all phases to ensure the quality and performance of the final system as a summary the main purpose and outcome of our testing is to ensure that the software functions as designed and as efficiently as the user experience demanded 3 results 3 1 u s scale ewed displays results in a range of ways to suit different user needs and are also downloadable for other use cases via a companion publication fulton and jin 2021 currently in review with data in brief one relevant use case for this article is to compare ewed results with previous national scale energy water assessments which were discussed in section 1 3 for reference year 2015 ewed estimates that the u s power sector withdrew 240 billion cubic meters bm3 and consumed 6 0 bm3 of water associated with 4 0 tw hours of electricity generation fig 3 this withdrawal result is similar to that of the eia cooling water dataset while ewed s consumption result is similar to that of the usgs compilation likely due to the difference in methods and coverage between ewed and those two assessments which are shown in table 1 however the fact that ewed s total generation is far greater than either of these sources indicates that the additional power plants activities captured by ewed may not be very water intensive with a nearly equivalent generation quantity captured in the usc ucb study ewed estimates 12 higher water withdrawal but 25 lower water consumption even though coefficients used in ewed were based on the usc ucb study these differences in results are attributable to methodological choices some of which were highlighted in section 2 1 3 as well as changes in the u s generation portfolio between 2014 and 2015 overall that ewed estimates are comparable with the upper ends of these four previous assessments indicates that its methods are comprehensive of existing methods and likely fill in gaps in existing data sets ewed may therefore be useful for future inventorying of power sector water use across the u s ewed s relatively long time series and monthly resolution provides additional insight into how power sector water demands have fluctuated from year to year as well as throughout the year at the national scale we estimate that total yearly water withdrawal and consumption have declined over the 18 year period represented in ewed s historical water use tables fig 4 withdrawal has trended consistently downward over this period a finding which concurs with 5 year trends found in the usgs compilation data and are attributable to closure or idling of more water intensive power plants dieter et al 2018 consumption has also declined over this time period likely due to similar factors but since 2015 has increased as many power plants began converting cooling systems from once through to recirculating to comply with a 2014 usepa regulation designed to reduce impingement and entrainment of aquatic organisms usepa 2020d monthly fluctuations show a pattern of peak water demands in the power sector occurring in july and august with a second smaller peak occurring in december and january this pattern generally parallels month to month electricity generation where peaks coincide with summer cooling needs and winter heating needs a larger portion of which are met directly with fuels such as natural gas fig 5 exceptions to this paralleling are worth noting and potentially investigating in the context of particular watersheds 1 a spring season rise in consumption or shoulder that is earlier than withdrawal which may have disproportionate impacts on spring runoff in some watersheds fig 5 line a and 2 a higher mid summer peak in both consumption and withdrawal relative to generation which indicates higher water use rates per mwh of generation at a time of year when runoff in many watersheds is at its lowest point fig 5 line b the month to month relationships between generation consumption and withdrawal vary widely among u s states counties and watershed regions and are made visible at these scales by ewed s ui discussed below in section 3 2 ewed s projections of water consumption and withdrawal in the conus power sector from 2020 to 2050 are shown in fig 6 and are based on the eight cases of the eia annual energy outlook 2019 useia 2020d water consumption continues to rise from current values by 13 for the reference case over the 30 year period increases in the other seven cases ranges from 6 5 low resource technology i e reduced oil and natural gas availability to 15 high macroeconomic growth which represents a range of 440 million m3 mm3 in 2050 rounded to two significant figures to account for uncertainty the mix of fuel types and generation types are important drivers of the variation in outcomes in the reference case for example the total increase of over 740 mm3 in water consumption is driven primarily by geothermal and natural gas power plants which increase by almost 290 and 37 respectively the increase is somewhat offset by declines at coal 12 and nuclear 10 power plants in the low rt case however the somewhat lesser consumption increase of 380 mm3 is driven solely by geothermal power plants while natural gas plants actually decline by 27 as extraction of unconventional natural gas becomes more challenging consumption at coal and nuclear power plants in the low rt case remains steady this range of results suggests that the mix of fuel types and generation types can have important effects on future water consumption in the power sector such findings are consistent with previous studies e g macknick et al 2012 although the range of our results is lower due to less variation in eia cases compared scenarios used in other power systems models water withdrawals in the power sector are projected to continue declining below current levels until the 2030s when in some cases they are projected to begin rising and return to near present levels by 2050 fig 6 because water withdrawals are so much larger than consumption in absolute terms the variation in cases is also larger with a difference of over 16 bm3 by 2050 these variations are also driven by fuel type and generation type differences for example the high price case shows the deepest overall reductions of nearly 15 bm3 between 2020 and 2050 driven by decreases at nuclear 21 and coal 14 power plants and only partially offset by increases at natural gas plants 14 in the high macro case overall water withdrawals return to within 99 of 2020 levels in 2050 as increases at natural gas plants 35 outweigh the more modest decreases in coal 6 and nuclear 16 linking the time series results from of ewed s historical modeling fig 4 to projections fig 6 results in a disconnect which is attributable to three factors first data for 2019 are incomplete in ewed s historical system due to the reporting lag from the eia for some power plant generation see section 2 1 2 using ewed s projection modeling to fill this grey area is not appropriate as 2019 data are regularly updated and as soon as data are complete will provide a more accurate picture of power sector water use second there are structural differences in historical versus projected generation data sourced via eia s api eia s historical data cover all power plants larger than 1 mw in capacity in the electric power commercial and industrial sectors while its projected data cover the electric power sector only resulting in 1 3 lower generation totals in ewed s projection system starting in 2020 third eia s projections only cover conus states thus omitting alaska and hawaii and further lowering ewed s overall projections compared to its historical results despite these differences and time series disconnect ewed s historical and projection systems independently offer unique opportunities to both compare to other national energy water assessments as well as to conduct new assessments and visualize energy water relationships at other scales 3 2 ui enabled scales ewed s modeling structure based on individual power plant activities allows for far more granular spatial resolution and analysis of the types of results presented in section 3 1 we first present ui results and features at the state level while the remainder of this section describes smaller scale results and more advanced ui features using the example of california the database and processing requirements of displaying these granular data at the national level are not feasible in the ui the ui allows users to query the database using text input fields or mouse clickable fields in the graphical display which includes a map table and various chart formats fig 7 input fields and graphical displays are synchronized at each input step and display filtered results consistently across the platform the map allows users may toggle or click on regions to change the spatial scale of the query to states watersheds counties or individual power plant facilities the latter three of which are not available for the entire u s the map displays regional results as choropleth color intensities divided into 10 bins and power plant point results as bubble sizes divided into 5 bins each using the jenks natural breaks classification method users may also toggle map displays between water consumption withdrawal and emissions results the table displays sortable numerical results and provides a link to download a csv file for the query and allows users to click on individual entries to change the query tabs allow users to view the queried results as charts including a monthly time series line chart not available for the entire u s or broken down by fuel type as a pie chart or bar chart which can also be downloaded as png or pdf files fuel type also serves as a query filter and updates results across the entire platform by selecting a state users can display results at more granular spatial scales including watersheds counties and individual power plant facilities fig 8 shows an example for california where the default map view displays watershed regions with aggregated results based on power plants within those regions users can toggle the map display to county or facility scales without affecting the query but the table not shown will change to display counties or facilities respectively the pie chart tab displays results for all of california broken down by fuel type in order to draw attention to the relative contribution of different fuel types to generation consumption withdrawal and emissions in the case of california a user may take note of the stark difference natural gas makes up the largest share of statewide generation 46 and emissions 92 but water consumption is dominated by geothermal 45 and withdrawal is dominated by nuclear 53 absolute values can be seen by hovering the cursor over pie wedges or by shifting to the bar chart tab which displays results on a log scale to identify the source of these outsized water uses a user could filter by fuel type and also toggle the map to view individual facilities in the case of california about 40 of geothermal water consumption occurs at one of the state s 32 facilities the geysers and all of nuclear water withdrawal occurs at the state s lone nuclear plant diablo canyon which uses saltwater zooming in to the watershed scale allows users to see power sector water use in relation to modeled water availability either historic or projected according to the selected climate scenario and gcm see section 2 1 4 fig 9 shows an example california watershed the santa ana river with results from ewed s projections for the year 2050 the map displays the watershed delineation with individual power plant facility locations as bubbles sized relative to the selected result consumption withdrawal or emissions clicking on an individual facility displays a pop up with associated power plant and cooling system attributes as well as activities including a monthly time series a monthly time series of results for the entire watershed are shown in the line chart along with monthly water availability projections the example of the santa ana river watershed in 2050 illustrates the situation discussed in section 3 1 where mid summer minimum streamflow coincides with peak water consumption and withdrawal in this case default projection inputs result in water use reaching within 40 water availability but selecting different energy scenario cases climate scenarios and gcm inputs can result in water use actually exceeding water availability by several times for example all four gcms deemed priority models for california s most recent climate change assessment pierce et al 2018 result in water consumption exceeding mid summer water availability users are encouraged to examine a range of scenarios but such visualizations nevertheless draw attention to the impact of water scarcity on future electricity generation and vice versa in a particular context 4 discussion the manifold ways that ewed presents results suggests that it can serve diverse user needs in both drawing attention to trends and potential challenges at different scales in the u s energy water climate nexus as well as supporting more integrative management and decision making ours is not the first assessment of energy water interdependencies yet ewed does represent a first attempt to our knowledge to leverage computer science methods to model such interdependencies in a way that is as automated timely integrative multi scaled in both spatial and temporal dimensions and is user friendly indeed ewed s novel design is built almost entirely on existing assessment methods and data and its results correspond with aspects of previous work further ewed s granular and timely results provide insights at multiple scales can be used to ground truth more complex modeling projections of the u s power sector e g miara et al 2019 voisin et al 2020 where ewed lacks in terms of capturing power system dynamics i e grid market and policy complexities it can complement energy water modeling in terms of visualizing spatial and temporal dynamics of water use as well as emissions in future work we aim to expand ewed s interfaces with such power systems models as well as hydrologic models and other user specified inputs compared to usgs thermoelectric water withdrawal estimates showing declines in water use from 2005 to 2010 and 2015 ewed s results parallel these rates of decline but are consistently about 20 higher in absolute terms this finding suggests that the usgs compilation which is the longest running and perhaps most official estimate of water use in the nation regularly overlooks a substantial amount of water use in the power sector and which is likely not accounted for in other water use sectors ewed results indicate that this unaccounted for water use is largely associated with fuel types that would likely be covered by usgs accounting methods and only partially associated with non thermoelectric and renewable fuel types further analysis would be needed at the county scale the smallest spatial unit reported in usgs data to determine the degree to which fuel type power plant size assessment method or other variables contribute for the overall difference the usgs along with other federal agencies has been tasked by the u s congress to establish an ongoing national water availability and use program referred to as the water census evenson et al 2018 critical to this mandate are improvements in both the temporal and spatial resolution of water use across all sectors the power sector presents numerous obstacles to these goals including inconsistent and incomplete coverage in reporting programs as well as reporting delays recent analysis by usgs harris and diehl 2017 shows that a detailed modeling approach can complement the bottom up data compilation approach of reporting programs because ewed uses individual facilities and monthly time step as its units of analysis it and related modeling efforts can help support national water census goals and play a more central role in describing trends and forecasting potential challenges in both energy and water systems ewed s novel and accessible user interface also makes visualizing and understanding energy water climate issues viable at much smaller scales which in some cases are better tailored to managing energy water climate challenges water resources management in particular occurs at local to regional scales from watersheds and counties to river basins and interstate collaborations ewed s water availability features call attention to the dynamics of water availability at these scales power system management too happens at scales ranging from local utilities to regional grid balancing entities these overlapping and yet often disparate jurisdictions all play critical roles in managing interdependent water and energy systems identifying common management goals e g see voisin et al 2019 for a qualitative multi scale resilience framework can be synergistic but often face a lack of integrative information cross platform modeling tools like ewed can serve such integrated management efforts to help identify and strategize around complex energy water challenges energy water challenges are also not unique to the u s context global climate change driven temperature increases and water scarcity demand the attention of energy system managers everywhere the need to monitor integrate analyze and visualize energy water data is therefore pervasive but currently lacking and disjointed cui et al 2020 larsen et al 2019 ewed may serve as a model for how to do this in other contexts as well as point to the need for underlying data to be publicly available and accessible 5 conclusions the u s power sector has been highly dynamic and is likely to remain so in the future as energy policies continue to address immense societal challenges like climate change national security and economic transitions our results are consistent with previous water energy assessments e g miara et al 2017 tidwell et al 2016 voisin et al 2020 showing that water resources have and will continue to play an essential role as a critical input to energy systems at the same time water resource systems are already being impacted by climate change and may be an increasingly limiting factor for power systems as well as a source of vulnerability recent transitions in the u s away from coal and nuclear fuels while not driven by water concerns have so far eased the power sector s thirst for water however even a potential wholesale transition to renewable energy sources may still conflict with water availability and management constraints as hydropower geothermal power solar thermal and biomass power plants all have high water demands understanding the water implications of past and future energy transitions requires integrative and accessible information and tools like ewed only then can we address the demands of a carbon constrained world without running afoul of its water constraints funding information this work was supported by the united states environmental protection agency exchange network grant program grant number os 83923301 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements author contributions j f conceived of the project and lead its implementation and the writing of this paper y j oversaw the project design and workflow and contributed to the writing of this paper we are grateful for the contributions of many student assistants that helped with various aspects and stages of the project in alphabetical orders tejaswini bhorkar gaurav bora trent buchanan aaron enberg jasmie guan priya gundlupet khoi hoang priyanka makwana and karan mitra we are also thankful for the administrative support of california state university sacramento s office of research affairs and university enterprises incorporated 
25803,the united states power sector uses immense quantities of water and is vulnerable to drought water mismanagement and climate change integrated management of energy and water systems is therefore critical yet is hindered by disparate and delayed information we present the energy water emissions dashboard ewed as an integrative modeling approach and exemplary web based user interface displaying monthly generation water withdrawal and consumption and greenhouse gas emissions at nearly 10 000 u s power plants from 2003 to the most recent data available ewed users may view aggregated results at larger spatial scales including watersheds where they are compared to modeled water availability data ewed also models projections out to 2050 based on a range of energy and climate scenarios finding that water resources will continue to play a critical role in energy sector transitions as such ewed supports efforts to integrate decision making on immediate and long term management challenges at energy water climate nexus graphical abstract image 1 keywords energy water nexus electricity power systems greenhouse gas emissions integrated water resources management software and data availability 1 introduction 1 1 background electricity production requires immense volumes of water for cooling thermoelectric power plants spinning hydroelectric turbines and other uses the united states thermoelectric power sector alone was estimated to withdraw 184 billion cubic meters of water in 2015 and has consistently over the past half century withdrawn more water than any other sector including agriculture dieter et al 2018 despite this outsized share of water use far less scientific and policy attention has been given to water issues in the power sector for instance the united states geologic survey reports national thermoelectric water use only every five years and there are at best sporadic efforts at the state or regional levels to track it on a more regular basis by contrast agricultural water use is tracked at far greater temporal and spatial resolutions by all major agricultural states evenson et al 2018 nevertheless the interdependence of energy and water systems is an increasingly important focus in environmental management and the term energy water nexus has been used to draw attention to these connections healy et al 2015 the electric power sector s dependence on sufficient water resources makes it vulnerable to shocks from water mismanagement competing uses droughts and long term climatic changes mu et al 2020 tidwell et al 2016 van vliet et al 2016 voisin et al 2016 2020 nearly every year water quantity or quality constraints compel u s power plants to reduce or halt power output mccall et al 2016 these curtailments especially over the scale of regions can pose significant challenges to the reliability and economics of power systems furthermore water supply and climate disruptions can set back important environmental goals in power system management including greenhouse gas reduction strategies intended to mitigate such climate disruptions in the first place fulton and cooley 2015 gleick 2017 curtailments aside expected power sector water demands can pose outsized impacts to water systems the management of which is increasingly challenged by climate change peer and sanders 2018 electricity generation in the u s is projected to increase by 30 by mid century under base case scenarios and could increase further under conditions of high economic growth and expanded electrification of transportation useia 2020a the electric power sector s mix of energy sources has changed rapidly in recent years and is expected to be increasingly dominated by natural gas and renewable energy sources in coming decades driven primarily by market conditions and state level greenhouse gas mitigation policies such as renewable portfolio standards some of these projected technologies such as gas turbines and photovoltaics use very little water while others such as hydropower and geothermal will continue to depend on large quantities of water tracking emissions alongside water use is therefore useful to see when and where decarbonization strategies might be working synergistically or at cross purposes with water management tarroja et al 2020 the water demands and impacts as well as emissions of an expanding and dynamic power sector are thus critical for the sustainability of the u s power sector at various scales yet remain highly uncertain and under examined given this gap in understanding as well as the important vulnerability and impacts that power systems face with respect to water resources at various scales this paper focuses on the role of information modeling and visualization to support more integrated management at the energy water climate nexus integrative modeling of disparate systems and data sources can yield important insights on tradeoffs and synergies among management options abdallah and rosenberg 2019 escriva bou et al 2018 porse 2018 in the remainder of this introduction we first describe ideal data attributes for modeling the relationship between electric power systems and water systems and then review the existing grey and peer reviewed literature for such information we then present the methods and findings of the energy water emissions dashboard ewed which builds on existing literatures using computer applications to fill data gaps with novel modeling techniques and ultimately provide better spatial and temporal resolution we conclude by discussing how such a modeling and visualization tool might better support the needs of current and future integrated energy water management 1 2 ideal energy water emissions data attributes modeling past and future water demands and impacts from the electric power sector requires detailed information on power plants and how they relate to water systems fig 1 there are nearly 10 000 power plants in the u s with a 1 mw mw or larger generation capacity and each one of them is unique the us energy information administration eia collects dozens of data points on each power plant every month from these data attributes of power plants that are strong determinants of water use include fuel type generation type and cooling system type the major variations of these technologies are given in fig 1 any single power plant may use multiple fuel types generation types and cooling system types and these technology mixes may change from month to month and from year to year thus it is helpful to track these attributes on a monthly basis and to characterize dominant attributes over the longer term for example by using electric generation for each attribute combination it is also helpful and required by law to monitor power plant greenhouse gas emissions as they are an increasingly important driver of power system dynamics predicting future technology mixes requires more complex modeling based on the economic policy and physical attributes generation capacities transmission and load balancing of power systems not depicted in fig 1 see e g miara et al 2019 voisin et al 2020 power plants withdraw discharge and consume water for a variety of purposes from and to a variety of water resource types cooling systems use water in conjunction with closed loop steam turbine systems to condense water vapor into liquid where it is again reheated using one or more thermal fuel types typical once through cooling systems withdraw water from a water source such as a river and discharge nearly all of it albeit at a higher temperature typical recirculating cooling systems rely on evaporative cooling in cooling towers or ponds where nearly all withdrawn water is eventually consumed through evaporation to the atmosphere thus power plants with once through cooling systems typically have very large water withdrawal rates but very low water consumption rates where consumption refers to the portion of withdrawn water not returned to its source power plants with recirculating cooling systems meanwhile have lower withdrawal rates but much higher consumption rates additionally thermal pollution from once through systems and mineral concentration in blowdown water discharged from recirculating systems both pose water quality concerns for receiving water bodies attributes of both water supply sources and receiving water bodies are thus useful for understanding how power plants both affect and are affected by water systems typically power plants rely on neighboring water resources these may include freshwater from rivers lakes artificial reservoirs groundwater aquifers municipal supplies or reused wastewater as well as saltwater from oceans or saline groundwater equally important is how using these waters for supply and discharge interact with local hydrology water quality and the competing needs of ecological and economic systems healy et al 2015 it is therefore helpful to consider water systems at the various spatial scales at which water is managed including watersheds water supply and sanitation districts counties and states attributes at these scales for modeling energy water interactions may include quantities and qualities of available water as well as water scarcity and ecosystem health indicators 1 3 existing energy water emissions studies given the complexity and magnitude of these ideal data requirements only partial aspects of energy water interactions have been assessed and published to date in the u s most national scale studies focus as does this one on assessing quantitative water withdrawal and consumption rather than qualitative ecological or economic impacts of water use and discharge which are often more local in nature table 1 compares the defining metadata of several such backward looking u s level quantitative assessments as well as our dashboard tool presented below in sections 2 and 3 the selected publications are by no means comprehensive of energy water assessments but define the strengths and limitations of dominant approaches further engagement with the energy water literature including more forward looking assessments is discussed in section 4 the usgs estimate mentioned in section 1 1 is published every 5 years as part of a national compilation of water use estimates across all major sectors dieter et al 2018 these data cover thermoelectric water use and are compiled at the county scale using a combination of surveying and modeling methods usgs data differentiate water withdrawal and consumption by once through and recirculating cooling types as well as by water source including fresh saline surface and ground waters other water attributes at different water management scales are not reported the usgs has also developed a parallel effort to model thermoelectric water use based on thermodynamics of power plants as well as source and discharge waters harris and diehl 2019 these dynamics are modeled for 1122 individual power plants on a monthly basis but reported on a national scale and only for years that can help validate or fill gaps in the usgs bi decadal compilation while these parallel assessments make the overall usgs approach more robust the aggregated spatial and temporal resolutions of these datasets are important limitations the usgs sources do not report greenhouse gas emissions in the power sector the eia collects and reports monthly water use data for large over 100 mw in capacity thermoelectric power plants that use steam as a prime mover and fossil nuclear biomass and solar fuel types useia 2018 these surveys also include all attributes of water resource type listed in fig 1 because eia also collects other power plant attributes cooling water data can be cross referenced with specific generation types and cooling system types the eia cooling water data thus provide higher system spatial and temporal resolutions two shortcomings are its limitation to larger power plants and the delay in reporting surveyed data which are typically published around october for the previous calendar year greenhouse gas emissions are not reported along with cooling water data although elsewhere eia calculates yearly plant level co2 emissions based on fossil fuel use the most comprehensive energy water assessment to date is by grubert and sanders 2018 referred to in table 1 as ucb usc study who conducted an exhaustive review of the energy water literature for all fuel types and across their life cycle transformation into energy products including electricity derived withdrawal discharge and consumption coefficients were developed for all water resource types and applied to the entire 2014 u s energy system while this study resulted in the first ever comprehensive inventory of water use in the u s energy system not just electricity and provides useful coefficients to complement other life cycle water assessments e g of emissions the study does not assess emissions the data are limited by their spatial national and temporal year resolutions a follow up study by peer et al 2019 provided electricity grid scale coefficients which varied greatly and highlight the need to regionalize such data but were limited to a 2014 snapshot and to water consumption only still these studies provide a useful 2014 baseline from which to assess more recent or future technology changes and at finer spatial and temporal resolutions the objective of the energy water emissions dashboard ewed is to build on the achievements of these existing assessments and to overcome their shortcomings using advances in computer science specifically in data integration and web design core to this objective is improving the coverage of power plants as well as the spatial and temporal resolutions at which data are collected processed and presented computer science is leveraged to address the complexity and timeliness of energy water emissions assessment aspects which also highlight the disconnect between such assessments and integrated management the following section outlines the methods used to achieve this objective 2 methods our design of ewed follows a typical three tier architecture relational database layer application server layer and presentation layer fig 2 ewed uses microsoft sql server as the database management system and stores data in base tables a java based web application middleware is deployed as the application server layer to support the communication between the database and the presentation layer in this paper we use back end to refer to the database layer and the application server layer the presentation layer presents a web based graphical user interface ui referred to as front end in this paper the following section presents how each of these layers was designed implemented and related to each other within ewed s programming environment additional methods and data sources as well as raw data files can be found in fulton and jin 2021 currently in review with data in brief 2 1 database layer the backend includes a relational database of 108 base tables that were populated from heterogeneous data sources covering power plant facility attributes generation activity water use water availability and greenhouse gas emissions it also includes 12 database stored procedures and 31 database views for data cleaning and processing data we create database views to integrate the data from different source tables at the facility scale and monthly time step at run time we aggregate the data from the database views to produce data at different spatial and temporal scales per the requirements of the application section 2 2 the following subsections describe how data were sourced and transformed to populate the database tables 2 1 1 power plant facilities table general information on power plants is sourced from the epa s facilities registry service frs rest service usepa 2020a power plants in frs are indicated in the program acronym field by pgm sys acrnm eia 860 which refers to the eia program that reports facility data to the epa query results include power plant attributes including frs id registry id name facility name eia plant code pgm sys id latitude latitude83 and longitude longitude83 other locational attributes were found to be incomplete and are not stored instead latitude longitude coordinates are used in a geographic information system gis to locate power plants within watershed county and state shapefiles uscb 2020 usfs 2020 along with this locating comes the assumption that power plants withdraw water from adjacent water sources which in reality is not always the case for example some plants source water from aqueducts that transfer water between watersheds and regions while this assumption is used to aggregate regional water use more accurate plant level details on reported water sources are collected see section 2 1 3 and provided in the ewed user interface power plants are also located within north american electric reliability corporation nerc subregions usdhhs 2020 for use in ewed s projection feature as described in sections 2 1 2 to 2 1 5 because of these extra steps of assigning geographical attributes ewed s facilities table is updated both using computer program written in python and manually cleaning the data at the time of submitting this article for publication there were 9961 facilities stored in ewed s database 2 1 2 generation tables monthly power plant electricity generation data are sourced from the eia s api useia 2020c for plant level data using the plant code pgm sys id given in ewed s facilities table generation data are published monthly via the api for power plants that report generation and there is often a lag time of several months for some power plants thus more recent data in ewed are incomplete and aggregated statistics for recent months should be used with caution in addition to monthly plant level generation ewed also queries yearly generation by fuel type and generation type prime mover combinations the dominant fuel type generation type combination for a given year is used to characterize the power plant for calculating water use at plants that do not report it because they are not larger than 100 mw and don t use fossil nuclear biomass and solar fuel types see section 2 1 3 for example total electricity generation at a single power plant may be dominated by natural gas gas turbines one year and then coal steam turbines the next year characterizing the power plant by its dominant generation from year to year allows for the categorization necessary to use appropriate water use coefficients as well as modeling future generation as explained in the next paragraph these characterizations are also used on the front end allowing the ui to both report plant types and filter by fuel type see section 2 2 1 ewed models projected monthly generation from 2020 to 2050 at individual power plants using the most recent set of plants currently 9961 and based on their dominant fuel type and monthly generation profile from the most recent complete calendar year currently 2018 annual projected generation data are sourced from the eia s apis for annual energy outlook 2019 which breaks down electricity generation into 14 fuel types solar is broken down by photovoltaic and thermal generation type 22 nerc subregions eia electricity market module regions across the contiguous u s conus and eight projection scenarios called cases in eia these annual generation values are first disaggregated to the monthly scale based on the most recent available e g 2018 monthly combined generation profile of all power plants of the corresponding fuel type and nerc subregion as in p r o j e c t e d m o n t h l y r e g i o n a l g e n e r a t i o n y m i j g e n y m i j g e n y i j g e n y i j where y and m are the future month and year respectively y and m are the most recent known month and year i is the fuel type of interest and j is the nerc subregion of interest these projected monthly generation regional pmrg values are then disaggregated to the power plant level according to each plant s most recent available contribution percentage for the corresponding future month as in p r o j e c t e d m o n t h l y p o w e r p l a n t g e n e r a t i o n y m i j k g e n y m i j k g e n y m i j p m r g y m i j where k is the power plant of interest while total generation by fuel type and region are thus consistent with eia projections we do not attempt to model any changes within these constraints more sophisticated power systems modeling efforts other than eia s capture individual power plant retirements additions and technology modifications based on projected market regulatory transmission and environmental factors eia s models do account for many of these factors in their various cases so the range of ewed s projections also capture this variability at the scale of emm regions still we see synergistic opportunities in future work to link ewed s water modeling environment with other power systems models that examine broader ranges of scenarios 2 1 3 water use tables monthly water withdrawal and consumption for individual power plants are assigned using one of three sources raw data dynamic coefficients or static coefficients flags of 0 1 or 2 are used in the database to indicate which method was used for each entry raw data are sourced from eia s thermoelectric cooling water data ms excel files 1 1 these files are prepared by eia to combine self reported data from power plants on eia forms 860 and 923 for water withdrawal and consumption values these files contain positive zero negative and blank entries including for different months for the same generator after consulting with eia staff we elected to only change blank entries to zero when a generator had a reported value in other months so that coefficient calculations would not result in mathematical errors useia 2020b which have not yet been made available via their api these monthly withdrawal and consumption values are assigned to power plants using plant code and the corresponding year and month flag 0 ewed also stores the eia reported values for cooling system type water type water source type and water source name which are viewable for individual power plants in the user interface as these eia water use files are only released yearly and with nearly a year of delay ewed also calculates more recent water use using generation based coefficients which are dynamically created using a database stored procedure for each power plant and all stored years that data are available flag 1 as an example for a power plant that has january 2019 generation data and sporadic eia water withdrawal data j a n 2019 w a t e r w i t h d r a w a l j a n 2019 g e n e r a t i o n s u m o f w a t e r w i t h d r a w a l f o r m o n t h s w i t h f l a g 0 s u m o f g e n e r a t i o n f o r c o r r e s p o n d i n g m o n t h s w i t h f l a g 0 likewise as these raw data only go back to 2014 prior water withdrawal and consumption values 2003 2013 are calculated using the dynamic coefficient for power plants which exist in the eia water use files as noted in table 1 eia water use data are limited to large power plants of certain fuel types resulting in less than 10 coverage of the total power plants in the u s for the remaining 90 of power plants ewed uses fuel type specific static withdrawal and consumption coefficients flag 2 derived from grubert and sanders 2018 discussed in section 1 3 for all fuel types except water i e hydropower we summed their lifecycle coefficients of water uses that take place at the power plant including where applicable conversion of all fuels to electricity i e cooling post conversion waste management for coal nuclear and biomass fuels as well as production of wind blade washing geothermal well augmentation solar pv panel washing and solar thermal mirror washing ewed s hydropower coefficients are based on previous work by grubert 2016 showing high regional variation in net evaporative losses from hydropower reservoirs their centroid based coefficients are assigned to ewed power plants based on location in a gis also following their logic that hydropower water withdrawal is qualitatively different from other power system withdrawals i e storing water temporarily and passing it through turbines versus withdrawing water and either consuming it heating it significantly ewed sets hydropower water withdrawal coefficients equal to consumption for the 90 of plants that use static flag 2 withdrawal and consumption coefficients generalized to fuel type not differentiated by prime mover or cooling type we had to characterize mixed technology power plants by their dominant fuel type as described in section 2 1 2 this generalization creates uncertainty in our water use estimates at the plant and regional scales for example a plant whose generation is dominated by natural gas turbines would be assigned a very low water use coefficient for all of its generation possibly masking intensive water use by a lesser generating technology like coal steam turbine some studies e g diehl and harris 2014 peer et al 2019 have assessed water use at the more specific generator level for individual years but likewise create uncertainty in applying coefficients from those sometimes very few known generators to others of similar technology this uncertainty is greatest for individual power plants and is somewhat limited in ewed by our application of fuel type specific coefficients to only smaller 100mw power plants which generally do not have as many generators of different types as larger power plants we expect that aggregating over larger spatial scales e g total water use within watersheds may reduce this uncertainty further additional uncertainty comes from applying static coefficients over all months while in reality withdrawal and consumption rates vary seasonally in reality summer rates tend to be higher due to lower thermal efficiencies and evaporation rates than in winter so our static coefficients likely underestimate summer water withdrawal and consumption values this uncertainty can be seen as a conservative underestimation when compared to water availability ewed models projected monthly withdrawal and consumption from 2020 to 2050 in the conus at individual power plants as the product of its projected generation section 2 1 2 and its most recent dynamic flag 1 or static flag 2 withdrawal and consumption coefficient this assumes unconstrained water availability which is of course not true in many cases but rather does allow for assessing the water demands of particular future regional generation portfolios based on recent performance these results can be used to verify and focus other power systems modeling efforts in places where projected increases in water use might be of concern 2 1 4 water availability tables to provide context for water withdrawal and consumption volumes at the watershed scale ewed sources water availability data from the u s forest service s water supply stress index model wassi wassi is a coupled water balance and ecosystem productivity model that provides monthly water supply and demand values at the 8 digit hydrologic unit code huc 8 scale termed watershed here across the conus caldwell et al 2019 duan et al 2019 the field flwout mm3 mo is used to describe huc 8 water availability which in this case means total monthly outflow after subtracting for consumptive water uses and including inflows from upstream watersheds ewed uses historic water availability data for 2003 2015 with thermoelectric water uses removed set to 100 in model inputs since ewed itself models power sector water use years 2016 2019 were not available from wassi at the time of this writing due to a lack of updated precipitation data needed to run the model ewed also sources future water availability data from wassi based on its use of statistically downscaled projections from 20 global climate models gcms used under the 5th climate model intercomparison project cmip5 caldwell et al 2019 each model contains results using two scenarios for future atmospheric greenhouse gas concentrations representative concentration pathways rcp 4 5 and 8 5 we also calculated a 20 model average for rcp 4 5 and rcp 8 5 making a total of 42 different monthly water availability projections for each conus watershed region 2 1 5 ghg emissions tables ewed sources greenhouse gas ghg emissions data from the epa s ghg restful data service usepa 2020b epa s ghg reporting program ghgrp has since 2011 collected yearly greenhouse gas co2 ch4 and n2o emissions data which are self reported by power plants and other direct sources that emit at least 25 000 metric tons of carbon dioxide equivalent co2e per year ghgrp facilities are identified by a unique ghgrp facility id and in only some instances reference an frs id that can be linked to ewed s facility table thus to connect the emissions tables to facilities tables we rely on a ghgrp facility to power plant crosswalk provided by the ghgrp usepa 2020c as new power plant facilities are added to ewed s facilities table we update the crosswalk by cross referencing plant names and other attributes with ghgrp tables yearly ghg emissions quantities for each power plant are disaggregated to monthly emissions by creating a yearly generation based emissions coefficient that is again multiplied by monthly generation emissions coefficients are also used to model monthly emissions before 2011 and after the most recently available data currently 2018 ewed s dynamic emissions coefficient procedure creates coefficients for the minimum and maximum years that a power plant exists in the ghgrp sourced emissions table any previous or subsequent respectively monthly generation for that power plant is multiplied by the min or max year coefficient to produce monthly emissions values similar to the water use tables ewed models projected monthly ghg emissions from 2020 to 2050 in the conus at individual power plants as the product of their projected generation section 2 1 2 and the max year dynamic emissions coefficient currently 2018 2 2 application server layer the application server layer was built as a dynamic web application using spring boot spring 2020 communication between the presentation layer and the application server layer is through representational state transfer rest application programming interfaces apis the application server layer transposes the rest request into database queries and returns the query results to the presentation layer we use a database oriented approach in the design and implementation of ewed we have evaluated different processing weight assignments between application server layer and the database server layer based on a comparison of time for executing a task we found out that using database queries for computation such as aggregation at the database layer are more efficient than using java programming to do the same task at the application layer as a result we delegated most of the computation to the database system we designed database queries that calculate values join multiple database tables group results and order outputs we avoided allocating computations especially complex computations to the application server at static time stored procedures and views are used to clean data calculate derived data and update data at run time to render the presentation according to ui inputs a request is sent from the presentation layer to the application layer by calling a rest end point the application layer converts the requests into database queries once the query result returns the application layer wraps the result and return it to the presentation layer 2 2 1 apis communication between the front end and the back end is enabled through rest apis the presentation layer sends get requests to the back end based on a user s input from the ui the application server processes the requests and forms database queries upon the results returned from the database the application server sends the results of the get request back to the presentation layer the main advantage of this approach is that it allows the design and implementation of different architecture components to be loosely coupled i e the front end and the back end could be developed concurrently this set of apis mainly serves the purpose of internal communication among architectural components which therefore provides more details than what the user needs in addition we built a public facing web service via a virtual node provided by the project funder the us epa exchange network this web service provides plant level data including power plant attributes from the facilities table as well as monthly generation emission water consumption and water withdrawal as described above the api provided by the web service allows users to filter the data by various parameters such as month year state huc and plant name ewed 2020 users can further aggregate the plant level monthly data to any other level such as huc state for any time duration 2 3 presentation layer the front end is designed and implemented using typescript based on the angular framework which is a component based web development environment angular 2020 our design consists of a combination of the waterfall model and the agile method in our agile development process potential user requirements of the ui were collected and modified through many sprints from using paper adobe xd to a prototype using javascript in the agile method requirements can be changed added and deleted due to the new understanding of the system the changes are reflected in the sequence of sprint implementations the javascript version is the final product of the agile development after the javascript version was deployed and tested feedback from potential users was collected and incorporated once the user requirements were finalized design implementation and testing were performed following the waterfall model the final presentation layer discarded the javascript prototype implementation and it was built using angular 10 2 4 system testing we conducted testing following sommerville 2016 including both white box and black box testing unit testing integration testing release testing performance testing and regression testing white box testing generally is a procedure that tests the internal structure of the computer program while black box testing tests the functionality without knowing the programming details unit testing generally is performed on an individual unit or component of a system we unit tested the database layer by testing the functionality of the views and the processing logic of the stored procedures by data comparison and verification with the actual values stored in the database we also unit tested at the application layer by creating various requests to all end points and verifying them with database query results we further unit tested at the presentation layer by exercising each functionality and all user input conditions integration testing generally tests the combination of individual components our integration testing focused on communications between different architectural components centered with https get requests release testing generally tests a system outside of the development team for the purpose of releasing the system to users our release testing not only covers the testing of functionalities but also heavily on boundary testing and invalid inputs performance testing generally tests if the system can process its intended load within an acceptable range execution time because of the diversity in software applications within the discipline there is no specified threshold for acceptable performance in addition differences in the hardware e g cpu memory size that hosts the software affect software performance our performance testing was conducted both at the component level and immediately after components were integrated which identified improvement potential in our overall system we modified our system accordingly to improve the performance to our satisfaction regression testing generally ensures software continues to perform after making changes our regression testing was performed at all phases to ensure the quality and performance of the final system as a summary the main purpose and outcome of our testing is to ensure that the software functions as designed and as efficiently as the user experience demanded 3 results 3 1 u s scale ewed displays results in a range of ways to suit different user needs and are also downloadable for other use cases via a companion publication fulton and jin 2021 currently in review with data in brief one relevant use case for this article is to compare ewed results with previous national scale energy water assessments which were discussed in section 1 3 for reference year 2015 ewed estimates that the u s power sector withdrew 240 billion cubic meters bm3 and consumed 6 0 bm3 of water associated with 4 0 tw hours of electricity generation fig 3 this withdrawal result is similar to that of the eia cooling water dataset while ewed s consumption result is similar to that of the usgs compilation likely due to the difference in methods and coverage between ewed and those two assessments which are shown in table 1 however the fact that ewed s total generation is far greater than either of these sources indicates that the additional power plants activities captured by ewed may not be very water intensive with a nearly equivalent generation quantity captured in the usc ucb study ewed estimates 12 higher water withdrawal but 25 lower water consumption even though coefficients used in ewed were based on the usc ucb study these differences in results are attributable to methodological choices some of which were highlighted in section 2 1 3 as well as changes in the u s generation portfolio between 2014 and 2015 overall that ewed estimates are comparable with the upper ends of these four previous assessments indicates that its methods are comprehensive of existing methods and likely fill in gaps in existing data sets ewed may therefore be useful for future inventorying of power sector water use across the u s ewed s relatively long time series and monthly resolution provides additional insight into how power sector water demands have fluctuated from year to year as well as throughout the year at the national scale we estimate that total yearly water withdrawal and consumption have declined over the 18 year period represented in ewed s historical water use tables fig 4 withdrawal has trended consistently downward over this period a finding which concurs with 5 year trends found in the usgs compilation data and are attributable to closure or idling of more water intensive power plants dieter et al 2018 consumption has also declined over this time period likely due to similar factors but since 2015 has increased as many power plants began converting cooling systems from once through to recirculating to comply with a 2014 usepa regulation designed to reduce impingement and entrainment of aquatic organisms usepa 2020d monthly fluctuations show a pattern of peak water demands in the power sector occurring in july and august with a second smaller peak occurring in december and january this pattern generally parallels month to month electricity generation where peaks coincide with summer cooling needs and winter heating needs a larger portion of which are met directly with fuels such as natural gas fig 5 exceptions to this paralleling are worth noting and potentially investigating in the context of particular watersheds 1 a spring season rise in consumption or shoulder that is earlier than withdrawal which may have disproportionate impacts on spring runoff in some watersheds fig 5 line a and 2 a higher mid summer peak in both consumption and withdrawal relative to generation which indicates higher water use rates per mwh of generation at a time of year when runoff in many watersheds is at its lowest point fig 5 line b the month to month relationships between generation consumption and withdrawal vary widely among u s states counties and watershed regions and are made visible at these scales by ewed s ui discussed below in section 3 2 ewed s projections of water consumption and withdrawal in the conus power sector from 2020 to 2050 are shown in fig 6 and are based on the eight cases of the eia annual energy outlook 2019 useia 2020d water consumption continues to rise from current values by 13 for the reference case over the 30 year period increases in the other seven cases ranges from 6 5 low resource technology i e reduced oil and natural gas availability to 15 high macroeconomic growth which represents a range of 440 million m3 mm3 in 2050 rounded to two significant figures to account for uncertainty the mix of fuel types and generation types are important drivers of the variation in outcomes in the reference case for example the total increase of over 740 mm3 in water consumption is driven primarily by geothermal and natural gas power plants which increase by almost 290 and 37 respectively the increase is somewhat offset by declines at coal 12 and nuclear 10 power plants in the low rt case however the somewhat lesser consumption increase of 380 mm3 is driven solely by geothermal power plants while natural gas plants actually decline by 27 as extraction of unconventional natural gas becomes more challenging consumption at coal and nuclear power plants in the low rt case remains steady this range of results suggests that the mix of fuel types and generation types can have important effects on future water consumption in the power sector such findings are consistent with previous studies e g macknick et al 2012 although the range of our results is lower due to less variation in eia cases compared scenarios used in other power systems models water withdrawals in the power sector are projected to continue declining below current levels until the 2030s when in some cases they are projected to begin rising and return to near present levels by 2050 fig 6 because water withdrawals are so much larger than consumption in absolute terms the variation in cases is also larger with a difference of over 16 bm3 by 2050 these variations are also driven by fuel type and generation type differences for example the high price case shows the deepest overall reductions of nearly 15 bm3 between 2020 and 2050 driven by decreases at nuclear 21 and coal 14 power plants and only partially offset by increases at natural gas plants 14 in the high macro case overall water withdrawals return to within 99 of 2020 levels in 2050 as increases at natural gas plants 35 outweigh the more modest decreases in coal 6 and nuclear 16 linking the time series results from of ewed s historical modeling fig 4 to projections fig 6 results in a disconnect which is attributable to three factors first data for 2019 are incomplete in ewed s historical system due to the reporting lag from the eia for some power plant generation see section 2 1 2 using ewed s projection modeling to fill this grey area is not appropriate as 2019 data are regularly updated and as soon as data are complete will provide a more accurate picture of power sector water use second there are structural differences in historical versus projected generation data sourced via eia s api eia s historical data cover all power plants larger than 1 mw in capacity in the electric power commercial and industrial sectors while its projected data cover the electric power sector only resulting in 1 3 lower generation totals in ewed s projection system starting in 2020 third eia s projections only cover conus states thus omitting alaska and hawaii and further lowering ewed s overall projections compared to its historical results despite these differences and time series disconnect ewed s historical and projection systems independently offer unique opportunities to both compare to other national energy water assessments as well as to conduct new assessments and visualize energy water relationships at other scales 3 2 ui enabled scales ewed s modeling structure based on individual power plant activities allows for far more granular spatial resolution and analysis of the types of results presented in section 3 1 we first present ui results and features at the state level while the remainder of this section describes smaller scale results and more advanced ui features using the example of california the database and processing requirements of displaying these granular data at the national level are not feasible in the ui the ui allows users to query the database using text input fields or mouse clickable fields in the graphical display which includes a map table and various chart formats fig 7 input fields and graphical displays are synchronized at each input step and display filtered results consistently across the platform the map allows users may toggle or click on regions to change the spatial scale of the query to states watersheds counties or individual power plant facilities the latter three of which are not available for the entire u s the map displays regional results as choropleth color intensities divided into 10 bins and power plant point results as bubble sizes divided into 5 bins each using the jenks natural breaks classification method users may also toggle map displays between water consumption withdrawal and emissions results the table displays sortable numerical results and provides a link to download a csv file for the query and allows users to click on individual entries to change the query tabs allow users to view the queried results as charts including a monthly time series line chart not available for the entire u s or broken down by fuel type as a pie chart or bar chart which can also be downloaded as png or pdf files fuel type also serves as a query filter and updates results across the entire platform by selecting a state users can display results at more granular spatial scales including watersheds counties and individual power plant facilities fig 8 shows an example for california where the default map view displays watershed regions with aggregated results based on power plants within those regions users can toggle the map display to county or facility scales without affecting the query but the table not shown will change to display counties or facilities respectively the pie chart tab displays results for all of california broken down by fuel type in order to draw attention to the relative contribution of different fuel types to generation consumption withdrawal and emissions in the case of california a user may take note of the stark difference natural gas makes up the largest share of statewide generation 46 and emissions 92 but water consumption is dominated by geothermal 45 and withdrawal is dominated by nuclear 53 absolute values can be seen by hovering the cursor over pie wedges or by shifting to the bar chart tab which displays results on a log scale to identify the source of these outsized water uses a user could filter by fuel type and also toggle the map to view individual facilities in the case of california about 40 of geothermal water consumption occurs at one of the state s 32 facilities the geysers and all of nuclear water withdrawal occurs at the state s lone nuclear plant diablo canyon which uses saltwater zooming in to the watershed scale allows users to see power sector water use in relation to modeled water availability either historic or projected according to the selected climate scenario and gcm see section 2 1 4 fig 9 shows an example california watershed the santa ana river with results from ewed s projections for the year 2050 the map displays the watershed delineation with individual power plant facility locations as bubbles sized relative to the selected result consumption withdrawal or emissions clicking on an individual facility displays a pop up with associated power plant and cooling system attributes as well as activities including a monthly time series a monthly time series of results for the entire watershed are shown in the line chart along with monthly water availability projections the example of the santa ana river watershed in 2050 illustrates the situation discussed in section 3 1 where mid summer minimum streamflow coincides with peak water consumption and withdrawal in this case default projection inputs result in water use reaching within 40 water availability but selecting different energy scenario cases climate scenarios and gcm inputs can result in water use actually exceeding water availability by several times for example all four gcms deemed priority models for california s most recent climate change assessment pierce et al 2018 result in water consumption exceeding mid summer water availability users are encouraged to examine a range of scenarios but such visualizations nevertheless draw attention to the impact of water scarcity on future electricity generation and vice versa in a particular context 4 discussion the manifold ways that ewed presents results suggests that it can serve diverse user needs in both drawing attention to trends and potential challenges at different scales in the u s energy water climate nexus as well as supporting more integrative management and decision making ours is not the first assessment of energy water interdependencies yet ewed does represent a first attempt to our knowledge to leverage computer science methods to model such interdependencies in a way that is as automated timely integrative multi scaled in both spatial and temporal dimensions and is user friendly indeed ewed s novel design is built almost entirely on existing assessment methods and data and its results correspond with aspects of previous work further ewed s granular and timely results provide insights at multiple scales can be used to ground truth more complex modeling projections of the u s power sector e g miara et al 2019 voisin et al 2020 where ewed lacks in terms of capturing power system dynamics i e grid market and policy complexities it can complement energy water modeling in terms of visualizing spatial and temporal dynamics of water use as well as emissions in future work we aim to expand ewed s interfaces with such power systems models as well as hydrologic models and other user specified inputs compared to usgs thermoelectric water withdrawal estimates showing declines in water use from 2005 to 2010 and 2015 ewed s results parallel these rates of decline but are consistently about 20 higher in absolute terms this finding suggests that the usgs compilation which is the longest running and perhaps most official estimate of water use in the nation regularly overlooks a substantial amount of water use in the power sector and which is likely not accounted for in other water use sectors ewed results indicate that this unaccounted for water use is largely associated with fuel types that would likely be covered by usgs accounting methods and only partially associated with non thermoelectric and renewable fuel types further analysis would be needed at the county scale the smallest spatial unit reported in usgs data to determine the degree to which fuel type power plant size assessment method or other variables contribute for the overall difference the usgs along with other federal agencies has been tasked by the u s congress to establish an ongoing national water availability and use program referred to as the water census evenson et al 2018 critical to this mandate are improvements in both the temporal and spatial resolution of water use across all sectors the power sector presents numerous obstacles to these goals including inconsistent and incomplete coverage in reporting programs as well as reporting delays recent analysis by usgs harris and diehl 2017 shows that a detailed modeling approach can complement the bottom up data compilation approach of reporting programs because ewed uses individual facilities and monthly time step as its units of analysis it and related modeling efforts can help support national water census goals and play a more central role in describing trends and forecasting potential challenges in both energy and water systems ewed s novel and accessible user interface also makes visualizing and understanding energy water climate issues viable at much smaller scales which in some cases are better tailored to managing energy water climate challenges water resources management in particular occurs at local to regional scales from watersheds and counties to river basins and interstate collaborations ewed s water availability features call attention to the dynamics of water availability at these scales power system management too happens at scales ranging from local utilities to regional grid balancing entities these overlapping and yet often disparate jurisdictions all play critical roles in managing interdependent water and energy systems identifying common management goals e g see voisin et al 2019 for a qualitative multi scale resilience framework can be synergistic but often face a lack of integrative information cross platform modeling tools like ewed can serve such integrated management efforts to help identify and strategize around complex energy water challenges energy water challenges are also not unique to the u s context global climate change driven temperature increases and water scarcity demand the attention of energy system managers everywhere the need to monitor integrate analyze and visualize energy water data is therefore pervasive but currently lacking and disjointed cui et al 2020 larsen et al 2019 ewed may serve as a model for how to do this in other contexts as well as point to the need for underlying data to be publicly available and accessible 5 conclusions the u s power sector has been highly dynamic and is likely to remain so in the future as energy policies continue to address immense societal challenges like climate change national security and economic transitions our results are consistent with previous water energy assessments e g miara et al 2017 tidwell et al 2016 voisin et al 2020 showing that water resources have and will continue to play an essential role as a critical input to energy systems at the same time water resource systems are already being impacted by climate change and may be an increasingly limiting factor for power systems as well as a source of vulnerability recent transitions in the u s away from coal and nuclear fuels while not driven by water concerns have so far eased the power sector s thirst for water however even a potential wholesale transition to renewable energy sources may still conflict with water availability and management constraints as hydropower geothermal power solar thermal and biomass power plants all have high water demands understanding the water implications of past and future energy transitions requires integrative and accessible information and tools like ewed only then can we address the demands of a carbon constrained world without running afoul of its water constraints funding information this work was supported by the united states environmental protection agency exchange network grant program grant number os 83923301 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements author contributions j f conceived of the project and lead its implementation and the writing of this paper y j oversaw the project design and workflow and contributed to the writing of this paper we are grateful for the contributions of many student assistants that helped with various aspects and stages of the project in alphabetical orders tejaswini bhorkar gaurav bora trent buchanan aaron enberg jasmie guan priya gundlupet khoi hoang priyanka makwana and karan mitra we are also thankful for the administrative support of california state university sacramento s office of research affairs and university enterprises incorporated 
25804,identification of complex systems often face structural modelling errors and limited or low quality data which hinder statistical characterisations an alternative is the set membership approach where errors are assumed unknown but bounded set membership estimation aims to find a feasible parameter set fps which produces model outputs that fit within given error bounds most algorithms are limited to linear models small number of parameters or to discrete approximation of the fps these limitations hinder parameter estimation for relatively complex systems we present an efficient sampling based set membership algorithm with low computational complexity that improves the coverage of a discrete approximation of the fps characterised by hyperspheres from a voronoi diagram of the parameter space additionally we suggest a measure for set membership accuracy based on deviations between the given error bounds and the feasible model output set our algorithm provides a balance between accuracy and computational complexity and a tool to investigate practical identifiability keywords set membership voronoi diagram hyperspheres uncertainty propagation 1 introduction mathematical models for biological and environmental systems often combine a priori knowledge and experimental data requiring a calibration step to estimate the unknown parameters frequently uncertainty of parameter estimates is based on a statistical characterisation of the error in experimental data however biological and environmental systems often present the problems of structural modelling error and limited availability or low quality of experimental data sets therefore most often a statistical characterisation of the error is inappropriate norton 1987 keesman 1990 walter and piet lahanier 1990 in this context of structural modelling error with limited and uncertain data an alternative to the statistical characterisation is a so called set membership sm characterisation where the errors are assumed to be unknown but bounded in the sm approach ranges of expected system outputs are predicted for each time instant instead of single values these ranges account for the effect of uncertainty in data and model outputs norton 1987 keesman 1990 walter and piet lahanier 1990 milanese et al 1996 diniz 2013 given a p dimensional parameter vector ϑ and the error between measurements y and model outputs f ϑ defined as e ϑ y f ϑ in a set membership approach the error is assumed to be point wise bounded by a fixed positive number i e e ϑ ϵ within the sm approach set valued estimation algorithms aim to find an exact or approximate feasible parameter set fps the fps produces model outputs that fit inside the error bounds at all times f p s ϑ r p y f ϑ ϵ fig 1 for overviews see milanese et al 1996 keesman 2003 norton 2003 walter 2003 keesman 2011 cerone et al 2014 the simplest case of sm algorithms are based on models that are linear in the parameters this type of algorithms is used in signal processing for e g adaptive filtering providing reduced computational complexity by updating parameter estimates only when error bounds are exceeded diniz 2013 applying these methods to non linear models common in biological and environmental systems would introduce additional linearisation steps in contrast sm parameter estimation of non linear dynamic systems is frequently applied to solve the problem of uncertain and limited data common algorithms rely on either interval based or sampling based methods for example using an interval based method marvel and williams 2012 proposed a framework for sm estimation and experimental design to deal with small data sets in biological systems based on set inversion via interval analysis sivia jaulin and walter 1993 similarly rumschinski et al 2010 proposed a partition algorithm for sm estimation and model invalidation to discriminate between competing models in biochemical reaction networks interval based algorithms can characterise the fps for linear and non linear models and are capable of characterising non convex parameter sets rumschinski et al 2010 common in biological and environmental systems the fps characterised by interval based methods is a collection of boxes with sizes determined by a desired accuracy in general they consist of a large number of boxes hypercubes that define the fps boundary ca 20 000 boxes for a lotka volterra test model with two estimated parameters by sivia marvel and williams 2012 the number of boxes increases with the number of parameters and when higher accuracy is required jaulin and walter 1993 furthermore the number of model evaluations is proportional to the number of boxes characterising the fps resulting in an exponential computational complexity with respect to the number of parameters raïssi et al 2009 i e a computational time with an order o n boxes p the fps characterised by interval based methods provides an accurate mathematical description that can be used to simulate a model and its prediction uncertainty however defining a large number of boxes and simulating from them is computationally demanding in other examples using sampling based methods keesman 1990 proposed the characterisation of the fps by ellipsoids for more effective sampling van straten and keesman 1991 applied the so called monte carlo set membership algorithm mcsm to calibrate a model for lake eutrophication and to simulate its prediction uncertainty from the resulting discrete fps similarly nurulhuda et al 2017 applied a latin hypercube sm algorithm for a flooded rice system returning a discrete approximation of the fps in a six dimensional space given a fixed sample size per iteration these algorithms have a linear computational complexity irrespective of the number of parameters i e a computational time with an order o n sample the fps characterised by sampling based methods is less computationally demanding than interval based methods however random sampling may require a large number of iterations therefore low computational times and a full coverage of the fps cannot be guaranteed additionally models of complex biological and environmental systems are often split into sub models see for example van straten and keesman 1991 mohtar et al 1997 mocenni and vicino 2006 and reyes lastiri et al 2018 uncertainty in the parameter estimates often propagates through sub models in uncertainty propagation studies the statistical approach uses methods such as first order variance propagation or monte carlo simulation first order variance propagation is hindered by the non linearity of complex systems similarly monte carlo simulation which requires sampling from a probability density function pdf is hindered by the uncertain and limited nature of experimental data which may lead to inadequate pdf characterisation alternatively in the sm approach interval based methods preserve the uncertainty characterisation from the calibration step but they are hindered by computational complexity in contrast sampling based methods have less computational complexity but simulating a discrete fps without full coverage and extending discrete feasible model output trajectories in time beyond the calibration interval may lead to falsified predictions with underestimated uncertainty consequently given the aforementioned limitations it is desired to have an efficient sampling based algorithm that closely approximates the fps while preventing underestimation and overestimation of uncertainty propagation therefore the objective of the paper was to investigate and evaluate a novel set membership estimation algorithm that meets the requirements of an uncertainty propagation study of complex systems with limited or low quality data 2 methods the sampling based sm estimation algorithm proposed in this paper aims at efficiently characterising an approximate fps using a relatively low number of elements additionally deviations from error bounds are quantified the algorithm was evaluated in four test cases the algorithm was developed in python 3 5 using the scipy functions for delaunay triangulation and voronoi diagrams based on the qhull library barber et al 1996 the algorithm tests were run in the ipython console of winpython 3 5 in an intel core i7 4790 cpu computer at 3 60 ghz with 16 0 gb ram operating on windows 7 the models were simulated with the odeint function in the scipy package v 0 18 1 of python using its default parameters 2 1 algorithm we propose characterizing the approximate fps based on hyper spheres centred at voronoi vertices parameters are assumed time independent the voronoi diagram is generated using all known unfeasible parameter vectors as seeds thus excluding them by definition using spheres complex fps shapes can be approximated by two data vectors centre coordinates c and corresponding radii r therefore non convex parameter sets from non linear models can be characterised with a relatively low number of elements random sampling from spheres of the characterised fps is computationally simple and can then be used to simulate the model for t 0 t where t is the final simulation time including the calibration time interval such sampling based method from a low number of elements allows for relatively low computational times convergence of the algorithm is not defined in the parameter space r p but in the model output space in terms of deviations between the approximate feasible model output set fmos and the data error bounds for all measurement instants in this way although sampling based the algorithm tries to prevent under and overestimation of prediction uncertainty 2 1 1 voronoi diagram and delaunay triangulation in a voronoi diagram fig 2 a space is partitioned into regions based on the distance to a specified set of points for each of these points called seeds there is a corresponding voronoi region where any point is closer to its seed than to any other seed the voronoi diagram for a set of points is dual to its delaunay triangulation in a delaunay triangulation no point is inside the circumcircle of any triangle the triangle circumcentres are also the voronoi vertices our algorithm is based on a voronoi diagram from the collection of all known unfeasible parameter vectors thus excluding them from the approximate fps 2 1 2 definitions for the algorithm implementation we define ϑ f and ϑ u as a feasible and unfeasible parameter vector respectively ω ϑ f and ω ϑ u are then the collections of all known feasible and unfeasible parameter vectors we also define s ϑ as a random sample of parameter vectors from the set of spheres in r p these sampled parameter vectors are evaluated individually to split the sample into a feasible s ϑ f and an unfeasible s ϑ u set of parameter vectors furthermore we define two types of deviations to measure accuracy of the approximate fps at each measurement instant k overestimation oe k is the maximum deviation between model output f ϑ and error bounds related to ϑ u sampled in the fps similarly underestimation ue k is the maximum deviation between model output f ϑ and error bounds related to all known ϑ f thus for measurement instants k 1 m we define 1 o e k max i u f ϑ u i u k y k ϵ max i u y k ϵ f ϑ u i u k u e k min i f y k ϵ f ϑ f i f k min i f f ϑ f i f k y k ϵ notice that oe k is calculated for a sample of unfeasible parameters with size n s ϑ u obtained from the approximate fps in each iteration i e i u 1 n s ϑ u in contrast ue k is calculated for the set of size n ω ϑ f of all known feasible parameters up to the current iteration i e i f 1 n ω ϑ f fig 3 illustrates these definitions total oe and ue are defined as the sum of deviations for all measurement instants m eq 2 2 o e k 1 m o e k u e k 1 m u e k finally we define the scalar valued weighted deviation wd from oe and ue oe is weighted for the number of ϑ u found in a sample inside the collection of spheres s ϑ u i n at the corresponding iteration ue is weighted for the number of ϑ f found in a sample outside but near the collection of spheres s ϑ f o u t at the corresponding iteration consequently 3 w d n s ϑ u i n n s ϑ i n o e n s θ f o u t n s ϑ o u t u e 2 1 3 implementation the algorithm consists of a main function estimate and four sub functions initialize generate spheres sample and evaluate implementation in pseudocode is shown in algorithms 1 and 2 the functions are illustrated in fig 4 and described below supporting functions are provided in algorithm a 1 in the appendix the approximate fps is characterised by sets of centres and radii of spheres c r 1 initialize fig 4 1 the sample set is initially defined as a hyper cube grid ω ϑ ini latin hyper cube sampling is applied iteratively on the grid ω ϑ ini evaluating n ini points per iteration sampled points are evaluated as feasible or unfeasible initializing the sets ω ϑ f and ω ϑ u sampling and evaluation continues until a desired size of ω ϑ f is obtained the sets are subsequently normalized to ω θ f and ω θ u based on the minimum and maximum feasible coordinates found in the sample normalization helps maintaining the approximate fps near the range 0 1 for all parameters if not enough ϑ f or ϑ u are found the algorithm must be restarted this step is purely random and therefore governed by the choice of parameter ranges to decrease randomness it is best to have prior knowledge on the model behaviour and parameters with physical meaning constrained to a certain region if no prior knowledge is available a large ω ϑ ini with large n ini can be used which is subsequently narrowed by trial and error using this step alone 2 generate spheres fig 4 2 a voronoi diagram is generated using the scipy function scipy spatial voronoi the scipy community b with ω θ u as seeds the voronoi vertices generated constitute sphere centres by definition those spheres exclude any known θ u given minimum and maximum radii r min r max and constraints based on prior knowledge ϑ min ϑ max an optional filter can be applied to remove spheres with r r min and r r max and spheres with any centre coordinate c j ϑ min j and c j ϑ max j subsequently spheres that do not contain any θ f are removed finally redundant spheres are also removed i e spheres containing only θ f included in larger spheres these filters ensure that the number of spheres is kept low and their size is kept large reducing memory use in the first iteration the set ω θ u is reset to contain only θ u on which spheres with θ f are circumscribed this reduces the amount of data stored and focuses the next steps on the region where θ f are found 3 sample fig 4 3 two random uniform samples of parameter vectors with size n s are obtained from the set of spheres both samples are achieved by combining a normal distribution and its inverse madan 2017 the first sample s θ in is obtained inside the spheres to search for new θ u the second sample s θ out is obtained in a ring outside but near the spheres with radii ranging from r to 2r to search for new θ f redundant θ sampled from overlapping spheres are discarded helping both samples to concentrate near the approximate fps boundary to improve its accuracy 4 evaluate fig 4 4 feasibility of sampled parameter vectors is evaluated for both samples s θ in and s θ out weighted deviation wd is calculated from eqn 3 the algorithm stops if wd wd tol otherwise unfeasible parameter vectors found inside the approximate fps s θ i n u are appended to the set ω θ u feasible parameter vectors found outside the approximate fps s θ o u t f are appended to the set ω θ f and a new iteration starts algorithm 1 vorsetmembership image 1 algorithm 2 vorsetmembership continue image 2 2 2 test model cases the algorithm was tested in four cases based on three non linear dynamic models with biological and environmental components a lotka volterra population model a microbial growth and degradation with under monod kinetics and the grass growth model in grasim mohtar et al 1997 for each case artificial noisy measurements were generated around the base model outputs using a zero mean uniform distribution with ϵ 1 4 y where y is the time averaged value of the model output all model cases were initialized in parameter space 0 5ϑ 1 5ϑ where ϑ is the vector of nominal reference parameter values used to generate the artificial noisy measurements the initial number of feasible parameter vectors required was n ω ϑ f i n i 15 sampling size for each iteration was n s θ in n s θ out 50 details for each test case are provided in table 1 see also appendix b for a list of symbols for each model 2 2 1 lotka volterra the lotka volterra model is a canonical biological model that describes the dynamics of predator prey populations it is represented by the differential equations 4 x 1 x 1 p 1 p 2 x 2 x 2 x 2 p 3 p 4 x 1 where the states are prey x 1 and predator x 2 populations and the four parameters p represent rates of population change due to growth death and predation this model has been used previously to test algorithms for set membership parameter estimation marvel and williams 2012 raissi et al 2004 we used the lotka volterra model to analyse the algorithm behaviour on two identifiable cases bounding one state x 1 and two states x 1 x 2 2 2 2 growth with monod kinetics microbial growth and degradation with monod kinetics is represented by the differential equations 5 s μ m a x x y s k s s x μ m a x s k s s x k d x where the states are concentrations of substrate s and bacteria x with interactions described by four parameters related to growth decay yield efficiency and substrate limitation the monod kinetics is theoretically identifiable from noise free measurements but its parameters cannot be uniquely identified from noisy measurements holmberg 1982 therefore we used this model to analyse the algorithm behaviour on one unidentifiable case 2 2 3 grasim the grass growth model in grasim splits the plant into components for storage and structure mohtar et al 1997 6 w s f p f s r f g f m r w g f g f s 8 p t w d m w g 0 4 with carbon mass flows for photosynthesis f p shoot respiration f sr structure growth f g maintenance respiration f mr and senescence f s the model output w dm is the dry matter of plant structure mass assuming 40 c content in dry matter see appendix c for the detailed model we used the grasim model to test the applicability of our algorithm on a larger model aiming towards implementation in biological and environmental systems commonly estimating multiple parameters in one model is preceded by a sensitivity analysis to find the most dominant parameters if however more than four dominant parameters are found the computational complexity of the algorithm will further increase for a given wd tol and fps coverage consequently for higher dimensional parameter cases accuracy of the algorithm can be relaxed by increasing wd tol and n ini ultimately leading to the mcsm algorithm by keesman and van straten 1990 demonstrated on a 16 dimensional parameter case by van straten and keesman 1991 3 results and discussion the main results for each case are shown in table 2 due to the sample based nature of the algorithm results varied between runs but the behaviour and final accuracy remained consistent it is important to note that in spite of the geometrical relation the proposed characterisation by spheres is different from the characterisation by ellipsoids the spheres proposed here are solely based on the voronoi tessellation of θ u and do not provide a direct description of the direction or shape of the approximate fps in contrast ellipsoids use tools like principal component analysis pca of θ f to describe the directionality of the approximate fps the choice of wd tol is arbitrary it depends on previous experience with the model and on the desired accuracy notice that we assumed an error of fixed width for all artificial measurement instants which constitutes a worst case scenario for underestimation ue 3 1 case 1 lotka volterra 1 output and 2 estimated parameters for case 1 we assumed that only x 1 was measured and bounded y x 1 the approximate fps was characterised by a maximum of 10 spheres fig 5 1 the algorithm converged after a maximum of 14 iterations 1400 model simulations deviations between fmos and error bounds show a negligible oe fig 5 2 however the convergence history shows a stagnant underestimation fig 5 3 which means that the model cannot reproduce the entire error bounds which in general is the case nonetheless wd converged because there were no new θ f found outside the sphere set in the last iteration uncertainty propagation from ω θ f on x 2 fig 5 4 is similar to the one obtained by the sivia algorithm marvel and williams 2012 however due to random sampling any ϑ u in the approximate fps could introduce a deviation in x 2 beyond the propagation from ϑ f this deviation and the uncertainty propagation itself can be avoided by bounding x 2 we show this in the next case 3 2 case 2 lotka volterra 2 outputs and 2 estimated parameters for case 2 we assumed error bounds on both states y x 1 x 2 t the approximate fps was characterised by a maximum of 11 spheres fig 6 1 the algorithm converged after a maximum of 15 iterations for a total of 1500 model simulations when bounding two states there is a reduced degree of freedom with respect to case 1 which results in a fmos with smaller intervals at each measurement instant k and thus larger ue fig 6 2 however as expected the bounds on x 2 led to a smaller oe on this state compared to case 1 3 3 case 3 biodegradation and growth with monod kinetics 1 output and 4 estimated parameters unidentifiability we tested the algorithm under a well known case of an unidentifiable model structure we assumed that only bacterial biomass was measured and bounded y x the estimation of all four parameters in the monod kinetics model resulted in an approximate fps that extends indefinitely with subsequent iterations fig 7 1 the projection of parameter combination μ m a x k s shows an elongated set because estimates of these parameters are highly correlated this result is in accordance with holmberg 1982 similarly the projection of parameter combination y k d also shows an elongated set indicating unidentifiability practical unidentifiability of this model is also reflected in high oe peaks resulting from continuously finding new areas with θ f that must be reshaped to exclude θ u fig 7 2 and 7 3 therefore high peaks of oe through convergence history combined with a fps that extends far beyond the normalized coordinates 0 1 constitute a novel test for practical identifiability these peaks also illustrate the opportunity to improve the mathematical rigour of the algorithm by developing a function to describe the convergence trend for example by a moving average filter of the historical oe and ue 3 4 case 4 crop growth model 1 output bounded and 4 estimated parameters finally we tested the algorithm on a model with higher complexity grasim steps often trivialized prior to calibration of complex models are a sensitivity analysis and the implementation of prior knowledge parameter constraints we performed a sobol global sensitivity analysis on the model sobol 2001 using the python package salib herman and usher 2017 the sensitivity analysis revealed that six out of the ten model parameters have a global sensitivity coefficient at least one order of magnitude larger than the rest from those six parameters a combination of four parameters is chosen with the lowest second order sensitivity coefficients reflecting low correlation in the parameter estimates this pre selection helps improving model identifiability the selected parameters were structural specific leaf area a senescence rate β extinction coefficient of canopy k and photosynthetic fraction available for growth φ subsequently we defined parameter constraints for the algorithm based on physical definitions and on reported ranges in literature mohtar et al 1997 zhai et al 2004 these constraints limit the region where spheres will characterise the approximate fps a 0 002 0 008 β 0 02 0 1 k 0 25 0 90 and φ 0 75 0 99 in this case simulation time of the model governs computational time in the algorithm implementation ca 2 min per iteration therefore we set maximum iterations to 100 the algorithm converged to wd tol 0 5 in 2 out of 5 runs in case of convergence the approximate fps was characterised by a maximum of 430 spheres in 88 iterations the approximate fps is bounded within the constraints provided fig 8 1 notice that the projection of a k is a non convex set in a narrow space which can still be characterised by the algorithm but requires a relatively high number of spheres this projection also indicates a hyperbolic inversely proportional relationship between a and k higher values for specific leaf area a indicate thinner grass leaves which result in lower values for canopy extinction of light k notice a visible oe at t k equal to 150 and 180 d fig 8 2 when growth rates are maximum parameters a k φ are directly related to growth rate and small changes in their values impact model output it may be possible to decrease oe by defining sub models for different time ranges growth stages thus introducing a time varying fps however this study focuses on the characterisation of a time invariant fps the model itself appears to be unidentifiable for the four parameters chosen but the implementation of constraints based on the physical meaning of parameters prevents an unbounded fps this case shows the relevance of a sensitivity analysis prior to parameter estimation a similar estimation of 3 parameters for this model resulted in a similar oe after convergence to wd 0 5 therefore adding parameters for estimation may require more computational time and more memory with little improvement in the fmos accuracy and may introduce unidentifiability to the model 4 conclusions our objective was to investigate and evaluate an efficient sampling based method for set membership parameter estimation we presented a set valued algorithm that characterises an approximate feasible parameter set fps of hyper spheres and provides a balance between accuracy and computational complexity the spheres were obtained using randomly sampled unfeasible parameter vectors as seeds for a voronoi diagram of the parameter space and using the resulting voronoi vertices as centres for the spheres the algorithm works with a fixed number of sampled parameter vectors per iteration i e the computational time has an order o n sample although lacking an exact mathematical description the approximate fps can generally be characterised by a low number of spheres we demonstrated an implementation on a 2 parameter case achieving lower computational requirements and similar accuracy as compared with the sivia algorithm we also demonstrated implementation on a 4 parameter case of a relatively complex model additionally we proposed a measure of the accuracy based on deviations between feasible model output set fmos and data error bounds when analysing both fps and these deviations it is possible to indicate practical identifiability of a model as we demonstrated on a 3 parameter case funding this work was done as part of the project inapro with funding from the european union s seventh framework programme for research technological development and demonstration under grant agreement no 619137 d myfiles elsevier enso 00105125 sce gs2 software availability the source code is available at https sourceforge net p vorsetmembership code ci master tree credit authorship contribution statement d reyes lastiri conceptualization of this study writing methodology software h j cappon methodology analysis of results writing k j keesman methodology analysis of results writing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper a algorithm supporting functions algorithm a 1 supporting functions image 3 b list of symbols and model parameters symbol description e norm of the error vector defined as e max 1 i n e i fps and fmos feasible parameter set and feasible model output set k m measurement instant and total of measurement instants n cardinality of a set number of elements o order of the algorithm time complexity oe ue wd overestimation underestimation and weighted deviation r p p dimensional parameter space s ϑ sample of parameter vectors ϵ upper error bound ϑ θ f or u parameter vector normalized feasible or unfeasible subscripts ω ϑ ω θ set of all known parameter vectors normalized lotka volterra model x 1 x 2 50 50 state variables initial value populations of prey and predator t sim 0 1 7 30 day simulation time t k 1 2 6 month artificial measurement instants x 1 x 2 reference model outputs parameters ref value p 2 p 4 estimated normalized parameters p 1 p 1 1 0 m o n t h 1 birth rate of prey p 2 p 2 0 01 m o n t h 1 p r e d 1 population decrease of prey due to predators p 3 p 3 1 0 m o n t h 1 predator death rate p 4 p 4 0 02 m o n t h 1 p r e y 1 population increase of predators due to prey microbial growth model s x 2 0 1 5 mg l state variables initial value concentrations of substrate and bacteria t sim 0 1 24 20 d simulation time t k 0 5 3 5 16 5 hr artificial measurement instants s x reference model outputs parameters ref value k d k s y μ m a x estimated normalized parameters k d k d 0 021 d 1 endogenous bacterial decay k s k s 5 14 m g l 1 half velocity constant y y 10 34 m g x m g s 1 true microbial yield per substrate consumed μ m a x μ m a x 1 15 d 1 maximum rate of substrate use grasim model w s w g 50 50 kgc ha 1 state variables initial value storage and structure mass t sim 0 1 365 d simulation time t k 120 150 330 hr artificial measurement instants w d m k g d m h a 1 reference model output dry matter of plant structure mass parameters ref value a β k y estimated normalized parameters a a 0 004 ha kg 1 structural specific leaf area α α 2 4 10 9 kg j 1 leaf photosynthetic efficiency β β 0 05 senescence rate k k 0 5 canopy extinction coefficient m m 0 1 leaf transmission coefficient μ m μ m 0 5 d 1 max structural specific growth rate φ φ 0 9 photosynthetic fraction available for growth p m p m 10000 k g h a 1 d 1 max photosynthesis y y 0 75 structure fraction from storage m m 0 02 d 1 maintenance respiration coefficient c grasim auxiliary equations photosynthetic growth is defined as a 1 f p 12 44 φ p where 12 44 is a conversion factor for mass from co 2 to c the photosynthesis rate is defined as a 2 p 0 l a i 0 h p g d l d τ p g α i p m α i p m i k 1 m i 0 e k l where lai is the leaf area index h is the daytime duration p g is the gross photosynthetic rate i is the light intensity over a leaf and i 0 is the irradiance assuming h 24hr and i 0 dli day light integral it is possible to obtain an approximate analytical solution for p a 3 p p m k l n a p m a e k l a i p m a α d l i k 1 m where dli for the test case was taken from the weather station de bilt for year 2001 knmi the leaf area index is a 4 l a i a w g the net mass conversion from storage to structure is a 5 f g μ m w g w s w g w s shoot respiration from storage mass is a 6 f s r μ m 1 y y w g w s w g w s maintenance respiration covered entirely by storage mass is a 7 f m r m w g senescence is a 8 f s β w g 
25804,identification of complex systems often face structural modelling errors and limited or low quality data which hinder statistical characterisations an alternative is the set membership approach where errors are assumed unknown but bounded set membership estimation aims to find a feasible parameter set fps which produces model outputs that fit within given error bounds most algorithms are limited to linear models small number of parameters or to discrete approximation of the fps these limitations hinder parameter estimation for relatively complex systems we present an efficient sampling based set membership algorithm with low computational complexity that improves the coverage of a discrete approximation of the fps characterised by hyperspheres from a voronoi diagram of the parameter space additionally we suggest a measure for set membership accuracy based on deviations between the given error bounds and the feasible model output set our algorithm provides a balance between accuracy and computational complexity and a tool to investigate practical identifiability keywords set membership voronoi diagram hyperspheres uncertainty propagation 1 introduction mathematical models for biological and environmental systems often combine a priori knowledge and experimental data requiring a calibration step to estimate the unknown parameters frequently uncertainty of parameter estimates is based on a statistical characterisation of the error in experimental data however biological and environmental systems often present the problems of structural modelling error and limited availability or low quality of experimental data sets therefore most often a statistical characterisation of the error is inappropriate norton 1987 keesman 1990 walter and piet lahanier 1990 in this context of structural modelling error with limited and uncertain data an alternative to the statistical characterisation is a so called set membership sm characterisation where the errors are assumed to be unknown but bounded in the sm approach ranges of expected system outputs are predicted for each time instant instead of single values these ranges account for the effect of uncertainty in data and model outputs norton 1987 keesman 1990 walter and piet lahanier 1990 milanese et al 1996 diniz 2013 given a p dimensional parameter vector ϑ and the error between measurements y and model outputs f ϑ defined as e ϑ y f ϑ in a set membership approach the error is assumed to be point wise bounded by a fixed positive number i e e ϑ ϵ within the sm approach set valued estimation algorithms aim to find an exact or approximate feasible parameter set fps the fps produces model outputs that fit inside the error bounds at all times f p s ϑ r p y f ϑ ϵ fig 1 for overviews see milanese et al 1996 keesman 2003 norton 2003 walter 2003 keesman 2011 cerone et al 2014 the simplest case of sm algorithms are based on models that are linear in the parameters this type of algorithms is used in signal processing for e g adaptive filtering providing reduced computational complexity by updating parameter estimates only when error bounds are exceeded diniz 2013 applying these methods to non linear models common in biological and environmental systems would introduce additional linearisation steps in contrast sm parameter estimation of non linear dynamic systems is frequently applied to solve the problem of uncertain and limited data common algorithms rely on either interval based or sampling based methods for example using an interval based method marvel and williams 2012 proposed a framework for sm estimation and experimental design to deal with small data sets in biological systems based on set inversion via interval analysis sivia jaulin and walter 1993 similarly rumschinski et al 2010 proposed a partition algorithm for sm estimation and model invalidation to discriminate between competing models in biochemical reaction networks interval based algorithms can characterise the fps for linear and non linear models and are capable of characterising non convex parameter sets rumschinski et al 2010 common in biological and environmental systems the fps characterised by interval based methods is a collection of boxes with sizes determined by a desired accuracy in general they consist of a large number of boxes hypercubes that define the fps boundary ca 20 000 boxes for a lotka volterra test model with two estimated parameters by sivia marvel and williams 2012 the number of boxes increases with the number of parameters and when higher accuracy is required jaulin and walter 1993 furthermore the number of model evaluations is proportional to the number of boxes characterising the fps resulting in an exponential computational complexity with respect to the number of parameters raïssi et al 2009 i e a computational time with an order o n boxes p the fps characterised by interval based methods provides an accurate mathematical description that can be used to simulate a model and its prediction uncertainty however defining a large number of boxes and simulating from them is computationally demanding in other examples using sampling based methods keesman 1990 proposed the characterisation of the fps by ellipsoids for more effective sampling van straten and keesman 1991 applied the so called monte carlo set membership algorithm mcsm to calibrate a model for lake eutrophication and to simulate its prediction uncertainty from the resulting discrete fps similarly nurulhuda et al 2017 applied a latin hypercube sm algorithm for a flooded rice system returning a discrete approximation of the fps in a six dimensional space given a fixed sample size per iteration these algorithms have a linear computational complexity irrespective of the number of parameters i e a computational time with an order o n sample the fps characterised by sampling based methods is less computationally demanding than interval based methods however random sampling may require a large number of iterations therefore low computational times and a full coverage of the fps cannot be guaranteed additionally models of complex biological and environmental systems are often split into sub models see for example van straten and keesman 1991 mohtar et al 1997 mocenni and vicino 2006 and reyes lastiri et al 2018 uncertainty in the parameter estimates often propagates through sub models in uncertainty propagation studies the statistical approach uses methods such as first order variance propagation or monte carlo simulation first order variance propagation is hindered by the non linearity of complex systems similarly monte carlo simulation which requires sampling from a probability density function pdf is hindered by the uncertain and limited nature of experimental data which may lead to inadequate pdf characterisation alternatively in the sm approach interval based methods preserve the uncertainty characterisation from the calibration step but they are hindered by computational complexity in contrast sampling based methods have less computational complexity but simulating a discrete fps without full coverage and extending discrete feasible model output trajectories in time beyond the calibration interval may lead to falsified predictions with underestimated uncertainty consequently given the aforementioned limitations it is desired to have an efficient sampling based algorithm that closely approximates the fps while preventing underestimation and overestimation of uncertainty propagation therefore the objective of the paper was to investigate and evaluate a novel set membership estimation algorithm that meets the requirements of an uncertainty propagation study of complex systems with limited or low quality data 2 methods the sampling based sm estimation algorithm proposed in this paper aims at efficiently characterising an approximate fps using a relatively low number of elements additionally deviations from error bounds are quantified the algorithm was evaluated in four test cases the algorithm was developed in python 3 5 using the scipy functions for delaunay triangulation and voronoi diagrams based on the qhull library barber et al 1996 the algorithm tests were run in the ipython console of winpython 3 5 in an intel core i7 4790 cpu computer at 3 60 ghz with 16 0 gb ram operating on windows 7 the models were simulated with the odeint function in the scipy package v 0 18 1 of python using its default parameters 2 1 algorithm we propose characterizing the approximate fps based on hyper spheres centred at voronoi vertices parameters are assumed time independent the voronoi diagram is generated using all known unfeasible parameter vectors as seeds thus excluding them by definition using spheres complex fps shapes can be approximated by two data vectors centre coordinates c and corresponding radii r therefore non convex parameter sets from non linear models can be characterised with a relatively low number of elements random sampling from spheres of the characterised fps is computationally simple and can then be used to simulate the model for t 0 t where t is the final simulation time including the calibration time interval such sampling based method from a low number of elements allows for relatively low computational times convergence of the algorithm is not defined in the parameter space r p but in the model output space in terms of deviations between the approximate feasible model output set fmos and the data error bounds for all measurement instants in this way although sampling based the algorithm tries to prevent under and overestimation of prediction uncertainty 2 1 1 voronoi diagram and delaunay triangulation in a voronoi diagram fig 2 a space is partitioned into regions based on the distance to a specified set of points for each of these points called seeds there is a corresponding voronoi region where any point is closer to its seed than to any other seed the voronoi diagram for a set of points is dual to its delaunay triangulation in a delaunay triangulation no point is inside the circumcircle of any triangle the triangle circumcentres are also the voronoi vertices our algorithm is based on a voronoi diagram from the collection of all known unfeasible parameter vectors thus excluding them from the approximate fps 2 1 2 definitions for the algorithm implementation we define ϑ f and ϑ u as a feasible and unfeasible parameter vector respectively ω ϑ f and ω ϑ u are then the collections of all known feasible and unfeasible parameter vectors we also define s ϑ as a random sample of parameter vectors from the set of spheres in r p these sampled parameter vectors are evaluated individually to split the sample into a feasible s ϑ f and an unfeasible s ϑ u set of parameter vectors furthermore we define two types of deviations to measure accuracy of the approximate fps at each measurement instant k overestimation oe k is the maximum deviation between model output f ϑ and error bounds related to ϑ u sampled in the fps similarly underestimation ue k is the maximum deviation between model output f ϑ and error bounds related to all known ϑ f thus for measurement instants k 1 m we define 1 o e k max i u f ϑ u i u k y k ϵ max i u y k ϵ f ϑ u i u k u e k min i f y k ϵ f ϑ f i f k min i f f ϑ f i f k y k ϵ notice that oe k is calculated for a sample of unfeasible parameters with size n s ϑ u obtained from the approximate fps in each iteration i e i u 1 n s ϑ u in contrast ue k is calculated for the set of size n ω ϑ f of all known feasible parameters up to the current iteration i e i f 1 n ω ϑ f fig 3 illustrates these definitions total oe and ue are defined as the sum of deviations for all measurement instants m eq 2 2 o e k 1 m o e k u e k 1 m u e k finally we define the scalar valued weighted deviation wd from oe and ue oe is weighted for the number of ϑ u found in a sample inside the collection of spheres s ϑ u i n at the corresponding iteration ue is weighted for the number of ϑ f found in a sample outside but near the collection of spheres s ϑ f o u t at the corresponding iteration consequently 3 w d n s ϑ u i n n s ϑ i n o e n s θ f o u t n s ϑ o u t u e 2 1 3 implementation the algorithm consists of a main function estimate and four sub functions initialize generate spheres sample and evaluate implementation in pseudocode is shown in algorithms 1 and 2 the functions are illustrated in fig 4 and described below supporting functions are provided in algorithm a 1 in the appendix the approximate fps is characterised by sets of centres and radii of spheres c r 1 initialize fig 4 1 the sample set is initially defined as a hyper cube grid ω ϑ ini latin hyper cube sampling is applied iteratively on the grid ω ϑ ini evaluating n ini points per iteration sampled points are evaluated as feasible or unfeasible initializing the sets ω ϑ f and ω ϑ u sampling and evaluation continues until a desired size of ω ϑ f is obtained the sets are subsequently normalized to ω θ f and ω θ u based on the minimum and maximum feasible coordinates found in the sample normalization helps maintaining the approximate fps near the range 0 1 for all parameters if not enough ϑ f or ϑ u are found the algorithm must be restarted this step is purely random and therefore governed by the choice of parameter ranges to decrease randomness it is best to have prior knowledge on the model behaviour and parameters with physical meaning constrained to a certain region if no prior knowledge is available a large ω ϑ ini with large n ini can be used which is subsequently narrowed by trial and error using this step alone 2 generate spheres fig 4 2 a voronoi diagram is generated using the scipy function scipy spatial voronoi the scipy community b with ω θ u as seeds the voronoi vertices generated constitute sphere centres by definition those spheres exclude any known θ u given minimum and maximum radii r min r max and constraints based on prior knowledge ϑ min ϑ max an optional filter can be applied to remove spheres with r r min and r r max and spheres with any centre coordinate c j ϑ min j and c j ϑ max j subsequently spheres that do not contain any θ f are removed finally redundant spheres are also removed i e spheres containing only θ f included in larger spheres these filters ensure that the number of spheres is kept low and their size is kept large reducing memory use in the first iteration the set ω θ u is reset to contain only θ u on which spheres with θ f are circumscribed this reduces the amount of data stored and focuses the next steps on the region where θ f are found 3 sample fig 4 3 two random uniform samples of parameter vectors with size n s are obtained from the set of spheres both samples are achieved by combining a normal distribution and its inverse madan 2017 the first sample s θ in is obtained inside the spheres to search for new θ u the second sample s θ out is obtained in a ring outside but near the spheres with radii ranging from r to 2r to search for new θ f redundant θ sampled from overlapping spheres are discarded helping both samples to concentrate near the approximate fps boundary to improve its accuracy 4 evaluate fig 4 4 feasibility of sampled parameter vectors is evaluated for both samples s θ in and s θ out weighted deviation wd is calculated from eqn 3 the algorithm stops if wd wd tol otherwise unfeasible parameter vectors found inside the approximate fps s θ i n u are appended to the set ω θ u feasible parameter vectors found outside the approximate fps s θ o u t f are appended to the set ω θ f and a new iteration starts algorithm 1 vorsetmembership image 1 algorithm 2 vorsetmembership continue image 2 2 2 test model cases the algorithm was tested in four cases based on three non linear dynamic models with biological and environmental components a lotka volterra population model a microbial growth and degradation with under monod kinetics and the grass growth model in grasim mohtar et al 1997 for each case artificial noisy measurements were generated around the base model outputs using a zero mean uniform distribution with ϵ 1 4 y where y is the time averaged value of the model output all model cases were initialized in parameter space 0 5ϑ 1 5ϑ where ϑ is the vector of nominal reference parameter values used to generate the artificial noisy measurements the initial number of feasible parameter vectors required was n ω ϑ f i n i 15 sampling size for each iteration was n s θ in n s θ out 50 details for each test case are provided in table 1 see also appendix b for a list of symbols for each model 2 2 1 lotka volterra the lotka volterra model is a canonical biological model that describes the dynamics of predator prey populations it is represented by the differential equations 4 x 1 x 1 p 1 p 2 x 2 x 2 x 2 p 3 p 4 x 1 where the states are prey x 1 and predator x 2 populations and the four parameters p represent rates of population change due to growth death and predation this model has been used previously to test algorithms for set membership parameter estimation marvel and williams 2012 raissi et al 2004 we used the lotka volterra model to analyse the algorithm behaviour on two identifiable cases bounding one state x 1 and two states x 1 x 2 2 2 2 growth with monod kinetics microbial growth and degradation with monod kinetics is represented by the differential equations 5 s μ m a x x y s k s s x μ m a x s k s s x k d x where the states are concentrations of substrate s and bacteria x with interactions described by four parameters related to growth decay yield efficiency and substrate limitation the monod kinetics is theoretically identifiable from noise free measurements but its parameters cannot be uniquely identified from noisy measurements holmberg 1982 therefore we used this model to analyse the algorithm behaviour on one unidentifiable case 2 2 3 grasim the grass growth model in grasim splits the plant into components for storage and structure mohtar et al 1997 6 w s f p f s r f g f m r w g f g f s 8 p t w d m w g 0 4 with carbon mass flows for photosynthesis f p shoot respiration f sr structure growth f g maintenance respiration f mr and senescence f s the model output w dm is the dry matter of plant structure mass assuming 40 c content in dry matter see appendix c for the detailed model we used the grasim model to test the applicability of our algorithm on a larger model aiming towards implementation in biological and environmental systems commonly estimating multiple parameters in one model is preceded by a sensitivity analysis to find the most dominant parameters if however more than four dominant parameters are found the computational complexity of the algorithm will further increase for a given wd tol and fps coverage consequently for higher dimensional parameter cases accuracy of the algorithm can be relaxed by increasing wd tol and n ini ultimately leading to the mcsm algorithm by keesman and van straten 1990 demonstrated on a 16 dimensional parameter case by van straten and keesman 1991 3 results and discussion the main results for each case are shown in table 2 due to the sample based nature of the algorithm results varied between runs but the behaviour and final accuracy remained consistent it is important to note that in spite of the geometrical relation the proposed characterisation by spheres is different from the characterisation by ellipsoids the spheres proposed here are solely based on the voronoi tessellation of θ u and do not provide a direct description of the direction or shape of the approximate fps in contrast ellipsoids use tools like principal component analysis pca of θ f to describe the directionality of the approximate fps the choice of wd tol is arbitrary it depends on previous experience with the model and on the desired accuracy notice that we assumed an error of fixed width for all artificial measurement instants which constitutes a worst case scenario for underestimation ue 3 1 case 1 lotka volterra 1 output and 2 estimated parameters for case 1 we assumed that only x 1 was measured and bounded y x 1 the approximate fps was characterised by a maximum of 10 spheres fig 5 1 the algorithm converged after a maximum of 14 iterations 1400 model simulations deviations between fmos and error bounds show a negligible oe fig 5 2 however the convergence history shows a stagnant underestimation fig 5 3 which means that the model cannot reproduce the entire error bounds which in general is the case nonetheless wd converged because there were no new θ f found outside the sphere set in the last iteration uncertainty propagation from ω θ f on x 2 fig 5 4 is similar to the one obtained by the sivia algorithm marvel and williams 2012 however due to random sampling any ϑ u in the approximate fps could introduce a deviation in x 2 beyond the propagation from ϑ f this deviation and the uncertainty propagation itself can be avoided by bounding x 2 we show this in the next case 3 2 case 2 lotka volterra 2 outputs and 2 estimated parameters for case 2 we assumed error bounds on both states y x 1 x 2 t the approximate fps was characterised by a maximum of 11 spheres fig 6 1 the algorithm converged after a maximum of 15 iterations for a total of 1500 model simulations when bounding two states there is a reduced degree of freedom with respect to case 1 which results in a fmos with smaller intervals at each measurement instant k and thus larger ue fig 6 2 however as expected the bounds on x 2 led to a smaller oe on this state compared to case 1 3 3 case 3 biodegradation and growth with monod kinetics 1 output and 4 estimated parameters unidentifiability we tested the algorithm under a well known case of an unidentifiable model structure we assumed that only bacterial biomass was measured and bounded y x the estimation of all four parameters in the monod kinetics model resulted in an approximate fps that extends indefinitely with subsequent iterations fig 7 1 the projection of parameter combination μ m a x k s shows an elongated set because estimates of these parameters are highly correlated this result is in accordance with holmberg 1982 similarly the projection of parameter combination y k d also shows an elongated set indicating unidentifiability practical unidentifiability of this model is also reflected in high oe peaks resulting from continuously finding new areas with θ f that must be reshaped to exclude θ u fig 7 2 and 7 3 therefore high peaks of oe through convergence history combined with a fps that extends far beyond the normalized coordinates 0 1 constitute a novel test for practical identifiability these peaks also illustrate the opportunity to improve the mathematical rigour of the algorithm by developing a function to describe the convergence trend for example by a moving average filter of the historical oe and ue 3 4 case 4 crop growth model 1 output bounded and 4 estimated parameters finally we tested the algorithm on a model with higher complexity grasim steps often trivialized prior to calibration of complex models are a sensitivity analysis and the implementation of prior knowledge parameter constraints we performed a sobol global sensitivity analysis on the model sobol 2001 using the python package salib herman and usher 2017 the sensitivity analysis revealed that six out of the ten model parameters have a global sensitivity coefficient at least one order of magnitude larger than the rest from those six parameters a combination of four parameters is chosen with the lowest second order sensitivity coefficients reflecting low correlation in the parameter estimates this pre selection helps improving model identifiability the selected parameters were structural specific leaf area a senescence rate β extinction coefficient of canopy k and photosynthetic fraction available for growth φ subsequently we defined parameter constraints for the algorithm based on physical definitions and on reported ranges in literature mohtar et al 1997 zhai et al 2004 these constraints limit the region where spheres will characterise the approximate fps a 0 002 0 008 β 0 02 0 1 k 0 25 0 90 and φ 0 75 0 99 in this case simulation time of the model governs computational time in the algorithm implementation ca 2 min per iteration therefore we set maximum iterations to 100 the algorithm converged to wd tol 0 5 in 2 out of 5 runs in case of convergence the approximate fps was characterised by a maximum of 430 spheres in 88 iterations the approximate fps is bounded within the constraints provided fig 8 1 notice that the projection of a k is a non convex set in a narrow space which can still be characterised by the algorithm but requires a relatively high number of spheres this projection also indicates a hyperbolic inversely proportional relationship between a and k higher values for specific leaf area a indicate thinner grass leaves which result in lower values for canopy extinction of light k notice a visible oe at t k equal to 150 and 180 d fig 8 2 when growth rates are maximum parameters a k φ are directly related to growth rate and small changes in their values impact model output it may be possible to decrease oe by defining sub models for different time ranges growth stages thus introducing a time varying fps however this study focuses on the characterisation of a time invariant fps the model itself appears to be unidentifiable for the four parameters chosen but the implementation of constraints based on the physical meaning of parameters prevents an unbounded fps this case shows the relevance of a sensitivity analysis prior to parameter estimation a similar estimation of 3 parameters for this model resulted in a similar oe after convergence to wd 0 5 therefore adding parameters for estimation may require more computational time and more memory with little improvement in the fmos accuracy and may introduce unidentifiability to the model 4 conclusions our objective was to investigate and evaluate an efficient sampling based method for set membership parameter estimation we presented a set valued algorithm that characterises an approximate feasible parameter set fps of hyper spheres and provides a balance between accuracy and computational complexity the spheres were obtained using randomly sampled unfeasible parameter vectors as seeds for a voronoi diagram of the parameter space and using the resulting voronoi vertices as centres for the spheres the algorithm works with a fixed number of sampled parameter vectors per iteration i e the computational time has an order o n sample although lacking an exact mathematical description the approximate fps can generally be characterised by a low number of spheres we demonstrated an implementation on a 2 parameter case achieving lower computational requirements and similar accuracy as compared with the sivia algorithm we also demonstrated implementation on a 4 parameter case of a relatively complex model additionally we proposed a measure of the accuracy based on deviations between feasible model output set fmos and data error bounds when analysing both fps and these deviations it is possible to indicate practical identifiability of a model as we demonstrated on a 3 parameter case funding this work was done as part of the project inapro with funding from the european union s seventh framework programme for research technological development and demonstration under grant agreement no 619137 d myfiles elsevier enso 00105125 sce gs2 software availability the source code is available at https sourceforge net p vorsetmembership code ci master tree credit authorship contribution statement d reyes lastiri conceptualization of this study writing methodology software h j cappon methodology analysis of results writing k j keesman methodology analysis of results writing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper a algorithm supporting functions algorithm a 1 supporting functions image 3 b list of symbols and model parameters symbol description e norm of the error vector defined as e max 1 i n e i fps and fmos feasible parameter set and feasible model output set k m measurement instant and total of measurement instants n cardinality of a set number of elements o order of the algorithm time complexity oe ue wd overestimation underestimation and weighted deviation r p p dimensional parameter space s ϑ sample of parameter vectors ϵ upper error bound ϑ θ f or u parameter vector normalized feasible or unfeasible subscripts ω ϑ ω θ set of all known parameter vectors normalized lotka volterra model x 1 x 2 50 50 state variables initial value populations of prey and predator t sim 0 1 7 30 day simulation time t k 1 2 6 month artificial measurement instants x 1 x 2 reference model outputs parameters ref value p 2 p 4 estimated normalized parameters p 1 p 1 1 0 m o n t h 1 birth rate of prey p 2 p 2 0 01 m o n t h 1 p r e d 1 population decrease of prey due to predators p 3 p 3 1 0 m o n t h 1 predator death rate p 4 p 4 0 02 m o n t h 1 p r e y 1 population increase of predators due to prey microbial growth model s x 2 0 1 5 mg l state variables initial value concentrations of substrate and bacteria t sim 0 1 24 20 d simulation time t k 0 5 3 5 16 5 hr artificial measurement instants s x reference model outputs parameters ref value k d k s y μ m a x estimated normalized parameters k d k d 0 021 d 1 endogenous bacterial decay k s k s 5 14 m g l 1 half velocity constant y y 10 34 m g x m g s 1 true microbial yield per substrate consumed μ m a x μ m a x 1 15 d 1 maximum rate of substrate use grasim model w s w g 50 50 kgc ha 1 state variables initial value storage and structure mass t sim 0 1 365 d simulation time t k 120 150 330 hr artificial measurement instants w d m k g d m h a 1 reference model output dry matter of plant structure mass parameters ref value a β k y estimated normalized parameters a a 0 004 ha kg 1 structural specific leaf area α α 2 4 10 9 kg j 1 leaf photosynthetic efficiency β β 0 05 senescence rate k k 0 5 canopy extinction coefficient m m 0 1 leaf transmission coefficient μ m μ m 0 5 d 1 max structural specific growth rate φ φ 0 9 photosynthetic fraction available for growth p m p m 10000 k g h a 1 d 1 max photosynthesis y y 0 75 structure fraction from storage m m 0 02 d 1 maintenance respiration coefficient c grasim auxiliary equations photosynthetic growth is defined as a 1 f p 12 44 φ p where 12 44 is a conversion factor for mass from co 2 to c the photosynthesis rate is defined as a 2 p 0 l a i 0 h p g d l d τ p g α i p m α i p m i k 1 m i 0 e k l where lai is the leaf area index h is the daytime duration p g is the gross photosynthetic rate i is the light intensity over a leaf and i 0 is the irradiance assuming h 24hr and i 0 dli day light integral it is possible to obtain an approximate analytical solution for p a 3 p p m k l n a p m a e k l a i p m a α d l i k 1 m where dli for the test case was taken from the weather station de bilt for year 2001 knmi the leaf area index is a 4 l a i a w g the net mass conversion from storage to structure is a 5 f g μ m w g w s w g w s shoot respiration from storage mass is a 6 f s r μ m 1 y y w g w s w g w s maintenance respiration covered entirely by storage mass is a 7 f m r m w g senescence is a 8 f s β w g 
