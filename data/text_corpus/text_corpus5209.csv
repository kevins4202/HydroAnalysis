index,text
26045,we compiled information on 26 numerical models which consider the terrestrial phosphorus p cycle and compared them regarding process description model structure and applicability to different ecosystems and scales we address the differences in their hydrological components and between their soil p routines the implementation of a preferential flow component in soils as well as whether the model performance has been tested for p transport the comparison of the models revealed that none offers the flexibility for a realistic representation of p transport through different ecosystems and on diverging scales especially the transport of p through macroporous soils e g forests is deficient five models represent macropores accurately but all of them lack a validated p routine we therefore present a model blueprint to be able to incorporate a physically realistic representation of macropore flow and particulate p transport in forested systems keywords phosphorus transport solute transport soil water leaching preferential flow macropores hydrological models 1 introduction phosphorus p is an important nutrient but a surplus of p can lead to eutrophication of aquatic ecosystems therefore it is important to study transport mechanisms and routes of p from terrestrial to aquatic ecosystems for this purpose it is essential to understand how water and particles are moved within soils in terrestrial ecosystems research still focuses mostly on p in agricultural soils king et al 2015 whereas p is often neglected in forests and other soils hence current knowledge of p cycling in these ecosystems is still insufficient although recent studies e g bol et al 2016 d julich et al 2017a sohrt et al 2017 have shown that p transport is relevant in undisturbed soils a better understanding of the processes involved may lead to a better comprehensibility of the correlation between different factors e g soil properties nutrient status and plant health this is important for forestry but also a key requirement for predictions of future forest ecosystem changes bol et al 2016 especially with regard to climate change and resulting shifts in precipitation behavior it is necessary to consider different ecosystems separately because p pools and transport processes differ between them especially due to dissimilar land management practices and thus differences in the hydrological cycles the main difference between the hydrological cycles of agriculture and forests is caused by the soil structure on arable land plowing and secondary tillage such as harrowing or rotovating leads to a relatively homogeneous structure in the upper soil and thus to a disruption of flow paths geohring et al 2001 jarvis 2007 macropore flow can still be generated in conventionally tilled soils under intense or persistent rain but studies have shown that macropore flow is more pronounced under no till arable compared to conventional tillage management andersson et al 2013 jarvis 2007 this predominance of macropores is similar in forests or other untilled soils animal burrows fissures cracks and root channels lead to the development of a wide network of relatively stable macropores these promote the formation of preferential flow paths pfps bogner et al 2012 bundt et al 2001 resulting in water bypassing large portions of soil without interaction with the matrix in forests these heterogeneous runoff characteristics are further facilitated by patchy throughfall and stem flow which can result in the concentration of large amounts of precipitation water at relatively small areas levia and frost 2003 in general p in soils is distributed over different pools which can be classified based on the form organic inorganic and attachment dissolved exchangeable sorbed the size of these pools can vary considerably between ecosystems prietzel et al 2016 showed that other factors are even more important for the size of the p pools than the type of ecosystem for example the parent material and stage of pedogenesis as stated by frossard et al 2000 and julich et al 2016 soils can contain between 100 and 3000 mg p kg 1 soil in forest soils p can be distributed highly variably with respect to the content speciation availability and source of p julich et al 2016 however a comparison of the p content between soil matrix and pfps in a german forest showed no statistically significant differences d julich et al 2017a in tilled soils the spatial variability of the p content is reduced compared to undisturbed soils due to the homogenization of the surface soil by plowing moreover fertilization usually leads to a much higher input of p in agroecosystems than in forests bol et al 2016 king et al 2015 fertilization often also decreases the diversity of p forms and increases orthophosphate concentrations cade menun 2005 while the transport of dissolved p often dominates in the soil water of arable soils particulate forms can account for a large proportion of total p transported in grassland heathwaite and dils 2000 turner and haygarth 2000 and forest soils bol et al 2016 this is mostly reasoned by the predominance of pfps which enables colloid transport beven and germann 2013 vendelboe et al 2011 and therefore the movement of particulate p a variety of studies indicate that especially large runoff events lead to the mobilization of high amounts of p in macroporous soils bol et al 2016 s julich et al 2017b kaiser et al 2003 king et al 2015 ulen 1995 contrary under baseflow conditions often the amount of dissolved p in the soil solution of forest soils is below the detection limit which in many laboratories is around 0 03 0 05 mg p l 1 bol et al 2016 mealy 2011 as a result movement of p is either only evident over long periods of time or during storm events historically these relatively short extreme events have been mostly neglected when calculating annual p losses to complement field studies on p pools and transport computer models are convenient tools these can be used for example for calculations of changes in p storage over time p loss predictions and balancing analysis of management or climate change scenarios as well as for testing hypotheses regarding p cycling mechanisms although many hydrological and biogeochemical models exist only some of them are able to simulate the transport of p through the soil and a large share of nutrient fate models entirely omit p turnover the state of p transport and turnover models has been subject to several reviews in the past e g lewis and mcgechan 2002 qi and qi 2016 radcliffe et al 2015 vadas et al 2013 wellen et al 2015 but most of them only considered a small selection of currently available models lewis and mcgechan 2002 summarize the state of four catchment models with regard to nitrogen n and p losses to groundwater and surface waters following the application of agricultural waste processes considered are the transport of soluble and particulate p surface application e g as fertilizer mineralization immobilization adsorption desorption leaching runoff and uptake by plants in agricultural systems radcliffe et al 2015 reviewed eight models more recently they examined their suitability for simulating p losses occurring in drainage waters from artificially drained fields for this purpose they also included information on macropore flow but confined to agricultural soils in another study wellen et al 2015 compared the n and p components of five spatially distributed models since the transport through macropores is not considered in their review the information contained is of limited use for forest soil applications qi and qi 2016 focused in their review on p loss through subsurface tile drains in nine water quality models models that cannot simulate tile drainage were excluded vadas et al 2013 also contains information about p transport but here the emphasis is on the challenges in developing new models the models considered are compared in regard for diffuse p losses from agricultural soils preferential flow is not taken into account these five reviews cover the processes of 17 models in total but all lack important information with regard to forest ecosystems or other ecosystems with dominating pfps to close this gap we review existing p transport models with a focus on their applicability for agricultural as well as forested ecosystems to simulate not only the transport of dissolved p but also particulate p the emphasis of this work is not the calculation of total p losses but the documentation of processes involved as well as potential improvements in process representation as an analytical framework we focus on the representation of the following model features temporal and spatial scale p pools and forms mechanisms of surface and subsurface transport with a focus on different flow paths for dissolved and particulate transport soil water solution interactions with the soil matrix p uptake by vegetation we apply this framework to a large number of environmental models that simulate transport of p or generalized nutrients thereby we consider models of different scales from plot to catchment scale and complexity in contrast to the previous reviews we establish a broad overview of all available models for the simulation of p transport 2 scope of models included the most important criterion for a model to be included in this review is the ability to simulate p cycling or the transport of solutes in general through soils to find suitable models we searched isi web of science database using keywords like phosph solute s transport or leach in combination with hydrological model l ing some models were also reported to us personally or found because they were referenced in scientific papers instead of finding them via web of science we included all dynamic numeric models found this way that were used for the modeling of p regardless of the complexity of the transport mechanisms or whether a validation for p transport exists in total we found 26 models that could be used for the investigation of p transport in soils for a first classification we analyzed the model types these can be divided into process based conceptual and empirical while for process based and conceptual models a theoretical understanding of relevant processes is necessary cuddington et al 2013 empirical models are based on empirical observations and do not make any statement about the underlying mechanisms and influencing variables both process based and conceptual models are mechanistic models based on a biogeochemical background while process based models try to represent the processes as accurately as possible conceptual models are created by a distinct conceptualization or generalization consequently they are greatly abstracted and simplified however most models cannot be clearly assigned to one of these types as they often contain components from more than one type addiscott and wagenet 1985 we summarized these models as mixed type models despite this uniform term these models can differ greatly from one another while some models are mainly process based but with some conceptualized features other models are contrary as a clear guidance to differentiate process based and conceptual models we decided to define all models that include the solution of partial differential equations pdes for transport simulation and a complex nutrient routine see below as process based models that include only simplified transport and nutrient components are defined as conceptual while models with either a simplified transport component or a simplified nutrient component are mixed types in addition to this distinguishing feature other important model characteristics are for example the spatial and temporal scales the spatial scale determines the way individual processes are represented in the models micro scale models i e soil profile and plot scales only simulate vertical infiltration and transport processes but no lateral processes large scale approaches simulate the processes for example on hillslope or catchment level the temporal scale of the models also differs significantly while some models are only able to represent very short time periods e g single precipitation events other models can simulate periods over one or several years see section 2 2 another distinction is the amount of data required for parameterization of the model sharpley et al 2002 this is closely related to the level of complexity of represented processes and therefore to the model type typical required data include land use soil texture topography and management practices the amount of data needed and the number of parameters increase with increasing mechanization of the models the data considered in these models can be a combination of collected field data and experimental data but also model results therefore we first examined all models with regard to these differentiation criteria in order to provide an overview the results of this initial classification and some additional general information are shown in table 1 in the following we will discuss the characteristics of the individual models in more detail 2 1 model overview the models in this review represent a wide range of different approaches with many similarities and overlaps in table 2 we give a short overview of the main objectives of every model as well as the land use forms for which they were primarily developed however even those models that were developed explicitly for one ecosystem can often be transferred to another based on the processes included at the same time the fact that a model has been developed for a specific ecosystem does not guarantee that it includes all the important processes to simulate p transport there in order to overcome this confinement some models offer the possibility to be coupled with other models to complement missing processes for example animo does not consider hydrological components but it can be combined with swatre belmans et al 1981 or watbal yates 1996 also pdp is not able to simulate transport of particulate p in surface water and dissolved p in runoff from dry and paddy lands but huang et al 2016a solved this problem by coupling the model with usle and inca p phreeqc is not able to simulate water flow and solute transport on its own so mao et al 2006 coupled it with seawat to close this gap the resulting model which is called phwat is not included in this review since we were not able to find information on p transport further models exist that are not considered in this review although they are able to simulate p transport through the environment for example surphos vadas et al 2007 simulates the fate and transport of p in agricultural systems but since it focuses on surface applied manure and dissolved p loss in surface runoff it is not relevant for p loss through the soil another excluded model is aple which is a microsoft excel spreadsheet model vadas et al 2012 it simulates p loss in runoff and soil p dynamics over ten years on annual time steps there are often different versions of the models we present in this review for example different versions of hydrus exist for different scales e g hydrus 1d and hydrus 2d 3d which are summarized for this review under the term hydrus moreover rzwqm2 p is a derivate of the whole system model rzwqm2 sadhukhan and qi 2018 the same applies for drainmod p which is based on drainmod askar 2019 tian et al 2012 developed another drainmod adaption named drainmod forest to simulate water and nutrient dynamics in drained forest soils however this model is based on the official drainmod release which is why it lacks important features included in drainmod p other included models are built from one or more predecessors for example apex is a derivative of epic and adapt is an extension of gleams with the hydrological component of drainmod icecream db is based on the finish model icecream larsson et al 2007 and the soil water and heat model soil the models inca p and simplyp have recently been re implemented within the mobius model building framework norling 2019 phreeqc a geochemical reactive transport model is based on reaction kinetics of chemical processes it uses ion association pitzer or sit specific ion interaction theory equations for the calculations of solute activities e g 1d transport parkhurst and appelo 2013 2 2 temporal and spatial scale the spatial and temporal scale has a large impact on the properties and functions of a model whereby both can be influenced by the model type while pure mechanistic models are mostly suitable for small spatial scales and rather short periods of time usually less than a year or even less than a day more empirical models can be used for annual or even multiyear simulations and at larger spatial scales radcliffe et al 2015 sharpley et al 2002 and haygarth et al 2005 pointed out which processes are important for p transport depends on the model scale for example the representation of detachment deposition and resuspension of soil particles differ between plot and catchment scales on small scales processes are often described in detail while on larger scales processes are represented by more simple empirical relations and soils often are grouped in associations savenije 2001 describes this as averaging processes scale dependency is evident not only in the spatial scale but also in the temporal scale in particular the time steps of a model have a great influence on the degree of detail e g a model with a resolution per second requires consideration of completely different processes than a model with daily time steps the temporal and spatial scales of all 26 models are depicted in table 1 for this overview the spatial scale was subdivided into soil profile one dimensional plot larger areas but homogeneous weather and soils equivalent to a field in agricultural models and catchment with increasing range soil profile and plot scaled models both focus on vertical fluxes and therefore often make similar assumptions while only three of the models in this review are restricted to one dimensional simulations of soil profiles nine models are specialized for plot and ten for catchment scale applications the remaining four models can be used flexibly for different scales the model swap was developed for plot scaled modeling but via the use of geographical information systems and definition of additional features upscaling to regional scale is possible another important factor is the spatial disaggregation which varies strongly between the models catchment scale models use a variety of lateral spatial disaggregation the models annagnps apex hype inca p swat and swim split the area into hydrologic response units hru which are combinations of homogeneous land use management topographical and soil characteristics arnold et al 2012 hgs provides several options ranging from simple rectangular domains to irregular domains with complex geometry and layering aquanty inc 2016 other models use grid cells answers 2000 camel and hydrus partitioning based on single features like land use hspf and pdp sub catchments lascam or p content classes simplyp soil profile and plot scaled models i e animo daycent drainmod p epic gleams icecream db macro phreeqc please rzwqm2 p and swap do not use lateral discretization adapt is also designed for plot scale applications however gowda et al 2007 used the concept of hrus to simulate whole watersheds in general plot scale models can also be used for larger areas as long as they are homogeneous for example for soil weather and management practice the size of the plot depends on the desired resolution and precision gerik et al 2015 likewise the disaggregation with depth differs between the models for example inca p and simplyp simulate one soil layer and one deeper mineral soil groundwater layer in lascam the soil is divided into three conceptual storages namely a perched near stream aquifer permanent groundwater and an intermediate unsaturated store other models subdivide the soil into more layers e g up to ten daycent epic rzwqm2 p 12 gleams 50 animo or even 200 macro freely chosen by the user besides the spatial scale the temporal scale also differs between the models typical time spans for many models are in the range of years only a few models are explicitly set up for the simulation of short periods e g on the scale of single precipitation events e g macro phreeqc or hydrus this does not mean that the models mentioned cannot simulate longer periods but it is not recommended due to the absence of processes that are important over longer periods the exact simulated period can usually be determined by the user whereas the time steps are mostly fixed 16 models use daily time steps while only phreeqc features a resolution per second the model answers 2000 follows a unique approach since it uses 30 s time steps during runoff and switches to daily time steps between runoff events rzwqm2 p simulates crop growth nutrient balance and pesticide modules on daily time steps and soil water soil heat transfer and surface energy balance on sub hourly time steps in macro precipitation data can be either hourly or daily while the output can be chosen freely still the calculation steps are defined internally hydrus also declares the time steps internally but the user can choose time step controls with which the time steps are automatic adjusted during computation the remaining six models animo drainmod p hgs hspf rzwqm2 p and swap allow the range to be chosen freely 3 phosphorus pools and forms with regard to the p routines the 26 models reviewed here can be divided into several groups with different degrees of complexity an often used approach is the conceptual soil p model of jones et al 1984a in this approach three interconnected inorganic p pools are modeled labile p active p and stable p as well as two organic p pools fresh organic p stable organic p an initial value for labile p is given by the user as an input parameter and based on this active and stable p are calculated furthermore some models follow similar structural approaches as jones et al 1984a although single pools and forms of p deviate other models only consider dissolved p and particulate p without further differentiation and finally there are some models in this review that do not have readily available p routines at all so for modeling of p transport the user has to parameterize a general solute transport component to represent different p forms all the models without a readily available p routine hgs hydrus macro and swap were used in the past for the simulation of p the parameterization results mostly in very simple p routines including only basic pools e g dissolved p or total p it is possible to parameterize swap for the simulation of dissolved p but kroes et al 2017 recommend coupling it with animo to simulate p or n processes to improve the p modeling of hydrus nahra 2006 coupled hydrus 1d with nica and created a po4 routine for soil water but this is not included in the official release of hydrus although these models without readily available p routine can be used to simulate p transport via appropriate parameterization the lack of p transformation and reaction processes results in the primary suitability for small periods of time e g individual precipitation events still since this review contains models of different complexity and applicability we decided to include these models except for hgs the performance for the simulation of p of all these general solute transport models was validated some models with p specific turnover routines i e answers 2000 camel daycent and swim miss any published validation with field data the p routine of jones et al 1984a was originally created for the model epic williams et al 1983 but it is also used in adapt annagnps answers 2000 apex camel drainmod p gleams icecream db rzwqm2 p swat and swim while all of these models p routines are based on this foundation they still comprise different modifications for example epic contains a constant p sorption parameter for an entire simulation while annagnps calculates this parameter daily based on changing soil properties vadas et al 2013 and swat calculates it dynamically at the beginning of each simulation year collick et al 2016 this distinction can lead to very different sizes of the p pools in drainmod p the organic p pools are based on the organic n routine from drainmod n ii youssef et al 2005 the model rzwqm2 p contains an additional routine for calculating the loss of particulate p via surface runoff and tile drainage there is also a modification for gleams to simulate the transport of particulate p namely an extension called partle shirmohammadi et al 1998 therefore of these models only rzwqm2 p and gleams allow for particulate p movement to be simulated whereas all other models based on this approach by jones et al 1984a are not capable of doing so see table 4 other models with structurally very similar p routines to jones et al 1984a are inca p jackson blake et al 2016 wade et al 2002 and simplyp jackson blake et al 2017 both simulate dissolved p inactive soil p and labile soil p another similar approach can be found in please schoumans et al 2013 van der salm et al 2011 which depicts dissolved inorganic p adsorbed p and soluble p slightly more complex is the approach of animo groenendijk and kroes 1999 which simulates in addition to three inorganic p stores dissolved adsorbed and precipitated inorganic p also three organic p stores dissolved stable and fresh organic p hype includes three immobile p pools inorganic adsorbed to soil particles organic with rapid turnover and organic with slow turnover and two mobile pools particulate and soluble p the p routine of hspf is based on the agchem module diaz ramirez et al 2013 here p is simulated as sediment attached dissolved in surface runoff and as concentrations in the interflow and groundwater compartments the p routines of other models are simpler for example pdp huang et al 2016b simulates only dissolved p and particulate p likewise according to lewis and mcgechan 2002 daycent is able to simulate sorbed and labile soil p but no applications or validations thereof could be found lascam distinguishes only between organic adsorbed p and soluble p viney et al 2000 phreeqc herrmann et al 2013 moharami and jalali 2014 takes a very different approach since it is a hydro geochemical transport model and therefore depicts the actual chemical compounds the question of which of these methods produces the best results is not easy to answer as all methods have advantages and disadvantages as qi and qi 2016 pointed out a simplified representation e g hydrus macro and swap can lead to less accurate prediction results on the other hand a simplified representation can also lead to more accurate prediction results as improved performance during calibration can be due to overfitting rather than improved process representation e g perrin et al 2001 seibert 2003 4 transport components for transport processes a distinction can be made between dissolved and suspended transport surface and subsurface transport and transition between mobile and immobile forms not all models include every transport component due to different spatial foci phreeqc is a 1d model of vadose zone transport and therefore lacks surface transport while conceptual large scale models like lascam simulate only dissolved p and no mobile immobile transition table 3 summarizes which water compartments are included in the models in order to provide an indicator for possible uses of the models 4 1 surface transport many models are capable of simulating the transport of p at the soil surface as shown in table 4 this can take place in various ways while some models only represent the transport of dissolved p other models simulate both the surface transport of suspended particulate p and dissolved p different mechanisms can be used for different transport routes dissolved p for example can either diffuse from soil solution of the upper soil layer or be released from sorption as a function of the extractability of p in the near surface soil sharpley et al 2002 suspended p is mostly simulated coupled with erosion most models simulate erosion using the universal soil loss equation usle wischmeier and smith 1978 or some modification of this like the modified usle musle williams 1975 or the revised usle rusle renard et al 1991 usle is a simple empirical approach for predicting long term average annual soil loss it is based on various factors like rainfall erosivity soil erodibility topography and cropping management a more complex technique is the process oriented modeling of erosion where detachment transport and deposition of sediment are simulated discretely wolfe 2007 however this technique is rarely used table 4 shows how the different models simulate erosion as well as surface transport of p models that are able to simulate surface transport of both dissolved and particulate p are adapt answers 2000 apex camel daycent epic gleams hspf icecream db inca p lascam rzwqm2 p simplyp swat and swim many of these models are not able to simulate the transport of particulate p through the soil still to represent the transport at the surface this is circumvented by coupling the surface transport of p via a transport factor to the erosion of sediments from all the models in this review many models e g adapt annagnps camel epic lascam and swat calculate surface transport of dissolved p based on the concentration of labile p in the top soil layer runoff volume and an extraction coefficient in please p loads from a field to surface waters are estimated based on a function of depth and the distribution of total annual horizontal water flux schoumans et al 2013 for the transport of particulate p icecream db assumes the same distribution between the p pools in the eroded material as in the bulk soil yli halla et al 2005 on the contrary particulate p transport in overland flow is often simulated by a logarithmic relationship between p enrichment ratio and sediment discharge menzel 1980 this is in accordance with the fact that eroded p is preferentially attached to the finer sediment particles which tend to be first eroded viney et al 2000 therefore eroded particulate material is mostly enriched with p compared to surface soil sharpley et al 2002 for example in lascam p concentrations decrease as the mass of eroded material increases similar enrichment ratios are also used for example in adapt and gleams 4 2 subsurface transport different approaches exist to simulate the infiltration and transport of water and solutes in soils infiltration is very often calculated using a conceptual curve number approach national resource conservation service nrcs 2004 or the green and ampt equation alternatively a constant infiltration rate can be assumed or infiltration can be capacity based approaches that are more complex calculate infiltration based on the hydraulic gradient richards equation table 3 shows how this is implemented in the different models for simulating water transport through soils a commonly used conceptual approach is a storage routing representation this approach often described as tipping bucket always fills one storage until field capacity is reached before the excess water is routed to the next layer this simple approach is used in most conceptual models but also in many models classified as mixed type still it has several drawbacks e g it is not able to simulate upward flow therefore they have certain disadvantages compared to physical based approaches for example when simulating shallow water table soils for process based models the subsurface water flow and solute transport can according to the classification of šimůnek et al 2003 be grouped in single porosity dual porosity and dual permeability approaches the different concepts are shown in fig 1 single porosity approaches only simulate water flow and solute transport through the soil matrix a variation of this approach is supplemented by a fast bypass flow component fig 1b here the bypassed water and solutes are directly routed to the groundwater or catchment outlet so there is no interaction between the slow and the fast water components this differs in dual porosity fig 1c and dual permeability fig 1d models where it is assumed that the porous medium consists of two interacting regions one region represents the macropores while the other comprises the micropores inside the matrix in dual porosity models water in the matrix is stagnant whereas dual permeability simulates water flow in both macropores and matrix additionally some dual permeability models simulate not only slow matrix and fast macropore transport but also immobilization processes šimůnek et al 2003 fig 1e in all these different approaches the transport of solutes is predominantly simulated as relatively simple physical relations e g via the convection diffusion dispersion equation gerke and van genuchten 1993 šimůnek et al 2003 an even simpler approach to calculate solute transport which is frequently used in conceptual models is to multiply the concentration of solute by the water flux 4 2 1 matrix transport in single porosity models fig 1a saturated water flow is mainly simulated via storage routing or the darcy equation particularly for groundwater flow whereas for unsaturated conditions the richards equation is the most used equation single porosity models are answers 2000 daycent epic gleams hspf lascam pdp please and swim see table 3 of these models answers 2000 epic gleams lascam and swim use the storage routing approach while daycent represents matrix transport using the richards equation pdp does not simulate the soil divided into soil layers as it was developed specifically for polder systems instead it describes the water balance in four land use areas namely residential area surface water area paddy and dry lands without vertical transport of water and p through the soil please also does not simulate the vertical transport of water and solutes since it focuses on the total amount of leached p instead of its transport routes therefore the soil is not divided in different layers but the loss of p is calculated based on empirical assumptions i e the concentration of p and the total groundwater outflow as a function of depth in this model only horizontal runoff is calculated matrix flow is also not included in the models annagnps and phreeqc since phreeqc is a dual porosity model water and solutes in the matrix are stagnant and only transported via macropores annagnps focusses on surface runoff and does not consider vertical leachate however lateral subsurface flow is calculated based on darcy s equation and assumed homogeneous through the entire soil profile bingner et al 2015 the remaining models all have a second faster transport route see section 4 2 2 still their matrix transport components are mostly similar to single porosity approaches namely six models i e apex camel hype inca p simplyp and swat with storage routing and six models hgs hydrus icecream db macro rzwqm2 p and swap using the richards equation drainmod p uses the darcy equation with dupuit forchheimer assumptions this approximation assumes that flow lines are parallel to the impermeable sublayer and thus that lateral flow processes can be separated from vertical processes this is reasonable when the rate of subsurface flow is low clark et al 2015a kampf and burges 2007 the model adapt is unable to simulate unsaturated water transport but since its hydrologic component is based on drainmod vertical transport through the matrix is simulated using the darcy equation animo has to be coupled with another model to represent hydrological processes since the model itself is not capable of simulating water transport components the transport of solutes through the matrix differs little between the models mostly it is calculated by convection diffusion equations animo drainmod p gleams hgs hydrus icecream db macro and swap kroes et al 2017 recommends combining swap with animo for a more realistic simulation of p transport in hspf subsurface transport of dissolved p is simulated by adjusting the ratio of surface to subsurface total p radcliffe et al 2015 for many of the models we were not able to find published information on the exact mechanisms of solute transport however apparently most models are able to simulate transport via water movement contrary the transport of particulate p is restricted to macropores so none of the single porosity models is able to simulate this process explicitly 4 2 2 macropore transport macropore transport is usually much faster than transport via matrix in many models i e adapt animo apex drainmod p hype icecream db inca p rzwqm2 p simplyp swap and swat it is simply represented as an additional fast bypass component in simplyp this quick flow component is simplified even more since it includes not only macropore flow but also saturation excess overland flow tile drainage and runoff from impervious surfaces jackson blake et al 2017 many soils especially those of forests grasslands and no tillage agriculture usually contain macropores hence transport through pfps as well as interactions between pfps and the matrix are important for p translocation bogner et al 2012 bundt et al 2001 julich et al 2016 as these interactions cannot be represented by bypass flow this transport route is mainly of interest for the modeling of agricultural soils with drainages while dual porosity and dual permeability approaches are representations of macroporous soils that are more realistic according to qi and qi 2016 macropore flow in dual permeability models is mostly represented either by richards equation kinematic wave approach or gravitational flow using poiseuille s law to calculate water infiltration into macropores while macropore flow based on the richards equation considers both gravitational flow and capillary driven flow the kinematic wave equation only includes the vertical gravity flow and ignores capillary since poiseuille s law premises that the macropores are cylindrical this approach is less accurate when the pores deviate from this assumption šimůnek et al 2012 moreover poiseuille s law assumes saturated conditions which only rarely applies to macropores jarvis 2007 of all the models presented in this review only five models contain dual porosity or dual permeability representations namely camel hgs hydrus macro and phreeqc while phreeqc is restricted to dual porosity the models hgs hydrus and macro are able to simulate both dual porosity and dual permeability systems camel takes a special position because the unsaturated soil is simulated simply as a single porosity system but it uses a dual permeability approach for the saturated aquifer this groundwater flow is simulated via darcian flow with two different hydraulic conductivities the dual permeability models hgs and hydrus use the richards equation for both matrix and macropore water flow in macro water transport through macropores is simulated via kinematic wave approach since phreeqc needs to be coupled with another model to simulate water flow it is not possible to specify the mechanism for example wissmeier and barry 2010 created an extension for unsaturated flow in phreeqc which enables the use of the richards equation generally existing models with a second flow component follow various approaches for the representation of solute and particle transport through macropores and how the exchange between matrix and macropores is modeled djabelkhir et al 2017 šimůnek et al 2003 for example in hydrus this is solved similar to most single porosity approaches solute transport is calculated via convection diffusion type equations gerke and van genuchten 1993 this is true for both fracture and matrix regions but with different parameter values assigned šimůnek et al 2003 in hydrus the exchange of water between matrix and macropores is driven by the gradient of pressure heads in macro the exchange of water from macropores to micropores is calculated using a mass transfer expression while the transport of solutes is calculated neglecting dispersion since advection is assumed to dominate in phreeqc various mechanisms are available advective transport advective dispersion transport 1d and diffuse transport 2d and 3d the model swat is only capable of simulating bypass flow and lacks a p transport component for the macropore pathways which is why it is not applicable for the physically correct simulation of p transport processes in macroporous soils radcliffe et al 2015 in rzwqm2 p the water flux through macropores is simulated via poiseuille s law which is based on gravitational flow dissolved reactive p and particulate p are directly routed from the first soil layer to the groundwater without interaction with the matrix sadhukhan and qi 2018 in swap water can be infiltrated into macropores at the soil surface and then be transported into deeper soil layers the model distinguishes between continuous horizontal interconnected macropores and discontinuous macropores ending at different depths so water and nutrients can be transported to various soil layers additionally the macropores are divided into static and dynamic kroes et al 2017 for apex ford et al 2017 recently developed a new modification to implement macropores they distinguish between matrix excess macropores and matrix desiccation macropores matrix excess macropores appear when saturation exceeds the water entry pressure of the matrix while matrix desiccation macropores occur at low moisture conditions and form a draught crack network the latter is modeled as a function of clay content and potential evapotranspiration demand deficiency in this approach macropore flow of dissolved p is assumed to equilibrate with the surface soil so p is partitioned between adsorption on the soil surface and transportation through the macropores by using the langmuir isotherm water transport takes place in the form of a bypass flow to the bottom soil layer and when its capacity is exceeded it is moved upwards to the next unsaturated layer 4 2 3 mobile immobile transition in dual porosity models the exchange of p and solutes between macropores and matrix is typically associated with mobilization and immobilization processes aside from these processes especially single porosity models also often simulate immobilization of p via adsorption immobilized p is generally not congruent with particulate p but in some model descriptions these two terms are used synonymous in most models that are able to simulate particulate p it is considered as immobile or it can only be transported by surface erosion jones et al 1984a created the concept of stable vs dissolved p for epic and this has been used in all models building on epics p concept see section 3 here stable p is only transported by surface erosion and is therefore excluded from leaching the immobilization of p in many other models works in similar ways heathwaite 2003 and vadas et al 2013 criticize this because this p routine has seen very limited updates especially movement of particulate p within the soil is therefore missing in most models only the models gleams via the extension partle hype inca p pdp rzwqm2 p and simplyp table 4 are able to simulate the transport of particulate p the transition between immobile and mobile p is often realized by an equilibrium function for example as described in section 3 models with p routines based on jones et al 1984a simulate the mobile immobile transition by creating an equilibrium between stable and active mineral p and between active mineral p and labile mineral p this equilibrium between the three pools is based on the user given value for labile p and the relative sizes of the pools are soil specific the equilibria can be disturbed by different processes for example leaching dissolved loss in run off and plant uptake of labile p or loss of stable or active p via erosion when this happens the imbalance is calculated and then p is moved between the pools to restore balance vadas et al 2013 the equilibrium between labile and active pools can be restored within several days or weeks while the equilibrium between active and stable pools is slower jones et al 1984a despite this similarity between so many models small differences exist between these approaches for example in adapt and gleams the partitioning of mineral p between aqueous and solid phases is implemented via a partitioning coefficient according to the linear adsorption isotherm radcliffe et al 2015 simplyp also uses a simple linear relationship to equilibrate labile soil p and dissolved p jackson blake et al 2017 the p routine of apex is also based on jones et al 1984a but this model uses the langmuir isotherm for adsorption also in please the dissolved inorganic p concentration is calculated using the langmuir isotherm equation radcliffe et al 2015 van der zee and bolt 1991 while the amount of reversibly sorbed p in the top soil layer is related to the water extractable p and oxalate extractable al and fe content radcliffe et al 2015 schoumans and groenendijk 2000 in deeper layers sorbed p decreases with depth based on a first order exponential expression animo provides the langmuir isotherm and the freundlich isotherm which is also used for example by hype inca p macro and swap lascam is not able to simulate mobile immobile transitions unfortunately for many models it was not possible to find detailed descriptions of how they simulate mobilization and immobilization 4 3 plant p uptake and removal an important difference between arable land and forests is the annual harvesting of crops from fields while forest trees are harvested irregularly or not at all in addition harvest and other management actions such as thinning often focus on selected trees without removing the entire stand this leads to differences in nutrient circulation examples of models that can simulate within year variations in both annual and perennial plant p uptake are epic inca p swap swat and swim in swap the disparity between annual and permanent affects not only plant growth but also rainfall interception for agricultural crops infiltration is calculated using the hoyninger braden equation whereas for forests the gash equation is used kroes et al 2017 models that appear to represent only annual crops are for example annagnps and rzwqm2 p in both models crop properties such as cultivating and harvest time tillage and fertilization need to be given as inputs another important factor is the method of calculation of plant p uptake it can be divided into different approaches namely supply driven and demand driven plant uptake as well as combinations of both while supply driven approaches simulate p uptake by plants based on the p concentrations in soils demand driven plant uptake is mainly based on the demand of the plants directly an example of demand driven p uptake can be found in gleams knisel and davis 2000 the uptake of labile p is estimated for each layer where transpiration occurs with the total uptake from all layers equal to the plant p demand the plant p demand is a function of the optimum leaf area index which is tabulated for a large number of crops over a growing season this approach is based on the formulation of the epic model where the potential plant uptake of labile p is simulated as a linear function up to a user specified critical concentration jones et al 1984a a similar approach was chosen in lascam where plant p uptake depends on the rate of canopy biomass accumulation instead of the optimum leaf area index so that it varies seasonally viney et al 2000 in daycent a combination of demand driven and supply driven p uptake is implemented plant p uptake is controlled by the size of the labile p pool whereas in turn the labile p pool varies with the size of the mineral n pool additionally the uptake of labile p is constrained by upper and lower limits for nutrient content in the shoots and roots which in turn are considered as a function of plant biomass lewis and mcgechan 2002 in apex p uptake is also simulated as a combination of demand and supply driven with the root weight as an confinement factor of the supply williams et al 2015 other models that simulate plant p uptake represented by a combination of both approaches are for example inca p jackson blake et al 2016 rzwqm2 p sadhukhan and qi 2018 and drainmod p askar 2019 hydrus can simulate chemical uptake of plants both passively and actively passive uptake is based on the feddes equation and p in soil solution while active uptake is based on the michaelis menten equation qi and qi 2016 in macro plant chemical uptake is included via a source sink term in the solute transport equation qi and qi 2016 for many models it was not possible to find out how they simulate plant uptake exactly see table 4 but it is likely that in most cases it is implemented very simplistically for example as a simple demand driven uptake based on c n p ratios in the plants 5 future developments in environmental process based p modeling 5 1 general suggestions for improvements as shown in this review there are a number of environmental models with p routines depending on the focus of the models they show significant differences in order to provide an overview of the existing models we created a decision tree see fig 2 there we present the different transport routes of the individual models single porosity dual porosity and dual permeability as well as the specific p forms that are included the color code of the figure follows the traffic light principle i e green boxes represent most accurate process representation e g dual permeability and transport of dissolved and particulate p orange boxes indicate less exact model structures e g dual porosity and dissolved p transport with immobile particulate p component and red boxes show the simplest representations no macropores no functioning p routine however this does not mean that the simpler models are generally unsuitable for calculating p fluxes through different ecosystems depending on the question and the complexity required the models can still be very useful it is noticeable that there is no model for which all processes are represented most accurately green to simulate p transport through forest soils many models simulate p transport based on a more than 30 years old approach by jones et al 1984a and we could not find many improvements over the last decades in p modeling often there is no reason against this established method but depending on the research question the lack of a mobile particulate p component can be a major deficit according to heathwaite 2003 and vadas et al 2013 the focus on the development of data intensive complex models instead of more generic models is a main reason for current deficits in modeling in line with this radcliffe et al 2015 recommend to revise p modeling and to develop new improved routines considering our focus of interest this might be especially the transport of particulate p which is only implemented in very few models additionally model performance needs to be tested specifically for p to make sure that simulation results of soil p dynamics are reliable this is a flaw of many existing models since simulated soil p dynamics are rarely presented besides this critique of the p routines and the often found lack of dual permeability approaches there are many other potentially important processes which might be worth considering for model development for example p uptake by trees and other plants might deviate from p uptake by crops surface transport groundwater and stream components are usually important components due to stem flow nutrient inputs might be concentrated locally levia and frost 2003 atmospheric particulate deposition might be increased due to interception lequy et al 2014 some of the named models include most of the processes we consider important the newly improved rzwqm2 p deserves particular mention here as it contains a complex p routine including mobile particulate p as well as a fast bypass component but no dual permeability still the possibility to up and downscale the model specific to the current research question would be an advantage this is very hard to realize since a change of scale results in a shift in the important processes moreover such a high flexibility in the model structure might lead to very complex models with many parameters for different reasons a large number of parameters can increase the inaccuracy of a model for example often parameters have no physical basis they might be impossible to measure in the field djabelkhir et al 2017 or measured parameters can be scale dependent and therefore not representative radcliffe et al 2015 and nelson and parsons 2006 also pointed out that there is generally a lack of guidance on how to obtain independent values for additional parameters in over parameterized models the values of individual parameters cannot be unequivocally identified by the data so called equifinality see beven and freer 2001 so prediction uncertainty might increase moreover small inaccuracies of individual parameters can lead to very large total errors this is for example criticized by buytaert et al 2008 as an over complexity of most models they propose a number of directives that should be followed when developing new models the model code should be fully accessible modular and portable this way the user is enabled to use a model in a highly flexible manner with improved control over the modeling assumptions for example modularity allows the user to choose whether particular processes should be represented either by mechanistic equations or by empirical relations it also simplifies the addition of new independent routines to represent additional processes this way in modular and accessible approaches the spatial discretization and the temporal disaggregation can be adjusted more easily all these suggestions are in accordance with the postulation of clark et al 2011 for the development of modular frameworks modeling frameworks are toolboxes that provide a variety of different processes which can be assembled into a model by a user the resulting model can thus be tailored to specific tasks although the compatibility of the individual process representations can be problematic this enables a large number of different models to be created without high programming effort moreover modeling frameworks are suitable for testing of multiple working hypotheses such an approach would be of great advantage for modeling p dynamics as the comparison of different hypotheses would allow testing which processes are actually important this way it could be analyzed which macropore transport component is sufficient fast bypass dual porosity or dual permeability or to what extent the included process representations depend on the spatial and temporal scale existing modeling frameworks are for example the catchment modelling framework cmf kraft et al 2011 summa clark et al 2015a 2015b raven craig and the raven development team 2019 and the more generic mobius norling 2019 unfortunately until now no existing hydro biogeochemical modeling framework is able to simulate p transport through soils 5 2 a blueprint for a process based p model for different ecosystems in this section we present a blueprint for a process based and modular environmental p model as outlined in section 5 1 a major disadvantage of most existing models is that they are static i e the process representations are predefined and cannot be altered modularity provides an option on how a model could be designed that allows the user to test and compare different hypotheses with regard to the results of this review the presented blueprint could be used to examine whether an explicit representation of macropores can improve modeling p dynamics in different soils and on different scales additionally different p routines could be compared without other factors being modified for this purpose a model should contain only the most important processes to simulate the transport of p in different environments i e arable land grassland and forests nevertheless in order to be able to test hypotheses for different landscapes and scales a large number of processes must be representable 1 the model should include different hydrological processes from which a user can choose see fig 3 top for example for infiltration e g green ampt curve number and percolation e g richards equation storage routing or optional features like snow storage 2 there should be different options for the transport through the soil i e parallel matrix and explicit macropore transport fig 3 and as a more simplified alternative direct infiltration into deeper layers via macropores the horizontal transport via macropores to the stream savenije 2018 should also be included as an optional feature 3 the possibility to connect different spatial entities gridded cells polygons horizontally for example via darcy richards or kinematic wave equation would allow for the construction of models ranging from plot to regional scale 4 for the simulation of p transport and turnover we propose the development of a p routine loosely based on jones et al 1984a but including the transport of particulate p as depicted in fig 3 bottom we differentiate between the transport of p through the soil matrix and if simulated explicitly macropores while processes in the matrix are represented in more detail the processes in the macropores are strictly simplified since the transport processes in pfps are based on gravitational flow the distinction between dissolved and particulate p will be sufficient these pools will be in equilibrium with the five pools in the soil matrix as an alternative approach a highly simplified p routine could be integrated which only distinguishes between dissolved and particulate p in both matrix and macropores 5 for the simulation of plants different possibilities should be included i e a differentiation between permanent forest and grassland versus annual plants and crops in order to achieve this flexibility we promote the implementation of this approach in a modeling framework since the catchment modeling framework cmf kraft et al 2011 offers a multitude of possibilities including the representation of macroporous flow and transport this framework is ideal for implementing a p routine obviously the modular modeling approach presented here can be further extended in order to be of use for even more tasks for example it could be possible to couple the p routines with the c and n cycles or to calculate the effect of nutrient states on the net primary productivity an extension to weathering processes is also possible the accessibility and modularity of modeling frameworks like cmf would allow such diverse approaches to be realized therefore while the blueprint presented here is certainly not a universally valid model for the simulation of p transport it qualifies as a good basis for hypothesis testing and provides the possibility for further refinements and adjustments 6 conclusion we reviewed 26 models that are able to simulate p transport through the soil still their foci are very diverse and therefore the representation of processes varies greatly most of the models were originally created for the simulation of processes in agricultural soils while some of these models were extended for other ecosystems it is likely that processes relevant in non agricultural environments are not well represented these include for example the uptake of p by plants other than crops or the transport through pfps moreover while all models in this review are able to simulate some sort of p transport and turnover they have not necessarily been established for this purpose for this reason the p routines of many models have only been tested in very limited experiments or not been tested at all only please inca p simplyp and pdp focus especially on the simulation of p leaching from soils furthermore the movement through the soil of particulate p is an important aspect of p leaching julich et al 2016 yet this process is only represented in seven of 26 models in all these models the transport is represented by a fast bypass component in order to be able to represent this transport process more realistically the simulation of a dual permeability system could be appropriate since no model fulfils all hypothesized demands we developed a blueprint of a modular model for the simulation of p leaching through different soils especially when it is implemented as part of a modular hydrological framework this approach could help to compare different hypotheses e g under which circumstances the explicit representation of a dual permeability system is appropriate it could also be used for further developments in modeling of p transport in order to improve the modeling of p processes in the environment we think that a shift towards the use of modeling frameworks is necessary by enabling multiple hypothesis testing we envisage substantial improvements in p modeling quality in addition the transferability of the models to different conditions e g various land use forms should be given greater consideration for this purpose the agreement on well established methods might be necessary also in the generation of experimental data only when sampling is comparable e g comparable depth consideration of macropores or same analysis methods for p can the data be used to develop comparable models which are of interest for more than an individual case study if these suggestions are considered we assume that an improvement of the modeling of p is possible declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this project was carried out in the frame of the priority program 1685 ecosystem nutrition forest strategies for limited phosphorus resources funded by the dfg subproject quantification modeling and regionalization of seepage losses of phosphorus from forest soils br 2238 26 2 table a 1 overview of model references and references for performance testing of phosphorus simulation model model reference reference for p routine testing adapt gowda et al 2012 dalzell et al 2004 animo groenendijk and kroes 1999 kroes and roelsma 1998 van der salm and schoumans 2000 annagnps bingner et al 2015 yuan et al 2005 pease et al 2010 yuan et al 2005 answers 2000 bouraoui and dillaha 2000 1996 na1 apex plotkin et al 2013 steglich et al 2016 bhandari et al 2016 francesconi et al 2016 saleh et al 2001 camel koo et al 2005 2004 na daycent parton et al 1998 na drainmod p deal et al 1986 tian et al 2012 askar 2019 askar 2019 epic jones et al 1984a sharpley and williams 1990 della peruta et al 2014 jones et al 1984b richardson and king 1995 gleams leonard et al 1987 knisel and turtola 2000 hgs brunner and simmons 2012 na hspf bicknell et al 1996 grimsrud et al 1982 johanson et al 1980 ribarova et al 2008 hydrus agah et al 2016 šimůnek et al 2008 agah et al 2016 freiberger et al 2013 hassan et al 2010 naseri et al 2011 hype lindström et al 2010 jiang and rode 2012 pers et al 2016 icecream db larsson et al 2007 bärlund et al 2008 larsson et al 2007 liu et al 2012 inca p jackson blake et al 2016 wade et al 2002 jackson blake et al 2017 2016 lascam viney et al 2000 viney and sivapalan 2001 zammit et al 2005 macro jarvis 1991 1995 mcgechan et al 2002 mcgechan 2003 mcgechan et al 2002 pdp huang et al 2016b huang et al 2016a phreeqc parkhurst and appelo 2013 1999 herrmann et al 2013 moharami and jalali 2014 please schoumans et al 2013 schoumans et al 2013 van der salm et al 2011 rzwqm2 p ma et al 2012 sadhukhan and qi 2018 sadhukhan et al 2019a 2019b simplyp jackson blake et al 2017 jackson blake et al 2017 swap gusev and nasonova 1998 kroes et al 2017 na swat arnold et al 2012 1998 grizzetti et al 2003 vadas and white 2010 swim krysanova et al 2005 na 1na means that we were not able to find this information 
26045,we compiled information on 26 numerical models which consider the terrestrial phosphorus p cycle and compared them regarding process description model structure and applicability to different ecosystems and scales we address the differences in their hydrological components and between their soil p routines the implementation of a preferential flow component in soils as well as whether the model performance has been tested for p transport the comparison of the models revealed that none offers the flexibility for a realistic representation of p transport through different ecosystems and on diverging scales especially the transport of p through macroporous soils e g forests is deficient five models represent macropores accurately but all of them lack a validated p routine we therefore present a model blueprint to be able to incorporate a physically realistic representation of macropore flow and particulate p transport in forested systems keywords phosphorus transport solute transport soil water leaching preferential flow macropores hydrological models 1 introduction phosphorus p is an important nutrient but a surplus of p can lead to eutrophication of aquatic ecosystems therefore it is important to study transport mechanisms and routes of p from terrestrial to aquatic ecosystems for this purpose it is essential to understand how water and particles are moved within soils in terrestrial ecosystems research still focuses mostly on p in agricultural soils king et al 2015 whereas p is often neglected in forests and other soils hence current knowledge of p cycling in these ecosystems is still insufficient although recent studies e g bol et al 2016 d julich et al 2017a sohrt et al 2017 have shown that p transport is relevant in undisturbed soils a better understanding of the processes involved may lead to a better comprehensibility of the correlation between different factors e g soil properties nutrient status and plant health this is important for forestry but also a key requirement for predictions of future forest ecosystem changes bol et al 2016 especially with regard to climate change and resulting shifts in precipitation behavior it is necessary to consider different ecosystems separately because p pools and transport processes differ between them especially due to dissimilar land management practices and thus differences in the hydrological cycles the main difference between the hydrological cycles of agriculture and forests is caused by the soil structure on arable land plowing and secondary tillage such as harrowing or rotovating leads to a relatively homogeneous structure in the upper soil and thus to a disruption of flow paths geohring et al 2001 jarvis 2007 macropore flow can still be generated in conventionally tilled soils under intense or persistent rain but studies have shown that macropore flow is more pronounced under no till arable compared to conventional tillage management andersson et al 2013 jarvis 2007 this predominance of macropores is similar in forests or other untilled soils animal burrows fissures cracks and root channels lead to the development of a wide network of relatively stable macropores these promote the formation of preferential flow paths pfps bogner et al 2012 bundt et al 2001 resulting in water bypassing large portions of soil without interaction with the matrix in forests these heterogeneous runoff characteristics are further facilitated by patchy throughfall and stem flow which can result in the concentration of large amounts of precipitation water at relatively small areas levia and frost 2003 in general p in soils is distributed over different pools which can be classified based on the form organic inorganic and attachment dissolved exchangeable sorbed the size of these pools can vary considerably between ecosystems prietzel et al 2016 showed that other factors are even more important for the size of the p pools than the type of ecosystem for example the parent material and stage of pedogenesis as stated by frossard et al 2000 and julich et al 2016 soils can contain between 100 and 3000 mg p kg 1 soil in forest soils p can be distributed highly variably with respect to the content speciation availability and source of p julich et al 2016 however a comparison of the p content between soil matrix and pfps in a german forest showed no statistically significant differences d julich et al 2017a in tilled soils the spatial variability of the p content is reduced compared to undisturbed soils due to the homogenization of the surface soil by plowing moreover fertilization usually leads to a much higher input of p in agroecosystems than in forests bol et al 2016 king et al 2015 fertilization often also decreases the diversity of p forms and increases orthophosphate concentrations cade menun 2005 while the transport of dissolved p often dominates in the soil water of arable soils particulate forms can account for a large proportion of total p transported in grassland heathwaite and dils 2000 turner and haygarth 2000 and forest soils bol et al 2016 this is mostly reasoned by the predominance of pfps which enables colloid transport beven and germann 2013 vendelboe et al 2011 and therefore the movement of particulate p a variety of studies indicate that especially large runoff events lead to the mobilization of high amounts of p in macroporous soils bol et al 2016 s julich et al 2017b kaiser et al 2003 king et al 2015 ulen 1995 contrary under baseflow conditions often the amount of dissolved p in the soil solution of forest soils is below the detection limit which in many laboratories is around 0 03 0 05 mg p l 1 bol et al 2016 mealy 2011 as a result movement of p is either only evident over long periods of time or during storm events historically these relatively short extreme events have been mostly neglected when calculating annual p losses to complement field studies on p pools and transport computer models are convenient tools these can be used for example for calculations of changes in p storage over time p loss predictions and balancing analysis of management or climate change scenarios as well as for testing hypotheses regarding p cycling mechanisms although many hydrological and biogeochemical models exist only some of them are able to simulate the transport of p through the soil and a large share of nutrient fate models entirely omit p turnover the state of p transport and turnover models has been subject to several reviews in the past e g lewis and mcgechan 2002 qi and qi 2016 radcliffe et al 2015 vadas et al 2013 wellen et al 2015 but most of them only considered a small selection of currently available models lewis and mcgechan 2002 summarize the state of four catchment models with regard to nitrogen n and p losses to groundwater and surface waters following the application of agricultural waste processes considered are the transport of soluble and particulate p surface application e g as fertilizer mineralization immobilization adsorption desorption leaching runoff and uptake by plants in agricultural systems radcliffe et al 2015 reviewed eight models more recently they examined their suitability for simulating p losses occurring in drainage waters from artificially drained fields for this purpose they also included information on macropore flow but confined to agricultural soils in another study wellen et al 2015 compared the n and p components of five spatially distributed models since the transport through macropores is not considered in their review the information contained is of limited use for forest soil applications qi and qi 2016 focused in their review on p loss through subsurface tile drains in nine water quality models models that cannot simulate tile drainage were excluded vadas et al 2013 also contains information about p transport but here the emphasis is on the challenges in developing new models the models considered are compared in regard for diffuse p losses from agricultural soils preferential flow is not taken into account these five reviews cover the processes of 17 models in total but all lack important information with regard to forest ecosystems or other ecosystems with dominating pfps to close this gap we review existing p transport models with a focus on their applicability for agricultural as well as forested ecosystems to simulate not only the transport of dissolved p but also particulate p the emphasis of this work is not the calculation of total p losses but the documentation of processes involved as well as potential improvements in process representation as an analytical framework we focus on the representation of the following model features temporal and spatial scale p pools and forms mechanisms of surface and subsurface transport with a focus on different flow paths for dissolved and particulate transport soil water solution interactions with the soil matrix p uptake by vegetation we apply this framework to a large number of environmental models that simulate transport of p or generalized nutrients thereby we consider models of different scales from plot to catchment scale and complexity in contrast to the previous reviews we establish a broad overview of all available models for the simulation of p transport 2 scope of models included the most important criterion for a model to be included in this review is the ability to simulate p cycling or the transport of solutes in general through soils to find suitable models we searched isi web of science database using keywords like phosph solute s transport or leach in combination with hydrological model l ing some models were also reported to us personally or found because they were referenced in scientific papers instead of finding them via web of science we included all dynamic numeric models found this way that were used for the modeling of p regardless of the complexity of the transport mechanisms or whether a validation for p transport exists in total we found 26 models that could be used for the investigation of p transport in soils for a first classification we analyzed the model types these can be divided into process based conceptual and empirical while for process based and conceptual models a theoretical understanding of relevant processes is necessary cuddington et al 2013 empirical models are based on empirical observations and do not make any statement about the underlying mechanisms and influencing variables both process based and conceptual models are mechanistic models based on a biogeochemical background while process based models try to represent the processes as accurately as possible conceptual models are created by a distinct conceptualization or generalization consequently they are greatly abstracted and simplified however most models cannot be clearly assigned to one of these types as they often contain components from more than one type addiscott and wagenet 1985 we summarized these models as mixed type models despite this uniform term these models can differ greatly from one another while some models are mainly process based but with some conceptualized features other models are contrary as a clear guidance to differentiate process based and conceptual models we decided to define all models that include the solution of partial differential equations pdes for transport simulation and a complex nutrient routine see below as process based models that include only simplified transport and nutrient components are defined as conceptual while models with either a simplified transport component or a simplified nutrient component are mixed types in addition to this distinguishing feature other important model characteristics are for example the spatial and temporal scales the spatial scale determines the way individual processes are represented in the models micro scale models i e soil profile and plot scales only simulate vertical infiltration and transport processes but no lateral processes large scale approaches simulate the processes for example on hillslope or catchment level the temporal scale of the models also differs significantly while some models are only able to represent very short time periods e g single precipitation events other models can simulate periods over one or several years see section 2 2 another distinction is the amount of data required for parameterization of the model sharpley et al 2002 this is closely related to the level of complexity of represented processes and therefore to the model type typical required data include land use soil texture topography and management practices the amount of data needed and the number of parameters increase with increasing mechanization of the models the data considered in these models can be a combination of collected field data and experimental data but also model results therefore we first examined all models with regard to these differentiation criteria in order to provide an overview the results of this initial classification and some additional general information are shown in table 1 in the following we will discuss the characteristics of the individual models in more detail 2 1 model overview the models in this review represent a wide range of different approaches with many similarities and overlaps in table 2 we give a short overview of the main objectives of every model as well as the land use forms for which they were primarily developed however even those models that were developed explicitly for one ecosystem can often be transferred to another based on the processes included at the same time the fact that a model has been developed for a specific ecosystem does not guarantee that it includes all the important processes to simulate p transport there in order to overcome this confinement some models offer the possibility to be coupled with other models to complement missing processes for example animo does not consider hydrological components but it can be combined with swatre belmans et al 1981 or watbal yates 1996 also pdp is not able to simulate transport of particulate p in surface water and dissolved p in runoff from dry and paddy lands but huang et al 2016a solved this problem by coupling the model with usle and inca p phreeqc is not able to simulate water flow and solute transport on its own so mao et al 2006 coupled it with seawat to close this gap the resulting model which is called phwat is not included in this review since we were not able to find information on p transport further models exist that are not considered in this review although they are able to simulate p transport through the environment for example surphos vadas et al 2007 simulates the fate and transport of p in agricultural systems but since it focuses on surface applied manure and dissolved p loss in surface runoff it is not relevant for p loss through the soil another excluded model is aple which is a microsoft excel spreadsheet model vadas et al 2012 it simulates p loss in runoff and soil p dynamics over ten years on annual time steps there are often different versions of the models we present in this review for example different versions of hydrus exist for different scales e g hydrus 1d and hydrus 2d 3d which are summarized for this review under the term hydrus moreover rzwqm2 p is a derivate of the whole system model rzwqm2 sadhukhan and qi 2018 the same applies for drainmod p which is based on drainmod askar 2019 tian et al 2012 developed another drainmod adaption named drainmod forest to simulate water and nutrient dynamics in drained forest soils however this model is based on the official drainmod release which is why it lacks important features included in drainmod p other included models are built from one or more predecessors for example apex is a derivative of epic and adapt is an extension of gleams with the hydrological component of drainmod icecream db is based on the finish model icecream larsson et al 2007 and the soil water and heat model soil the models inca p and simplyp have recently been re implemented within the mobius model building framework norling 2019 phreeqc a geochemical reactive transport model is based on reaction kinetics of chemical processes it uses ion association pitzer or sit specific ion interaction theory equations for the calculations of solute activities e g 1d transport parkhurst and appelo 2013 2 2 temporal and spatial scale the spatial and temporal scale has a large impact on the properties and functions of a model whereby both can be influenced by the model type while pure mechanistic models are mostly suitable for small spatial scales and rather short periods of time usually less than a year or even less than a day more empirical models can be used for annual or even multiyear simulations and at larger spatial scales radcliffe et al 2015 sharpley et al 2002 and haygarth et al 2005 pointed out which processes are important for p transport depends on the model scale for example the representation of detachment deposition and resuspension of soil particles differ between plot and catchment scales on small scales processes are often described in detail while on larger scales processes are represented by more simple empirical relations and soils often are grouped in associations savenije 2001 describes this as averaging processes scale dependency is evident not only in the spatial scale but also in the temporal scale in particular the time steps of a model have a great influence on the degree of detail e g a model with a resolution per second requires consideration of completely different processes than a model with daily time steps the temporal and spatial scales of all 26 models are depicted in table 1 for this overview the spatial scale was subdivided into soil profile one dimensional plot larger areas but homogeneous weather and soils equivalent to a field in agricultural models and catchment with increasing range soil profile and plot scaled models both focus on vertical fluxes and therefore often make similar assumptions while only three of the models in this review are restricted to one dimensional simulations of soil profiles nine models are specialized for plot and ten for catchment scale applications the remaining four models can be used flexibly for different scales the model swap was developed for plot scaled modeling but via the use of geographical information systems and definition of additional features upscaling to regional scale is possible another important factor is the spatial disaggregation which varies strongly between the models catchment scale models use a variety of lateral spatial disaggregation the models annagnps apex hype inca p swat and swim split the area into hydrologic response units hru which are combinations of homogeneous land use management topographical and soil characteristics arnold et al 2012 hgs provides several options ranging from simple rectangular domains to irregular domains with complex geometry and layering aquanty inc 2016 other models use grid cells answers 2000 camel and hydrus partitioning based on single features like land use hspf and pdp sub catchments lascam or p content classes simplyp soil profile and plot scaled models i e animo daycent drainmod p epic gleams icecream db macro phreeqc please rzwqm2 p and swap do not use lateral discretization adapt is also designed for plot scale applications however gowda et al 2007 used the concept of hrus to simulate whole watersheds in general plot scale models can also be used for larger areas as long as they are homogeneous for example for soil weather and management practice the size of the plot depends on the desired resolution and precision gerik et al 2015 likewise the disaggregation with depth differs between the models for example inca p and simplyp simulate one soil layer and one deeper mineral soil groundwater layer in lascam the soil is divided into three conceptual storages namely a perched near stream aquifer permanent groundwater and an intermediate unsaturated store other models subdivide the soil into more layers e g up to ten daycent epic rzwqm2 p 12 gleams 50 animo or even 200 macro freely chosen by the user besides the spatial scale the temporal scale also differs between the models typical time spans for many models are in the range of years only a few models are explicitly set up for the simulation of short periods e g on the scale of single precipitation events e g macro phreeqc or hydrus this does not mean that the models mentioned cannot simulate longer periods but it is not recommended due to the absence of processes that are important over longer periods the exact simulated period can usually be determined by the user whereas the time steps are mostly fixed 16 models use daily time steps while only phreeqc features a resolution per second the model answers 2000 follows a unique approach since it uses 30 s time steps during runoff and switches to daily time steps between runoff events rzwqm2 p simulates crop growth nutrient balance and pesticide modules on daily time steps and soil water soil heat transfer and surface energy balance on sub hourly time steps in macro precipitation data can be either hourly or daily while the output can be chosen freely still the calculation steps are defined internally hydrus also declares the time steps internally but the user can choose time step controls with which the time steps are automatic adjusted during computation the remaining six models animo drainmod p hgs hspf rzwqm2 p and swap allow the range to be chosen freely 3 phosphorus pools and forms with regard to the p routines the 26 models reviewed here can be divided into several groups with different degrees of complexity an often used approach is the conceptual soil p model of jones et al 1984a in this approach three interconnected inorganic p pools are modeled labile p active p and stable p as well as two organic p pools fresh organic p stable organic p an initial value for labile p is given by the user as an input parameter and based on this active and stable p are calculated furthermore some models follow similar structural approaches as jones et al 1984a although single pools and forms of p deviate other models only consider dissolved p and particulate p without further differentiation and finally there are some models in this review that do not have readily available p routines at all so for modeling of p transport the user has to parameterize a general solute transport component to represent different p forms all the models without a readily available p routine hgs hydrus macro and swap were used in the past for the simulation of p the parameterization results mostly in very simple p routines including only basic pools e g dissolved p or total p it is possible to parameterize swap for the simulation of dissolved p but kroes et al 2017 recommend coupling it with animo to simulate p or n processes to improve the p modeling of hydrus nahra 2006 coupled hydrus 1d with nica and created a po4 routine for soil water but this is not included in the official release of hydrus although these models without readily available p routine can be used to simulate p transport via appropriate parameterization the lack of p transformation and reaction processes results in the primary suitability for small periods of time e g individual precipitation events still since this review contains models of different complexity and applicability we decided to include these models except for hgs the performance for the simulation of p of all these general solute transport models was validated some models with p specific turnover routines i e answers 2000 camel daycent and swim miss any published validation with field data the p routine of jones et al 1984a was originally created for the model epic williams et al 1983 but it is also used in adapt annagnps answers 2000 apex camel drainmod p gleams icecream db rzwqm2 p swat and swim while all of these models p routines are based on this foundation they still comprise different modifications for example epic contains a constant p sorption parameter for an entire simulation while annagnps calculates this parameter daily based on changing soil properties vadas et al 2013 and swat calculates it dynamically at the beginning of each simulation year collick et al 2016 this distinction can lead to very different sizes of the p pools in drainmod p the organic p pools are based on the organic n routine from drainmod n ii youssef et al 2005 the model rzwqm2 p contains an additional routine for calculating the loss of particulate p via surface runoff and tile drainage there is also a modification for gleams to simulate the transport of particulate p namely an extension called partle shirmohammadi et al 1998 therefore of these models only rzwqm2 p and gleams allow for particulate p movement to be simulated whereas all other models based on this approach by jones et al 1984a are not capable of doing so see table 4 other models with structurally very similar p routines to jones et al 1984a are inca p jackson blake et al 2016 wade et al 2002 and simplyp jackson blake et al 2017 both simulate dissolved p inactive soil p and labile soil p another similar approach can be found in please schoumans et al 2013 van der salm et al 2011 which depicts dissolved inorganic p adsorbed p and soluble p slightly more complex is the approach of animo groenendijk and kroes 1999 which simulates in addition to three inorganic p stores dissolved adsorbed and precipitated inorganic p also three organic p stores dissolved stable and fresh organic p hype includes three immobile p pools inorganic adsorbed to soil particles organic with rapid turnover and organic with slow turnover and two mobile pools particulate and soluble p the p routine of hspf is based on the agchem module diaz ramirez et al 2013 here p is simulated as sediment attached dissolved in surface runoff and as concentrations in the interflow and groundwater compartments the p routines of other models are simpler for example pdp huang et al 2016b simulates only dissolved p and particulate p likewise according to lewis and mcgechan 2002 daycent is able to simulate sorbed and labile soil p but no applications or validations thereof could be found lascam distinguishes only between organic adsorbed p and soluble p viney et al 2000 phreeqc herrmann et al 2013 moharami and jalali 2014 takes a very different approach since it is a hydro geochemical transport model and therefore depicts the actual chemical compounds the question of which of these methods produces the best results is not easy to answer as all methods have advantages and disadvantages as qi and qi 2016 pointed out a simplified representation e g hydrus macro and swap can lead to less accurate prediction results on the other hand a simplified representation can also lead to more accurate prediction results as improved performance during calibration can be due to overfitting rather than improved process representation e g perrin et al 2001 seibert 2003 4 transport components for transport processes a distinction can be made between dissolved and suspended transport surface and subsurface transport and transition between mobile and immobile forms not all models include every transport component due to different spatial foci phreeqc is a 1d model of vadose zone transport and therefore lacks surface transport while conceptual large scale models like lascam simulate only dissolved p and no mobile immobile transition table 3 summarizes which water compartments are included in the models in order to provide an indicator for possible uses of the models 4 1 surface transport many models are capable of simulating the transport of p at the soil surface as shown in table 4 this can take place in various ways while some models only represent the transport of dissolved p other models simulate both the surface transport of suspended particulate p and dissolved p different mechanisms can be used for different transport routes dissolved p for example can either diffuse from soil solution of the upper soil layer or be released from sorption as a function of the extractability of p in the near surface soil sharpley et al 2002 suspended p is mostly simulated coupled with erosion most models simulate erosion using the universal soil loss equation usle wischmeier and smith 1978 or some modification of this like the modified usle musle williams 1975 or the revised usle rusle renard et al 1991 usle is a simple empirical approach for predicting long term average annual soil loss it is based on various factors like rainfall erosivity soil erodibility topography and cropping management a more complex technique is the process oriented modeling of erosion where detachment transport and deposition of sediment are simulated discretely wolfe 2007 however this technique is rarely used table 4 shows how the different models simulate erosion as well as surface transport of p models that are able to simulate surface transport of both dissolved and particulate p are adapt answers 2000 apex camel daycent epic gleams hspf icecream db inca p lascam rzwqm2 p simplyp swat and swim many of these models are not able to simulate the transport of particulate p through the soil still to represent the transport at the surface this is circumvented by coupling the surface transport of p via a transport factor to the erosion of sediments from all the models in this review many models e g adapt annagnps camel epic lascam and swat calculate surface transport of dissolved p based on the concentration of labile p in the top soil layer runoff volume and an extraction coefficient in please p loads from a field to surface waters are estimated based on a function of depth and the distribution of total annual horizontal water flux schoumans et al 2013 for the transport of particulate p icecream db assumes the same distribution between the p pools in the eroded material as in the bulk soil yli halla et al 2005 on the contrary particulate p transport in overland flow is often simulated by a logarithmic relationship between p enrichment ratio and sediment discharge menzel 1980 this is in accordance with the fact that eroded p is preferentially attached to the finer sediment particles which tend to be first eroded viney et al 2000 therefore eroded particulate material is mostly enriched with p compared to surface soil sharpley et al 2002 for example in lascam p concentrations decrease as the mass of eroded material increases similar enrichment ratios are also used for example in adapt and gleams 4 2 subsurface transport different approaches exist to simulate the infiltration and transport of water and solutes in soils infiltration is very often calculated using a conceptual curve number approach national resource conservation service nrcs 2004 or the green and ampt equation alternatively a constant infiltration rate can be assumed or infiltration can be capacity based approaches that are more complex calculate infiltration based on the hydraulic gradient richards equation table 3 shows how this is implemented in the different models for simulating water transport through soils a commonly used conceptual approach is a storage routing representation this approach often described as tipping bucket always fills one storage until field capacity is reached before the excess water is routed to the next layer this simple approach is used in most conceptual models but also in many models classified as mixed type still it has several drawbacks e g it is not able to simulate upward flow therefore they have certain disadvantages compared to physical based approaches for example when simulating shallow water table soils for process based models the subsurface water flow and solute transport can according to the classification of šimůnek et al 2003 be grouped in single porosity dual porosity and dual permeability approaches the different concepts are shown in fig 1 single porosity approaches only simulate water flow and solute transport through the soil matrix a variation of this approach is supplemented by a fast bypass flow component fig 1b here the bypassed water and solutes are directly routed to the groundwater or catchment outlet so there is no interaction between the slow and the fast water components this differs in dual porosity fig 1c and dual permeability fig 1d models where it is assumed that the porous medium consists of two interacting regions one region represents the macropores while the other comprises the micropores inside the matrix in dual porosity models water in the matrix is stagnant whereas dual permeability simulates water flow in both macropores and matrix additionally some dual permeability models simulate not only slow matrix and fast macropore transport but also immobilization processes šimůnek et al 2003 fig 1e in all these different approaches the transport of solutes is predominantly simulated as relatively simple physical relations e g via the convection diffusion dispersion equation gerke and van genuchten 1993 šimůnek et al 2003 an even simpler approach to calculate solute transport which is frequently used in conceptual models is to multiply the concentration of solute by the water flux 4 2 1 matrix transport in single porosity models fig 1a saturated water flow is mainly simulated via storage routing or the darcy equation particularly for groundwater flow whereas for unsaturated conditions the richards equation is the most used equation single porosity models are answers 2000 daycent epic gleams hspf lascam pdp please and swim see table 3 of these models answers 2000 epic gleams lascam and swim use the storage routing approach while daycent represents matrix transport using the richards equation pdp does not simulate the soil divided into soil layers as it was developed specifically for polder systems instead it describes the water balance in four land use areas namely residential area surface water area paddy and dry lands without vertical transport of water and p through the soil please also does not simulate the vertical transport of water and solutes since it focuses on the total amount of leached p instead of its transport routes therefore the soil is not divided in different layers but the loss of p is calculated based on empirical assumptions i e the concentration of p and the total groundwater outflow as a function of depth in this model only horizontal runoff is calculated matrix flow is also not included in the models annagnps and phreeqc since phreeqc is a dual porosity model water and solutes in the matrix are stagnant and only transported via macropores annagnps focusses on surface runoff and does not consider vertical leachate however lateral subsurface flow is calculated based on darcy s equation and assumed homogeneous through the entire soil profile bingner et al 2015 the remaining models all have a second faster transport route see section 4 2 2 still their matrix transport components are mostly similar to single porosity approaches namely six models i e apex camel hype inca p simplyp and swat with storage routing and six models hgs hydrus icecream db macro rzwqm2 p and swap using the richards equation drainmod p uses the darcy equation with dupuit forchheimer assumptions this approximation assumes that flow lines are parallel to the impermeable sublayer and thus that lateral flow processes can be separated from vertical processes this is reasonable when the rate of subsurface flow is low clark et al 2015a kampf and burges 2007 the model adapt is unable to simulate unsaturated water transport but since its hydrologic component is based on drainmod vertical transport through the matrix is simulated using the darcy equation animo has to be coupled with another model to represent hydrological processes since the model itself is not capable of simulating water transport components the transport of solutes through the matrix differs little between the models mostly it is calculated by convection diffusion equations animo drainmod p gleams hgs hydrus icecream db macro and swap kroes et al 2017 recommends combining swap with animo for a more realistic simulation of p transport in hspf subsurface transport of dissolved p is simulated by adjusting the ratio of surface to subsurface total p radcliffe et al 2015 for many of the models we were not able to find published information on the exact mechanisms of solute transport however apparently most models are able to simulate transport via water movement contrary the transport of particulate p is restricted to macropores so none of the single porosity models is able to simulate this process explicitly 4 2 2 macropore transport macropore transport is usually much faster than transport via matrix in many models i e adapt animo apex drainmod p hype icecream db inca p rzwqm2 p simplyp swap and swat it is simply represented as an additional fast bypass component in simplyp this quick flow component is simplified even more since it includes not only macropore flow but also saturation excess overland flow tile drainage and runoff from impervious surfaces jackson blake et al 2017 many soils especially those of forests grasslands and no tillage agriculture usually contain macropores hence transport through pfps as well as interactions between pfps and the matrix are important for p translocation bogner et al 2012 bundt et al 2001 julich et al 2016 as these interactions cannot be represented by bypass flow this transport route is mainly of interest for the modeling of agricultural soils with drainages while dual porosity and dual permeability approaches are representations of macroporous soils that are more realistic according to qi and qi 2016 macropore flow in dual permeability models is mostly represented either by richards equation kinematic wave approach or gravitational flow using poiseuille s law to calculate water infiltration into macropores while macropore flow based on the richards equation considers both gravitational flow and capillary driven flow the kinematic wave equation only includes the vertical gravity flow and ignores capillary since poiseuille s law premises that the macropores are cylindrical this approach is less accurate when the pores deviate from this assumption šimůnek et al 2012 moreover poiseuille s law assumes saturated conditions which only rarely applies to macropores jarvis 2007 of all the models presented in this review only five models contain dual porosity or dual permeability representations namely camel hgs hydrus macro and phreeqc while phreeqc is restricted to dual porosity the models hgs hydrus and macro are able to simulate both dual porosity and dual permeability systems camel takes a special position because the unsaturated soil is simulated simply as a single porosity system but it uses a dual permeability approach for the saturated aquifer this groundwater flow is simulated via darcian flow with two different hydraulic conductivities the dual permeability models hgs and hydrus use the richards equation for both matrix and macropore water flow in macro water transport through macropores is simulated via kinematic wave approach since phreeqc needs to be coupled with another model to simulate water flow it is not possible to specify the mechanism for example wissmeier and barry 2010 created an extension for unsaturated flow in phreeqc which enables the use of the richards equation generally existing models with a second flow component follow various approaches for the representation of solute and particle transport through macropores and how the exchange between matrix and macropores is modeled djabelkhir et al 2017 šimůnek et al 2003 for example in hydrus this is solved similar to most single porosity approaches solute transport is calculated via convection diffusion type equations gerke and van genuchten 1993 this is true for both fracture and matrix regions but with different parameter values assigned šimůnek et al 2003 in hydrus the exchange of water between matrix and macropores is driven by the gradient of pressure heads in macro the exchange of water from macropores to micropores is calculated using a mass transfer expression while the transport of solutes is calculated neglecting dispersion since advection is assumed to dominate in phreeqc various mechanisms are available advective transport advective dispersion transport 1d and diffuse transport 2d and 3d the model swat is only capable of simulating bypass flow and lacks a p transport component for the macropore pathways which is why it is not applicable for the physically correct simulation of p transport processes in macroporous soils radcliffe et al 2015 in rzwqm2 p the water flux through macropores is simulated via poiseuille s law which is based on gravitational flow dissolved reactive p and particulate p are directly routed from the first soil layer to the groundwater without interaction with the matrix sadhukhan and qi 2018 in swap water can be infiltrated into macropores at the soil surface and then be transported into deeper soil layers the model distinguishes between continuous horizontal interconnected macropores and discontinuous macropores ending at different depths so water and nutrients can be transported to various soil layers additionally the macropores are divided into static and dynamic kroes et al 2017 for apex ford et al 2017 recently developed a new modification to implement macropores they distinguish between matrix excess macropores and matrix desiccation macropores matrix excess macropores appear when saturation exceeds the water entry pressure of the matrix while matrix desiccation macropores occur at low moisture conditions and form a draught crack network the latter is modeled as a function of clay content and potential evapotranspiration demand deficiency in this approach macropore flow of dissolved p is assumed to equilibrate with the surface soil so p is partitioned between adsorption on the soil surface and transportation through the macropores by using the langmuir isotherm water transport takes place in the form of a bypass flow to the bottom soil layer and when its capacity is exceeded it is moved upwards to the next unsaturated layer 4 2 3 mobile immobile transition in dual porosity models the exchange of p and solutes between macropores and matrix is typically associated with mobilization and immobilization processes aside from these processes especially single porosity models also often simulate immobilization of p via adsorption immobilized p is generally not congruent with particulate p but in some model descriptions these two terms are used synonymous in most models that are able to simulate particulate p it is considered as immobile or it can only be transported by surface erosion jones et al 1984a created the concept of stable vs dissolved p for epic and this has been used in all models building on epics p concept see section 3 here stable p is only transported by surface erosion and is therefore excluded from leaching the immobilization of p in many other models works in similar ways heathwaite 2003 and vadas et al 2013 criticize this because this p routine has seen very limited updates especially movement of particulate p within the soil is therefore missing in most models only the models gleams via the extension partle hype inca p pdp rzwqm2 p and simplyp table 4 are able to simulate the transport of particulate p the transition between immobile and mobile p is often realized by an equilibrium function for example as described in section 3 models with p routines based on jones et al 1984a simulate the mobile immobile transition by creating an equilibrium between stable and active mineral p and between active mineral p and labile mineral p this equilibrium between the three pools is based on the user given value for labile p and the relative sizes of the pools are soil specific the equilibria can be disturbed by different processes for example leaching dissolved loss in run off and plant uptake of labile p or loss of stable or active p via erosion when this happens the imbalance is calculated and then p is moved between the pools to restore balance vadas et al 2013 the equilibrium between labile and active pools can be restored within several days or weeks while the equilibrium between active and stable pools is slower jones et al 1984a despite this similarity between so many models small differences exist between these approaches for example in adapt and gleams the partitioning of mineral p between aqueous and solid phases is implemented via a partitioning coefficient according to the linear adsorption isotherm radcliffe et al 2015 simplyp also uses a simple linear relationship to equilibrate labile soil p and dissolved p jackson blake et al 2017 the p routine of apex is also based on jones et al 1984a but this model uses the langmuir isotherm for adsorption also in please the dissolved inorganic p concentration is calculated using the langmuir isotherm equation radcliffe et al 2015 van der zee and bolt 1991 while the amount of reversibly sorbed p in the top soil layer is related to the water extractable p and oxalate extractable al and fe content radcliffe et al 2015 schoumans and groenendijk 2000 in deeper layers sorbed p decreases with depth based on a first order exponential expression animo provides the langmuir isotherm and the freundlich isotherm which is also used for example by hype inca p macro and swap lascam is not able to simulate mobile immobile transitions unfortunately for many models it was not possible to find detailed descriptions of how they simulate mobilization and immobilization 4 3 plant p uptake and removal an important difference between arable land and forests is the annual harvesting of crops from fields while forest trees are harvested irregularly or not at all in addition harvest and other management actions such as thinning often focus on selected trees without removing the entire stand this leads to differences in nutrient circulation examples of models that can simulate within year variations in both annual and perennial plant p uptake are epic inca p swap swat and swim in swap the disparity between annual and permanent affects not only plant growth but also rainfall interception for agricultural crops infiltration is calculated using the hoyninger braden equation whereas for forests the gash equation is used kroes et al 2017 models that appear to represent only annual crops are for example annagnps and rzwqm2 p in both models crop properties such as cultivating and harvest time tillage and fertilization need to be given as inputs another important factor is the method of calculation of plant p uptake it can be divided into different approaches namely supply driven and demand driven plant uptake as well as combinations of both while supply driven approaches simulate p uptake by plants based on the p concentrations in soils demand driven plant uptake is mainly based on the demand of the plants directly an example of demand driven p uptake can be found in gleams knisel and davis 2000 the uptake of labile p is estimated for each layer where transpiration occurs with the total uptake from all layers equal to the plant p demand the plant p demand is a function of the optimum leaf area index which is tabulated for a large number of crops over a growing season this approach is based on the formulation of the epic model where the potential plant uptake of labile p is simulated as a linear function up to a user specified critical concentration jones et al 1984a a similar approach was chosen in lascam where plant p uptake depends on the rate of canopy biomass accumulation instead of the optimum leaf area index so that it varies seasonally viney et al 2000 in daycent a combination of demand driven and supply driven p uptake is implemented plant p uptake is controlled by the size of the labile p pool whereas in turn the labile p pool varies with the size of the mineral n pool additionally the uptake of labile p is constrained by upper and lower limits for nutrient content in the shoots and roots which in turn are considered as a function of plant biomass lewis and mcgechan 2002 in apex p uptake is also simulated as a combination of demand and supply driven with the root weight as an confinement factor of the supply williams et al 2015 other models that simulate plant p uptake represented by a combination of both approaches are for example inca p jackson blake et al 2016 rzwqm2 p sadhukhan and qi 2018 and drainmod p askar 2019 hydrus can simulate chemical uptake of plants both passively and actively passive uptake is based on the feddes equation and p in soil solution while active uptake is based on the michaelis menten equation qi and qi 2016 in macro plant chemical uptake is included via a source sink term in the solute transport equation qi and qi 2016 for many models it was not possible to find out how they simulate plant uptake exactly see table 4 but it is likely that in most cases it is implemented very simplistically for example as a simple demand driven uptake based on c n p ratios in the plants 5 future developments in environmental process based p modeling 5 1 general suggestions for improvements as shown in this review there are a number of environmental models with p routines depending on the focus of the models they show significant differences in order to provide an overview of the existing models we created a decision tree see fig 2 there we present the different transport routes of the individual models single porosity dual porosity and dual permeability as well as the specific p forms that are included the color code of the figure follows the traffic light principle i e green boxes represent most accurate process representation e g dual permeability and transport of dissolved and particulate p orange boxes indicate less exact model structures e g dual porosity and dissolved p transport with immobile particulate p component and red boxes show the simplest representations no macropores no functioning p routine however this does not mean that the simpler models are generally unsuitable for calculating p fluxes through different ecosystems depending on the question and the complexity required the models can still be very useful it is noticeable that there is no model for which all processes are represented most accurately green to simulate p transport through forest soils many models simulate p transport based on a more than 30 years old approach by jones et al 1984a and we could not find many improvements over the last decades in p modeling often there is no reason against this established method but depending on the research question the lack of a mobile particulate p component can be a major deficit according to heathwaite 2003 and vadas et al 2013 the focus on the development of data intensive complex models instead of more generic models is a main reason for current deficits in modeling in line with this radcliffe et al 2015 recommend to revise p modeling and to develop new improved routines considering our focus of interest this might be especially the transport of particulate p which is only implemented in very few models additionally model performance needs to be tested specifically for p to make sure that simulation results of soil p dynamics are reliable this is a flaw of many existing models since simulated soil p dynamics are rarely presented besides this critique of the p routines and the often found lack of dual permeability approaches there are many other potentially important processes which might be worth considering for model development for example p uptake by trees and other plants might deviate from p uptake by crops surface transport groundwater and stream components are usually important components due to stem flow nutrient inputs might be concentrated locally levia and frost 2003 atmospheric particulate deposition might be increased due to interception lequy et al 2014 some of the named models include most of the processes we consider important the newly improved rzwqm2 p deserves particular mention here as it contains a complex p routine including mobile particulate p as well as a fast bypass component but no dual permeability still the possibility to up and downscale the model specific to the current research question would be an advantage this is very hard to realize since a change of scale results in a shift in the important processes moreover such a high flexibility in the model structure might lead to very complex models with many parameters for different reasons a large number of parameters can increase the inaccuracy of a model for example often parameters have no physical basis they might be impossible to measure in the field djabelkhir et al 2017 or measured parameters can be scale dependent and therefore not representative radcliffe et al 2015 and nelson and parsons 2006 also pointed out that there is generally a lack of guidance on how to obtain independent values for additional parameters in over parameterized models the values of individual parameters cannot be unequivocally identified by the data so called equifinality see beven and freer 2001 so prediction uncertainty might increase moreover small inaccuracies of individual parameters can lead to very large total errors this is for example criticized by buytaert et al 2008 as an over complexity of most models they propose a number of directives that should be followed when developing new models the model code should be fully accessible modular and portable this way the user is enabled to use a model in a highly flexible manner with improved control over the modeling assumptions for example modularity allows the user to choose whether particular processes should be represented either by mechanistic equations or by empirical relations it also simplifies the addition of new independent routines to represent additional processes this way in modular and accessible approaches the spatial discretization and the temporal disaggregation can be adjusted more easily all these suggestions are in accordance with the postulation of clark et al 2011 for the development of modular frameworks modeling frameworks are toolboxes that provide a variety of different processes which can be assembled into a model by a user the resulting model can thus be tailored to specific tasks although the compatibility of the individual process representations can be problematic this enables a large number of different models to be created without high programming effort moreover modeling frameworks are suitable for testing of multiple working hypotheses such an approach would be of great advantage for modeling p dynamics as the comparison of different hypotheses would allow testing which processes are actually important this way it could be analyzed which macropore transport component is sufficient fast bypass dual porosity or dual permeability or to what extent the included process representations depend on the spatial and temporal scale existing modeling frameworks are for example the catchment modelling framework cmf kraft et al 2011 summa clark et al 2015a 2015b raven craig and the raven development team 2019 and the more generic mobius norling 2019 unfortunately until now no existing hydro biogeochemical modeling framework is able to simulate p transport through soils 5 2 a blueprint for a process based p model for different ecosystems in this section we present a blueprint for a process based and modular environmental p model as outlined in section 5 1 a major disadvantage of most existing models is that they are static i e the process representations are predefined and cannot be altered modularity provides an option on how a model could be designed that allows the user to test and compare different hypotheses with regard to the results of this review the presented blueprint could be used to examine whether an explicit representation of macropores can improve modeling p dynamics in different soils and on different scales additionally different p routines could be compared without other factors being modified for this purpose a model should contain only the most important processes to simulate the transport of p in different environments i e arable land grassland and forests nevertheless in order to be able to test hypotheses for different landscapes and scales a large number of processes must be representable 1 the model should include different hydrological processes from which a user can choose see fig 3 top for example for infiltration e g green ampt curve number and percolation e g richards equation storage routing or optional features like snow storage 2 there should be different options for the transport through the soil i e parallel matrix and explicit macropore transport fig 3 and as a more simplified alternative direct infiltration into deeper layers via macropores the horizontal transport via macropores to the stream savenije 2018 should also be included as an optional feature 3 the possibility to connect different spatial entities gridded cells polygons horizontally for example via darcy richards or kinematic wave equation would allow for the construction of models ranging from plot to regional scale 4 for the simulation of p transport and turnover we propose the development of a p routine loosely based on jones et al 1984a but including the transport of particulate p as depicted in fig 3 bottom we differentiate between the transport of p through the soil matrix and if simulated explicitly macropores while processes in the matrix are represented in more detail the processes in the macropores are strictly simplified since the transport processes in pfps are based on gravitational flow the distinction between dissolved and particulate p will be sufficient these pools will be in equilibrium with the five pools in the soil matrix as an alternative approach a highly simplified p routine could be integrated which only distinguishes between dissolved and particulate p in both matrix and macropores 5 for the simulation of plants different possibilities should be included i e a differentiation between permanent forest and grassland versus annual plants and crops in order to achieve this flexibility we promote the implementation of this approach in a modeling framework since the catchment modeling framework cmf kraft et al 2011 offers a multitude of possibilities including the representation of macroporous flow and transport this framework is ideal for implementing a p routine obviously the modular modeling approach presented here can be further extended in order to be of use for even more tasks for example it could be possible to couple the p routines with the c and n cycles or to calculate the effect of nutrient states on the net primary productivity an extension to weathering processes is also possible the accessibility and modularity of modeling frameworks like cmf would allow such diverse approaches to be realized therefore while the blueprint presented here is certainly not a universally valid model for the simulation of p transport it qualifies as a good basis for hypothesis testing and provides the possibility for further refinements and adjustments 6 conclusion we reviewed 26 models that are able to simulate p transport through the soil still their foci are very diverse and therefore the representation of processes varies greatly most of the models were originally created for the simulation of processes in agricultural soils while some of these models were extended for other ecosystems it is likely that processes relevant in non agricultural environments are not well represented these include for example the uptake of p by plants other than crops or the transport through pfps moreover while all models in this review are able to simulate some sort of p transport and turnover they have not necessarily been established for this purpose for this reason the p routines of many models have only been tested in very limited experiments or not been tested at all only please inca p simplyp and pdp focus especially on the simulation of p leaching from soils furthermore the movement through the soil of particulate p is an important aspect of p leaching julich et al 2016 yet this process is only represented in seven of 26 models in all these models the transport is represented by a fast bypass component in order to be able to represent this transport process more realistically the simulation of a dual permeability system could be appropriate since no model fulfils all hypothesized demands we developed a blueprint of a modular model for the simulation of p leaching through different soils especially when it is implemented as part of a modular hydrological framework this approach could help to compare different hypotheses e g under which circumstances the explicit representation of a dual permeability system is appropriate it could also be used for further developments in modeling of p transport in order to improve the modeling of p processes in the environment we think that a shift towards the use of modeling frameworks is necessary by enabling multiple hypothesis testing we envisage substantial improvements in p modeling quality in addition the transferability of the models to different conditions e g various land use forms should be given greater consideration for this purpose the agreement on well established methods might be necessary also in the generation of experimental data only when sampling is comparable e g comparable depth consideration of macropores or same analysis methods for p can the data be used to develop comparable models which are of interest for more than an individual case study if these suggestions are considered we assume that an improvement of the modeling of p is possible declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this project was carried out in the frame of the priority program 1685 ecosystem nutrition forest strategies for limited phosphorus resources funded by the dfg subproject quantification modeling and regionalization of seepage losses of phosphorus from forest soils br 2238 26 2 table a 1 overview of model references and references for performance testing of phosphorus simulation model model reference reference for p routine testing adapt gowda et al 2012 dalzell et al 2004 animo groenendijk and kroes 1999 kroes and roelsma 1998 van der salm and schoumans 2000 annagnps bingner et al 2015 yuan et al 2005 pease et al 2010 yuan et al 2005 answers 2000 bouraoui and dillaha 2000 1996 na1 apex plotkin et al 2013 steglich et al 2016 bhandari et al 2016 francesconi et al 2016 saleh et al 2001 camel koo et al 2005 2004 na daycent parton et al 1998 na drainmod p deal et al 1986 tian et al 2012 askar 2019 askar 2019 epic jones et al 1984a sharpley and williams 1990 della peruta et al 2014 jones et al 1984b richardson and king 1995 gleams leonard et al 1987 knisel and turtola 2000 hgs brunner and simmons 2012 na hspf bicknell et al 1996 grimsrud et al 1982 johanson et al 1980 ribarova et al 2008 hydrus agah et al 2016 šimůnek et al 2008 agah et al 2016 freiberger et al 2013 hassan et al 2010 naseri et al 2011 hype lindström et al 2010 jiang and rode 2012 pers et al 2016 icecream db larsson et al 2007 bärlund et al 2008 larsson et al 2007 liu et al 2012 inca p jackson blake et al 2016 wade et al 2002 jackson blake et al 2017 2016 lascam viney et al 2000 viney and sivapalan 2001 zammit et al 2005 macro jarvis 1991 1995 mcgechan et al 2002 mcgechan 2003 mcgechan et al 2002 pdp huang et al 2016b huang et al 2016a phreeqc parkhurst and appelo 2013 1999 herrmann et al 2013 moharami and jalali 2014 please schoumans et al 2013 schoumans et al 2013 van der salm et al 2011 rzwqm2 p ma et al 2012 sadhukhan and qi 2018 sadhukhan et al 2019a 2019b simplyp jackson blake et al 2017 jackson blake et al 2017 swap gusev and nasonova 1998 kroes et al 2017 na swat arnold et al 2012 1998 grizzetti et al 2003 vadas and white 2010 swim krysanova et al 2005 na 1na means that we were not able to find this information 
26046,the coupling of a geographic information system gis and nonpoint source nps models has significantly promoted nps modeling and output visualization this study reported an approach using r to fully integrate the gis and a nps phosphorus indicator model as well as to build an interactive web interface for the model a case study in a semiarid northern china subwatershed showed that the proposed method was feasible flexible and effective our experiences demonstrated that developing a fully coupled gis nps model system in r could simplify nps modeling across computation platforms promote modeling efficiency implement dynamic simulations enhance model inputs outputs display and provide readily interactivity we envision that the experiences could provide a promising option for nps modeling keywords r language fully integrated approach geographic information system nonpoint source modeling 1 introduction as a tool for the management query visualization and analysis of spatially referred information gis has been recognized as a method to aid the modeling of nps pollution and to visualize the results in a spatial context beven and alcock 2012 liu et al 2014 shen et al 2013 many attempts have been made to couple nps models with a gis for both research and management purposes table 1 the couplings span various models such as usle answers agnps swat basins topmodel and phosphorus p indicator and various gis tools giss such as grass arcgis map window gis supermap and qgis bhatt et al 2014 di luzio et al 2004 fan et al 2015 hession and shanholtz 1988 huang and jiang 2002 joão and walsh 1992 kinerson et al 1999 liao 1996 liu et al 2014 nielsen et al 2017 olivera et al 2006 pullar and springer 2000 rewerts and engel 1991 srinivasan and arnold 1994 srinivasan and engel 1991a b tim and jolly 1994 zhang et al 2011 nyerges et al 1993 classified the gis model couplings into three categories loose tight or fully integrated each approach has its own advantages and disadvantages they differ to various degrees in the role of giss the manner of data exchange model suitability reusability and the requirements of programming capabilities generally the gis in loose coupling serves as both a preprocessor e g input generation and a postprocessor e g the results analysis and visualization liao 1996 liu et al 2014 martin et al 2005 the model and gis work unrelatedly with the data exchange usually being manually performed which could be tedious and error prone liu et al 2014 martin et al 2005 sui and maggio 1999 due to the loose coupling with gis the model users cannot take full advantage of gis functionalities such as spatial analysis because this approach avoids redundant programming it could be the most suitable choice for most gis users and environmental engineers to conduct modeling work liao 1996 liu et al 2014 most of the earlier cited examples of the integration of nps models and giss took this approach hession and shanholtz 1988 joão and walsh 1992 rewerts and engel 1991 srinivasan and engel 1991a b tim and jolly 1994 subsequently there was the tight coupling which used gis platforms as interfaces to run and exchange data with nps models as shown in the works of he et al 2001 jayakrishnan et al 2005 liao and tim 1997 lin et al 2011 olivera et al 2006 pullar and springer 2000 srinivasan and arnold 1994 srinivasan and engel 1991b a and vairavamoorthy et al 2007 in tight coupling the models are generally developed into dynamic link libraries dlls by using higher level programing languages such as fortran or c c and the dlls are linked into the gis macro languages huang and jiang 2002 liu et al 2014 to tackle the data format compatibility problem between the gis and the model a software library was further developed huang and jiang 2002 liu et al 2014 due to this the modelers can easily access the model data and other project data and run various gis functions on them compared to the loose coupling the tight coupling seems to be more effective and demonstrates more advantages in dealing with spatial analysis and modeling nonetheless the main drawbacks are the requirement of increasing programming efforts and the occasional serious communication problems between the gis and model languages daniel et al 2011 liu et al 2014 martin et al 2005 in fully integrated coupling the model is embedded as a component within the host gis by programming the model equations using the gis s own code or in the opposite way with a gis structure being programmed within a model itself fan et al 2015 martin et al 2005 vairavamoorthy et al 2007 there is no intermediate transfer software input output data flow or executable calls between the gis and the model liu et al 2014 concluded that this approach avoided tangled data exchange and routine execution and could be more robust than loose and tight coupling approaches however due to the complexities and significant efforts and costs involved limited attempts in gis model full coupling have been recorded daniel et al 2011 liu et al 2014 martin et al 2005 the existing attempts mainly focuses on relatively simple models such as a simplified pollutant model liao and tim 1994 topmodel huang and jiang 2002 p indicator liu et al 2014 and the siaqua iph model fan et al 2015 as one of the most simple nps models the p index or indicators were developed worldwide to provide coarse measurements or to act as screening tools as the first step in identifying critical source areas of sediments and nutrient generation heathwaite et al 2003 the p index concept attempted to reveal a complex nps p loss phenomenon by aggregating the key factors and processes determining p sources e g soil p status fertilization practices manure application and transport e g erosion runoff delivery connectivity drewry et al 2011 this type of p model tools generally had less complex structures than process based p models since they had to be easily handled by the intended end users e g farmers nutrient management planners the early p indices were used to predict p loss risk but then evolved to be able to predict nps p loss at annual time step radcliffe et al 2009 typical examples of the evolved ones were pit p indicator tool developed by heathwait et al 2003 and aple annual p loss estimation by vadas et al 2009 generally speaking most of the existing p indexes or indicators were loosely coupled with gis gis was mainly used to extract model inputs such as land uses vegetation terrain distances to streams or rivers and so on as well as to spatially display the model outputs and indicate the critical source areas of the nps p pollution the data were transferred forward and back between gis and the model which was coded in another language this system might work usefully when less spatial data were involved and single calculation was carried on but became particularly time consuming and error prone when batch or dynamic simulation were required liu et al 2014 however the increasing availability of large volumes of spatial temporal data and needs for precise watershed management had raised a high demand for dynamic nps modeling in both spatial and temporal contexts which required a closer integration of gis and nps models huang and jiang 2002 we noticed that r was not only a statistical analysis tool but also a sophisticated language supporting object oriented programming as a computation tool the performance of r is comparable to matlab fuka et al 2014 in the spatial analysis and display it could act as a gis relying on a wide variety of packages and functions that enable r to interface with geographic spatial data bivand et al 2008 brunsdon and comber 2015 lovelace et al 2018 malone et al 2016 and thus supports advanced geospatial statistics modeling and visualization lovelace et al 2018 furthermore the shiny package makes building a web browser interface for models and interactively working with them possible chang et al 2015 these flexibilities enable r be a promising language programming nps models since it can meet the multiple needs of nps modeling in aspects of spatial data manipulation geo computation visualization and interactivity without crossing platforms therefore the objectives of this paper were to 1 propose an alternative option to develop a fast and cost effective system that fully integrates the gis and nps model by exploiting the capacity of r in numeric computation geo spatial analysis graphical visualization and interactive display 2 implement the dynamic simulation of the proposed gis nps models in both temporal and spatial dimensions and 3 build a web interface of this gis nps model for end users to interact with the model a homemade nps p indicator tool was used as an example of the nps model to illustrate the advantages and limitations of this fully integrated coupling approach in r it should be noted that the main focus of this paper was the coupling approach rather than the nps model itself the model development was described in previous papers su et al 2016 2018 2 methods and methodology 2 1 brief introduction of the studied nps p indicator the nps pi was a watershed scale p indicator quantifying non point source p losses in semi arid watersheds it separately calculated the watershed annual particulate phosphorus pp loss through erosion and dissolved phosphorus dp loss via runoff from the sources e g soil manure and fertilizer each p component involved a set of variables and or coefficients that acted as the most important source and transport factors for that type of p loss and the total nps p loads entering water courses were quantified as the sum of delivered pp and dp fig 1 this indicator treated pp loss as a function of p levels in source materials erosion rates of soil and manure particles and the delivery efficiency from source area to watercourse a conjunction of an empirical erosion model rusle and a sediment delivery ratio sdr was used to predict sediment yields at catchment or basin outlet as many other modeling studies did alatorre et al 2012 heathwaite et al 2003 dp loss was dependent on the solubility of p in soils fertilizers and manure as well as p delivery efficiency by both surface and subsurface runoff the determination of dp loss could be sub divided into two processes 1 dp leaving the cell comprised the soluble parts of soil p fertilizer p and manure p which were available for delivery from source area to cell edges by surface and subsurface runoff dp contributed by soils was expressed as the dp mass extracted from soil by runoff in two pathways and those from manure and fertilizer were obtained by apportioning the total losable dp from manure or fertilizer to surface and subsurface pathways according to runoff distribution ratios and p concentration ratio between two pathways c9 in fig 1 and 2 dp loads mobilized in each cell were further weighed by a lumped dp delivery ratio c8 in fig 1 to obtain the delivered p loads calculations were performed on discrete cells and the resulting p losses and intermediate outputs were presented as watershed annual average values 2 2 the model and gis integration process the coupling of the gis and the nps p indicator was demonstrated by developing a system that included 1 spatial data extraction from a specified database according to the boundaries of the specified catchment and data conversion to the format coordinate system cell size required by the model 2 quantification and digital mapping of the source transport factors existing in the nps p indicator 3 the model simulation 4 the visualization of model inputs and outputs and 5 a shiny web based application with which the end users can work interactively with the nps p indicator fig 2 the first four parts were implemented in r s command line interface cli the indicator was coded by simple commands and basic r functions in cli thus enabling access for researchers who use r as for the spatial analysis and visualization that are involved in this p indicator development functions from the spatial r packages were used to implement the gis operations the package rgdal was used to extract the geospatial data in raster and vector formats from databases bivand et al 2016 packages sp raster gstat and rgeos were used to process the spatial data conversion e g define and transform the coordinate system resample rasterize and computation e g interpolation map algebra bivand et al 2017 hijmans and van etten 2014 pebesma et al 2016 pebesma and graeler 2018 and the package ggplot2 was used to create high quality spatial graphics wickham and chang 2019 table 2 listed the main spatial analysis functions and packages to speed up the modeling progress the packages foreach snow and dosnow were used for parallel computation analytics and weston 2015a b tierney 2011 the computation environment is summarized in table 3 2 3 shiny web application the package shiny was used to create a web based application of the nps p indicator for users who wish to work interactively mainly watershed managers and planners the shiny applications were built using two r scripts that communicate with each other a user interface script ui r which controlled the layout and appearance and a server script server r which incorporated instructions for user input processing data and output by utilizing the r language and functions from user installed packages or self defined functions when launching an application from r shiny would open a web browser window for the application a customized web based interface of the proposed nps p indicator was built in r based on various layouts and widgets that shiny provided the navigation bar listed as many important indicator components as possible such as the source and transport factors the intermediate rusle results and the final p losses by simply clicking the tab panel the selected component would be displayed in the main panel in either a graphical or tabular format after a parameter adjustment in the scale bar and a menu selection of the modeling year and output variable the model is run and the selected output is subsequently mapped in the plot section a local map with high spatial resolution was laid under the displayed output to precisely indicate which areas posed the highest risk for nps p losses we adopted an online interactive map of the studied region by the r package leaflet and its minimum display unit was the village leaflet is one of the most popular open source javascript libraries for interactive maps and the leaflet r package makes it easy to create interactive web maps from within r cheng and xie 2016 furthermore a comparison between simulated and observed sediments or nps p losses was further implemented to indicate the prediction validity the codes and data of the nps p indicator and its web app can be accessed in the github repository via the following link https github com sujjj nps pi git 3 case study the liu river subwatershed lrw was used as an example to demonstrate the application of the nps p indicator model the subwatershed is located approximately 70 km northeast of beijing the region has a semihumid and semiarid continental monsoon climate the annual average rainfall is 658 mm and more than 70 of the rainfall occurs during the period from june to september the topography of the subwatershed is hilly and the dominant land cover is forest a hydrological station named liying is installed in the subwatershed outlet this study focused on the 560 km2 watershed area upstream of the liying station three administrative units xinglong county the yingzi district and chengde county spanned the subwatershed and accounts for 83 2 15 3 and 1 4 respectively of the subwatershed area the data used in this study are presented in table 4 the input data preparation module works mainly on the spatially distributed data and the data needing to be converted into spatially distributed data to extract and convert existing spatial data e g dem soil land use boundary into the required format a mask layer with a defined boundary subwatershed boundary cell size 1 5 km 1 5 km and projection system wgs84 was generated and then a series of r commands were executed this could be done in a batch manner which significantly reduced the time required for data preparation fertilizer p application rates manure p production rates rainfall and runoff represented the most important source and transport factors in the nps p indicator the former two were estimated based on the annual county level census data such as p fertilizer application rates livestock types numbers and the rural population the digitalization of these data was implemented by spatially joining the county polygon and the attributes which were the estimated fertilizer p application rates or manure p production rates in each county in this case and the polygon rasterisation the rainfall raster generation was carried out by interpolating the rainfall data in multiple stations to the entire subwatershed by an inverse distance interpolation approach the runoff was collected from the only hydrological station in the tested subwatershed they were considered to be spatially evenly distributed within the subwatershed the runoff data were first treated with the base flow separation by the r package ecohydrology to obtain the surface and subsurface runoff fuka et al 2013 which were then used to derive the runoff depths runoff ratios and runoff ranks as model inputs sediment and p loads in the subwatershed outlet were calculated based on runoff water quality data and point source data which were used as calibrating data for the model simulation there were twelve parameters in this p indicator fig 1 their values were difficult to obtain because they varied widely due to site specific characteristics and processes their initial ranges were determined by extensive literature review and set as wide as considered feasible by physical argument or experience freer et al 1996 a model calibration using a glue generalized likelihood uncertainty estimation methodology proposed by beven and binley 1992 had been carried out to identify the optimum parameter ranges and prediction bounds su et al 2018 the nash sutcliffe efficiency coefficient ens nash and sutcliffe 1970 was used as the likelihood measure the detailed glue based uncertainty analysis of this nps pi can be found in su et al 2018 4 model application results 4 1 predicted nps p loss loads fig 3 displayed the 90 uncertainty bands of the predicted annual sediment load and total p load in the watershed outlet which were obtained by a glue generalized likelihood uncertainty estimation methodology that was based on 20000 runs of monte carlo simulation su et al 2018 the results indicated that the nps p indicator along with the glue methodology in this study could generate acceptable prediction outputs despite that the 90 uncertainty band could not bracket all of the sediment or nps tp observations the uncertainty bands for either sediment or tp prediction captured well the temporal dynamics of the observations fig 3 the predicted annual average nps p loads over the subwatershed ranged from 0 12 kg ha to 1 75 kg ha which was close to that previously reported for nps tp loads from predominantly agricultural basins in the northern china plain 0 8 1 6 kg ha 4 2 spatial distribution of the intermediate outcomes and the final result the p indicators were designated to provide coarse measurements or identify critical source areas of sediments and nutrients generation the spatial display of the intermediate outcomes and the final predictions would help us know better about which watershed areas were posing the high risk of nps p losses and what were the main causes fig 4 illustrated that as the green color deepened the risk of sediment erosion or nps p loss increased the critical source areas which were in dark green were mainly located in the head watershed several factors contributed to this spatial pattern firstly the majority of the upland in this subwatershed was located in the head watershed and received relatively high amount of p fertilizers each year 70 kg ha this p input also resulted in the soil olsen p enrichment 30 50 mg p per kg soil in these areas secondly the rainfall in the headwater area was higher than other parts of the subwatershed data not shown the co occurrence of high source potential and high transport potential exacerbated the losses of sediments dissolved p particulate p and the total p we could also notice from fig 4 that dp dominated the nps tp loss and the subsurface runoff was the major loss pathway for dp this was reasonable considering 1 that more than 70 of the watershed area was covered by forest and shrubs which probably intercepted the eroded particles and 2 that soils in this subwatershed were mainly sandy which had promoted the infiltration of runoff and downward transfer of nutrients these results would provide insightful information to watershed managers to decide which areas should be the primary targets of best management practices bmps and what kind of bmps should be implemented to mitigate the loss of various forms of nps p loss 4 3 the dynamic variations in the nps p prediction the nps pi can simulate not only the dynamic changes of the nps tp loss but also those of its components which included eleven p forms in different pathways and two sediment outputs this paper used nps tp as an example to demonstrate the dynamic simulation outputs fig 5 revealed obvious variations in the magnitudes and extents of nps tp losses among years fig 5 the most and least nps tp loss respectively occurred in the year 2001 and year 2002 which corresponded to the years with the most and least rainfall 548 mm vs 227 mm the locations of main critical source areas for nps tp loss remained almost identical during the observation period implying that these areas could be set as the primary routine management targets in this subwatershed whereas the expansion of high risk areas of nps p loss in wet years also indicated the necessity to include other high risk areas as management targets in wet seasons or years 4 4 the interactive use of the nps p indicator fig 6 displayed the p indicator web browser interface created by shiny this shiny app had similar features functionalities and database as those of the p indicator working in the console by clicking the navigation bar in the side panel the source and transport factors which included the fertilization application rates manure p generation rates soil p status rainfall and runoff could be selected and displayed in either graphical or tabular format the end users could further select the interested year and output variable from the drop down menu in the main panel then the output would be computed and displayed over a regional leaflet online map these interactive operations could help the end users to better understand how the nps p loss processes developed and how these processes were related to the final nps p loss the overlay of model outputs and the leaflet online map enhanced the indication of critical source areas the end users could easily identify the villages where the critical source areas were located and clarify the responsible parties since most of the parameter ranges were identified by model calibration we left the parameter settings flexible in case measured data from base field studies becomes available in the future 5 discussions the gis model coupling system in this study could be classified as a full integration it was achieved by using a single programming environment r all stages of the model building were undertaken in r from the initial selection and conversion of datasets to the final visualization of results in various formats such as charts spatial maps and web interface previous studies of huang and jiang 2002 and bhatt et al 2014 also pointed out that the same programming language for the development of gis tools and the hydrological nps models could facilitate full integrated coupling by doing this the gis and the model worked as a coherent whole in this nps pi gis operations were implemented by functions existing in spatial r packages or customized functions according to our analysis or model needs they were entirely embedded in the model algorithms such an approach eliminated the data transfer between the gis and the model which might involve different platforms and made it easy to capitalize on the gis spatial analysis and visualization functions this significantly promoted the modeling efficiency and enhanced the dynamic simulation capacity of the nps pi when we used the early version of this nps pi that was a loosely coupled gis model system it took considerable time in extracting or converting data it was particularly time consuming and error prone when batch or series data were involved while this new version of nps pi can carry the data preparation model simulation and output visualization in a batch manner our previous work indicated that 20000 runs of monte carlo simulation for an eleven year time series of a catchment over 560 km2 took around 14940 s given a 6 core parallel computation this study also included the interactive user interface as a part of the gis model coupling system to meet the needs of end users for nps models like p indicator they would eventually serve the nutrient managers who normally prefers to use visible interactive tools that could capture the spatial and temporal dynamics of the pollutant loss processes to design effective mitigating strategies sharpley et al 2011 relying on the r shiny package the interactive nps pi interface could be easily built without requiring sufficient expertise and experiences in gis developing this speeded up the application of such tools which were designated for management purposes and the transformation of research tools to management tools despite of these benefits of using r to fully integrate gis and nps models there is one thing we want to emphasize which is that the complexity of the nps model should be considered when fully coupling with a gis up to date only simple or simplified models have been successfully fully integrated with gis liao and tim 1994 liu et al 2014 martin et al 2005 the number of full coupling applications is far less than that of the loose coupling and tight coupling applications table 1 one reason might be that majority of the nps models have complex structures and algorithms and the full integration of such models and a gis requires significant effort and cost martin et al 2005 another reason could be that the existing full gis model integration generally embed models into gis host using gis macro languages or other advanced languages while the computation capacity of such languages are seldom powerful enough to implement sophisticated models sui and maggio 1999 our study implemented full integration on simple semi distributed indicator models in r whether r could handle sophisticated distributed nps modeling still needs further investigation 6 conclusions this study reported an attempt to use r to fully integrate nps models and gis and to build an interactive web interface our experiences indicated that 1 to fully integrate nps pi and gis was feasible and effective by utilizing the capacities of r in numeric computation geo computation and visualization 2 the full integration approach significantly promoted the modeling efficiency of our nps pi particularly in batch or dynamic simulation tasks and enhanced the spatial visualization for multiple variables which included not only the final results but also the inputs and intermediate outcomes and in dynamic time scales and 3 to build an interactive web interface for a simple model tool by r was also feasible for scholars who have less expertise and experiences in interface developing our work provides a promising option for scholars and engineers who work in the field of nps modeling yet it s important to mention that it is difficult to conclude based on this case study that the full integration is superior to the loose coupling or tight coupling or r is superior to the other programming languages we believe that the selection of a suitable integration approach for gis and nps model depends on several factors which included the type of the nps model its complexity and reusability developer s programming capacity research needs and project budgets the final method selection is the result of a tradeoff among these factors we also notice that as the technology advances more options are emerging in the field of gis model system developing one typical example is python which shares a lot in common with r we may apply both r and python in the future nps model developing work and compare their performances software availability name of model npspi developers jingjun su xuyong li programming languages r contact email jjsu rcees ac cn mailto jjsu rcees ac cn codes and data available from the github https github com sujjj nps pi git https github com sujjj nps pi git declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the national natural science foundation of china grant numbers 41401590 41773531 and the major science and technology program for water pollution control and treatment grant number 2015zx07203 005 01 grateful thanks also go to the enthusiastic r community for the numerous tools and packages that made this work available we are also grateful to the editor of this paper and the anonymous reviewers for their suggestions that helped to improve the quality of our work appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104637 
26046,the coupling of a geographic information system gis and nonpoint source nps models has significantly promoted nps modeling and output visualization this study reported an approach using r to fully integrate the gis and a nps phosphorus indicator model as well as to build an interactive web interface for the model a case study in a semiarid northern china subwatershed showed that the proposed method was feasible flexible and effective our experiences demonstrated that developing a fully coupled gis nps model system in r could simplify nps modeling across computation platforms promote modeling efficiency implement dynamic simulations enhance model inputs outputs display and provide readily interactivity we envision that the experiences could provide a promising option for nps modeling keywords r language fully integrated approach geographic information system nonpoint source modeling 1 introduction as a tool for the management query visualization and analysis of spatially referred information gis has been recognized as a method to aid the modeling of nps pollution and to visualize the results in a spatial context beven and alcock 2012 liu et al 2014 shen et al 2013 many attempts have been made to couple nps models with a gis for both research and management purposes table 1 the couplings span various models such as usle answers agnps swat basins topmodel and phosphorus p indicator and various gis tools giss such as grass arcgis map window gis supermap and qgis bhatt et al 2014 di luzio et al 2004 fan et al 2015 hession and shanholtz 1988 huang and jiang 2002 joão and walsh 1992 kinerson et al 1999 liao 1996 liu et al 2014 nielsen et al 2017 olivera et al 2006 pullar and springer 2000 rewerts and engel 1991 srinivasan and arnold 1994 srinivasan and engel 1991a b tim and jolly 1994 zhang et al 2011 nyerges et al 1993 classified the gis model couplings into three categories loose tight or fully integrated each approach has its own advantages and disadvantages they differ to various degrees in the role of giss the manner of data exchange model suitability reusability and the requirements of programming capabilities generally the gis in loose coupling serves as both a preprocessor e g input generation and a postprocessor e g the results analysis and visualization liao 1996 liu et al 2014 martin et al 2005 the model and gis work unrelatedly with the data exchange usually being manually performed which could be tedious and error prone liu et al 2014 martin et al 2005 sui and maggio 1999 due to the loose coupling with gis the model users cannot take full advantage of gis functionalities such as spatial analysis because this approach avoids redundant programming it could be the most suitable choice for most gis users and environmental engineers to conduct modeling work liao 1996 liu et al 2014 most of the earlier cited examples of the integration of nps models and giss took this approach hession and shanholtz 1988 joão and walsh 1992 rewerts and engel 1991 srinivasan and engel 1991a b tim and jolly 1994 subsequently there was the tight coupling which used gis platforms as interfaces to run and exchange data with nps models as shown in the works of he et al 2001 jayakrishnan et al 2005 liao and tim 1997 lin et al 2011 olivera et al 2006 pullar and springer 2000 srinivasan and arnold 1994 srinivasan and engel 1991b a and vairavamoorthy et al 2007 in tight coupling the models are generally developed into dynamic link libraries dlls by using higher level programing languages such as fortran or c c and the dlls are linked into the gis macro languages huang and jiang 2002 liu et al 2014 to tackle the data format compatibility problem between the gis and the model a software library was further developed huang and jiang 2002 liu et al 2014 due to this the modelers can easily access the model data and other project data and run various gis functions on them compared to the loose coupling the tight coupling seems to be more effective and demonstrates more advantages in dealing with spatial analysis and modeling nonetheless the main drawbacks are the requirement of increasing programming efforts and the occasional serious communication problems between the gis and model languages daniel et al 2011 liu et al 2014 martin et al 2005 in fully integrated coupling the model is embedded as a component within the host gis by programming the model equations using the gis s own code or in the opposite way with a gis structure being programmed within a model itself fan et al 2015 martin et al 2005 vairavamoorthy et al 2007 there is no intermediate transfer software input output data flow or executable calls between the gis and the model liu et al 2014 concluded that this approach avoided tangled data exchange and routine execution and could be more robust than loose and tight coupling approaches however due to the complexities and significant efforts and costs involved limited attempts in gis model full coupling have been recorded daniel et al 2011 liu et al 2014 martin et al 2005 the existing attempts mainly focuses on relatively simple models such as a simplified pollutant model liao and tim 1994 topmodel huang and jiang 2002 p indicator liu et al 2014 and the siaqua iph model fan et al 2015 as one of the most simple nps models the p index or indicators were developed worldwide to provide coarse measurements or to act as screening tools as the first step in identifying critical source areas of sediments and nutrient generation heathwaite et al 2003 the p index concept attempted to reveal a complex nps p loss phenomenon by aggregating the key factors and processes determining p sources e g soil p status fertilization practices manure application and transport e g erosion runoff delivery connectivity drewry et al 2011 this type of p model tools generally had less complex structures than process based p models since they had to be easily handled by the intended end users e g farmers nutrient management planners the early p indices were used to predict p loss risk but then evolved to be able to predict nps p loss at annual time step radcliffe et al 2009 typical examples of the evolved ones were pit p indicator tool developed by heathwait et al 2003 and aple annual p loss estimation by vadas et al 2009 generally speaking most of the existing p indexes or indicators were loosely coupled with gis gis was mainly used to extract model inputs such as land uses vegetation terrain distances to streams or rivers and so on as well as to spatially display the model outputs and indicate the critical source areas of the nps p pollution the data were transferred forward and back between gis and the model which was coded in another language this system might work usefully when less spatial data were involved and single calculation was carried on but became particularly time consuming and error prone when batch or dynamic simulation were required liu et al 2014 however the increasing availability of large volumes of spatial temporal data and needs for precise watershed management had raised a high demand for dynamic nps modeling in both spatial and temporal contexts which required a closer integration of gis and nps models huang and jiang 2002 we noticed that r was not only a statistical analysis tool but also a sophisticated language supporting object oriented programming as a computation tool the performance of r is comparable to matlab fuka et al 2014 in the spatial analysis and display it could act as a gis relying on a wide variety of packages and functions that enable r to interface with geographic spatial data bivand et al 2008 brunsdon and comber 2015 lovelace et al 2018 malone et al 2016 and thus supports advanced geospatial statistics modeling and visualization lovelace et al 2018 furthermore the shiny package makes building a web browser interface for models and interactively working with them possible chang et al 2015 these flexibilities enable r be a promising language programming nps models since it can meet the multiple needs of nps modeling in aspects of spatial data manipulation geo computation visualization and interactivity without crossing platforms therefore the objectives of this paper were to 1 propose an alternative option to develop a fast and cost effective system that fully integrates the gis and nps model by exploiting the capacity of r in numeric computation geo spatial analysis graphical visualization and interactive display 2 implement the dynamic simulation of the proposed gis nps models in both temporal and spatial dimensions and 3 build a web interface of this gis nps model for end users to interact with the model a homemade nps p indicator tool was used as an example of the nps model to illustrate the advantages and limitations of this fully integrated coupling approach in r it should be noted that the main focus of this paper was the coupling approach rather than the nps model itself the model development was described in previous papers su et al 2016 2018 2 methods and methodology 2 1 brief introduction of the studied nps p indicator the nps pi was a watershed scale p indicator quantifying non point source p losses in semi arid watersheds it separately calculated the watershed annual particulate phosphorus pp loss through erosion and dissolved phosphorus dp loss via runoff from the sources e g soil manure and fertilizer each p component involved a set of variables and or coefficients that acted as the most important source and transport factors for that type of p loss and the total nps p loads entering water courses were quantified as the sum of delivered pp and dp fig 1 this indicator treated pp loss as a function of p levels in source materials erosion rates of soil and manure particles and the delivery efficiency from source area to watercourse a conjunction of an empirical erosion model rusle and a sediment delivery ratio sdr was used to predict sediment yields at catchment or basin outlet as many other modeling studies did alatorre et al 2012 heathwaite et al 2003 dp loss was dependent on the solubility of p in soils fertilizers and manure as well as p delivery efficiency by both surface and subsurface runoff the determination of dp loss could be sub divided into two processes 1 dp leaving the cell comprised the soluble parts of soil p fertilizer p and manure p which were available for delivery from source area to cell edges by surface and subsurface runoff dp contributed by soils was expressed as the dp mass extracted from soil by runoff in two pathways and those from manure and fertilizer were obtained by apportioning the total losable dp from manure or fertilizer to surface and subsurface pathways according to runoff distribution ratios and p concentration ratio between two pathways c9 in fig 1 and 2 dp loads mobilized in each cell were further weighed by a lumped dp delivery ratio c8 in fig 1 to obtain the delivered p loads calculations were performed on discrete cells and the resulting p losses and intermediate outputs were presented as watershed annual average values 2 2 the model and gis integration process the coupling of the gis and the nps p indicator was demonstrated by developing a system that included 1 spatial data extraction from a specified database according to the boundaries of the specified catchment and data conversion to the format coordinate system cell size required by the model 2 quantification and digital mapping of the source transport factors existing in the nps p indicator 3 the model simulation 4 the visualization of model inputs and outputs and 5 a shiny web based application with which the end users can work interactively with the nps p indicator fig 2 the first four parts were implemented in r s command line interface cli the indicator was coded by simple commands and basic r functions in cli thus enabling access for researchers who use r as for the spatial analysis and visualization that are involved in this p indicator development functions from the spatial r packages were used to implement the gis operations the package rgdal was used to extract the geospatial data in raster and vector formats from databases bivand et al 2016 packages sp raster gstat and rgeos were used to process the spatial data conversion e g define and transform the coordinate system resample rasterize and computation e g interpolation map algebra bivand et al 2017 hijmans and van etten 2014 pebesma et al 2016 pebesma and graeler 2018 and the package ggplot2 was used to create high quality spatial graphics wickham and chang 2019 table 2 listed the main spatial analysis functions and packages to speed up the modeling progress the packages foreach snow and dosnow were used for parallel computation analytics and weston 2015a b tierney 2011 the computation environment is summarized in table 3 2 3 shiny web application the package shiny was used to create a web based application of the nps p indicator for users who wish to work interactively mainly watershed managers and planners the shiny applications were built using two r scripts that communicate with each other a user interface script ui r which controlled the layout and appearance and a server script server r which incorporated instructions for user input processing data and output by utilizing the r language and functions from user installed packages or self defined functions when launching an application from r shiny would open a web browser window for the application a customized web based interface of the proposed nps p indicator was built in r based on various layouts and widgets that shiny provided the navigation bar listed as many important indicator components as possible such as the source and transport factors the intermediate rusle results and the final p losses by simply clicking the tab panel the selected component would be displayed in the main panel in either a graphical or tabular format after a parameter adjustment in the scale bar and a menu selection of the modeling year and output variable the model is run and the selected output is subsequently mapped in the plot section a local map with high spatial resolution was laid under the displayed output to precisely indicate which areas posed the highest risk for nps p losses we adopted an online interactive map of the studied region by the r package leaflet and its minimum display unit was the village leaflet is one of the most popular open source javascript libraries for interactive maps and the leaflet r package makes it easy to create interactive web maps from within r cheng and xie 2016 furthermore a comparison between simulated and observed sediments or nps p losses was further implemented to indicate the prediction validity the codes and data of the nps p indicator and its web app can be accessed in the github repository via the following link https github com sujjj nps pi git 3 case study the liu river subwatershed lrw was used as an example to demonstrate the application of the nps p indicator model the subwatershed is located approximately 70 km northeast of beijing the region has a semihumid and semiarid continental monsoon climate the annual average rainfall is 658 mm and more than 70 of the rainfall occurs during the period from june to september the topography of the subwatershed is hilly and the dominant land cover is forest a hydrological station named liying is installed in the subwatershed outlet this study focused on the 560 km2 watershed area upstream of the liying station three administrative units xinglong county the yingzi district and chengde county spanned the subwatershed and accounts for 83 2 15 3 and 1 4 respectively of the subwatershed area the data used in this study are presented in table 4 the input data preparation module works mainly on the spatially distributed data and the data needing to be converted into spatially distributed data to extract and convert existing spatial data e g dem soil land use boundary into the required format a mask layer with a defined boundary subwatershed boundary cell size 1 5 km 1 5 km and projection system wgs84 was generated and then a series of r commands were executed this could be done in a batch manner which significantly reduced the time required for data preparation fertilizer p application rates manure p production rates rainfall and runoff represented the most important source and transport factors in the nps p indicator the former two were estimated based on the annual county level census data such as p fertilizer application rates livestock types numbers and the rural population the digitalization of these data was implemented by spatially joining the county polygon and the attributes which were the estimated fertilizer p application rates or manure p production rates in each county in this case and the polygon rasterisation the rainfall raster generation was carried out by interpolating the rainfall data in multiple stations to the entire subwatershed by an inverse distance interpolation approach the runoff was collected from the only hydrological station in the tested subwatershed they were considered to be spatially evenly distributed within the subwatershed the runoff data were first treated with the base flow separation by the r package ecohydrology to obtain the surface and subsurface runoff fuka et al 2013 which were then used to derive the runoff depths runoff ratios and runoff ranks as model inputs sediment and p loads in the subwatershed outlet were calculated based on runoff water quality data and point source data which were used as calibrating data for the model simulation there were twelve parameters in this p indicator fig 1 their values were difficult to obtain because they varied widely due to site specific characteristics and processes their initial ranges were determined by extensive literature review and set as wide as considered feasible by physical argument or experience freer et al 1996 a model calibration using a glue generalized likelihood uncertainty estimation methodology proposed by beven and binley 1992 had been carried out to identify the optimum parameter ranges and prediction bounds su et al 2018 the nash sutcliffe efficiency coefficient ens nash and sutcliffe 1970 was used as the likelihood measure the detailed glue based uncertainty analysis of this nps pi can be found in su et al 2018 4 model application results 4 1 predicted nps p loss loads fig 3 displayed the 90 uncertainty bands of the predicted annual sediment load and total p load in the watershed outlet which were obtained by a glue generalized likelihood uncertainty estimation methodology that was based on 20000 runs of monte carlo simulation su et al 2018 the results indicated that the nps p indicator along with the glue methodology in this study could generate acceptable prediction outputs despite that the 90 uncertainty band could not bracket all of the sediment or nps tp observations the uncertainty bands for either sediment or tp prediction captured well the temporal dynamics of the observations fig 3 the predicted annual average nps p loads over the subwatershed ranged from 0 12 kg ha to 1 75 kg ha which was close to that previously reported for nps tp loads from predominantly agricultural basins in the northern china plain 0 8 1 6 kg ha 4 2 spatial distribution of the intermediate outcomes and the final result the p indicators were designated to provide coarse measurements or identify critical source areas of sediments and nutrients generation the spatial display of the intermediate outcomes and the final predictions would help us know better about which watershed areas were posing the high risk of nps p losses and what were the main causes fig 4 illustrated that as the green color deepened the risk of sediment erosion or nps p loss increased the critical source areas which were in dark green were mainly located in the head watershed several factors contributed to this spatial pattern firstly the majority of the upland in this subwatershed was located in the head watershed and received relatively high amount of p fertilizers each year 70 kg ha this p input also resulted in the soil olsen p enrichment 30 50 mg p per kg soil in these areas secondly the rainfall in the headwater area was higher than other parts of the subwatershed data not shown the co occurrence of high source potential and high transport potential exacerbated the losses of sediments dissolved p particulate p and the total p we could also notice from fig 4 that dp dominated the nps tp loss and the subsurface runoff was the major loss pathway for dp this was reasonable considering 1 that more than 70 of the watershed area was covered by forest and shrubs which probably intercepted the eroded particles and 2 that soils in this subwatershed were mainly sandy which had promoted the infiltration of runoff and downward transfer of nutrients these results would provide insightful information to watershed managers to decide which areas should be the primary targets of best management practices bmps and what kind of bmps should be implemented to mitigate the loss of various forms of nps p loss 4 3 the dynamic variations in the nps p prediction the nps pi can simulate not only the dynamic changes of the nps tp loss but also those of its components which included eleven p forms in different pathways and two sediment outputs this paper used nps tp as an example to demonstrate the dynamic simulation outputs fig 5 revealed obvious variations in the magnitudes and extents of nps tp losses among years fig 5 the most and least nps tp loss respectively occurred in the year 2001 and year 2002 which corresponded to the years with the most and least rainfall 548 mm vs 227 mm the locations of main critical source areas for nps tp loss remained almost identical during the observation period implying that these areas could be set as the primary routine management targets in this subwatershed whereas the expansion of high risk areas of nps p loss in wet years also indicated the necessity to include other high risk areas as management targets in wet seasons or years 4 4 the interactive use of the nps p indicator fig 6 displayed the p indicator web browser interface created by shiny this shiny app had similar features functionalities and database as those of the p indicator working in the console by clicking the navigation bar in the side panel the source and transport factors which included the fertilization application rates manure p generation rates soil p status rainfall and runoff could be selected and displayed in either graphical or tabular format the end users could further select the interested year and output variable from the drop down menu in the main panel then the output would be computed and displayed over a regional leaflet online map these interactive operations could help the end users to better understand how the nps p loss processes developed and how these processes were related to the final nps p loss the overlay of model outputs and the leaflet online map enhanced the indication of critical source areas the end users could easily identify the villages where the critical source areas were located and clarify the responsible parties since most of the parameter ranges were identified by model calibration we left the parameter settings flexible in case measured data from base field studies becomes available in the future 5 discussions the gis model coupling system in this study could be classified as a full integration it was achieved by using a single programming environment r all stages of the model building were undertaken in r from the initial selection and conversion of datasets to the final visualization of results in various formats such as charts spatial maps and web interface previous studies of huang and jiang 2002 and bhatt et al 2014 also pointed out that the same programming language for the development of gis tools and the hydrological nps models could facilitate full integrated coupling by doing this the gis and the model worked as a coherent whole in this nps pi gis operations were implemented by functions existing in spatial r packages or customized functions according to our analysis or model needs they were entirely embedded in the model algorithms such an approach eliminated the data transfer between the gis and the model which might involve different platforms and made it easy to capitalize on the gis spatial analysis and visualization functions this significantly promoted the modeling efficiency and enhanced the dynamic simulation capacity of the nps pi when we used the early version of this nps pi that was a loosely coupled gis model system it took considerable time in extracting or converting data it was particularly time consuming and error prone when batch or series data were involved while this new version of nps pi can carry the data preparation model simulation and output visualization in a batch manner our previous work indicated that 20000 runs of monte carlo simulation for an eleven year time series of a catchment over 560 km2 took around 14940 s given a 6 core parallel computation this study also included the interactive user interface as a part of the gis model coupling system to meet the needs of end users for nps models like p indicator they would eventually serve the nutrient managers who normally prefers to use visible interactive tools that could capture the spatial and temporal dynamics of the pollutant loss processes to design effective mitigating strategies sharpley et al 2011 relying on the r shiny package the interactive nps pi interface could be easily built without requiring sufficient expertise and experiences in gis developing this speeded up the application of such tools which were designated for management purposes and the transformation of research tools to management tools despite of these benefits of using r to fully integrate gis and nps models there is one thing we want to emphasize which is that the complexity of the nps model should be considered when fully coupling with a gis up to date only simple or simplified models have been successfully fully integrated with gis liao and tim 1994 liu et al 2014 martin et al 2005 the number of full coupling applications is far less than that of the loose coupling and tight coupling applications table 1 one reason might be that majority of the nps models have complex structures and algorithms and the full integration of such models and a gis requires significant effort and cost martin et al 2005 another reason could be that the existing full gis model integration generally embed models into gis host using gis macro languages or other advanced languages while the computation capacity of such languages are seldom powerful enough to implement sophisticated models sui and maggio 1999 our study implemented full integration on simple semi distributed indicator models in r whether r could handle sophisticated distributed nps modeling still needs further investigation 6 conclusions this study reported an attempt to use r to fully integrate nps models and gis and to build an interactive web interface our experiences indicated that 1 to fully integrate nps pi and gis was feasible and effective by utilizing the capacities of r in numeric computation geo computation and visualization 2 the full integration approach significantly promoted the modeling efficiency of our nps pi particularly in batch or dynamic simulation tasks and enhanced the spatial visualization for multiple variables which included not only the final results but also the inputs and intermediate outcomes and in dynamic time scales and 3 to build an interactive web interface for a simple model tool by r was also feasible for scholars who have less expertise and experiences in interface developing our work provides a promising option for scholars and engineers who work in the field of nps modeling yet it s important to mention that it is difficult to conclude based on this case study that the full integration is superior to the loose coupling or tight coupling or r is superior to the other programming languages we believe that the selection of a suitable integration approach for gis and nps model depends on several factors which included the type of the nps model its complexity and reusability developer s programming capacity research needs and project budgets the final method selection is the result of a tradeoff among these factors we also notice that as the technology advances more options are emerging in the field of gis model system developing one typical example is python which shares a lot in common with r we may apply both r and python in the future nps model developing work and compare their performances software availability name of model npspi developers jingjun su xuyong li programming languages r contact email jjsu rcees ac cn mailto jjsu rcees ac cn codes and data available from the github https github com sujjj nps pi git https github com sujjj nps pi git declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the national natural science foundation of china grant numbers 41401590 41773531 and the major science and technology program for water pollution control and treatment grant number 2015zx07203 005 01 grateful thanks also go to the enthusiastic r community for the numerous tools and packages that made this work available we are also grateful to the editor of this paper and the anonymous reviewers for their suggestions that helped to improve the quality of our work appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104637 
26047,crop water production functions quantifying crop yield as a function of irrigation rate can help in the design of management systems that reduce the water footprint we examined the role of parameter uncertainties in characterizing production functions using the daycent agroecosystem model a global sensitivity analysis was conducted to identify the model parameters associated with the greatest uncertainties in model responses under both irrigated and non irrigated conditions growth production related parameters had relatively more impact on grain yield than did soil related parameters under non irrigated conditions there was greater sensitivity to evapotranspiration related parameters we then used the dream method a markov chain monte carlo mcmc bayesian approach to determine the posterior distributions of the selected parameters the dream method produced good estimates for the posterior distribution of the critical parameters the utility of water production functions as predictive tools to guide water management decisions is greatly enhanced by incorporating rigorous estimates of uncertainty keywords sensitivity analysis uncertainty analysis bayesian crop water production function limited irrigation daycent model software availability program title daycent model developer w j parton s j del grosso s ogle k paustian y zhang contact address natural resource ecology laboratory colorado state university fort collins co usa telephone 970 491 2195 email address yao zhang colostate edu year first available 1998 hardware required pc software required windows or linux availability and cost available on request free program title dream differential evolution adaptive metropolis package for r developer j a vrugt c j f ter braak et al contact address department of civil and environmental engineering the university of texas at san antonio one utsa circle san antonio tx 78249 usa email address john joseph utsa edu j f joseph availability and cost http dream r forge r project org free 1 introduction in the irrigated river basins of arid and semi arid regions in the western united states vulnerability to water shortage poses a significant risk to agricultural production ahuja et al 2008 doorenbos and kassam 1979 dozier et al 2017 large amounts of water from surface and underground sources are applied as irrigation to maintain high crop yields irrigation withdrawals in the us account for approximately 38 of total freshwater withdrawals maupin et al 2014 the increasing demand for water from municipal users due to rapid population growth and urbanization as well as demands for other industrial and environmental uses increasingly limit the availability of water for agriculture colorado water conservation board 2010 vorosmarty et al 2000 extended drought periods in a changing climate and declining groundwater levels are expected to further exacerbate the situation colorado water conservation board 2010 mcguire 2014 understanding the response of cropping systems to changes in irrigation levels is essential for reducing the water footprint of agricultural crops while maintaining production levels fereres and soriano 2007 saseendran et al 2014 trout et al 2010 the estimations of the responses can be used in complex economic and social analyses for decision support the optimal irrigation amounts are often determined by various economic and social factors dozier et al 2017 dynamic crop models are valuable tools for the estimation of the crop yield response to water brumbelow and georgakakos 2007 garcia vila and fereres 2012 saseendran et al 2014 however simulation models are only approximate representations of real world systems and thus bear uncertainties in simulating system behavior the predictions of dynamic crop models are influenced by inputs meteorological soil and land use uncertain model parameters the limitation of the mathematical representation of real world processes and uncertainty in the observed data that are used for calibration purposes all of these components need to be considered in assessing the uncertainty in crop model predictions confalonieri et al 2016 sources of modeling uncertainties can be grouped into three categories input structural and parameter uncertainties haefner 2005 input uncertainty is from errors in input forcing e g precipitation or soil texture of a field model structures are invariably incomplete and uncertain due to the simplification of real world processes lack of knowledge about some processes and from neglecting to include some processes that are deemed insignificant for pragmatic considerations finally model parameters time invariant coefficients that are treated as constants and are estimated by means of calibration to observed data can bear considerable uncertainty for a single model structure the uncertainty due to model parameters can be estimated using bayesian methods by conditioning the model behavior on measurements the literature is replete with methods for uncertainty analysis based on bayesian formalism particularly in hydrological studies e g beven and binley 1992 some bayesian methods have been applied for uncertainty analysis of crop models the generalized likelihood uncertainty estimation glue method beven and binley 1992 has been used for the estimation of posterior parameter distributions in studies of wheat using the simulateur multidiscipli naire pour les cultures standard stics wheat model varella et al 2010 sweet corn using the crop environment resource synthesis ceres maize model he et al 2009 maize and wheat using root zone water quality model 2 rzwqm2 model sun et al 2016 and cotton using the cropping system model csm cropgro cotton model pathak et al 2012 despite the computational simplicity and popularity of the glue method concerns about using informal bayesian likelihood functions in glue have been the subject of extensive scientific discourse stedinger et al 2008 vrugt et al 2009b alternatively formal bayesian methods using markov chain monte carlo mcmc techniques have been developed in crop modeling mcmc methods have been applied to quantify the uncertainty in predicted phenological development of maize in slovenia using the world food studies wofost model ceglar et al 2011 more recently a mcmc method named differential evolution adaptive metropolis dream vrugt and ter braak 2011 was applied to characterize parameter uncertainties of the stics model in simulations of winter wheat dumont et al 2014 another recent study applied the mcmc method with the systems approach for land use sustainability salus model to simulate maize peanut and cotton dzotsi et al 2015 the mcmc method was found useful as a method for quantifying uncertainty parameter sensitivity analysis sa is usually performed prior to uncertainty analysis to evaluate the importance of model parameters ceglar et al 2011 he et al 2009 laloy et al 2010 pathak et al 2012 while several local and global methods are available global sa methods are more informative since they account for interactions between parameters saltelli et al 2000 furthermore global sa can provide information on the structure of the model residuals which is essential for the implementation of formal bayesian techniques for uncertainty analysis ahmadi et al 2014 the daycent model parton et al 1998 is a widely used ecosystem model for simulating crop yield soil carbon nitrous oxide emissions and other agroecosystem responses chang et al 2013 del grosso et al 2006 2008 jarecki et al 2008 stehfest et al 2007 zhang et al 2013 a few previous studies have assessed the predictive uncertainty of daycent due to parameter uncertainty de gryze et al 2010 del grosso et al 2010 fitton et al 2014 lee et al 2011 two studies in particular analyzed the parameter uncertainty on trace gas emissions using bayesian methods van oijen et al 2011 wang and chen 2012 the daycent model is used in widely deployed decision support systems including the carbon management evaluation tool comet farm tool paustian et al 2018 http cometfarm nrel colostate edu a farm scale carbon and greenhouse gas accounting tool with new features of water management and water quality in development and the agroecosystem analysis tool on environmental resource assessment and management system erams platform arabi 2011 https erams com a field to basin scale water management tool thus it is critical to provide accurate uncertainty estimates for crop growth and water dynamics in these tools recent development of the daycent model include a new crop canopy development algorithm and improved accuracy in predicted crop water use zhang et al 2018b however the new crop submodel was manually calibrated and tested for water limited conditions zhang et al 2018a leaving a need for a systematic analysis of parameter sensitivity and uncertainty a systematic analysis could improve our understanding of the model and reveal the weaknesses in model structure e g non sensitive parameters and constantly biased predictions thus the overall goal of this study was to enhance the applicability of the new version of the model for simulating crop and soil water dynamics under water limited conditions by analyzing parameter sensitivity and quantifying uncertainty associated with model predictions our objectives were to i understand the importance of parameters and the processes they represent in the daycent model through a global sensitivity analysis ii characterize the uncertainty of important parameters and iii validate the model predictions in water limited environments 2 material and methods for the sensitivity and uncertainty analysis of the daycent agroecosystem model parton et al 1998 we used data from a field experiment conducted in mead ne which included three treatments irrigated continuous maize irrigated maize soybean rotation and a rainfed maize soybean rotation in our analysis we first applied sobol s global sensitivity analysis sobol 1993 to identify the relative importance of model parameters for predicted grain yield monthly green leaf area index glai and monthly aboveground biomass then results from the sensitivity analysis were used to investigate the structure of model errors using measurement data six year treatment separated for training and testing posterior distributions of the model parameters for one maize hybrid were identified using the dream technique the predictive uncertainty of the training dataset three out of six year treatment combinations and testing datasets the remaining three year treatment combinations was estimated 2 1 field experiments field data were obtained from an experiment conducted at the university of nebraska agricultural research and development center near mead ne a detailed experimental design can be found in suyker and verma 2009 although it is not a limited irrigation experiment the irrigated treatment and rainfed treatments under years with varying amounts of precipitation provide enough information to analyze water stress the experiment was initialized in 2001 two of the treatments were irrigated and one was rainfed each treatment is a large production field 49 65 ha one of the irrigated treatments was planted in continuous maize zea mays l irrigated continuous maize or icm the other irrigated treatment was in a maize soybean glycine max l rotation irrigated maize soybean rotation or ims the rainfed treatment was also in a maize soybean rotation rainfed maize soybean rotation or rms these treatments weremanaged using standard best management practices in this region for fertilizer herbicide and pesticide applications during the experimental period different hybrids of maize were grown with different planting date depending on the relative maturity and weather soil conditions zhang et al 2018b hybrid pioneer 33b51 was planted in 2001 2003 2004 and 2005 table 1 data from this hybrid were selected for use in this study within each treatment six 20 20 m measurement areas intensive measurement zones were established for detailed measurements of leaf area aboveground biomass and other important ecosystem variables verma et al 2005 in our study glai aboveground biomass and grain yield measurements were the variables of interest grain yields were recorded from the measurement of combine harvest of the entire treatment field leaf area and aboveground biomass were sampled destructively on an average of 11 day basis at each intensive measurement zone of each treatment the soil in all three treatments was a deep silty clay loam with a near level slope soil characteristics were measured for four depth increments and details can be found in zhang et al 2018b air temperature solar radiation relative humidity and wind speed for model simulation were from an on site weather station station name meadagrofarm high plains regional climate center lincoln ne precipitation and irrigation amounts needed as model inputs via a center pivot irrigation system were directly measured within each treatment field using rain gauges 2 2 agroecosystem model daycent the daycent ecosystem cropland forest grassland and savanna model parton et al 1998 daily version of the century model parton et al 1987 was used in this study the major sub models of daycent include plant growth soil water soil organic matter decomposition soil nitrogen and trace gas emission major inputs for the model are daily weather soil physical properties plant type and management practices recently zhang et al 2018b incorporated a new method to simulate the canopy dynamics of annual crops along with other modifications the field experiment used in this study has been previously simulated with the improved model using manually calibrated parameters zhang et al 2018b the results show improved glai simulation and a better fit in late season evapotranspiration rate in comparison with the previous version of the model by improving the calculation for green leaf biomass described later in this section this version of daycent has also been applied to simulate limited irrigation experiments in eastern colorado zhang et al 2018a with manual calibration a brief discussion of the theory concepts and methods used in the improved model is presented here in daycent daily potential net primary production is simulated as the product of radiation use efficiency and intercepted photosynthetically active radiation par 1 p p i c c i p a r i r u e t b where p p i is the potential production on the ith day c c i is the fraction of radiation intercepted by canopy on the ith day and ruetb is the radiation use efficiency of total biomass production aboveground and belowground the variable c c i is calculated using beer s law monsi and saeki 1953 sellers 1985 2 c c i 1 e x p k l i g h t g l a i i where k l i g h t is the extinction coefficient of vegetation the actual production is affected by temperature water and nutrient daily actual production is allocated to above and below ground based on the development stage and stress water and nitrogen phenology of growth is estimated by a growing degree day gdd method temperature effect t e on p p i approximately a bell shaped curve is as follows 3 t e p p d f 2 t m e a n p p d f 2 p p d f 1 p p d f 3 e x p p p d f 3 p p d f 4 1 p p d f 2 t m e a n p p d f 2 p p d f 1 p p d f 4 where ppdf1 ppdf2 ppdf3 ppdf4 are parameters to control the shape of the curve t mean is the daily mean temperature the soil water sub model simulates 1 dimensional water balance including precipitation irrigation evapotranspiration et runoff and percolation parton et al 1998 potential et is simulated by a calculated reference et and crop coefficients allen et al 1998 potential et is partitioned into potential evaporation from the soil and transpiration by the plant based on glai both the crop production sub model and soil water sub model require prediction of glai the new glai method is described in zhang et al 2018b briefly glai is converted from green leaf biomass using a constant specific leaf area sla in our new method green leaf biomass is simulated using green leaf weight ratio glwr as a function of gdd and aboveground biomass 4 g l a i i a g b i o m a s s i g l w r i s l a 2 3 global sensitivity analysis global sensitivity analysis gsa apportions the uncertainty in model outputs to the uncertainty in individual inputs and interactions thereof saltelli et al 2000 the sobol method is arguably the most comprehensive gsa method due to its sampling design for the exploration of the parameter space the decomposition of the variance of the model outputs v a r y ˆ for k parameters θ is written as 5 v a r y ˆ i 1 k d i 1 i j k d i j d 1 k where d i is the main effect of input parameter θ i the terms of d i j d 1 k correspond to the interactions between parameters the computation of these terms can be found in sobol 1993 and is not discussed here the sensitivity indices are given by 6 s i 1 i s d i 1 i s v a r y ˆ where 1 i 1 i s k and s 1 k hence the first order sensitivity indices main effects for each parameter are 7 s i d i v a r y ˆ total order indices are then computed as 8 t s i s i 1 i j k s i j s 1 k twenty four parameters in the improved version of daycent model were used in sensitivity analysis table 2 these parameters can be divided into two groups i crop growth production related parameters which are species or cultivar specific and ii parameters representing et and soil water processes uniform distributions were assumed for the prior parameter distributions dejonge et al 2012 dzotsi et al 2015 the ranges of model parameters were selected based on field measurements at the mead site and or relative studies in the literature global sensitivity analysis using the method of sobol requires independence of parameters however parameters mnddhrv minimum number of degree days from anthesis to harvest and mxddhrv maximum number of degree days from anthesis to harvest are not independent mnddhrv must be smaller than mxddhrv a new parameter gapmndd the difference between mnddhrv and mxddhrv was defined as a random variable mnddhrv was then calculated based on the mxddhrv and gapmndd additionally a wider range of 0 9 1 3 for the crop coefficient for evapotranspiration kcet parameter was used because field measurements indicated smaller values 1 03 0 07 suyker and verma 2009 than those reported by food and agriculture organization of the united nations fao allen et al 1998 soil parameters including saturation point field capacity wilting point and saturated conductivity were estimated by soil texture using the saxton equation saxton et al 1986 the sand content clay content and bulk density were varied within the ranges of a silty clay loam u s soil texture triangle by assuming only one soil texture in the experimental fields soil parameters were inputs to the model and were not changed during the simulation the model sensitivity to input weather variables were not included in this study it was analyzed and published previously zhang and paustian 2019 in this study a sample size of 25 600 was generated using the simlab software joint research center of the european commission 2004 this sample size meets the requirement of n k 2 with n in range of 500 1000 typically k is the number of parameters to ensure numerical stability saltelli et al 1999 2005 these samples of parameter sets were used to run the simulations for hybrid pioneer 33b51 total six year treatment table 1 the model responses examined in the sensitivity analysis were annual grain yield monthly aboveground biomass and monthly glai monthly averages of aboveground biomass and glai in may july and september were examined for differences in sensitivity during early middle and late growing seasons as the timing of drought stress is important for crop development important model parameters were then included in parameter and predictive uncertainty analysis the criterion for classifying parameters as important was sensitivity indices greater than 0 05 for monthly aboveground biomass monthly glai or annual grain yield 2 4 bayesian parameter uncertainty analysis using dream using bayesian formalism the posterior distribution of a set of parameters θ of model responses y ˆ conditioned on observed data y is 9 p θ y p y θ p θ p y θ p θ d θ where p y θ represents the likelihood of the data p θ is the prior distribution of parameters the likelihood p y θ is determined from the probability distribution of the residuals between observed y and modeled y ˆ responses residuals are often assumed to be uncorrelated independent normally distributed box and tiao 1992 hence yielding the likelihood function 10 l θ y i 1 n 2 π σ ε 2 1 2 exp 1 2 σ ε 2 y ˆ i θ y i 2 where σ ε is the standard deviation of model errors and n is the number of observed responses assuming homoscedastic model residuals the log likelihood function is 11 l θ y n 2 l n 2 π 2 n ln σ ε 1 2 σ ε 2 i 1 n y i y ˆ i θ 2 when model residuals are not homoscedastic observed and model responses are typically transformed using appropriate transformations e g box cox transformation box and cox 1964 prior to computation of the likelihood function similarly autoregressive time series models e g first order autoregressive transformation ar 1 may be applied to remove model error autocorrelation ahmadi et al 2014 vrugt 2016 mcmc simulations are commonly used for estimation of posterior parameter distributions as a formal bayesian method the dream algorithm vrugt et al 2008 2009a vrugt and ter braak 2011 vrugt 2016 was selected for this study the advantage of this approach is its efficiency in mitigating issues with high dimensionality multimodality nonlinearity and local optima with proved ergodicity compared with some traditional mcmc algorithms vrugt 2016 presents a complete review of the theory concepts and matlab implementation for the dream approach 2 5 identification of the structure of model residuals daycent model residuals were investigated for homoscedasticity normality and uncorrelated residuals from the 25 600 gsa runs outputs were extracted and residuals were calculated for each run using measurement data of annual grain yield multiple in season glai measurements and in season aboveground biomass of hybrid pioneer 33b51 residuals for the best model parameters selected based on the minimum root mean squared error rmse were explored model residuals of the three response variables i e yield glai biomass were examined for heteroscedasticity using the chi square test for normality since the glai and biomass are only continuously measured within each year partial autocorrelation in each year was also graphically assessed 2 6 implementation of the daycent linkage with dream the r package for dream guillaume and andrews 2012 was integrated with the daycent model to conduct the parameter uncertainty analysis we wrote a script in r to compute the likelihood function required as input to the dream package twelve mcmc chains were used in this study the gelman and rubin 1992 statistic r ˆ of 1 2 was used for convergence the first 50 of simulations were treated as the so called burn in runs discarded after which chain approached its stationary distribution vrugt and ter braak 2011 the measurement data used in residual analysis were divided into two datasets for training and testing data from the icm treatment in 2004 ims treatments in 2005 and rms treatment in 2001 were used for training since these data covered variations in planting dates water stress irrigated vs non irrigated and growing season temperature this data set contained 28 measurements of glai 26 measurements of aboveground biomass and 3 measurements of annual grain yield for testing purposes measurements from the three treatments in 2003 were used the measurement data included 24 measurements of monthly glai 24 measurements of monthly aboveground biomass and 3 measurements of annual grain yield the σ ε in equation 11 is associated with uncertainty the σ ε values were estimated in parallel with the daycent parameters iizumi et al 2014 very wide uniform prior distribution was used for σ ε for grain yield sigma graincarbon 10 200 g c m 2 grain carbon is a good predictor for corn yield but may not be for other crops aboveground biomass sigma abovegroundcarbon 10 400 g c m 2 and glai sigma glai 0 1 2 5 the predictive uncertainty for glai aboveground biomass and annual grain yield were computed using the last 10 of parameter sets from the dream algorithm after convergence 2 7 uncertainty in the prediction of crop water production functions we used input variables from the rainfed treatment at mead for a 12 year period from january 2001 to december 2012 to generate crop production functions only the dry years in this period 2001 2003 and 2012 were in our analysis to show the drought effect on production the planting date was fixed at doy 130 simulations were then conducted assuming no nutrient stress to be able to discern the effects of water stress at varying irrigation levels evidences showed interactions of moisture stress and nutrient uptake by corn and other crops ahanger et al 2016 ahmad et al 2014 eissa and roshdy 2019 but this synergistic effect is beyond the model s capability and was not considered in this study the optimal daycent parameter set from dream computational experiments was used to estimate irrigation requirements to meet crop consumptive use in each year within the analysis period subsequently the uncertainty of model responses was evaluated for limited irrigation treatments at 0 i e rainfed 20 40 60 and 80 percent of full irrigation requirements 3 results and discussion 3 1 important daycent parameters and critical crop growth processes fig 1 presents a summary of the main effects first order indices and total effects total order indices of daycent model parameters on the estimated average annual grain yield for the icm ims and rms treatments the most important parameters were crop growth production related parameters the total sensitivity indices for et and soil water related parameters were very small even under rainfed treatment rms parameters ppdf1 ruetb and klight were the most important parameters for all treatments results suggest that more attention should be paid to the optimum temperature for production ppdf1 radiation use efficiency ruetb the primary parameter that controls the potential crop growth in daycent was found to have a very high sensitivity index these results corroborate findings for other crop models with similar scientific theory and conceptualization for crop growth simulation including ceres maize dejonge et al 2012 and epic wang et al 2005 the extinction coefficient parameter klight is another parameter widely used by crop models which determines how much light can be intercepted by the canopy for photosynthesis thus it is expected to be very influential on yield pathak et al 2007 results indicated that variation in the soil texture parameters bd p sand and p clay within a given texture class had a relatively small influence on simulated average annual crop yields which justifies the use of generalized soil texture classes in regional studies or field level studies where detailed soil information are not available similarly soil property parameters used in ceres maize were found to have relatively low sensitivity for prediction of grain yield of corn in both full and limited irrigation treatments dejonge et al 2012 ma et al 2009 showed relatively large variation of the saturated conductivity ksat of soils with high percent of sand could result in significant change in crop yield in crop simulations in our simulation ksat was predicted by the saxton pedotransfer equation based on soil texture the small predicted ksat and its relative small range for silty clay loam 0 00008 0 0003 mm h resulted in limited impact on yield the kcet crop coefficient for et parameter in the rainfed treatment was more important than for the two irrigated treatments this result is plausible since higher potential et rate higher kcet value results in higher actual et and subsequently higher drought stress when irrigation is not available to mitigate water stress the impact is crop type and growth stage dependent the sensitivity of seasonal or monthly crop response variables in daycent has not been investigated in previous studies as the timing of drought stress within the growing season is important in crop development jha et al 2018 saseendran et al 2014 we presented the total sensitivity indices for may july and september in the rainfed treatment corresponding to early middle and late growing season fig 2 better understanding of within season variation in stress responses is vital for proper parameterization of models in response to temporal variability of climatic conditions results are depicted only for parameters with indices greater than 0 05 for monthly glai and aboveground biomass the ranking of indices of the two irrigated treatments is similar except for the parameter gapmndd which was more important in the rainfed treatment since it represents the change of gdd requirement from anthesis to maturity under drought stress the three most important parameters for grain yield ppdf1 ruetb and klight were also important in most months for glai and aboveground biomass in some months a single daycent parameter was shown to be most influential for example in may the sensitivity indices for ddemerg for both glai and aboveground biomass were higher than 0 4 showing the large sensitivity of early crop growth to parameters controlling time of emergence after planting 3 2 analysis of residuals from sobol gsa model residuals for the gsa simulation with the lowest rmse were analyzed to identify a proper likelihood function for uncertainty analysis appendix fig a1 heteroscedasticity was not detected in model residuals using the brown forsythe test p values for glai and biomass were 0 246 and 0 462 respectively the homoscedasticity of grain yield residuals was not tested because only six observations were available residuals for all three responses monthly glai monthly aboveground biomass and annual grain yield were normally distributed based on the chi square test for normality at 0 05 significance level p values for glai biomass and grain yield were 0 918 0 088 and 0 059 respectively the partial autocorrelation plots of each year and treatment showed no significant correlation at any lag 3 3 posterior distribution of parameters the dream algorithm does not only predict the best value for a parameter but also the statistical distribution of each parameter value as informed by the measurements the marginal posterior probability density function pdf for the 12 most important daycent parameters and three σ ε from dream were plotted fig 3 the summary of the basic statistics and the optimal value for each parameter are shown in table 3 the ruetb ppdf1 ddemerg ddbase bmini and klight parameters exhibited approximately normal or log normal distributions suggesting that the central tendency and variability of the parameters were well defined by the measurements for mxddhrv gapmndd leafpm the most likely values were not well informed by the measured data as the shapes of the posterior distributions were close to a uniform distribution ppdf2 and leafmx exhibited their highest probability at their upper bounds despite the fact that the full range between upper and lower bounds represent reasonable limits in field observations both of them were curve defining parameters in the model the temperature response curve defined by equation 3 and the curve of g l w r which is used in equation 4 suggesting the model structure in simulating these responses can be improved fig 4 illustrates the correlation structure between posterior parameters from dream analysis a strong negative correlation was evident between ruetb and klight this observation can be explained because to produce the same amount of biomass when more light is intercepted i e greater klight the radiation use efficiency would have to decrease i e smaller ruetb a high negative correlation was also found between ddbase and leafmx when the time of maximum glai is delayed the leafmx glwr at maximum glai decreases because of the linear function with negative slope used in the revised daycent model zhang et al 2018b the ddbase parameters was also highly correlated with sla as they control the leaf biomass and glai an increase in ddbase or sla results in higher glai for highly correlated parameters the value of one parameter affects how we choose the correlated parameters and the posterior distribution of a parameter cannot be seen as separate from the other parameters for predictive uncertainty analysis it is not right to generate samples from the posterior distributions without considering their correlations the correlations between other parameters in fig 4 were relatively low 3 4 predictive uncertainty for the training data we first used the optimal parameter set from dream to generate predictions for the training dataset and compared model results with field observations the optimal parameter values provided optimized predictions for biomass with rmse 979 9 kg ha 1 and r2 0 98 fig 5 the predictions for glai was slightly lower rmse 0 79 and r2 0 84 there was substantial underestimation of glai at the late growing season for ims in 2005 fig 5 this suggested the phenology was not predicted correctly because the onset and the end of leaf senescence were controlled by phenology this was also suggested by the wide and flat posterior distributions of mxddhrv gapmndd and leafpm i e the algorithm could not find a well defined small range for these parameters that relate to phenology and leaf senescence which indicates that the model structure needs improvement one possible improvement could be to calculate heat units hourly instead of daily and use non linear temperature functions yin and laar 2005 regarding the grain yield it was accurately predicted using the optimal parameter values rmse 514 8 kg ha 1 and r2 0 92 the dream algorithm predicted relative narrow 95 uncertainty bands for the training dataset fig 5 but with several observations outside the bands similar results were found in dumont et al 2014 which also used the dream algorithm for predictive uncertainty analysis the narrower uncertainty bands were because only parameter uncertainty was included in our analysis input uncertainty and model structural uncertainty would be needed to characterize total uncertainty and expand the uncertainty band ajami et al 2007 3 5 predictive uncertainty for the testing data for the testing dataset the optimal parameter values yielded accurate prediction for biomass rmse 1575 2 kg ha 1 and r2 0 96 but the accuracy was lower than for the training dataset as expected fig 6 similarly the accuracy for glai was lower rmse 1 06 and r2 0 78 the glai of the two irrigated treatments icm and ims was under predicted for the whole growing season which may be because the days to anthesis were under predicted corn is generally believed to have very low sensitivity to photoperiod corbeels et al 2016 soltani and sinclair 2012 however some cultivars might respond significantly as demonstrated by ceres maize model studies dejonge et al 2012 saddique et al 2019 including photoperiod responses in our simulation might produce better predictions of days to anthesis the water stress effect for the rainfed treatment rms was not very well estimated and led to an over prediction of biomass glai and grain yield at harvest fig 6 the rmse for grain yield 999 5 kg ha 1 was lower than the training data but the r2 0 96 was slightly higher the width of the 95 uncertainty bands were similar to the training data the overall accuracy was high considering the large variation across the large experimental fields 49 65 ha per field in one of our previous studies the model was able to accurately simulate water stress effect for corn under various water stressed conditions at different locations in colorado zhang et al 2018a the reason for the overestimation for the rainfed treatment here was found to be the inaccurate estimation of soil water fig a3 this could be a result of the uncertainty in precipitation and or soil properties due to spatial variability across such large fields 3 6 prediction uncertainty interval for crop water production functions for each irrigation scenario during the three driest years 2002 2003 and 2012 annual precipitation less than 60 cm distributions of predicted yields were plotted using a boxplot fig 7 the response of yield to irrigation was very clear the median values of predicted yield of the non irrigated scenario were about half of those of the full irrigation scenario in these years irrigation level of 80 et replacement was predicted to produce similar yields as the 100 scenario this is supported by our understanding from field studies e g english 1990 that the increase in yield slows down when irrigation increases towards meeting total crop water demand we also observed that the coefficient of variation cv of predicted yields which is a standardized measure of dispersion of a distribution at every irrigation level was within a narrow range 0 05 0 13 similar to our work posterior distributions of parameters can be easily used to generate uncertainty estimates of crop production functions for other locations and other crops or cultivars these crop production functions will be site specific and in theory more accurate than a generalized crop production function for a larger region using climate models to generate future weather as an input site specific predictions could be made for assessing crop responses to climate change which could support decision making for farmers and irrigation managers our uncertainty analysis can be extended to provide uncertainty estimates for decision supporting tools such as comet farm and the erams system which run the daycent model as part of their predictive functions 3 7 limitations we quantified predictive uncertainty due to parameter uncertainty in this study uncertainty from input forcing e g weather variables can be added to the analysis by providing prior distributions of multipliers of these variables it is impossible to set prior distribution for each daily value vrugt et al 2008 for future predictions it is popular to use an ensemble approach which uses more than one climate datasets to drive an ago ecosystem model e g baigorria et al 2008 the quantification of structural uncertainty is difficult engeland et al 2005 estimated the total of parameter uncertainty and structural uncertainty by adding the model residuals to each of the output values at each step of the mcmc algorithm however we agree with marshall et al 2007 that a robust way of estimating structural uncertainty requires multiple models the outputs from multiple models are used to generate an ensemble the bayesian model averaging method fragoso et al 2018 is popular in this category we will address the uncertainty from input forcing and model structure in future studies 4 conclusions in this study we analyzed the sensitivity and uncertainty of daycent model parameters for one hybrid of corn growing in well irrigated versus water stressed treatments we also quantified the predictive uncertainty of simulated grain yield for varying degrees of water stress we found that among the 24 parameters tested the growth production related parameters in daycent had relatively more impact on grain yield glai and biomass than did et and soil water related parameters for both rainfed and irrigated conditions under rainfed conditions evapotranspiration related parameters and drought stress related parameters showed higher sensitivity than irrigated conditions as expected our monthly results demonstrated that the sensitivity could be highly dependent on the seasonality as most of the model parameters have physiological meanings the sensitivity results implied that breeding and selecting cultivars for traits that have the greatest sensitivity impact on growth could substantially improve production under both irrigated and non irrigated conditions these could include cultivars with better heat tolerance higher capacity of light utilization and canopy structures that allowing higher planting density for dryland crops cultivars with lower transpiration potential would be more drought tolerant and potentially produce more yield our analysis also revealed some model weaknesses for future improvements in addition our study provides a rigorous template for producing crop water production functions with well defined uncertainty bounds that can be used to provide management recommendations to improve the water use efficiency of annual crop production for our study conditions the results suggested that 80 of full irrigation could lead to similar grain yield as for full irrigation in dry years which could help farmers to save water without losing yield the relative narrow uncertainty band indicated that agro ecosystem models can be reliable in producing estimates for decision making similar simulations with predictive uncertainty can be made for different crops and locations to provide improved information for water management declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by grants from the agriculture and food research initiative of the united states department of agriculture usda national institute of food and agriculture nifa grant numbers 2012 67003 19904 and 2011 67003 3025 and a conservation innovation grant no 69 3a75 14 61 from usda natural resources conservation service a appendix fig a1 modeled residuals plotted against a measured glai and b measured aboveground biomass the density plots of residuals are for c glai and d aboveground biomass fig a1 fig a2 zoom in view of fig 1 x 0 05 and y 0 05 comparison of first order and total order sensitivity indices of sobol for daycent output of grain yield of maize from three treatments treatments were irrigated continuous maize icm irrigated maize soybean ims and rainfed maize soybean rms the numerical values are references to parameters in table 2 fig a2 fig a3 simulated and measured soil water content swc of the rms treatment in 2003 the over estimation of swc at 50 and 100 cm resulted in the overestimation of biomass and yield in fig 6 for the rms treatment fig a3 
26047,crop water production functions quantifying crop yield as a function of irrigation rate can help in the design of management systems that reduce the water footprint we examined the role of parameter uncertainties in characterizing production functions using the daycent agroecosystem model a global sensitivity analysis was conducted to identify the model parameters associated with the greatest uncertainties in model responses under both irrigated and non irrigated conditions growth production related parameters had relatively more impact on grain yield than did soil related parameters under non irrigated conditions there was greater sensitivity to evapotranspiration related parameters we then used the dream method a markov chain monte carlo mcmc bayesian approach to determine the posterior distributions of the selected parameters the dream method produced good estimates for the posterior distribution of the critical parameters the utility of water production functions as predictive tools to guide water management decisions is greatly enhanced by incorporating rigorous estimates of uncertainty keywords sensitivity analysis uncertainty analysis bayesian crop water production function limited irrigation daycent model software availability program title daycent model developer w j parton s j del grosso s ogle k paustian y zhang contact address natural resource ecology laboratory colorado state university fort collins co usa telephone 970 491 2195 email address yao zhang colostate edu year first available 1998 hardware required pc software required windows or linux availability and cost available on request free program title dream differential evolution adaptive metropolis package for r developer j a vrugt c j f ter braak et al contact address department of civil and environmental engineering the university of texas at san antonio one utsa circle san antonio tx 78249 usa email address john joseph utsa edu j f joseph availability and cost http dream r forge r project org free 1 introduction in the irrigated river basins of arid and semi arid regions in the western united states vulnerability to water shortage poses a significant risk to agricultural production ahuja et al 2008 doorenbos and kassam 1979 dozier et al 2017 large amounts of water from surface and underground sources are applied as irrigation to maintain high crop yields irrigation withdrawals in the us account for approximately 38 of total freshwater withdrawals maupin et al 2014 the increasing demand for water from municipal users due to rapid population growth and urbanization as well as demands for other industrial and environmental uses increasingly limit the availability of water for agriculture colorado water conservation board 2010 vorosmarty et al 2000 extended drought periods in a changing climate and declining groundwater levels are expected to further exacerbate the situation colorado water conservation board 2010 mcguire 2014 understanding the response of cropping systems to changes in irrigation levels is essential for reducing the water footprint of agricultural crops while maintaining production levels fereres and soriano 2007 saseendran et al 2014 trout et al 2010 the estimations of the responses can be used in complex economic and social analyses for decision support the optimal irrigation amounts are often determined by various economic and social factors dozier et al 2017 dynamic crop models are valuable tools for the estimation of the crop yield response to water brumbelow and georgakakos 2007 garcia vila and fereres 2012 saseendran et al 2014 however simulation models are only approximate representations of real world systems and thus bear uncertainties in simulating system behavior the predictions of dynamic crop models are influenced by inputs meteorological soil and land use uncertain model parameters the limitation of the mathematical representation of real world processes and uncertainty in the observed data that are used for calibration purposes all of these components need to be considered in assessing the uncertainty in crop model predictions confalonieri et al 2016 sources of modeling uncertainties can be grouped into three categories input structural and parameter uncertainties haefner 2005 input uncertainty is from errors in input forcing e g precipitation or soil texture of a field model structures are invariably incomplete and uncertain due to the simplification of real world processes lack of knowledge about some processes and from neglecting to include some processes that are deemed insignificant for pragmatic considerations finally model parameters time invariant coefficients that are treated as constants and are estimated by means of calibration to observed data can bear considerable uncertainty for a single model structure the uncertainty due to model parameters can be estimated using bayesian methods by conditioning the model behavior on measurements the literature is replete with methods for uncertainty analysis based on bayesian formalism particularly in hydrological studies e g beven and binley 1992 some bayesian methods have been applied for uncertainty analysis of crop models the generalized likelihood uncertainty estimation glue method beven and binley 1992 has been used for the estimation of posterior parameter distributions in studies of wheat using the simulateur multidiscipli naire pour les cultures standard stics wheat model varella et al 2010 sweet corn using the crop environment resource synthesis ceres maize model he et al 2009 maize and wheat using root zone water quality model 2 rzwqm2 model sun et al 2016 and cotton using the cropping system model csm cropgro cotton model pathak et al 2012 despite the computational simplicity and popularity of the glue method concerns about using informal bayesian likelihood functions in glue have been the subject of extensive scientific discourse stedinger et al 2008 vrugt et al 2009b alternatively formal bayesian methods using markov chain monte carlo mcmc techniques have been developed in crop modeling mcmc methods have been applied to quantify the uncertainty in predicted phenological development of maize in slovenia using the world food studies wofost model ceglar et al 2011 more recently a mcmc method named differential evolution adaptive metropolis dream vrugt and ter braak 2011 was applied to characterize parameter uncertainties of the stics model in simulations of winter wheat dumont et al 2014 another recent study applied the mcmc method with the systems approach for land use sustainability salus model to simulate maize peanut and cotton dzotsi et al 2015 the mcmc method was found useful as a method for quantifying uncertainty parameter sensitivity analysis sa is usually performed prior to uncertainty analysis to evaluate the importance of model parameters ceglar et al 2011 he et al 2009 laloy et al 2010 pathak et al 2012 while several local and global methods are available global sa methods are more informative since they account for interactions between parameters saltelli et al 2000 furthermore global sa can provide information on the structure of the model residuals which is essential for the implementation of formal bayesian techniques for uncertainty analysis ahmadi et al 2014 the daycent model parton et al 1998 is a widely used ecosystem model for simulating crop yield soil carbon nitrous oxide emissions and other agroecosystem responses chang et al 2013 del grosso et al 2006 2008 jarecki et al 2008 stehfest et al 2007 zhang et al 2013 a few previous studies have assessed the predictive uncertainty of daycent due to parameter uncertainty de gryze et al 2010 del grosso et al 2010 fitton et al 2014 lee et al 2011 two studies in particular analyzed the parameter uncertainty on trace gas emissions using bayesian methods van oijen et al 2011 wang and chen 2012 the daycent model is used in widely deployed decision support systems including the carbon management evaluation tool comet farm tool paustian et al 2018 http cometfarm nrel colostate edu a farm scale carbon and greenhouse gas accounting tool with new features of water management and water quality in development and the agroecosystem analysis tool on environmental resource assessment and management system erams platform arabi 2011 https erams com a field to basin scale water management tool thus it is critical to provide accurate uncertainty estimates for crop growth and water dynamics in these tools recent development of the daycent model include a new crop canopy development algorithm and improved accuracy in predicted crop water use zhang et al 2018b however the new crop submodel was manually calibrated and tested for water limited conditions zhang et al 2018a leaving a need for a systematic analysis of parameter sensitivity and uncertainty a systematic analysis could improve our understanding of the model and reveal the weaknesses in model structure e g non sensitive parameters and constantly biased predictions thus the overall goal of this study was to enhance the applicability of the new version of the model for simulating crop and soil water dynamics under water limited conditions by analyzing parameter sensitivity and quantifying uncertainty associated with model predictions our objectives were to i understand the importance of parameters and the processes they represent in the daycent model through a global sensitivity analysis ii characterize the uncertainty of important parameters and iii validate the model predictions in water limited environments 2 material and methods for the sensitivity and uncertainty analysis of the daycent agroecosystem model parton et al 1998 we used data from a field experiment conducted in mead ne which included three treatments irrigated continuous maize irrigated maize soybean rotation and a rainfed maize soybean rotation in our analysis we first applied sobol s global sensitivity analysis sobol 1993 to identify the relative importance of model parameters for predicted grain yield monthly green leaf area index glai and monthly aboveground biomass then results from the sensitivity analysis were used to investigate the structure of model errors using measurement data six year treatment separated for training and testing posterior distributions of the model parameters for one maize hybrid were identified using the dream technique the predictive uncertainty of the training dataset three out of six year treatment combinations and testing datasets the remaining three year treatment combinations was estimated 2 1 field experiments field data were obtained from an experiment conducted at the university of nebraska agricultural research and development center near mead ne a detailed experimental design can be found in suyker and verma 2009 although it is not a limited irrigation experiment the irrigated treatment and rainfed treatments under years with varying amounts of precipitation provide enough information to analyze water stress the experiment was initialized in 2001 two of the treatments were irrigated and one was rainfed each treatment is a large production field 49 65 ha one of the irrigated treatments was planted in continuous maize zea mays l irrigated continuous maize or icm the other irrigated treatment was in a maize soybean glycine max l rotation irrigated maize soybean rotation or ims the rainfed treatment was also in a maize soybean rotation rainfed maize soybean rotation or rms these treatments weremanaged using standard best management practices in this region for fertilizer herbicide and pesticide applications during the experimental period different hybrids of maize were grown with different planting date depending on the relative maturity and weather soil conditions zhang et al 2018b hybrid pioneer 33b51 was planted in 2001 2003 2004 and 2005 table 1 data from this hybrid were selected for use in this study within each treatment six 20 20 m measurement areas intensive measurement zones were established for detailed measurements of leaf area aboveground biomass and other important ecosystem variables verma et al 2005 in our study glai aboveground biomass and grain yield measurements were the variables of interest grain yields were recorded from the measurement of combine harvest of the entire treatment field leaf area and aboveground biomass were sampled destructively on an average of 11 day basis at each intensive measurement zone of each treatment the soil in all three treatments was a deep silty clay loam with a near level slope soil characteristics were measured for four depth increments and details can be found in zhang et al 2018b air temperature solar radiation relative humidity and wind speed for model simulation were from an on site weather station station name meadagrofarm high plains regional climate center lincoln ne precipitation and irrigation amounts needed as model inputs via a center pivot irrigation system were directly measured within each treatment field using rain gauges 2 2 agroecosystem model daycent the daycent ecosystem cropland forest grassland and savanna model parton et al 1998 daily version of the century model parton et al 1987 was used in this study the major sub models of daycent include plant growth soil water soil organic matter decomposition soil nitrogen and trace gas emission major inputs for the model are daily weather soil physical properties plant type and management practices recently zhang et al 2018b incorporated a new method to simulate the canopy dynamics of annual crops along with other modifications the field experiment used in this study has been previously simulated with the improved model using manually calibrated parameters zhang et al 2018b the results show improved glai simulation and a better fit in late season evapotranspiration rate in comparison with the previous version of the model by improving the calculation for green leaf biomass described later in this section this version of daycent has also been applied to simulate limited irrigation experiments in eastern colorado zhang et al 2018a with manual calibration a brief discussion of the theory concepts and methods used in the improved model is presented here in daycent daily potential net primary production is simulated as the product of radiation use efficiency and intercepted photosynthetically active radiation par 1 p p i c c i p a r i r u e t b where p p i is the potential production on the ith day c c i is the fraction of radiation intercepted by canopy on the ith day and ruetb is the radiation use efficiency of total biomass production aboveground and belowground the variable c c i is calculated using beer s law monsi and saeki 1953 sellers 1985 2 c c i 1 e x p k l i g h t g l a i i where k l i g h t is the extinction coefficient of vegetation the actual production is affected by temperature water and nutrient daily actual production is allocated to above and below ground based on the development stage and stress water and nitrogen phenology of growth is estimated by a growing degree day gdd method temperature effect t e on p p i approximately a bell shaped curve is as follows 3 t e p p d f 2 t m e a n p p d f 2 p p d f 1 p p d f 3 e x p p p d f 3 p p d f 4 1 p p d f 2 t m e a n p p d f 2 p p d f 1 p p d f 4 where ppdf1 ppdf2 ppdf3 ppdf4 are parameters to control the shape of the curve t mean is the daily mean temperature the soil water sub model simulates 1 dimensional water balance including precipitation irrigation evapotranspiration et runoff and percolation parton et al 1998 potential et is simulated by a calculated reference et and crop coefficients allen et al 1998 potential et is partitioned into potential evaporation from the soil and transpiration by the plant based on glai both the crop production sub model and soil water sub model require prediction of glai the new glai method is described in zhang et al 2018b briefly glai is converted from green leaf biomass using a constant specific leaf area sla in our new method green leaf biomass is simulated using green leaf weight ratio glwr as a function of gdd and aboveground biomass 4 g l a i i a g b i o m a s s i g l w r i s l a 2 3 global sensitivity analysis global sensitivity analysis gsa apportions the uncertainty in model outputs to the uncertainty in individual inputs and interactions thereof saltelli et al 2000 the sobol method is arguably the most comprehensive gsa method due to its sampling design for the exploration of the parameter space the decomposition of the variance of the model outputs v a r y ˆ for k parameters θ is written as 5 v a r y ˆ i 1 k d i 1 i j k d i j d 1 k where d i is the main effect of input parameter θ i the terms of d i j d 1 k correspond to the interactions between parameters the computation of these terms can be found in sobol 1993 and is not discussed here the sensitivity indices are given by 6 s i 1 i s d i 1 i s v a r y ˆ where 1 i 1 i s k and s 1 k hence the first order sensitivity indices main effects for each parameter are 7 s i d i v a r y ˆ total order indices are then computed as 8 t s i s i 1 i j k s i j s 1 k twenty four parameters in the improved version of daycent model were used in sensitivity analysis table 2 these parameters can be divided into two groups i crop growth production related parameters which are species or cultivar specific and ii parameters representing et and soil water processes uniform distributions were assumed for the prior parameter distributions dejonge et al 2012 dzotsi et al 2015 the ranges of model parameters were selected based on field measurements at the mead site and or relative studies in the literature global sensitivity analysis using the method of sobol requires independence of parameters however parameters mnddhrv minimum number of degree days from anthesis to harvest and mxddhrv maximum number of degree days from anthesis to harvest are not independent mnddhrv must be smaller than mxddhrv a new parameter gapmndd the difference between mnddhrv and mxddhrv was defined as a random variable mnddhrv was then calculated based on the mxddhrv and gapmndd additionally a wider range of 0 9 1 3 for the crop coefficient for evapotranspiration kcet parameter was used because field measurements indicated smaller values 1 03 0 07 suyker and verma 2009 than those reported by food and agriculture organization of the united nations fao allen et al 1998 soil parameters including saturation point field capacity wilting point and saturated conductivity were estimated by soil texture using the saxton equation saxton et al 1986 the sand content clay content and bulk density were varied within the ranges of a silty clay loam u s soil texture triangle by assuming only one soil texture in the experimental fields soil parameters were inputs to the model and were not changed during the simulation the model sensitivity to input weather variables were not included in this study it was analyzed and published previously zhang and paustian 2019 in this study a sample size of 25 600 was generated using the simlab software joint research center of the european commission 2004 this sample size meets the requirement of n k 2 with n in range of 500 1000 typically k is the number of parameters to ensure numerical stability saltelli et al 1999 2005 these samples of parameter sets were used to run the simulations for hybrid pioneer 33b51 total six year treatment table 1 the model responses examined in the sensitivity analysis were annual grain yield monthly aboveground biomass and monthly glai monthly averages of aboveground biomass and glai in may july and september were examined for differences in sensitivity during early middle and late growing seasons as the timing of drought stress is important for crop development important model parameters were then included in parameter and predictive uncertainty analysis the criterion for classifying parameters as important was sensitivity indices greater than 0 05 for monthly aboveground biomass monthly glai or annual grain yield 2 4 bayesian parameter uncertainty analysis using dream using bayesian formalism the posterior distribution of a set of parameters θ of model responses y ˆ conditioned on observed data y is 9 p θ y p y θ p θ p y θ p θ d θ where p y θ represents the likelihood of the data p θ is the prior distribution of parameters the likelihood p y θ is determined from the probability distribution of the residuals between observed y and modeled y ˆ responses residuals are often assumed to be uncorrelated independent normally distributed box and tiao 1992 hence yielding the likelihood function 10 l θ y i 1 n 2 π σ ε 2 1 2 exp 1 2 σ ε 2 y ˆ i θ y i 2 where σ ε is the standard deviation of model errors and n is the number of observed responses assuming homoscedastic model residuals the log likelihood function is 11 l θ y n 2 l n 2 π 2 n ln σ ε 1 2 σ ε 2 i 1 n y i y ˆ i θ 2 when model residuals are not homoscedastic observed and model responses are typically transformed using appropriate transformations e g box cox transformation box and cox 1964 prior to computation of the likelihood function similarly autoregressive time series models e g first order autoregressive transformation ar 1 may be applied to remove model error autocorrelation ahmadi et al 2014 vrugt 2016 mcmc simulations are commonly used for estimation of posterior parameter distributions as a formal bayesian method the dream algorithm vrugt et al 2008 2009a vrugt and ter braak 2011 vrugt 2016 was selected for this study the advantage of this approach is its efficiency in mitigating issues with high dimensionality multimodality nonlinearity and local optima with proved ergodicity compared with some traditional mcmc algorithms vrugt 2016 presents a complete review of the theory concepts and matlab implementation for the dream approach 2 5 identification of the structure of model residuals daycent model residuals were investigated for homoscedasticity normality and uncorrelated residuals from the 25 600 gsa runs outputs were extracted and residuals were calculated for each run using measurement data of annual grain yield multiple in season glai measurements and in season aboveground biomass of hybrid pioneer 33b51 residuals for the best model parameters selected based on the minimum root mean squared error rmse were explored model residuals of the three response variables i e yield glai biomass were examined for heteroscedasticity using the chi square test for normality since the glai and biomass are only continuously measured within each year partial autocorrelation in each year was also graphically assessed 2 6 implementation of the daycent linkage with dream the r package for dream guillaume and andrews 2012 was integrated with the daycent model to conduct the parameter uncertainty analysis we wrote a script in r to compute the likelihood function required as input to the dream package twelve mcmc chains were used in this study the gelman and rubin 1992 statistic r ˆ of 1 2 was used for convergence the first 50 of simulations were treated as the so called burn in runs discarded after which chain approached its stationary distribution vrugt and ter braak 2011 the measurement data used in residual analysis were divided into two datasets for training and testing data from the icm treatment in 2004 ims treatments in 2005 and rms treatment in 2001 were used for training since these data covered variations in planting dates water stress irrigated vs non irrigated and growing season temperature this data set contained 28 measurements of glai 26 measurements of aboveground biomass and 3 measurements of annual grain yield for testing purposes measurements from the three treatments in 2003 were used the measurement data included 24 measurements of monthly glai 24 measurements of monthly aboveground biomass and 3 measurements of annual grain yield the σ ε in equation 11 is associated with uncertainty the σ ε values were estimated in parallel with the daycent parameters iizumi et al 2014 very wide uniform prior distribution was used for σ ε for grain yield sigma graincarbon 10 200 g c m 2 grain carbon is a good predictor for corn yield but may not be for other crops aboveground biomass sigma abovegroundcarbon 10 400 g c m 2 and glai sigma glai 0 1 2 5 the predictive uncertainty for glai aboveground biomass and annual grain yield were computed using the last 10 of parameter sets from the dream algorithm after convergence 2 7 uncertainty in the prediction of crop water production functions we used input variables from the rainfed treatment at mead for a 12 year period from january 2001 to december 2012 to generate crop production functions only the dry years in this period 2001 2003 and 2012 were in our analysis to show the drought effect on production the planting date was fixed at doy 130 simulations were then conducted assuming no nutrient stress to be able to discern the effects of water stress at varying irrigation levels evidences showed interactions of moisture stress and nutrient uptake by corn and other crops ahanger et al 2016 ahmad et al 2014 eissa and roshdy 2019 but this synergistic effect is beyond the model s capability and was not considered in this study the optimal daycent parameter set from dream computational experiments was used to estimate irrigation requirements to meet crop consumptive use in each year within the analysis period subsequently the uncertainty of model responses was evaluated for limited irrigation treatments at 0 i e rainfed 20 40 60 and 80 percent of full irrigation requirements 3 results and discussion 3 1 important daycent parameters and critical crop growth processes fig 1 presents a summary of the main effects first order indices and total effects total order indices of daycent model parameters on the estimated average annual grain yield for the icm ims and rms treatments the most important parameters were crop growth production related parameters the total sensitivity indices for et and soil water related parameters were very small even under rainfed treatment rms parameters ppdf1 ruetb and klight were the most important parameters for all treatments results suggest that more attention should be paid to the optimum temperature for production ppdf1 radiation use efficiency ruetb the primary parameter that controls the potential crop growth in daycent was found to have a very high sensitivity index these results corroborate findings for other crop models with similar scientific theory and conceptualization for crop growth simulation including ceres maize dejonge et al 2012 and epic wang et al 2005 the extinction coefficient parameter klight is another parameter widely used by crop models which determines how much light can be intercepted by the canopy for photosynthesis thus it is expected to be very influential on yield pathak et al 2007 results indicated that variation in the soil texture parameters bd p sand and p clay within a given texture class had a relatively small influence on simulated average annual crop yields which justifies the use of generalized soil texture classes in regional studies or field level studies where detailed soil information are not available similarly soil property parameters used in ceres maize were found to have relatively low sensitivity for prediction of grain yield of corn in both full and limited irrigation treatments dejonge et al 2012 ma et al 2009 showed relatively large variation of the saturated conductivity ksat of soils with high percent of sand could result in significant change in crop yield in crop simulations in our simulation ksat was predicted by the saxton pedotransfer equation based on soil texture the small predicted ksat and its relative small range for silty clay loam 0 00008 0 0003 mm h resulted in limited impact on yield the kcet crop coefficient for et parameter in the rainfed treatment was more important than for the two irrigated treatments this result is plausible since higher potential et rate higher kcet value results in higher actual et and subsequently higher drought stress when irrigation is not available to mitigate water stress the impact is crop type and growth stage dependent the sensitivity of seasonal or monthly crop response variables in daycent has not been investigated in previous studies as the timing of drought stress within the growing season is important in crop development jha et al 2018 saseendran et al 2014 we presented the total sensitivity indices for may july and september in the rainfed treatment corresponding to early middle and late growing season fig 2 better understanding of within season variation in stress responses is vital for proper parameterization of models in response to temporal variability of climatic conditions results are depicted only for parameters with indices greater than 0 05 for monthly glai and aboveground biomass the ranking of indices of the two irrigated treatments is similar except for the parameter gapmndd which was more important in the rainfed treatment since it represents the change of gdd requirement from anthesis to maturity under drought stress the three most important parameters for grain yield ppdf1 ruetb and klight were also important in most months for glai and aboveground biomass in some months a single daycent parameter was shown to be most influential for example in may the sensitivity indices for ddemerg for both glai and aboveground biomass were higher than 0 4 showing the large sensitivity of early crop growth to parameters controlling time of emergence after planting 3 2 analysis of residuals from sobol gsa model residuals for the gsa simulation with the lowest rmse were analyzed to identify a proper likelihood function for uncertainty analysis appendix fig a1 heteroscedasticity was not detected in model residuals using the brown forsythe test p values for glai and biomass were 0 246 and 0 462 respectively the homoscedasticity of grain yield residuals was not tested because only six observations were available residuals for all three responses monthly glai monthly aboveground biomass and annual grain yield were normally distributed based on the chi square test for normality at 0 05 significance level p values for glai biomass and grain yield were 0 918 0 088 and 0 059 respectively the partial autocorrelation plots of each year and treatment showed no significant correlation at any lag 3 3 posterior distribution of parameters the dream algorithm does not only predict the best value for a parameter but also the statistical distribution of each parameter value as informed by the measurements the marginal posterior probability density function pdf for the 12 most important daycent parameters and three σ ε from dream were plotted fig 3 the summary of the basic statistics and the optimal value for each parameter are shown in table 3 the ruetb ppdf1 ddemerg ddbase bmini and klight parameters exhibited approximately normal or log normal distributions suggesting that the central tendency and variability of the parameters were well defined by the measurements for mxddhrv gapmndd leafpm the most likely values were not well informed by the measured data as the shapes of the posterior distributions were close to a uniform distribution ppdf2 and leafmx exhibited their highest probability at their upper bounds despite the fact that the full range between upper and lower bounds represent reasonable limits in field observations both of them were curve defining parameters in the model the temperature response curve defined by equation 3 and the curve of g l w r which is used in equation 4 suggesting the model structure in simulating these responses can be improved fig 4 illustrates the correlation structure between posterior parameters from dream analysis a strong negative correlation was evident between ruetb and klight this observation can be explained because to produce the same amount of biomass when more light is intercepted i e greater klight the radiation use efficiency would have to decrease i e smaller ruetb a high negative correlation was also found between ddbase and leafmx when the time of maximum glai is delayed the leafmx glwr at maximum glai decreases because of the linear function with negative slope used in the revised daycent model zhang et al 2018b the ddbase parameters was also highly correlated with sla as they control the leaf biomass and glai an increase in ddbase or sla results in higher glai for highly correlated parameters the value of one parameter affects how we choose the correlated parameters and the posterior distribution of a parameter cannot be seen as separate from the other parameters for predictive uncertainty analysis it is not right to generate samples from the posterior distributions without considering their correlations the correlations between other parameters in fig 4 were relatively low 3 4 predictive uncertainty for the training data we first used the optimal parameter set from dream to generate predictions for the training dataset and compared model results with field observations the optimal parameter values provided optimized predictions for biomass with rmse 979 9 kg ha 1 and r2 0 98 fig 5 the predictions for glai was slightly lower rmse 0 79 and r2 0 84 there was substantial underestimation of glai at the late growing season for ims in 2005 fig 5 this suggested the phenology was not predicted correctly because the onset and the end of leaf senescence were controlled by phenology this was also suggested by the wide and flat posterior distributions of mxddhrv gapmndd and leafpm i e the algorithm could not find a well defined small range for these parameters that relate to phenology and leaf senescence which indicates that the model structure needs improvement one possible improvement could be to calculate heat units hourly instead of daily and use non linear temperature functions yin and laar 2005 regarding the grain yield it was accurately predicted using the optimal parameter values rmse 514 8 kg ha 1 and r2 0 92 the dream algorithm predicted relative narrow 95 uncertainty bands for the training dataset fig 5 but with several observations outside the bands similar results were found in dumont et al 2014 which also used the dream algorithm for predictive uncertainty analysis the narrower uncertainty bands were because only parameter uncertainty was included in our analysis input uncertainty and model structural uncertainty would be needed to characterize total uncertainty and expand the uncertainty band ajami et al 2007 3 5 predictive uncertainty for the testing data for the testing dataset the optimal parameter values yielded accurate prediction for biomass rmse 1575 2 kg ha 1 and r2 0 96 but the accuracy was lower than for the training dataset as expected fig 6 similarly the accuracy for glai was lower rmse 1 06 and r2 0 78 the glai of the two irrigated treatments icm and ims was under predicted for the whole growing season which may be because the days to anthesis were under predicted corn is generally believed to have very low sensitivity to photoperiod corbeels et al 2016 soltani and sinclair 2012 however some cultivars might respond significantly as demonstrated by ceres maize model studies dejonge et al 2012 saddique et al 2019 including photoperiod responses in our simulation might produce better predictions of days to anthesis the water stress effect for the rainfed treatment rms was not very well estimated and led to an over prediction of biomass glai and grain yield at harvest fig 6 the rmse for grain yield 999 5 kg ha 1 was lower than the training data but the r2 0 96 was slightly higher the width of the 95 uncertainty bands were similar to the training data the overall accuracy was high considering the large variation across the large experimental fields 49 65 ha per field in one of our previous studies the model was able to accurately simulate water stress effect for corn under various water stressed conditions at different locations in colorado zhang et al 2018a the reason for the overestimation for the rainfed treatment here was found to be the inaccurate estimation of soil water fig a3 this could be a result of the uncertainty in precipitation and or soil properties due to spatial variability across such large fields 3 6 prediction uncertainty interval for crop water production functions for each irrigation scenario during the three driest years 2002 2003 and 2012 annual precipitation less than 60 cm distributions of predicted yields were plotted using a boxplot fig 7 the response of yield to irrigation was very clear the median values of predicted yield of the non irrigated scenario were about half of those of the full irrigation scenario in these years irrigation level of 80 et replacement was predicted to produce similar yields as the 100 scenario this is supported by our understanding from field studies e g english 1990 that the increase in yield slows down when irrigation increases towards meeting total crop water demand we also observed that the coefficient of variation cv of predicted yields which is a standardized measure of dispersion of a distribution at every irrigation level was within a narrow range 0 05 0 13 similar to our work posterior distributions of parameters can be easily used to generate uncertainty estimates of crop production functions for other locations and other crops or cultivars these crop production functions will be site specific and in theory more accurate than a generalized crop production function for a larger region using climate models to generate future weather as an input site specific predictions could be made for assessing crop responses to climate change which could support decision making for farmers and irrigation managers our uncertainty analysis can be extended to provide uncertainty estimates for decision supporting tools such as comet farm and the erams system which run the daycent model as part of their predictive functions 3 7 limitations we quantified predictive uncertainty due to parameter uncertainty in this study uncertainty from input forcing e g weather variables can be added to the analysis by providing prior distributions of multipliers of these variables it is impossible to set prior distribution for each daily value vrugt et al 2008 for future predictions it is popular to use an ensemble approach which uses more than one climate datasets to drive an ago ecosystem model e g baigorria et al 2008 the quantification of structural uncertainty is difficult engeland et al 2005 estimated the total of parameter uncertainty and structural uncertainty by adding the model residuals to each of the output values at each step of the mcmc algorithm however we agree with marshall et al 2007 that a robust way of estimating structural uncertainty requires multiple models the outputs from multiple models are used to generate an ensemble the bayesian model averaging method fragoso et al 2018 is popular in this category we will address the uncertainty from input forcing and model structure in future studies 4 conclusions in this study we analyzed the sensitivity and uncertainty of daycent model parameters for one hybrid of corn growing in well irrigated versus water stressed treatments we also quantified the predictive uncertainty of simulated grain yield for varying degrees of water stress we found that among the 24 parameters tested the growth production related parameters in daycent had relatively more impact on grain yield glai and biomass than did et and soil water related parameters for both rainfed and irrigated conditions under rainfed conditions evapotranspiration related parameters and drought stress related parameters showed higher sensitivity than irrigated conditions as expected our monthly results demonstrated that the sensitivity could be highly dependent on the seasonality as most of the model parameters have physiological meanings the sensitivity results implied that breeding and selecting cultivars for traits that have the greatest sensitivity impact on growth could substantially improve production under both irrigated and non irrigated conditions these could include cultivars with better heat tolerance higher capacity of light utilization and canopy structures that allowing higher planting density for dryland crops cultivars with lower transpiration potential would be more drought tolerant and potentially produce more yield our analysis also revealed some model weaknesses for future improvements in addition our study provides a rigorous template for producing crop water production functions with well defined uncertainty bounds that can be used to provide management recommendations to improve the water use efficiency of annual crop production for our study conditions the results suggested that 80 of full irrigation could lead to similar grain yield as for full irrigation in dry years which could help farmers to save water without losing yield the relative narrow uncertainty band indicated that agro ecosystem models can be reliable in producing estimates for decision making similar simulations with predictive uncertainty can be made for different crops and locations to provide improved information for water management declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by grants from the agriculture and food research initiative of the united states department of agriculture usda national institute of food and agriculture nifa grant numbers 2012 67003 19904 and 2011 67003 3025 and a conservation innovation grant no 69 3a75 14 61 from usda natural resources conservation service a appendix fig a1 modeled residuals plotted against a measured glai and b measured aboveground biomass the density plots of residuals are for c glai and d aboveground biomass fig a1 fig a2 zoom in view of fig 1 x 0 05 and y 0 05 comparison of first order and total order sensitivity indices of sobol for daycent output of grain yield of maize from three treatments treatments were irrigated continuous maize icm irrigated maize soybean ims and rainfed maize soybean rms the numerical values are references to parameters in table 2 fig a2 fig a3 simulated and measured soil water content swc of the rms treatment in 2003 the over estimation of swc at 50 and 100 cm resulted in the overestimation of biomass and yield in fig 6 for the rms treatment fig a3 
26048,we present hydroman a flexible spatially explicit model coupling human and hydrological processes to explore shallow water tables and land cover interactions in flat agricultural landscapes modeled after the argentine pampas with fewer parameters hydroman aligned well with established hydrological models and was validated with observed water table patterns and crop yield data simulations with different climate phreatic and land cover conditions confirmed that climate remains the main driver but crops also influence water levels and yields depending on the growing cycle we also examined the impacts of two alternative sowing strategies risk aversion proves robust in minimizing crop losses but often results in less sowing exacerbating flooding strict rotators risk more but help stabilize the groundwater levels reintroducing pasture further stabilizes the system future work will engage farmers to derive and assess land cover strategies that maximize yield and minimize losses and transfer our modeling approach to other applications keywords natural human systems modeling rural decision making water table water risk management pampas 1 introduction in rainfed agricultural systems groundwater affects agricultural productivity and ultimately farmers land cover decisions if the water table is too deep groundwater cannot be reached by crop roots so that crop growth depends mostly on rainfall crops yields grow exponentially as the water table approaches the root zone enabling capillary water supply from the saturated zone kang et al 2001 nosetto et al 2009 when the water table lies at this optimum depth groundwater can supply most of the crop s water requirements mainly in dry years however crop yields fall sharply as water table levels continue to increase creating saturated conditions within the crops root zone mueller et al 2005 nosetto et al 2009 flat landscapes with humid climates like the argentine pampas the carpathian basin or the great plains of western canada are particularly vulnerable to flooding because the water table tends to oscillate close to the soil surface fan et al 2013 jobbágy and jackson 2004 as a consequence these areas may be waterlogged for prolonged periods not only reducing crop yields but also affecting available land machinery use and transport logistics aragón et al 2011 viglizzo et al 2009 in such landscapes regional horizontal water flows are relatively limited also due to low soil hydraulic conductivity while vertical water inputs and outputs dominate the water balance mercau et al 2016 thus groundwater levels in flat landscapes mainly follow rainfall variability portela et al 2009 and the main water outputs are plant consumption and soil evaporation which are in turn influenced by land cover decisions nosetto et al 2012 the magnitude and timing of evapotranspiration together with root depth and waterlogging tolerance vary among crops for instance pastures which grow during the whole year and have a deeper root system may consume almost twice the water used by annual cash crops like soybean which occupy the field only part of the year 4 5 months nosetto et al 2009 2015 farmers agronomical practices may also affect groundwater dynamics like no tillage cropping that leave the soil undisturbed and covered with stubble to reduce soil evaporation sinclair et al 2007 in other words farmers decisions introduce a reciprocal relationship with water table dynamics and they are both influenced by climate variability the effects of land cover on groundwater could encourage farmers to make cropping decisions to keep the water table level in the sweet zone nosetto et al 2012 i e between 1 5 and 2 5 m from the soil surface nosetto et al 2009 achieving this is not straightforward however first farmers make land cover decisions within their plots while water flows through property lines heterogeneous land covers across a landscape may trigger horizontal groundwater flows introducing interdependency among farmers sharing the same phreatic aquifer garcía et al 2017 therefore water table depth at the farm level depends not only on the farmer s land cover decisions but also on the decisions of the neighboring farmers second the amount of rain during the cropping cycle one of the main drivers of groundwater dynamics is highly uncertain and variable which translates into greater uncertainty for farmers regarding the impacts of their land cover decisions mercau et al 2016 understanding linkages between climate variability groundwater dynamics and land cover decisions is central to the sustainability of coupled water and agriculture systems water for food production exceeds all other water needs and water also drives several important ecosystem functions the proposal of managing water table depth to enhance the sustainability of water and agriculture should be based on a deep understanding and assessment of these linkages from the individual farm level through the landscape level gleeson et al 2012 rosegrant et al 2009 wada et al 2010 existing models are difficult to use for this purpose they tend to be either too simple or too complicated which makes them unsuitable to test a wide range of scenarios and include the explicit representation of decision making guarda is an example of a simple spreadsheet based model used to make site specific estimates of agricultural soil water content mercau and jobbágy 2013 in its current form it does not allow for the representation of the spatial context and cross scale interactions on the other extreme detailed process based and spatially explicit models are data intensive and are costly to calibrate and parameterize mike she was created to provide a wide range of customizable water mass balance outputs for nearly all types of hydrology refsgaard and storm 1995 refsgaard et al 2010 given its underlying computational complexity the number of time steps is limited to 800 calibration is extensive and recommended resolution is low to ensure that simulations can be completed within reasonable time frames hydrus was developed to analyze movements of water heat and solutes in porous media and is available in versions that are either two or three dimensional šimůnek et al 2005 time steps may be as small as 1 s which together with a hexahedral geometry yields higher precision results precision comes at the expense of flexibility in scenario testing and parameterization however which limits its applicability and slows downs simulations while originally developed to model groundwater flow modflow now includes several modules that simulate additional processes langevin et al 2018 modflow is a data intensive numerical model but the modularity of the model can make it easier to run faster simulations than with other process based models if fewer outputs are desired surface water flows are harder to simulate in modflow however drainmod dssat seeks to optimize drainage in agricultural soils assuming surface and sub surface drainage infrastructure and not lateral groundwater flow skaggs 1978 negm et al 2014 outputs include water mass balance data and crop yields this model was not intended for conditions other than humid climates slight slopes and the presence of drainage networks however while the above models are extensively used they do not explicitly consider the human dimension although some cases exist of coupling these sophisticated hydrological models to human decision making e g garcía et al 2019 reeves and zellner 2010 zellner and reeves 2010 these efforts take considerable amount of time and funding to both develop and run our aim was to develop a simpler and more agile spatially explicit platform that recreates enough of both the hydrological and social complexity of flatland agricultural systems to rapidly explore the effects of a wide range of climate and decision making scenarios castilla rho et al 2015 zellner 2007 such a platform would also be more useful to stakeholders and decision makers to explore the unintended consequences of their individual and collective decisions this paper has two main objectives first we describe our model which we called hydroman hydrology human and validate it against other established hydrological models and field data to assess its capability to reproduce primary patterns in hydrological processes second we introduce land cover decision making processes to understand and assess interactions between climate land cover and groundwater dynamics in agricultural systems of the argentine pampas the last section builds on this understanding to explore joint land and water management implications 1 1 case study our work targets the area of the salado a basin a part of the río de la plata hydrographic system and specifically a site in pehuajo fig 1 this salado basin is in the argentine pampas a key agricultural area for global food security calviño and monzon 2009 hall et al 1992 the pampas is one of the flattest areas in the world with regional slopes of less than 0 1 jobbágy et al 2008 and also show a strong climate variability on inter annual goddard et al 2001 to inter decadal scales boulanger et al 2005 rusticucci and penalba 2000 as a result of its flat topography and significant climate variability floods and droughts have been reported in the salado basin since colonial times given that the majority of agricultural production in the salado a basin is rainfed productivity of annual crops is strongly affected by rainfall and water table variations nosetto et al 2009 podestá et al 1999 since the 1970s the pampas showed a steady increase in late spring and summer rains particularly near the western boundaries berbery et al 2006 in the same period there was a transition from grasslands and pastures to annual grain crops mainly soybean paruelo et al 2005 viglizzo et al 2011 this land cover change emerged from individual farmers land cover decisions bert et al 2014 as result of higher precipitations and a dominance of annual crops that consume less water than perennial pastures and grasslands water table levels have risen nosetto et al 2015 viglizzo et al 2009 much uncertainty remains regarding the projected paths of future climate land cover and technological change in the pampas and there is growing concern among farmers and policy makers about potential effects on groundwater levels particularly on the risk of flooding in the salado a basin in particular there is an increasing need to understand how management practices can help prevent flooding while maintaining water table at depths that reduce the impacts of droughts garcía et al 2019 we developed hydroman to understand and provide insights regarding these questions in the hope that this may be relevant to similar agricultural regions in the world 2 model components and processes 2 1 model overview hydroman simulates the main hydrological processes relevant to our questions land cover decisions precipitation evapotranspiration and both surface and subsurface water flow the model tracks the water contents and depths in the soil horizons groundwater capillary upper and root zones as well as on the surface further the model also keeps track of crop yields as they are affected by water availability in contrast to other models each 40 year run takes 2 3 min in a 2 8 ghz processor laptop 2 2 landscape the landscape is represented as a square grid with the size of lattice determined by the user depending on the scenario chosen in all of the experiments completed for this publication the size of each cell was 1 ha 100 m 100 m but the size can be adjusted by the user boundary conditions can be set to be open where cells at the edge of the domain maintain a constant groundwater head during groundwater flow or can be set to be closed assuming that the landscape acts as a self contained basin and no water can flow in or out through the edges while this choice is left to the user to adapt boundary conditions to specific landscape representation size and resolution this must be thoroughly tested to understand how edge effects may influence results 2 2 1 land cover each cell of the simulated landscape can have one of seven different land cover options throughout a year pasture maize a cover crop of minimal economic value wheat regular soybean short cycle soybean and fallow no crop sowing decisions during a simulation determine the land cover at any point during a year for each cell section 2 3 4 in some scenarios the land cover may change during a year or between years section 4 2 each land cover type has unique daily values for water need for transpiration k cb the basal crop coefficient 1 1 the basal crop coefficient kcb is defined as the ratio of the crop evapotranspiration over the reference evapotranspiration etc eto for more details see allen r g pereira l s raes d smith m 1998 crop evapotranspiration guidelines for computing crop water requirements fao irrigation and drainage paper no 56 fao rome italy and rooting depth and critical growing periods when partial unmet water need directly affects yields fig 2 both k cb and root depth dynamics were built based on crop simulations carried out with dssat decision support system for agrotechnology transfer models jones et al 2003 literature values allen et al 1998 satorre et al 2003 and expert knowledge the critical growth periods for soybean maize and wheat yields are linked to a short period of high water demand a window of time spanning 30 days before and after the day with the maximum k cb during a cycle in contrast pasture and cover crops are assumed to have critical demand for water every day they are alive they produce biomass rather than a commercial product meaning that unmet water demand for the entire crop cycle affects their yields soybean maize wheat and cover crops were assumed to be able to tolerate only seven consecutive days it can be adjusted by the user between 0 and 10 days without any water before dying whereas pasture is more resilient and will never fully die once sown sheaffer et al 1988 2 2 2 elevation and slope given the little variation in ground elevation characteristic of the argentine pampas slopes can be set with a slider or an import file with values for each cell the former option produces a stylized landscape that is useful for model verification but the latter option can apply elevations from digital elevation models which is useful for model validation and scenario testing elevation is in absolute meters above sea level 2 2 3 soil horizons the soil reaches a total depth of 100 m in all cells soil is divided into four separate zones as described in the following sections fig 3 and is assumed to have three pore sizes small medium and large the small pores are assumed to be always saturated but their water is unavailable for flow or evapotranspiration due to surface tension matrix potential the large free draining pores are assumed to be always empty because of gravitational force unless located in the groundwater zone where they are saturated medium pores can show different degrees of saturation due to infiltration evapotranspiration or water transfers between horizons due to changes in the groundwater levels the proportion of small medium and large pores in the soil is set by the user in all of the experiments completed for this publication medium and large pores occupied 12 and 19 of soil volume respectively which would correspond to the typical sandy loam soil of the region the soil horizons are dynamic and their depths change as roots grow and groundwater flows horizontally and vertically groundwater zone the groundwater zone makes up the deepest and largest portion of the soil column both the large and medium pores are fully saturated and water can flow horizontally between cells if there are differences in hydraulic heads section 2 3 3 soil in this zone is devoid of oxygen so any portion of plant roots that reach into this zone will die capillary zone for the typical soil type of the study region i e sandy loam mollisol this was set as the 0 8 m above the top of the groundwater zone its medium pores remain fully saturated due to capillary action that draws water from the groundwater zone plants can safely draw water from this zone root zone this is the top horizon the root zone is any part of the soil column above the capillary zone into which the plant s roots grow at a minimum the root zone is assumed to be 0 3 m in depth limited by available soil column above the capillary zone whether roots occupy that space or not to represent the greater influence of evaporation close to the soil surface plants can draw water from the medium pores in the root zone for transpiration upper zone this is any soil column between the capillary and root zones to account for water that may be stored in the soil this water will be available for transpiration as the root grows and expands the root zone into the upper zone or will add to the groundwater as the water table rises into the upper zone 2 3 processes and order of events hydroman represents daily cropping and hydrological processes that are most relevant to our research questions the processes run in the following order fig 4 1 precipitation runoff and infiltration 2 surface flow 3 groundwater flow 4 sowing decisions 5 plant growth 6 evapotranspiration and 7 harvesting additionally soil horizons adjust after every change in hydraulic head or root length in any of these processes 2 3 1 precipitation runoff and infiltration the model uses daily precipitation amounts from input files that can represent either hypothetical or observed data over a number of years each day the model reads the daily precipitation from the file and this value is applied to each cell as follows hydroman assumes a fixed percentage which can be set by the user of the amount will be runoff and the rest immediately infiltrates where it falls in all of the experiments completed for this publication runoff was set at 30 a reasonable value for this type of soil mercau pers comm the rain that infiltrates first fills unsaturated volume in the medium pores of the root zone if there is not enough room in the root zone for all the water the remaining rainwater fills up the medium pores of the upper zone any further remaining water is added to the groundwater zone since the medium pores of the capillary zone are by definition already saturated in this case the groundwater level rises by an amount that depends on the amount of water transferred and the specific yield of the soil if there is not enough room in the medium or large pores in the soil for water that is infiltrating then the water that cannot infiltrate stays on the surface and is added to the fixed runoff amount the soil horizons are adjusted to reflect the change in the groundwater table section 2 3 8 2 3 2 surface flow each iteration water flows from a high hydraulic head to a low hydraulic head to do this cells are sorted in ascending order of elevation and sequentially interact with each one of its upstream neighbors to exchange water also in ascending order of elevation during the interaction the cell determines the difference in hydraulic heads between itself and the neighbor with which it is interacting then this difference in hydraulic head is divided in half to estimate the water flow between the cell and its neighbor needed to reach equilibrium if the neighbor s head is higher water flows into the cell constrained by the amount of the neighbor s water if the reverse is true water flows out to the neighbor constrained by the amount of water in the originating cell this setup results in asynchronous updating of water levels where each pair of cells is updated one at a time rather than all simultaneously since iterations are one day in length and surface water under normal conditions can be expected to reach an equilibrium level by the end of a day this removes the need for a more intensive surface flow algorithm that accounts for factors including surface roughness velocity or routing 2 3 3 groundwater flow the process for groundwater flow in this model builds on a previous implementation of darcy s law of flow zellner 2007 zellner et al 2012 each time step cells asynchronously exchange water with each of their neighbors first the flow volume is calculated according to equation 1 1 q k e l d δ h where q volume of flow in m3 per day k hydraulic conductivity per day e l large pore specific yield i e porosity d aquifer depth in the cell in m δh difference in hydraulic heads between the cell and its neighbor in m the water is transferred and cells update their water table depths based on the content of water added or subtracted if the top of the groundwater zone is at the surface the height of the surface water column is added to the hydraulic head to calculate flow and transfer after all cells have finished transferring water the model adjusts the soil horizons of the zones that are above the groundwater including surface water if the water table reaches the surface for the cells whose groundwater level changed section 2 3 8 2 3 4 sowing decisions sowing decisions are determined exogenously by the user and are taken at the start of a new cropping cycle may 1 or day 0 unless the crop begins growth on the first day pasture or cover crops are sown seven days before its k cb is first greater than 0 which happens when the plant starts growing and transpiring when sowing happens root growth root damage by flooding and yield variables for the cell are reset pasture does not reset root damage because it is assumed that it never truly dies or gets sown anew it is a perennial crop while the over crops are annual after an initial set of sensitivity tests section 3 we modified the model to include adaptive risk averse farming strategies determined endogenously based on the water table depth at different times during the cycle and the crop rotation schedule these will be explained in more detail in section 4 2 2 3 5 plant growth every crop has unique daily root lengths corresponding to the time in its cropping cycle as determined by the input file fig 2 each day a first check for prior root damage due to contact with the water table is performed in cells with live crops i e not yet harvested and with positive water demand for transpiration if undamaged the root length of each cell is updated according to the input file if by doing so the roots enter the groundwater zone the root length only grows up to the water table depth the part of the root within the groundwater zone dies due to hypoxia and is marked as damaged if the roots were previously damaged they may grow back depending on the crop type and available space above the water table for all crops except pasture damaged roots regrow the amount corresponding to the growth for that day since pasture s root length is held constant throughout the year they are set to regrow 1 of the root length when they are damaged up to the length of an undamaged root the cells will later use the new root lengths to update their root and upper zones section 2 3 8 2 3 6 evapotranspiration soil evaporation and crop transpiration are directly linked to daily reference evapotranspiration et o potential crop evapotranspiration et c is a function of the crop s demand for water i e k cb and et o equation 2 and soil evaporation e is simply the difference between et o and t for the crop equation 3 this means that on a given day if t is high when the crop is at a critical stage and leaf coverage is maximized then e will be low because the soil will be shaded by the foliage allen et al 1998 2 e t c e t 0 k c b i where et c potential evapotranspiration i e the daily water needs for crop i in m per unit area et 0 daily reference evapotranspiration in m per unit area k cbi the basal coefficient for crop i 3 e i e t 0 t i where e i daily soil evaporation in m per unit area et 0 daily reference evapotranspiration in m per unit area t i transpiration for crop i in meters per unit area first the model computes the daily water need for each crop type equation 2 daily water need i e et c for each cell is updated based on its cover or set to zero when fallow the soil zone from which water will be drawn for transpiration is determined by considering the proportion of roots located in the root and capillary zones then the actual amount of water that is available is computed assuming that at most 10 of water that is reachable is available for transpiration at each time step dardanelli et al 1997 next plants are allowed to draw water from the two zones sequentially starting with the root zone and corresponding to the shares as computed above if after withdrawing water from the root zone there is still unmet need and any of its roots are in the capillary zone then the plant will continue to withdraw any unmet need from the capillary zone any deficit in daily water need i e whatever need remains unmet is recorded equation 4 taking a value between 0 and 1 where 0 is completely met and 1 is completely unmet water need and the cumulative percent unmet demand for the critical growth period in the current growing cycle is calculated and then averaged over the critical period a counter keeps track of the number of consecutive days in which no water has been withdrawn by the crop if the counter reaches 7 consecutive days and the crop is anything except pasture the plant dies the root length is set to 0 and both root and upper zones adjust accordingly section 2 3 8 finally the total daily transpiration amount from both zones is recorded 4 u w i t w d c g p i t w n c g p i where uw i daily unmet water need for crop i 0 1 twd cgp daily water deficit during the critical growth period for crop i twn cgp daily water need during the critical growth period for crop i the cell s daily potential soil evaporation e i is now determined equation 3 when groundwater is at the ground surface e i is increased by 20 due to water being more readily available to evaporate from either the surface or the groundwater itself if there is surface water the e i amount is first subtracted from the surface water column if there is still remaining e i after all surface water evaporates the evaporating water will be withdrawn from the groundwater at the same increased rate if the capillary zone is at the surface then e i will be subtracted from the groundwater but at the base rate in the case where neither groundwater or capillary zones are at the surface evaporating water will be withdrawn from the root zone the upper zone by definition will always be too far from the surface for water to evaporate from it in this situation the amount of water that will evaporate from this zone depends on the saturation of its medium pores equation 5 5 e r e i θ where e r root zone evaporation amount in height m per unit area e i potential daily soil evaporation in m θ the soil water content of the medium pores in the root zone evaporation only takes water from the first 0 2 m of soil because it is assumed that below this depth direct evaporation is negligible jalota and prihar 1990 schwartz et al 2010 if the root zone s height is less than 0 2 m because the water table is close to the surface any amount of e i not withdrawn from the root zone is removed from the groundwater after the evapotranspiration process if the groundwater zone shrank due to evaporation or transpiration soil horizons are updated section 2 3 8 2 3 7 harvesting there are critical growth periods when the amount of water consumed has a direct relationship on the crop yield at harvest calviño and sadras 2002 calviño et al 2003 during the critical growth period the unmet water needs are recorded equation 4 at harvest day i e the last day that a crop s k cb is greater than 0 a crop yield factor is calculated for each cell based on the average water deficit during the critical period if the plant died before harvest then the unmet demand is assumed to be 100 for that year which will mean there is no yield cumulative unmet daily need and days the length the crop was in critical growth are then reset the model then translates the crop yield factor into crop production based on the potential yield for an area the size of the cell equation 6 since harvest results in plant death the root length is set to 0 at that time which may result in an updating of the horizons for the root and upper zones 6 y i 1 f y p y i where y i the annual yield for crop i on this cell in metric tons f y crop yield factor py i the potential yield or maximum annual tonnage possible for crop i on an area the size of this cell this is the yield when f y 0 py i is defined by users in all of the experiments completed for this publication py i was 5 6 14 5 5 3 5 and 8 tn ha 1 for cover wheat maize soybean short soybean and pasture respectively 2 3 8 updating horizons soil horizons are updated whenever there is a change in groundwater levels or root lengths groundwater rises groundwater levels can rise only due to infiltration or groundwater flow when this happens the capillary root and upper zones need to be adjusted the new sizing of the zones follows the rules outlined in section 2 2 3 soil that was previously in upper or even root zones may now be in the groundwater or capillary zones thus the amount of water in the upper and root zones will decrease if the size of the zones decrease but the overall saturation of the medium pores in the root and upper zones will remain unchanged groundwater falls groundwater levels can fall only due to groundwater flow or evapotranspiration if the groundwater levels fall the horizon for the capillary zone will change and the upper and perhaps root zones will increase following the sizing rules outlined in section 2 2 3 any new soil in the root or upper zones is assumed to have fully saturated medium pores since it was previously in the groundwater or capillary zones the cells with receding water table receive water left behind in the appropriate zone as groundwater levels drop and the result will be a net increase in saturation of the medium pores in the zones if not previously fully saturated root length changes plant growth and death may lead to a change in the root and upper zones the capillary zone horizon is unaffected by changes in root lengths after plants adjust their root lengths the root and upper zones will adjust following the rules outlined in section 2 2 3 since we assume uniform saturation of soils within a zone any soil that is transferred between the two zones will bring along water the new amounts of water in a new zone are calculated based on the size of change to a zone and previous saturation levels appendix a 3 model verification and validation to ensure that the model implementation matched its intended design we followed three complementary verification procedures throughout model development first the team performed a code walk through in which the lead programmer explained the functionality of each line of the code this process ensured that all design concepts and specifications were correctly mapped onto the code second we conducted independent verification by running portions of the whole model algorithm in a spreadsheet checking intermediate and final outcomes e g water table depth for a specific cell and date this procedure although time consuming was very effective in identifying conceptual and numerical errors as it allowed us to compare simulation results with results from an independent system finally we ran simplified but realistic scenarios to ensure that key outcomes variables had reasonable values both temporally and spatially we also examined how well hydroman recreated both micro and macro level patterns of water table depth over time and in space i e validation railsback and grimm 2012 first we consulted with literature and expert hydrologists to ensure that hydrological processes were adequately conceptualized and implemented in our model our second approach involved docking our model with other existing hydrological models that have been applied in the area of study to see to what extent the water levels in time and space matched the ones simulated by other models once we established the adequacy of the model relative to existing modeling tools we finally contrasted site specific simulation results to observed ground and surface water records in that location the validation process is described in more detail below 3 1 conceptual validation with expert hydrologists hydroman involves universal and well known hydrological processes the initial design of those processes was based on established work in hydrological modeling menendez and garcía 2014 mercau and jobbágy 2013 the main contribution of the experts was a to determine which hydrological processes should be included b to decide the level of detail in which each process should be represented and c to simplify some key processes e g soil evaporation and runoff the involvement of local experts allowed us to keep the model simplified but relevant to its purpose 3 2 hydrological model docking as a second validation technique we aligned scenarios in hydroman to match those in alternative established hydrological models previously used in the region the goal of this docking exercise was to assess the extent to which hydroman is able to reproduce temporal and spatial patterns of groundwater levels of other models nosetto et al 2015 first we performed simulations to assess the temporal dynamics of groundwater levels in one point in the space to this end we compared outputs from hydroman with hydrus 1d šimůnek et al 2005 and guarda mercau and jobbágy 2013 2 2 hydrus 1d pc progress is a public domain windows based modeling environment for analysis of water flow and solute transport in variably saturated porous media guarda is a simplified excel based water budget model developed by mercau and jobbágy as a practical tool to simulate soil water content and groundwater depth in agricultural soils we also performed simulations to assess the spatial dynamics of groundwater in a two dimensional space comparing outputs from hydroman with mike she 3 3 mike she is a deterministic spatially distributed physically based numerical model which couples surface and groundwater flows refsgaard and storm 1995 refsgaard et al 2010 details of this validation exercise and its results can be found in appendix b overall we observed a high degree of matching between hydroman and both 1d and 2d models we were also able to identify specific sources of discrepancies across models such as the infiltration and crop transpiration used in different models and adjust hydroman parameters accordingly 3 3 validation against observed hydrological data this assessment involved the simulation of a plot in a farm located in pehuajó buenos aires province argentina we obtained monthly groundwater depth records from may 2008 to may 2013 for a 50 ha plot in this farm fig 5 characterized by uneven topography and three wells located at different topographic positions of the plot table 1 the simulation aimed to recreate the groundwater dynamics at those three points during the same period hydroman was set and initialized to represent as precisely as possible the plot conditions in terms of topography soil characteristics and initial water table depth a land surface digital elevation model dem based on the shuttle radar topographic mission srtm was produced to represent the plot topography a landscape with 7 7 cells of 1 ha each was created and the elevation of each cell was defined based on the dem the dem based landscape roughly reproduced the topography of the plot as confirmed by field observations soil related parameter values for a typical soil in pehuajó were assumed and the initial water table depth at each of the observation wells was set based on records for may 2008 the sequence of land covers for the plot was also obtained starting with cropping season 2008 09 data from the weather station of the national meteorological service smn in pehuajó was used as weather input hydroman was able to closely reproduce three observed structural groundwater dynamics over time fig 6 the model accurately reproduced the magnitude of water table depth and the dynamics of groundwater at the three points monitored including the significant increase towards the end of the simulated time period leading to flooding in the intermediate and lowest land the model was able also to capture the relative differences in groundwater level between topographic positions the model could only reproduce these patterns under closed boundary conditions that reduced the edge effects of an open fixed boundary on a small landscape the latter introduce an artificially high supply of water that overrides any water table changes produced by the small simulated landscape although hydroman reproduced the main patterns some second order differences both under and over estimations are noticeable between observed and simulated water table levels the main differences are observed during winter spring 2009 at the three topographic positions and towards the end of the simulation where hydroman tended to simulate higher water levels we analyzed several factors that may be the source of that discrepancy among the most important we included a possible spatial heterogeneity in precipitations as the simulation used data from a weather station 18 km away from the simulated farm b disruption in monitoring due to a maintenance of the wells conducted during autumn 2009 which may have led to erroneous readings in the following winter and or c possible influence of groundwater levels surrounding this plot while we assumed a closed boundary between this plot and adjacent areas to reduce edge effects this is actually an open boundary which may have contributed with incoming or outgoing flows hydroman reproduced the crop yields registered in the pehuajó plot in the simulated period with an acceptable precision fig 7 the normalized root mean square error for all crops and cropping cycle was 18 this is a reasonable error considering the model s parsimony the few data points against which simulation outputs are compared and the short time frame for the validation 5 crop rotation years more sophisticated models like dssat and apsim show similar results when applied to the pampas region garcía et al 2018 guevara et al 1999 mercau et al 2007 mercau and otegui 2014 differences between observed and simulated yield were smaller for wheat maize and soybean crops hydroman s performance was poorer only in the case of short cycle soybean overestimating yield for the two cropping cycles simulated reasons for this discrepancy may include weather extremes or biotics constraints there was a drought in 2008 09 and heavy rains in 2011 12 which might have affected the later part of the sowing cycle in addition later summer crops in the pampas usually find better water conditions during their critical periods than earlier crops however solar radiation levels decrease at that time making this the main constraint on crop yield since hydroman does not simulate crop yield based on radiation the better water conditions result in an over estimation of simulated yield additionally there may have been a range of disruptions in the field that led to lower yield data the validation exercise above provided enough evidence that hydroman could recreate temporal and spatial dynamics of water table consistent with those from other models and observed data while identifying the specific sources of discrepancy at this point we turned to using hydroman to explore the questions of land cover climate and water table interactions 4 understanding the influence of climate and land cover decisions on groundwater dynamics our goal was to use hydroman to identify practices that may help to manage groundwater levels contributing to a balance between preventing flooding and drought accordingly we designed two sets of simulations around the following questions i how do different land cover scenarios influence water table depth ii how can adaptive land cover strategies prevent extreme water table levels 4 1 effect of land cover scenarios on groundwater dynamics we seek to assess the effect of various land covers each with different water consumption capacities on groundwater dynamics and levels we ran six land cover scenarios that included the typical options in the study area a pasture b soybean c cover crop followed by soybean d maize e wheat followed by short cycle soybean and f fallow no crop land cover was the same all across the landscape and was maintained constant throughout the simulation period two sets of weather data were used to assess the interactions between land cover and climate a three sequences each of them generated by repeating 40 times a dry 2008 09 542 mm average 1980 81 1024 mm and wet 1986 87 1306 mm agricultural cycle and b the historical weather records for pehuajó 1971 2010 further two initial contrasting but realistic groundwater levels were simulated 2 and 5 m to understand the influence of initial water table conditions and system behaviour towards a dynamic equilibrium as a result we ran 48 scenarios 6 land covers under 4 climate sequences with 2 initial groundwater levels all scenarios assumed a completely flat landscape encompassing 11 11 1 ha cells for simplification purposes groundwater level was strongly affected by the land cover fig 8 from deeper to shallower simulated groundwater the general order was pasture deepest water table depth cover soybean wheat soybean maize soybean and fallow shallowest water table depth the deeper roots 3 5 m vs 1 8 2 m and the uninterrupted water consumption of pasture throughout the year led to the lowest groundwater levels in relation to the rest of the crops among double crops higher water consumption during the whole agricultural cycle is evidenced when a cover crop is sown during winter compared to a harvest crop i e wheat the cover has an earlier plot release that allows earlier sowing and establishment of the soybean crop that follows explaining the water consumption differences when soybean is sown after wheat that delay in evapotranspiration reduces its water withdrawal andrade et al 2015 the wheat soybean double crop also has little water consumption during the transition between crops low canopy and root size in early summer when high atmospheric evaporative demand occurs mercau et al 2016 comparison between single crops showed groundwater levels a little deeper with maize than soybean as land cover due to the earlier establishment and water consumption of the former during spring maize is sown approximately one month before soybean the effect of land cover on groundwater dynamics heavily depended on climate scenarios and initial conditions mostly within the first 5 to 10 simulated years until the water table reached a long term dynamic equilibrium for most land covers fig 8 larger differences among land covers were observed under average climate conditions with groundwater level tending to rise at different rates except with pasture which stabilized the water table at levels similar to dry conditions dry climate favored groundwater stabilization at lower depths in all land covers rising only with fallow under wet conditions groundwater tended to rise in all land covers initial water table depth can magnify the climate impact on groundwater dynamics at the beginning of each simulation period further reducing differences among land covers in the extremes i e dry weather and deep water table and wet weather with shallow water table the middle conditions i e dry weather and shallow water table average weather and wet weather with deep water table support more distinctive behaviors across land covers during the initial simulation period these differences however disappear over time in average and wet climates crop yields varied according to the climate scenario and the dynamics of groundwater table 2 initial water table depth did not influence the outcomes beyond the spin up period and results were averaged between both conditions under average climatic conditions the relative yields of all land covers were closest to the maximum showing the most favorable conditions for all crops except soybean and soybean after cover the average scenario still introduces significant amounts of precipitation at a time that hurts the crop although groundwater dynamics under maize seems very similar to soybean on average 0 1 m deeper for maize maize yield was high because the water table was deeper than 0 5 m during the critical crop stages under the sequence of wet years the excess water decreased root functionality no matter the land cover leading to extensive losses for all crops yields for most crops were also reduced under the sequence of dry years although not to the same extent as with flooding especially for crops with low water demand e g wheat soybean was the most affected crop by both wet and average climate while the others proved more robust to the range of scenarios tested these patterns align in general with those reported by florio et al 2015 mercau et al 2016 nosetto et al 2015 the results using historical climate suggest not only an interaction between land covers and total precipitation but also among the temporal rain distribution and cover water consumption pattern considering the last 20 simulated years where the initial conditions no longer influence the groundwater dynamics the effect of water shortages or flooding determined by the actual climate variability was similar for all crops resulting in relative yields of around 80 pasture had higher values and wheat and full cycle soybean the lower ones table 2 the deepest groundwater levels were observed for pasture and the shallowest for fallow with cover soybean and soybean as the deepest and shallowest respectively among the grain crops groundwater dynamics both under wheat soybean and maize had an intermediate behaviour the differences described between those land covers in stylized scenarios fig 8 are less noticeable under the historical climate series after the first few years of simulation fig 9 larger differences are observed among land covers with a deeper initial level 5 m but only during the first half of the simulated period before the system reaches a dynamic equilibrium temporal variations in climate may be introducing a time lag in which crops can catch up with water uptake maintaining overall levels below and disconnected from the surface except where there are consecutive wet years overall however cover soybean is better able to maintain the water table depth at more manageable levels than other land covers a lower evapotranspiration from land cover change i e the observed shift from mixed crop cattle systems to continuous agriculture together with increased rainfall have contributed to increase groundwater recharge in the pampas mainly in the area of study favoring the rise of water tables aragón et al 2011 viglizzo et al 2009 although the simulations did not have this aim the scenario with an initial water table depth of 5 m reproduced the observed groundwater patterns in the region under agricultural land covers groundwater levels tended to increase modulated by rainfall conditions conversely groundwater levels stayed at deeper levels under pasture increasing only 1 m along the 40 years of the simulation 4 2 effect of adaptive land cover strategies farmers have expressed interest in developing strategies to adapt to climate and water table variations arora et al 2016 we extended hydroman to represent possible adaptive strategies and to understand their effect on groundwater dynamics and risks of waterlogging on crop production to do this we compare scenarios in which the farmers either do not consider non adaptation or consider adaptation water table depth to select their land cover allocation the non adaptive strategy is characterized by a farmer who strictly followed the typical crop rotation scheme for the study area regardless of the groundwater level i e a strict rotator adaptive strategy on the other hand is characterized by farmers who decide the land cover at the beginning and throughout the cropping cycle depending on groundwater levels regarding their reference thresholds fig 10 the default rotation sequence which is adopted by the strict rotator non adaptive strategy is maize year 1 full cycle soybean year 2 and wheat or cover crop followed by soybean short or full cycle soybean respectively year 3 adaptive farmers would deviate from this sequence depending on water table depth at the moment of sowing decisions the rationale behind the adaptive strategy represented in the model is that the farmer may introduce a high consumption cover to lower water table levels under threatening waterlogging conditions groundwater thresholds assumed by farmers correspond to the lower limit of optimal depth range for highest yield for wheat maize and soybean 0 7 1 4 and 1 2 m respectively nosetto et al 2009 thus on may 1 day 0 of each year during a simulation if a the water table depth is between the shallow and deep thresholds or b it is year 3 in the rotation and the depth to the water table is greater than the shallow thresholds wheat will be sown if it wasn t sown the previous year otherwise cover crop will be sown assuming farmers would allow soil recovery by rotating crops the farmer will recheck the water table depth on december 13 after sowing wheat or on october 24 after sowing cover crop to determine if a subsequent sowing happens however if conditions a or b above are not met the farmer will not sow in may and will recheck the water table on september 18 if it is year 1 in the crop rotation corresponding to the sowing of maize or on october 24 any other year if marked to recheck the water table depth on september 18 and on that day the water table depth is deeper than the threshold the farmer will sow maize and advance the rotation year if shallower than the threshold the farmer will recheck on october 24 by that date those farmers marked to check the water table depth will sow full cycle soybean if the water table is deeper than the threshold also if it is year 2 of the rotation or year 3 of the rotation and a cover crop was sown on may 1 the rotation year advances if the water table was not deep enough to allow any crop sowing in october the farmer will check again the water table depth on december 13 on december 13 the final opportunity to check the water table during a cropping cycle if the water table is deeper than the threshold short cycle soybean will be sown if it is year 3 of the rotation and either wheat or cover had been sown on may 1 the rotation year is reset to year 1 if the water table was shallower than the threshold on this day the land will remain fallow the famer decisions are all represented at the cell level the experiment included the two decision strategies described above adopted in two landscapes a completely flat stylized landscape and the plot from pehuajó used for model validation section 3 3 the landscape encompasses 7 7 cells of 1 ha each in both cases always under the historical weather records 1971 2010 from the pehuajó weather station and starting in an initial groundwater level of 2 m additionally two precision levels in the water table depth readings were adopted to guide land cover decisions in the pehuajó landscape low sowing decisions in each cell are based on groundwater levels from a single cell in the entire plot or high decisions are based on groundwater levels in each cell in the plot in the low precision level all the cells in the plot will have the same land cover while in the high precision level each cell will have a land cover according to its groundwater level the water table depth results suggest several trends fig 11 the bimodal distribution in water table depth is in line with theoretical discussions in our broader research team prompted by field observations there are essentially two basins of attraction for the water table represented in the two peaks in the distribution of the pehuajó landscape the depth of these two basins depends heavily on the crop s root length and transpiration rates under normal or dry conditions transpiration depresses the water table only as much as its root length allows water levels will rise with precipitation but transpiration will keep them in that basin when a wet period causes a significant rise in the water table and consumption cannot keep up the roots are killed due to anoxia decreasing the capacity of the plant to transpire and exacerbating the water table rise once it reaches the surface direct evaporation takes over operating at greater rates to compensate for rising water levels this then becomes the second basin of attraction in contrast with the pehuajó landscape a flat landscape minimizes the lateral flows afforded by heterogeneous elevations increasing the sensitivity to different root lengths among the sowing strategies adaptation is better able to maintain the water table at lower depths than strict rotation when the landscape is flat i e cells have complete information about the landscape widespread sowing of specific crops that affect the water table depth can have a substantial impact on keeping the water table at desirable levels even when climate is unfavorable at the other extreme when cells make decisions on one point in a heterogeneous landscape adaptation is worse than strict rotation that is for adaptation to be successful it must rely on appropriate levels of information otherwise the wrong crops will be sown in the wrong places initial sensitivity tests on water table depth thresholds showed that adaptation matters more than the details of its implementation and is a robust strategy when information is available to maintain the water table at acceptable levels in heterogeneous landscapes and more decentralized decision making i e when each cell decides its own sowing we see virtually the same outcomes between adaptation and strict rotation fig 11 this suggests that the temporal variability brought about by strict rotation can partially compensate for the fluctuations in water table depth that each cell experiences adaptation can compensate for spatial differences over a single time period by adapting to geographic differences in water table depths at one time strict rotation on the other hand can compensate for differences in water table depth across time periods so that a water demanding crop can help address high water tables left over by less water demanding crops overall adaptation seems to be a robust strategy to follow in homogeneous landscapes but precision agriculture might be important in ensuring its success in more heterogeneous landscapes adaptive strategies may end up with more instances of fallow cover in heterogeneous landscapes with low information levels exacerbating flooding table 3 this effect could be countered if instead of leaving land fallow flood resistant crops were sowed strict rotators do not allow their land to go fallow non crop and thus may better maintain the water levels below the surface although exposing themselves to more losses due to flooding in relation to crop yields simulations tend to show that adaptation may still be overall better than strict rotation table 3 particularly when we observe crop losses a pattern emerges of how adaptation provides an advantage over strict rotation risk averse loses fewer crops than strict rotators because strict rotators do not consider water table depth they end up losing more of their crops mostly to flooding although they may also do so to drought they can partially compensate for these losses however by sowing at risk which sometimes may turn out well for them especially when it helps lower water table levels paradoxically by adapting to water table levels adaptive decision makers increasingly avoid sowing and thus exacerbate the flooding problem yields may be higher for the land farmed and losses may be minimized but the areas farmed are much smaller given these results we hypothesized that re introducing pasture to the flat lands might be beneficial in regulating water table depths and thus ensure more successful outcomes particularly since the cost of farming and monitoring water levels at high precision would be unrealistically costly confirming our expectations the inclusion of pasture in the heterogeneous pehuajó landscape improved the performance of the system by increasing crop yields reducing crop losses and stabilizing the water table table 3 and fig 12 introducing as little as 7 random cells of pasture over the 49 14 coverage slightly increased the yield of all strategies and reduced the crop losses moreover less land is left fallow in the adaptive strategies at double that area of pasture 29 coverage yield increased and crop losses were further reduced sowing 21 cells of pasture 43 coverage stabilized the water table depth increasing the benefits for the strict rotator by reducing crop losses and increasing yields to levels similar to the risk averse virtually eliminating the advantage of adaptation and the associated monitoring cost at this point however pasture started occupying half of the lot severely competing for space it is also worth noting that none of these conditions trigger the sowing of maize in the adaptive decision making suggesting that water levels may still be too high for this crop these results imply that a stabilizing longer term strategy that allocates pasture in different spatial arrangements may be worth exploring in more detail relative to the use of flood resistant crops when crises arise 5 implications for agricultural decision making we developed a parsimonious process based dynamic and spatially explicit model called hydroman that considers the main hydrological processes of groundwater and surface water flow as a function of land cover and climate hydroman provides a flexible platform to quickly and easily examine how the human dimension of agriculture sowing decision rules influence both water table levels and crop yields in flat agricultural areas the model was able to reproduce patterns of groundwater levels over time and in space capturing both the micro level complexity as validated by experts in the field and the emerging macro level patterns as validated by alignment with established models and empirical data we used hydroman to understand how climate land cover and water tables interact and with this understanding identify possible strategies for agricultural water management while climate continues to be a main driver in the system the switch from cattle ranching to annual grain crops which use less water than pasture has also influenced the water balance of the region nosetto et al 2012 viglizzo et al 2009 among the land covers examined double crops tend to reduce the now predominant risk of flooding by extending the period of time in which they absorb water however it may be more difficult to plant it in areas that are already waterlogged adaptive strategies offer some relief from flooding but only if implemented with spatial precision with more spatial variability the advantages disappear and even may backfire as sowing is adapting to the wrong information thus increasing the risk of lower yields greater losses and flooding with appropriate information the details of adaptation matter less than the fact that environmental information is being used to make decisions when information is lacking strict rotation may in fact be the better option particularly with increasing landscape heterogeneity in extreme years however adaptation may not be enough to prevent flooding particularly when sowing is avoided to minimize losses which exacerbates the flooding problem policy makers and farmers may wish to consider a partial reversal to pasture strategically locating them in low lying areas in enough coverage to generate more stability in the system hydroman is set up in a way that allows for further development and exploration of management strategies among the ones we seek to explore in future work are rules that account for decision in neighboring plots which poses a coordination problem among actions that can potentially exacerbate or cancel out effects such explorations would allow us for example to develop generalizable recommendations for the allocation amount and spatial location of pasture to reduce flooding risk such decisions however may have different implications for the distribution of benefits and losses of the actors in the system to pursue this work we will work with stakeholders to both develop strategies and to examine them in an iterative participatory modeling process collaborative approaches supported by flexible and parsimonious models like hydroman can support the emergence of new institutions that can increase the adaptive capacity resilience and sustainability of human natural systems beyond the agricultural settings we represent here gray et al 2018 voinov et al 2018 zellner 2008 zellner et al in press zellner et al 2012 software availability name of software hydroman developers dean massey and moira zellner contact information mzellner uic edu hardware required software required netlogo programming languages netlogo license www comses net codebase release 1db4c97d 46f1 42dd 9d62 77bf45f95776 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national science foundation nsf cnh award 1211613 the uic under represented faculty recruitment program co sponsored by the provost and the college of urban planning and public affairs conicet argentina pip 112 201501 00609 anpcyt argentina pict 2014 2790 and 2017 3811 and the inter american institute for global change research iai grant crn 3035 in turn supported by the nsf grant geo 1128040 guillermo garcia held a postdoctoral fellowship from the national scientific and technical research council conicet argentina we greatly appreciate the support of g podestá principal investigator of this grant and early conversations with co investigators p arora b rajagopalan and c macal we are very thankful to e jobbagy j mercau a menéndez and p garcía for their contribution in the conceptual validation of hydroman and s rovere for assistance with r scripts appendix a example calculation of water transfer across soil horizons we illustrate with an example below the calculations that update soil horizons in hydroman and transfer the corresponding water content across horizons as they change in this illustrative example the code updates the root and upper zones after the daily growth of the root 1 calculate the new lower limit of the root zone equation a 1 example i f s t c 0 3 a n d s t c l 10 9 0 3 and 10 9 0 5 where s the elevation of the cell in m t c the depth to the capillary zone in m l the length of the roots in m 1 1 if true equation a 1 1 example b r t 1 s max 0 3 l b r t 1 9 495 10 0 505 where b r t the root zone lower limit at time t in m 1 2 if false equation a 1 2 example b r t 1 t c not applicable 2 determine the size of the change to the root zone equation a 2 example δ c r c r t 1 c r t δ cr 0 005 0 505 0 5 where c r t the height of the root zone soil column at time t in m 3 if there is a change in the root zone 3 1 if the change is positive soil and water content must be transferred from the upper zone to the root zone 3 1 1 determine the water content of the upper zone amount there maximum there equation a 3 1 1 example θ u w u t c u t e m 0 75 0 045 0 5 0 12 where θ u the water content of the medium pores in the upper zone in saturation w u t the height of the water column in the upper zone at time t in m c u t the height of the upper zone soil column at time t in m e m the medium pore specific yield porosity 3 1 2 determine the change to the upper zone s water column equation a 3 1 2 example δ w u δ c r θ u p m 0 00045 0 005 0 75 0 12 where δwu the change in height of the upper zone water column in m 3 1 3 transfer the water from the upper zone to the root zone and adopt the updated values for soil horizons 3 2 if the change is negative soil and water content must be transferred from the root zone to the upper zone same as above but with transfers from the root zone to the upper zone appendix b comparison of hydroman with other hydrological models b1 temporal dynamics of groundwater the evolution of groundwater depth under different climate scenarios and initial groundwater levels was simulated with hydroman and two alternative one dimensional vertical hydrological models hydrus 1d and guarda hydrus 1d pc progress is a public domain windows based modeling environment for analysis of water flow and solute transport in variably saturated porous media šimůnek et al 2005 which has been used in the study area to simulate groundwater dynamics nosetto et al 2015 guarda is a simplified excel based water budget model developed by mercau and jobbágy 2013 as a practical tool to simulate soil water content and groundwater depth in agricultural soils simulations were performed using weather records and soil parameters from pehuajó a representative location in the study area a landscape with 11 11 cells of 1 ha each was created it was assumed to be completely flat and the watershed was entirely contained within the landscape all simulations spanned an agricultural cycle from may 1st of year 0 to apr 31st of year 1 three different agricultural cycles were selected from the historical climate records according to total precipitations to perform simulations under dry 2008 09 542 mm average 1980 81 1024 mm and wet 1986 87 1306 mm agricultural cycles the land cover assumed for all simulations was soybean for the whole landscape these three climate scenarios were combined with three initial may 1st groundwater depths 0 5 2 0 and 3 5 m simulated daily water table depth from each model was compared because hydroman is not a 1d model groundwater levels at the center cell were analyzed to make the runs comparable across models the water table dynamics simulated by hydroman were very similar to that simulated by the other two models for most of the situations fig b1 this similarity suggests that hydroman captures the main hydrological processes that reproduce the dynamic patterns there were differences between the models in some cases specifically between hydroman and guarda fig b1 middle panel the differences can be tied to how each model represents some key hydrological processes for instance while guarda uses the empirical curve number approach to represent runoff this process is endogenously simulated in hydroman and hydrus as a result while in guarda there is always runoff hydroman does not produce runoff when the landscape is completely flat and the land cover is homogenous hydroman will produce runoff in heterogeneous landscape either for land cover or topography to evaluate if differences between hydroman and guarda were associated with the infiltration process effective rainfall 4 4 rainfall stored in the root zone that can be use by plants i e water not lost by deep percolation and or run off simulated by guarda was used as input data to hydroman the outputs from these simulations were much closer fig b2 although hydroman produced results very similar to hydrus the latter produced smoother trajectories of water table levels mainly for deep initial water table depth e g left lower panel fig b1 the difference in the dynamics of simulated water table may be tied to the way in which each model simulates vertical fluxes hydroman considers a cascade model and hydrus relies on richard s approach the conductivity approach tends to smooth trajectories especially when the soil layer above water table is wide fig b1 temporal dynamics of groundwater simulated by guarda hydroman and hydrus 1d in 9 scenarios resulting from the combination of rainfall amounts during the agricultural cycle dry average or wet climate and initial water table depth 0 5 2 or 3 5 m fig b1 fig b2 temporal dynamics of groundwater simulated with guarda and hydroman with two alternative inputs i normal or ii effective rainfall from guarda to compare with it in 3 scenarios resulting from the combination of average rainfall amounts during the agricultural cycle and initial water table depth 0 5 2 or 3 5 m fig b2 b2 spatial dynamics of groundwater the spatial dynamics of groundwater within a simplified landscape was simulated with hydroman and mike she models mike she is a deterministic spatially distributed physically based numerical model which couples surface and groundwater flows refsgaard and storm 1995 refsgaard et al 2010 this model had been calibrated and validated in the study area badano 2010 garcía et al 2017 2019 our simulations were specifically aimed to assess spatial variations in water table depth as result of horizontal water flows triggered by heterogeneous land uses i e with contrasting water consumption over the landscape the simulated landscape involved a square grid of 151 151 cells of 1 ha each cell the land cover assigned to the whole landscape was soybean except for an island of 31 31 cells at the center that was assigned to pasture a land cover with higher water consumption the simulation was performed using an average rainfall year 1981 82 for pehuajó also with a completely flat landscape soil related parameters were defined for each model to represent a typical soil in pehuajó the initial water table depth was set to 2 5 m in both models water table depth from each model lengthwise in the landscape was compared at the end of the season apr 30th 1982 hydroman was able to simulate spatial changes in groundwater levels in response to heterogeneous land covers pasture and soybean that were qualitatively similar to those produced by mike she fig b3 these different groundwater levels were triggered by the response to differential water uptake between two plant covers although the spatial pattern of water table levels was qualitatively similar between models there were quantitative differences in water table depth by the end of the simulation we hypothesized that these differences were likely associated with a variety of processes that differ in their representation in each model for instance crop transpiration is represented via the k cb coefficient in hydroman and via the leaf area index in mike she similarly some parameters characterizing soil properties and initial conditions are different in each model which prevent a perfect alignment between models although we could calibrate hydroman to close the gap with mike she outcomes by manipulating any of these variables we decided to maintain the original setting because our focus was on assessing relative spatial patterns and not in reproducing absolute groundwater levels fig b3 groundwater levels simulated by hydroman and mike she on a longitudinal section of the landscape the dashed lines mark the limits of the central island planted with pasture the rest of the landscape is planted with soybean fig b3 appendix c supplementary data the following is are the supplementary data to this article data profile data profile appendix c supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104641 
26048,we present hydroman a flexible spatially explicit model coupling human and hydrological processes to explore shallow water tables and land cover interactions in flat agricultural landscapes modeled after the argentine pampas with fewer parameters hydroman aligned well with established hydrological models and was validated with observed water table patterns and crop yield data simulations with different climate phreatic and land cover conditions confirmed that climate remains the main driver but crops also influence water levels and yields depending on the growing cycle we also examined the impacts of two alternative sowing strategies risk aversion proves robust in minimizing crop losses but often results in less sowing exacerbating flooding strict rotators risk more but help stabilize the groundwater levels reintroducing pasture further stabilizes the system future work will engage farmers to derive and assess land cover strategies that maximize yield and minimize losses and transfer our modeling approach to other applications keywords natural human systems modeling rural decision making water table water risk management pampas 1 introduction in rainfed agricultural systems groundwater affects agricultural productivity and ultimately farmers land cover decisions if the water table is too deep groundwater cannot be reached by crop roots so that crop growth depends mostly on rainfall crops yields grow exponentially as the water table approaches the root zone enabling capillary water supply from the saturated zone kang et al 2001 nosetto et al 2009 when the water table lies at this optimum depth groundwater can supply most of the crop s water requirements mainly in dry years however crop yields fall sharply as water table levels continue to increase creating saturated conditions within the crops root zone mueller et al 2005 nosetto et al 2009 flat landscapes with humid climates like the argentine pampas the carpathian basin or the great plains of western canada are particularly vulnerable to flooding because the water table tends to oscillate close to the soil surface fan et al 2013 jobbágy and jackson 2004 as a consequence these areas may be waterlogged for prolonged periods not only reducing crop yields but also affecting available land machinery use and transport logistics aragón et al 2011 viglizzo et al 2009 in such landscapes regional horizontal water flows are relatively limited also due to low soil hydraulic conductivity while vertical water inputs and outputs dominate the water balance mercau et al 2016 thus groundwater levels in flat landscapes mainly follow rainfall variability portela et al 2009 and the main water outputs are plant consumption and soil evaporation which are in turn influenced by land cover decisions nosetto et al 2012 the magnitude and timing of evapotranspiration together with root depth and waterlogging tolerance vary among crops for instance pastures which grow during the whole year and have a deeper root system may consume almost twice the water used by annual cash crops like soybean which occupy the field only part of the year 4 5 months nosetto et al 2009 2015 farmers agronomical practices may also affect groundwater dynamics like no tillage cropping that leave the soil undisturbed and covered with stubble to reduce soil evaporation sinclair et al 2007 in other words farmers decisions introduce a reciprocal relationship with water table dynamics and they are both influenced by climate variability the effects of land cover on groundwater could encourage farmers to make cropping decisions to keep the water table level in the sweet zone nosetto et al 2012 i e between 1 5 and 2 5 m from the soil surface nosetto et al 2009 achieving this is not straightforward however first farmers make land cover decisions within their plots while water flows through property lines heterogeneous land covers across a landscape may trigger horizontal groundwater flows introducing interdependency among farmers sharing the same phreatic aquifer garcía et al 2017 therefore water table depth at the farm level depends not only on the farmer s land cover decisions but also on the decisions of the neighboring farmers second the amount of rain during the cropping cycle one of the main drivers of groundwater dynamics is highly uncertain and variable which translates into greater uncertainty for farmers regarding the impacts of their land cover decisions mercau et al 2016 understanding linkages between climate variability groundwater dynamics and land cover decisions is central to the sustainability of coupled water and agriculture systems water for food production exceeds all other water needs and water also drives several important ecosystem functions the proposal of managing water table depth to enhance the sustainability of water and agriculture should be based on a deep understanding and assessment of these linkages from the individual farm level through the landscape level gleeson et al 2012 rosegrant et al 2009 wada et al 2010 existing models are difficult to use for this purpose they tend to be either too simple or too complicated which makes them unsuitable to test a wide range of scenarios and include the explicit representation of decision making guarda is an example of a simple spreadsheet based model used to make site specific estimates of agricultural soil water content mercau and jobbágy 2013 in its current form it does not allow for the representation of the spatial context and cross scale interactions on the other extreme detailed process based and spatially explicit models are data intensive and are costly to calibrate and parameterize mike she was created to provide a wide range of customizable water mass balance outputs for nearly all types of hydrology refsgaard and storm 1995 refsgaard et al 2010 given its underlying computational complexity the number of time steps is limited to 800 calibration is extensive and recommended resolution is low to ensure that simulations can be completed within reasonable time frames hydrus was developed to analyze movements of water heat and solutes in porous media and is available in versions that are either two or three dimensional šimůnek et al 2005 time steps may be as small as 1 s which together with a hexahedral geometry yields higher precision results precision comes at the expense of flexibility in scenario testing and parameterization however which limits its applicability and slows downs simulations while originally developed to model groundwater flow modflow now includes several modules that simulate additional processes langevin et al 2018 modflow is a data intensive numerical model but the modularity of the model can make it easier to run faster simulations than with other process based models if fewer outputs are desired surface water flows are harder to simulate in modflow however drainmod dssat seeks to optimize drainage in agricultural soils assuming surface and sub surface drainage infrastructure and not lateral groundwater flow skaggs 1978 negm et al 2014 outputs include water mass balance data and crop yields this model was not intended for conditions other than humid climates slight slopes and the presence of drainage networks however while the above models are extensively used they do not explicitly consider the human dimension although some cases exist of coupling these sophisticated hydrological models to human decision making e g garcía et al 2019 reeves and zellner 2010 zellner and reeves 2010 these efforts take considerable amount of time and funding to both develop and run our aim was to develop a simpler and more agile spatially explicit platform that recreates enough of both the hydrological and social complexity of flatland agricultural systems to rapidly explore the effects of a wide range of climate and decision making scenarios castilla rho et al 2015 zellner 2007 such a platform would also be more useful to stakeholders and decision makers to explore the unintended consequences of their individual and collective decisions this paper has two main objectives first we describe our model which we called hydroman hydrology human and validate it against other established hydrological models and field data to assess its capability to reproduce primary patterns in hydrological processes second we introduce land cover decision making processes to understand and assess interactions between climate land cover and groundwater dynamics in agricultural systems of the argentine pampas the last section builds on this understanding to explore joint land and water management implications 1 1 case study our work targets the area of the salado a basin a part of the río de la plata hydrographic system and specifically a site in pehuajo fig 1 this salado basin is in the argentine pampas a key agricultural area for global food security calviño and monzon 2009 hall et al 1992 the pampas is one of the flattest areas in the world with regional slopes of less than 0 1 jobbágy et al 2008 and also show a strong climate variability on inter annual goddard et al 2001 to inter decadal scales boulanger et al 2005 rusticucci and penalba 2000 as a result of its flat topography and significant climate variability floods and droughts have been reported in the salado basin since colonial times given that the majority of agricultural production in the salado a basin is rainfed productivity of annual crops is strongly affected by rainfall and water table variations nosetto et al 2009 podestá et al 1999 since the 1970s the pampas showed a steady increase in late spring and summer rains particularly near the western boundaries berbery et al 2006 in the same period there was a transition from grasslands and pastures to annual grain crops mainly soybean paruelo et al 2005 viglizzo et al 2011 this land cover change emerged from individual farmers land cover decisions bert et al 2014 as result of higher precipitations and a dominance of annual crops that consume less water than perennial pastures and grasslands water table levels have risen nosetto et al 2015 viglizzo et al 2009 much uncertainty remains regarding the projected paths of future climate land cover and technological change in the pampas and there is growing concern among farmers and policy makers about potential effects on groundwater levels particularly on the risk of flooding in the salado a basin in particular there is an increasing need to understand how management practices can help prevent flooding while maintaining water table at depths that reduce the impacts of droughts garcía et al 2019 we developed hydroman to understand and provide insights regarding these questions in the hope that this may be relevant to similar agricultural regions in the world 2 model components and processes 2 1 model overview hydroman simulates the main hydrological processes relevant to our questions land cover decisions precipitation evapotranspiration and both surface and subsurface water flow the model tracks the water contents and depths in the soil horizons groundwater capillary upper and root zones as well as on the surface further the model also keeps track of crop yields as they are affected by water availability in contrast to other models each 40 year run takes 2 3 min in a 2 8 ghz processor laptop 2 2 landscape the landscape is represented as a square grid with the size of lattice determined by the user depending on the scenario chosen in all of the experiments completed for this publication the size of each cell was 1 ha 100 m 100 m but the size can be adjusted by the user boundary conditions can be set to be open where cells at the edge of the domain maintain a constant groundwater head during groundwater flow or can be set to be closed assuming that the landscape acts as a self contained basin and no water can flow in or out through the edges while this choice is left to the user to adapt boundary conditions to specific landscape representation size and resolution this must be thoroughly tested to understand how edge effects may influence results 2 2 1 land cover each cell of the simulated landscape can have one of seven different land cover options throughout a year pasture maize a cover crop of minimal economic value wheat regular soybean short cycle soybean and fallow no crop sowing decisions during a simulation determine the land cover at any point during a year for each cell section 2 3 4 in some scenarios the land cover may change during a year or between years section 4 2 each land cover type has unique daily values for water need for transpiration k cb the basal crop coefficient 1 1 the basal crop coefficient kcb is defined as the ratio of the crop evapotranspiration over the reference evapotranspiration etc eto for more details see allen r g pereira l s raes d smith m 1998 crop evapotranspiration guidelines for computing crop water requirements fao irrigation and drainage paper no 56 fao rome italy and rooting depth and critical growing periods when partial unmet water need directly affects yields fig 2 both k cb and root depth dynamics were built based on crop simulations carried out with dssat decision support system for agrotechnology transfer models jones et al 2003 literature values allen et al 1998 satorre et al 2003 and expert knowledge the critical growth periods for soybean maize and wheat yields are linked to a short period of high water demand a window of time spanning 30 days before and after the day with the maximum k cb during a cycle in contrast pasture and cover crops are assumed to have critical demand for water every day they are alive they produce biomass rather than a commercial product meaning that unmet water demand for the entire crop cycle affects their yields soybean maize wheat and cover crops were assumed to be able to tolerate only seven consecutive days it can be adjusted by the user between 0 and 10 days without any water before dying whereas pasture is more resilient and will never fully die once sown sheaffer et al 1988 2 2 2 elevation and slope given the little variation in ground elevation characteristic of the argentine pampas slopes can be set with a slider or an import file with values for each cell the former option produces a stylized landscape that is useful for model verification but the latter option can apply elevations from digital elevation models which is useful for model validation and scenario testing elevation is in absolute meters above sea level 2 2 3 soil horizons the soil reaches a total depth of 100 m in all cells soil is divided into four separate zones as described in the following sections fig 3 and is assumed to have three pore sizes small medium and large the small pores are assumed to be always saturated but their water is unavailable for flow or evapotranspiration due to surface tension matrix potential the large free draining pores are assumed to be always empty because of gravitational force unless located in the groundwater zone where they are saturated medium pores can show different degrees of saturation due to infiltration evapotranspiration or water transfers between horizons due to changes in the groundwater levels the proportion of small medium and large pores in the soil is set by the user in all of the experiments completed for this publication medium and large pores occupied 12 and 19 of soil volume respectively which would correspond to the typical sandy loam soil of the region the soil horizons are dynamic and their depths change as roots grow and groundwater flows horizontally and vertically groundwater zone the groundwater zone makes up the deepest and largest portion of the soil column both the large and medium pores are fully saturated and water can flow horizontally between cells if there are differences in hydraulic heads section 2 3 3 soil in this zone is devoid of oxygen so any portion of plant roots that reach into this zone will die capillary zone for the typical soil type of the study region i e sandy loam mollisol this was set as the 0 8 m above the top of the groundwater zone its medium pores remain fully saturated due to capillary action that draws water from the groundwater zone plants can safely draw water from this zone root zone this is the top horizon the root zone is any part of the soil column above the capillary zone into which the plant s roots grow at a minimum the root zone is assumed to be 0 3 m in depth limited by available soil column above the capillary zone whether roots occupy that space or not to represent the greater influence of evaporation close to the soil surface plants can draw water from the medium pores in the root zone for transpiration upper zone this is any soil column between the capillary and root zones to account for water that may be stored in the soil this water will be available for transpiration as the root grows and expands the root zone into the upper zone or will add to the groundwater as the water table rises into the upper zone 2 3 processes and order of events hydroman represents daily cropping and hydrological processes that are most relevant to our research questions the processes run in the following order fig 4 1 precipitation runoff and infiltration 2 surface flow 3 groundwater flow 4 sowing decisions 5 plant growth 6 evapotranspiration and 7 harvesting additionally soil horizons adjust after every change in hydraulic head or root length in any of these processes 2 3 1 precipitation runoff and infiltration the model uses daily precipitation amounts from input files that can represent either hypothetical or observed data over a number of years each day the model reads the daily precipitation from the file and this value is applied to each cell as follows hydroman assumes a fixed percentage which can be set by the user of the amount will be runoff and the rest immediately infiltrates where it falls in all of the experiments completed for this publication runoff was set at 30 a reasonable value for this type of soil mercau pers comm the rain that infiltrates first fills unsaturated volume in the medium pores of the root zone if there is not enough room in the root zone for all the water the remaining rainwater fills up the medium pores of the upper zone any further remaining water is added to the groundwater zone since the medium pores of the capillary zone are by definition already saturated in this case the groundwater level rises by an amount that depends on the amount of water transferred and the specific yield of the soil if there is not enough room in the medium or large pores in the soil for water that is infiltrating then the water that cannot infiltrate stays on the surface and is added to the fixed runoff amount the soil horizons are adjusted to reflect the change in the groundwater table section 2 3 8 2 3 2 surface flow each iteration water flows from a high hydraulic head to a low hydraulic head to do this cells are sorted in ascending order of elevation and sequentially interact with each one of its upstream neighbors to exchange water also in ascending order of elevation during the interaction the cell determines the difference in hydraulic heads between itself and the neighbor with which it is interacting then this difference in hydraulic head is divided in half to estimate the water flow between the cell and its neighbor needed to reach equilibrium if the neighbor s head is higher water flows into the cell constrained by the amount of the neighbor s water if the reverse is true water flows out to the neighbor constrained by the amount of water in the originating cell this setup results in asynchronous updating of water levels where each pair of cells is updated one at a time rather than all simultaneously since iterations are one day in length and surface water under normal conditions can be expected to reach an equilibrium level by the end of a day this removes the need for a more intensive surface flow algorithm that accounts for factors including surface roughness velocity or routing 2 3 3 groundwater flow the process for groundwater flow in this model builds on a previous implementation of darcy s law of flow zellner 2007 zellner et al 2012 each time step cells asynchronously exchange water with each of their neighbors first the flow volume is calculated according to equation 1 1 q k e l d δ h where q volume of flow in m3 per day k hydraulic conductivity per day e l large pore specific yield i e porosity d aquifer depth in the cell in m δh difference in hydraulic heads between the cell and its neighbor in m the water is transferred and cells update their water table depths based on the content of water added or subtracted if the top of the groundwater zone is at the surface the height of the surface water column is added to the hydraulic head to calculate flow and transfer after all cells have finished transferring water the model adjusts the soil horizons of the zones that are above the groundwater including surface water if the water table reaches the surface for the cells whose groundwater level changed section 2 3 8 2 3 4 sowing decisions sowing decisions are determined exogenously by the user and are taken at the start of a new cropping cycle may 1 or day 0 unless the crop begins growth on the first day pasture or cover crops are sown seven days before its k cb is first greater than 0 which happens when the plant starts growing and transpiring when sowing happens root growth root damage by flooding and yield variables for the cell are reset pasture does not reset root damage because it is assumed that it never truly dies or gets sown anew it is a perennial crop while the over crops are annual after an initial set of sensitivity tests section 3 we modified the model to include adaptive risk averse farming strategies determined endogenously based on the water table depth at different times during the cycle and the crop rotation schedule these will be explained in more detail in section 4 2 2 3 5 plant growth every crop has unique daily root lengths corresponding to the time in its cropping cycle as determined by the input file fig 2 each day a first check for prior root damage due to contact with the water table is performed in cells with live crops i e not yet harvested and with positive water demand for transpiration if undamaged the root length of each cell is updated according to the input file if by doing so the roots enter the groundwater zone the root length only grows up to the water table depth the part of the root within the groundwater zone dies due to hypoxia and is marked as damaged if the roots were previously damaged they may grow back depending on the crop type and available space above the water table for all crops except pasture damaged roots regrow the amount corresponding to the growth for that day since pasture s root length is held constant throughout the year they are set to regrow 1 of the root length when they are damaged up to the length of an undamaged root the cells will later use the new root lengths to update their root and upper zones section 2 3 8 2 3 6 evapotranspiration soil evaporation and crop transpiration are directly linked to daily reference evapotranspiration et o potential crop evapotranspiration et c is a function of the crop s demand for water i e k cb and et o equation 2 and soil evaporation e is simply the difference between et o and t for the crop equation 3 this means that on a given day if t is high when the crop is at a critical stage and leaf coverage is maximized then e will be low because the soil will be shaded by the foliage allen et al 1998 2 e t c e t 0 k c b i where et c potential evapotranspiration i e the daily water needs for crop i in m per unit area et 0 daily reference evapotranspiration in m per unit area k cbi the basal coefficient for crop i 3 e i e t 0 t i where e i daily soil evaporation in m per unit area et 0 daily reference evapotranspiration in m per unit area t i transpiration for crop i in meters per unit area first the model computes the daily water need for each crop type equation 2 daily water need i e et c for each cell is updated based on its cover or set to zero when fallow the soil zone from which water will be drawn for transpiration is determined by considering the proportion of roots located in the root and capillary zones then the actual amount of water that is available is computed assuming that at most 10 of water that is reachable is available for transpiration at each time step dardanelli et al 1997 next plants are allowed to draw water from the two zones sequentially starting with the root zone and corresponding to the shares as computed above if after withdrawing water from the root zone there is still unmet need and any of its roots are in the capillary zone then the plant will continue to withdraw any unmet need from the capillary zone any deficit in daily water need i e whatever need remains unmet is recorded equation 4 taking a value between 0 and 1 where 0 is completely met and 1 is completely unmet water need and the cumulative percent unmet demand for the critical growth period in the current growing cycle is calculated and then averaged over the critical period a counter keeps track of the number of consecutive days in which no water has been withdrawn by the crop if the counter reaches 7 consecutive days and the crop is anything except pasture the plant dies the root length is set to 0 and both root and upper zones adjust accordingly section 2 3 8 finally the total daily transpiration amount from both zones is recorded 4 u w i t w d c g p i t w n c g p i where uw i daily unmet water need for crop i 0 1 twd cgp daily water deficit during the critical growth period for crop i twn cgp daily water need during the critical growth period for crop i the cell s daily potential soil evaporation e i is now determined equation 3 when groundwater is at the ground surface e i is increased by 20 due to water being more readily available to evaporate from either the surface or the groundwater itself if there is surface water the e i amount is first subtracted from the surface water column if there is still remaining e i after all surface water evaporates the evaporating water will be withdrawn from the groundwater at the same increased rate if the capillary zone is at the surface then e i will be subtracted from the groundwater but at the base rate in the case where neither groundwater or capillary zones are at the surface evaporating water will be withdrawn from the root zone the upper zone by definition will always be too far from the surface for water to evaporate from it in this situation the amount of water that will evaporate from this zone depends on the saturation of its medium pores equation 5 5 e r e i θ where e r root zone evaporation amount in height m per unit area e i potential daily soil evaporation in m θ the soil water content of the medium pores in the root zone evaporation only takes water from the first 0 2 m of soil because it is assumed that below this depth direct evaporation is negligible jalota and prihar 1990 schwartz et al 2010 if the root zone s height is less than 0 2 m because the water table is close to the surface any amount of e i not withdrawn from the root zone is removed from the groundwater after the evapotranspiration process if the groundwater zone shrank due to evaporation or transpiration soil horizons are updated section 2 3 8 2 3 7 harvesting there are critical growth periods when the amount of water consumed has a direct relationship on the crop yield at harvest calviño and sadras 2002 calviño et al 2003 during the critical growth period the unmet water needs are recorded equation 4 at harvest day i e the last day that a crop s k cb is greater than 0 a crop yield factor is calculated for each cell based on the average water deficit during the critical period if the plant died before harvest then the unmet demand is assumed to be 100 for that year which will mean there is no yield cumulative unmet daily need and days the length the crop was in critical growth are then reset the model then translates the crop yield factor into crop production based on the potential yield for an area the size of the cell equation 6 since harvest results in plant death the root length is set to 0 at that time which may result in an updating of the horizons for the root and upper zones 6 y i 1 f y p y i where y i the annual yield for crop i on this cell in metric tons f y crop yield factor py i the potential yield or maximum annual tonnage possible for crop i on an area the size of this cell this is the yield when f y 0 py i is defined by users in all of the experiments completed for this publication py i was 5 6 14 5 5 3 5 and 8 tn ha 1 for cover wheat maize soybean short soybean and pasture respectively 2 3 8 updating horizons soil horizons are updated whenever there is a change in groundwater levels or root lengths groundwater rises groundwater levels can rise only due to infiltration or groundwater flow when this happens the capillary root and upper zones need to be adjusted the new sizing of the zones follows the rules outlined in section 2 2 3 soil that was previously in upper or even root zones may now be in the groundwater or capillary zones thus the amount of water in the upper and root zones will decrease if the size of the zones decrease but the overall saturation of the medium pores in the root and upper zones will remain unchanged groundwater falls groundwater levels can fall only due to groundwater flow or evapotranspiration if the groundwater levels fall the horizon for the capillary zone will change and the upper and perhaps root zones will increase following the sizing rules outlined in section 2 2 3 any new soil in the root or upper zones is assumed to have fully saturated medium pores since it was previously in the groundwater or capillary zones the cells with receding water table receive water left behind in the appropriate zone as groundwater levels drop and the result will be a net increase in saturation of the medium pores in the zones if not previously fully saturated root length changes plant growth and death may lead to a change in the root and upper zones the capillary zone horizon is unaffected by changes in root lengths after plants adjust their root lengths the root and upper zones will adjust following the rules outlined in section 2 2 3 since we assume uniform saturation of soils within a zone any soil that is transferred between the two zones will bring along water the new amounts of water in a new zone are calculated based on the size of change to a zone and previous saturation levels appendix a 3 model verification and validation to ensure that the model implementation matched its intended design we followed three complementary verification procedures throughout model development first the team performed a code walk through in which the lead programmer explained the functionality of each line of the code this process ensured that all design concepts and specifications were correctly mapped onto the code second we conducted independent verification by running portions of the whole model algorithm in a spreadsheet checking intermediate and final outcomes e g water table depth for a specific cell and date this procedure although time consuming was very effective in identifying conceptual and numerical errors as it allowed us to compare simulation results with results from an independent system finally we ran simplified but realistic scenarios to ensure that key outcomes variables had reasonable values both temporally and spatially we also examined how well hydroman recreated both micro and macro level patterns of water table depth over time and in space i e validation railsback and grimm 2012 first we consulted with literature and expert hydrologists to ensure that hydrological processes were adequately conceptualized and implemented in our model our second approach involved docking our model with other existing hydrological models that have been applied in the area of study to see to what extent the water levels in time and space matched the ones simulated by other models once we established the adequacy of the model relative to existing modeling tools we finally contrasted site specific simulation results to observed ground and surface water records in that location the validation process is described in more detail below 3 1 conceptual validation with expert hydrologists hydroman involves universal and well known hydrological processes the initial design of those processes was based on established work in hydrological modeling menendez and garcía 2014 mercau and jobbágy 2013 the main contribution of the experts was a to determine which hydrological processes should be included b to decide the level of detail in which each process should be represented and c to simplify some key processes e g soil evaporation and runoff the involvement of local experts allowed us to keep the model simplified but relevant to its purpose 3 2 hydrological model docking as a second validation technique we aligned scenarios in hydroman to match those in alternative established hydrological models previously used in the region the goal of this docking exercise was to assess the extent to which hydroman is able to reproduce temporal and spatial patterns of groundwater levels of other models nosetto et al 2015 first we performed simulations to assess the temporal dynamics of groundwater levels in one point in the space to this end we compared outputs from hydroman with hydrus 1d šimůnek et al 2005 and guarda mercau and jobbágy 2013 2 2 hydrus 1d pc progress is a public domain windows based modeling environment for analysis of water flow and solute transport in variably saturated porous media guarda is a simplified excel based water budget model developed by mercau and jobbágy as a practical tool to simulate soil water content and groundwater depth in agricultural soils we also performed simulations to assess the spatial dynamics of groundwater in a two dimensional space comparing outputs from hydroman with mike she 3 3 mike she is a deterministic spatially distributed physically based numerical model which couples surface and groundwater flows refsgaard and storm 1995 refsgaard et al 2010 details of this validation exercise and its results can be found in appendix b overall we observed a high degree of matching between hydroman and both 1d and 2d models we were also able to identify specific sources of discrepancies across models such as the infiltration and crop transpiration used in different models and adjust hydroman parameters accordingly 3 3 validation against observed hydrological data this assessment involved the simulation of a plot in a farm located in pehuajó buenos aires province argentina we obtained monthly groundwater depth records from may 2008 to may 2013 for a 50 ha plot in this farm fig 5 characterized by uneven topography and three wells located at different topographic positions of the plot table 1 the simulation aimed to recreate the groundwater dynamics at those three points during the same period hydroman was set and initialized to represent as precisely as possible the plot conditions in terms of topography soil characteristics and initial water table depth a land surface digital elevation model dem based on the shuttle radar topographic mission srtm was produced to represent the plot topography a landscape with 7 7 cells of 1 ha each was created and the elevation of each cell was defined based on the dem the dem based landscape roughly reproduced the topography of the plot as confirmed by field observations soil related parameter values for a typical soil in pehuajó were assumed and the initial water table depth at each of the observation wells was set based on records for may 2008 the sequence of land covers for the plot was also obtained starting with cropping season 2008 09 data from the weather station of the national meteorological service smn in pehuajó was used as weather input hydroman was able to closely reproduce three observed structural groundwater dynamics over time fig 6 the model accurately reproduced the magnitude of water table depth and the dynamics of groundwater at the three points monitored including the significant increase towards the end of the simulated time period leading to flooding in the intermediate and lowest land the model was able also to capture the relative differences in groundwater level between topographic positions the model could only reproduce these patterns under closed boundary conditions that reduced the edge effects of an open fixed boundary on a small landscape the latter introduce an artificially high supply of water that overrides any water table changes produced by the small simulated landscape although hydroman reproduced the main patterns some second order differences both under and over estimations are noticeable between observed and simulated water table levels the main differences are observed during winter spring 2009 at the three topographic positions and towards the end of the simulation where hydroman tended to simulate higher water levels we analyzed several factors that may be the source of that discrepancy among the most important we included a possible spatial heterogeneity in precipitations as the simulation used data from a weather station 18 km away from the simulated farm b disruption in monitoring due to a maintenance of the wells conducted during autumn 2009 which may have led to erroneous readings in the following winter and or c possible influence of groundwater levels surrounding this plot while we assumed a closed boundary between this plot and adjacent areas to reduce edge effects this is actually an open boundary which may have contributed with incoming or outgoing flows hydroman reproduced the crop yields registered in the pehuajó plot in the simulated period with an acceptable precision fig 7 the normalized root mean square error for all crops and cropping cycle was 18 this is a reasonable error considering the model s parsimony the few data points against which simulation outputs are compared and the short time frame for the validation 5 crop rotation years more sophisticated models like dssat and apsim show similar results when applied to the pampas region garcía et al 2018 guevara et al 1999 mercau et al 2007 mercau and otegui 2014 differences between observed and simulated yield were smaller for wheat maize and soybean crops hydroman s performance was poorer only in the case of short cycle soybean overestimating yield for the two cropping cycles simulated reasons for this discrepancy may include weather extremes or biotics constraints there was a drought in 2008 09 and heavy rains in 2011 12 which might have affected the later part of the sowing cycle in addition later summer crops in the pampas usually find better water conditions during their critical periods than earlier crops however solar radiation levels decrease at that time making this the main constraint on crop yield since hydroman does not simulate crop yield based on radiation the better water conditions result in an over estimation of simulated yield additionally there may have been a range of disruptions in the field that led to lower yield data the validation exercise above provided enough evidence that hydroman could recreate temporal and spatial dynamics of water table consistent with those from other models and observed data while identifying the specific sources of discrepancy at this point we turned to using hydroman to explore the questions of land cover climate and water table interactions 4 understanding the influence of climate and land cover decisions on groundwater dynamics our goal was to use hydroman to identify practices that may help to manage groundwater levels contributing to a balance between preventing flooding and drought accordingly we designed two sets of simulations around the following questions i how do different land cover scenarios influence water table depth ii how can adaptive land cover strategies prevent extreme water table levels 4 1 effect of land cover scenarios on groundwater dynamics we seek to assess the effect of various land covers each with different water consumption capacities on groundwater dynamics and levels we ran six land cover scenarios that included the typical options in the study area a pasture b soybean c cover crop followed by soybean d maize e wheat followed by short cycle soybean and f fallow no crop land cover was the same all across the landscape and was maintained constant throughout the simulation period two sets of weather data were used to assess the interactions between land cover and climate a three sequences each of them generated by repeating 40 times a dry 2008 09 542 mm average 1980 81 1024 mm and wet 1986 87 1306 mm agricultural cycle and b the historical weather records for pehuajó 1971 2010 further two initial contrasting but realistic groundwater levels were simulated 2 and 5 m to understand the influence of initial water table conditions and system behaviour towards a dynamic equilibrium as a result we ran 48 scenarios 6 land covers under 4 climate sequences with 2 initial groundwater levels all scenarios assumed a completely flat landscape encompassing 11 11 1 ha cells for simplification purposes groundwater level was strongly affected by the land cover fig 8 from deeper to shallower simulated groundwater the general order was pasture deepest water table depth cover soybean wheat soybean maize soybean and fallow shallowest water table depth the deeper roots 3 5 m vs 1 8 2 m and the uninterrupted water consumption of pasture throughout the year led to the lowest groundwater levels in relation to the rest of the crops among double crops higher water consumption during the whole agricultural cycle is evidenced when a cover crop is sown during winter compared to a harvest crop i e wheat the cover has an earlier plot release that allows earlier sowing and establishment of the soybean crop that follows explaining the water consumption differences when soybean is sown after wheat that delay in evapotranspiration reduces its water withdrawal andrade et al 2015 the wheat soybean double crop also has little water consumption during the transition between crops low canopy and root size in early summer when high atmospheric evaporative demand occurs mercau et al 2016 comparison between single crops showed groundwater levels a little deeper with maize than soybean as land cover due to the earlier establishment and water consumption of the former during spring maize is sown approximately one month before soybean the effect of land cover on groundwater dynamics heavily depended on climate scenarios and initial conditions mostly within the first 5 to 10 simulated years until the water table reached a long term dynamic equilibrium for most land covers fig 8 larger differences among land covers were observed under average climate conditions with groundwater level tending to rise at different rates except with pasture which stabilized the water table at levels similar to dry conditions dry climate favored groundwater stabilization at lower depths in all land covers rising only with fallow under wet conditions groundwater tended to rise in all land covers initial water table depth can magnify the climate impact on groundwater dynamics at the beginning of each simulation period further reducing differences among land covers in the extremes i e dry weather and deep water table and wet weather with shallow water table the middle conditions i e dry weather and shallow water table average weather and wet weather with deep water table support more distinctive behaviors across land covers during the initial simulation period these differences however disappear over time in average and wet climates crop yields varied according to the climate scenario and the dynamics of groundwater table 2 initial water table depth did not influence the outcomes beyond the spin up period and results were averaged between both conditions under average climatic conditions the relative yields of all land covers were closest to the maximum showing the most favorable conditions for all crops except soybean and soybean after cover the average scenario still introduces significant amounts of precipitation at a time that hurts the crop although groundwater dynamics under maize seems very similar to soybean on average 0 1 m deeper for maize maize yield was high because the water table was deeper than 0 5 m during the critical crop stages under the sequence of wet years the excess water decreased root functionality no matter the land cover leading to extensive losses for all crops yields for most crops were also reduced under the sequence of dry years although not to the same extent as with flooding especially for crops with low water demand e g wheat soybean was the most affected crop by both wet and average climate while the others proved more robust to the range of scenarios tested these patterns align in general with those reported by florio et al 2015 mercau et al 2016 nosetto et al 2015 the results using historical climate suggest not only an interaction between land covers and total precipitation but also among the temporal rain distribution and cover water consumption pattern considering the last 20 simulated years where the initial conditions no longer influence the groundwater dynamics the effect of water shortages or flooding determined by the actual climate variability was similar for all crops resulting in relative yields of around 80 pasture had higher values and wheat and full cycle soybean the lower ones table 2 the deepest groundwater levels were observed for pasture and the shallowest for fallow with cover soybean and soybean as the deepest and shallowest respectively among the grain crops groundwater dynamics both under wheat soybean and maize had an intermediate behaviour the differences described between those land covers in stylized scenarios fig 8 are less noticeable under the historical climate series after the first few years of simulation fig 9 larger differences are observed among land covers with a deeper initial level 5 m but only during the first half of the simulated period before the system reaches a dynamic equilibrium temporal variations in climate may be introducing a time lag in which crops can catch up with water uptake maintaining overall levels below and disconnected from the surface except where there are consecutive wet years overall however cover soybean is better able to maintain the water table depth at more manageable levels than other land covers a lower evapotranspiration from land cover change i e the observed shift from mixed crop cattle systems to continuous agriculture together with increased rainfall have contributed to increase groundwater recharge in the pampas mainly in the area of study favoring the rise of water tables aragón et al 2011 viglizzo et al 2009 although the simulations did not have this aim the scenario with an initial water table depth of 5 m reproduced the observed groundwater patterns in the region under agricultural land covers groundwater levels tended to increase modulated by rainfall conditions conversely groundwater levels stayed at deeper levels under pasture increasing only 1 m along the 40 years of the simulation 4 2 effect of adaptive land cover strategies farmers have expressed interest in developing strategies to adapt to climate and water table variations arora et al 2016 we extended hydroman to represent possible adaptive strategies and to understand their effect on groundwater dynamics and risks of waterlogging on crop production to do this we compare scenarios in which the farmers either do not consider non adaptation or consider adaptation water table depth to select their land cover allocation the non adaptive strategy is characterized by a farmer who strictly followed the typical crop rotation scheme for the study area regardless of the groundwater level i e a strict rotator adaptive strategy on the other hand is characterized by farmers who decide the land cover at the beginning and throughout the cropping cycle depending on groundwater levels regarding their reference thresholds fig 10 the default rotation sequence which is adopted by the strict rotator non adaptive strategy is maize year 1 full cycle soybean year 2 and wheat or cover crop followed by soybean short or full cycle soybean respectively year 3 adaptive farmers would deviate from this sequence depending on water table depth at the moment of sowing decisions the rationale behind the adaptive strategy represented in the model is that the farmer may introduce a high consumption cover to lower water table levels under threatening waterlogging conditions groundwater thresholds assumed by farmers correspond to the lower limit of optimal depth range for highest yield for wheat maize and soybean 0 7 1 4 and 1 2 m respectively nosetto et al 2009 thus on may 1 day 0 of each year during a simulation if a the water table depth is between the shallow and deep thresholds or b it is year 3 in the rotation and the depth to the water table is greater than the shallow thresholds wheat will be sown if it wasn t sown the previous year otherwise cover crop will be sown assuming farmers would allow soil recovery by rotating crops the farmer will recheck the water table depth on december 13 after sowing wheat or on october 24 after sowing cover crop to determine if a subsequent sowing happens however if conditions a or b above are not met the farmer will not sow in may and will recheck the water table on september 18 if it is year 1 in the crop rotation corresponding to the sowing of maize or on october 24 any other year if marked to recheck the water table depth on september 18 and on that day the water table depth is deeper than the threshold the farmer will sow maize and advance the rotation year if shallower than the threshold the farmer will recheck on october 24 by that date those farmers marked to check the water table depth will sow full cycle soybean if the water table is deeper than the threshold also if it is year 2 of the rotation or year 3 of the rotation and a cover crop was sown on may 1 the rotation year advances if the water table was not deep enough to allow any crop sowing in october the farmer will check again the water table depth on december 13 on december 13 the final opportunity to check the water table during a cropping cycle if the water table is deeper than the threshold short cycle soybean will be sown if it is year 3 of the rotation and either wheat or cover had been sown on may 1 the rotation year is reset to year 1 if the water table was shallower than the threshold on this day the land will remain fallow the famer decisions are all represented at the cell level the experiment included the two decision strategies described above adopted in two landscapes a completely flat stylized landscape and the plot from pehuajó used for model validation section 3 3 the landscape encompasses 7 7 cells of 1 ha each in both cases always under the historical weather records 1971 2010 from the pehuajó weather station and starting in an initial groundwater level of 2 m additionally two precision levels in the water table depth readings were adopted to guide land cover decisions in the pehuajó landscape low sowing decisions in each cell are based on groundwater levels from a single cell in the entire plot or high decisions are based on groundwater levels in each cell in the plot in the low precision level all the cells in the plot will have the same land cover while in the high precision level each cell will have a land cover according to its groundwater level the water table depth results suggest several trends fig 11 the bimodal distribution in water table depth is in line with theoretical discussions in our broader research team prompted by field observations there are essentially two basins of attraction for the water table represented in the two peaks in the distribution of the pehuajó landscape the depth of these two basins depends heavily on the crop s root length and transpiration rates under normal or dry conditions transpiration depresses the water table only as much as its root length allows water levels will rise with precipitation but transpiration will keep them in that basin when a wet period causes a significant rise in the water table and consumption cannot keep up the roots are killed due to anoxia decreasing the capacity of the plant to transpire and exacerbating the water table rise once it reaches the surface direct evaporation takes over operating at greater rates to compensate for rising water levels this then becomes the second basin of attraction in contrast with the pehuajó landscape a flat landscape minimizes the lateral flows afforded by heterogeneous elevations increasing the sensitivity to different root lengths among the sowing strategies adaptation is better able to maintain the water table at lower depths than strict rotation when the landscape is flat i e cells have complete information about the landscape widespread sowing of specific crops that affect the water table depth can have a substantial impact on keeping the water table at desirable levels even when climate is unfavorable at the other extreme when cells make decisions on one point in a heterogeneous landscape adaptation is worse than strict rotation that is for adaptation to be successful it must rely on appropriate levels of information otherwise the wrong crops will be sown in the wrong places initial sensitivity tests on water table depth thresholds showed that adaptation matters more than the details of its implementation and is a robust strategy when information is available to maintain the water table at acceptable levels in heterogeneous landscapes and more decentralized decision making i e when each cell decides its own sowing we see virtually the same outcomes between adaptation and strict rotation fig 11 this suggests that the temporal variability brought about by strict rotation can partially compensate for the fluctuations in water table depth that each cell experiences adaptation can compensate for spatial differences over a single time period by adapting to geographic differences in water table depths at one time strict rotation on the other hand can compensate for differences in water table depth across time periods so that a water demanding crop can help address high water tables left over by less water demanding crops overall adaptation seems to be a robust strategy to follow in homogeneous landscapes but precision agriculture might be important in ensuring its success in more heterogeneous landscapes adaptive strategies may end up with more instances of fallow cover in heterogeneous landscapes with low information levels exacerbating flooding table 3 this effect could be countered if instead of leaving land fallow flood resistant crops were sowed strict rotators do not allow their land to go fallow non crop and thus may better maintain the water levels below the surface although exposing themselves to more losses due to flooding in relation to crop yields simulations tend to show that adaptation may still be overall better than strict rotation table 3 particularly when we observe crop losses a pattern emerges of how adaptation provides an advantage over strict rotation risk averse loses fewer crops than strict rotators because strict rotators do not consider water table depth they end up losing more of their crops mostly to flooding although they may also do so to drought they can partially compensate for these losses however by sowing at risk which sometimes may turn out well for them especially when it helps lower water table levels paradoxically by adapting to water table levels adaptive decision makers increasingly avoid sowing and thus exacerbate the flooding problem yields may be higher for the land farmed and losses may be minimized but the areas farmed are much smaller given these results we hypothesized that re introducing pasture to the flat lands might be beneficial in regulating water table depths and thus ensure more successful outcomes particularly since the cost of farming and monitoring water levels at high precision would be unrealistically costly confirming our expectations the inclusion of pasture in the heterogeneous pehuajó landscape improved the performance of the system by increasing crop yields reducing crop losses and stabilizing the water table table 3 and fig 12 introducing as little as 7 random cells of pasture over the 49 14 coverage slightly increased the yield of all strategies and reduced the crop losses moreover less land is left fallow in the adaptive strategies at double that area of pasture 29 coverage yield increased and crop losses were further reduced sowing 21 cells of pasture 43 coverage stabilized the water table depth increasing the benefits for the strict rotator by reducing crop losses and increasing yields to levels similar to the risk averse virtually eliminating the advantage of adaptation and the associated monitoring cost at this point however pasture started occupying half of the lot severely competing for space it is also worth noting that none of these conditions trigger the sowing of maize in the adaptive decision making suggesting that water levels may still be too high for this crop these results imply that a stabilizing longer term strategy that allocates pasture in different spatial arrangements may be worth exploring in more detail relative to the use of flood resistant crops when crises arise 5 implications for agricultural decision making we developed a parsimonious process based dynamic and spatially explicit model called hydroman that considers the main hydrological processes of groundwater and surface water flow as a function of land cover and climate hydroman provides a flexible platform to quickly and easily examine how the human dimension of agriculture sowing decision rules influence both water table levels and crop yields in flat agricultural areas the model was able to reproduce patterns of groundwater levels over time and in space capturing both the micro level complexity as validated by experts in the field and the emerging macro level patterns as validated by alignment with established models and empirical data we used hydroman to understand how climate land cover and water tables interact and with this understanding identify possible strategies for agricultural water management while climate continues to be a main driver in the system the switch from cattle ranching to annual grain crops which use less water than pasture has also influenced the water balance of the region nosetto et al 2012 viglizzo et al 2009 among the land covers examined double crops tend to reduce the now predominant risk of flooding by extending the period of time in which they absorb water however it may be more difficult to plant it in areas that are already waterlogged adaptive strategies offer some relief from flooding but only if implemented with spatial precision with more spatial variability the advantages disappear and even may backfire as sowing is adapting to the wrong information thus increasing the risk of lower yields greater losses and flooding with appropriate information the details of adaptation matter less than the fact that environmental information is being used to make decisions when information is lacking strict rotation may in fact be the better option particularly with increasing landscape heterogeneity in extreme years however adaptation may not be enough to prevent flooding particularly when sowing is avoided to minimize losses which exacerbates the flooding problem policy makers and farmers may wish to consider a partial reversal to pasture strategically locating them in low lying areas in enough coverage to generate more stability in the system hydroman is set up in a way that allows for further development and exploration of management strategies among the ones we seek to explore in future work are rules that account for decision in neighboring plots which poses a coordination problem among actions that can potentially exacerbate or cancel out effects such explorations would allow us for example to develop generalizable recommendations for the allocation amount and spatial location of pasture to reduce flooding risk such decisions however may have different implications for the distribution of benefits and losses of the actors in the system to pursue this work we will work with stakeholders to both develop strategies and to examine them in an iterative participatory modeling process collaborative approaches supported by flexible and parsimonious models like hydroman can support the emergence of new institutions that can increase the adaptive capacity resilience and sustainability of human natural systems beyond the agricultural settings we represent here gray et al 2018 voinov et al 2018 zellner 2008 zellner et al in press zellner et al 2012 software availability name of software hydroman developers dean massey and moira zellner contact information mzellner uic edu hardware required software required netlogo programming languages netlogo license www comses net codebase release 1db4c97d 46f1 42dd 9d62 77bf45f95776 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national science foundation nsf cnh award 1211613 the uic under represented faculty recruitment program co sponsored by the provost and the college of urban planning and public affairs conicet argentina pip 112 201501 00609 anpcyt argentina pict 2014 2790 and 2017 3811 and the inter american institute for global change research iai grant crn 3035 in turn supported by the nsf grant geo 1128040 guillermo garcia held a postdoctoral fellowship from the national scientific and technical research council conicet argentina we greatly appreciate the support of g podestá principal investigator of this grant and early conversations with co investigators p arora b rajagopalan and c macal we are very thankful to e jobbagy j mercau a menéndez and p garcía for their contribution in the conceptual validation of hydroman and s rovere for assistance with r scripts appendix a example calculation of water transfer across soil horizons we illustrate with an example below the calculations that update soil horizons in hydroman and transfer the corresponding water content across horizons as they change in this illustrative example the code updates the root and upper zones after the daily growth of the root 1 calculate the new lower limit of the root zone equation a 1 example i f s t c 0 3 a n d s t c l 10 9 0 3 and 10 9 0 5 where s the elevation of the cell in m t c the depth to the capillary zone in m l the length of the roots in m 1 1 if true equation a 1 1 example b r t 1 s max 0 3 l b r t 1 9 495 10 0 505 where b r t the root zone lower limit at time t in m 1 2 if false equation a 1 2 example b r t 1 t c not applicable 2 determine the size of the change to the root zone equation a 2 example δ c r c r t 1 c r t δ cr 0 005 0 505 0 5 where c r t the height of the root zone soil column at time t in m 3 if there is a change in the root zone 3 1 if the change is positive soil and water content must be transferred from the upper zone to the root zone 3 1 1 determine the water content of the upper zone amount there maximum there equation a 3 1 1 example θ u w u t c u t e m 0 75 0 045 0 5 0 12 where θ u the water content of the medium pores in the upper zone in saturation w u t the height of the water column in the upper zone at time t in m c u t the height of the upper zone soil column at time t in m e m the medium pore specific yield porosity 3 1 2 determine the change to the upper zone s water column equation a 3 1 2 example δ w u δ c r θ u p m 0 00045 0 005 0 75 0 12 where δwu the change in height of the upper zone water column in m 3 1 3 transfer the water from the upper zone to the root zone and adopt the updated values for soil horizons 3 2 if the change is negative soil and water content must be transferred from the root zone to the upper zone same as above but with transfers from the root zone to the upper zone appendix b comparison of hydroman with other hydrological models b1 temporal dynamics of groundwater the evolution of groundwater depth under different climate scenarios and initial groundwater levels was simulated with hydroman and two alternative one dimensional vertical hydrological models hydrus 1d and guarda hydrus 1d pc progress is a public domain windows based modeling environment for analysis of water flow and solute transport in variably saturated porous media šimůnek et al 2005 which has been used in the study area to simulate groundwater dynamics nosetto et al 2015 guarda is a simplified excel based water budget model developed by mercau and jobbágy 2013 as a practical tool to simulate soil water content and groundwater depth in agricultural soils simulations were performed using weather records and soil parameters from pehuajó a representative location in the study area a landscape with 11 11 cells of 1 ha each was created it was assumed to be completely flat and the watershed was entirely contained within the landscape all simulations spanned an agricultural cycle from may 1st of year 0 to apr 31st of year 1 three different agricultural cycles were selected from the historical climate records according to total precipitations to perform simulations under dry 2008 09 542 mm average 1980 81 1024 mm and wet 1986 87 1306 mm agricultural cycles the land cover assumed for all simulations was soybean for the whole landscape these three climate scenarios were combined with three initial may 1st groundwater depths 0 5 2 0 and 3 5 m simulated daily water table depth from each model was compared because hydroman is not a 1d model groundwater levels at the center cell were analyzed to make the runs comparable across models the water table dynamics simulated by hydroman were very similar to that simulated by the other two models for most of the situations fig b1 this similarity suggests that hydroman captures the main hydrological processes that reproduce the dynamic patterns there were differences between the models in some cases specifically between hydroman and guarda fig b1 middle panel the differences can be tied to how each model represents some key hydrological processes for instance while guarda uses the empirical curve number approach to represent runoff this process is endogenously simulated in hydroman and hydrus as a result while in guarda there is always runoff hydroman does not produce runoff when the landscape is completely flat and the land cover is homogenous hydroman will produce runoff in heterogeneous landscape either for land cover or topography to evaluate if differences between hydroman and guarda were associated with the infiltration process effective rainfall 4 4 rainfall stored in the root zone that can be use by plants i e water not lost by deep percolation and or run off simulated by guarda was used as input data to hydroman the outputs from these simulations were much closer fig b2 although hydroman produced results very similar to hydrus the latter produced smoother trajectories of water table levels mainly for deep initial water table depth e g left lower panel fig b1 the difference in the dynamics of simulated water table may be tied to the way in which each model simulates vertical fluxes hydroman considers a cascade model and hydrus relies on richard s approach the conductivity approach tends to smooth trajectories especially when the soil layer above water table is wide fig b1 temporal dynamics of groundwater simulated by guarda hydroman and hydrus 1d in 9 scenarios resulting from the combination of rainfall amounts during the agricultural cycle dry average or wet climate and initial water table depth 0 5 2 or 3 5 m fig b1 fig b2 temporal dynamics of groundwater simulated with guarda and hydroman with two alternative inputs i normal or ii effective rainfall from guarda to compare with it in 3 scenarios resulting from the combination of average rainfall amounts during the agricultural cycle and initial water table depth 0 5 2 or 3 5 m fig b2 b2 spatial dynamics of groundwater the spatial dynamics of groundwater within a simplified landscape was simulated with hydroman and mike she models mike she is a deterministic spatially distributed physically based numerical model which couples surface and groundwater flows refsgaard and storm 1995 refsgaard et al 2010 this model had been calibrated and validated in the study area badano 2010 garcía et al 2017 2019 our simulations were specifically aimed to assess spatial variations in water table depth as result of horizontal water flows triggered by heterogeneous land uses i e with contrasting water consumption over the landscape the simulated landscape involved a square grid of 151 151 cells of 1 ha each cell the land cover assigned to the whole landscape was soybean except for an island of 31 31 cells at the center that was assigned to pasture a land cover with higher water consumption the simulation was performed using an average rainfall year 1981 82 for pehuajó also with a completely flat landscape soil related parameters were defined for each model to represent a typical soil in pehuajó the initial water table depth was set to 2 5 m in both models water table depth from each model lengthwise in the landscape was compared at the end of the season apr 30th 1982 hydroman was able to simulate spatial changes in groundwater levels in response to heterogeneous land covers pasture and soybean that were qualitatively similar to those produced by mike she fig b3 these different groundwater levels were triggered by the response to differential water uptake between two plant covers although the spatial pattern of water table levels was qualitatively similar between models there were quantitative differences in water table depth by the end of the simulation we hypothesized that these differences were likely associated with a variety of processes that differ in their representation in each model for instance crop transpiration is represented via the k cb coefficient in hydroman and via the leaf area index in mike she similarly some parameters characterizing soil properties and initial conditions are different in each model which prevent a perfect alignment between models although we could calibrate hydroman to close the gap with mike she outcomes by manipulating any of these variables we decided to maintain the original setting because our focus was on assessing relative spatial patterns and not in reproducing absolute groundwater levels fig b3 groundwater levels simulated by hydroman and mike she on a longitudinal section of the landscape the dashed lines mark the limits of the central island planted with pasture the rest of the landscape is planted with soybean fig b3 appendix c supplementary data the following is are the supplementary data to this article data profile data profile appendix c supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104641 
26049,to tackle fundamental scientific questions regarding health resilience and sustainability of water resources which encompass multiple disciplines researchers need to be able to easily access diverse data sources and to also effectively incorporate these data into heterogeneous models to address these cyberinfrastructure challenges a new sustainable and easy to use open data and open modeling framework called meta scientific modeling msm is developed msm addresses the challenges of accessing heterogeneous data sources via the open data architecture which facilitates integration of various external data sources data agents are used to handle remote data access protocols metadata standards and source specific implementations the open modeling architecture allows different models to be easily integrated into msm via model agents enabling direct heterogeneous model coupling msm adopts a graphical scientific workflow system vistrails and does not require re compiling or adding interface codes for any diverse model integration a study case is presented to illustrate the merit of msm graphical abstract image 1 keywords open architecture scientific workflow data source integration model coupling machine to machine automation reproducible process abbreviations msm meta scientific modeling mks multiscale kalman smoother noaa national oceanic and atmospheric administration opendap open source project for a network data access protocol vic variable infiltration capacity xdac data agent component service that offers the services to access external data making use of data agents it returns datasets as its results software data availability name author year first available size data format access vistrails new york university 2007 300 mb python language https www vistrails org index php main page ges disc through opendap nasa 2011 opendap https developer earthdata nasa gov opendap quickstart usgs water service usgs xml webservices http waterservices usgs gov noaa radar precipitation noaa 2004 shapefile https water weather gov precip archive https water weather gov precip downloads 1 introduction 1 1 context and motivation models are developed for various applications such as predictions of weather floods landslides erosions droughts water quality air quality climate variability evolution of landscape and pollutant transport within soil column and rivers to improve our understanding of the complex behaviors of the various processes e g physical hydrological atmospheric biological chemical and the interactions among them as well as to improve the accuracy and reliability of the models predictions and simulations researchers need to make an effective use of various available data across disciplines to improve theories algorithms models and validations however a large amount of such valuable data often goes unused due to the significant overhead of time and effort needed to discover access understand and process these heterogeneous data kannan et al 2000 mcphillips et al 2009 parada and liang 2004 ravindran et al 2010 salas and liang 2013 while a number of modeling systems exist for scientific communities bhat and jadhav 2010 bryant 2007 deluca et al 2008 peckham et al 2013 rajib et al 2016 salas et al 2012 most of them do not support directly accessing to heterogeneous data sources over the internet also the complexity of the existing models makes them difficulty to be shared and used by others consequently the strengths and limitations of these various developed models are not well evaluated understood and widely used 1 2 strategy for solution to address the aforementioned challenges we develop an open data and open model framework our approach is based on several fundamental concepts and strategies first we design an open system architecture which includes two types of open system interfaces by which individual models and heterogeneous data sources are connected to the framework through model agents and data agents respectively thus this open system architecture makes it easy for the individual models to be integrated into the framework by their model agents to access the different data sources by making use of the data agents our framework provides data agents for some popular sources like nasa opendap and radar data from noaa a data owner or user can also write his her own data agent if he she wants his her data to be widely disseminated to the community through this framework second we adopt a non proprietary workflow system that organizes the scientific tasks in a reproducible manner these tasks can be of different types including data retrieval data pre processing model execution model coupling and data visualization third we develop a system wide data fusion scheme enabling the user to fuse data from several data sources and or models in his her modeling exploration our proposed open data open model framework msm meta scientific modeling whose implementation is called msm has effectively addressed the drawbacks of the existing modeling systems and thus has the following unique features 1 other systems use proprietary workflows with preliminary functionalities dou et al 2008 in contrast the msm incorporates with an independent open source and graphical based workflow engine which is benefited by the future improvements of the generic open source workflow engine 2 other systems suffer the lack of access support to external data sources on the contrary the msm facilitates users to obtain data directly from popular sources such as nasa opendap and usgs web services by just dragging a component inside a working board area 3 the msm does not require a central administration and each modeler has the responsibility of his her own model and its corresponding model agent this makes msm de centralized and more sustainable than the approaches that require adaption and recompilation to be made by a central administration team 4 unlike other modeling systems the msm enables models to be freely connected with each other in the msm framework that is once the user has written a single agent for his her specific model to connect into the msm he she is able not only to access all the data sources but also to integrate it with other models already connected to the msm framework without any additional effort the remainder of this paper is organized as follows section 2 briefly overviews the relevant existing work and background section 3 presents the design of our framework and its implementation of the msm section 4 illustrates our framework s functionality and usability via examples section 5 presents an end to end modeling process to demonstrate the current version of msm framework finally section 6 gives our conclusions and planned future work 2 related works and background 2 1 existing systems there have been several efforts in developing different frameworks to integrate models to meet different needs in the broad earth science and environmental domains including open modeling interface openmi 1 1 https www openmi org gregersen et al 2007 knapen et al 2011 moore and tindall 2005 community surface dynamics modeling system csdms 2 2 https csdms colorado edu wiki main page peckham et al 2013 object modeling system oms 3 3 https alm engr colostate edu cb wiki 16961 ahuja et al 2005 interactive component modeling system icms 4 4 http www clw csiro au products icms index html vertessy et al 2002 earth system modeling framework esmf 5 5 https www earthsystemcog org projects esmf hill et al 2004 and community hydrological prediction system chps 6 6 http www nws noaa gov ohd hrl chps chps is a main hydrological modeling framework used by the noaa s river forecast centers rfcs its main hydrologic modeling software is fews flood early warning system krzhizhanovskaya et al 2011 werner et al 2013 all of these existing model integration systems have their strengths and shed lights on this important research area nevertheless these existing frameworks have several weaknesses which are briefly summarized below lack of data access as mainly focusing on modeling environments open data access is not considered in the existing modeling frameworks by design although a few of them e g fews support some data sources in general the access to data sources in those modeling frameworks relies on user s own application implementation for example as illustrated in csdms university of colorado boulder 2012 no data fusion data fusion for multiple datasets and or model results is not provided by the existing modeling frameworks preliminary workflow while many of these frameworks have some basic ad hoc workflow like schemes to link models a standard and sophisticated scientific graphical workflow engine is missing as a result workflow provenance management is not available deelman and chervenak 2008 lack of model source code transparency while the requirements on models to be linked to a framework vary from one framework to another most frameworks require the source code of the models for example csdms requires 1 to implement a basic modeling interface bmi for a model to become csdms compliant model which requires some refactoring of the model source code hutton et al 2014 and 2 to implement an additional component model interface cmi by csdms integration facility staff that wraps the csdms compliant model to be used in the csdms framework some frameworks are not centrally administrated such as openmi oms and esfm while others need central administration for framework development and use such as csdms and fews 2 2 desirable features table 1 shows a list of functionalities that are important for hydrological modeling systems it also compares the functionalities of the existing systems openmi gregersen et al 2007 knapen et al 2011 csdms peckham et al 2013 fews gijsbers 2010 werner et al 2013 oms ahuja et al 2005 icms rizzoli et al 1998 esmf hill et al 2004 with those from our msm framework the ones marked with an x in the column desirable are critical in terms of reducing the time spent by researchers in tedious activities such as codifying retrieving and administering data and or improving the modeling systems sustainability in the following the features of each category shown in table 1 are discussed models the first feature listed under this category in table 1 is the execution location which has been chosen to be individual local for our msm to save the time required to upload and manage remote information the choice of individual makes it easier to run models that are installed individually and locally but are not required at a centrally administrated system it also makes it easier for the user to add his her models to the framework without the need of a central team in other words the user does not need to wait for a centralized administration to have his her model integrated into the framework but can do it by himself herself regarding the programming language some existing systems e g icms and esmf require specific languages however the language in which a model is written should not be a restriction a desirable framework should be able to support models written in any languages by supporting the models in their compiled forms or at least to support a number of languages the framework should also be able to support the integration of not only the open source models but also the commercial models this feature is important since the commercial models usually do not provide source codes but they are often useful in research activities besides even though the re compilation is possible with the open source models it may not be always honored successfully this is because the difficulties of finding and or rebuilding dependencies as third party libraries of particular versions are enormous in many cases besides the re compiling and releasing processes would invalidate all the testing and verifications that a model has already achieved on the other hand when the added code is minimal it is not efficient to have the entire open source model be recompiled data sources with respect to the category of data sources it is desirable that the framework can retrieve the information directly from the external sources and make it usable to models learning retrieving downloading and administering these data usually take a considerable portion of the researchers work time thus a desirable framework should be able to help retrieve the data via the framework system itself and also allow the user to easily connect new data sources into the system fitting i o each model or data source has its own set of specific requirements of input and output formats in order to integrate models and data sources together the desirable framework should provide necessary conversions between their inputs and outputs to enable them fitting each other re scaling data in time and space provides such a glue facility to connect models with data sources and to link models with each other doing this manually would take a considerable portion of researchers time kouzes et al 2009 for a desirable framework this feature should be not only provided but also represented in a way that the user can easily use it for example through a graphical workflow instead of coding data fusion allows the user to fuse data from several data sources and or models that represent the same variable at the same time and for the same spatial area by having a data fusion feature available the researcher can analyze additional hypothesis finally the re gridding is also a desirable binding feature used to process the data from different sources that use disparate coordinate systems or resolutions data analysis even though the user may need to create complex views of the data using their preferred and or familiar tools a desirable framework should be able to provide the user a minimum number of functionalities to display spatial information for any given time step in that way the researcher can save time by having a quick graphical view of the results from his her work such as hypothesis testing data analyses model simulations etc and only needs to spend additional time to create graphic views using external tools for specifically chosen results data management creating and administering data folders detecting errors injected by accidentally deleted or moved files dealing with machine oriented data file names in thousands of files etc are not only a considerable workload for the researcher but also error prone due to its tediousness since this is a repetitive machine doable process manual execution as it is typically done at present not only distracts the researchers from doing their real research but also easily injects errors ma et al 2010 sonntag et al 2011 because of this a desirable framework should provide data management functionalities particularly from the very beginning when the data are retrieved from the data sources through the workflow and coupling process until the results are obtained and displayed or exported several techniques can be used to transfer data from one model to another some techniques are easier for the user to implement and modify the model integration with a reasonable model execution speed for research i e at a small scale but may not be sufficient for execution performance for a production system i e at a large scale like the daily operation at the national weather forecast offices other techniques may provide better execution performance but are more difficult to make changes or to have additional models integrated a desirable research framework should focus more on easy integration and user friendly experience because the goal is to help researchers to analyze various hypotheses and to conduct real research once a new hypothesis is discovered for example a second tool or the same tool with a different configuration can be used to thoroughly test the hypothesis in depth where the system s performance becomes more critical workflow tools to improve the understanding and explanation of the modeling results and to ensure a reproducible process of researcher s modeling work it is desirable to have the execution of his her modeling process controlled by a graphical workflow callaghan et al 2010 deelman et al 2009 a desirable workflow engine should provide the provenance service automatically to track the changes of the workflow itself barkstrom 2010 in this way the user can investigate the trace of data not only in the current workflow version but also in previous workflow versions and determine how the changes in the workflow affected the results of his her hypotheses ludäscher et al 2006 since storing such information is a repetitive task performing it manually would add a heavy workload to the researcher and be also error prone a desirable workflow engine should also be an open source and an independent tool since its maintenance and evolution would benefit the framework and the end user in addition the inputs and outputs of each component involved in a desirable workflow need to be graphically explicit to ensure that different modeling simulations correspond to different inputs and outputs and that they are clear and visible for the researcher it can be seen from table 1 that each of the existing hydrological modeling tools systems offers only some of the desirable features but not all of them also some of the existing systems in table 1 have their features only focused on certain specific categories e g openmi has more features in the categories of the models and workflow tools while fews has more features in the model category in general while most of the existing systems only offer the basic functionality in providing connectivity among models they do not support the other important functionalities including remote data retrieval transformations and traceability required for actual workflow execution without those important functionalities supported from the framework system the models cannot be easily connected to each other in a workflow with compatible time scale space scale units and or gridding geometry which has to be taken care of by users themselves as most of these systems do not provide support to access external data sources consequently the researcher has to manually download administer transform and feed the data into models adding more workload to the researcher and increasing the risks of injecting errors and none of the existing systems have a strategy to add any data source oriented plug ins in addition the existing systems do not provide any functionality to fuse datasets yet such capability of easily fusing different datasets is fundamentally important in this data rich era this is because oftentimes there are different techniques to measure or simulate the same data variables where each of them has its own strengths and weaknesses the researcher then has to either develop his her own code to fuse information from different data sources or use just one data source at a time while most existing systems provide visualization tools for viewing the results and conducting data analysis they have no graphical tools for controlling the workflow sequences this means that the user needs to deal with text or xml based workflow which is not only tedious but also error prone thus it is desirable to have user oriented graphical inputs and outputs allowing the user to graphically design the workflow davidson and freire 2008 wang et al 2009 from table 1 it can also be seen that most of the existing systems require recompiling the sources when new models are added this reduces the flexibility of the system because the researcher may become dependent on the central administration organization to have his her model connected in some cases the user is attempting to connect a model developed by a third party by requiring code changes and recompiling the user needs to contact the model authors and have them changing the code compiling testing and releasing another version before the model can get integrated into the system in the case of csdms for example the framework team keeps the central control of the source code of all the models connected this may make it easier for a researcher who just needs to use the models which are already connected to the system however if the researcher wants to connect his her own models and run simulations with his her own data the process becomes complex 3 the msm design 3 1 overall architecture we present our design and development of a novel open data open model framework as an integrated solution to provide researchers and practitioners with a sophisticated workflow controlled modeling environment that ensures traceability and reproducibility for hypothesis tests in hydrological studies from a top level design point of view our framework system msm is composed by a core referred to as msm core an interface with workflow engine data agents and model agents fig 1 basically msm interacts with the selected workflow engine through the workflow interface interacts with data sources through data agents and interacts with models through model agents in the overall architecture of our framework in fig 1 the msm core controls all the other components and reaches external plugged in models and connected remote data sources by the corresponding model and data agents respectively the msm core is connected to the workflow engine to provide end users with all workflow control functionality the msm core includes a data persistency service that can be used by all the msm components in particular an instance of the framework system is administered by an individual researcher who configures and runs it not by any centralized entity thus the msm framework allows the user researcher not only to easily access external data from diverse sources but also to easily and efficiently execute couple and evaluate intercompare various and complex models the former is achieved via the open data architecture while the latter is achieved via the open modeling architecture the open data architecture adopts a common internal data model and representation to facilitate the integration of various external data sources into the msm framework using data agents these data agents hide the heterogeneity of the external data sources and provide a common interface to the msm core the open modeling architecture allows different models or modules to be easily integrated into the msm framework via model agents the msm architectural design offers a general many to many connectivity between all individual models and external data sources instead of specific one to one pair wise connectivity in other words assume there are m heterogeneous data sources and n diverse models that need to be fully coupled and integrated in a modeling system to accomplish this task existing model frameworks would typically require mn n n 1 pair wise agents but the msm framework only requires m n agents due to its architecture design the number of m n agents represents the lowest linear complexity for such a model integration task in our msm framework the modeling processes are dynamically defined by the user through a workflow engine workflow provides the user with a capacity of defining the sequence of activities to be performed activities are user defined standalone tasks by which a user can easily build up any workflow sequence for his her modeling process each activity has to be pluggable with others and should not impose any implicit restrictions to the workflow sequence to this end activities have been defined with the following properties 1 each workflow activity has a well defined responsibility each activity is independent 2 no any hidden activity exists in any workflow all workflow activities must be explicitly specified and controlled by the user 3 there is no any additional communication channel for an activity other than its inputs and outputs loose coupling to be connected with other activities which are controlled only by the workflow engine 4 the activities are self sufficient as soon as the inputs are ready the activities are ready to be executed that is no other tasks need to be performed prior to or at the same time of their execution 5 the activities are stateless the memory is a responsibility of the persistency data management components with which the activity can use therefore once any activity finishes its execution and returns the outputs it must release any acquired resource or data that could be used by a subsequent execution to satisfy the above properties in our msm framework we introduce a general data abstract called msmdataset to ensure the type compatibility of any workflow activity input output connections this msmdataset is a data representation composed by a list of time steps and a 2 dimensional image per time step it is the only data abstract type apart from basic int boolean and string types that an activity can accept for its inputs and generate for its outputs our framework currently supports four types of activities in a workflow 1 data retrieval the framework automatically generates a graphical activity a box in the workflow for the corresponding data agent provided and pre configured by msm or added by the user 2 data transformation these are activities provided by the framework directly and performed by the core by executing an internal algorithm data fusion time space re scale change of units etc 3 model execution the framework automatically generates a graphical activity a box in the workflow for the corresponding model agent provided by the user or pre configured 4 data visualization even though the workflow engine can provide many of the visualization tools it requires the core to prepare the data to be reported the responsibility of the workflow control is to determine the sequence of activities and the inputs outputs for each activity in all cases the workflow will request the msm core to perform the activity for the given inputs and will send back the corresponding outputs once the activity is done the workflow can use its outputs as inputs for the subsequent activity most of the time for example the first activity defined in the workflow will be a retrieval of data from a data source the workflow control requests the core to execute such a task the core will call the data agent to execute the task the data agent will retrieve the data and store them using services offered by the core one of our design criteria is to have a general and flexible open system architecture so that our framework can be easily integrated with different open source workflow engines this way our msm framework can take the advantage of existing and future workflow engines that the scientific communities use or prefer and at the same time can also avoid any reinventing of the wheels in our current implementation of msm we select vistrails bavoil et al 2005 as the workflow engine this is because vistrails provides a nice and convenient graphical workflow interface in addition to its unique capabilities such as provenance and data visualization which serve well to the goals of our msm framework the other components in the msm framework shown in fig 1 are described below 1 data agents they are dynamically loaded components that are connected to external data sources through the internet and store retrieved information in msm using services provided by the core they are loaded at run time and msm comes with developed data agents for some popular data sources the framework automatically generates a workflow activity template per each data agent 2 model agents they are dynamically loaded components that are able to run external models the framework automatically generates a workflow activity template per each model agent a model agent performs the following three main steps preparing inputs the agent receives the inputs from the workflow i e msmdatasets and transforms them into the input files with the format needed by the model executing model the agent will call the model executable file storing outputs the agent reads the output files generated by the model and transforms them into msmdatasets then the agent uses the framework to store them 3 core data management this is a layer inside the msm core that provides persistency for the msmdatasets allowing other components to write datasets and read datasets created during previous workflow activities this component has a cache to improve its performance 3 2 open data our framework addresses the challenges of accessing multiple and heterogeneous external data sources via its open data architecture which adopts a common internal data model and representation in this architecture data sources are integrated into the system using data agents that handle all source specific implementations and remote data access protocols e g opendap web services metadata standards and source specific implementations thus abstracting the data sources heterogeneity and providing a common interface to the msm core system the open data architecture not only allows integrating external data sources in an abstract and extensible manner but also allows end users to load data agents dynamically at runtime without having to stop current operations or recompiling the entire system in this way end users can develop their custom data agents for immediate use by the workflow engine the framework s internal data model integrates a relational representation of the system s metadata and a non relational representation to store the actual data received from external sources and or the results produced from model computation the data model allows persisting data sets associated with gridded data as well as time series data all currently represented by the msmdataset structure we have developed and integrated two data agents into the framework see fig 2 which already covers a broad range of data sources and data access protocols nasa opendap gds and usgs rest web services for bringing in data from both gridded netcdf and point time series waterml services using the major cataloging services e g nasa ges disc 3 2 1 develop an agent for a data source to enable users to easily develop new data agents so as to add new data sources into the msm framework for their scientific explorations we have designed a generic data agent class it offers the generic obtain data method individual data agents inherit from the generic data agent and override the generic obtain data method which enables the use of a specific data retrieval protocol from the workflow the data agent also uses services from the generic data agent for the creation and edition of the output datasets simplifying the development of new data agents all data agents share the following basic responsibilities 1 securely contact the data offering server 2 download the data files to the local machine if they do not already exist and 3 read the data from the downloaded files based on their format s and create a new dataset if at some point during the downloading process the connection is interrupted the simulation workflow will stop in such a case the user can restart the workflow and msm will continue to download the data from where it last stopped from the data source since there will be a local copy of the data downloaded so far the user is free to delete these locally downloaded data or maps at any time to write the data agent the user has to create a text file including a class in python as outlined below image 3 after that the user can add in the obtain data function all the necessary codes to download the data and create the dataset object when the information is extracted and is ready to be stored in a dataset object the user can call for example the function create full dataset of the generic data agent which will ensure the proper building of the dataset object and the persistence of it image 4 3 2 2 register data agents into msm framework the data agents are added to the system by copying the folder with the agent s code into the upload folder of the framework the folder needs to be named exactly as the class representing the agent also the file containing the class needs to be named exactly as the class the folder may contain more folders and more python code files the system needs to be refreshed to generate the graphical representation of the agent in the open data list after that the agent will be visible in the graphical interface on the panel and can be considered successfully registered 3 3 open model to take the full advantages of the framework such as the m2m 7 7 m2m machine to machine automated data retrieval from popular data sources e g nasa data centers and usgs graphical workflow process provenance data transformations and rescaling data fusion and data visualizations researchers users need to connect their model agents into the msm framework there are two steps required to accomplish this 1 develop agents for their models and 2 register the agents into the framework 3 3 1 develop an agent for a model to enable users to easily develop their model agents so as to add their scientific models into the msm framework for their scientific explorations we have designed a generic agent class the generic agent declares the generic run model method individual model agents inherit from the generic agent and override the generic run model method which enables the invocation of a specific user model from the workflow the model agent uses services offered by the generic agent class to read the inputs from and write the outputs into the msm core database which simplifies the integration of a user s model into the framework this model agent is independent of the language used in writing the model that is the language used by the model can be in c c fortran python java etc to facilitate the model agent development by individual users we have also developed an agent development kit 8 8 the adk agent development kit is a set of libraries that contains the interfaces and utilities required to write compile and test an agent that contains only the basic api necessary to write and test an agent without the entire msm core and the workflow this makes it easier to set up the development environment to start writing and testing a model agent the responsibility of the model agent is to provide the steps to 1 read the inputs from the msm core and save the data into files from which the model can read 2 run the model and 3 read the model s output files and save the information into the msm core this is implemented by overriding the run model function to write the model agent the user has to create a text file including a class in python as outlined below image 5 after that the user can add in the run model function all the necessary codes to prepare the inputs execute the model and store the outputs to read variables from the database the user can call for example the function get time series of the genericagent which will return an array with the values of the time series for the dataset requested image 6 to write variables i e model outputs into the database the user can call the following provided functions image 7 the create dataset function serves to initialize a msmdataset and provides the dataset id the save timestep function saves a timestep inside the dataset both are provided by the genericagent the user also needs to implement the function getinputs the msm system will use such functions to create appropriate ports in the workflow activities 3 3 2 register agents into msm framework the model agents are added to the system by copying the folder with the agent s code to the upload folder of the framework the folder needs to be named exactly as the class representing the agent also the file containing the class needs to be named exactly as the class the folder may contain more folders and more python code files also the folder must contain the executable files required to run the model the workflow needs to be refreshed to generate the graphical representation of the agent after that the agent will be visible in the graphical interface and can be considered successfully registered 3 3 3 an example of agent to illustrate we describe the model agent written for the vic model cherkauer and lettenmaier 1999 liang et al 1996a 1996b 1994 liang and xie 2003 2001 parada and liang 2004 a land surface model that is widely used in the hydrology and water communities maurer et al 2002 nijssen et al 2001 the run model function for the vic model agent vicagent which performs all the responsibilities described above include 1 initialization of environment 2 preparation of input files in this part the vic model agent vicagent uses several functions to build the configuration and input files required by the vic model the vicagent prepares one input forcing file for each modeling cell of the study area over which the vic model is to be run this forcing file includes all the forcing variables needed to run vic since vic can be run at different levels of complexities which require different forcing data the users need to be careful with the different requirements on the forcing files for each case it is important to mention that when obtaining the information e g forcing data from the database the agent does not directly query the database instead the model agent only uses the services offered by the generic agent from the msm core such a design in the framework s architecture ensures a minimum complexity for the user when he she writes the model agent the vicagent will automatically create the parameter files e g soil vegetation and snow required for the model to run in case they do not exist yet in the working directory otherwise the model will use the existing parameter files this allows the user to perform model calibration manually through changing the values in the parameter files 3 execution in this step the vic s model agent builds the command that calls the vic executable with its given global parameter file for instance prompt vic config file myconfig txt input dir inputs files the command is sent to the operating system for its execution and the agent waits until the vic model run is completed at which time the output and error streams if any of the vic model are directly sent back to the console of msm which is visualized in the console of vistrails 4 processing of outputs once the command is executed the agent processes the output files for each of the vic model s output variables vic produces results in time series if it is run with a choice of time first then space because of that the agent needs to open all of the output files one per cell and reads all of them for each time step in order to generate area images and store them for each time step in the output dataset in msm to save this in the database the agent again uses the services offered by the generic agent from the msm core 3 4 data management layer the persistence of information in msm is implemented as an in memory and local data caching featuring a non relational database scheme that supports high throughput our data management facilitates caching the retrieved data storing previous results and making the task of coupling different models more efficient where only a dataset s identifier is passed among coupled models our framework persists metadata information msmdatasets and remote cached data the metadata contains configuration information physical variables used by the workflow activities and the inventory by id of msmdatasets the msmdatasets storage in our framework contains the time steps which can be the big data volume each time step contains a reference to the msmdataset it belongs to and a document the data oriented structure with a 2d image the remote cached data are useful in storing raw data received from external data sources in this way the data agents do not have to download the same data every time the execution repeats they can reuse the data even when the researcher tests a slightly different hypothesis allowing the system to work offline 4 implementation the current version of our open data and open model msm prototype is implemented in python and integrated with vistrails at present the msm prototype supports various components summarized in table 2 the functions of the msm framework described in table 2 are presented below 4 1 graphical workflow the msm runs inside vistrails an open source of graphical data workflow that deals with control of the sequence of activities the versions provenance and visualization tools see fig 3 during execution vistrails will start to analyze the activities of the workflow for each one vistrails will track back the origin of the required inputs such tracking is repeated until tasks without inputs are found with this analysis vistrails marks and detects all the required tasks for execution unmarked tasks are not executed 4 2 retrieving data the open data agents see fig 4 can be used to retrieve data and create msmdatasets each data agent can define its own inputs and they can produce one or more datasets using the already developed data agents msm can retrieve opendap information from nasa and access data from usgs using web services in case the data retrieval is interrupted msm is capable of restarting downloading the data from where the last time step downloaded was this is done not only to reduce the time it takes to retrieve the information into the local machine but to resolve the internet interruption problems the user is free to delete these locally downloaded maps or datasets from his or her machine 4 3 provenance the provenance is a vistrails functionality from which msm benefits it keeps track of all of the executions from all versions of the workflow it helps users find and review previous executions the graphical configuration and the potential errors each execution is identified by the name of the version which is labeled in the history tab and the start and end time fig 5 shows a failed and a successful execution the color code shown in the upper right side of the screen shot each using a different version of the workflow the row that shows the execution can be expanded to show the list of components used with the execution time completion condition and whether it was cached or not 4 4 re scale space and re gridding the re gridding component see fig 6 transforms a dataset from its original spatial configuration to a desired target configuration the spatial configuration is defined by 1 shape of the cells although the shapes of the data cells are in squares most of the times they can also be in rectangular or rhomboidal shapes in the case of the radar data each cell is a different tetragon 2 resolution size of the cells 3 borders starting point even when two grids have the same shape and resolution if their borders are not the same their spatial configurations will not be the same the re gridding module first identifies the portions of the original data cells that are located within the study area i e represented by destination cells then it computes the data values for these destination cells using an areal interpolation method whenever the data cells and the destination cells do not match with each other in terms of spatial resolution shapes or borders 4 5 re scale time using the msmtimerescale component see fig 7 the msmdatasets can be re scaled to the time resolution required by a model or another input this component can use one of the following aggregation functions average maximum and minimum it also interpolates when data is unavailable in a required timestep 4 6 fusion of datasets using the mks parada and liang 2004 framework the msmdatasets can be fused when more than one source is included in an analysis for a given physical variable see fig 8 for example if precipitation data are available from nasa opendap and from radar they can be fused to form a single precipitation input to be used by a model 4 7 running models the workflow creates a graphical component for each model agent registered in the msm framework fig 9 shows that two models are registered in the msm framework one model agent for the vic model and the other one for the routing model see highlighted square the msm framework creates graphical inputs and outputs as defined in the model agents for vic model see fig 10 4 8 coupling models the user can couple the components using any of the available ports in the way he she desires because all components in msm accept and return msmdatasets as shown in fig 11 where the vic model is coupled to a routing model through their corresponding model agents vicagent and routingagent in this example the vicagent outputs its baseflow and surface runoff to be used as inputs for the routing model agent this is the way model agents interact with each other in msm from the workflow perspective new model agents implemented by the users need to clearly specify the datasets and units required on each port since not all models provide outputs for every single time step some preprocessing may be necessary for models appropriate interactions with each other one solution offered by msm is to use the msmtimerescale component to modify the temporal granularity of the datasets flowed between models another possibility involves the usage of the iterate component see fig 21 to perform a full spatial simulation for a single time step this way the user can create a time series with the snapshots of each simulation a user can also modify his her particular model in order to accommodate a time step wise integration with other models 4 9 adding new data agents the msm framework can be expanded to access data from other data sources by adding new corresponding data agents created by users after writing a data agent the user just needs to copy the code into a folder provided by the framework as described in sections 3 2 1 and 3 2 2 4 10 visualization of results the msm makes use of the vistrails visualization tools to show 2d images in time point time series and snapshots of variables for a given time fig 12 illustrates the time series plots generated using the msmtimerescale component shown in fig 7 4 11 loading local information fig 13 shows that data stored locally in files can be loaded into the msm framework using the functions built in msm after the local data are loaded into the msm framework they can be accessed just by using the id of the dataset 5 a modeling example in this section we present an end to end hydrological modeling example to demonstrate how the msm framework can facilitate modeling with complex data retrieval and processing it in an automated manner it starts with retrieving precipitation wind and temperature from the nasa opendap data sources which follows by running the vic model in its water balance mode to compute the water budget related variables such as evapotranspiration soil moisture and runoff then the vic simulated runoff time series is used as an input to a routing model the example finishes by comparing the routed discharge based on the vic simulation with the usgs measured streamflow data which is automatically read into the msm framework from the usgs website this is a typical hydrological modeling use case scenario which involves retrieving the weather forcing data needed for running a sophisticated model executing it and comparing the model simulation results with observations compared to the typical modeling practice in the hydrology community the main difference shown in this example is that all of those tasks are done automatically under the msm framework with machine to machine communication for data retrieval from external data sources this example also demonstrates several important features of the msm including using the modules of open data open model mks based data fusion and visualization fig 14 shows the study area of the example fig 15 shows the selected watershed and its river network 5 1 configuration of the workflow the first step is to set up the components to retrieve various types of information from the corresponding data sources precipitation temperature and wind from nldas nasa for example when vic is run in its water balance mode fig 16 shows the workflow designed for conducting this modeling task in which each component for retrieving the forcing data is created by dragging the corresponding data agent component from the open data list on the panel shown in fig 17 into the working area in addition the vicagent component is dragged from the open model list into the working area as well as shown in fig 16 for each of the three retrievedatasetagent components the configuration inputs showing in the right column of fig 16 next to the work area are filled with values shown in table 3 below note that some of the fields listed in table 3 cannot be seen fig 16 to see all of them the user just needs to scroll down using the arrow in the right bottom corner of the right panel shown in fig 16 next the vic model is set up by connecting the vicagent component to the appropriate input data sources as well as the output displays shown in fig 16 for the model input connection the dataset id output ports from the retrievedatasetagent components are connected to the vicagent input ports we note that vic requires the min and max temperature as inputs but the same variable temperature is used in this case for simplicity the dirtodataset component is used here to load the static soil parameters used by vic if it is not provided vic will use the default values this component reads all the files from a folder and then creates a map of the specified study area for each file read in each such file contains a 2d matrix corresponding to the modeling grids over the study area for a time step since the soil parameters are static and thus they are stored as a one time step image the component also has other input ports that can be used to provide information such as the coordinates and the desired scale but in this case the information of coordinates and desired scale is received from the retrievedataset component for the model output connections two different functions msmshowdataset and msmshowplot are used to illustrate two types of visualization for the model simulation results the msmshowdataset is connected to the soil moisture output of the vicagent to view vic generated soil moisture results as an image while the msmshowplot is connected to the evapotranspiration output to view it as a time series more specifically once the computation of the vic model is finished the soil moisture output will be shown as an image for each time step whereas the evapotranspiration output will be shown as a time series plot the evapotranspiration output is being re scaled to scale zero to show the averaged evapotranspiration of the study area as a time series where the msmmks component is used to achieve the areal average through the rescaling operation based on the mks algorithm 5 2 execution the execution of the workflow starts when the user clicks the execute button shown in the 2nd top row of the vistrails window see fig 13 the retrievedataset components will attempt to automatically download the information from the specified data sources if the data to be downloaded are too large the msm component will retrieve it in chunks of one time step each if the communication is lost at any time the user can re run the workflow and the components will continue downloading the data from the last time step it was saved before the vic model component starts all the retrievedataset components and the dirtodataset must have been finished they will provide the dataset ids for all the forcing inputs and the model parameters the vicagent will then use such dataset ids to create the inputs run vic and wait for it to finish then the vicagent will read the vic outputs and save them as datasets vicagent will send the dataset ids of the outputs to the visualization components to generate plots the execution of the retrievedatasetagent components is completed when all the information specified is downloaded only at that point the execution of the subsequent component vicagent is invoked vistrails has a color code for the workflow boxes shown in the working area e g see the snapshot shown in fig 18 during an execution phase for example vistrails will show green for the boxes already computed yellow for the boxes under execution orange for the boxes waiting for the preceded boxes to complete gray for the boxes that have not yet been started or even considered for execution red for the boxes that failed and blue for the boxes that cannot be executed because of failures in the inputs fig 18 shows a few different statuses of the boxes during the execution phase of one workflow case it is worth mentioning that these color indicators are different from the colors used for the workflows saved in the provenance as shown in fig 5 5 3 results generated by the vic model the vic model with a general vicagent generates more than 160 output variables for this specific illustration the vicagent is configured to generate only 2 outputs soil moisture and evapotranspiration fig 19 shows the vic model simulated soil moisture plotted as an image per time step for the study area and for eighteen consecutive time steps the vic simulated evapotranspiration is averaged over the study area for each time step and is shown in fig 20 as a time series in order to generate such time series the vic results for the study area were re scaled to scale zero using the mks component to obtain the average in this example we further illustrate how to change the configuration during the task execution in a timestep by timestep fashion for instance the execution described above has an overall retrieval phase in which all the inputs are downloaded for the entire simulation period before the vicagent is executed this approach is widely used in model applications when using historical data and is called time first then space however in the forecast applications with real time data a model needs to be run one step at a time for the entire study area and then move on to the next time step in an iterative fashion in other words one needs to download the model input data from each data source for only one or a few timesteps each time then run the model for that or those time step s for the entire study area then download the input data again for another time step or few time steps and then run the model for the new time step or new time steps again etc to achieve this the user can use the iterative functionality developed in msm that is by using the configuration with an iterative approach it is possible to control the tasks executed at each time step or even repeat a set of activities until the convergence is reached before moving forward the next time step the readability of such workflow can be improved by using sub workflows this is a vistrails feature that allows the user to group a set of modules to make them usable as an entire new aggregated module this new component can be used as a single box in other workflows in that way workflows with many modules become simpler and organized in a hierarchical way for easier understanding figs 21 and 22 illustrate the use of the iterative function we developed in conjunction with the sub workflow feature of vistrails running the vic model coupled to a routing scheme specifically fig 21 shows the main workflow after grouping some of the activities into the one timestep box and using the looping component i e iterate the measured streamflow is also included in this workflow through the timeseriesfiletodataset component in this way the vic model simulated runoff after routing from the msm framework can be compared with the usgs measured streamflows the iterative nature of this workflow is accomplished through the iterate component which makes repetitive use of the task named one timestep the one timestep box in fig 21 represents a subworkflow which is shown in fig 22 this component contains all the tasks needed to be performed at each time step it starts by setting the looping parameters time per step number of steps and initial time then retrieves all the inputs subworkflow swf retrieving then runs the vic model vicagent and then sends the surface runoff and baseflow outputs to the routing model subworkflow swf routing at the end of the execution of this subworkflow one can compare the model simulated streamflows i e after the vic and routing models with the usgs measured ones in addition the model results can also be saved as text files via the component datasettotimeseriesfile shown in fig 22 such saved model simulated results can be used for further analysis or other purposes by the user for instance the vic model results obtained here are based on the default vic model parameters no calibration for the model parameters is conducted if one wants to do model calibration and compare the results one can save the results for later comparison studies the saved results can also be plotted with different software tools at the user s preference the vic routing model simulated results shown in fig 23 are obtained by running the vic model with default parameters plus the routing model without conducting any parameter calibration such a plot is generated by the msmshowchart component in msm 6 conclusions the fields of geosciences are entering a new era of big data in which physically based computational models with easy access to and use of increasingly available and diverse data are fundamentally important for scientific explorations our presented open data open modeling framework innovatively combines open data access and open modeling framework together and hence simultaneously addresses several critical issues faced by the broad community 1 direct open machine to machine m2m access of data to models from external data sources 2 graphical scientific workflow environment for scientists 3 easy model sharing and heterogeneous diverse model couplings without the need to share or change model source codes 4 no required central administration of shared models and the modeling framework system 5 data fusion of datasets from different sources and or computational model outputs 6 provenance management for reproducible computing and 7 data exploration and visualization these seven challenges have been repeatedly identified and highlighted by the geosciences communities the unique features of the presented open data open modeling framework make it very suitable as an integrated solution for general geoscientists to overcome the above challenges in their explorations the prototype system of our framework msm has successfully demonstrated its usefulness and effectiveness in various aspects of scientific modeling activities the openness of our framework by design indicates that when a user integrates his her model s into msm the impact of the integration process on user s model is none since there is no inter dependency between the msm framework and the model codes moreover the approach of the integration of an open scientific workflow engine i e vistrails into our framework provides a unique provenance management among other desirable graphical workflow features which directly facilitates reproducibility study in model couplings and thus is critical for users research and its reliability our plan of future work includes continuing to add more external data sources into the msm such as hydro meteorological datasets offered by nasa nldas north american land data assimilation system and ncaldas which are composites of measurements from land stations and model simulations as well as the satellite datasets like gpm for precipitation and smap for soil moisture in addition in the near future we will add more noaa datasets such as nam north american mesoscale forecast system and gfs global forecast system which are datasets from the model forecasts also there are plans to add more computing facility choices e g high performance computing or cloud computing into the msm framework for users to select based on the demand of each workflow activity at present we are developing new model agents to integrate models like the distributed hydrology soil and vegetation model dhsvm and the ph redox equilibrium model in c phreeqc into the msm system moreover a newer version of vic vic5 0 is being integrated to msm we are also working on developing generic model agent tools to help the user to develop his her own model agent s with little to no coding to integrate the model s of the user s choices into msm our framework software msm is intended to be made available to the geosciences community as an open source at its due course part of this work involves making it available on the ubuntu operative system since the msm has only been fully tested on windows 10 os so far declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the u s national science foundation under ear 1245067 and oac 1835785 to the university of pittsburgh and under ear 1245171 and oac 1835817 to indiana university purdue university indianapolis iupui respectively we would like to thank the support from thomas adams jerad bales richard hooper steve kempler pedro restrepo and william teng the second author also acknowledges the support from the william kepler whiteford professorship from the university of pittsburgh appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104622 
26049,to tackle fundamental scientific questions regarding health resilience and sustainability of water resources which encompass multiple disciplines researchers need to be able to easily access diverse data sources and to also effectively incorporate these data into heterogeneous models to address these cyberinfrastructure challenges a new sustainable and easy to use open data and open modeling framework called meta scientific modeling msm is developed msm addresses the challenges of accessing heterogeneous data sources via the open data architecture which facilitates integration of various external data sources data agents are used to handle remote data access protocols metadata standards and source specific implementations the open modeling architecture allows different models to be easily integrated into msm via model agents enabling direct heterogeneous model coupling msm adopts a graphical scientific workflow system vistrails and does not require re compiling or adding interface codes for any diverse model integration a study case is presented to illustrate the merit of msm graphical abstract image 1 keywords open architecture scientific workflow data source integration model coupling machine to machine automation reproducible process abbreviations msm meta scientific modeling mks multiscale kalman smoother noaa national oceanic and atmospheric administration opendap open source project for a network data access protocol vic variable infiltration capacity xdac data agent component service that offers the services to access external data making use of data agents it returns datasets as its results software data availability name author year first available size data format access vistrails new york university 2007 300 mb python language https www vistrails org index php main page ges disc through opendap nasa 2011 opendap https developer earthdata nasa gov opendap quickstart usgs water service usgs xml webservices http waterservices usgs gov noaa radar precipitation noaa 2004 shapefile https water weather gov precip archive https water weather gov precip downloads 1 introduction 1 1 context and motivation models are developed for various applications such as predictions of weather floods landslides erosions droughts water quality air quality climate variability evolution of landscape and pollutant transport within soil column and rivers to improve our understanding of the complex behaviors of the various processes e g physical hydrological atmospheric biological chemical and the interactions among them as well as to improve the accuracy and reliability of the models predictions and simulations researchers need to make an effective use of various available data across disciplines to improve theories algorithms models and validations however a large amount of such valuable data often goes unused due to the significant overhead of time and effort needed to discover access understand and process these heterogeneous data kannan et al 2000 mcphillips et al 2009 parada and liang 2004 ravindran et al 2010 salas and liang 2013 while a number of modeling systems exist for scientific communities bhat and jadhav 2010 bryant 2007 deluca et al 2008 peckham et al 2013 rajib et al 2016 salas et al 2012 most of them do not support directly accessing to heterogeneous data sources over the internet also the complexity of the existing models makes them difficulty to be shared and used by others consequently the strengths and limitations of these various developed models are not well evaluated understood and widely used 1 2 strategy for solution to address the aforementioned challenges we develop an open data and open model framework our approach is based on several fundamental concepts and strategies first we design an open system architecture which includes two types of open system interfaces by which individual models and heterogeneous data sources are connected to the framework through model agents and data agents respectively thus this open system architecture makes it easy for the individual models to be integrated into the framework by their model agents to access the different data sources by making use of the data agents our framework provides data agents for some popular sources like nasa opendap and radar data from noaa a data owner or user can also write his her own data agent if he she wants his her data to be widely disseminated to the community through this framework second we adopt a non proprietary workflow system that organizes the scientific tasks in a reproducible manner these tasks can be of different types including data retrieval data pre processing model execution model coupling and data visualization third we develop a system wide data fusion scheme enabling the user to fuse data from several data sources and or models in his her modeling exploration our proposed open data open model framework msm meta scientific modeling whose implementation is called msm has effectively addressed the drawbacks of the existing modeling systems and thus has the following unique features 1 other systems use proprietary workflows with preliminary functionalities dou et al 2008 in contrast the msm incorporates with an independent open source and graphical based workflow engine which is benefited by the future improvements of the generic open source workflow engine 2 other systems suffer the lack of access support to external data sources on the contrary the msm facilitates users to obtain data directly from popular sources such as nasa opendap and usgs web services by just dragging a component inside a working board area 3 the msm does not require a central administration and each modeler has the responsibility of his her own model and its corresponding model agent this makes msm de centralized and more sustainable than the approaches that require adaption and recompilation to be made by a central administration team 4 unlike other modeling systems the msm enables models to be freely connected with each other in the msm framework that is once the user has written a single agent for his her specific model to connect into the msm he she is able not only to access all the data sources but also to integrate it with other models already connected to the msm framework without any additional effort the remainder of this paper is organized as follows section 2 briefly overviews the relevant existing work and background section 3 presents the design of our framework and its implementation of the msm section 4 illustrates our framework s functionality and usability via examples section 5 presents an end to end modeling process to demonstrate the current version of msm framework finally section 6 gives our conclusions and planned future work 2 related works and background 2 1 existing systems there have been several efforts in developing different frameworks to integrate models to meet different needs in the broad earth science and environmental domains including open modeling interface openmi 1 1 https www openmi org gregersen et al 2007 knapen et al 2011 moore and tindall 2005 community surface dynamics modeling system csdms 2 2 https csdms colorado edu wiki main page peckham et al 2013 object modeling system oms 3 3 https alm engr colostate edu cb wiki 16961 ahuja et al 2005 interactive component modeling system icms 4 4 http www clw csiro au products icms index html vertessy et al 2002 earth system modeling framework esmf 5 5 https www earthsystemcog org projects esmf hill et al 2004 and community hydrological prediction system chps 6 6 http www nws noaa gov ohd hrl chps chps is a main hydrological modeling framework used by the noaa s river forecast centers rfcs its main hydrologic modeling software is fews flood early warning system krzhizhanovskaya et al 2011 werner et al 2013 all of these existing model integration systems have their strengths and shed lights on this important research area nevertheless these existing frameworks have several weaknesses which are briefly summarized below lack of data access as mainly focusing on modeling environments open data access is not considered in the existing modeling frameworks by design although a few of them e g fews support some data sources in general the access to data sources in those modeling frameworks relies on user s own application implementation for example as illustrated in csdms university of colorado boulder 2012 no data fusion data fusion for multiple datasets and or model results is not provided by the existing modeling frameworks preliminary workflow while many of these frameworks have some basic ad hoc workflow like schemes to link models a standard and sophisticated scientific graphical workflow engine is missing as a result workflow provenance management is not available deelman and chervenak 2008 lack of model source code transparency while the requirements on models to be linked to a framework vary from one framework to another most frameworks require the source code of the models for example csdms requires 1 to implement a basic modeling interface bmi for a model to become csdms compliant model which requires some refactoring of the model source code hutton et al 2014 and 2 to implement an additional component model interface cmi by csdms integration facility staff that wraps the csdms compliant model to be used in the csdms framework some frameworks are not centrally administrated such as openmi oms and esfm while others need central administration for framework development and use such as csdms and fews 2 2 desirable features table 1 shows a list of functionalities that are important for hydrological modeling systems it also compares the functionalities of the existing systems openmi gregersen et al 2007 knapen et al 2011 csdms peckham et al 2013 fews gijsbers 2010 werner et al 2013 oms ahuja et al 2005 icms rizzoli et al 1998 esmf hill et al 2004 with those from our msm framework the ones marked with an x in the column desirable are critical in terms of reducing the time spent by researchers in tedious activities such as codifying retrieving and administering data and or improving the modeling systems sustainability in the following the features of each category shown in table 1 are discussed models the first feature listed under this category in table 1 is the execution location which has been chosen to be individual local for our msm to save the time required to upload and manage remote information the choice of individual makes it easier to run models that are installed individually and locally but are not required at a centrally administrated system it also makes it easier for the user to add his her models to the framework without the need of a central team in other words the user does not need to wait for a centralized administration to have his her model integrated into the framework but can do it by himself herself regarding the programming language some existing systems e g icms and esmf require specific languages however the language in which a model is written should not be a restriction a desirable framework should be able to support models written in any languages by supporting the models in their compiled forms or at least to support a number of languages the framework should also be able to support the integration of not only the open source models but also the commercial models this feature is important since the commercial models usually do not provide source codes but they are often useful in research activities besides even though the re compilation is possible with the open source models it may not be always honored successfully this is because the difficulties of finding and or rebuilding dependencies as third party libraries of particular versions are enormous in many cases besides the re compiling and releasing processes would invalidate all the testing and verifications that a model has already achieved on the other hand when the added code is minimal it is not efficient to have the entire open source model be recompiled data sources with respect to the category of data sources it is desirable that the framework can retrieve the information directly from the external sources and make it usable to models learning retrieving downloading and administering these data usually take a considerable portion of the researchers work time thus a desirable framework should be able to help retrieve the data via the framework system itself and also allow the user to easily connect new data sources into the system fitting i o each model or data source has its own set of specific requirements of input and output formats in order to integrate models and data sources together the desirable framework should provide necessary conversions between their inputs and outputs to enable them fitting each other re scaling data in time and space provides such a glue facility to connect models with data sources and to link models with each other doing this manually would take a considerable portion of researchers time kouzes et al 2009 for a desirable framework this feature should be not only provided but also represented in a way that the user can easily use it for example through a graphical workflow instead of coding data fusion allows the user to fuse data from several data sources and or models that represent the same variable at the same time and for the same spatial area by having a data fusion feature available the researcher can analyze additional hypothesis finally the re gridding is also a desirable binding feature used to process the data from different sources that use disparate coordinate systems or resolutions data analysis even though the user may need to create complex views of the data using their preferred and or familiar tools a desirable framework should be able to provide the user a minimum number of functionalities to display spatial information for any given time step in that way the researcher can save time by having a quick graphical view of the results from his her work such as hypothesis testing data analyses model simulations etc and only needs to spend additional time to create graphic views using external tools for specifically chosen results data management creating and administering data folders detecting errors injected by accidentally deleted or moved files dealing with machine oriented data file names in thousands of files etc are not only a considerable workload for the researcher but also error prone due to its tediousness since this is a repetitive machine doable process manual execution as it is typically done at present not only distracts the researchers from doing their real research but also easily injects errors ma et al 2010 sonntag et al 2011 because of this a desirable framework should provide data management functionalities particularly from the very beginning when the data are retrieved from the data sources through the workflow and coupling process until the results are obtained and displayed or exported several techniques can be used to transfer data from one model to another some techniques are easier for the user to implement and modify the model integration with a reasonable model execution speed for research i e at a small scale but may not be sufficient for execution performance for a production system i e at a large scale like the daily operation at the national weather forecast offices other techniques may provide better execution performance but are more difficult to make changes or to have additional models integrated a desirable research framework should focus more on easy integration and user friendly experience because the goal is to help researchers to analyze various hypotheses and to conduct real research once a new hypothesis is discovered for example a second tool or the same tool with a different configuration can be used to thoroughly test the hypothesis in depth where the system s performance becomes more critical workflow tools to improve the understanding and explanation of the modeling results and to ensure a reproducible process of researcher s modeling work it is desirable to have the execution of his her modeling process controlled by a graphical workflow callaghan et al 2010 deelman et al 2009 a desirable workflow engine should provide the provenance service automatically to track the changes of the workflow itself barkstrom 2010 in this way the user can investigate the trace of data not only in the current workflow version but also in previous workflow versions and determine how the changes in the workflow affected the results of his her hypotheses ludäscher et al 2006 since storing such information is a repetitive task performing it manually would add a heavy workload to the researcher and be also error prone a desirable workflow engine should also be an open source and an independent tool since its maintenance and evolution would benefit the framework and the end user in addition the inputs and outputs of each component involved in a desirable workflow need to be graphically explicit to ensure that different modeling simulations correspond to different inputs and outputs and that they are clear and visible for the researcher it can be seen from table 1 that each of the existing hydrological modeling tools systems offers only some of the desirable features but not all of them also some of the existing systems in table 1 have their features only focused on certain specific categories e g openmi has more features in the categories of the models and workflow tools while fews has more features in the model category in general while most of the existing systems only offer the basic functionality in providing connectivity among models they do not support the other important functionalities including remote data retrieval transformations and traceability required for actual workflow execution without those important functionalities supported from the framework system the models cannot be easily connected to each other in a workflow with compatible time scale space scale units and or gridding geometry which has to be taken care of by users themselves as most of these systems do not provide support to access external data sources consequently the researcher has to manually download administer transform and feed the data into models adding more workload to the researcher and increasing the risks of injecting errors and none of the existing systems have a strategy to add any data source oriented plug ins in addition the existing systems do not provide any functionality to fuse datasets yet such capability of easily fusing different datasets is fundamentally important in this data rich era this is because oftentimes there are different techniques to measure or simulate the same data variables where each of them has its own strengths and weaknesses the researcher then has to either develop his her own code to fuse information from different data sources or use just one data source at a time while most existing systems provide visualization tools for viewing the results and conducting data analysis they have no graphical tools for controlling the workflow sequences this means that the user needs to deal with text or xml based workflow which is not only tedious but also error prone thus it is desirable to have user oriented graphical inputs and outputs allowing the user to graphically design the workflow davidson and freire 2008 wang et al 2009 from table 1 it can also be seen that most of the existing systems require recompiling the sources when new models are added this reduces the flexibility of the system because the researcher may become dependent on the central administration organization to have his her model connected in some cases the user is attempting to connect a model developed by a third party by requiring code changes and recompiling the user needs to contact the model authors and have them changing the code compiling testing and releasing another version before the model can get integrated into the system in the case of csdms for example the framework team keeps the central control of the source code of all the models connected this may make it easier for a researcher who just needs to use the models which are already connected to the system however if the researcher wants to connect his her own models and run simulations with his her own data the process becomes complex 3 the msm design 3 1 overall architecture we present our design and development of a novel open data open model framework as an integrated solution to provide researchers and practitioners with a sophisticated workflow controlled modeling environment that ensures traceability and reproducibility for hypothesis tests in hydrological studies from a top level design point of view our framework system msm is composed by a core referred to as msm core an interface with workflow engine data agents and model agents fig 1 basically msm interacts with the selected workflow engine through the workflow interface interacts with data sources through data agents and interacts with models through model agents in the overall architecture of our framework in fig 1 the msm core controls all the other components and reaches external plugged in models and connected remote data sources by the corresponding model and data agents respectively the msm core is connected to the workflow engine to provide end users with all workflow control functionality the msm core includes a data persistency service that can be used by all the msm components in particular an instance of the framework system is administered by an individual researcher who configures and runs it not by any centralized entity thus the msm framework allows the user researcher not only to easily access external data from diverse sources but also to easily and efficiently execute couple and evaluate intercompare various and complex models the former is achieved via the open data architecture while the latter is achieved via the open modeling architecture the open data architecture adopts a common internal data model and representation to facilitate the integration of various external data sources into the msm framework using data agents these data agents hide the heterogeneity of the external data sources and provide a common interface to the msm core the open modeling architecture allows different models or modules to be easily integrated into the msm framework via model agents the msm architectural design offers a general many to many connectivity between all individual models and external data sources instead of specific one to one pair wise connectivity in other words assume there are m heterogeneous data sources and n diverse models that need to be fully coupled and integrated in a modeling system to accomplish this task existing model frameworks would typically require mn n n 1 pair wise agents but the msm framework only requires m n agents due to its architecture design the number of m n agents represents the lowest linear complexity for such a model integration task in our msm framework the modeling processes are dynamically defined by the user through a workflow engine workflow provides the user with a capacity of defining the sequence of activities to be performed activities are user defined standalone tasks by which a user can easily build up any workflow sequence for his her modeling process each activity has to be pluggable with others and should not impose any implicit restrictions to the workflow sequence to this end activities have been defined with the following properties 1 each workflow activity has a well defined responsibility each activity is independent 2 no any hidden activity exists in any workflow all workflow activities must be explicitly specified and controlled by the user 3 there is no any additional communication channel for an activity other than its inputs and outputs loose coupling to be connected with other activities which are controlled only by the workflow engine 4 the activities are self sufficient as soon as the inputs are ready the activities are ready to be executed that is no other tasks need to be performed prior to or at the same time of their execution 5 the activities are stateless the memory is a responsibility of the persistency data management components with which the activity can use therefore once any activity finishes its execution and returns the outputs it must release any acquired resource or data that could be used by a subsequent execution to satisfy the above properties in our msm framework we introduce a general data abstract called msmdataset to ensure the type compatibility of any workflow activity input output connections this msmdataset is a data representation composed by a list of time steps and a 2 dimensional image per time step it is the only data abstract type apart from basic int boolean and string types that an activity can accept for its inputs and generate for its outputs our framework currently supports four types of activities in a workflow 1 data retrieval the framework automatically generates a graphical activity a box in the workflow for the corresponding data agent provided and pre configured by msm or added by the user 2 data transformation these are activities provided by the framework directly and performed by the core by executing an internal algorithm data fusion time space re scale change of units etc 3 model execution the framework automatically generates a graphical activity a box in the workflow for the corresponding model agent provided by the user or pre configured 4 data visualization even though the workflow engine can provide many of the visualization tools it requires the core to prepare the data to be reported the responsibility of the workflow control is to determine the sequence of activities and the inputs outputs for each activity in all cases the workflow will request the msm core to perform the activity for the given inputs and will send back the corresponding outputs once the activity is done the workflow can use its outputs as inputs for the subsequent activity most of the time for example the first activity defined in the workflow will be a retrieval of data from a data source the workflow control requests the core to execute such a task the core will call the data agent to execute the task the data agent will retrieve the data and store them using services offered by the core one of our design criteria is to have a general and flexible open system architecture so that our framework can be easily integrated with different open source workflow engines this way our msm framework can take the advantage of existing and future workflow engines that the scientific communities use or prefer and at the same time can also avoid any reinventing of the wheels in our current implementation of msm we select vistrails bavoil et al 2005 as the workflow engine this is because vistrails provides a nice and convenient graphical workflow interface in addition to its unique capabilities such as provenance and data visualization which serve well to the goals of our msm framework the other components in the msm framework shown in fig 1 are described below 1 data agents they are dynamically loaded components that are connected to external data sources through the internet and store retrieved information in msm using services provided by the core they are loaded at run time and msm comes with developed data agents for some popular data sources the framework automatically generates a workflow activity template per each data agent 2 model agents they are dynamically loaded components that are able to run external models the framework automatically generates a workflow activity template per each model agent a model agent performs the following three main steps preparing inputs the agent receives the inputs from the workflow i e msmdatasets and transforms them into the input files with the format needed by the model executing model the agent will call the model executable file storing outputs the agent reads the output files generated by the model and transforms them into msmdatasets then the agent uses the framework to store them 3 core data management this is a layer inside the msm core that provides persistency for the msmdatasets allowing other components to write datasets and read datasets created during previous workflow activities this component has a cache to improve its performance 3 2 open data our framework addresses the challenges of accessing multiple and heterogeneous external data sources via its open data architecture which adopts a common internal data model and representation in this architecture data sources are integrated into the system using data agents that handle all source specific implementations and remote data access protocols e g opendap web services metadata standards and source specific implementations thus abstracting the data sources heterogeneity and providing a common interface to the msm core system the open data architecture not only allows integrating external data sources in an abstract and extensible manner but also allows end users to load data agents dynamically at runtime without having to stop current operations or recompiling the entire system in this way end users can develop their custom data agents for immediate use by the workflow engine the framework s internal data model integrates a relational representation of the system s metadata and a non relational representation to store the actual data received from external sources and or the results produced from model computation the data model allows persisting data sets associated with gridded data as well as time series data all currently represented by the msmdataset structure we have developed and integrated two data agents into the framework see fig 2 which already covers a broad range of data sources and data access protocols nasa opendap gds and usgs rest web services for bringing in data from both gridded netcdf and point time series waterml services using the major cataloging services e g nasa ges disc 3 2 1 develop an agent for a data source to enable users to easily develop new data agents so as to add new data sources into the msm framework for their scientific explorations we have designed a generic data agent class it offers the generic obtain data method individual data agents inherit from the generic data agent and override the generic obtain data method which enables the use of a specific data retrieval protocol from the workflow the data agent also uses services from the generic data agent for the creation and edition of the output datasets simplifying the development of new data agents all data agents share the following basic responsibilities 1 securely contact the data offering server 2 download the data files to the local machine if they do not already exist and 3 read the data from the downloaded files based on their format s and create a new dataset if at some point during the downloading process the connection is interrupted the simulation workflow will stop in such a case the user can restart the workflow and msm will continue to download the data from where it last stopped from the data source since there will be a local copy of the data downloaded so far the user is free to delete these locally downloaded data or maps at any time to write the data agent the user has to create a text file including a class in python as outlined below image 3 after that the user can add in the obtain data function all the necessary codes to download the data and create the dataset object when the information is extracted and is ready to be stored in a dataset object the user can call for example the function create full dataset of the generic data agent which will ensure the proper building of the dataset object and the persistence of it image 4 3 2 2 register data agents into msm framework the data agents are added to the system by copying the folder with the agent s code into the upload folder of the framework the folder needs to be named exactly as the class representing the agent also the file containing the class needs to be named exactly as the class the folder may contain more folders and more python code files the system needs to be refreshed to generate the graphical representation of the agent in the open data list after that the agent will be visible in the graphical interface on the panel and can be considered successfully registered 3 3 open model to take the full advantages of the framework such as the m2m 7 7 m2m machine to machine automated data retrieval from popular data sources e g nasa data centers and usgs graphical workflow process provenance data transformations and rescaling data fusion and data visualizations researchers users need to connect their model agents into the msm framework there are two steps required to accomplish this 1 develop agents for their models and 2 register the agents into the framework 3 3 1 develop an agent for a model to enable users to easily develop their model agents so as to add their scientific models into the msm framework for their scientific explorations we have designed a generic agent class the generic agent declares the generic run model method individual model agents inherit from the generic agent and override the generic run model method which enables the invocation of a specific user model from the workflow the model agent uses services offered by the generic agent class to read the inputs from and write the outputs into the msm core database which simplifies the integration of a user s model into the framework this model agent is independent of the language used in writing the model that is the language used by the model can be in c c fortran python java etc to facilitate the model agent development by individual users we have also developed an agent development kit 8 8 the adk agent development kit is a set of libraries that contains the interfaces and utilities required to write compile and test an agent that contains only the basic api necessary to write and test an agent without the entire msm core and the workflow this makes it easier to set up the development environment to start writing and testing a model agent the responsibility of the model agent is to provide the steps to 1 read the inputs from the msm core and save the data into files from which the model can read 2 run the model and 3 read the model s output files and save the information into the msm core this is implemented by overriding the run model function to write the model agent the user has to create a text file including a class in python as outlined below image 5 after that the user can add in the run model function all the necessary codes to prepare the inputs execute the model and store the outputs to read variables from the database the user can call for example the function get time series of the genericagent which will return an array with the values of the time series for the dataset requested image 6 to write variables i e model outputs into the database the user can call the following provided functions image 7 the create dataset function serves to initialize a msmdataset and provides the dataset id the save timestep function saves a timestep inside the dataset both are provided by the genericagent the user also needs to implement the function getinputs the msm system will use such functions to create appropriate ports in the workflow activities 3 3 2 register agents into msm framework the model agents are added to the system by copying the folder with the agent s code to the upload folder of the framework the folder needs to be named exactly as the class representing the agent also the file containing the class needs to be named exactly as the class the folder may contain more folders and more python code files also the folder must contain the executable files required to run the model the workflow needs to be refreshed to generate the graphical representation of the agent after that the agent will be visible in the graphical interface and can be considered successfully registered 3 3 3 an example of agent to illustrate we describe the model agent written for the vic model cherkauer and lettenmaier 1999 liang et al 1996a 1996b 1994 liang and xie 2003 2001 parada and liang 2004 a land surface model that is widely used in the hydrology and water communities maurer et al 2002 nijssen et al 2001 the run model function for the vic model agent vicagent which performs all the responsibilities described above include 1 initialization of environment 2 preparation of input files in this part the vic model agent vicagent uses several functions to build the configuration and input files required by the vic model the vicagent prepares one input forcing file for each modeling cell of the study area over which the vic model is to be run this forcing file includes all the forcing variables needed to run vic since vic can be run at different levels of complexities which require different forcing data the users need to be careful with the different requirements on the forcing files for each case it is important to mention that when obtaining the information e g forcing data from the database the agent does not directly query the database instead the model agent only uses the services offered by the generic agent from the msm core such a design in the framework s architecture ensures a minimum complexity for the user when he she writes the model agent the vicagent will automatically create the parameter files e g soil vegetation and snow required for the model to run in case they do not exist yet in the working directory otherwise the model will use the existing parameter files this allows the user to perform model calibration manually through changing the values in the parameter files 3 execution in this step the vic s model agent builds the command that calls the vic executable with its given global parameter file for instance prompt vic config file myconfig txt input dir inputs files the command is sent to the operating system for its execution and the agent waits until the vic model run is completed at which time the output and error streams if any of the vic model are directly sent back to the console of msm which is visualized in the console of vistrails 4 processing of outputs once the command is executed the agent processes the output files for each of the vic model s output variables vic produces results in time series if it is run with a choice of time first then space because of that the agent needs to open all of the output files one per cell and reads all of them for each time step in order to generate area images and store them for each time step in the output dataset in msm to save this in the database the agent again uses the services offered by the generic agent from the msm core 3 4 data management layer the persistence of information in msm is implemented as an in memory and local data caching featuring a non relational database scheme that supports high throughput our data management facilitates caching the retrieved data storing previous results and making the task of coupling different models more efficient where only a dataset s identifier is passed among coupled models our framework persists metadata information msmdatasets and remote cached data the metadata contains configuration information physical variables used by the workflow activities and the inventory by id of msmdatasets the msmdatasets storage in our framework contains the time steps which can be the big data volume each time step contains a reference to the msmdataset it belongs to and a document the data oriented structure with a 2d image the remote cached data are useful in storing raw data received from external data sources in this way the data agents do not have to download the same data every time the execution repeats they can reuse the data even when the researcher tests a slightly different hypothesis allowing the system to work offline 4 implementation the current version of our open data and open model msm prototype is implemented in python and integrated with vistrails at present the msm prototype supports various components summarized in table 2 the functions of the msm framework described in table 2 are presented below 4 1 graphical workflow the msm runs inside vistrails an open source of graphical data workflow that deals with control of the sequence of activities the versions provenance and visualization tools see fig 3 during execution vistrails will start to analyze the activities of the workflow for each one vistrails will track back the origin of the required inputs such tracking is repeated until tasks without inputs are found with this analysis vistrails marks and detects all the required tasks for execution unmarked tasks are not executed 4 2 retrieving data the open data agents see fig 4 can be used to retrieve data and create msmdatasets each data agent can define its own inputs and they can produce one or more datasets using the already developed data agents msm can retrieve opendap information from nasa and access data from usgs using web services in case the data retrieval is interrupted msm is capable of restarting downloading the data from where the last time step downloaded was this is done not only to reduce the time it takes to retrieve the information into the local machine but to resolve the internet interruption problems the user is free to delete these locally downloaded maps or datasets from his or her machine 4 3 provenance the provenance is a vistrails functionality from which msm benefits it keeps track of all of the executions from all versions of the workflow it helps users find and review previous executions the graphical configuration and the potential errors each execution is identified by the name of the version which is labeled in the history tab and the start and end time fig 5 shows a failed and a successful execution the color code shown in the upper right side of the screen shot each using a different version of the workflow the row that shows the execution can be expanded to show the list of components used with the execution time completion condition and whether it was cached or not 4 4 re scale space and re gridding the re gridding component see fig 6 transforms a dataset from its original spatial configuration to a desired target configuration the spatial configuration is defined by 1 shape of the cells although the shapes of the data cells are in squares most of the times they can also be in rectangular or rhomboidal shapes in the case of the radar data each cell is a different tetragon 2 resolution size of the cells 3 borders starting point even when two grids have the same shape and resolution if their borders are not the same their spatial configurations will not be the same the re gridding module first identifies the portions of the original data cells that are located within the study area i e represented by destination cells then it computes the data values for these destination cells using an areal interpolation method whenever the data cells and the destination cells do not match with each other in terms of spatial resolution shapes or borders 4 5 re scale time using the msmtimerescale component see fig 7 the msmdatasets can be re scaled to the time resolution required by a model or another input this component can use one of the following aggregation functions average maximum and minimum it also interpolates when data is unavailable in a required timestep 4 6 fusion of datasets using the mks parada and liang 2004 framework the msmdatasets can be fused when more than one source is included in an analysis for a given physical variable see fig 8 for example if precipitation data are available from nasa opendap and from radar they can be fused to form a single precipitation input to be used by a model 4 7 running models the workflow creates a graphical component for each model agent registered in the msm framework fig 9 shows that two models are registered in the msm framework one model agent for the vic model and the other one for the routing model see highlighted square the msm framework creates graphical inputs and outputs as defined in the model agents for vic model see fig 10 4 8 coupling models the user can couple the components using any of the available ports in the way he she desires because all components in msm accept and return msmdatasets as shown in fig 11 where the vic model is coupled to a routing model through their corresponding model agents vicagent and routingagent in this example the vicagent outputs its baseflow and surface runoff to be used as inputs for the routing model agent this is the way model agents interact with each other in msm from the workflow perspective new model agents implemented by the users need to clearly specify the datasets and units required on each port since not all models provide outputs for every single time step some preprocessing may be necessary for models appropriate interactions with each other one solution offered by msm is to use the msmtimerescale component to modify the temporal granularity of the datasets flowed between models another possibility involves the usage of the iterate component see fig 21 to perform a full spatial simulation for a single time step this way the user can create a time series with the snapshots of each simulation a user can also modify his her particular model in order to accommodate a time step wise integration with other models 4 9 adding new data agents the msm framework can be expanded to access data from other data sources by adding new corresponding data agents created by users after writing a data agent the user just needs to copy the code into a folder provided by the framework as described in sections 3 2 1 and 3 2 2 4 10 visualization of results the msm makes use of the vistrails visualization tools to show 2d images in time point time series and snapshots of variables for a given time fig 12 illustrates the time series plots generated using the msmtimerescale component shown in fig 7 4 11 loading local information fig 13 shows that data stored locally in files can be loaded into the msm framework using the functions built in msm after the local data are loaded into the msm framework they can be accessed just by using the id of the dataset 5 a modeling example in this section we present an end to end hydrological modeling example to demonstrate how the msm framework can facilitate modeling with complex data retrieval and processing it in an automated manner it starts with retrieving precipitation wind and temperature from the nasa opendap data sources which follows by running the vic model in its water balance mode to compute the water budget related variables such as evapotranspiration soil moisture and runoff then the vic simulated runoff time series is used as an input to a routing model the example finishes by comparing the routed discharge based on the vic simulation with the usgs measured streamflow data which is automatically read into the msm framework from the usgs website this is a typical hydrological modeling use case scenario which involves retrieving the weather forcing data needed for running a sophisticated model executing it and comparing the model simulation results with observations compared to the typical modeling practice in the hydrology community the main difference shown in this example is that all of those tasks are done automatically under the msm framework with machine to machine communication for data retrieval from external data sources this example also demonstrates several important features of the msm including using the modules of open data open model mks based data fusion and visualization fig 14 shows the study area of the example fig 15 shows the selected watershed and its river network 5 1 configuration of the workflow the first step is to set up the components to retrieve various types of information from the corresponding data sources precipitation temperature and wind from nldas nasa for example when vic is run in its water balance mode fig 16 shows the workflow designed for conducting this modeling task in which each component for retrieving the forcing data is created by dragging the corresponding data agent component from the open data list on the panel shown in fig 17 into the working area in addition the vicagent component is dragged from the open model list into the working area as well as shown in fig 16 for each of the three retrievedatasetagent components the configuration inputs showing in the right column of fig 16 next to the work area are filled with values shown in table 3 below note that some of the fields listed in table 3 cannot be seen fig 16 to see all of them the user just needs to scroll down using the arrow in the right bottom corner of the right panel shown in fig 16 next the vic model is set up by connecting the vicagent component to the appropriate input data sources as well as the output displays shown in fig 16 for the model input connection the dataset id output ports from the retrievedatasetagent components are connected to the vicagent input ports we note that vic requires the min and max temperature as inputs but the same variable temperature is used in this case for simplicity the dirtodataset component is used here to load the static soil parameters used by vic if it is not provided vic will use the default values this component reads all the files from a folder and then creates a map of the specified study area for each file read in each such file contains a 2d matrix corresponding to the modeling grids over the study area for a time step since the soil parameters are static and thus they are stored as a one time step image the component also has other input ports that can be used to provide information such as the coordinates and the desired scale but in this case the information of coordinates and desired scale is received from the retrievedataset component for the model output connections two different functions msmshowdataset and msmshowplot are used to illustrate two types of visualization for the model simulation results the msmshowdataset is connected to the soil moisture output of the vicagent to view vic generated soil moisture results as an image while the msmshowplot is connected to the evapotranspiration output to view it as a time series more specifically once the computation of the vic model is finished the soil moisture output will be shown as an image for each time step whereas the evapotranspiration output will be shown as a time series plot the evapotranspiration output is being re scaled to scale zero to show the averaged evapotranspiration of the study area as a time series where the msmmks component is used to achieve the areal average through the rescaling operation based on the mks algorithm 5 2 execution the execution of the workflow starts when the user clicks the execute button shown in the 2nd top row of the vistrails window see fig 13 the retrievedataset components will attempt to automatically download the information from the specified data sources if the data to be downloaded are too large the msm component will retrieve it in chunks of one time step each if the communication is lost at any time the user can re run the workflow and the components will continue downloading the data from the last time step it was saved before the vic model component starts all the retrievedataset components and the dirtodataset must have been finished they will provide the dataset ids for all the forcing inputs and the model parameters the vicagent will then use such dataset ids to create the inputs run vic and wait for it to finish then the vicagent will read the vic outputs and save them as datasets vicagent will send the dataset ids of the outputs to the visualization components to generate plots the execution of the retrievedatasetagent components is completed when all the information specified is downloaded only at that point the execution of the subsequent component vicagent is invoked vistrails has a color code for the workflow boxes shown in the working area e g see the snapshot shown in fig 18 during an execution phase for example vistrails will show green for the boxes already computed yellow for the boxes under execution orange for the boxes waiting for the preceded boxes to complete gray for the boxes that have not yet been started or even considered for execution red for the boxes that failed and blue for the boxes that cannot be executed because of failures in the inputs fig 18 shows a few different statuses of the boxes during the execution phase of one workflow case it is worth mentioning that these color indicators are different from the colors used for the workflows saved in the provenance as shown in fig 5 5 3 results generated by the vic model the vic model with a general vicagent generates more than 160 output variables for this specific illustration the vicagent is configured to generate only 2 outputs soil moisture and evapotranspiration fig 19 shows the vic model simulated soil moisture plotted as an image per time step for the study area and for eighteen consecutive time steps the vic simulated evapotranspiration is averaged over the study area for each time step and is shown in fig 20 as a time series in order to generate such time series the vic results for the study area were re scaled to scale zero using the mks component to obtain the average in this example we further illustrate how to change the configuration during the task execution in a timestep by timestep fashion for instance the execution described above has an overall retrieval phase in which all the inputs are downloaded for the entire simulation period before the vicagent is executed this approach is widely used in model applications when using historical data and is called time first then space however in the forecast applications with real time data a model needs to be run one step at a time for the entire study area and then move on to the next time step in an iterative fashion in other words one needs to download the model input data from each data source for only one or a few timesteps each time then run the model for that or those time step s for the entire study area then download the input data again for another time step or few time steps and then run the model for the new time step or new time steps again etc to achieve this the user can use the iterative functionality developed in msm that is by using the configuration with an iterative approach it is possible to control the tasks executed at each time step or even repeat a set of activities until the convergence is reached before moving forward the next time step the readability of such workflow can be improved by using sub workflows this is a vistrails feature that allows the user to group a set of modules to make them usable as an entire new aggregated module this new component can be used as a single box in other workflows in that way workflows with many modules become simpler and organized in a hierarchical way for easier understanding figs 21 and 22 illustrate the use of the iterative function we developed in conjunction with the sub workflow feature of vistrails running the vic model coupled to a routing scheme specifically fig 21 shows the main workflow after grouping some of the activities into the one timestep box and using the looping component i e iterate the measured streamflow is also included in this workflow through the timeseriesfiletodataset component in this way the vic model simulated runoff after routing from the msm framework can be compared with the usgs measured streamflows the iterative nature of this workflow is accomplished through the iterate component which makes repetitive use of the task named one timestep the one timestep box in fig 21 represents a subworkflow which is shown in fig 22 this component contains all the tasks needed to be performed at each time step it starts by setting the looping parameters time per step number of steps and initial time then retrieves all the inputs subworkflow swf retrieving then runs the vic model vicagent and then sends the surface runoff and baseflow outputs to the routing model subworkflow swf routing at the end of the execution of this subworkflow one can compare the model simulated streamflows i e after the vic and routing models with the usgs measured ones in addition the model results can also be saved as text files via the component datasettotimeseriesfile shown in fig 22 such saved model simulated results can be used for further analysis or other purposes by the user for instance the vic model results obtained here are based on the default vic model parameters no calibration for the model parameters is conducted if one wants to do model calibration and compare the results one can save the results for later comparison studies the saved results can also be plotted with different software tools at the user s preference the vic routing model simulated results shown in fig 23 are obtained by running the vic model with default parameters plus the routing model without conducting any parameter calibration such a plot is generated by the msmshowchart component in msm 6 conclusions the fields of geosciences are entering a new era of big data in which physically based computational models with easy access to and use of increasingly available and diverse data are fundamentally important for scientific explorations our presented open data open modeling framework innovatively combines open data access and open modeling framework together and hence simultaneously addresses several critical issues faced by the broad community 1 direct open machine to machine m2m access of data to models from external data sources 2 graphical scientific workflow environment for scientists 3 easy model sharing and heterogeneous diverse model couplings without the need to share or change model source codes 4 no required central administration of shared models and the modeling framework system 5 data fusion of datasets from different sources and or computational model outputs 6 provenance management for reproducible computing and 7 data exploration and visualization these seven challenges have been repeatedly identified and highlighted by the geosciences communities the unique features of the presented open data open modeling framework make it very suitable as an integrated solution for general geoscientists to overcome the above challenges in their explorations the prototype system of our framework msm has successfully demonstrated its usefulness and effectiveness in various aspects of scientific modeling activities the openness of our framework by design indicates that when a user integrates his her model s into msm the impact of the integration process on user s model is none since there is no inter dependency between the msm framework and the model codes moreover the approach of the integration of an open scientific workflow engine i e vistrails into our framework provides a unique provenance management among other desirable graphical workflow features which directly facilitates reproducibility study in model couplings and thus is critical for users research and its reliability our plan of future work includes continuing to add more external data sources into the msm such as hydro meteorological datasets offered by nasa nldas north american land data assimilation system and ncaldas which are composites of measurements from land stations and model simulations as well as the satellite datasets like gpm for precipitation and smap for soil moisture in addition in the near future we will add more noaa datasets such as nam north american mesoscale forecast system and gfs global forecast system which are datasets from the model forecasts also there are plans to add more computing facility choices e g high performance computing or cloud computing into the msm framework for users to select based on the demand of each workflow activity at present we are developing new model agents to integrate models like the distributed hydrology soil and vegetation model dhsvm and the ph redox equilibrium model in c phreeqc into the msm system moreover a newer version of vic vic5 0 is being integrated to msm we are also working on developing generic model agent tools to help the user to develop his her own model agent s with little to no coding to integrate the model s of the user s choices into msm our framework software msm is intended to be made available to the geosciences community as an open source at its due course part of this work involves making it available on the ubuntu operative system since the msm has only been fully tested on windows 10 os so far declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the u s national science foundation under ear 1245067 and oac 1835785 to the university of pittsburgh and under ear 1245171 and oac 1835817 to indiana university purdue university indianapolis iupui respectively we would like to thank the support from thomas adams jerad bales richard hooper steve kempler pedro restrepo and william teng the second author also acknowledges the support from the william kepler whiteford professorship from the university of pittsburgh appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104622 
