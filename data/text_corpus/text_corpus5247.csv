index,text
26235,developing a complex environmental modelling web application or web app can be a challenging task that requires integration of various models and data sources with ever changing internet technologies service oriented architecture soa has been shown to be useful for building complex modelling workflows however compared with other types of web services such as those for data delivery and mapping the implementation of open geospatial consortium ogc web processing services wps for environmental modelling and data analysis is not very common this problem stems in part from the lack of tools to simplify the development and deployment of wps for the broad and complex set of environmental modelling applications this paper presents the development and testing of a ready to use wps implementation called tethys wps server which provides a formalized way to expose web app functionality as standardized wps alongside a web app s graphical user interface the wps server is created based on tethys platform by leveraging pywps three tethys web apps are developed to demonstrate how web app functionality s can be exposed as wps using tethys wps server and to show how these wps can be coupled to build a complex modelling web app moreover we demonstrate that the services hosted on tethys wps server follow ogc standards correctly and can be used successfully by third party applications and clients that support the ogc wps specification keywords tethys platform web processing service wps web app interoperability pywps 1 introduction environmental modelling can be extremely complex because it includes dynamic physical chemical biological and human processes that can vary at different spatial and temporal scales an accurate environmental modelling system often requires integrating multiple models data sources and analysis routines into a workflow to address a research question and requires some level of cooperation among experts with different backgrounds the concept of chaining interoperable model components is gaining momentum for modelling because such a chain can potentially answer more questions than the individual models alone castronova et al 2013 dubois et al 2013 generally we can achieve model interoperability by sharing input and output files directly rewriting models into a single software system or establishing software architecture principles that facilitate the coupling of independent models belete et al 2017 granell et al 2010 in the model coupling approach models are written in a modular way in which each model performs an isolated task while the whole workflow addresses a much broader problem this approach enables each model to remain as flexible extensible and reusable as possible argent et al 2006 castronova et al 2013 schaeffer 2008 however integrating multidisciplinary heterogeneous models still involves barriers such as different programming languages operating platforms and user interfaces it is also difficult for researchers to understand models from other disciplines jiang et al 2017 yue et al 2016 hence setting up a system to make heterogeneous models easily connected remains a challenge service oriented architecture soa has been widely used to integrate models and build scientific workflows bosin et al 2011 lin et al 2009 yue et al 2016 zhao et al 2012 this standards based loosely coupled and service oriented approach emphasizes the decomposition of a system into functional components that communicate via web services castronova and goodall 2010 web services enable communication and interoperation among various applications over the network by using open standards and protocols which means applications written in different programming languages or running on different platforms can seamlessly exchange data over the internet through web services michaelis and ames 2009 nativi et al 2013 the model developer can therefore focus more on how to structure the internal algorithms goodall et al 2011 it has been shown that soa based applications can address the issues of data accessibility and service interoperability for environmental models granell et al 2010 huang et al 2011 mason et al 2014 zhao et al 2012 also it has been demonstrated that soa has significantly improved dealing with complex problems by making data and models available on the internet as interoperable services dubois et al 2013 nino ruiz et al 2013 skøien et al 2013 yang et al 2009 while numerous environmental web services exist for water data distribution e g horsburgh et al 2015 maidment et al 2009 and for web mapping e g blower et al 2013 palomo et al 2017 environmental models as web services is still an area of research that has not been widely investigated and implemented belete et al 2017 hu et al 2015 vitolo et al 2012 2015 the open geospatial consortium ogc has promulgated the web processing service wps specification which has been demonstrated as an efficient technology for publishing geospatial processes and constructing integrated model chains castronova et al 2013 schaeffer 2008 tan et al 2015 ogc is the foremost organization guiding the development of standards and specifications for geospatial services and it manages a global consensus process that results in approved interface and encoding standards that enable interoperability among and between diverse applications ogc wps is a commonly recognized specification for publishing processes as web services it specifies a standard method for processing data as a request from client to server using extensible markup language xml for communication through the internet schut and whiteside 2007 ogc wps also standardizes the interoperation and communication between wps which provides flexibility to create workflows for different purposes it has also enabled openly sharing models over the internet to address the needs for complex simulations that involve diverse data and algorithms kumar and saran 2014 many recent studies have demonstrated orchestrating ogc wps into environmental workflows feng et al 2011 have developed five ecosystem disciplinary models that comply with the ogc wps specification and a geospatial model sharing interface geomsi that provides a service interactive interface for sharing accessing models through wps a modelling system that implements a time driven process simulation of wetland ecosystems has been established through integrating these five remote services vitolo et al 2012 implemented a web service based modelling system for hydrological modelling on the basis of the fuse modelling framework clark et al 2008 exposing hydrological processes using an open source library called pywps castronova et al 2013 have built a wps process of the topmodel hydrologic model and used it within a client application they advanced pywps to maintain state and store data values on the server in order for the wps to perform time dependent calculations kumar and saran 2014 designed and implemented a wps process that fetches data from an ogc web coverage service wcs server and performs the normalized difference vegetative index ndvi calculation astsatryan et al 2015 developed several vegetation index computation wps processes using pywps and a user friendly portal using the joomla content management system to enable users to compute either a single vegetation index or a combination of vegetation indices as a workflow some studies also include cloud computing and parallel computing to improve the performance of complex wps processes tan et al 2015 constructed an elastic parallel ogc wps on a cloud based cluster to provide high performance computation astsatryan et al 2015 designed and applied hpc clusters with an effective parallelization algorithm to speed up the execution time of the vegetation index computation wps compared with web services for water time series data e g cuahsi wateroneflow and spatial data e g ogc web mapping and web feature services the implementation of wps for environmental modelling and data analysis is still not particularly common indeed the existing literature is more heavily weighted towards specific services for particular environmental workflows rather than general tools to support creating wps services one obvious exception to this observation is the readily available capabilities of the commercial environmental systems research institute esri arcgis server software which can easily publish data analysis and modeling services arcgis server uses a proprietary format for services consumed by the arcgis desktop applications and it can also serve wps services to be consumed in web applications and other desktop software esri 2018 notable recent examples of data processing services developed and deployed using arcgis server include leonard et al 2014 yue et al 2015 we posit that there is much value in exposing existing models and data analysis workflows via wps in addition to graphical user interfaces gui for optimal flexibility this work presents the design development and testing of an ogc wps system on the tethys platform a collection of existing open source gis tools wrapped in a django python framework we elected to use tethys platform as our development environment because it is open source and provides a complete and relatively uncomplicated environment for web based environmental modelling applications development tethys platform is intended for the development and deployment of web apps that are characterized as generally single purpose lightweight web applications that are independently developed and are installed and uninstalled from a web app portal mirroring the app paradigm of mobile devices swain et al 2016 demonstrate that tethys platform successfully lowers the barrier to developing web apps in the environmental domain by providing 1 a suite of software that meet the spatial and computational capabilities commonly required for environmental modeling including tools for geoprocessing of spatial data distributed computing database management map rendering and visualization 2 a programmatic means to use each of the recommended software systems in a single programming language python 3 a reduction to the web development skills required to develop web apps and 4 a web safe mechanism for deploying the finished web apps that is flexible enough to work on the most common means for obtaining hardware swain et al 2016 our research goal was to generate an approach of simultaneously exposing web app functionality as wps when developing a web app this approach makes the process of wps development almost transparent to developers in this way environmental modelers and developers can focus on creating web apps and tethys platform takes care of creating the corresponding wps services in addition exposing apps functions as wps processes can improve the interoperability and reusability of apps it also facilitates the implementation of complex modelling including chaining apps for integrated modelling the remainder of this paper is organized as follows the system design and implementation of tethys wps server is shown in section 2 we also present the design of a hydroprospector hydrological modelling system to demonstrate how tethys wps server enables and simplifies environmental workflow modelling the results of this research are described in section 3 a detailed discussion on the benefits of this research for environmental modelling and how it successfully facilitates complex environmental modelling web app development are presented in section 4 section 5 provides conclusions and opportunities for future work in this area section 6 describes the software availability and source code of tethys wps server case study apps and all the software used in this paper 2 methods 2 1 system design the fundamental purpose of tethys wps server is to provide a simple method to expose function s of environmental web apps as wps this allows environmental modelers and developers to focus more on web app development and less on the details of the ogc wps specification a tethys app project is organized using the model view controller mvc software architectural pattern leff and rayfield 2001 swain 2015 the model is the app s data structure it directly manages the data logic and rules of the app the view is the visualization of the data the controller handles user input and performs interactions on the data model or view a tethys app receives input datasets the data model from users through a gui performs computation in the backend controller and returns outputs to the web browser the view the core part of a tethys app is its controller functions which are implemented in python similar to tethys apps the mechanism of wps also includes accepting input parameters from a client executing processes in the backend and returning outputs to the client hence it is feasible to disseminate tethys app functions as wps processes the primary difference between tethys apps and wps processes is each tethys app defines its own specific formats of inputs and outputs while the inputs and outputs of wps processes are uniformly defined in xml format each tethys app typically contains its own data analysis or modelling workflow to provide a solution for one specified task or several tasks as shown in fig 1 here we use the term workflow to indicate the overall functionality of a web app a workflow is comprised of one or more computational processes such processes can be hosted within the app itself or can be included as web processing services provided by other apps for example the workflow of a runoff prediction app includes a snap function that moves a user defined point to the nearest river a watershed delineation function that generates watershed boundaries based on the snapped point and a runoff calculation function that calculates runoff within this watershed area using the latest precipitation forecasts each function of this workflow can be part of other water resources modelling tasks with tethys wps server these functions can be exposed as ogc wps processes and reused in the workflow of other tethys apps or other third party clients that support the ogc wps specification the general system architecture of tethys wps server and its relationship with tethys platform is shown in fig 2 tethys platform consists of three major components tethys software suite tethys software development kit sdk and tethys portal tethys software suite synthesizes several free and open source software foss projects that are needed for developing environmental modelling applications including geoserver 2013 for spatial datasets publishing 52 north 2018 for geoprocessing tools postgresql 2018 database with postgis 2018 extension for spatial datasets storage htcondor 2018 for distributed computing and a number of javascript libraries like openlayers 2018 and highcharts 2018 to help visualization tethys sdk provides multiple python apis for each supporting software element this makes it possible to orchestrate the functionality of each software using python in web app scripts tethys portal is a web portal used to host web apps that developed with tethys platform christensen 2016 swain 2015 in this study tethys wps server is implemented as a plugin component that has no effect on other components and functions of tethys platform the purpose of this design is to 1 leave apps developed based on former versions of tethys platform unaffected and 2 make exposing wps a flexible option which means the app can execute normally with or without exposing internal functions as wps processes after exposing various functions processes as wps clients are able to send requests to the server to fetch related information about specific processes or execute processes once the wps server is invoked by a request it will automatically accept input data or fetch data from specified databases generally with urls perform computation with the data encode the result into xml and send it back to the client 2 2 system implementation the first challenge of implementing tethys wps server is to integrate an existing software product into tethys platform to provide server side implementation of ogc wps interface specification by server side implementation we refer specifically to implementing a wps server on a web server to handle requests from clients and responses back to clients by using existing ogc wps implementation software we can avoid having to build this functionality from scratch and can take advantage of the debugging and testing of the software by others of course this is the self evident advantage of using any third party module as tethys platform is python based jones et al 2014 and we aim to directly disseminate app functions as wps without too much modification the implementation project is required to support python scripting doing so can also facilitate code debugging when developing wps processes table 1 lists several popular software packages that support server side ogc wps implementation geoserver wps and deegree wps müller 2007 are both java based frameworks and only support java scripting 52 north wps is java based implementation according to its documentation 52 north supports python scripting however the python support in 52 north was originally designed for use within the esri arcgis python library in the windows operating system limiting cross platform usage boerboom 2013 there is also a 52 north module for exposing ilwis gis 2001 functions as wps services unfortunately there does not appear to be support in 52 north for exposing native python wps functions on a linux server arcgis server wps refers to its modelbuilder module that supports exposing arcgis geoprocessing services as ogc wps pywps 2009 is a python based server side implementation of wps allowing integration publishing and execution of python processes via the wps standard it was originally developed for implementing grass gis 2018a operations as ogc wps processes and has shown to be well suited for integration with tethys platform pywps version 4 utilizes werkzeug 2011 an open source web server gateway interface wsgi utility library to make the wps functionalities written in python be accessible over the internet there are four core classes in pywps service process wpsrequest and wpsresponse the service class streamlines the request pre processing process execution and the response post processing into a complete hypertext transfer protocol http request response cycle a complete http request response cycle begins with a client sending a request message to a server the server handles the request and sends a response message back to the client the service class is the top level object representing the wps service it can run as a wsgi application the process class specifies the attributes attached to a generalized wps process including metadata terms and a handler function to hold process logic implementation and a set of functions to operate on a process object each wps process accepts a wpsrequest argument and returns a wpsresponse object the workflow of pywps is shown in fig 3 when the wps server is invoked by a http request pywps utilizes werkzeug to create a werkzeug request object containing metadata about the http request and then packages it to a pywps wpsrequest object ogc wps specifies three operations that can be requested by clients and performed by a wps server including getcapabilities describeprocess and execute see table 2 for getcapabilities and describeprocess requests pywps directly returns werkzeug response objects for execute requests pywps loads the appropriate wps process and passes the wpsrequest to the function the function is responsible for returning a wpsresponse object which can then be converted to a werkzeug response and sent back to the web server tethys platform is powered by django framework of which the primary deployment platform is wsgi when a tethys page is requested django creates a django httprequest object including the request metadata then django passes the httprequest to the specified function and returns a django httpresponse object because tethys platform and pywps are both wsgi compliant applications they can be deployed on the same web server and coexist as two separate web applications running in parallel with different python interpreter instances however for a seamless integration it is preferable for the two applications to use the same python interpreter instance and thereby share python level objects variables and functions as one web application to allow for this seamless integration we choose to downgrade pywps from a wsgi application to a pure python package this was accomplished by removing the werkzeug decorator request application from the callable functions in the service class and the wpsresponse class the slightly modified pywps still has the full implementation of wps functionality that can be consumed as normal python classes or functions from within tethys in addition since the interfaces of pywps classes and functions are unchanged they still only accept werkzeug request objects as input and return werkzeug response objects as output a conversion between werkzeug versioned request response objects and django versioned request response objects is required the general workflow is depicted in fig 4 after integrating pywps with tethys platform the next step was to establish a method to connect tethys apps with the wps server in pywps each wps process is defined as a process class in a python script containing metadata configuration and a handler function holding detailed execution algorithm the handler method can directly call outside functions as a whole or part of the wps process to support this behavior we created a wps definition file as shown in fig 5 that is included with the tethys app source code containing a pywps process class definition template the app s functions can be called in the handler function to be disseminated as wps processes in pywps all the wps processes should be located in the same directory to be imported in the server to implement this capability tethys platform automatically collects all the wps definition files in each app hosted on the server and creates symbolic links of them in a location identified in the wps server configuration under this approach the wps definition files located in deployed tethys apps are imported to the wps server as shown in fig 5 the app s algorithm can be written in a separate file that can be used by both the app gui and the wps process the wps feature is thereby a new route to access the app s algorithm and any update to the algorithm will be automatically available in both the app gui and the wps process 2 3 experimental case study design this section presents design of use cases to illustrate 1 bi directional communication between tethys apps and tethys wps server including how the functions of a tethys app can be exposed as wps processes on tethys wps server and how services hosted on it can be included in another tethys app as components of the workflow 2 consuming services hosted on tethys wps server with third party wps clients the aim of these use cases is to test and demonstrate how tethys wps server can simplify environmental ogc wps development and significantly lower the barrier to developing complex web apps 2 3 1 hydroprospector use case consider hydroprospector as a reservior management model that calculates the storage capacity curve of a reservior to help decision makers choose the best dam location the storage capacity curve which refers to the relationship between dam height and reservior storage capacity is important for dam planners designers and operators issa et al 2017 to calculate the storage capacity curve the first step is delineating a watershed based on a dam location the watershed basin defines the maximum reservior size and works as a boundary for latter calculation then the reservoir s storage capcity are calculated for different dam heights finally the storage capacity curve is plotted using different dam heights with corresponding calculated storage capcity the hydroprospector model contains a complex geoprocessing workflow that requires a relatively long processing time about 2 min see compute time discussion in section 3 3 challenges with developing this app include but are not limited to complex geoprocessing coding handling asynchronous execution and job management furthermore the watershed delineation process and reservoir storage calculation process are both essential and commonly used in environmental modelling exposing these processes as web services can make them more easy to be reused in other complex models to demonstrate this we developed a service oriented tethys app that performs hydroprospector model in the dominican republic country workflow shown as fig 6 instead of coding from scratch the app consumes two wps processes hosted on tethys wps server watershed delineation wps and reservoir calculation wps these two wps processes are respectively exposed from two tethys apps watershed delineation for dominican republic app and reservoir calculation for dominican republic app both of these two tethys apps are functionally independent with their own graphical user interfaces both of these two wps processes use grass gis functions for geoprocessing calculation grass gis provides gis functions that can be accessed via python code neteler et al 2008 the watershed delineation service fig 7 accepts coordinates of a point and returns the snapped point at nearest stream and a watershed in geographic markup language gml format the service first performs a grass gis function r watershed to generate a set of maps indicating flow accumulation and flow direction then a point indexing function is performed to link the given outlet to the nearest stream network via a shortest snap function finally a watershed basin is calculated with the snapped outlet point and the flow direction map the reservoir calculation service fig 8 calculates the boundary and volume of a reservoir which is generated based on coordinates of a pour point and a designed water level at the pour point a maximum boundary polygon is required as input to subset the digital elevation model dem file to reduce the execution time of raster calculation process the service uses the grass gis function r lake to generate a reservoir raster from the dam point the resulting reservoir raster based on which the reservoir boundary and volume are generated contains cells with values representing reservoir depth and null for all other cells beyond the reservoir both the output of the watershed delineation service and one input of the reservoir calculation service are polygons in the geojson format having variables in the same format enables the connection of these two services each of the services hosted in these tethys wps server instances can be executed using the ogc wps specification the hydroprospector app user interface consists of a user interactive map and a chart app code flow shown as fig 9 the user first can add a point anywhere on the map with a mouse click after selecting a point the coordinates of the user clicked point are passed to the app controller using asynchronous javascript ajax the app controller reads in the coordinates and sends it as a request to the watershed delineation service on tethys wps server as the watershed delineation service execution is finished the controller extracts the watershed and snapped point results and passes them to the map using ajax the map periodically checks the controller for progress status and adds the watershed and snapped point to the map once the processing is finished next the user defines dam height and interval then clicks the calculate button each gage height with the watershed and snapped point from the first step are passed to the controller using ajax then the controller submits a request to the reservoir calculation service on tethys wps server once the service execution is finished and the response is returned to the controller function the controller function extracts the reservoir boundary and volume and passes them to the gui to sequentially get the proposed reservoir boundary and volume results the data with updated gage height is passed until the former processing is finished after each ajax function is completed the reservoir boundary is added to the map and the reservoir volume is drawn in the chart the process is completed when the storage capacity values for all gage heights are calculated 2 3 2 wps client use case one advantage of tethys wps server is that the wps services hosted on it can be consumed not only by tethys apps but also by various types of clients set up in accordance with the ogc wps implementation specification the simplest client of a wps service is a web browser the wps services can be consumed through a web browser using http get method with key value pair kvp encoded requests responses and exceptions are then returned to the web browser however there are also some third party clients and libraries capable of consuming ogc wps services in the hydroprospector app we use owslib 2017 to interact with tethys wps server including sending requests to the server and receiving responses from services owslib is a wps client library that provides a common api for accessing and executing ogc wps services we also used an open source desktop gis software qgis 2018b as a wps client to demonstrate that the wps processes hosted on tethys wps server conform to the ogc wps standard and are able to be consumed by other third party software that supports ogc wps 3 results 3 1 tethys wps server we developed an api for exposing tethys app functions as ogc wps processes when a new tethys app project is created a wps definition file fig 10 is automatically included in the app source code the wps definition file provides a template that allows app developers to expeditiously define a wps process each wps process is defined as a pywps process class which contains an initialization function and a handler function the initialization function includes the definition of inputs outputs service metadata and server based parameters the handler function specifies the actual operation of the wps process other outside functions defined in the tethys app can be called in the handler method to become a wps process or part of a wps process this design allows the wps process to be updated simultaneously with any modification of the app the services described in the wps definition file are not activated automatically they must be activated or deactivated using command line statements created to help manage wps processes on tethys wps server these include tethys wps list lists all published and unpublished wps processes this lists the available published and unpublished processes on the linux command line with no further interaction required from the user tethys wps publish publishes selected wps processes this interactive command results in a prompt to the user requesting the name of a specific app and associated service to be published tethys wps remove removes selected wps processes this interactive command results in a prompt to the user requesting the name of the service to be removed the benefits of using command lines include simplifying common management tasks related to wps and allowing app developers the flexibility to modify wps processes without affecting the apps existing operation through its graphical user interface 3 1 1 interaction with tethys wps server ogc wps specifies three operations that can be requested by clients and performed by a wps server including getcapabilities describeprocess and execute table 2 supported data formats for inputs and outputs include literal data character string value date etc complex data vector raster and bounding box data bounding box area with coordinate reference system wps servers can be invoked using the http get method with a kvp encoded request or the http post method using xml format for the request generally the kvp encoding method is accepted for getcapabilities and describeprocess requests while the execute requests often adopt xml encoding the kvp encoded requests are written as urls composed of a series of request parameters and input data they are commonly used for simple requests or requests with simple inputs like literal data while sending an execute request that includes complex data vector raster or bounding box data the xml coding method is recommended over kvp the inputs can be included directly in the request or they can reference web accessible resources the outputs can be returned in the form of an xml response document either embedded within the response document or stored as web accessible resources tethys wps server as an ogc wps implementation supports executing processes either synchronously or asynchronously for the synchronous execution a wps client sends an execute request to tethys wps server and keeps listening for a response until the process has completed and returned the result in this situation the client and wps server should keep connected for the asynchronous execution a wps client receives a response immediately after sending an execute request to tethys wps server the response confirms that the request is received and accepted by the server a processing job has been created and will be run the response contains execution status and a job identifier with which the client can check the execution status it also contains the location usually as url where the execution result can be found after the processing job has completed typically asynchronous execution is recommended for wps processes as geoprocessing processes usually contain complex and time consuming calculations 3 2 case study results 3 2 1 hydroprospector use case we deployed three tethys web apps at the website http cosmo byu edu apps watershed delineation for dominican republic app reservoir calculation for dominican republic app and hydroprospector for dominican republic app from the first two apps we respectively exposed a watershed delineation wps and a reservoir calculation wps on tethys wps server details in table 3 these processes were exposed through the linux command line statements described previously the hydroprospector app was developed by coupling these two wps processes into the workflow shown in fig 6 owslib is used to interact with the wps processes on tethys wps server the hydroprospector app user interface fig 11 includes an interactive map to show watershed and reservoir boundaries along with a chart to show the storage capacity curve of designed dams the user is required to 1 click on the map to select an outlet point for watershed delineation and then 2 define a dam height and interval the app will dynamically draw the storage capacity curve in the chart and show corresponding reservoir boundaries with different dam heights when selecting a data point in the chart the corresponding reservoir boundary is shown on the map the service oriented approach presented here is particularly suited to complex or time consuming workflows where information must persist beyond server client transactions for example when we directly implemented the hydroprospector model in a single web app the model execution time often exceeded the typical http request response timeout setting and failed to reply to the request made from the client the browser timeout can be extended long enough to account for this or can be disabled completely however this can affect the normal execution of other web browser requests in addition interruption or error can be caused by conflicting requests by different clients to overcome these barriers a job queue system should be included to implement asynchronous execution and provide real time monitoring of different requests a database or other persistent data store mechanism is also required for the storage of job information and results to allow users to check the job status and retrieve result this approach is complicated and time consuming and it requires advanced web development skills tethys wps server as an ogc wps implementation supports storing the execution response and outputs as web accessible resources that can be retrieved by the client it also supports asynchronous execution which can keep the execution status updated and accessible while the request is being processed by using tethys wps server app developers can focus more on model design rather than on web development 3 2 2 third party wps client use case we choose qgis as a wps client to demonstrate that the wps processes hosted on tethys wps server can be used by other third party clients that support ogc wps specification qgis was chosen because it is open source and is a comprehensive gis environment qgis has a wps python client plug in through which qgis can directly consume wps services on wps servers the interactions include listing wps capabilities sending request to execute a wps process and visualizing outputs in qgis interface we successfully connected to tethys wps server executed the watershed delineation wps and the reservoir calculation wps through the qgis wps client and displayed the results in the qgis map this effort proved to be uncomplicated and self explanatory with no unusual results or unpredicted outcomes hence no further discussion of this test is given here 3 3 quantitative analysis an analysis of programming language composition was performed to measure how tethys wps server overcomes the hurdle of complex web app development in environmental modelling we compared the hydroprospector app with another tethys app called storage capacity service https github com xhqiao89 storage capacity service git which implements the same functionality of the hydroprospector model fully natively without using wps services we used the count lines of code cloc linux package to count the number of code lines excluding blank lines comment lines and third party libraries included one aim of tethys wps server is lowering the barrier to complex environmental web app development this is evident by the reduced amount of python used in the hydroprospector app shown in table 4 204 lines compared to 603 lines for the storage capacity service app in addition the storage capacity service app adopts celery solem 2007 for asynchronous execution and task job management and postgis database for job results storage none of which is required in the wps based hydroprospector in addition we selected 10 hydropower dam sites around dominican republic country and calculated the storage capacity curve with the hydroprospector app and the storage capacity service app respectively the dams were all 30 m high and the interval for calculating the storage capacity curve was set to 10 m the total compute time for each dam site were recorded as fig 12 the average compute time of using the hydroprospector app is 147 2 s while 103 8 s with the storage capacity service app the hydroprospector app takes a longer time because it calls two independent wps services which contains more steps than the pure storage capacity curve calculation process such as setting up grass gis environment creating grass gis projects input data preprocessing and outputs post processing 3 4 qualitative analysis as a qualitative assessment of how tethys wps server lowers the barrier of ogc wps deployment we conducted a workshop and collected results from a questionnaire survey focusing on the ease of operation and the required time to setup wps processes with tethys wps server we had 10 attendees with various knowledge and experience on environmental web app development participate the workshop and survey see fig 13 the survey generally focused on 1 level of difficulty to deploy a wps service with tethys wps sever compared with from creating a wps using other means 2 duration of time to convert an existing app function into a wps process through defining the wps definition file and publishing it through command line functions based on the survey results all the attendees agree that it is easier to publish app functions as wps using tethys wps server fig 14 shows the difficulty level scale 1 to 10 where 1 is very easy and 10 is very difficult of deploying wps with without using tethys wps server for the attendees with different years of web application development experience based on the different programming level of the survey attendees most of them spend less than 15 min to convert an existing app function into a wps process and less than 3 min to publish it through command lines shown as fig 15 approximate 60 of the attendees estimate that this wps deployment process takes less than 5 of the total app development time while the other 40 estimate it may take 5 20 overall with tethys wps server the time of exposing an app function as a wps service is negligible 4 discussion the motivation of this work was to create a ready to use tool to expose web app functions to standard ogc wps thereby facilitating the development of web apps containing complex environmental models pywps was chosen for server side ogc wps implementation because it is python based and supports python scripts tethys platform was chosen as the development environment because of its demonstrated advantages in developing web based environmental apps it enables those with limited web development skills to develop web based environmental apps using a pre packaged web app development environment including geoprocessing tools for spatial data map rendering and visualization distributed computing and database management jones et al 2014 an api was developed for exposing tethys app functions as wps processes a set of command line functions was developed for wps management on the server based on the case studies presented here and our own experience with tethys wps server the key outcomes of this work for app developers using tethys platform include 1 ease of implementation it is possible to add wps processes without needing to change well written codes in existing web apps 2 easier maintenance a wps process is based on and connected with a web app so these services can be debugged tested and updated together with the web app enabling simpler maintenance of the services 3 avoidance of code duplication as ogc wps can be used across applications with different programming languages over different computational platforms wps processes hosted on tethys wps server can be used within other tethys apps or by third party applications or clients which support ogc wps specification 4 lowering the barrier to environmental ogc wps development and deployment tethys platform has been demonstrated to successfully lower the barrier to developing and deploying environmental web apps tethys wps server allows developers to convert existing app functions into wps processes making the wps generation process almost transparent to developers a wps process is automatically deployed along with the web app from which it is defined and can be flexibly activated or deleted by command lines therefore the barrier to developing ogc wps processes should be lowered 5 facilitating complex environmental web app development implementing complex environmental models to web apps can be a challenging task because complex models are normally time consuming processes which require task management asynchronous execution data storage and other related issues as demonstrated in our case study decomposing the model to loosely coupled wps processes can avoid many web development issues especially benefiting environmental scientists and engineers with limited programming skills moreover a wps process can contain a series of other wps processes which is necessary for environmental modelling as many complex environmental models contain multiple steps for example some models may first decompose the water system into atmosphere land surface and subsurface each component may contain a list of more detailed process level services such as land surface including infiltration evaporation runoff and others and each process can be decomposed to multiple smaller services in addition to creating a tethys specific implementation of wps and demonstrating its utility this work also serves as a general methodological experience and guidance for alternative implementations of wps which may not use the tethys django framework we have shown that disaggregation of a complex workflow into multiple modular wps instances can help avoid overloading a single server and does yield many of the benefits reported by castronova et al 2013 and goodall et al 2011 especially enabling models to be flexibly extended and reused by clients from different systems others can learn from and emulate our success in deploying gis enabled web applications that include both a front end gui for end users and a back end wps service which can be activated and deactivated through simple server side commands maintaining the integrity of pywps with only minor changes as a separate package that is linked into our tethys infrastructure we gain the benefit of being able to readily upgrade to newer versions of this library that may become available in the future in addition our experience with the pywps library specifically is highly positive and serves as a recommendation for this library in similar use cases where python is the primary server side technology we expect that our observations and outcomes will have broader application for future environmental web application developers beyond the tethys user and developer community we also note a few challenges that remain with respect to this work first it still requires minor extra coding to integrate functions of an app into wps processes app developers must manually define wps processes following the api which also causes some level of code duplication in the app including request and response data processing second the services hosted on tethys wps server currently are configured to be accessible to anyone without any authorization or authentication requirements the third challenge is not a shortcoming of tethys wps server but is a shortcoming of wps in general and is related to moving large datasets between services which can cause network latency one way to minimize this effect is to avoid passing large sizes of messages when designing services this means even though tethys wps server provides an easy environment to develop wps there remains a high requirement for developers ability to decompose a complex modelling system into a set of representative services and design services with a minimum size of input and output data 5 conclusion and future work in this study we developed an open source platform called tethys wps server using pywps which can help web app developers expose app functions to standard ogc wps processes a set of command line functions was created for flexible wps processes management including publishing listing and removal a tethys web application coupling two wps processes was developed to demonstrate the advantages and benefits of tethys wps server for complex environmental modelling systems through tethys wps server one or more functionalities in each tethys app can be exposed as ogc wps processes through several simple steps and deployed along with the tethys app with the work presented in this study tethys wps server can lower the barrier to ogc wps development and deployment and further improve complex modelling web applications development in the environmental domain the next steps for tethys wps server include upgrading it from a tethys internal application to a django application that can be easily coupled with any django based system handling the problem of security and user authentication and providing more examples and guidance on well designed modularization and decomposition of complex problems to avoid large data passing problems furthermore we have provided here only a hydroprospector web app to serve as a proof of benefits for using tethys wps server in complex environmental web app development more complicated web apps are needed to fully test the pros and cons of tethys wps server 5 1 software availability tethys platform source code https github com tethysplatform tethys home page http www tethysplatform org license the bsd 2 clause open source license pywps source code https github com geopython pywps home page http pywps org license the mit license tethys wps server source code https github com tethysplatform tethys tree tethys wps web page http cosmo byu edu tethys wps service wps request getcapabilities license the bsd 2 clause open source license case study apps three web apps in the case study can be found at http cosmo byu edu apps login credential username password demo demo the source code for these three web apps are available on github in the following repositories watershed delineation for dominican republic app https github com xhqiao89 watershed delineation app o reservoir calculation for dominican republic app https github com xhqiao89 reservoir calculation app o hydroprospector for dominican republic app https github com xhqiao89 hydroprospector app author contributions and acknowledgements author contributions are as follows qiao did the bulk of the code development and writing li made significant code contributions ames was the primary research advisor and contributed extensively to the writing nelson and swain provided significant intellectual support in terms of the case study and tethys platform integration the authors express their appreciation to dr norman l jones tethys steering committee byu hydroinformatics lab and comprehensive reviews and comments from dr lorne leonard at penn state university and other reviewers for their input all of which has greatly improved this work 
26235,developing a complex environmental modelling web application or web app can be a challenging task that requires integration of various models and data sources with ever changing internet technologies service oriented architecture soa has been shown to be useful for building complex modelling workflows however compared with other types of web services such as those for data delivery and mapping the implementation of open geospatial consortium ogc web processing services wps for environmental modelling and data analysis is not very common this problem stems in part from the lack of tools to simplify the development and deployment of wps for the broad and complex set of environmental modelling applications this paper presents the development and testing of a ready to use wps implementation called tethys wps server which provides a formalized way to expose web app functionality as standardized wps alongside a web app s graphical user interface the wps server is created based on tethys platform by leveraging pywps three tethys web apps are developed to demonstrate how web app functionality s can be exposed as wps using tethys wps server and to show how these wps can be coupled to build a complex modelling web app moreover we demonstrate that the services hosted on tethys wps server follow ogc standards correctly and can be used successfully by third party applications and clients that support the ogc wps specification keywords tethys platform web processing service wps web app interoperability pywps 1 introduction environmental modelling can be extremely complex because it includes dynamic physical chemical biological and human processes that can vary at different spatial and temporal scales an accurate environmental modelling system often requires integrating multiple models data sources and analysis routines into a workflow to address a research question and requires some level of cooperation among experts with different backgrounds the concept of chaining interoperable model components is gaining momentum for modelling because such a chain can potentially answer more questions than the individual models alone castronova et al 2013 dubois et al 2013 generally we can achieve model interoperability by sharing input and output files directly rewriting models into a single software system or establishing software architecture principles that facilitate the coupling of independent models belete et al 2017 granell et al 2010 in the model coupling approach models are written in a modular way in which each model performs an isolated task while the whole workflow addresses a much broader problem this approach enables each model to remain as flexible extensible and reusable as possible argent et al 2006 castronova et al 2013 schaeffer 2008 however integrating multidisciplinary heterogeneous models still involves barriers such as different programming languages operating platforms and user interfaces it is also difficult for researchers to understand models from other disciplines jiang et al 2017 yue et al 2016 hence setting up a system to make heterogeneous models easily connected remains a challenge service oriented architecture soa has been widely used to integrate models and build scientific workflows bosin et al 2011 lin et al 2009 yue et al 2016 zhao et al 2012 this standards based loosely coupled and service oriented approach emphasizes the decomposition of a system into functional components that communicate via web services castronova and goodall 2010 web services enable communication and interoperation among various applications over the network by using open standards and protocols which means applications written in different programming languages or running on different platforms can seamlessly exchange data over the internet through web services michaelis and ames 2009 nativi et al 2013 the model developer can therefore focus more on how to structure the internal algorithms goodall et al 2011 it has been shown that soa based applications can address the issues of data accessibility and service interoperability for environmental models granell et al 2010 huang et al 2011 mason et al 2014 zhao et al 2012 also it has been demonstrated that soa has significantly improved dealing with complex problems by making data and models available on the internet as interoperable services dubois et al 2013 nino ruiz et al 2013 skøien et al 2013 yang et al 2009 while numerous environmental web services exist for water data distribution e g horsburgh et al 2015 maidment et al 2009 and for web mapping e g blower et al 2013 palomo et al 2017 environmental models as web services is still an area of research that has not been widely investigated and implemented belete et al 2017 hu et al 2015 vitolo et al 2012 2015 the open geospatial consortium ogc has promulgated the web processing service wps specification which has been demonstrated as an efficient technology for publishing geospatial processes and constructing integrated model chains castronova et al 2013 schaeffer 2008 tan et al 2015 ogc is the foremost organization guiding the development of standards and specifications for geospatial services and it manages a global consensus process that results in approved interface and encoding standards that enable interoperability among and between diverse applications ogc wps is a commonly recognized specification for publishing processes as web services it specifies a standard method for processing data as a request from client to server using extensible markup language xml for communication through the internet schut and whiteside 2007 ogc wps also standardizes the interoperation and communication between wps which provides flexibility to create workflows for different purposes it has also enabled openly sharing models over the internet to address the needs for complex simulations that involve diverse data and algorithms kumar and saran 2014 many recent studies have demonstrated orchestrating ogc wps into environmental workflows feng et al 2011 have developed five ecosystem disciplinary models that comply with the ogc wps specification and a geospatial model sharing interface geomsi that provides a service interactive interface for sharing accessing models through wps a modelling system that implements a time driven process simulation of wetland ecosystems has been established through integrating these five remote services vitolo et al 2012 implemented a web service based modelling system for hydrological modelling on the basis of the fuse modelling framework clark et al 2008 exposing hydrological processes using an open source library called pywps castronova et al 2013 have built a wps process of the topmodel hydrologic model and used it within a client application they advanced pywps to maintain state and store data values on the server in order for the wps to perform time dependent calculations kumar and saran 2014 designed and implemented a wps process that fetches data from an ogc web coverage service wcs server and performs the normalized difference vegetative index ndvi calculation astsatryan et al 2015 developed several vegetation index computation wps processes using pywps and a user friendly portal using the joomla content management system to enable users to compute either a single vegetation index or a combination of vegetation indices as a workflow some studies also include cloud computing and parallel computing to improve the performance of complex wps processes tan et al 2015 constructed an elastic parallel ogc wps on a cloud based cluster to provide high performance computation astsatryan et al 2015 designed and applied hpc clusters with an effective parallelization algorithm to speed up the execution time of the vegetation index computation wps compared with web services for water time series data e g cuahsi wateroneflow and spatial data e g ogc web mapping and web feature services the implementation of wps for environmental modelling and data analysis is still not particularly common indeed the existing literature is more heavily weighted towards specific services for particular environmental workflows rather than general tools to support creating wps services one obvious exception to this observation is the readily available capabilities of the commercial environmental systems research institute esri arcgis server software which can easily publish data analysis and modeling services arcgis server uses a proprietary format for services consumed by the arcgis desktop applications and it can also serve wps services to be consumed in web applications and other desktop software esri 2018 notable recent examples of data processing services developed and deployed using arcgis server include leonard et al 2014 yue et al 2015 we posit that there is much value in exposing existing models and data analysis workflows via wps in addition to graphical user interfaces gui for optimal flexibility this work presents the design development and testing of an ogc wps system on the tethys platform a collection of existing open source gis tools wrapped in a django python framework we elected to use tethys platform as our development environment because it is open source and provides a complete and relatively uncomplicated environment for web based environmental modelling applications development tethys platform is intended for the development and deployment of web apps that are characterized as generally single purpose lightweight web applications that are independently developed and are installed and uninstalled from a web app portal mirroring the app paradigm of mobile devices swain et al 2016 demonstrate that tethys platform successfully lowers the barrier to developing web apps in the environmental domain by providing 1 a suite of software that meet the spatial and computational capabilities commonly required for environmental modeling including tools for geoprocessing of spatial data distributed computing database management map rendering and visualization 2 a programmatic means to use each of the recommended software systems in a single programming language python 3 a reduction to the web development skills required to develop web apps and 4 a web safe mechanism for deploying the finished web apps that is flexible enough to work on the most common means for obtaining hardware swain et al 2016 our research goal was to generate an approach of simultaneously exposing web app functionality as wps when developing a web app this approach makes the process of wps development almost transparent to developers in this way environmental modelers and developers can focus on creating web apps and tethys platform takes care of creating the corresponding wps services in addition exposing apps functions as wps processes can improve the interoperability and reusability of apps it also facilitates the implementation of complex modelling including chaining apps for integrated modelling the remainder of this paper is organized as follows the system design and implementation of tethys wps server is shown in section 2 we also present the design of a hydroprospector hydrological modelling system to demonstrate how tethys wps server enables and simplifies environmental workflow modelling the results of this research are described in section 3 a detailed discussion on the benefits of this research for environmental modelling and how it successfully facilitates complex environmental modelling web app development are presented in section 4 section 5 provides conclusions and opportunities for future work in this area section 6 describes the software availability and source code of tethys wps server case study apps and all the software used in this paper 2 methods 2 1 system design the fundamental purpose of tethys wps server is to provide a simple method to expose function s of environmental web apps as wps this allows environmental modelers and developers to focus more on web app development and less on the details of the ogc wps specification a tethys app project is organized using the model view controller mvc software architectural pattern leff and rayfield 2001 swain 2015 the model is the app s data structure it directly manages the data logic and rules of the app the view is the visualization of the data the controller handles user input and performs interactions on the data model or view a tethys app receives input datasets the data model from users through a gui performs computation in the backend controller and returns outputs to the web browser the view the core part of a tethys app is its controller functions which are implemented in python similar to tethys apps the mechanism of wps also includes accepting input parameters from a client executing processes in the backend and returning outputs to the client hence it is feasible to disseminate tethys app functions as wps processes the primary difference between tethys apps and wps processes is each tethys app defines its own specific formats of inputs and outputs while the inputs and outputs of wps processes are uniformly defined in xml format each tethys app typically contains its own data analysis or modelling workflow to provide a solution for one specified task or several tasks as shown in fig 1 here we use the term workflow to indicate the overall functionality of a web app a workflow is comprised of one or more computational processes such processes can be hosted within the app itself or can be included as web processing services provided by other apps for example the workflow of a runoff prediction app includes a snap function that moves a user defined point to the nearest river a watershed delineation function that generates watershed boundaries based on the snapped point and a runoff calculation function that calculates runoff within this watershed area using the latest precipitation forecasts each function of this workflow can be part of other water resources modelling tasks with tethys wps server these functions can be exposed as ogc wps processes and reused in the workflow of other tethys apps or other third party clients that support the ogc wps specification the general system architecture of tethys wps server and its relationship with tethys platform is shown in fig 2 tethys platform consists of three major components tethys software suite tethys software development kit sdk and tethys portal tethys software suite synthesizes several free and open source software foss projects that are needed for developing environmental modelling applications including geoserver 2013 for spatial datasets publishing 52 north 2018 for geoprocessing tools postgresql 2018 database with postgis 2018 extension for spatial datasets storage htcondor 2018 for distributed computing and a number of javascript libraries like openlayers 2018 and highcharts 2018 to help visualization tethys sdk provides multiple python apis for each supporting software element this makes it possible to orchestrate the functionality of each software using python in web app scripts tethys portal is a web portal used to host web apps that developed with tethys platform christensen 2016 swain 2015 in this study tethys wps server is implemented as a plugin component that has no effect on other components and functions of tethys platform the purpose of this design is to 1 leave apps developed based on former versions of tethys platform unaffected and 2 make exposing wps a flexible option which means the app can execute normally with or without exposing internal functions as wps processes after exposing various functions processes as wps clients are able to send requests to the server to fetch related information about specific processes or execute processes once the wps server is invoked by a request it will automatically accept input data or fetch data from specified databases generally with urls perform computation with the data encode the result into xml and send it back to the client 2 2 system implementation the first challenge of implementing tethys wps server is to integrate an existing software product into tethys platform to provide server side implementation of ogc wps interface specification by server side implementation we refer specifically to implementing a wps server on a web server to handle requests from clients and responses back to clients by using existing ogc wps implementation software we can avoid having to build this functionality from scratch and can take advantage of the debugging and testing of the software by others of course this is the self evident advantage of using any third party module as tethys platform is python based jones et al 2014 and we aim to directly disseminate app functions as wps without too much modification the implementation project is required to support python scripting doing so can also facilitate code debugging when developing wps processes table 1 lists several popular software packages that support server side ogc wps implementation geoserver wps and deegree wps müller 2007 are both java based frameworks and only support java scripting 52 north wps is java based implementation according to its documentation 52 north supports python scripting however the python support in 52 north was originally designed for use within the esri arcgis python library in the windows operating system limiting cross platform usage boerboom 2013 there is also a 52 north module for exposing ilwis gis 2001 functions as wps services unfortunately there does not appear to be support in 52 north for exposing native python wps functions on a linux server arcgis server wps refers to its modelbuilder module that supports exposing arcgis geoprocessing services as ogc wps pywps 2009 is a python based server side implementation of wps allowing integration publishing and execution of python processes via the wps standard it was originally developed for implementing grass gis 2018a operations as ogc wps processes and has shown to be well suited for integration with tethys platform pywps version 4 utilizes werkzeug 2011 an open source web server gateway interface wsgi utility library to make the wps functionalities written in python be accessible over the internet there are four core classes in pywps service process wpsrequest and wpsresponse the service class streamlines the request pre processing process execution and the response post processing into a complete hypertext transfer protocol http request response cycle a complete http request response cycle begins with a client sending a request message to a server the server handles the request and sends a response message back to the client the service class is the top level object representing the wps service it can run as a wsgi application the process class specifies the attributes attached to a generalized wps process including metadata terms and a handler function to hold process logic implementation and a set of functions to operate on a process object each wps process accepts a wpsrequest argument and returns a wpsresponse object the workflow of pywps is shown in fig 3 when the wps server is invoked by a http request pywps utilizes werkzeug to create a werkzeug request object containing metadata about the http request and then packages it to a pywps wpsrequest object ogc wps specifies three operations that can be requested by clients and performed by a wps server including getcapabilities describeprocess and execute see table 2 for getcapabilities and describeprocess requests pywps directly returns werkzeug response objects for execute requests pywps loads the appropriate wps process and passes the wpsrequest to the function the function is responsible for returning a wpsresponse object which can then be converted to a werkzeug response and sent back to the web server tethys platform is powered by django framework of which the primary deployment platform is wsgi when a tethys page is requested django creates a django httprequest object including the request metadata then django passes the httprequest to the specified function and returns a django httpresponse object because tethys platform and pywps are both wsgi compliant applications they can be deployed on the same web server and coexist as two separate web applications running in parallel with different python interpreter instances however for a seamless integration it is preferable for the two applications to use the same python interpreter instance and thereby share python level objects variables and functions as one web application to allow for this seamless integration we choose to downgrade pywps from a wsgi application to a pure python package this was accomplished by removing the werkzeug decorator request application from the callable functions in the service class and the wpsresponse class the slightly modified pywps still has the full implementation of wps functionality that can be consumed as normal python classes or functions from within tethys in addition since the interfaces of pywps classes and functions are unchanged they still only accept werkzeug request objects as input and return werkzeug response objects as output a conversion between werkzeug versioned request response objects and django versioned request response objects is required the general workflow is depicted in fig 4 after integrating pywps with tethys platform the next step was to establish a method to connect tethys apps with the wps server in pywps each wps process is defined as a process class in a python script containing metadata configuration and a handler function holding detailed execution algorithm the handler method can directly call outside functions as a whole or part of the wps process to support this behavior we created a wps definition file as shown in fig 5 that is included with the tethys app source code containing a pywps process class definition template the app s functions can be called in the handler function to be disseminated as wps processes in pywps all the wps processes should be located in the same directory to be imported in the server to implement this capability tethys platform automatically collects all the wps definition files in each app hosted on the server and creates symbolic links of them in a location identified in the wps server configuration under this approach the wps definition files located in deployed tethys apps are imported to the wps server as shown in fig 5 the app s algorithm can be written in a separate file that can be used by both the app gui and the wps process the wps feature is thereby a new route to access the app s algorithm and any update to the algorithm will be automatically available in both the app gui and the wps process 2 3 experimental case study design this section presents design of use cases to illustrate 1 bi directional communication between tethys apps and tethys wps server including how the functions of a tethys app can be exposed as wps processes on tethys wps server and how services hosted on it can be included in another tethys app as components of the workflow 2 consuming services hosted on tethys wps server with third party wps clients the aim of these use cases is to test and demonstrate how tethys wps server can simplify environmental ogc wps development and significantly lower the barrier to developing complex web apps 2 3 1 hydroprospector use case consider hydroprospector as a reservior management model that calculates the storage capacity curve of a reservior to help decision makers choose the best dam location the storage capacity curve which refers to the relationship between dam height and reservior storage capacity is important for dam planners designers and operators issa et al 2017 to calculate the storage capacity curve the first step is delineating a watershed based on a dam location the watershed basin defines the maximum reservior size and works as a boundary for latter calculation then the reservoir s storage capcity are calculated for different dam heights finally the storage capacity curve is plotted using different dam heights with corresponding calculated storage capcity the hydroprospector model contains a complex geoprocessing workflow that requires a relatively long processing time about 2 min see compute time discussion in section 3 3 challenges with developing this app include but are not limited to complex geoprocessing coding handling asynchronous execution and job management furthermore the watershed delineation process and reservoir storage calculation process are both essential and commonly used in environmental modelling exposing these processes as web services can make them more easy to be reused in other complex models to demonstrate this we developed a service oriented tethys app that performs hydroprospector model in the dominican republic country workflow shown as fig 6 instead of coding from scratch the app consumes two wps processes hosted on tethys wps server watershed delineation wps and reservoir calculation wps these two wps processes are respectively exposed from two tethys apps watershed delineation for dominican republic app and reservoir calculation for dominican republic app both of these two tethys apps are functionally independent with their own graphical user interfaces both of these two wps processes use grass gis functions for geoprocessing calculation grass gis provides gis functions that can be accessed via python code neteler et al 2008 the watershed delineation service fig 7 accepts coordinates of a point and returns the snapped point at nearest stream and a watershed in geographic markup language gml format the service first performs a grass gis function r watershed to generate a set of maps indicating flow accumulation and flow direction then a point indexing function is performed to link the given outlet to the nearest stream network via a shortest snap function finally a watershed basin is calculated with the snapped outlet point and the flow direction map the reservoir calculation service fig 8 calculates the boundary and volume of a reservoir which is generated based on coordinates of a pour point and a designed water level at the pour point a maximum boundary polygon is required as input to subset the digital elevation model dem file to reduce the execution time of raster calculation process the service uses the grass gis function r lake to generate a reservoir raster from the dam point the resulting reservoir raster based on which the reservoir boundary and volume are generated contains cells with values representing reservoir depth and null for all other cells beyond the reservoir both the output of the watershed delineation service and one input of the reservoir calculation service are polygons in the geojson format having variables in the same format enables the connection of these two services each of the services hosted in these tethys wps server instances can be executed using the ogc wps specification the hydroprospector app user interface consists of a user interactive map and a chart app code flow shown as fig 9 the user first can add a point anywhere on the map with a mouse click after selecting a point the coordinates of the user clicked point are passed to the app controller using asynchronous javascript ajax the app controller reads in the coordinates and sends it as a request to the watershed delineation service on tethys wps server as the watershed delineation service execution is finished the controller extracts the watershed and snapped point results and passes them to the map using ajax the map periodically checks the controller for progress status and adds the watershed and snapped point to the map once the processing is finished next the user defines dam height and interval then clicks the calculate button each gage height with the watershed and snapped point from the first step are passed to the controller using ajax then the controller submits a request to the reservoir calculation service on tethys wps server once the service execution is finished and the response is returned to the controller function the controller function extracts the reservoir boundary and volume and passes them to the gui to sequentially get the proposed reservoir boundary and volume results the data with updated gage height is passed until the former processing is finished after each ajax function is completed the reservoir boundary is added to the map and the reservoir volume is drawn in the chart the process is completed when the storage capacity values for all gage heights are calculated 2 3 2 wps client use case one advantage of tethys wps server is that the wps services hosted on it can be consumed not only by tethys apps but also by various types of clients set up in accordance with the ogc wps implementation specification the simplest client of a wps service is a web browser the wps services can be consumed through a web browser using http get method with key value pair kvp encoded requests responses and exceptions are then returned to the web browser however there are also some third party clients and libraries capable of consuming ogc wps services in the hydroprospector app we use owslib 2017 to interact with tethys wps server including sending requests to the server and receiving responses from services owslib is a wps client library that provides a common api for accessing and executing ogc wps services we also used an open source desktop gis software qgis 2018b as a wps client to demonstrate that the wps processes hosted on tethys wps server conform to the ogc wps standard and are able to be consumed by other third party software that supports ogc wps 3 results 3 1 tethys wps server we developed an api for exposing tethys app functions as ogc wps processes when a new tethys app project is created a wps definition file fig 10 is automatically included in the app source code the wps definition file provides a template that allows app developers to expeditiously define a wps process each wps process is defined as a pywps process class which contains an initialization function and a handler function the initialization function includes the definition of inputs outputs service metadata and server based parameters the handler function specifies the actual operation of the wps process other outside functions defined in the tethys app can be called in the handler method to become a wps process or part of a wps process this design allows the wps process to be updated simultaneously with any modification of the app the services described in the wps definition file are not activated automatically they must be activated or deactivated using command line statements created to help manage wps processes on tethys wps server these include tethys wps list lists all published and unpublished wps processes this lists the available published and unpublished processes on the linux command line with no further interaction required from the user tethys wps publish publishes selected wps processes this interactive command results in a prompt to the user requesting the name of a specific app and associated service to be published tethys wps remove removes selected wps processes this interactive command results in a prompt to the user requesting the name of the service to be removed the benefits of using command lines include simplifying common management tasks related to wps and allowing app developers the flexibility to modify wps processes without affecting the apps existing operation through its graphical user interface 3 1 1 interaction with tethys wps server ogc wps specifies three operations that can be requested by clients and performed by a wps server including getcapabilities describeprocess and execute table 2 supported data formats for inputs and outputs include literal data character string value date etc complex data vector raster and bounding box data bounding box area with coordinate reference system wps servers can be invoked using the http get method with a kvp encoded request or the http post method using xml format for the request generally the kvp encoding method is accepted for getcapabilities and describeprocess requests while the execute requests often adopt xml encoding the kvp encoded requests are written as urls composed of a series of request parameters and input data they are commonly used for simple requests or requests with simple inputs like literal data while sending an execute request that includes complex data vector raster or bounding box data the xml coding method is recommended over kvp the inputs can be included directly in the request or they can reference web accessible resources the outputs can be returned in the form of an xml response document either embedded within the response document or stored as web accessible resources tethys wps server as an ogc wps implementation supports executing processes either synchronously or asynchronously for the synchronous execution a wps client sends an execute request to tethys wps server and keeps listening for a response until the process has completed and returned the result in this situation the client and wps server should keep connected for the asynchronous execution a wps client receives a response immediately after sending an execute request to tethys wps server the response confirms that the request is received and accepted by the server a processing job has been created and will be run the response contains execution status and a job identifier with which the client can check the execution status it also contains the location usually as url where the execution result can be found after the processing job has completed typically asynchronous execution is recommended for wps processes as geoprocessing processes usually contain complex and time consuming calculations 3 2 case study results 3 2 1 hydroprospector use case we deployed three tethys web apps at the website http cosmo byu edu apps watershed delineation for dominican republic app reservoir calculation for dominican republic app and hydroprospector for dominican republic app from the first two apps we respectively exposed a watershed delineation wps and a reservoir calculation wps on tethys wps server details in table 3 these processes were exposed through the linux command line statements described previously the hydroprospector app was developed by coupling these two wps processes into the workflow shown in fig 6 owslib is used to interact with the wps processes on tethys wps server the hydroprospector app user interface fig 11 includes an interactive map to show watershed and reservoir boundaries along with a chart to show the storage capacity curve of designed dams the user is required to 1 click on the map to select an outlet point for watershed delineation and then 2 define a dam height and interval the app will dynamically draw the storage capacity curve in the chart and show corresponding reservoir boundaries with different dam heights when selecting a data point in the chart the corresponding reservoir boundary is shown on the map the service oriented approach presented here is particularly suited to complex or time consuming workflows where information must persist beyond server client transactions for example when we directly implemented the hydroprospector model in a single web app the model execution time often exceeded the typical http request response timeout setting and failed to reply to the request made from the client the browser timeout can be extended long enough to account for this or can be disabled completely however this can affect the normal execution of other web browser requests in addition interruption or error can be caused by conflicting requests by different clients to overcome these barriers a job queue system should be included to implement asynchronous execution and provide real time monitoring of different requests a database or other persistent data store mechanism is also required for the storage of job information and results to allow users to check the job status and retrieve result this approach is complicated and time consuming and it requires advanced web development skills tethys wps server as an ogc wps implementation supports storing the execution response and outputs as web accessible resources that can be retrieved by the client it also supports asynchronous execution which can keep the execution status updated and accessible while the request is being processed by using tethys wps server app developers can focus more on model design rather than on web development 3 2 2 third party wps client use case we choose qgis as a wps client to demonstrate that the wps processes hosted on tethys wps server can be used by other third party clients that support ogc wps specification qgis was chosen because it is open source and is a comprehensive gis environment qgis has a wps python client plug in through which qgis can directly consume wps services on wps servers the interactions include listing wps capabilities sending request to execute a wps process and visualizing outputs in qgis interface we successfully connected to tethys wps server executed the watershed delineation wps and the reservoir calculation wps through the qgis wps client and displayed the results in the qgis map this effort proved to be uncomplicated and self explanatory with no unusual results or unpredicted outcomes hence no further discussion of this test is given here 3 3 quantitative analysis an analysis of programming language composition was performed to measure how tethys wps server overcomes the hurdle of complex web app development in environmental modelling we compared the hydroprospector app with another tethys app called storage capacity service https github com xhqiao89 storage capacity service git which implements the same functionality of the hydroprospector model fully natively without using wps services we used the count lines of code cloc linux package to count the number of code lines excluding blank lines comment lines and third party libraries included one aim of tethys wps server is lowering the barrier to complex environmental web app development this is evident by the reduced amount of python used in the hydroprospector app shown in table 4 204 lines compared to 603 lines for the storage capacity service app in addition the storage capacity service app adopts celery solem 2007 for asynchronous execution and task job management and postgis database for job results storage none of which is required in the wps based hydroprospector in addition we selected 10 hydropower dam sites around dominican republic country and calculated the storage capacity curve with the hydroprospector app and the storage capacity service app respectively the dams were all 30 m high and the interval for calculating the storage capacity curve was set to 10 m the total compute time for each dam site were recorded as fig 12 the average compute time of using the hydroprospector app is 147 2 s while 103 8 s with the storage capacity service app the hydroprospector app takes a longer time because it calls two independent wps services which contains more steps than the pure storage capacity curve calculation process such as setting up grass gis environment creating grass gis projects input data preprocessing and outputs post processing 3 4 qualitative analysis as a qualitative assessment of how tethys wps server lowers the barrier of ogc wps deployment we conducted a workshop and collected results from a questionnaire survey focusing on the ease of operation and the required time to setup wps processes with tethys wps server we had 10 attendees with various knowledge and experience on environmental web app development participate the workshop and survey see fig 13 the survey generally focused on 1 level of difficulty to deploy a wps service with tethys wps sever compared with from creating a wps using other means 2 duration of time to convert an existing app function into a wps process through defining the wps definition file and publishing it through command line functions based on the survey results all the attendees agree that it is easier to publish app functions as wps using tethys wps server fig 14 shows the difficulty level scale 1 to 10 where 1 is very easy and 10 is very difficult of deploying wps with without using tethys wps server for the attendees with different years of web application development experience based on the different programming level of the survey attendees most of them spend less than 15 min to convert an existing app function into a wps process and less than 3 min to publish it through command lines shown as fig 15 approximate 60 of the attendees estimate that this wps deployment process takes less than 5 of the total app development time while the other 40 estimate it may take 5 20 overall with tethys wps server the time of exposing an app function as a wps service is negligible 4 discussion the motivation of this work was to create a ready to use tool to expose web app functions to standard ogc wps thereby facilitating the development of web apps containing complex environmental models pywps was chosen for server side ogc wps implementation because it is python based and supports python scripts tethys platform was chosen as the development environment because of its demonstrated advantages in developing web based environmental apps it enables those with limited web development skills to develop web based environmental apps using a pre packaged web app development environment including geoprocessing tools for spatial data map rendering and visualization distributed computing and database management jones et al 2014 an api was developed for exposing tethys app functions as wps processes a set of command line functions was developed for wps management on the server based on the case studies presented here and our own experience with tethys wps server the key outcomes of this work for app developers using tethys platform include 1 ease of implementation it is possible to add wps processes without needing to change well written codes in existing web apps 2 easier maintenance a wps process is based on and connected with a web app so these services can be debugged tested and updated together with the web app enabling simpler maintenance of the services 3 avoidance of code duplication as ogc wps can be used across applications with different programming languages over different computational platforms wps processes hosted on tethys wps server can be used within other tethys apps or by third party applications or clients which support ogc wps specification 4 lowering the barrier to environmental ogc wps development and deployment tethys platform has been demonstrated to successfully lower the barrier to developing and deploying environmental web apps tethys wps server allows developers to convert existing app functions into wps processes making the wps generation process almost transparent to developers a wps process is automatically deployed along with the web app from which it is defined and can be flexibly activated or deleted by command lines therefore the barrier to developing ogc wps processes should be lowered 5 facilitating complex environmental web app development implementing complex environmental models to web apps can be a challenging task because complex models are normally time consuming processes which require task management asynchronous execution data storage and other related issues as demonstrated in our case study decomposing the model to loosely coupled wps processes can avoid many web development issues especially benefiting environmental scientists and engineers with limited programming skills moreover a wps process can contain a series of other wps processes which is necessary for environmental modelling as many complex environmental models contain multiple steps for example some models may first decompose the water system into atmosphere land surface and subsurface each component may contain a list of more detailed process level services such as land surface including infiltration evaporation runoff and others and each process can be decomposed to multiple smaller services in addition to creating a tethys specific implementation of wps and demonstrating its utility this work also serves as a general methodological experience and guidance for alternative implementations of wps which may not use the tethys django framework we have shown that disaggregation of a complex workflow into multiple modular wps instances can help avoid overloading a single server and does yield many of the benefits reported by castronova et al 2013 and goodall et al 2011 especially enabling models to be flexibly extended and reused by clients from different systems others can learn from and emulate our success in deploying gis enabled web applications that include both a front end gui for end users and a back end wps service which can be activated and deactivated through simple server side commands maintaining the integrity of pywps with only minor changes as a separate package that is linked into our tethys infrastructure we gain the benefit of being able to readily upgrade to newer versions of this library that may become available in the future in addition our experience with the pywps library specifically is highly positive and serves as a recommendation for this library in similar use cases where python is the primary server side technology we expect that our observations and outcomes will have broader application for future environmental web application developers beyond the tethys user and developer community we also note a few challenges that remain with respect to this work first it still requires minor extra coding to integrate functions of an app into wps processes app developers must manually define wps processes following the api which also causes some level of code duplication in the app including request and response data processing second the services hosted on tethys wps server currently are configured to be accessible to anyone without any authorization or authentication requirements the third challenge is not a shortcoming of tethys wps server but is a shortcoming of wps in general and is related to moving large datasets between services which can cause network latency one way to minimize this effect is to avoid passing large sizes of messages when designing services this means even though tethys wps server provides an easy environment to develop wps there remains a high requirement for developers ability to decompose a complex modelling system into a set of representative services and design services with a minimum size of input and output data 5 conclusion and future work in this study we developed an open source platform called tethys wps server using pywps which can help web app developers expose app functions to standard ogc wps processes a set of command line functions was created for flexible wps processes management including publishing listing and removal a tethys web application coupling two wps processes was developed to demonstrate the advantages and benefits of tethys wps server for complex environmental modelling systems through tethys wps server one or more functionalities in each tethys app can be exposed as ogc wps processes through several simple steps and deployed along with the tethys app with the work presented in this study tethys wps server can lower the barrier to ogc wps development and deployment and further improve complex modelling web applications development in the environmental domain the next steps for tethys wps server include upgrading it from a tethys internal application to a django application that can be easily coupled with any django based system handling the problem of security and user authentication and providing more examples and guidance on well designed modularization and decomposition of complex problems to avoid large data passing problems furthermore we have provided here only a hydroprospector web app to serve as a proof of benefits for using tethys wps server in complex environmental web app development more complicated web apps are needed to fully test the pros and cons of tethys wps server 5 1 software availability tethys platform source code https github com tethysplatform tethys home page http www tethysplatform org license the bsd 2 clause open source license pywps source code https github com geopython pywps home page http pywps org license the mit license tethys wps server source code https github com tethysplatform tethys tree tethys wps web page http cosmo byu edu tethys wps service wps request getcapabilities license the bsd 2 clause open source license case study apps three web apps in the case study can be found at http cosmo byu edu apps login credential username password demo demo the source code for these three web apps are available on github in the following repositories watershed delineation for dominican republic app https github com xhqiao89 watershed delineation app o reservoir calculation for dominican republic app https github com xhqiao89 reservoir calculation app o hydroprospector for dominican republic app https github com xhqiao89 hydroprospector app author contributions and acknowledgements author contributions are as follows qiao did the bulk of the code development and writing li made significant code contributions ames was the primary research advisor and contributed extensively to the writing nelson and swain provided significant intellectual support in terms of the case study and tethys platform integration the authors express their appreciation to dr norman l jones tethys steering committee byu hydroinformatics lab and comprehensive reviews and comments from dr lorne leonard at penn state university and other reviewers for their input all of which has greatly improved this work 
26236,pathline or streamline computation is used today to improve the understanding of fluid flow behavior in groundwater modelling in particular pathline computation on unstructured grids requires an accurate velocity interpolation method when the flow velocity field is given by numerical simulators only at the faces of the grid blocks as for example in the case of the integral finite difference method is used for spatial discretization in the case of 3d voronoi unstructured grids a corner velocity interpolation cvi method allows continuous velocity field interpolation while preserving the mass conservation principle we have developed a computer code named tough2path able to compute the velocity field based on the cvi method and generalized barycentric coordinates for 3d voronoi polytope grid blocks tailored for the tough family of codes results for the classical quarter five spot problem show that the coded algorithm correctly reproduces the pathlines computed with semi analytical methods keywords pathlines tough unstructured grids groundwater modelling 3d voronoi software availability name of the software tough2path developer s bonduà contact address stefano bondua unibo it designed by s bonduà v bortolotti year first available 2018 hardware requirement pc software requirement windows os program language c program size 175 kb binary file availability freely available as binary file at http software dicam unibo it tough2path 1 introduction in order to improve the understanding of fluid flow behavior in the groundwater modelling a very powerful method is to trace the flow streamlines or pathlines of the fluid particles streamlines are a family of curves that are instantaneously tangent to the velocity vector of the flow a pathline is the trajectory of a particle moving at the same velocity as the fluid flow hægland et al 2007 in the case of steady flow when the velocity vector field does not change with time streamlines and pathlines coincide usually when reservoir behavior is simulated with a numerical model the flow velocity field fvf is computed only at the corners or on the faces of the grid blocks used to discretize the reservoir domain the fvf inside the volume of the blocks is therefore unknown tracing accurate streamlines over a grid therefore requires finding a method to interpolate the flow velocity inside the volume of blocks there have been many efforts over the years to compute fvf distribution inside grid blocks in 1988 pollock implemented a semi analytical method of linear interpolation of the velocity field inside the blocks of structured regular grids the improvement of the pollock method for quadrilaterals grids was firstly developed by cordes and kinzelbach 1992 who adopted a isoparametric local coordinate system by prevost et al 2002 who applied the pollock method in a transformed space and then mapped back the calculated velocity for more general polyhedrons and by jimenez et al 2005 who used the lowest order raviat thomas space an isoparametric trilinear transformation of an irregular hexahedral cell to a unitary cube in a reference space matringe et al 2006 2008 improved these methods using the brezzi douglas marini space of order one all these methods are valid for triangular or quadrilateral blocks in 2d and tetrahedral or hexahedral blocks in 3d in the case of completely unstructured arbitrary convex polyhedral grids e g voronoi grids streamline computation cannot be achieved with an analytical or semi analytical methods hægland et al 2007 proposed the approach of corner velocity interpolation cvi for unstructured irregular grids in the case of quadrilateral or hexahedral blocks rasmussen 2010 interpolated fvf in convex polyhedrons by estimating the cvi and making use of the generalized barycentric coordinates of the polyhedrons zhang et al 2012 proposed a cvi method applicable to both degenerate and non convex polyhedrons interpolating the velocity field using the isoparametric mapping technique painter et al 2012 proposed a method based on equivalent nodal velocity that uses the least square error method to minimize the contribution of the velocity through the faces of a block the method can also be used in the case of neumann or dirichlet boundary condition blocks streamlines computed with this method approximate very well to the streamlines obtained with the semi analytical method of morel seytoux 1966 and with the pollock method 1988 painter et al 2012 method does not allow path computation in the region between the domain boundaries and the convex hull of the set of nodes furthermore the painter method does not obey the law of mass conservation a factor whose importance for accurate streamline construction is well known sun et al 2005 an enhanced method applicable to fully unstructured 3d grids and obeying the law of mass conservation was proposed by klausen et al 2012 it uses an enhanced cvi scheme that applies the basis functions klausen et al 2012 and the generalized barycentric coordinates warren et al 2007 see next paragraph for a detailed description of the method it follows that in the case of an unstructured 3d voronoi grid like those created with voro2mesh bonduà et al 2017 the method of klausen et al 2012 seems to be the most accurate method since i it preserves the mass flow ii there is no need for triangulation for 2d grids or tetrahedralization 3d grids thereby allowing the tracing of pathlines to be computed directly on simulation results one of the most popular computer program suite for numerical simulation of geothermal reservoir underground carbon storage nuclear waste and environmental management is the tough family of codes o sullivan et al 2001 it is a suite of simulators for non isothermal flows of multicomponent multiphase fluids in one two and three dimensional porous and fractured media pruess et al 1999 tough is very robust and flexible due to a modular structure which allows studying systems characterized by different thermo fluid dynamics conditions by choosing one of the interchangeable modules generically called the equation of state eos module in particular it permits to study non isothermal multicomponent and multiphase fluid flows in continuous or fractured porous media in 1d 2d and 3d domains berry et al 2014 the integral finite difference ifd method edwards 1972 narasimhan and witherspoon 1976 narasimhan et al 1978 is used in tough in order to solve the differential equations for the flow of mass and heat ifd preserves the mass balance flow at the interface between the blocks flow rates or velocity are therefore computed and given only at the face of neighboring blocks as far as we know there is no dedicated software that allows pathlines to be traced using the results of tough simulations performed with full voronoi 3d grids we have developed a computer software named tough2path 1 1 the code is free and can be downloaded from http software dicam unibo it tough2path that is able to compute the streamlines of particles using simulation results obtained with tough2 pruess et al 1999 3d voronoi grids and the klausen et al 2012 method as a first validation and verification step tough2path was applied on a 2d and a 3d five spot problem and results compared with semi analytical solutions although not definitive the good results of these preliminary tests permit to guarantee the good quality of tough2path 1 1 the method of klausen et al the klausen et al 2012 method makes use of an enhanced cvi scheme where the fvf is interpolated using the face basis functions and generalized barycentric coordinates barycentric coordinates are commonly used for interpolating discrete scalar fields vector fields or arbitrary multidimensional fields over irregular tessellations as they permit smooth interpolation of data located on vertices via multilinear interpolation warren et al 2007 the velocity v is interpolated at the point x inside a given block e by the following relations 1 v x e f i e f i ψ i e x 2 ψ i x j v j i v j i n i λ j x j λ j x 1 where i 1 to the number of faces of e j 1 to the number of vertices of the i th face of e e is the surface of the block e fi is the i th face of the e f i is the flow through the i th face ψ i is the i th basis function v j i is the edge not coplanar to f i of the vertex j fig 1 in case of a 2d grid the 3rd dimension of the blocks is assumed as the ration between the volume and the surface of the block n i is the normal vector to the face i λ j x is the j th barycentric coordinate of x respect to the vertex j of the block e to evaluate the generalized barycentric coordinate λ j x we implemented the methods described in warren et al 2007 and in rasmussen and lie 2014 a comparison between the two methods indicate that the percentage difference in term of time of flight and distance travelled is less than 10 2 the pathline is then calculated with an iterative procedure as follows given a particle located at the location point p 0 at time t 0 to locate the block e that contains p 0 evaluate λ j p 0 and compute the basis functions ψ i p 0 estimate v p 0 evaluate the new position of the particle as p 1 p 1 v p 0 dt or high order methods and check if the new particle position is still in the same block repeat the computation of new positions until an interrupt condition occurs maximum number of iterations encountered block with boundary conditions etc it should be noted that in the case of a cartesian grid the klausen et al 2012 method reduces to a linear interpolation of the velocity between two parallel faces and coincides with the pollock 1988 method see appendix c for the demonstration 2 tough2path code to draw pathlines for tough simulation if the particles are moving at the same velocity as the fluid then tough2path can compute the pathline of a particle through each block of a 3d voronoi discretized domain making direct use of the output file of a tough2 pruess et al 1999 simulation as well as of the klausen et al 2012 method tough2path is a command line software for windows os coded in c it applies a parallel programming approach using openmp open multi processing 2 2 openmp architecture review board the openmp specification http www openmp org 2017 accessed 2019 01 07 to speed up computation thereby allowing contemporaneously computation of a large number of particle paths at a reasonable computation time cost openmp is an application programming interface allowing multi platform shared memory multiprocessing programming it consists of a set of compiler directives library routines and environment variables tough2path can also compute the pathline taking into account flow change in time to do this we adopted linear interpolation of the module of the flow vector at the block face between two successive time steps taken from the tough2 output file 2 1 tough2path input files tough2path needs geometrical information input of both grid block shape and flow data between blocks in particular as the structure of the tough2 output file depends on the specific eos used see pruess et al 1999 for details tough2path needs to be instructed as to the location of the variables to be read see fig 2 for details therefore the input data of tough2path is composed of several files tough2path par contains the parameters of the path particle computation such as the maximum number of iterations the directive ending computation domain limits the step length and directive about automatic step length reduction etc see appendix d for details mesh is the standard mesh file of tough2 see tough2 manual pruess et al 1999 elements with volumes larger than 1 0 1020 m3 are considered ending blocks therefore when the particle enters a ending block the computation will terminate tough2viewer dat is the file generated by voro2mesh see bonduà et al 2017 2012 containing the geometrical information of each block vertices edges faces and faces normal for a detailed file format specification please refer to bonduà et al 2017 appendix b t2 out the standard output file of tough2 it must contain flow velocities between blocks usually named vel liq m s or vel gas m s header dat is a file containing at least 3 lines of characters as they appear in the t2 out file this is to allow easy parsing of the tough2 output files which are different for each eos by tough2path the user must specify the position of elem1 elem2 and the variables to be read see fig 2 for details seed points dat an ascii file space separated x y z coordinate of the initial position of the set of particles whose path is to be calculated gener is the standard gener file of tough2 if the specified flow rate of a gener element is greater than zero injection block then a seed point for each face is added to the seed points set if the flow rate is lower than zero production block then the block will be considered as an ending block ending points dat an ascii file space separated x y z r radius coordinate of the ending positions of the particle set on which to terminate path computation particle path computation will be terminated when the 3d distance between particle position and an ending point is lower than r 2 2 tough2path output files the standard output of tough2path comprises a set of ascii files providing information on the path of each input particle specifically a path file is created for each particle tracked it is an ascii space separated file where each line contains the position of the particle x y z the 3 velocity components vx vy vz the id of the block crossed travelled distance and integration time the naming convention for these files is path particle number dat t2path vtp file an xml file polydata paraview 3 3 www paraview org accessed accessed 2019 01 07 file for particle pathline visualization in paraview the file contains all the necessary information for visualization of the particle path as a polyline the coordinate of each point x y z the estimated velocity vx vy vz the id of the block to which the point belongs the integration time the total travelled distance the reason for pathline computation termination a code between 1 and 8 see table 1 node vel files are comma separated files csv of the velocity vector calculated for each nodal point for each time step the naming convention of these file is node vel time step csv tough2path log a file with information on the parameters used time of computation warnings and if any errors during the computation 3 code validation and verification a preliminary verification and validation of tough2path was obtained computing pathlines with tough2 simulated data hereinafter simply called numerical pathlines of two well known case studies a 2d five spot problem and a 3d five spot problem and comparing them with pathlines computed via semi analytical solutions hereinafter simply called semi analytical pathlines 3 1 case study a pathline tracing of the classical 2d five spot problem a semi analytical solution is available for this problem morel seytoux 1966 that therefore allows the comparison with the paths calculated by tough2path the semi analytical method computes an analytical velocity field and requires a quadrature computation to find the pathlines to this end the javandel et al 1984 velocity computation method was implemented and integrated in tough2path see appendix a for details it should be noted that the numerical pathlines computation depends on the numerical simulation results numerically simulated pressure which are strongly affected by the grid refinement and orientation used pruess and bodvarsson 1983 pruess 1991 yamamoto and doughty 2011 for this reason we present pathline results computed on several different grids in order to obtain a preliminary evaluation of the unavoidable gridding effects we used the ewasg module battistelli et al 1997 of tough2 to simulate an isothermal 20 c 2d flow in an aquifer with porosity of ϕ 5 isotropic permeability k 24 10 15 m2 thickness of h 300 m in a five spot infinite staggered pattern of size 500 500 m2 the point source iw q 1 0 kg s is located at 0 0 0 0 m while the point sink pw q 1 0 kg s is at 500 0 500 0 m neumann type boundary conditions were the implicit semi analytical reference solution for the semi analytical computation an injected fluid of density 998 9 kg m3 was considered as computed by the tough simulations tough2 simulation was performed using 5 types of grid cartesian structured grid named 2d structured 45 rotated structured grid named 2d 45structured perturbed quadrilateral voronoi grid named 2d quadperturbed voronoi grid named 2d voronoi centroidal voronoi tessellation cvt grid named 2d cvt a cvt is a particular voronoi tessellation satisfying the requirement of having the seed point at the barycenter of the particle table 2 summarizes the main characteristics of the 5 grids and they are illustrated in fig 3 the streamlines which coincide with pathlines in the case of steady flow of 4 particles were traced for all grids in all the used grids the initial position of two particles is the same p1 50 0 50 0 and p2 50 0 10 0 m while the other two particles p3 and p4 are initially positioned at the coordinates of the nodes of two blocks near the source block the termination condition for computation of all 4 pathlines was when the distance of the particle to the pw was less than the distance between the initial position and point source iw 3 1 1 results and discussions fig 3 shows the semi analytical and the numerical pathlines for five types of grids the comparisons between the time of flight tof and distance travelled dt obtained using the two methods are summarized in table 3 the columns tof difference and dt difference are calculated as tof difference semi analytical tof numerical tof semi analytical tof x 100 dt difference semi analytical dt numerical dt semi analytical dt x 100 the tof and dt differences computed for the 4 particles table 3 show that unstructured grids have a lower difference compared to structured grids particles initially located within boundary blocks exhibit greater differences in order to better map the difference between the semi analytical and the numerical pathlines as a consequence of the initial position of the particles we calculated the absolute dt difference and absolute tof difference in a fine grid in the bottom left quarter of the domain near the point source resulting in 14641 pathlines fig 4 shows the tof and dt difference maps for the 5 different grids used table 3 and especially fig 4 show that the zone with the highest difference of tof and dt is located near the boundary blocks and near the point source these results clearly shows evidence that tough2path works quite well since the maximum discrepancy with the semi analytical solution is around 6 for tof and 4 for dt except for some particles located near the border domain where the tof and dt difference can increase up to 15 and 7 respectively moreover the best results are obtained when an unstructured grid is used this confirms that unstructured grids having no preferential face orientation reproduce better the fluid flow behavior in order to improve the test to evaluate the correctness of the velocity interpolation method implemented in tough2path the tof and dt were also computed using a discrete velocity field obtained integrating the semi analytical velocity field over the faces of the grid blocks using this approach hereinafter called for the sake of simplicity semi numerical the velocity field used to compute the pathlines is not affected by the numerical approximations introduced by the tough2 simulation in table 4 are reported for each grid the maximum tod and dt absolute differences of the numerical and semi numerical pathlines both evaluated respect to the semi analytical solutions also 3 cvt refined grids with 103 104 and 105 block elements named 2d cvt 1k 2d cvt 10k and 2d cvt 100k respectively were used to verify the convergence of the numerical pathlines when the tough velocity field is used and the semi numerical pathlines when is used to the reference semi analytical solution fig 5 shows the maximum tof and dt absolute differences versus the grid size of the cvt grids as expected the maximum tof and dt absolute asymptotically decrease when the number of the grid elements increases for all the 2d cvt 1k 2d cvt 10k and 2d cvt 100k grids the starting position of the particles were far from the boundary blocks of the domain the 121 121 particles were distributed over a regular lattice of size 2 2 in the left bottom corner 10 10 of the grid therefore the resulting pathlines do not cross the boundary blocks of the domain resulting in a lower maximum tof and td differences therefore these results corroborates that in general the pathlines computed through boundary blocks are poorly accurate it is worth mentioning that the fluid flow results obtained from tough2 using ewasg consider the compressibility of the fluid whereas in the semi analytical method the fluid is considered at constant density even in a steady state simulation with a low fluid injection production rate the variation of the pressure implies a density change affecting the total volume of fluid passing through a block tough2 simulations consider the injection or production rate in mass so the resulting computed velocity depends on the density of the fluid this introduce a difference in the computation of the velocity not taken into account by the semi analytical method for example in a column of 500 blocks depth 500 m the variation of the fluid density between the top and the bottom block is about of 1 7 kg m3 this density change imply a difference between the top and the bottom velocity considering a vertical top velocity of 0 8013e 07 ms 1 on the block faces of about 0 16 and the corresponding tof differ about of 0 08 3 2 case study b pathline tracing of the 3d five spot problem we calculated the pathline of 100 particles in a simulation problem in a 3d domain of size 500 500 500 m3 in a homogeneous porous medium with the same petro physical properties as the previous case study the point source q 1 0 kg s was located at 0 0 0 0 0 0 m while the point sink q 1 0 kg s was at 500 0 500 0 500 0 m this configuration can be considered the numerical model of a 3d five spot problem in a staggered cubic producing grid for this particular configuration of point sources sinks we developed a reference semi analytical solution to compare with the simulation results the semi analytical solution was obtained as an extension of the javandel et al 1984 method valid for a 2d domain see appendix b for details as in the previous case we analyzed the simulation results using several 3d voronoi grids we built eight 3d voronoi grids see fig 6 a structured block dimensions 50 50 50 m3 named 3d structured b a rotated structured where grid blocks were aligned along the diagonal of the cube named 3d 45structured c a perturbed structured grid where nodes were obtained by a random displacement of the 3d structured grid nodes named 3d hexperturbed d a voronoi 2 5d grid with vertical replication of the case study a grid named 2d voronoi with block thickness of 50 m top and bottom layer of 25 m named 2 5d voronoi e a 3d cvt grid named 3d cvt f a 3d cvt grid where the nodes of the boundary blocks were kept equal to the 3d structured grid named 3d cvt2 g a 3d cvt grid named 3d cvt 10k with 104 blocks h a 3d cvt grid named 3d cvt 100k with 105 blocks table 5 shows the main characteristics of the six grids the pathlines for 100 particles were evaluated using the same initial position on every grids randomly located on a surface of a quarter of a sphere centered in 0 0 0 and of 110 m in radius as for the 2d case the pathlines of the 100 particles was computed using two velocity fields defined as a the velocity field obtained by integrating the semi analytical velocity computed by the 3d extension of the javandel et al 1984 see appendix b for details on each face of blocks semi numerical pathlines b the velocity field obtained by the tough2 simulations numerical pathlines 3 2 1 results and discussions the maximum tof and dt absolute differences of the semi numerical and the numerical pathlines respect to the semi analytical solutions of the 100 particles are summarized in table 6 results of table 6 shows that the difference between the semi numerical and numerical pathlines are subject to grids artifacts and to the size of the blocks the higher difference observed among all the grids is for the 3d 45 structured grid with a maximum tof absolute difference of 52 in this case the initial position of one particle falls inside a boundary block and the pathline of this particle intersect several boundary blocks resulting in high tof and dt difference respect to the semi analytical solution see fig 7 the maximum tof and dt absolute differences as expected decrease when the discretization of the domain increases see table 6 fig 8 shows the maximum tof and dt absolute differences trend as a function of the cvt grid block size it is possible to see that the tof and dt differences of the numerical and semi numerical pathlines tend asymptotically to zero with the increasing of the discretization 3 3 toughpath and openmp library performance the computation time of tough2path depends largely on grid size and the number of iterations needed to compute a particle pathline which in turn it depends on the step length and the total length of the particle path table 7 shows the computation times for each case study when a computer with a i7 3770k cpu 3 50 ghz processor was used openmp library lowered computation time by simultaneously calculating the particle path using several threads to evaluate the performance of tough2path with the openmp library computation of the 14641 particle paths of the 2d structured grid was repeated using a number of threads between 1 no multithreading and 8 on a personal computer equipped with a i7 3770k cpu 3 50 ghz processor with 4 physical cores 8 virtual cores using hyper threading and 8 gb of ram the higher tough2path performance with openmp was noticeable when up to four threads were used fig 9 then further increase in the number of threads did not improve the computation time 4 conclusions in general to compute particle pathlines using the discrete velocity field as obtained with a numerical simulation for example in numerical modeling using the ifd method requires the use of algorithms to estimate the velocity field in every points of the domain we have developed a program code tough2path that calculates the particle path for the tough family of simulators in the presence of 3d voronoi grids implementing the mass conserving method developed by klausen et al 2012 tough2path has been validated also comparing its results with a 3d five spot problem we was able to obtain as an extension of the 2d semi analytical solution of morel seytoux as expected we found that the computed pathlines are affected both by the grid shape discretization the grid size of the simulated domain and by the initial position of the particles anyway the comparison with the semi analytical approach shows the good accuracy of the method except for particles initially positioned within boundary blocks therefore tough2path is a robust and useful tool to compute pathlines of fluid particles when the numerical simulations use unstructured full 3d voronoi grids diffusion and changing phase phenomena now not take into account by the tool are under investigation tough2path is freely downloadable at http software dicam unibo it tough2path appendix a analytical formulation of the velocity field for the 2d five spot case the following derivation follows the development proposed by javandel et al 1984 consider a confined horizontal infinite layer of thickness h of a porous medium with porosity ϕ a point source sink located at the origin of the system of coordinates with a constant flow rate q of an incompressible fluid then the velocity field in term of cartesian coordinates has the form v x y q 2 π h ϕ x 2 y 2 x i ˆ y j ˆ if we consider an infinite set of spaced staggered x spacing 2 a y spacing 2 b points sources and sinks the resulting velocity field can be constructed by means of the superposition principle the general expression of the velocity field may be written as where w x i j 2 i a w y i j 2 j b and w x i j 2 i a a w y i j 2 j b b in the region x 0 a 0 b the contribution of far point sources or sinks is negligible with the result that the velocity field can be evaluated with an adequate degree of accuracy by choosing i and j between 9 9 even with an increment to 10 10 velocity module changes remain below 2 0 10 3 appendix b analytical formulation of the velocity field for the 3d five spot case the 3d five spot case can be considered as an extension of the 2d five spot case considering a hypothetical set of point sources and sinks in a hexahedral staggered pattern the velocity field of a point source or sink can be computed with the same method used for the 2d case i e considering an infinite porous medium with porosity ϕ and a point source located at 0 0 0 at a constant flow rate q of an uncompressible fluid with a sphere of radius r an infinitesimal volume change d v q d t will expand the sphere volume of radius r of d v s 4 π r 2 ϕ d r by equating the two terms we obtain q d t 4 π r 2 ϕ d r which gives v r d r d t q 4 π r 2 ϕ the velocity field generated of a point source or sink located at 0 0 0 in terms of cartesian component becomes v x y z q 4 π ϕ x 2 y 2 z 2 3 2 x i ˆ y j ˆ z k ˆ if we consider a regular spaced staggered x spacing 2a y spacing 2b z spacing 2c infinite set of point source and sink the resulting flow field can be constructed by the superposition principle the general expression of the flow field may be written as v x y z 1 4 π ϕ i j k q i j k x w x i j k i ˆ y w y i j k j ˆ z w z i j k k ˆ x w x i j k 2 y w y i j k 2 z w z i j k 2 3 2 i j k q i j k x w x i j k i ˆ y w y i j k j ˆ z w z i j k k ˆ x w x i j k 2 y w y i j k 2 z w z i j k 2 3 2 where q i j k flow rate of the point source q i j k flow rate of the point sink point source sink coordinates w x i j k 2 i a w y i j k 2 i b w z i j k 2 i c a n d w x i j k 2 i a a w y i j k 2 i b b w z i j k 2 i c c in the region x 0 a 0 b 0 c as the contribution of far wells is negligible the velocity field can be evaluated with an adequate degree of accuracy by choosing i j and k between 9 9 even with an increment to 10 10 velocity module changes remain below 4 0 10 4 appendix c equivalence between the klausen et al 2012 and pollock method for cartesian orthogonal grids we here show the following theorem in the case of an orthogonal hexahedral prism the velocity estimation using the basis function as defined by klausen 2012 becomes a linear interpolator in x y z as in the pollock method consider an orthogonal hexahedral prism e of size a b c as shown in figure c1 fig c1 the orthogonal hexahedral prism vertices numbered and flow notation fig c1 the evaluation of the velocity field through the basis function uses equations 1 and 2 3 v x e f i e f i ψ i e x 4 ψ i x j v j i v j i n i λ j x for the sake of simplicity we define f 1 v x 1 f 2 v x 2 f 3 v y 1 f 4 v y 2 f 5 v z 1 f 6 v z 2 the computation of the λ j x following the explicit definition of rasmussen and lie 2014 is expressed by the definition of the weighting function λ v x k v j i n d v n j x j x where x is the vector of the coordinates of the location point v is the vertex of the polyhedral k v d e t n i n d v i n d v denotes the set of indices j such that the facet normal to n j contains the vertex v n i n d v is a matrix whose rows are the vectors n j where j i n d v x j is the centroid of the j face the barycentric coordinate are then defined as λ i x λ i x i n λ i x normalized weighting function i 1 n λ i 1 following the notations of figure c1 for an orthogonal hexahedral prism k v 1 v the weighting functions are λ 1 a x b y c z λ 2 x b y c z λ 3 x y c z λ 4 a x y c z λ 5 a x b y z λ 6 x b y z λ 7 x y z λ 8 a x y z the sum of λ i is i n λ i a b c we can calculate the generalized barycentric coordinate for each vertex as λ 1 a x b y c z a b c λ 2 x b y c z a b c λ 3 x y c z a b c λ 4 y a x c z a b c λ 5 z a x b y a b c λ 6 x z a x c z a b c λ 7 x y z a b c λ 8 y z a x a b c for the sake of simplicity we calculate v x x y z x direction which requires evaluation of ψ i just for i 1 and i 2 from figure c1 ψ 1 hold λ j with j 1 4 8 5 while ψ 2 hold λ j with j 2 3 6 7 for ψ 2 the v j i v j i n i term is i ˆ while for ψ 1 the v j i v j i n i term is opposite to i ˆ by developing ψ 1 and ψ 2 ψ 1 1 a b c a x b y c z y a x c z y z a x z a x b y i ˆ 1 x a i ˆ ψ 2 1 a b c x b y c z x y c z x z b y x y z i ˆ x a i ˆ by estimating the velocity field using equation 1 we can finally write v x x y z ψ 1 f 1 i ˆ ψ 2 f 2 i ˆ 1 x a v x 1 x a v x 2 that is equal to the linear combination defined that can be obtained using the pollock s method by developing ψ i for i 3 4 and for i 5 6 it is possible to show that the interpolation of the velocity field inside the block for v y and v z respectively is linear appendix d tough2path par file the tough2path par file contains the computation parameters and directive keywords are briefly resumed in the example file image 2 
26236,pathline or streamline computation is used today to improve the understanding of fluid flow behavior in groundwater modelling in particular pathline computation on unstructured grids requires an accurate velocity interpolation method when the flow velocity field is given by numerical simulators only at the faces of the grid blocks as for example in the case of the integral finite difference method is used for spatial discretization in the case of 3d voronoi unstructured grids a corner velocity interpolation cvi method allows continuous velocity field interpolation while preserving the mass conservation principle we have developed a computer code named tough2path able to compute the velocity field based on the cvi method and generalized barycentric coordinates for 3d voronoi polytope grid blocks tailored for the tough family of codes results for the classical quarter five spot problem show that the coded algorithm correctly reproduces the pathlines computed with semi analytical methods keywords pathlines tough unstructured grids groundwater modelling 3d voronoi software availability name of the software tough2path developer s bonduà contact address stefano bondua unibo it designed by s bonduà v bortolotti year first available 2018 hardware requirement pc software requirement windows os program language c program size 175 kb binary file availability freely available as binary file at http software dicam unibo it tough2path 1 introduction in order to improve the understanding of fluid flow behavior in the groundwater modelling a very powerful method is to trace the flow streamlines or pathlines of the fluid particles streamlines are a family of curves that are instantaneously tangent to the velocity vector of the flow a pathline is the trajectory of a particle moving at the same velocity as the fluid flow hægland et al 2007 in the case of steady flow when the velocity vector field does not change with time streamlines and pathlines coincide usually when reservoir behavior is simulated with a numerical model the flow velocity field fvf is computed only at the corners or on the faces of the grid blocks used to discretize the reservoir domain the fvf inside the volume of the blocks is therefore unknown tracing accurate streamlines over a grid therefore requires finding a method to interpolate the flow velocity inside the volume of blocks there have been many efforts over the years to compute fvf distribution inside grid blocks in 1988 pollock implemented a semi analytical method of linear interpolation of the velocity field inside the blocks of structured regular grids the improvement of the pollock method for quadrilaterals grids was firstly developed by cordes and kinzelbach 1992 who adopted a isoparametric local coordinate system by prevost et al 2002 who applied the pollock method in a transformed space and then mapped back the calculated velocity for more general polyhedrons and by jimenez et al 2005 who used the lowest order raviat thomas space an isoparametric trilinear transformation of an irregular hexahedral cell to a unitary cube in a reference space matringe et al 2006 2008 improved these methods using the brezzi douglas marini space of order one all these methods are valid for triangular or quadrilateral blocks in 2d and tetrahedral or hexahedral blocks in 3d in the case of completely unstructured arbitrary convex polyhedral grids e g voronoi grids streamline computation cannot be achieved with an analytical or semi analytical methods hægland et al 2007 proposed the approach of corner velocity interpolation cvi for unstructured irregular grids in the case of quadrilateral or hexahedral blocks rasmussen 2010 interpolated fvf in convex polyhedrons by estimating the cvi and making use of the generalized barycentric coordinates of the polyhedrons zhang et al 2012 proposed a cvi method applicable to both degenerate and non convex polyhedrons interpolating the velocity field using the isoparametric mapping technique painter et al 2012 proposed a method based on equivalent nodal velocity that uses the least square error method to minimize the contribution of the velocity through the faces of a block the method can also be used in the case of neumann or dirichlet boundary condition blocks streamlines computed with this method approximate very well to the streamlines obtained with the semi analytical method of morel seytoux 1966 and with the pollock method 1988 painter et al 2012 method does not allow path computation in the region between the domain boundaries and the convex hull of the set of nodes furthermore the painter method does not obey the law of mass conservation a factor whose importance for accurate streamline construction is well known sun et al 2005 an enhanced method applicable to fully unstructured 3d grids and obeying the law of mass conservation was proposed by klausen et al 2012 it uses an enhanced cvi scheme that applies the basis functions klausen et al 2012 and the generalized barycentric coordinates warren et al 2007 see next paragraph for a detailed description of the method it follows that in the case of an unstructured 3d voronoi grid like those created with voro2mesh bonduà et al 2017 the method of klausen et al 2012 seems to be the most accurate method since i it preserves the mass flow ii there is no need for triangulation for 2d grids or tetrahedralization 3d grids thereby allowing the tracing of pathlines to be computed directly on simulation results one of the most popular computer program suite for numerical simulation of geothermal reservoir underground carbon storage nuclear waste and environmental management is the tough family of codes o sullivan et al 2001 it is a suite of simulators for non isothermal flows of multicomponent multiphase fluids in one two and three dimensional porous and fractured media pruess et al 1999 tough is very robust and flexible due to a modular structure which allows studying systems characterized by different thermo fluid dynamics conditions by choosing one of the interchangeable modules generically called the equation of state eos module in particular it permits to study non isothermal multicomponent and multiphase fluid flows in continuous or fractured porous media in 1d 2d and 3d domains berry et al 2014 the integral finite difference ifd method edwards 1972 narasimhan and witherspoon 1976 narasimhan et al 1978 is used in tough in order to solve the differential equations for the flow of mass and heat ifd preserves the mass balance flow at the interface between the blocks flow rates or velocity are therefore computed and given only at the face of neighboring blocks as far as we know there is no dedicated software that allows pathlines to be traced using the results of tough simulations performed with full voronoi 3d grids we have developed a computer software named tough2path 1 1 the code is free and can be downloaded from http software dicam unibo it tough2path that is able to compute the streamlines of particles using simulation results obtained with tough2 pruess et al 1999 3d voronoi grids and the klausen et al 2012 method as a first validation and verification step tough2path was applied on a 2d and a 3d five spot problem and results compared with semi analytical solutions although not definitive the good results of these preliminary tests permit to guarantee the good quality of tough2path 1 1 the method of klausen et al the klausen et al 2012 method makes use of an enhanced cvi scheme where the fvf is interpolated using the face basis functions and generalized barycentric coordinates barycentric coordinates are commonly used for interpolating discrete scalar fields vector fields or arbitrary multidimensional fields over irregular tessellations as they permit smooth interpolation of data located on vertices via multilinear interpolation warren et al 2007 the velocity v is interpolated at the point x inside a given block e by the following relations 1 v x e f i e f i ψ i e x 2 ψ i x j v j i v j i n i λ j x j λ j x 1 where i 1 to the number of faces of e j 1 to the number of vertices of the i th face of e e is the surface of the block e fi is the i th face of the e f i is the flow through the i th face ψ i is the i th basis function v j i is the edge not coplanar to f i of the vertex j fig 1 in case of a 2d grid the 3rd dimension of the blocks is assumed as the ration between the volume and the surface of the block n i is the normal vector to the face i λ j x is the j th barycentric coordinate of x respect to the vertex j of the block e to evaluate the generalized barycentric coordinate λ j x we implemented the methods described in warren et al 2007 and in rasmussen and lie 2014 a comparison between the two methods indicate that the percentage difference in term of time of flight and distance travelled is less than 10 2 the pathline is then calculated with an iterative procedure as follows given a particle located at the location point p 0 at time t 0 to locate the block e that contains p 0 evaluate λ j p 0 and compute the basis functions ψ i p 0 estimate v p 0 evaluate the new position of the particle as p 1 p 1 v p 0 dt or high order methods and check if the new particle position is still in the same block repeat the computation of new positions until an interrupt condition occurs maximum number of iterations encountered block with boundary conditions etc it should be noted that in the case of a cartesian grid the klausen et al 2012 method reduces to a linear interpolation of the velocity between two parallel faces and coincides with the pollock 1988 method see appendix c for the demonstration 2 tough2path code to draw pathlines for tough simulation if the particles are moving at the same velocity as the fluid then tough2path can compute the pathline of a particle through each block of a 3d voronoi discretized domain making direct use of the output file of a tough2 pruess et al 1999 simulation as well as of the klausen et al 2012 method tough2path is a command line software for windows os coded in c it applies a parallel programming approach using openmp open multi processing 2 2 openmp architecture review board the openmp specification http www openmp org 2017 accessed 2019 01 07 to speed up computation thereby allowing contemporaneously computation of a large number of particle paths at a reasonable computation time cost openmp is an application programming interface allowing multi platform shared memory multiprocessing programming it consists of a set of compiler directives library routines and environment variables tough2path can also compute the pathline taking into account flow change in time to do this we adopted linear interpolation of the module of the flow vector at the block face between two successive time steps taken from the tough2 output file 2 1 tough2path input files tough2path needs geometrical information input of both grid block shape and flow data between blocks in particular as the structure of the tough2 output file depends on the specific eos used see pruess et al 1999 for details tough2path needs to be instructed as to the location of the variables to be read see fig 2 for details therefore the input data of tough2path is composed of several files tough2path par contains the parameters of the path particle computation such as the maximum number of iterations the directive ending computation domain limits the step length and directive about automatic step length reduction etc see appendix d for details mesh is the standard mesh file of tough2 see tough2 manual pruess et al 1999 elements with volumes larger than 1 0 1020 m3 are considered ending blocks therefore when the particle enters a ending block the computation will terminate tough2viewer dat is the file generated by voro2mesh see bonduà et al 2017 2012 containing the geometrical information of each block vertices edges faces and faces normal for a detailed file format specification please refer to bonduà et al 2017 appendix b t2 out the standard output file of tough2 it must contain flow velocities between blocks usually named vel liq m s or vel gas m s header dat is a file containing at least 3 lines of characters as they appear in the t2 out file this is to allow easy parsing of the tough2 output files which are different for each eos by tough2path the user must specify the position of elem1 elem2 and the variables to be read see fig 2 for details seed points dat an ascii file space separated x y z coordinate of the initial position of the set of particles whose path is to be calculated gener is the standard gener file of tough2 if the specified flow rate of a gener element is greater than zero injection block then a seed point for each face is added to the seed points set if the flow rate is lower than zero production block then the block will be considered as an ending block ending points dat an ascii file space separated x y z r radius coordinate of the ending positions of the particle set on which to terminate path computation particle path computation will be terminated when the 3d distance between particle position and an ending point is lower than r 2 2 tough2path output files the standard output of tough2path comprises a set of ascii files providing information on the path of each input particle specifically a path file is created for each particle tracked it is an ascii space separated file where each line contains the position of the particle x y z the 3 velocity components vx vy vz the id of the block crossed travelled distance and integration time the naming convention for these files is path particle number dat t2path vtp file an xml file polydata paraview 3 3 www paraview org accessed accessed 2019 01 07 file for particle pathline visualization in paraview the file contains all the necessary information for visualization of the particle path as a polyline the coordinate of each point x y z the estimated velocity vx vy vz the id of the block to which the point belongs the integration time the total travelled distance the reason for pathline computation termination a code between 1 and 8 see table 1 node vel files are comma separated files csv of the velocity vector calculated for each nodal point for each time step the naming convention of these file is node vel time step csv tough2path log a file with information on the parameters used time of computation warnings and if any errors during the computation 3 code validation and verification a preliminary verification and validation of tough2path was obtained computing pathlines with tough2 simulated data hereinafter simply called numerical pathlines of two well known case studies a 2d five spot problem and a 3d five spot problem and comparing them with pathlines computed via semi analytical solutions hereinafter simply called semi analytical pathlines 3 1 case study a pathline tracing of the classical 2d five spot problem a semi analytical solution is available for this problem morel seytoux 1966 that therefore allows the comparison with the paths calculated by tough2path the semi analytical method computes an analytical velocity field and requires a quadrature computation to find the pathlines to this end the javandel et al 1984 velocity computation method was implemented and integrated in tough2path see appendix a for details it should be noted that the numerical pathlines computation depends on the numerical simulation results numerically simulated pressure which are strongly affected by the grid refinement and orientation used pruess and bodvarsson 1983 pruess 1991 yamamoto and doughty 2011 for this reason we present pathline results computed on several different grids in order to obtain a preliminary evaluation of the unavoidable gridding effects we used the ewasg module battistelli et al 1997 of tough2 to simulate an isothermal 20 c 2d flow in an aquifer with porosity of ϕ 5 isotropic permeability k 24 10 15 m2 thickness of h 300 m in a five spot infinite staggered pattern of size 500 500 m2 the point source iw q 1 0 kg s is located at 0 0 0 0 m while the point sink pw q 1 0 kg s is at 500 0 500 0 m neumann type boundary conditions were the implicit semi analytical reference solution for the semi analytical computation an injected fluid of density 998 9 kg m3 was considered as computed by the tough simulations tough2 simulation was performed using 5 types of grid cartesian structured grid named 2d structured 45 rotated structured grid named 2d 45structured perturbed quadrilateral voronoi grid named 2d quadperturbed voronoi grid named 2d voronoi centroidal voronoi tessellation cvt grid named 2d cvt a cvt is a particular voronoi tessellation satisfying the requirement of having the seed point at the barycenter of the particle table 2 summarizes the main characteristics of the 5 grids and they are illustrated in fig 3 the streamlines which coincide with pathlines in the case of steady flow of 4 particles were traced for all grids in all the used grids the initial position of two particles is the same p1 50 0 50 0 and p2 50 0 10 0 m while the other two particles p3 and p4 are initially positioned at the coordinates of the nodes of two blocks near the source block the termination condition for computation of all 4 pathlines was when the distance of the particle to the pw was less than the distance between the initial position and point source iw 3 1 1 results and discussions fig 3 shows the semi analytical and the numerical pathlines for five types of grids the comparisons between the time of flight tof and distance travelled dt obtained using the two methods are summarized in table 3 the columns tof difference and dt difference are calculated as tof difference semi analytical tof numerical tof semi analytical tof x 100 dt difference semi analytical dt numerical dt semi analytical dt x 100 the tof and dt differences computed for the 4 particles table 3 show that unstructured grids have a lower difference compared to structured grids particles initially located within boundary blocks exhibit greater differences in order to better map the difference between the semi analytical and the numerical pathlines as a consequence of the initial position of the particles we calculated the absolute dt difference and absolute tof difference in a fine grid in the bottom left quarter of the domain near the point source resulting in 14641 pathlines fig 4 shows the tof and dt difference maps for the 5 different grids used table 3 and especially fig 4 show that the zone with the highest difference of tof and dt is located near the boundary blocks and near the point source these results clearly shows evidence that tough2path works quite well since the maximum discrepancy with the semi analytical solution is around 6 for tof and 4 for dt except for some particles located near the border domain where the tof and dt difference can increase up to 15 and 7 respectively moreover the best results are obtained when an unstructured grid is used this confirms that unstructured grids having no preferential face orientation reproduce better the fluid flow behavior in order to improve the test to evaluate the correctness of the velocity interpolation method implemented in tough2path the tof and dt were also computed using a discrete velocity field obtained integrating the semi analytical velocity field over the faces of the grid blocks using this approach hereinafter called for the sake of simplicity semi numerical the velocity field used to compute the pathlines is not affected by the numerical approximations introduced by the tough2 simulation in table 4 are reported for each grid the maximum tod and dt absolute differences of the numerical and semi numerical pathlines both evaluated respect to the semi analytical solutions also 3 cvt refined grids with 103 104 and 105 block elements named 2d cvt 1k 2d cvt 10k and 2d cvt 100k respectively were used to verify the convergence of the numerical pathlines when the tough velocity field is used and the semi numerical pathlines when is used to the reference semi analytical solution fig 5 shows the maximum tof and dt absolute differences versus the grid size of the cvt grids as expected the maximum tof and dt absolute asymptotically decrease when the number of the grid elements increases for all the 2d cvt 1k 2d cvt 10k and 2d cvt 100k grids the starting position of the particles were far from the boundary blocks of the domain the 121 121 particles were distributed over a regular lattice of size 2 2 in the left bottom corner 10 10 of the grid therefore the resulting pathlines do not cross the boundary blocks of the domain resulting in a lower maximum tof and td differences therefore these results corroborates that in general the pathlines computed through boundary blocks are poorly accurate it is worth mentioning that the fluid flow results obtained from tough2 using ewasg consider the compressibility of the fluid whereas in the semi analytical method the fluid is considered at constant density even in a steady state simulation with a low fluid injection production rate the variation of the pressure implies a density change affecting the total volume of fluid passing through a block tough2 simulations consider the injection or production rate in mass so the resulting computed velocity depends on the density of the fluid this introduce a difference in the computation of the velocity not taken into account by the semi analytical method for example in a column of 500 blocks depth 500 m the variation of the fluid density between the top and the bottom block is about of 1 7 kg m3 this density change imply a difference between the top and the bottom velocity considering a vertical top velocity of 0 8013e 07 ms 1 on the block faces of about 0 16 and the corresponding tof differ about of 0 08 3 2 case study b pathline tracing of the 3d five spot problem we calculated the pathline of 100 particles in a simulation problem in a 3d domain of size 500 500 500 m3 in a homogeneous porous medium with the same petro physical properties as the previous case study the point source q 1 0 kg s was located at 0 0 0 0 0 0 m while the point sink q 1 0 kg s was at 500 0 500 0 500 0 m this configuration can be considered the numerical model of a 3d five spot problem in a staggered cubic producing grid for this particular configuration of point sources sinks we developed a reference semi analytical solution to compare with the simulation results the semi analytical solution was obtained as an extension of the javandel et al 1984 method valid for a 2d domain see appendix b for details as in the previous case we analyzed the simulation results using several 3d voronoi grids we built eight 3d voronoi grids see fig 6 a structured block dimensions 50 50 50 m3 named 3d structured b a rotated structured where grid blocks were aligned along the diagonal of the cube named 3d 45structured c a perturbed structured grid where nodes were obtained by a random displacement of the 3d structured grid nodes named 3d hexperturbed d a voronoi 2 5d grid with vertical replication of the case study a grid named 2d voronoi with block thickness of 50 m top and bottom layer of 25 m named 2 5d voronoi e a 3d cvt grid named 3d cvt f a 3d cvt grid where the nodes of the boundary blocks were kept equal to the 3d structured grid named 3d cvt2 g a 3d cvt grid named 3d cvt 10k with 104 blocks h a 3d cvt grid named 3d cvt 100k with 105 blocks table 5 shows the main characteristics of the six grids the pathlines for 100 particles were evaluated using the same initial position on every grids randomly located on a surface of a quarter of a sphere centered in 0 0 0 and of 110 m in radius as for the 2d case the pathlines of the 100 particles was computed using two velocity fields defined as a the velocity field obtained by integrating the semi analytical velocity computed by the 3d extension of the javandel et al 1984 see appendix b for details on each face of blocks semi numerical pathlines b the velocity field obtained by the tough2 simulations numerical pathlines 3 2 1 results and discussions the maximum tof and dt absolute differences of the semi numerical and the numerical pathlines respect to the semi analytical solutions of the 100 particles are summarized in table 6 results of table 6 shows that the difference between the semi numerical and numerical pathlines are subject to grids artifacts and to the size of the blocks the higher difference observed among all the grids is for the 3d 45 structured grid with a maximum tof absolute difference of 52 in this case the initial position of one particle falls inside a boundary block and the pathline of this particle intersect several boundary blocks resulting in high tof and dt difference respect to the semi analytical solution see fig 7 the maximum tof and dt absolute differences as expected decrease when the discretization of the domain increases see table 6 fig 8 shows the maximum tof and dt absolute differences trend as a function of the cvt grid block size it is possible to see that the tof and dt differences of the numerical and semi numerical pathlines tend asymptotically to zero with the increasing of the discretization 3 3 toughpath and openmp library performance the computation time of tough2path depends largely on grid size and the number of iterations needed to compute a particle pathline which in turn it depends on the step length and the total length of the particle path table 7 shows the computation times for each case study when a computer with a i7 3770k cpu 3 50 ghz processor was used openmp library lowered computation time by simultaneously calculating the particle path using several threads to evaluate the performance of tough2path with the openmp library computation of the 14641 particle paths of the 2d structured grid was repeated using a number of threads between 1 no multithreading and 8 on a personal computer equipped with a i7 3770k cpu 3 50 ghz processor with 4 physical cores 8 virtual cores using hyper threading and 8 gb of ram the higher tough2path performance with openmp was noticeable when up to four threads were used fig 9 then further increase in the number of threads did not improve the computation time 4 conclusions in general to compute particle pathlines using the discrete velocity field as obtained with a numerical simulation for example in numerical modeling using the ifd method requires the use of algorithms to estimate the velocity field in every points of the domain we have developed a program code tough2path that calculates the particle path for the tough family of simulators in the presence of 3d voronoi grids implementing the mass conserving method developed by klausen et al 2012 tough2path has been validated also comparing its results with a 3d five spot problem we was able to obtain as an extension of the 2d semi analytical solution of morel seytoux as expected we found that the computed pathlines are affected both by the grid shape discretization the grid size of the simulated domain and by the initial position of the particles anyway the comparison with the semi analytical approach shows the good accuracy of the method except for particles initially positioned within boundary blocks therefore tough2path is a robust and useful tool to compute pathlines of fluid particles when the numerical simulations use unstructured full 3d voronoi grids diffusion and changing phase phenomena now not take into account by the tool are under investigation tough2path is freely downloadable at http software dicam unibo it tough2path appendix a analytical formulation of the velocity field for the 2d five spot case the following derivation follows the development proposed by javandel et al 1984 consider a confined horizontal infinite layer of thickness h of a porous medium with porosity ϕ a point source sink located at the origin of the system of coordinates with a constant flow rate q of an incompressible fluid then the velocity field in term of cartesian coordinates has the form v x y q 2 π h ϕ x 2 y 2 x i ˆ y j ˆ if we consider an infinite set of spaced staggered x spacing 2 a y spacing 2 b points sources and sinks the resulting velocity field can be constructed by means of the superposition principle the general expression of the velocity field may be written as where w x i j 2 i a w y i j 2 j b and w x i j 2 i a a w y i j 2 j b b in the region x 0 a 0 b the contribution of far point sources or sinks is negligible with the result that the velocity field can be evaluated with an adequate degree of accuracy by choosing i and j between 9 9 even with an increment to 10 10 velocity module changes remain below 2 0 10 3 appendix b analytical formulation of the velocity field for the 3d five spot case the 3d five spot case can be considered as an extension of the 2d five spot case considering a hypothetical set of point sources and sinks in a hexahedral staggered pattern the velocity field of a point source or sink can be computed with the same method used for the 2d case i e considering an infinite porous medium with porosity ϕ and a point source located at 0 0 0 at a constant flow rate q of an uncompressible fluid with a sphere of radius r an infinitesimal volume change d v q d t will expand the sphere volume of radius r of d v s 4 π r 2 ϕ d r by equating the two terms we obtain q d t 4 π r 2 ϕ d r which gives v r d r d t q 4 π r 2 ϕ the velocity field generated of a point source or sink located at 0 0 0 in terms of cartesian component becomes v x y z q 4 π ϕ x 2 y 2 z 2 3 2 x i ˆ y j ˆ z k ˆ if we consider a regular spaced staggered x spacing 2a y spacing 2b z spacing 2c infinite set of point source and sink the resulting flow field can be constructed by the superposition principle the general expression of the flow field may be written as v x y z 1 4 π ϕ i j k q i j k x w x i j k i ˆ y w y i j k j ˆ z w z i j k k ˆ x w x i j k 2 y w y i j k 2 z w z i j k 2 3 2 i j k q i j k x w x i j k i ˆ y w y i j k j ˆ z w z i j k k ˆ x w x i j k 2 y w y i j k 2 z w z i j k 2 3 2 where q i j k flow rate of the point source q i j k flow rate of the point sink point source sink coordinates w x i j k 2 i a w y i j k 2 i b w z i j k 2 i c a n d w x i j k 2 i a a w y i j k 2 i b b w z i j k 2 i c c in the region x 0 a 0 b 0 c as the contribution of far wells is negligible the velocity field can be evaluated with an adequate degree of accuracy by choosing i j and k between 9 9 even with an increment to 10 10 velocity module changes remain below 4 0 10 4 appendix c equivalence between the klausen et al 2012 and pollock method for cartesian orthogonal grids we here show the following theorem in the case of an orthogonal hexahedral prism the velocity estimation using the basis function as defined by klausen 2012 becomes a linear interpolator in x y z as in the pollock method consider an orthogonal hexahedral prism e of size a b c as shown in figure c1 fig c1 the orthogonal hexahedral prism vertices numbered and flow notation fig c1 the evaluation of the velocity field through the basis function uses equations 1 and 2 3 v x e f i e f i ψ i e x 4 ψ i x j v j i v j i n i λ j x for the sake of simplicity we define f 1 v x 1 f 2 v x 2 f 3 v y 1 f 4 v y 2 f 5 v z 1 f 6 v z 2 the computation of the λ j x following the explicit definition of rasmussen and lie 2014 is expressed by the definition of the weighting function λ v x k v j i n d v n j x j x where x is the vector of the coordinates of the location point v is the vertex of the polyhedral k v d e t n i n d v i n d v denotes the set of indices j such that the facet normal to n j contains the vertex v n i n d v is a matrix whose rows are the vectors n j where j i n d v x j is the centroid of the j face the barycentric coordinate are then defined as λ i x λ i x i n λ i x normalized weighting function i 1 n λ i 1 following the notations of figure c1 for an orthogonal hexahedral prism k v 1 v the weighting functions are λ 1 a x b y c z λ 2 x b y c z λ 3 x y c z λ 4 a x y c z λ 5 a x b y z λ 6 x b y z λ 7 x y z λ 8 a x y z the sum of λ i is i n λ i a b c we can calculate the generalized barycentric coordinate for each vertex as λ 1 a x b y c z a b c λ 2 x b y c z a b c λ 3 x y c z a b c λ 4 y a x c z a b c λ 5 z a x b y a b c λ 6 x z a x c z a b c λ 7 x y z a b c λ 8 y z a x a b c for the sake of simplicity we calculate v x x y z x direction which requires evaluation of ψ i just for i 1 and i 2 from figure c1 ψ 1 hold λ j with j 1 4 8 5 while ψ 2 hold λ j with j 2 3 6 7 for ψ 2 the v j i v j i n i term is i ˆ while for ψ 1 the v j i v j i n i term is opposite to i ˆ by developing ψ 1 and ψ 2 ψ 1 1 a b c a x b y c z y a x c z y z a x z a x b y i ˆ 1 x a i ˆ ψ 2 1 a b c x b y c z x y c z x z b y x y z i ˆ x a i ˆ by estimating the velocity field using equation 1 we can finally write v x x y z ψ 1 f 1 i ˆ ψ 2 f 2 i ˆ 1 x a v x 1 x a v x 2 that is equal to the linear combination defined that can be obtained using the pollock s method by developing ψ i for i 3 4 and for i 5 6 it is possible to show that the interpolation of the velocity field inside the block for v y and v z respectively is linear appendix d tough2path par file the tough2path par file contains the computation parameters and directive keywords are briefly resumed in the example file image 2 
26237,we present a parameter estimation study of the soil tree atmosphere continuum stac model a process based model that simulates water flow through an individual tree and its surrounding root zone parameters are estimated to optimize the model fit to observations of sap flux stem water potential and soil water storage made for a white fir abies concolor in the sierra nevada california bayesian inference is applied with a likelihood function that considers temporal correlation of the model errors key vegetation properties are estimated such as the tree s root distribution tolerance to drought and hydraulic conductivity and retention functions we find the model parameters are relatively non identifiable when considering just soil water storage overall by utilizing multiple processes e g sap flow stem water potential and soil water storage during the parameter estimation we find the simulations of the soil and tree water properties to be more accurate when compared to observed data keywords ecohydrology vegetation hydraulics climate parameter estimation mcmc 1 introduction ecohydrology is a field of study focusing on the hydrologic mechanisms that govern and explain ecologic patterns and processes rodriguez iturbe 2000 jackson et al 2009 ecohydrologic system properties depend on many interrelated links between climate soil and vegetation rodriguez iturbe et al 2001 one part of this system includes the role that climate and soil have in controlling vegetation dynamics lange et al 1976 boyer 1982 kramer and boyer 1995 larcher 2003 jones 2013 ali et al 2016 and another part of the system is the control that vegetation exerts on the water and energy balance schlesinger et al 1990 kutzbach et al harrison zeng et al 1999 massoud et al 2018a a quantitative understanding of these vegetation dynamics better supports environmental preservation management of resources and improved model representation of ecohydrologic systems noy meir 1973 shmida et al 1986 scholes and walker 2004 xu et al 2013 johnson et al 2018 generally the role that trees play in the overall water cycle in regards to ecosystem water storage residence time and vegetation tolerance to drought are poorly represented in land surface models lsms fisher et al 2018 for example the impact of soil water availability on vegetation is typically represented in land surface and climate models using simple empirical relationships with parameter values that are extracted from arbitrary data sets this may not represent vegetation hydraulic properties or capture seasonal or ontogenetic changes observed in reality which can cause major bias in the representation of vegetation in this suite of models the lack of proper representation of water dynamics in vegetation contributes to large discrepancies seen between various model simulations that run into the next century sitch et al 2008 mcdowell et al mackay et al new models are expected to better capture the vegetation response to water stress as they can be directly constrained by observations at the process level observational data sets have been collected to fill some of the gaps in our understanding of tree water dynamics especially in temperate and mediterranean ecosystems zweifel et al 2007 west et al 2008 west et al 2012 matheny et al 2014 pivovaro et al 2016 matheny et al curtis such studies can inform ecohydrologic models by enhancing their fidelity and guiding their development christoffersen et al 2016 feng et al thompson additionally these models can be diagnosed to help further understand the ecohydrologic relationships providing information on where and what type of additional observations are needed to re develop the models perämäki et al 2001 hofstetter et al 2005 massoud et al 2018b future development will enhance the ability of lsms to predict individual tree processes such as drought tolerance or storage capacity and thus enhance the overall representation of vegetation s effect on the global water cycle mcdowell et al 2013 medlyn et al 2016 studies dedicated to understanding ecohydrologic processes have been a topic of interest for decades sala and lauenroth 1982 tyree 1988 christoffersen et al 2016 previous works have highlighted the differences between saturated and unsaturated flow aumann and ford 2002 improved on the representation of branch junctions schulte and brooks 2003 linked tree sap flow to stem growth steppe et al 2006 modeled both xylem as well as phloem water fluxes lacointe and minchin 2008 hölttä et al 2009 improved prediction of xylem abscisic acid aba concentrations by proper accounting of sap flow dodd et al 2008 improved understanding of the effect of root system architecture for the enhancement of drought tolerance draye et al 2010 accounted for hydraulic redistribution between different soil parts via plant root systems prieto et al 2012 david et al 2013 provided a computationally efficient 1 d alternative to 3 d models that includes a xylem flow model janott et al 2009 applied ecohydrologic models in a model emulation and machine learning framework massoud 2019 among others we present here a bayesian approach to estimate the parameters of a numerical model that simulates water storage and transport through a tree and its root zone coined the soil tree atmosphere continuum stac model several early papers have applied the bayes framework in tree transpiration models samanta et al ewers mackay et al 2012 rings et al 2013 the stac model used in this study is structured with an axi symmetrical 2d or quasi 3d representation of water flow through the combined soil tree domain where the soil is simulated as a separate domain from the tree itself the model uses richards equation and mualem van genuchten hydraulic functions from van genuchten 1980 and mualem 1976 to characterize water storage and movement through both the soil and tree domains we utilize bayesian inference to obtain parameter posterior distributions that allow model simulations to fit closely with observations made for a mature white fir abies concolor in the kings river experimental watershed krew in the sierra nevada california our goals for this study are to accurately simulate the dynamics of water flow in a single mature tree and its root zone g1 to properly infer model parameters that dictate how much water can be stored capacity or can flow conductance in the tree and its surrounding soil domain g2 and to assess the efficiency of parameter estimation based on the combination of different data sources g3 through this study we aim to diagnose some flaws or drawbacks of the model while also highlighting the properties that are well represented ordinarily parameter values used in model simulations do not accurately describe the underlying vegetation properties they are supposed to represent and here we aim to estimate these parameter values along with their associated uncertainties in this study we will gauge the effect of the different data sources on the respective parameter estimation results 2 materials and methods to estimate the parameter uncertainty of the stac model we apply bayes theorem within in a markov chain monte carlo mcmc framework katz 2002 numerical implementation of this application requires the user to specify a prior parameter distribution as well as a likelihood function the prior distribution should encode all the subjective knowledge about the parameters before collection of the data whereas the likelihood function summarizes in a probabilistic sense the compatibility of the observed data to the simulated model outputs likelihood functions play a key role in statistical inference and here we utilize a specially designed likelihood function that can combine various data streams from several processes being considered it is generally assumed that if only one data set is used for the parameter estimation the parameter values will be fitted to that specific process too closely however by considering various processes during the parameter estimation the parameter search will be balanced by each data set and an overall more realistic representation of the system properties can be achieved medlyn et al 2015 to this end we use the likelihood function defined in schoups and vrugt and utilize multiple processes during the parameter estimation we show that this does provide an overall accurate estimation of the soil and tree water properties when compared to observed data 2 1 stac model the soil tree atmosphere continuum stac model is a physically based nonlinear modeling framework kumagai 2001 bohrer et al katul chuang et al 2006 mirfenderesgi et al 2016 typical for the simulation of water flow in unsaturated media siqueira et al porporato rings et al 2013 the stac model discretizes the system domain and couples the soil with the tree domain simulating the soil roots and tree trunk as a continuum water flow is driven by water potential gradients along the coupled system bittner et al 2005 with spatially distributed root water uptake and canopy transpiration sink terms the stac model utilizes the hydrus model for simulation of hydrodynamics simunek et al 2008 where water flow through the soil and the tree root system and stem is driven by the evaporative demand and soil available water leading to a gradient in soil and xylem water potentials along the stac we approximate both the soil and plant conducting tissues by a porous medium with conductive and capacitive properties that are a function of water potential 2 2 domain boundaries hydrus allows the estimation of water potential volumetric water content and water flux density across the coupled soil tree domain both the soil and tree trunk are modeled as axial symmetrical represented by a rectangular domain fig 1 the simulated soil domain extends to 5 m outwards three soil layers characterize the top 2 5 m in the unsaturated soil and the bottom 2 5 m interval represents the weathered low conductivity saprolite that can store water but is inaccessible to tree roots the lower boundary of the soil at the 5 m depth was described by a seepage boundary allowing water to leave the soil domain when saturated and allowing for both upwards and downwards flow across the whole soil domain the upper boundary of the soil domain consists of measured values of rainfall and evapotranspiration the lower boundary condition of the tree trunk is root water uptake from the soil domain and the upper boundary of the tree is atmospheric demand of potential evapotranspiration the 10 cm radius of the tree trunk was chosen so that the domain volume is approximately equal to that of the sapwood of the tree we use observations of soil moisture soil water retention curves and assume hydraulic equilibrium to initiate water potential distribution across the domain for the soil we converted 24 elements of soil moisture data collected on july 15 2009 to soil water matric potential values using the laboratory measured retention curves then a 2nd order polynomial interpolation scheme was applied to estimate the soil water potential across the measured soil domain assuming hydraulic equilibrium at the domain boundaries this completed the necessary initial and boundary conditions of the domain for the model simulations 2 3 unifying equations to set up the model simulations we use the finite element hydrus software simunek et al 2008 which can solve unsaturated water flow across the soil tree domain using the richards equation richards 1931 in a discretized system of linear equations equations 1 and 2 the flow in the soil domain is presented here in its axisymmetrical two dimensional isotropic form 1 θ soil t 1 r r r k r h h r z k z h h z k z h z w soil h r z where θ soil l3l 3 is the volumetric soil water content k h lt 1 defines the unsaturated hydraulic conductivity function further denoted by either r for radial direction or z for vertical direction h l is the soil water pressure head r and z are the lateral and vertical coordinates positive downwards of the soil domain respectively t t is time and w soil l3l 3t 1 defines a sink source term that quantifies spatially distributed root water uptake from the soil both k and w soil are functions of θ and or h the subscripts r and z allow for the possibility of soil anisotropy i e to simulate water flow with the unsaturated hydraulic conductivity function being different for the r and z directions the set up of richards equation for the tree domain to represent flow through the canopy is similar to that of the soil domain in equation 1 but in one dimensional form this equation is derivable directly from equation 1 by reducing to one dimension z only thus the axi symetrical flow through the tree canopy is represented by 2 θ tree t z k z h h z k z h z w tree h z where θ tree l3l 3 is the volumetric soil water content k h lt 1 defines the unsaturated hydraulic conductivity function further denoted by z for vertical direction h l is the soil water pressure head z is the vertical coordinate of the tree domain positive downwards t t is time and w tree defines a sink term l3l 3t 1 that quantifies spatially distributed canopy transpiration for solution of equations 1 and 2 unsaturated hydraulic conductivity and the water retention functions must be defined for both the soil and tree conducting matrix the unsaturated hydraulic conductivity function equation 3 defines the relationship between the moisture content and the corresponding hydraulic conductivity of the domain and the retention function equation 4 characterizes the ability of the domain to retain water we define these functions using the relationships of van genuchten 1980 and mualem 1976 where 3 k h k s s e f f 1 1 s e f f 1 m m 2 and 4 s e f f h θ θ r θ s θ r 1 αh n m in which k h represents the hydraulic conductivity and the degree of effective saturation s e f f h represents the retention function for these equations θ s denotes the saturated water content at h 0 l3l 3 θ r is the residual water content l3l 3 α is a scale parameter inversely proportional to mean pore diameter l 1 n m 1 1 n is a shape parameter of the soil water characteristic and k s lt 1 is the conductivity at saturated conditions or when θ θ s 2 3 1 root water uptake model the actual root water uptake term in equation 1 is computed from 5 w soil h r z γ h β r z π r m 2 t p with w soil h r z representing actual water uptake of roots from the soil l3l3t 1 at each node in the soil domain controlled by root density distribution β r z l 3 and a soil water stress response function γ h r m is a coefficient that represents the maximum radial root depth and t p is the potential tree transpiration shown later in equation 9 both β r z and γ h have functional values between 0 and 1 the normalized root distribution β r z for an axisymmetrical soil domain ω is defined by vrugt et al 2001 gardenass et al 2005 6 β r z β 2 π ω β d ω with a general nonuniform root distribution β as defined by vrugt et al 2001 7 β r z 1 z z m 1 r r m e p z z m z z p r r m r r where z m and r m define the maximum rooting extent in the vertical and radial directions l respectively z and r are empirical parameters l that shift the maximum of the distribution in vertical and radial direction respectively and p z and p r are empirical parameters that determine the exponential shape of the distribution for water stressed root conditions in the soil γ h dimensionless was introduced by feddes et al 1978 and reduces root water uptake from its maximum possible value because of soil water stress γ h is defined by four water potential values p1 through p4 feddes et al 2001 for soil water potential values between p2 and p3 γ h will be optimum and equal to 1 0 for h values between p1 and p2 soil aeration stress and between p3 and p4 soil water stress γ h values will be smaller than one and zero at a minimum the equation that describes the soil water stress response γ h as a function of water potential h in cm is 8 γ h h 25 c m p 3 25 c m i f p 3 h p 4 for the estimation of the potential tree transpiration t p in equation 5 meteorological data from a local weather tower were used to estimate local hourly potential evapotranspiration et 0 using the penman monteith equation allen et al 1998 this is the reference penman monteith equation as in allen et al 1998 where the surface stomatal conductance parameters are for non water limiting conditions values for the aerodynamic resistance and bulk surface stomatal resistance terms were calculated according to fao guidelines allen et al 1998 to estimate the potential tree transpiration t p we multiplied et 0 with a tree coefficient s et0 or 9 t p s et 0 et 0 e s we assume soil water evaporation e s to be negligible as canopy cover dominates the landscape and dry surface soil moisture conditions occurred throughout the study time period finally from integration of equation 5 over the soil domain the actual total root water uptake r a l t 1 is computed from 10 r a 2 π π r m 2 ω r w soil d ω in the presented coupled domain the volume of water taken up by the roots must now be transported in the conducting vessels xylem of the sapwood in the tree trunk for that purpose the coupled model includes a small storage reservoir that acts as a buffer for water transport between the soil and the tree finally by defining a lower flux boundary condition for the tree domain the tree s sapwood draws water from the buffer storage and initiates water flux through the tree this water flux and ultimately tree transpiration are discussed in the next section 2 3 2 tree transpiration the stac model uses the jarvis model to quantify plant transpiration waring et al 1979 specifically the canopy transpiration sink term w tree h z in equation 2 is calculated as follows 11 w tree h z γ h β z t p where β z is the one dimensional canopy density distribution function used for estimation of transpiration at different elevations along the canopy in the tree domain γ h is the canopy water stress response function that represents the stomatal closure under increasing water tension and is of a similar feddes form as used for characterizing soil water stress t p is the potential tree transpiration from equation 9 the normalized canopy distribution β z for an axisymmetrical tree domain ω is defined by vrugt et al 2001 gardenass et al 2005 12 β z β 2 π ω β d ω with a general nonuniform tree distribution β l 1 as defined by rings et al 2013 13 β z 1 z 6 24 for z 6 m and zero below 6 m in other words the tree distribution term that controls transpiration is zero at heights of the tree trunk that are below 6 m is at a maximum at 6 m and decreases linearly with height at points above 6 m thus the actual tree transpiration t a is computed from 14 t a 2 π π r m 2 ω r w tree d ω 2 π r a ω γ h β z d z overall this approach couples root water uptake with tree transpiration therefore the model is set up so that at each time step the amount of total water uptake from the tree s roots r a is equivalent to the water flow leaving the soil domain into the buffer zone of the tree and the tree s transpiration t a is the flow of water leaving the tree the tree water storage calculation can be estimated as the difference between the water flowing into r a and out of t a the simulated tree domain the solutions to these equations are estimated through a finite element mesh with thousands of nodes dividing the domain of the problem into a collection of subdomains with each subdomain represented by these sets of equations 2 3 3 sapflux and soil water storage we can assume that the simulated values of the water fluxes and stores at each individual node in the finite element mesh grid represent the true values in the actual tree soil system this assumption allows for the calculation of processes such as sapflux or soil water storage at each time step for calculation of the sapflux output the stac model simulates the change in water content at each node at each time step this directly allows the simulation of water flux in the model the amount of which is controlled by the chosen parameterization the stac model does not output soil water storage directly yet by combining the water content information at each node one can estimate the water storage changes at each time step therefore if we take the soil water storage measurement value at initialization to be our starting point for the simulated soil water storage then we can estimate the change of moisture content values at each time step and therefore calculate the change in storage and thus the storage level at each time step 2 4 data the model will be tested using data collected in and around a white fir abies concolor in a 99 ha subcatchment p301 of the king s river experimental watershed krew as part of the critical zone observatory czo tree 1 project this site is located in the rain snow transition zone of the southern sierra nevada mountain range in california at an elevation of 2018 m data include soil water content and water potential in 3 spatial dimensions in the root zone tree stem water content and sap flux canopy water potential and atmospheric variables including net radiation air temperature and humidity undisturbed soil samples were collected to a depth of 2 5 m for the soil analysis corresponding measurements of saturated hydraulic conductivity were made using the constant head method reynolds et al 2002 calibration data was selected for a 17 day rainless period in summer of 2009 starting july 15 and includes sapflow stem water potential and soil water storage three sap flow sensors transflonz palmerston north nz were installed into the sapwood at a trunk height of 2 5 m using the compensation heat pulse technique green and clothier 1988 average sap flux flow l t was estimated at 30 min time intervals then stem water potential measurements were taken from terminal shoots of the stems of lower tree branches at approximately 6 m height seven measurements were taken during 24 h on july 21 22 2009 finally echo 5 te soil moisture sensors were installed at depths of 0 15 m 0 30 m 0 60 m and 0 90 m in each of 6 locations within a 5 m radius from the tree trunk the sensors were calibrated in the laboratory kizito et al 2008 from which it was determined that their accuracy is around 3 for a range of soils using all water content measurements average total soil water storage m3 was computed during the 17 day measurement period every half hour however only about half of the soil water storage data was used for the parameter estimation due to incomplete measurements on some days 2 5 bayesian inference of model parameters we chose a total of 15 parameters from the stac model to be estimated a total of 4 parameters are used to characterize the spatial tree root distribution see table 1 and these include z and r from equation 7 which are empirical parameters m that shift the maximum of the distribution in vertical and radial direction respectively and p z and p r are empirical parameters that determine the exponential shape of the distribution also a total of 3 parameters are used to characterize the water stress response functions see table 1 finally a total of 8 parameters are used to characterize the hydraulic conductivity and retention of the entire coupled domain see table 1 these parameters include θ s k s α and n for the tree layer and θ s and k s for soil layers 1 and 2 bayes law or bayes rule mathematically expresses the fundamental relationship between the prior conditional and posterior beliefs of the parameter values in this case a 15 dimensional vector denoted by x this probability equation can be formalized as p x y l x y where p x y signifies the posterior parameter distributions and l x y represents the likelihood function the model simulations are coupled with observed data y to estimate the posterior probability of the parameters using a rigorous markov chain monte carlo mcmc sampling algorithm the differential evolution adaptive metropolis dream of vrugt 2016 vrugt and massoud 2018 the likelihood function used for the mcmc sampling can combine all three sources of information i e the sapflow stem water potential and soil water storage without being affected by the magnitude of error that is contributed from any of the individual sources this likelihood function is applied as follows 15 l x y φ σ 2 1 2 j 1 3 t 2 n j e j t x φ e j t 1 x σ j t 2 where j distinguishes the various model outputs considered for the parameter estimation x is the parameter set y is the observed data φ is the temporal correlation of the residuals with 30 min between each time step and σ is the measurement error of the calibration data e j t x is the error of the model simulations for output j and a given parameter set x therefore we calculate a likelihood value from each considered output i e l x y φ σ 2 j and as equation 15 indicates we sum the three likelihood values to obtain one overall probability value for this study we examine various parameter estimation strategies first we fit the model simulations to individual data sources i e sapflux stem water potential and soil water storage and then fit the simulations to all three sources combined in the first case the model is calibrated to just the sapflux data and equation 15 is reduced to just one term the likelihood obtained from the fit to the sapflux data these results are assigned the sap acronym for the second and third cases the model is calibrated to the stem water potential and soil water storage data respectively and equation 15 is similarly reduced to one term these results are assigned the stem and stor acronyms respectively in the final case the model is calibrated to all three data sets and equation 15 utilizes all three likelihood terms these results are assigned the full acronym this final case highlights the ability of the likelihood function to combine various data streams by normalizing the prediction errors based on the observation error and combining the likelihood or probability from all three processes considered for the parameter estimation runs the measurement error values were defined as σ sap 1 cm day σ stem 100 kpa and σ stor 0 05 m3 2 6 numerical setup and cpu costs calculation of the stac model involves solution of the partial differential equations pde that are described in the previous sections the time difference between each model output is δt 30 min and the temporal discretization of the pde is based on an adaptive time step limited by 10 maximum iterations and with tolerances of 0 01 unitless and 10 kpa to solve the moisture levels when described by the moisture content θ or the head h respectively the spatial discretization is designed by a finite element mesh with thousands of nodes and the location of these nodes for our case study are depicted in figs 1 and 3 with each dot representing the center of a node this first involves dividing the domain of the problem into a collection of subdomains with each subdomain represented by a set of element equations to the original problem followed by systematically recombining all sets of element equations into a global system of equations for the final calculation the stac model simulation time is 30 seconds on average for the 17 day period in the sierra nevada test site for the mcmc runs we used a total of 8 chains and ran for 2500 generations therefore a simple calculation shows that the stac model parameters can be estimated in roughly 30 seconds multiplied by 8 chains multiplied by 2500 generations this amounts to 600 000 seconds to apply the parameter estimation which ultimately translates to a week of simulation time for convergence of the posterior distributions we noticed that the sap and full strategies converged well into the 2500 generations however for the stem strategy the posterior solution converged relatively quickly since there were only 7 measurements to fit against lastly and importantly for the stor strategy the posterior solution was never really identified even after 2500 generations 3 results for the remainder of the paper the results are color coded as follows the estimation to sapflux sap is shown in blue estimation to stem water potential stem is shown in light blue estimation to soil water storage stor is shown in green and estimation to all three data sets full is shown in black 3 1 parameter estimates the stac model simulates the spatial root distribution of the tree using equation 7 for the four estimation methods considered the estimated root distribution parameters are shown in table 1 the standard deviation of the posterior samples are shown in parenthesis in table 1 and are represented graphically in fig 2 the resulting root distributions shown in fig 3 allow a visual comparison of all the different estimation strategies both the tree and its roots may experience stress from water limitation as well as nutrient limitation or stress from extreme vapor pressure deficits as a result of hot temperatures among other factors the stac model numerically accounts for this through the stress terms γ in equations 5 and 11 these stress terms are characterized using the feddes function feddes et al 1978 and have values ranging from 0 full stress to 1 no stress four levels of head or pressure are used to express this function p1 p2 p3 and p4 for soil water potential values between p2 and p3 there is no stress while the stress occurs between p1 p2 aeration stress or saturated conditions and between p3 p4 water stress or drought conditions a few of these coefficients are parameterized and the calibrated values are shown in table 1 the standard deviation of the posterior samples are shown in parenthesis in table 1 and are represented graphically in fig 2 after all feddes parameters are defined the stress functions for each layer can be constructed these functions are shown in fig 4 and also allow a visual comparison of the various estimation strategies through equations 3 and 4 the stac model characterizes the retention and hydraulic conductivity of each soil layer and of the tree layer table 1 shows the values of the model parameters that are van genuchten parameters used to create hydraulic relationships of the tree and soil domains the standard deviation of the posterior samples are shown in parenthesis in table 1 and are represented graphically in fig 2 these parameters help represent the saturated conductivity and moisture contents of each layer and also contain certain shape parameters for the van genuchten functions the resulting hydraulic conductivity and retention functions for soil layers 1 and 2 as well as for the tree layer are shown in fig 5 in the first column of figures the retention function of each layer is shown one thing to note is that the retention function of the tree domain greatly differs from that of the soil layers the figure shows that it will require higher amounts of pressure to extract the water from the tree than from the soils 103 kpa for soils vs 105 kpa for tree which can be expected north and nobel 1997 black and pritchard 2002 3 2 comparing stac model simulations with observations in this study we focus on three processes represented in the stac model which are the sapflux through the tree domain the stem water potential in the canopy and the water storage of the soil domain all of these outputs are accompanied by observed data and the model simulation results are shown in fig 6 for each parameter estimation method for the sapflux simulations the sap and full strategies performed the best according to the rmse table 2 the other estimation strategies stem and stor do not fit the observations quite as well however they do allow the simulations to capture high peaks in the observed data for the stem water potential simulations the stem strategy provided the lowest rmse although estimation to the stem water potential data was not as informative since there were only 7 data points to fit these observations still allow us to constrain the simulations this is shown in table 2 since the rmse for the stem water potential simulations of the full strategy is lower than that of the sap and stor strategies which is not surprising since the full strategy considers the stem water potential data in its likelihood function for the soil water storage simulations the stor parameter set performed the best according to the rmse yet we see in fig 6 that all the simulations behave almost identically in all simulations the model underestimated the observed soil water storage indicating a model structural error that could be from more water being drawn from the soil domain in the simulations than is seen in the observed data or perhaps this could be due to the use of a likelihood function that only accounts for short term temporal correlation 4 discussion for this study we wanted to accurately simulate the dynamics of water flow in and around a mature white fir in the sierra nevada california using a process based ecohydrologic model the stac model g1 to achieve these simulations we inferred model parameters that dictated how much water can be stored or can flow in the tree and its surrounding soil domain g2 lastly we combined various data sources to accurately pinpoint the posterior distributions for the model parameters g3 by fitting the observed data and its underlying uncertainty we were able to mimic the dynamics seen for the white fir using the process based stac model our results indicate that some stac model parameters were not identifiable regardless of the data used for parameter estimation such as the root distribution parameters however some parameters were estimated well with posterior distributions that were well identified regardless of the data set used such as the parameter that describes the tree s saturated hydraulic conductivity k s tree overall as hypothesized the combination of all three data sets allows for the most precise estimation of the model parameters with the most localized posteriors and thus the least uncertainty about the corresponding parameter values in past parameter estimation studies it has been common to separate data sets to calibrate the model on the first set of data and then to evaluate that calibration on the second set however given the lack of data availability for this study such as only having 7 stem water potential measurements to use this type of evaluation is challenging thus in this study we focus on parameter estimation to the observed data but leave model validation for future studies 4 1 model limitations interestingly our results show that most of the parameters were not identifiable when just the soil water storage measurements were used as calibration data stor the only parameters that showed any sensitivity to calibration of this output were the θ s soil1 and the α tree parameters we can infer from the very wide posterior distributions for the stor estimates fig 2 this informs us that the soil water storage might very well be ill represented in the model additionally the α tree parameter seems to have a very narrow posterior for each of the calibration strategies also shown in fig 2 this indicates that the parameter used for this process is not properly represented either by having an incorrect prior range or possibly by having a bad model representation in general these types of clues allow us to further diagnose the model and can help pinpoint possible model improvements and developments 4 2 applicability of richards equation for xylem flow to simulate water flow through the coupled tree and soil domains the stac model is setup with the hydrus software which is simulated with the richards equation richards equation has been a common tool for simulating unsaturated water flow in nonswelling soils with numerous applications shown for simulating vegetative mediums in recent studies e g sperry et al 1998 bohrer et al katul or janott et al 2009 while the applicability of richards equation allows us to simulate water flow in the stem of a mature tree and its respective soil domain as a coupled system there are certain biological factors of a tree s water dynamics that are not captured directly with a richards equation type of model such as elasticity of the xylem which for simplicity is not represented in most current ecohydrologic models but see christoffersen et al 2016 future developments of the application of richards equation that consider elasticity of the xylem could drastically improve the model s capability to capture diurnal changes of water storage in plants mencuccini et al as a reference applications in the literature for models that account for stem elasticity in the water retention function include perämäki et al 2001 who developed a model that simulates tree stem diameter variations and transpiration using a dynamic sap flow model and hofstetter et al 2005 who developed and validated a continuum micromechanics model for the elasticity of wood 4 3 other parameter estimation methods in this study the parameter estimation algorithm sums the errors of the simulations into a single index and computes a likelihood based on this sum while most calibration studies are performed in this manner some drawbacks arise from employing this method for example since the soil storage output has a stronger memory effect within the modeling framework fig 6 it would be hypothetically difficult to separate the model structural errors in the process of the parameter estimation this is why the stor set of parameters produce the least realistic simulations in future work it would be beneficial to possibly use an alternative likelihood function or perhaps a parameter estimation method that completely does not require a likelihood function likelihood free calibration methods are new in the literature e g the approximate bayesian computation abc method which allows parameter estimation to a set of summary metrics instead of calibrating to a set of simulation residuals vrugt and sadegh 2013 sadegh and vrugt 2014 for instance our study fig 7 shows the observed relative hydraulic conductivity of a white fir abies concolor compared with ones produced from the calibrated parameter sets in this study the full parameter set creates a hydraulic relationship that is most realistic according to the observed relationship but there could be a parameter set that produces a closer hydraulic relationship to the observed data this parameter set can be inferred with the abc method and may prove to be more realistic although this goes beyond the scope of this study we encourage readers to try various parameter estimation algorithms that are available such as abc that use many different summary metrics to capture the hydraulic behaviors of the soil tree atmosphere system 5 conclusion major inconsistencies exist in the representation of vegetation in large scale land surface and climate models model parameters are typically inferred from empirical relationships or extracted from arbitrary data sets and efforts are now aimed at identifying parameter sets that appropriately describe these vegetation properties we presented simulations with the soil tree atmosphere continuum stac model showing the hydraulic processes of a mature white fir abies concolor and its surrounding root zone the model couples both soil and tree domains and simulates the movement of water based on different ecohydrologic processes we used bayesian inversion to estimate the model parameters against observations of sapflux stem water potential and soil water storage we evaluated the model s ability to fit the data with specific emphasis on the soil and tree water flow and storage properties the calibration of the model allowed us to estimate the spatial root distribution of the tree the feddes stress parameters to describe aeration or water stress and the van genuchten parameters that correspond to the retention and conductivity functions of soil and tree domains after calibration the stac model simulated processes such as sapflow stem water potential and soil water storage and the outputs were compared with the observed data for a full diagnosis of the model the results presented in this paper show that the choice of calibration data largely affects the parameter estimates and thus the model outputs by considering the full domain of the tree and combining all the observed data in the parameter estimation process the most realistic parameter combination was estimated and the closest fit between the model outputs and the observed data was achieved a likelihood function that considers various streams of data by normalizing simulation errors by the measurement errors was considered and implemented we conclude that the stac model offers a physical representation of water flow in and around a vegetative medium and can provide insight on how trees actually behave in their environments ecohydrologic models are evolving from having empirically based structures to more physically based ones setting the stage for tools such as the stac model to expand our knowledge on fundamental hydraulic processes that occur in vegetation software availability the stac model is not open source software but available upon request from the first author data accessibility the measured data used for this study is made available through the following digital figshare repository https doi org 10 6084 m9 gshare 5792676 v1 acknowledgements the authors appreciate support from the scgsr fellowship of the department of energy e m the uc lab fees research program award 237285 e m the lfr 18 542511 c x and the doe office of science next generation ecosystem experiment at tropics ngee t project c x the authors are also grateful to dr jasper a vrugt for providing the tools needed to conduct this study including the stac model source code the calibration data from the krew site as well as discussion that inspired ideas appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 01 022 
26237,we present a parameter estimation study of the soil tree atmosphere continuum stac model a process based model that simulates water flow through an individual tree and its surrounding root zone parameters are estimated to optimize the model fit to observations of sap flux stem water potential and soil water storage made for a white fir abies concolor in the sierra nevada california bayesian inference is applied with a likelihood function that considers temporal correlation of the model errors key vegetation properties are estimated such as the tree s root distribution tolerance to drought and hydraulic conductivity and retention functions we find the model parameters are relatively non identifiable when considering just soil water storage overall by utilizing multiple processes e g sap flow stem water potential and soil water storage during the parameter estimation we find the simulations of the soil and tree water properties to be more accurate when compared to observed data keywords ecohydrology vegetation hydraulics climate parameter estimation mcmc 1 introduction ecohydrology is a field of study focusing on the hydrologic mechanisms that govern and explain ecologic patterns and processes rodriguez iturbe 2000 jackson et al 2009 ecohydrologic system properties depend on many interrelated links between climate soil and vegetation rodriguez iturbe et al 2001 one part of this system includes the role that climate and soil have in controlling vegetation dynamics lange et al 1976 boyer 1982 kramer and boyer 1995 larcher 2003 jones 2013 ali et al 2016 and another part of the system is the control that vegetation exerts on the water and energy balance schlesinger et al 1990 kutzbach et al harrison zeng et al 1999 massoud et al 2018a a quantitative understanding of these vegetation dynamics better supports environmental preservation management of resources and improved model representation of ecohydrologic systems noy meir 1973 shmida et al 1986 scholes and walker 2004 xu et al 2013 johnson et al 2018 generally the role that trees play in the overall water cycle in regards to ecosystem water storage residence time and vegetation tolerance to drought are poorly represented in land surface models lsms fisher et al 2018 for example the impact of soil water availability on vegetation is typically represented in land surface and climate models using simple empirical relationships with parameter values that are extracted from arbitrary data sets this may not represent vegetation hydraulic properties or capture seasonal or ontogenetic changes observed in reality which can cause major bias in the representation of vegetation in this suite of models the lack of proper representation of water dynamics in vegetation contributes to large discrepancies seen between various model simulations that run into the next century sitch et al 2008 mcdowell et al mackay et al new models are expected to better capture the vegetation response to water stress as they can be directly constrained by observations at the process level observational data sets have been collected to fill some of the gaps in our understanding of tree water dynamics especially in temperate and mediterranean ecosystems zweifel et al 2007 west et al 2008 west et al 2012 matheny et al 2014 pivovaro et al 2016 matheny et al curtis such studies can inform ecohydrologic models by enhancing their fidelity and guiding their development christoffersen et al 2016 feng et al thompson additionally these models can be diagnosed to help further understand the ecohydrologic relationships providing information on where and what type of additional observations are needed to re develop the models perämäki et al 2001 hofstetter et al 2005 massoud et al 2018b future development will enhance the ability of lsms to predict individual tree processes such as drought tolerance or storage capacity and thus enhance the overall representation of vegetation s effect on the global water cycle mcdowell et al 2013 medlyn et al 2016 studies dedicated to understanding ecohydrologic processes have been a topic of interest for decades sala and lauenroth 1982 tyree 1988 christoffersen et al 2016 previous works have highlighted the differences between saturated and unsaturated flow aumann and ford 2002 improved on the representation of branch junctions schulte and brooks 2003 linked tree sap flow to stem growth steppe et al 2006 modeled both xylem as well as phloem water fluxes lacointe and minchin 2008 hölttä et al 2009 improved prediction of xylem abscisic acid aba concentrations by proper accounting of sap flow dodd et al 2008 improved understanding of the effect of root system architecture for the enhancement of drought tolerance draye et al 2010 accounted for hydraulic redistribution between different soil parts via plant root systems prieto et al 2012 david et al 2013 provided a computationally efficient 1 d alternative to 3 d models that includes a xylem flow model janott et al 2009 applied ecohydrologic models in a model emulation and machine learning framework massoud 2019 among others we present here a bayesian approach to estimate the parameters of a numerical model that simulates water storage and transport through a tree and its root zone coined the soil tree atmosphere continuum stac model several early papers have applied the bayes framework in tree transpiration models samanta et al ewers mackay et al 2012 rings et al 2013 the stac model used in this study is structured with an axi symmetrical 2d or quasi 3d representation of water flow through the combined soil tree domain where the soil is simulated as a separate domain from the tree itself the model uses richards equation and mualem van genuchten hydraulic functions from van genuchten 1980 and mualem 1976 to characterize water storage and movement through both the soil and tree domains we utilize bayesian inference to obtain parameter posterior distributions that allow model simulations to fit closely with observations made for a mature white fir abies concolor in the kings river experimental watershed krew in the sierra nevada california our goals for this study are to accurately simulate the dynamics of water flow in a single mature tree and its root zone g1 to properly infer model parameters that dictate how much water can be stored capacity or can flow conductance in the tree and its surrounding soil domain g2 and to assess the efficiency of parameter estimation based on the combination of different data sources g3 through this study we aim to diagnose some flaws or drawbacks of the model while also highlighting the properties that are well represented ordinarily parameter values used in model simulations do not accurately describe the underlying vegetation properties they are supposed to represent and here we aim to estimate these parameter values along with their associated uncertainties in this study we will gauge the effect of the different data sources on the respective parameter estimation results 2 materials and methods to estimate the parameter uncertainty of the stac model we apply bayes theorem within in a markov chain monte carlo mcmc framework katz 2002 numerical implementation of this application requires the user to specify a prior parameter distribution as well as a likelihood function the prior distribution should encode all the subjective knowledge about the parameters before collection of the data whereas the likelihood function summarizes in a probabilistic sense the compatibility of the observed data to the simulated model outputs likelihood functions play a key role in statistical inference and here we utilize a specially designed likelihood function that can combine various data streams from several processes being considered it is generally assumed that if only one data set is used for the parameter estimation the parameter values will be fitted to that specific process too closely however by considering various processes during the parameter estimation the parameter search will be balanced by each data set and an overall more realistic representation of the system properties can be achieved medlyn et al 2015 to this end we use the likelihood function defined in schoups and vrugt and utilize multiple processes during the parameter estimation we show that this does provide an overall accurate estimation of the soil and tree water properties when compared to observed data 2 1 stac model the soil tree atmosphere continuum stac model is a physically based nonlinear modeling framework kumagai 2001 bohrer et al katul chuang et al 2006 mirfenderesgi et al 2016 typical for the simulation of water flow in unsaturated media siqueira et al porporato rings et al 2013 the stac model discretizes the system domain and couples the soil with the tree domain simulating the soil roots and tree trunk as a continuum water flow is driven by water potential gradients along the coupled system bittner et al 2005 with spatially distributed root water uptake and canopy transpiration sink terms the stac model utilizes the hydrus model for simulation of hydrodynamics simunek et al 2008 where water flow through the soil and the tree root system and stem is driven by the evaporative demand and soil available water leading to a gradient in soil and xylem water potentials along the stac we approximate both the soil and plant conducting tissues by a porous medium with conductive and capacitive properties that are a function of water potential 2 2 domain boundaries hydrus allows the estimation of water potential volumetric water content and water flux density across the coupled soil tree domain both the soil and tree trunk are modeled as axial symmetrical represented by a rectangular domain fig 1 the simulated soil domain extends to 5 m outwards three soil layers characterize the top 2 5 m in the unsaturated soil and the bottom 2 5 m interval represents the weathered low conductivity saprolite that can store water but is inaccessible to tree roots the lower boundary of the soil at the 5 m depth was described by a seepage boundary allowing water to leave the soil domain when saturated and allowing for both upwards and downwards flow across the whole soil domain the upper boundary of the soil domain consists of measured values of rainfall and evapotranspiration the lower boundary condition of the tree trunk is root water uptake from the soil domain and the upper boundary of the tree is atmospheric demand of potential evapotranspiration the 10 cm radius of the tree trunk was chosen so that the domain volume is approximately equal to that of the sapwood of the tree we use observations of soil moisture soil water retention curves and assume hydraulic equilibrium to initiate water potential distribution across the domain for the soil we converted 24 elements of soil moisture data collected on july 15 2009 to soil water matric potential values using the laboratory measured retention curves then a 2nd order polynomial interpolation scheme was applied to estimate the soil water potential across the measured soil domain assuming hydraulic equilibrium at the domain boundaries this completed the necessary initial and boundary conditions of the domain for the model simulations 2 3 unifying equations to set up the model simulations we use the finite element hydrus software simunek et al 2008 which can solve unsaturated water flow across the soil tree domain using the richards equation richards 1931 in a discretized system of linear equations equations 1 and 2 the flow in the soil domain is presented here in its axisymmetrical two dimensional isotropic form 1 θ soil t 1 r r r k r h h r z k z h h z k z h z w soil h r z where θ soil l3l 3 is the volumetric soil water content k h lt 1 defines the unsaturated hydraulic conductivity function further denoted by either r for radial direction or z for vertical direction h l is the soil water pressure head r and z are the lateral and vertical coordinates positive downwards of the soil domain respectively t t is time and w soil l3l 3t 1 defines a sink source term that quantifies spatially distributed root water uptake from the soil both k and w soil are functions of θ and or h the subscripts r and z allow for the possibility of soil anisotropy i e to simulate water flow with the unsaturated hydraulic conductivity function being different for the r and z directions the set up of richards equation for the tree domain to represent flow through the canopy is similar to that of the soil domain in equation 1 but in one dimensional form this equation is derivable directly from equation 1 by reducing to one dimension z only thus the axi symetrical flow through the tree canopy is represented by 2 θ tree t z k z h h z k z h z w tree h z where θ tree l3l 3 is the volumetric soil water content k h lt 1 defines the unsaturated hydraulic conductivity function further denoted by z for vertical direction h l is the soil water pressure head z is the vertical coordinate of the tree domain positive downwards t t is time and w tree defines a sink term l3l 3t 1 that quantifies spatially distributed canopy transpiration for solution of equations 1 and 2 unsaturated hydraulic conductivity and the water retention functions must be defined for both the soil and tree conducting matrix the unsaturated hydraulic conductivity function equation 3 defines the relationship between the moisture content and the corresponding hydraulic conductivity of the domain and the retention function equation 4 characterizes the ability of the domain to retain water we define these functions using the relationships of van genuchten 1980 and mualem 1976 where 3 k h k s s e f f 1 1 s e f f 1 m m 2 and 4 s e f f h θ θ r θ s θ r 1 αh n m in which k h represents the hydraulic conductivity and the degree of effective saturation s e f f h represents the retention function for these equations θ s denotes the saturated water content at h 0 l3l 3 θ r is the residual water content l3l 3 α is a scale parameter inversely proportional to mean pore diameter l 1 n m 1 1 n is a shape parameter of the soil water characteristic and k s lt 1 is the conductivity at saturated conditions or when θ θ s 2 3 1 root water uptake model the actual root water uptake term in equation 1 is computed from 5 w soil h r z γ h β r z π r m 2 t p with w soil h r z representing actual water uptake of roots from the soil l3l3t 1 at each node in the soil domain controlled by root density distribution β r z l 3 and a soil water stress response function γ h r m is a coefficient that represents the maximum radial root depth and t p is the potential tree transpiration shown later in equation 9 both β r z and γ h have functional values between 0 and 1 the normalized root distribution β r z for an axisymmetrical soil domain ω is defined by vrugt et al 2001 gardenass et al 2005 6 β r z β 2 π ω β d ω with a general nonuniform root distribution β as defined by vrugt et al 2001 7 β r z 1 z z m 1 r r m e p z z m z z p r r m r r where z m and r m define the maximum rooting extent in the vertical and radial directions l respectively z and r are empirical parameters l that shift the maximum of the distribution in vertical and radial direction respectively and p z and p r are empirical parameters that determine the exponential shape of the distribution for water stressed root conditions in the soil γ h dimensionless was introduced by feddes et al 1978 and reduces root water uptake from its maximum possible value because of soil water stress γ h is defined by four water potential values p1 through p4 feddes et al 2001 for soil water potential values between p2 and p3 γ h will be optimum and equal to 1 0 for h values between p1 and p2 soil aeration stress and between p3 and p4 soil water stress γ h values will be smaller than one and zero at a minimum the equation that describes the soil water stress response γ h as a function of water potential h in cm is 8 γ h h 25 c m p 3 25 c m i f p 3 h p 4 for the estimation of the potential tree transpiration t p in equation 5 meteorological data from a local weather tower were used to estimate local hourly potential evapotranspiration et 0 using the penman monteith equation allen et al 1998 this is the reference penman monteith equation as in allen et al 1998 where the surface stomatal conductance parameters are for non water limiting conditions values for the aerodynamic resistance and bulk surface stomatal resistance terms were calculated according to fao guidelines allen et al 1998 to estimate the potential tree transpiration t p we multiplied et 0 with a tree coefficient s et0 or 9 t p s et 0 et 0 e s we assume soil water evaporation e s to be negligible as canopy cover dominates the landscape and dry surface soil moisture conditions occurred throughout the study time period finally from integration of equation 5 over the soil domain the actual total root water uptake r a l t 1 is computed from 10 r a 2 π π r m 2 ω r w soil d ω in the presented coupled domain the volume of water taken up by the roots must now be transported in the conducting vessels xylem of the sapwood in the tree trunk for that purpose the coupled model includes a small storage reservoir that acts as a buffer for water transport between the soil and the tree finally by defining a lower flux boundary condition for the tree domain the tree s sapwood draws water from the buffer storage and initiates water flux through the tree this water flux and ultimately tree transpiration are discussed in the next section 2 3 2 tree transpiration the stac model uses the jarvis model to quantify plant transpiration waring et al 1979 specifically the canopy transpiration sink term w tree h z in equation 2 is calculated as follows 11 w tree h z γ h β z t p where β z is the one dimensional canopy density distribution function used for estimation of transpiration at different elevations along the canopy in the tree domain γ h is the canopy water stress response function that represents the stomatal closure under increasing water tension and is of a similar feddes form as used for characterizing soil water stress t p is the potential tree transpiration from equation 9 the normalized canopy distribution β z for an axisymmetrical tree domain ω is defined by vrugt et al 2001 gardenass et al 2005 12 β z β 2 π ω β d ω with a general nonuniform tree distribution β l 1 as defined by rings et al 2013 13 β z 1 z 6 24 for z 6 m and zero below 6 m in other words the tree distribution term that controls transpiration is zero at heights of the tree trunk that are below 6 m is at a maximum at 6 m and decreases linearly with height at points above 6 m thus the actual tree transpiration t a is computed from 14 t a 2 π π r m 2 ω r w tree d ω 2 π r a ω γ h β z d z overall this approach couples root water uptake with tree transpiration therefore the model is set up so that at each time step the amount of total water uptake from the tree s roots r a is equivalent to the water flow leaving the soil domain into the buffer zone of the tree and the tree s transpiration t a is the flow of water leaving the tree the tree water storage calculation can be estimated as the difference between the water flowing into r a and out of t a the simulated tree domain the solutions to these equations are estimated through a finite element mesh with thousands of nodes dividing the domain of the problem into a collection of subdomains with each subdomain represented by these sets of equations 2 3 3 sapflux and soil water storage we can assume that the simulated values of the water fluxes and stores at each individual node in the finite element mesh grid represent the true values in the actual tree soil system this assumption allows for the calculation of processes such as sapflux or soil water storage at each time step for calculation of the sapflux output the stac model simulates the change in water content at each node at each time step this directly allows the simulation of water flux in the model the amount of which is controlled by the chosen parameterization the stac model does not output soil water storage directly yet by combining the water content information at each node one can estimate the water storage changes at each time step therefore if we take the soil water storage measurement value at initialization to be our starting point for the simulated soil water storage then we can estimate the change of moisture content values at each time step and therefore calculate the change in storage and thus the storage level at each time step 2 4 data the model will be tested using data collected in and around a white fir abies concolor in a 99 ha subcatchment p301 of the king s river experimental watershed krew as part of the critical zone observatory czo tree 1 project this site is located in the rain snow transition zone of the southern sierra nevada mountain range in california at an elevation of 2018 m data include soil water content and water potential in 3 spatial dimensions in the root zone tree stem water content and sap flux canopy water potential and atmospheric variables including net radiation air temperature and humidity undisturbed soil samples were collected to a depth of 2 5 m for the soil analysis corresponding measurements of saturated hydraulic conductivity were made using the constant head method reynolds et al 2002 calibration data was selected for a 17 day rainless period in summer of 2009 starting july 15 and includes sapflow stem water potential and soil water storage three sap flow sensors transflonz palmerston north nz were installed into the sapwood at a trunk height of 2 5 m using the compensation heat pulse technique green and clothier 1988 average sap flux flow l t was estimated at 30 min time intervals then stem water potential measurements were taken from terminal shoots of the stems of lower tree branches at approximately 6 m height seven measurements were taken during 24 h on july 21 22 2009 finally echo 5 te soil moisture sensors were installed at depths of 0 15 m 0 30 m 0 60 m and 0 90 m in each of 6 locations within a 5 m radius from the tree trunk the sensors were calibrated in the laboratory kizito et al 2008 from which it was determined that their accuracy is around 3 for a range of soils using all water content measurements average total soil water storage m3 was computed during the 17 day measurement period every half hour however only about half of the soil water storage data was used for the parameter estimation due to incomplete measurements on some days 2 5 bayesian inference of model parameters we chose a total of 15 parameters from the stac model to be estimated a total of 4 parameters are used to characterize the spatial tree root distribution see table 1 and these include z and r from equation 7 which are empirical parameters m that shift the maximum of the distribution in vertical and radial direction respectively and p z and p r are empirical parameters that determine the exponential shape of the distribution also a total of 3 parameters are used to characterize the water stress response functions see table 1 finally a total of 8 parameters are used to characterize the hydraulic conductivity and retention of the entire coupled domain see table 1 these parameters include θ s k s α and n for the tree layer and θ s and k s for soil layers 1 and 2 bayes law or bayes rule mathematically expresses the fundamental relationship between the prior conditional and posterior beliefs of the parameter values in this case a 15 dimensional vector denoted by x this probability equation can be formalized as p x y l x y where p x y signifies the posterior parameter distributions and l x y represents the likelihood function the model simulations are coupled with observed data y to estimate the posterior probability of the parameters using a rigorous markov chain monte carlo mcmc sampling algorithm the differential evolution adaptive metropolis dream of vrugt 2016 vrugt and massoud 2018 the likelihood function used for the mcmc sampling can combine all three sources of information i e the sapflow stem water potential and soil water storage without being affected by the magnitude of error that is contributed from any of the individual sources this likelihood function is applied as follows 15 l x y φ σ 2 1 2 j 1 3 t 2 n j e j t x φ e j t 1 x σ j t 2 where j distinguishes the various model outputs considered for the parameter estimation x is the parameter set y is the observed data φ is the temporal correlation of the residuals with 30 min between each time step and σ is the measurement error of the calibration data e j t x is the error of the model simulations for output j and a given parameter set x therefore we calculate a likelihood value from each considered output i e l x y φ σ 2 j and as equation 15 indicates we sum the three likelihood values to obtain one overall probability value for this study we examine various parameter estimation strategies first we fit the model simulations to individual data sources i e sapflux stem water potential and soil water storage and then fit the simulations to all three sources combined in the first case the model is calibrated to just the sapflux data and equation 15 is reduced to just one term the likelihood obtained from the fit to the sapflux data these results are assigned the sap acronym for the second and third cases the model is calibrated to the stem water potential and soil water storage data respectively and equation 15 is similarly reduced to one term these results are assigned the stem and stor acronyms respectively in the final case the model is calibrated to all three data sets and equation 15 utilizes all three likelihood terms these results are assigned the full acronym this final case highlights the ability of the likelihood function to combine various data streams by normalizing the prediction errors based on the observation error and combining the likelihood or probability from all three processes considered for the parameter estimation runs the measurement error values were defined as σ sap 1 cm day σ stem 100 kpa and σ stor 0 05 m3 2 6 numerical setup and cpu costs calculation of the stac model involves solution of the partial differential equations pde that are described in the previous sections the time difference between each model output is δt 30 min and the temporal discretization of the pde is based on an adaptive time step limited by 10 maximum iterations and with tolerances of 0 01 unitless and 10 kpa to solve the moisture levels when described by the moisture content θ or the head h respectively the spatial discretization is designed by a finite element mesh with thousands of nodes and the location of these nodes for our case study are depicted in figs 1 and 3 with each dot representing the center of a node this first involves dividing the domain of the problem into a collection of subdomains with each subdomain represented by a set of element equations to the original problem followed by systematically recombining all sets of element equations into a global system of equations for the final calculation the stac model simulation time is 30 seconds on average for the 17 day period in the sierra nevada test site for the mcmc runs we used a total of 8 chains and ran for 2500 generations therefore a simple calculation shows that the stac model parameters can be estimated in roughly 30 seconds multiplied by 8 chains multiplied by 2500 generations this amounts to 600 000 seconds to apply the parameter estimation which ultimately translates to a week of simulation time for convergence of the posterior distributions we noticed that the sap and full strategies converged well into the 2500 generations however for the stem strategy the posterior solution converged relatively quickly since there were only 7 measurements to fit against lastly and importantly for the stor strategy the posterior solution was never really identified even after 2500 generations 3 results for the remainder of the paper the results are color coded as follows the estimation to sapflux sap is shown in blue estimation to stem water potential stem is shown in light blue estimation to soil water storage stor is shown in green and estimation to all three data sets full is shown in black 3 1 parameter estimates the stac model simulates the spatial root distribution of the tree using equation 7 for the four estimation methods considered the estimated root distribution parameters are shown in table 1 the standard deviation of the posterior samples are shown in parenthesis in table 1 and are represented graphically in fig 2 the resulting root distributions shown in fig 3 allow a visual comparison of all the different estimation strategies both the tree and its roots may experience stress from water limitation as well as nutrient limitation or stress from extreme vapor pressure deficits as a result of hot temperatures among other factors the stac model numerically accounts for this through the stress terms γ in equations 5 and 11 these stress terms are characterized using the feddes function feddes et al 1978 and have values ranging from 0 full stress to 1 no stress four levels of head or pressure are used to express this function p1 p2 p3 and p4 for soil water potential values between p2 and p3 there is no stress while the stress occurs between p1 p2 aeration stress or saturated conditions and between p3 p4 water stress or drought conditions a few of these coefficients are parameterized and the calibrated values are shown in table 1 the standard deviation of the posterior samples are shown in parenthesis in table 1 and are represented graphically in fig 2 after all feddes parameters are defined the stress functions for each layer can be constructed these functions are shown in fig 4 and also allow a visual comparison of the various estimation strategies through equations 3 and 4 the stac model characterizes the retention and hydraulic conductivity of each soil layer and of the tree layer table 1 shows the values of the model parameters that are van genuchten parameters used to create hydraulic relationships of the tree and soil domains the standard deviation of the posterior samples are shown in parenthesis in table 1 and are represented graphically in fig 2 these parameters help represent the saturated conductivity and moisture contents of each layer and also contain certain shape parameters for the van genuchten functions the resulting hydraulic conductivity and retention functions for soil layers 1 and 2 as well as for the tree layer are shown in fig 5 in the first column of figures the retention function of each layer is shown one thing to note is that the retention function of the tree domain greatly differs from that of the soil layers the figure shows that it will require higher amounts of pressure to extract the water from the tree than from the soils 103 kpa for soils vs 105 kpa for tree which can be expected north and nobel 1997 black and pritchard 2002 3 2 comparing stac model simulations with observations in this study we focus on three processes represented in the stac model which are the sapflux through the tree domain the stem water potential in the canopy and the water storage of the soil domain all of these outputs are accompanied by observed data and the model simulation results are shown in fig 6 for each parameter estimation method for the sapflux simulations the sap and full strategies performed the best according to the rmse table 2 the other estimation strategies stem and stor do not fit the observations quite as well however they do allow the simulations to capture high peaks in the observed data for the stem water potential simulations the stem strategy provided the lowest rmse although estimation to the stem water potential data was not as informative since there were only 7 data points to fit these observations still allow us to constrain the simulations this is shown in table 2 since the rmse for the stem water potential simulations of the full strategy is lower than that of the sap and stor strategies which is not surprising since the full strategy considers the stem water potential data in its likelihood function for the soil water storage simulations the stor parameter set performed the best according to the rmse yet we see in fig 6 that all the simulations behave almost identically in all simulations the model underestimated the observed soil water storage indicating a model structural error that could be from more water being drawn from the soil domain in the simulations than is seen in the observed data or perhaps this could be due to the use of a likelihood function that only accounts for short term temporal correlation 4 discussion for this study we wanted to accurately simulate the dynamics of water flow in and around a mature white fir in the sierra nevada california using a process based ecohydrologic model the stac model g1 to achieve these simulations we inferred model parameters that dictated how much water can be stored or can flow in the tree and its surrounding soil domain g2 lastly we combined various data sources to accurately pinpoint the posterior distributions for the model parameters g3 by fitting the observed data and its underlying uncertainty we were able to mimic the dynamics seen for the white fir using the process based stac model our results indicate that some stac model parameters were not identifiable regardless of the data used for parameter estimation such as the root distribution parameters however some parameters were estimated well with posterior distributions that were well identified regardless of the data set used such as the parameter that describes the tree s saturated hydraulic conductivity k s tree overall as hypothesized the combination of all three data sets allows for the most precise estimation of the model parameters with the most localized posteriors and thus the least uncertainty about the corresponding parameter values in past parameter estimation studies it has been common to separate data sets to calibrate the model on the first set of data and then to evaluate that calibration on the second set however given the lack of data availability for this study such as only having 7 stem water potential measurements to use this type of evaluation is challenging thus in this study we focus on parameter estimation to the observed data but leave model validation for future studies 4 1 model limitations interestingly our results show that most of the parameters were not identifiable when just the soil water storage measurements were used as calibration data stor the only parameters that showed any sensitivity to calibration of this output were the θ s soil1 and the α tree parameters we can infer from the very wide posterior distributions for the stor estimates fig 2 this informs us that the soil water storage might very well be ill represented in the model additionally the α tree parameter seems to have a very narrow posterior for each of the calibration strategies also shown in fig 2 this indicates that the parameter used for this process is not properly represented either by having an incorrect prior range or possibly by having a bad model representation in general these types of clues allow us to further diagnose the model and can help pinpoint possible model improvements and developments 4 2 applicability of richards equation for xylem flow to simulate water flow through the coupled tree and soil domains the stac model is setup with the hydrus software which is simulated with the richards equation richards equation has been a common tool for simulating unsaturated water flow in nonswelling soils with numerous applications shown for simulating vegetative mediums in recent studies e g sperry et al 1998 bohrer et al katul or janott et al 2009 while the applicability of richards equation allows us to simulate water flow in the stem of a mature tree and its respective soil domain as a coupled system there are certain biological factors of a tree s water dynamics that are not captured directly with a richards equation type of model such as elasticity of the xylem which for simplicity is not represented in most current ecohydrologic models but see christoffersen et al 2016 future developments of the application of richards equation that consider elasticity of the xylem could drastically improve the model s capability to capture diurnal changes of water storage in plants mencuccini et al as a reference applications in the literature for models that account for stem elasticity in the water retention function include perämäki et al 2001 who developed a model that simulates tree stem diameter variations and transpiration using a dynamic sap flow model and hofstetter et al 2005 who developed and validated a continuum micromechanics model for the elasticity of wood 4 3 other parameter estimation methods in this study the parameter estimation algorithm sums the errors of the simulations into a single index and computes a likelihood based on this sum while most calibration studies are performed in this manner some drawbacks arise from employing this method for example since the soil storage output has a stronger memory effect within the modeling framework fig 6 it would be hypothetically difficult to separate the model structural errors in the process of the parameter estimation this is why the stor set of parameters produce the least realistic simulations in future work it would be beneficial to possibly use an alternative likelihood function or perhaps a parameter estimation method that completely does not require a likelihood function likelihood free calibration methods are new in the literature e g the approximate bayesian computation abc method which allows parameter estimation to a set of summary metrics instead of calibrating to a set of simulation residuals vrugt and sadegh 2013 sadegh and vrugt 2014 for instance our study fig 7 shows the observed relative hydraulic conductivity of a white fir abies concolor compared with ones produced from the calibrated parameter sets in this study the full parameter set creates a hydraulic relationship that is most realistic according to the observed relationship but there could be a parameter set that produces a closer hydraulic relationship to the observed data this parameter set can be inferred with the abc method and may prove to be more realistic although this goes beyond the scope of this study we encourage readers to try various parameter estimation algorithms that are available such as abc that use many different summary metrics to capture the hydraulic behaviors of the soil tree atmosphere system 5 conclusion major inconsistencies exist in the representation of vegetation in large scale land surface and climate models model parameters are typically inferred from empirical relationships or extracted from arbitrary data sets and efforts are now aimed at identifying parameter sets that appropriately describe these vegetation properties we presented simulations with the soil tree atmosphere continuum stac model showing the hydraulic processes of a mature white fir abies concolor and its surrounding root zone the model couples both soil and tree domains and simulates the movement of water based on different ecohydrologic processes we used bayesian inversion to estimate the model parameters against observations of sapflux stem water potential and soil water storage we evaluated the model s ability to fit the data with specific emphasis on the soil and tree water flow and storage properties the calibration of the model allowed us to estimate the spatial root distribution of the tree the feddes stress parameters to describe aeration or water stress and the van genuchten parameters that correspond to the retention and conductivity functions of soil and tree domains after calibration the stac model simulated processes such as sapflow stem water potential and soil water storage and the outputs were compared with the observed data for a full diagnosis of the model the results presented in this paper show that the choice of calibration data largely affects the parameter estimates and thus the model outputs by considering the full domain of the tree and combining all the observed data in the parameter estimation process the most realistic parameter combination was estimated and the closest fit between the model outputs and the observed data was achieved a likelihood function that considers various streams of data by normalizing simulation errors by the measurement errors was considered and implemented we conclude that the stac model offers a physical representation of water flow in and around a vegetative medium and can provide insight on how trees actually behave in their environments ecohydrologic models are evolving from having empirically based structures to more physically based ones setting the stage for tools such as the stac model to expand our knowledge on fundamental hydraulic processes that occur in vegetation software availability the stac model is not open source software but available upon request from the first author data accessibility the measured data used for this study is made available through the following digital figshare repository https doi org 10 6084 m9 gshare 5792676 v1 acknowledgements the authors appreciate support from the scgsr fellowship of the department of energy e m the uc lab fees research program award 237285 e m the lfr 18 542511 c x and the doe office of science next generation ecosystem experiment at tropics ngee t project c x the authors are also grateful to dr jasper a vrugt for providing the tools needed to conduct this study including the stac model source code the calibration data from the krew site as well as discussion that inspired ideas appendix a supplementary data the following is the supplementary data to this article data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 01 022 
26238,formit m is a widely applicable open access simple and flexible climate sensitive forest management simulator requiring only standard forest inventory data as input it combines a process based carbon balance approach with a strong inventory based empirical component the model has been linked to the global forest sector model efi gtm to secure consistency between timber cutting and demand although prescribed harvest scenarios can also be used here we introduce the structure of the model and demonstrate its use with example simulations until the end of the 21st century in europe comparing different management scenarios in different regions under climate change the model was consistent with country level statistics of growing stock volumes r2 0 938 and its projections of climate impact on growth agreed with other studies the management changes had a greater impact on growing stocks harvest potential and carbon balance than projected climate change at least in the absence of increased disturbance rates keywords scenario analysis timber harvests bioeconomy sustainability disturbances forest planning npp model formit bioenergy software availability name of software formit m main developer sanna härkönen contact person annikki mäkelä university of helsinki p o box 27 latokartanonkaari 7 00014 university of helsinki finland e mail annikki makela at helsinki fi year first available 2018 hardware required pc software required r https www r project org program language r program size 2 mb the formit m program code and input data will be made freely available through mendeley data at https doi org 10 17632 344n6ts3tg 1 1 introduction europe is aiming at a transition to a low carbon economy by 2050 in order to mitigate climate change by reducing carbon emissions from fuel consumption and industrial production chains european parliament and council 2013 replacing fossil based products by renewable sources for instance energy from coal and gas with bioenergy has been suggested as a key component of this strategy lundmark et al 2014 williamson 2016 for example in finland the governmental climate and energy strategy aims to increase the annual cutting level from the current about 66 million m3 yr 1 to 80 million m3 yr 1 by 2030 simultaneously increasing the usage of harvest residues for biofuel from 8 million m3 yr 1 to 14 18 million m3 yr 1 ministry of agriculture and forestry 2015 on the other hand increasing cuttings have raised concerns about biodiversity and carbon sequestration capacity of forests and it has been proposed that increasing the carbon storage in ecosystems would lead to more effective climate change mitigation than increasing the use of forest biomass holtsmark 2012 vanhala et al 2013 these alternatives are largely mutually exclusive at least within a confined region and depending on how storage and harvesting will be combined at the local regional and national scale forest management may need to be adjusted analysing the implications of such alternative strategies requires a forest model that is responsive to both management actions and climate change returning as output the time development of ecosystem carbon stocks and fluxes but also the main forest product assortments the impacts of climate change on forest ecosystems has usually been described with process based physiological models thornton et al 2002 jin et al 2016 whereas management impacts and economically relevant model outputs have mainly been produced with tree or stand based empirical models huber et al 2013 thurnher et al 2017 while the physiological models provide good plot scale predictions in the short term their larger scale application is often restricted by intensive input and parametrisation requirements and changes in stand composition not incorporated in the models pietsch et al 2005 jin et al 2016 the empirical models on the other hand often do not include an appropriate representation of climate change impacts so called hybrid ecosystem models propose to overcome these problems by merging empirical functions with simplified descriptions of physiological processes leading to physiologically driven empirically constrained forest ecosystem models seidl et al 2005 mäkelä et al 2016 a recent study showed that hybrid models outperformed complex physiological models when applied at regional spatial and decadal temporal scale suggesting that at this scale forest composition and structure may be more influential than physiological detail jin et al 2016 in large scale continental or global models key challenges involve accurate scaling of the model outputs and representation of the large spatial variability yet keeping the calculations feasible both as regards computation time and input requirements seidl et al 2013 perhaps the most common method of spatial up scaling is to do the calculations in grid cells of specified size homogenising inputs and outputs within each cell pixel this approach provides a wall to wall description of model outputs but may require a huge computational effort as the ideal grid cell size should be based on internally homogeneous pixels with regard to input and output variables some models consider potential forest structure as a response to long term climatic patterns leading to relatively large pixel size determined by mean climatic variability examples of this are landscape level succession models e g seidl et al 2012 huang et al 2017 and dynamic global vegetation models e g cramer et al 2001 friend et al 2014 naudts et al 2015 to model effects of forest management realistically it is important that the forward predictions are initialised on the basis of the measured state of forests model outputs must be informative about the distribution of product assortments because the spatial variability of species age and soil type is in general high large scale inventory and projection in forestry is usually not based on gridded wall to wall mapping but systematic sampling is used by most national forest inventories nfi the samples are used as representations of frequencies of measured variables in larger regions such as countries or provinces rather than spatially explicit maps most large scale modelling methods utilising nfi data are based on direct manipulation of country level distributions on the basis of empirical relationships schelhaas et al 2007 sirkiä 2012 mubareka et al 2014 schelhaas et al 2015 however the nfi network could also provide a good basis for driving stand level models wang et al 2014 initialising the simulations by nfi sample plot data the aggregated country scale results would be representative of the sampling network provided that the model is reliable here we report the development of a new hybrid model that utilises nfi data from 10 european countries in order to reflect the actual forest resources and forest growth and combines these with a process based meta model approach to climate impacts on net primary production npp and stemwood growth valentine and mäkelä 2005 härkönen et al 2010 the model was developed in the eu fp7 project forest management strategies to enhance the mitigation potential of european forests 2012 2016 formit this new forest growth model formit m produces estimates of carbon storage and fluxes at the forest site above and below ground as well as wood production available for harvests as roundwood accounting for forest product assortments and forest biomass under selected climate scenarios the simulation results can be used as inputs for life cycle analysis economic analysis and finally overall scenario analysis the objective of this paper is to 1 describe the model structure parametrisation and testing 2 demonstrate its applicability in three case studies in different parts of europe and 3 consider some initial overall results related to the impacts of management under climate change in europe the case studies focus on different relevant forest management questions including harvest intensities rotation lengths and species selection the analysis of results focuses on wood production and ecosystem carbon content 2 methods and materials 2 1 the model 2 1 1 overview of model structure the growth model is defined in terms of stand mean tree variables and stand density which together define stand level variables such as stem volume and component biomass the actual state variables of the model comprise mean height h m mean breast height diameter d cm stand density n and depending on the region mean height to the crown base h c m empirical functions are applied on these to derive auxiliary variables including mean tree volume v t r e e m3 and form factor f f o r m component biomasses w x kg litterfall l x kg yr 1 and leaf area index l fig 1 the rate variables driving the dynamics in the growth model are derived from estimated gross primary production gpp and its allocation to net primary production npp and further to stem growth gpp is calculated using a semi empirical light use efficiency lue based canopy level model mäkelä et al 2008 peltoniemi et al 2015 minunno et al 2016 which uses daily weather data and lai as inputs an empirical model was derived using this gpp and nfi based npp neumann et al 2016a 2016b for estimating the npp gpp ratio for different species and regions similarly an empirical function for the ratio of stem growth to npp was derived for species and european regions fig 1 table 1 stand level stemwood volume growth is obtained from the volume increment based on gpp and corresponding npp allocation this is divided by stand density to estimate mean tree growth and empirically derived allometric functions are used to compute new values of h d and h c from new volume and stand density the latter is updated on the basis of harvests and mortality where mortality is assumed to occur if stand density exceeds the maximum density modelled according to reineke s stand density index sdi reineke 1933 fig 1 the mean tree approach was chosen to simplify the regional calculations acknowledging that it may make the description of management systems with non uniform structures more challenging soil carbon dynamics are estimated using the yasso07 model tuomi et al 2009 2011 yasso07 takes tree litter fall and stand mean temperature and rainfall as input to estimate the development of soil carbon stocks the initial soil carbon is estimated assuming the system is at steady state with respect to current litter input fig 1 2 1 2 climate and site effects formit m calculates annual gpp using preles mäkelä et al 2008 peltoniemi et al 2015 a semi empirical model of daily gpp designed for boreal and temperate coniferous forests but also parameterised for a mediterranean pinus pinaster stand mäkelä et al 2008 the model uses the lue approach where the potential gpp is calculated as a function of photosynthetically active radiation par which is subsequently modified by multiplicative factors depending on temperature precipitation and vapour pressure deficit mathematically preles is a multiplicative model of 4 driver functions 1 p k p k k β f a p a r φ k f l φ k f s s k f d d k f w w k where p is annual canopy gpp g c m 2 yr 1 p k is canopy gpp on day k g c m 2 d 1 β is potential daily lue g c mol 1 f a p a r is proportion of absorbed par photosynthetically active radiation φ k is par mol m 2 d 1 f l φ k describes the saturation of gpp at high par s k is the state of acclimation to temperature d k is vapour pressure deficit and w k is the relative soil water availability another equation of preles calculates soil water balance and components of evapotransipiration using daily rainfall as an additional input variable the model has been previously parameterised using flux tower data for boreal and temperate coniferous sites mäkelä et al 2008 and results from a recent study suggest that the parameters are largely independent of site at least within a selected vegetation type minunno et al 2016 on the basis of previous studies preles can be regarded as comparatively reliable for predictions of gpp under stable atmospheric co2 recently co2 impacts have also been included in the model kalliokoski et al 2018 however in formit m we chose not to include an explicit co2 impact in our predictions under climate change although the direct co2 effect on potential gpp is comparable with the climate effect there is mounting evidence that this effect is down regulated due to other limiting factors comins and mcmurtrie 1993 hyvönen et al 2007 smith et al 2016 for example in many face free air carbon enrichment experiments no long term growth enhancement has been observed probably because of nutrient limitation norby and zak 2011 reich and hobbie 2013 however the postulated interaction between elevated co2 and stomatal conductance may be of significance at least at dry sites where it may counteract drought effects ainsworth and rogers 2007 kalliokoski et al 2018 as a result our projections for the future climate are conservative rather than over estimated and remain to be evaluated critically from this perspective formit m computes forest growth on the basis of gpp and its allocation first to respiration and npp then from npp to stem volume growth it is known from many studies that allocation of npp to stem growth decreases with reducing site quality while below ground allocation increases at the same time litton et al 2007 valentine and mäkelä 2012 in order to provide site dependent growth projections we therefore require information about site quality site quality classifications differ between countries and are often not independent of forest growth measurements in some countries site quality assessment is based on indicator species of ground vegetation and for example in finland this kind of site quality class is recorded at all nfi plots most commonly site quality assessment is based on site index which is derived assuming that dominant height growth is stable for a site type and thus determined as the height of dominant trees at a reference age skovsgaard and vanclay 2008 site quality information is generally not available in nfi data however in order to take the effects of site quality into account in carbon allocation we devised a semi empirical method of site quality assessment for those sites where site quality was not provided in the data it is based on the well established empirical observation that height growth within a confined geographical region reflects site quality however because our model potentially covers a wide geographical area we also account for the impact of potential photosynthetic productivity on potential height growth we defined a model for height growth as a function of site quality and photosynthetic productivity as follows 2 h a c s c a x p 0 z where h a is mean height m at age a yr c s c is a coefficient dependent on site quality s c p 0 is potential annual gpp determined using eqn 1 as gpp of a canopy absorbing all incoming par and without any water stress and x and z are empirical parameters we use this model to determine the mean height as a function of age and photosynthetic production then classify sites into three site quality classes representing the mean as well as lower or higher quality compared to the mean see section 2 1 3 the details of this model are provided in the supplementary information 2 1 3 model equations the fraction of photosynthetically active radiation f apar which is actually absorbed by the forest depends on the forest structure approaching f apar 1 with a fully closed canopy in formit m the f apar is estimated based on leaf area index and an effective extinction coefficient as 3 f a p a r 1 exp i k e f f i l i where l i denotes all sided leaf area index of species i and k e f f i is effective extinction coefficient l i is calculated based on stand foliage biomass w f s t a n d i kg and specific leaf area s l a i m2 kg 1 dw for the species as 4 l i w f s t a n d i s l a i 10 4 constant species specific values for k e f f i were used which were estimated for each species from tree level structural data following duursma and mäkelä 2007 5 k e f f φ s a l a 1 e k h l a φ s a where s a m2 is crown surface area l a m2 is leaf area and φ is an empirical parameter the actual stand level gpp p kg c ha 1 year 1 is calculated as 6 p p 0 f a p a r 10 where p 0 is potential canopy gpp calculated from eqn 1 with f a p a r 1 the ratio of net primary production npp to gpp r npp gpp is estimated as a function of mean stand height m mäkelä and valentine 2001 härkönen et al 2010 7 r n p p g p p f h the fraction of npp allocated to stem is estimated as function of stand age a and site quality class s c 8 f n p p s t e m f a s c stand level annual stem biomass growth kg dw ha 1 can be expressed as 9 g s t e m b i o m a s s 2 p r n p p g p p f n p p s t e m with 50 of dry weight biomass assumed to be carbon biomass components w x in kg dw of the mean tree foliage branches stem bark stump coarse roots 2 mm are calculated using species specific biomass functions for details see neumann et al 2016a 10 w x f d h h c where x denotes the tree compartment foliage branches stem bark coarse roots and stump regional biomass models may have different explanatory variables see chapter 2 2 fine root 2 mm biomass for mean tree kg dw is calculated as 11 w f i n e r o o t s r f r f o l w f o l i a g e where r f r f o l depends on the tree species and site quality class stand level biomasses kg dw ha 1 were obtained by multiplying the mean tree values by stand density per species see below stem volume for mean tree m 3 is calculated using species specific volume functions as 12 v t r e e 1 f h d stand level stem volume m 3 ha 1 in the beginning of the simulation year is calculated as 13 v s t a n d 1 n 1 v t r e e 1 stand density index is calculated based on mean diameter and number of stems per hectare using reineke 1933 rule as 14 s d i n 1 d 1 25 1 605 stand level stem volume after one year growth m 3 ha 1 is calculated as 15 v s t a n d 2 v s t a n d 1 g s t e m b i o m a s s ρ w o o d 1 and stem volume of the mean tree after one year growth m 3 ha 1 as 16 v t r e e 2 v s t a n d 2 n 1 where v s t a n d 1 and v s t a n d 2 are stand level stem volumes m3 ha 1 in the beginning and end of the simulation year respectively g s t e m b i o m a s s is annual npp allocated to stem growth eqn 9 and ρ w o o d is wood density kg m 3 v t r e e 2 is mean tree stem volume m3 in the end of the year and n 1 is the total number of trees per hectare in the beginning of the simulation year stand mean diameter after one year growth cm is calculated using a model based on structural relationships of v d and s d i fitted with nfi data formit project s tree level nfi data first measuring round 17 d 2 f v t r e e 2 s d i where d 2 is mean tree s diameter cm and s d i is stand density index eqn 14 stand mean height after one year growth m is calculated as 18 h 2 v t r e e 2 f f o r m π 0 5 d 2 100 2 where f f o r m is form factor calculated using mean height and mean diameter in the beginning of the simulation year as 19 f f o r m v t r e e 1 h 1 π 0 5 d 1 100 2 mean crown base height m is assumed to rise based on average spacing or stand sparsity of the trees in the stand using the equations by valentine et al 1994 and valentine and mäkelä 2005 as 20 h c 2 h c 1 m c b h 2 h 1 h 1 β c x h c 1 h c 1 h 1 β c x h c 1 where m cb is a parameter β c is the ratio of crown length to tree spacing after closure β c 2 0 valentine and mäkelä 2012 and x 100 n denotes the average spacing of trees m in case no thinnings occur in a simulation year the number of trees per hectare is estimated according to reineke 1933 rule as 21 n 2 min n 1 e a 1 605 ln d 1 where a is parameter natural damages e g caused by insects storms or fire may lower the growth rates of stands considerably natural damages were included by annually assigning a prescribed share of plots as damaged then selecting this share randomly from among all plots we used the share of severely damaged forests as reported by forest statistics for 2010 and subsequently applied the shares predicted by seidl et al 2014 on the damaged plots the annual potential gpp was lowered by 50 in the first damage year after which the full growth potential was regained linearly within 20 years if thinning takes place in the simulation year the number of trees in the end of the year is 22 n 2 n a f t e r t h i n n i n g where n a f t e r t h i n n i n g is the number of trees per hectare left in the stand after thinning thinnings can also be expressed through basal area as b a n π 0 5 d 100 2 soil carbon content is estimated using the yasso07 soil carbon model tuomi et al 2009 2011 yasso07 estimates decomposition of non woody fine root and foliage and woody litter branches stem coarse roots modelling litterfall using turnover rates and biomass provide litterfall estimates that largely agree with observations if regional species specific parameters are used neumann et at 2018 we used a similar approach and estimated annual litterfall kg dw ha 1 based on published biomass turnover rates as 23 l x f w x where l x denotes the litterfall of biomass compartment x eqn 10 the decomposition rates depend on mean annual temperature temperature amplitude between the annual minimum and maximum of mean monthly temperatures and annual precipitation annual change in soil carbon δc s g c m 2 yr 1 is estimated as 24 δ c s c s 2 c s 1 where c s 1 g c m 2 yr 1 is soil carbon at the beginning of the simulation year and c s 2 g c m 2 yr 1 is soil carbon at the beginning of the next simulation year net ecosystem exchange nee g c m 2 yr 1 denoted by e n e t can be expressed based on net primary production p n r n p p g p p p litterfall l t o t and annual soil carbon change δ c s as 25 e n e t p n l t o t δ c s negative nee indicates that the forest is a carbon sink and positive nee indicates that it is a carbon source initial steady states were obtained from yasso07 runs tuomi et al 2011 2 2 model formulation and parameter estimation the quantification of the model was based on regions and species groups due to insufficient data in the south eastern region we combined the southern countries to one mediterranean region the country groups were selected to provide an approximate representation of biomes and climates boreal northern temperate continental east central temperate maritime west continental and mediterranean nfi data was available for a subgroup of countries in the regions table 1 silvicultural management as well as growth and carbon storage properties are largely species specific as the number of species is large we reduced the number of cases to cover by grouping the species on the basis of their ecology table 2 the regional functions and parameters were based on data from the countries with nfi data using the nfi data and previously published results table 3 the models were parameterised for species groups relevant for each country group table 1 using the most common representative of the species group as a basis a more detailed description of the parameterisation is provided in supplementary information 2 3 description of forest management 2 3 1 silvicultural systems the description of forest management was based on seven silvicultural systems table 4 that were defined as management chains with values of control variables described with submodels for each combination of species silvicultural system and country group termed forest management unit fmu for definitions see supplementary information the following control variables were defined for each fmu planting density harvest frequency rotation length harvested yield fractions timber pulp waste retained trees and coarse woody debris forest management scenarios were defined on the basis of these silvicultural systems a business as usual bau scenario was defined as reference to represent the current management practices in the country groups while the scenarios by definition determined the timing and intensity of harvests for each fmu a fraction of these scenario based harvests was omitted if the overall harvest level determined by the roundwood demand was lower than the supply based on forest growth and the applied harvest rules see below the rules for thinning and final cut were generally based on the mean diameter and height of the standing stock with variation caused by site quality regeneration in the bau management was done with the same species as currently occurring the details of the rules were defined on the basis of expert opinion among the participants in the formit project and are provided in the supplementary information the impact of alternative forest management options on forest development and carbon stocks was analysed by defining alternative management scenarios where changes relative to the bau scenario were specified the alternative management scenarios considered here are defined separately for each case study see section 2 5 2 3 2 cutting levels the timber cuttings were decided in three different ways labelled respectively demand limited supply limited and constant harvests in the demand limited cuttings the level of total cuttings per country for the coming years was decided using the economic equilibrium market model efi gtm kallio and solberg 2018 moiseyev et al 2014 to secure consistency between roundwood harvests and demand for each year and country including considerations of import and export the boundary conditions in efi gtm depended on the management scenario but not on the rcp scenario the equilibrium was found by repeated iterations between formit m and the efi gtm in order to obtain a situation where for each country the harvests and forest growing stock in efi gtm equalled within satisfactorily limits the harvests and growing stock in formit m for the respective forest management scenario analysed in the initial iteration formit m gave the first estimate of the harvest supply by country and assortment based on the state of the stand and the management rules and efi gtm calculated the demand of different species by country corresponding to the pre specified global demand for forest industry products in the next iteration the formit m cuttings were modified to satisfy the former efi gtm harvest but not exceeding the cuttings possible by the specified harvest rules see tables 2 1 2 4 in supplementary information and the growing stock estimates from formit m were used in efi gtm s growing stock sub module such iterations were continued until the two models were in balance the actual harvest operations were applied to a new random set of plots each year such that the annual total harvest corresponded to the demand in the country the demand included a split between conifers and hardwood as well as a specification of assortments timber pulp biomass the plots to be managed were selected among the plots in silvicultural systems 2 7 that were mature for cutting according to the defined harvest rules the second simulated cutting method labelled supply limited was carried out by considering only the prescribed forest management so that all stands where harvested whenever the management rules allowed for it in other words it was assumed that the prescribed harvest quantities would be supplied independent of the timber prices in the third option constant harvest levels a prescribed harvest level was specified and followed throughout the simulation 2 4 simulation setup the simulation setup of formit m was based on nfi data points the model was initialised and simulated at all nfi points available initialisation was done by updating all the nfi plots from the year of measurement to the year 2010 by running formit m with rcp 4 5 climate data average for 2000 2010 period 2010 cutting levels and bau forest management note that historical climate is characterised with the same statistics in all rcps the results for all scenarios were aggregated to the fmu level on the basis of country silvicultural system and species group all output variables were presented in these aggregated units the individual nfi plot simulations were not used for the results as they cannot be regarded representative on their own the initial shares of each silvicultural system in each country were determined on the basis of a questionnaire sent to forestry professionals in each country as part of the formit project cardellini et al 2018 where ever possible the replies were derived from forestry statistics but as official statistics do not necessarily record the silvicultural systems and fmus used in this study the shares were partly based on expert opinion for initialising the simulation the country level information about the shares of silvicultural systems was disaggregated to each nfi point in the calculation using a prescribed random selection procedure except for the unmanaged plots which were selected based on their location natura 2000 map of protected areas in europe european environment agency 2011 however in many areas in europe forest management may occur in protected areas to support the aims of protection and unmanaged forests may occur outside of protected areas on one hand if the mapped protected area was smaller than unmanaged area reported in the statistics a random selection of the remaining nfi plots was excluded from all management on the other hand if less unmanaged area was reported than the share of mapped protected area the shares of the rest of the silvicultural systems were scaled up accordingly the nfi plots to represent the rest of the silvicultural systems were selected randomly from the remaining plots such that the total shares of each silvicultural system corresponded with those reported in the statistics yet the location of the plots does not necessarily correspond to the real locations the nfi plots were then simulated according to the management scenario specific definitions for each silvicultural system as noted above utilizable nfi data was only available for 11 european countries table 1 in order to obtain european wide estimates we extended the simulated results to those european countries where no nfi data was available to the project henceforth called non nfi countries by multiplying their fmu areas by the nearest nfi country s simulated average result in the corresponding fmu supplementary information the initial area of fmus in each non nfi country was obtained from a spatial analysis where the fmu areas were calculated based on the natura 2000 protected area map european environment agency 2011 species map and age class map produced using a k nn algorithm moreno et al 2017 the development of the age class distribution was calculated by transferring 1 20 of the age class area age classes are defined in 20 year periods to the next age class each year species and management class distributions were kept as they were initially further the share of clear cut plots in the simulations was used for determining which share of area is annually moved to the first age class in the non nfi countries as described above daily weather data was required for aggregating the annual level maximum potential gross primary production to be used as input for the model the weather data was generated by the mpi m mpi esm lr model version cclm4 8 17 which was run by the eu consortium clmcom clm community with contributions by btu dwd ethz ucd wegc and provided by the knot of the german climate calculating centre carbon dkrz de http www mpimet mpg de en science models mpi esm james special issue html we used three scenarios defined as rcp2 6 rcp4 5 and rcp8 5 representative concentration pathways the climate scenarios were run for 100 years from 2000 to 2100 for scenarios with current climate we repeated the scenario data from 2006 to 2010 the simulator is available at mendeley data formit m simulator https doi org 10 17632 344n6ts3tg 1 2 5 case studies in order to demonstrate the applicability of formit m we present three case studies where we analyse impacts of different management and climate scenarios in different regions in europe the case studies include 1 a comparison of the bau scenario with an intensive bioenergy management scenario with a range of total cutting levels demands in the nordic countries 2 a comparison of the bau scenario with a scenario to increase biodiversity with a range of total cutting levels in selected central european countries and 3 a comparison of climate scenarios using bau management in selected south european countries 2 5 1 increased harvests for bioenergy in the nordic countries in sweden finland and norway forests cover about 2 3 of the land area and forestry based bioeconomy has widely been regarded as a potential means of climate change mitigation lundmark et al 2014 suggested that if forest management was intensified in sweden a considerable additional biomass production could be obtained that could be used to substitute fossil fuels and energy intensive materials and thus increase the contribution of forestry to climate change mitigation however several other nordic country level studies have concluded that using forests for bioenergy is not an efficient management strategy for climate change mitigation repo et al 2011 holtsmark 2012 kallio et al 2013 here we consider the development of nordic forests using six different forest management scenarios where bau management is compared with intensified management for increased bioenergy production both bau and management for bioenergy are considered under three different cutting levels current cutting level 30 increase to the current level and supply limited cuttings the bioenergy scenario is defined thus 66 of the harvest residues are removed from the forest for bioenergy use spruce stumps are harvested from fertile site quality classes no thinning takes place clear cut is made in the year of the stand s maximum mean average increment mai of stem branches and coarse root biomass birch or norway spruce are planted on semi fertile and fertile site classes 2 3 after clear cut scots pine on dry sites class 1 2 5 2 increased biodiversity in central europe biodiversity and tree species selection has received a lot of attention in the recent discussions of forest management strategies in central europe e g kraus and krumm 2013 for example in germany only 30 of the forest area is covered by native species which is considered as a key indicator of biodiversity if spruce in lowlands is considered as a non native species one of the concerns is that the non native species may be more susceptible to climate change induced damages compared to natural vegetation netherer and schopf 2010 here we compare the development of forests in selected central european countries germany austria poland and the czech republic under bau management and alternatively under a management strategy aimed for increasing biodiversity and conservation a general outline of management strategies that countries have adopted to achieve these goals can be found in the criteria and indicators of sustainable forest management by forest europe 2011 the biodiversity and conservation bdc strategy differs from bau in the following aspects 20 of the plots are left unmanaged the plots located on protected areas randomly selected plots regeneration is done with species groups representing the potential natural vegetation of europe 20 of the harvested stems are left as dead wood final cut is postponed 25 longer rotation time harvest residues are left in the forest not used as bioenergy no difference to bau 2 5 3 impacts of climate change in southern europe mediterranean forests are expected to be the most severely affected by climate change in europe as the climate is projected to become significantly dryer especially during the summer months and drought is already a key limiting factor to growth in southern europe seppälä et al 2009 here we compare the effect of the different climate scenarios rcp2 6 rcp4 5 and rcp8 5 on the forest carbon budget in southern europe italy spain and portugal using the demand limited bau scenario the combined scenarios are termed bau26 bau45 and bau85 3 results 3 1 comparison with data on growing stock increment and harvests the growing stock corresponded quite well with the estimates presented by european forest statistics for 2010 forest europe 2011 r2 0 938 with an average overestimation of 15 in all countries and 11 in the countries for which we had data available the largest over estimations were found in spain and in romania fig 2 a the harvest levels coincided well with statistics with only about 1 overestimation both in the entire data set and in the nfi data fig 2b however volume increment was about 20 overestimated both in the entire data set and in the nfi data fig 2c compared with the respective statistics in forest europe 2011 3 2 bau in all europe the climate change impact in formit m operates through the maximum potential annual gpp showing an increasing trend in northern europe and a decreasing trend in southern europe except under rcp2 6 where no marked change was detected in southern europe fig 3 the average impact in bau i e under rcp 4 5 had an increasing trend with increasing latitude fig 4 1 in supplementary information in the bau scenarios with cuttings at the level predicted by the efi gtm model a common trend in europe was that growing stocks kept increasing because the demand of wood and forest biomass was predicted to be less than its supply table 5 this resulted in an increasing trend in both tree stand and soil carbon stocks fig 4 a at the same time the harvests increased modestly in pace with the increasing demand but gross increment was predicted to saturate towards the end of the century fig 4b the development of the growing stocks and harvests was rather insensitive to the climate change scenario under the demand driven management scenarios despite this common trend the simulated stocks and harvests behaved very differently in different countries partly due to the current age structure and differences in raw material demand as predicted by the economic model table 5 but also due to the different species and assortment structures in different countries 3 3 nordic case study the development of the growing stock volume varied among the scenarios fig 5 a in the constant demand scenarios the growing stock increased steadily during the simulation period the increase being highest in the scenarios with the lowest current cutting level in the supply limited scenarios there was a sudden decrease of growing stock at the beginning reflecting the fact that a large proportion of the growing stock was initially over mature relative to the pre specified cutting recommendations after the initial dip the standing growing stock started to increase again in both scenarios reaching the initial level around 2040 in the bau scenario but remaining lower in the bioenergy scenario stemwood increment increased in all scenarios from 2010 to 2100 the pattern of increase being very similar between all the demand limited scenarios with a slightly higher level in the bioenergy scenario compared with the respective bau scenario fig 5b in the supply limited bau scenarios there was also an increase of stem growth but this generally remained lower and showed strong fluctuations the supply limited bioenergy scenarios had the lowest average productivity but the average growth of the supply limited bioenergy scenario scenario 6 periodically exceeded that of the other scenarios around 2030 2060 the choice of forest management had a strong effect on the age distributions of stands fig 6 in the demand limited scenarios distribution averages moved towards older forests in the supply limited scenarios the majority of forests at the end of the simulation period consisted of productive young or middle aged forests 3 4 central european case study the most distinct effect of the bdc45 scenario in comparison with the bau45 scenario was that harvests were reduced by about a quarter from the beginning of the simulation and the difference between the scenarios increased with time fig 7 a the reduction of harvests caused the total increment to stabilize towards the end of the century whereas in the bau45 scenario the increment continued to increase as a consequence of the reduced harvests the age distribution shifted towards older stands in the bdc45 simulation compared with bau45 fig 4 2 in supplementary information the bdc management scenario favoured regeneration with species belonging to the potential natural vegetation cover and hence the proportion of species groups 1 pine and larch and 2 spruce decreased and that of 5 oak and 6 beech increased towards the end of the simulation fig 8 the tree stand carbon pool increased more rapidly in the bdc45 than in the bau45 scenario especially towards the end of the simulation fig 7b however the soil carbon pool slightly decreased in the bdc45 scenario fig 7b this was related 1 to a decrease in lying deadwood as a result of reduced frequency of harvests and therefore in harvest residues left to the sites not shown and 2 to the fact that deciduous litter was assumed to decompose faster than conifer litter the total ecosystem carbon pool remained larger in the bdc45 than the bau45 scenario throughout the simulation fig 7b 3 5 south european case study the harvests in the mediterranean countries were predicted to almost double over the century in the bau scenario with efi gtm demand fig 9 a whereas the increment was predicted to increase only modestly under the rcp2 6 climate and decrease with rcp4 5 and rcp8 5 because the increment nevertheless remained considerably above total harvests the ecosystem carbon stock was predicted to increase both in the tree stand and soil the accumulation of soil carbon was largest for rcp2 6 and smallest for rcp8 5 although there were hardly any differences in the tree stand carbon stock fig 9b 4 discussion here we presented the structure and example results of a new semi empirical hybrid climate sensitive forest growth simulator intended for predicting european forest development under different management and climate scenarios the functioning of the simulator was demonstrated in three different case studies northern central europe and southern europe with region specific management scenarios in addition to future socioeconomic development and political decisions considerable uncertainty is related to climate change projections due to differences between climate models and their regional down scaling as well as to uncertainties about the impact mechanisms lang et al 2017 kalliokoski et al 2018 here we used only one climate model mpi m mpi esm lr model version cclm4 8 17 the projections of which are fairly conservative compared with many others but which on the other hand has been regarded as particularly applicable to europe brands et al 2013 we also treated the climate impacts on forest growth with a very simple approach assuming that any direct co2 effects would be largely down regulated by water and nutrient limitation hyvönen et al 2007 norby and zak 2011 smith et al 2016 however despite our simple and straightforward approach our results are consistent with the general understanding of impacts on productivity in the different vegetation zones in europe seppälä et al 2009 ipcc 2014 the results are also in line with other forest model projections reyer et al 2014 gustafson et al 2017 in the north productivity is expected to increase with increasing temperature as no considerable drought limitation is expected to take place in contrast higher temperatures are expected to be accompanied with severe drought effects in the mediterranean countries leading to clear reductions in productivity european forestry statistics are available for comparison in the early simulation years formit m estimated the total growing stock in 2010 to be 34 0 109 m3 which was 24 larger than the values 27 4 109 m3 reported by forest europe 2011 the total carbon stock in europe in 2015 was estimated by formit m to be 12 9 gt c in the tree stand 21 5 gt c in soils 0 249 gt c in deadwood and 0 520 gt c in new litter here we should bear in mind that the model does not simulate carbon stocks in peatlands and will therefore underestimate the total c storage in soils the vegetation pool reported by forest europe 2015 was 12 5 gt c ha which was about half of the soil pool the other pools being considerably smaller the litter pool was about 10 fold compared with that reported here but here we only accounted for the most recent litter an increasing trend in all pools was also reported by the statistics as the simulations were started a few years earlier than 2010 the model result is a combination of initial state and simulation however the short simulations before 2010 were used only to produce a more consistent initial state and had little effect on the overall outcome of the model this suggests that the nfi measurements show some difference in comparison with the statistics reported to forest europe in accordance with other european schelhaas et al 2015 and country level e g lundmark et al 2014 kalliokoski et al 2018 studies formit m projected an increase in the total growing stock and ecosystem carbon content in the bau scenario this is caused by harvests remaining below forest growth increment in the bau demand scenario prescribed by efi gtm the increasing potential productivity in the northern part of europe had a minor additional impact on this trend in the iterative simulation keeping the cuttings at the level of the demand meant that forests were generally not harvested as intensively as could be acceptable according to forest management rules and therefore a lot of potentially harvestable wood is accumulating in the european forests according to good silvicultural practices e g smith et al 1997 this situation has been considered undesirable because postponing thinnings particularly in young stands reduces timber quality and increases the risk of damage due to wind and pests delaying final cuts increases the proportion of old stands that are considered less productive and susceptible to damage fig 6 fig 2c shows relatively high differences between modelled and actual forest increment in 2010 the over estimation of increments is bigger in countries where the stocks have also been over estimated notably finland france and spain fig 2a this could be related to discrepancies between forest areas used for scaling likely in finland and france or differences between the nfi data available to us and those used by forest europe likely in spain one possible cause for over estimation by the model could be the method used for deciding and allocating site quality classes our scenarios of supply limited cuttings in the nordic case study demonstrated the largely hypothetical situation that all cuttings are done according to the assumed good management practices without delay this gives surely an upper limit of harvests for a given set of management recommendations the level of cuttings obviously depends on the recommended intensity of thinnings and the recommended rotation lengths because the initial age structure of managed forests was already influenced by delayed cuttings in the past under the supply limited scenarios a large proportion of forest area was immediately cut in the simulations after that the cuttings stabilised to a somewhat higher level than the constant cutting scenario on average as virtually all of the stemwood increment was harvested however because the initial age structure of the forests was uneven large fluctuations occurred in the annual harvests the supply limited scenarios also resulted in very low and fluctuating growing stocks fig 5 with a low proportion of old stands fig 6 although the cuttings in the supply limited scenario are clearly exaggerated they demonstrate the fact that more cuttings lead to lower standing stocks in the forests and that the shorter the rotation length implied by the management scenario the lower the standing stocks a bioenergy scenario therefore generally leads to lower stocks than e g the biodiversity and conservation scenario because more carbon is taken out of the forest sites with harvests the soil carbon stocks are also reduced as a result achat et al 2015 a similar trend was seen in the central european case study with the bdc scenario although much less pronounced in that case the differences between the carbon stocks in the bau and bdc scenario were also influenced by the change in species from conifers towards broadleaves influencing the retention time of carbon originating in foliage litter in the soil tuomi et al 2011 the mediterranean case study demonstrated that volume increment would start to decline already around 2040 under the most severe climate change projection rcp8 5 and in general that climate change would have a detrimental effect on the growth potential in the mediterranean area fig 9 this is consistent with other studies morales et al 2007 marques et al 2018 however we should note that our result is likely an underestimation of the effects in the mediterranean as no additional risks such as increased probability of forest fire were considered here seidl et al 2014 2017 here we have demonstrated the use of the model with a number of european wide alternative management scenarios and climate scenarios produced by one general circulation model as also demonstrated in the case studies the actual management questions and management alternatives may be quite different in different regions the model provides a framework for defining country wise management scenarios where more realistic details can be included in the management alternatives than here our approach to disturbance was strongly simplified excluding any dynamic effects considerable uncertainty is related to disturbances and in general disturbance rates are expected to increase under climate change seidl et al 2014 2017 different disturbances act in different parts of europe drought events and fires being prevalent in southern europe wind disturbances followed by insect attacks in central europe and possibly an increase in storm events and insect damage occurring in the northern parts of the continent seidl et al 2014 accounting for these would likely reduce the projected growth and carbon sequestration rates because formit m is operating on stand level considering only the mean characteristics of dominant species the simulations in regions with high share of mixed forests are likely to be more uncertain than in regions where the majority of forest stands is dominated by one species also simulations for continuous cover forests were based on a strong simplification and in reality the development of continuous cover forests can be a much more complex process further model development should therefore focus on improving the description of forest structure which has been found to influence not only the size distribution and species relationships but also the impacts of climate change on production de cáceres et al 2015 bohn et al 2018 another important direction of model development is to make the entire growth process more clearly process based currently the model considers the effect of climate to be mediated by photosynthesis while species differences are accounted for in species specific allocation of photosynthetic carbon to respiration and organ growth inclusion of more direct growth impacts of climate could improve the results particularly in drought prone areas sánchez salguero et al 2017 a better description of nutrient impacts is particularly important for short rotation and bioenergy management which tends to drain the natural nutrient supplies schulze et al 2012 the challenge of model development for large scale applications is to retain its simplicity in relation to required inputs and parameters as well as its faithfulness to empirical observation of growth from nfi type data because of the development needs listed above the present simulation results are likely more realistic in the northern part of europe than in central and southern europe this is due to both simpler species composition and lower share of mixed stands in the north than further south and due to the fact that drought impacts are probably not properly described obviously the availability of actual nfi data is crucial for the reliability of the results and the projections for the countries that were simulated using forestry maps and neighboring countries as proxies could be made much more reliable if real nfi data were made available despite the shortcomings in the current formulation of formit m its general structure holds a strong potential for descriptions of the future development of european forests this is because it combines in a modular manner a productivity submodel making the system responsive to climate change and a forest structure and growth module based on large scale monitoring of actual forest resources a crucial component of the model development for creating this link was that we had empirical estimates of npp in different biomass components for a large number of nfi plots which could be connected to measured tree growth on one hand and to our process based estimates of growth on the other hand secondly the linkage of the model with the economic efi gtm simulator allowed us to incorporate realistic demand scenarios which influence the future growth and carbon balance dynamics our bau simulations with the demand limited harvest rates also suggest that we have been able to adequately describe the management in different countries this basic modular setup provides a framework for future model development and a quantification of the potential amount of harvestable wood the photosynthesis module and the soil carbon module can be independently replaced by some alternative models and the growth equations including site quality allocation can be improved as more test material becomes available also the integration between this model and economic modelling can be improved for example by applying dynamic forest sector modelling like shown in sjølie et al 2015 acknowledgements funding this work was supported by the european union seventh framework programme grant 311970 estonian ministry of education and research grant iut21 4 the polish research was supported by funds for science in the years 2013 2016 allocated to an international co financed project the check republic supported the research with institutional project extemit k no cz 02 1 01 0 0 0 0 15 003 0000433 the authors thank jari liski for making the yasso model code available for the study appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 02 009 
26238,formit m is a widely applicable open access simple and flexible climate sensitive forest management simulator requiring only standard forest inventory data as input it combines a process based carbon balance approach with a strong inventory based empirical component the model has been linked to the global forest sector model efi gtm to secure consistency between timber cutting and demand although prescribed harvest scenarios can also be used here we introduce the structure of the model and demonstrate its use with example simulations until the end of the 21st century in europe comparing different management scenarios in different regions under climate change the model was consistent with country level statistics of growing stock volumes r2 0 938 and its projections of climate impact on growth agreed with other studies the management changes had a greater impact on growing stocks harvest potential and carbon balance than projected climate change at least in the absence of increased disturbance rates keywords scenario analysis timber harvests bioeconomy sustainability disturbances forest planning npp model formit bioenergy software availability name of software formit m main developer sanna härkönen contact person annikki mäkelä university of helsinki p o box 27 latokartanonkaari 7 00014 university of helsinki finland e mail annikki makela at helsinki fi year first available 2018 hardware required pc software required r https www r project org program language r program size 2 mb the formit m program code and input data will be made freely available through mendeley data at https doi org 10 17632 344n6ts3tg 1 1 introduction europe is aiming at a transition to a low carbon economy by 2050 in order to mitigate climate change by reducing carbon emissions from fuel consumption and industrial production chains european parliament and council 2013 replacing fossil based products by renewable sources for instance energy from coal and gas with bioenergy has been suggested as a key component of this strategy lundmark et al 2014 williamson 2016 for example in finland the governmental climate and energy strategy aims to increase the annual cutting level from the current about 66 million m3 yr 1 to 80 million m3 yr 1 by 2030 simultaneously increasing the usage of harvest residues for biofuel from 8 million m3 yr 1 to 14 18 million m3 yr 1 ministry of agriculture and forestry 2015 on the other hand increasing cuttings have raised concerns about biodiversity and carbon sequestration capacity of forests and it has been proposed that increasing the carbon storage in ecosystems would lead to more effective climate change mitigation than increasing the use of forest biomass holtsmark 2012 vanhala et al 2013 these alternatives are largely mutually exclusive at least within a confined region and depending on how storage and harvesting will be combined at the local regional and national scale forest management may need to be adjusted analysing the implications of such alternative strategies requires a forest model that is responsive to both management actions and climate change returning as output the time development of ecosystem carbon stocks and fluxes but also the main forest product assortments the impacts of climate change on forest ecosystems has usually been described with process based physiological models thornton et al 2002 jin et al 2016 whereas management impacts and economically relevant model outputs have mainly been produced with tree or stand based empirical models huber et al 2013 thurnher et al 2017 while the physiological models provide good plot scale predictions in the short term their larger scale application is often restricted by intensive input and parametrisation requirements and changes in stand composition not incorporated in the models pietsch et al 2005 jin et al 2016 the empirical models on the other hand often do not include an appropriate representation of climate change impacts so called hybrid ecosystem models propose to overcome these problems by merging empirical functions with simplified descriptions of physiological processes leading to physiologically driven empirically constrained forest ecosystem models seidl et al 2005 mäkelä et al 2016 a recent study showed that hybrid models outperformed complex physiological models when applied at regional spatial and decadal temporal scale suggesting that at this scale forest composition and structure may be more influential than physiological detail jin et al 2016 in large scale continental or global models key challenges involve accurate scaling of the model outputs and representation of the large spatial variability yet keeping the calculations feasible both as regards computation time and input requirements seidl et al 2013 perhaps the most common method of spatial up scaling is to do the calculations in grid cells of specified size homogenising inputs and outputs within each cell pixel this approach provides a wall to wall description of model outputs but may require a huge computational effort as the ideal grid cell size should be based on internally homogeneous pixels with regard to input and output variables some models consider potential forest structure as a response to long term climatic patterns leading to relatively large pixel size determined by mean climatic variability examples of this are landscape level succession models e g seidl et al 2012 huang et al 2017 and dynamic global vegetation models e g cramer et al 2001 friend et al 2014 naudts et al 2015 to model effects of forest management realistically it is important that the forward predictions are initialised on the basis of the measured state of forests model outputs must be informative about the distribution of product assortments because the spatial variability of species age and soil type is in general high large scale inventory and projection in forestry is usually not based on gridded wall to wall mapping but systematic sampling is used by most national forest inventories nfi the samples are used as representations of frequencies of measured variables in larger regions such as countries or provinces rather than spatially explicit maps most large scale modelling methods utilising nfi data are based on direct manipulation of country level distributions on the basis of empirical relationships schelhaas et al 2007 sirkiä 2012 mubareka et al 2014 schelhaas et al 2015 however the nfi network could also provide a good basis for driving stand level models wang et al 2014 initialising the simulations by nfi sample plot data the aggregated country scale results would be representative of the sampling network provided that the model is reliable here we report the development of a new hybrid model that utilises nfi data from 10 european countries in order to reflect the actual forest resources and forest growth and combines these with a process based meta model approach to climate impacts on net primary production npp and stemwood growth valentine and mäkelä 2005 härkönen et al 2010 the model was developed in the eu fp7 project forest management strategies to enhance the mitigation potential of european forests 2012 2016 formit this new forest growth model formit m produces estimates of carbon storage and fluxes at the forest site above and below ground as well as wood production available for harvests as roundwood accounting for forest product assortments and forest biomass under selected climate scenarios the simulation results can be used as inputs for life cycle analysis economic analysis and finally overall scenario analysis the objective of this paper is to 1 describe the model structure parametrisation and testing 2 demonstrate its applicability in three case studies in different parts of europe and 3 consider some initial overall results related to the impacts of management under climate change in europe the case studies focus on different relevant forest management questions including harvest intensities rotation lengths and species selection the analysis of results focuses on wood production and ecosystem carbon content 2 methods and materials 2 1 the model 2 1 1 overview of model structure the growth model is defined in terms of stand mean tree variables and stand density which together define stand level variables such as stem volume and component biomass the actual state variables of the model comprise mean height h m mean breast height diameter d cm stand density n and depending on the region mean height to the crown base h c m empirical functions are applied on these to derive auxiliary variables including mean tree volume v t r e e m3 and form factor f f o r m component biomasses w x kg litterfall l x kg yr 1 and leaf area index l fig 1 the rate variables driving the dynamics in the growth model are derived from estimated gross primary production gpp and its allocation to net primary production npp and further to stem growth gpp is calculated using a semi empirical light use efficiency lue based canopy level model mäkelä et al 2008 peltoniemi et al 2015 minunno et al 2016 which uses daily weather data and lai as inputs an empirical model was derived using this gpp and nfi based npp neumann et al 2016a 2016b for estimating the npp gpp ratio for different species and regions similarly an empirical function for the ratio of stem growth to npp was derived for species and european regions fig 1 table 1 stand level stemwood volume growth is obtained from the volume increment based on gpp and corresponding npp allocation this is divided by stand density to estimate mean tree growth and empirically derived allometric functions are used to compute new values of h d and h c from new volume and stand density the latter is updated on the basis of harvests and mortality where mortality is assumed to occur if stand density exceeds the maximum density modelled according to reineke s stand density index sdi reineke 1933 fig 1 the mean tree approach was chosen to simplify the regional calculations acknowledging that it may make the description of management systems with non uniform structures more challenging soil carbon dynamics are estimated using the yasso07 model tuomi et al 2009 2011 yasso07 takes tree litter fall and stand mean temperature and rainfall as input to estimate the development of soil carbon stocks the initial soil carbon is estimated assuming the system is at steady state with respect to current litter input fig 1 2 1 2 climate and site effects formit m calculates annual gpp using preles mäkelä et al 2008 peltoniemi et al 2015 a semi empirical model of daily gpp designed for boreal and temperate coniferous forests but also parameterised for a mediterranean pinus pinaster stand mäkelä et al 2008 the model uses the lue approach where the potential gpp is calculated as a function of photosynthetically active radiation par which is subsequently modified by multiplicative factors depending on temperature precipitation and vapour pressure deficit mathematically preles is a multiplicative model of 4 driver functions 1 p k p k k β f a p a r φ k f l φ k f s s k f d d k f w w k where p is annual canopy gpp g c m 2 yr 1 p k is canopy gpp on day k g c m 2 d 1 β is potential daily lue g c mol 1 f a p a r is proportion of absorbed par photosynthetically active radiation φ k is par mol m 2 d 1 f l φ k describes the saturation of gpp at high par s k is the state of acclimation to temperature d k is vapour pressure deficit and w k is the relative soil water availability another equation of preles calculates soil water balance and components of evapotransipiration using daily rainfall as an additional input variable the model has been previously parameterised using flux tower data for boreal and temperate coniferous sites mäkelä et al 2008 and results from a recent study suggest that the parameters are largely independent of site at least within a selected vegetation type minunno et al 2016 on the basis of previous studies preles can be regarded as comparatively reliable for predictions of gpp under stable atmospheric co2 recently co2 impacts have also been included in the model kalliokoski et al 2018 however in formit m we chose not to include an explicit co2 impact in our predictions under climate change although the direct co2 effect on potential gpp is comparable with the climate effect there is mounting evidence that this effect is down regulated due to other limiting factors comins and mcmurtrie 1993 hyvönen et al 2007 smith et al 2016 for example in many face free air carbon enrichment experiments no long term growth enhancement has been observed probably because of nutrient limitation norby and zak 2011 reich and hobbie 2013 however the postulated interaction between elevated co2 and stomatal conductance may be of significance at least at dry sites where it may counteract drought effects ainsworth and rogers 2007 kalliokoski et al 2018 as a result our projections for the future climate are conservative rather than over estimated and remain to be evaluated critically from this perspective formit m computes forest growth on the basis of gpp and its allocation first to respiration and npp then from npp to stem volume growth it is known from many studies that allocation of npp to stem growth decreases with reducing site quality while below ground allocation increases at the same time litton et al 2007 valentine and mäkelä 2012 in order to provide site dependent growth projections we therefore require information about site quality site quality classifications differ between countries and are often not independent of forest growth measurements in some countries site quality assessment is based on indicator species of ground vegetation and for example in finland this kind of site quality class is recorded at all nfi plots most commonly site quality assessment is based on site index which is derived assuming that dominant height growth is stable for a site type and thus determined as the height of dominant trees at a reference age skovsgaard and vanclay 2008 site quality information is generally not available in nfi data however in order to take the effects of site quality into account in carbon allocation we devised a semi empirical method of site quality assessment for those sites where site quality was not provided in the data it is based on the well established empirical observation that height growth within a confined geographical region reflects site quality however because our model potentially covers a wide geographical area we also account for the impact of potential photosynthetic productivity on potential height growth we defined a model for height growth as a function of site quality and photosynthetic productivity as follows 2 h a c s c a x p 0 z where h a is mean height m at age a yr c s c is a coefficient dependent on site quality s c p 0 is potential annual gpp determined using eqn 1 as gpp of a canopy absorbing all incoming par and without any water stress and x and z are empirical parameters we use this model to determine the mean height as a function of age and photosynthetic production then classify sites into three site quality classes representing the mean as well as lower or higher quality compared to the mean see section 2 1 3 the details of this model are provided in the supplementary information 2 1 3 model equations the fraction of photosynthetically active radiation f apar which is actually absorbed by the forest depends on the forest structure approaching f apar 1 with a fully closed canopy in formit m the f apar is estimated based on leaf area index and an effective extinction coefficient as 3 f a p a r 1 exp i k e f f i l i where l i denotes all sided leaf area index of species i and k e f f i is effective extinction coefficient l i is calculated based on stand foliage biomass w f s t a n d i kg and specific leaf area s l a i m2 kg 1 dw for the species as 4 l i w f s t a n d i s l a i 10 4 constant species specific values for k e f f i were used which were estimated for each species from tree level structural data following duursma and mäkelä 2007 5 k e f f φ s a l a 1 e k h l a φ s a where s a m2 is crown surface area l a m2 is leaf area and φ is an empirical parameter the actual stand level gpp p kg c ha 1 year 1 is calculated as 6 p p 0 f a p a r 10 where p 0 is potential canopy gpp calculated from eqn 1 with f a p a r 1 the ratio of net primary production npp to gpp r npp gpp is estimated as a function of mean stand height m mäkelä and valentine 2001 härkönen et al 2010 7 r n p p g p p f h the fraction of npp allocated to stem is estimated as function of stand age a and site quality class s c 8 f n p p s t e m f a s c stand level annual stem biomass growth kg dw ha 1 can be expressed as 9 g s t e m b i o m a s s 2 p r n p p g p p f n p p s t e m with 50 of dry weight biomass assumed to be carbon biomass components w x in kg dw of the mean tree foliage branches stem bark stump coarse roots 2 mm are calculated using species specific biomass functions for details see neumann et al 2016a 10 w x f d h h c where x denotes the tree compartment foliage branches stem bark coarse roots and stump regional biomass models may have different explanatory variables see chapter 2 2 fine root 2 mm biomass for mean tree kg dw is calculated as 11 w f i n e r o o t s r f r f o l w f o l i a g e where r f r f o l depends on the tree species and site quality class stand level biomasses kg dw ha 1 were obtained by multiplying the mean tree values by stand density per species see below stem volume for mean tree m 3 is calculated using species specific volume functions as 12 v t r e e 1 f h d stand level stem volume m 3 ha 1 in the beginning of the simulation year is calculated as 13 v s t a n d 1 n 1 v t r e e 1 stand density index is calculated based on mean diameter and number of stems per hectare using reineke 1933 rule as 14 s d i n 1 d 1 25 1 605 stand level stem volume after one year growth m 3 ha 1 is calculated as 15 v s t a n d 2 v s t a n d 1 g s t e m b i o m a s s ρ w o o d 1 and stem volume of the mean tree after one year growth m 3 ha 1 as 16 v t r e e 2 v s t a n d 2 n 1 where v s t a n d 1 and v s t a n d 2 are stand level stem volumes m3 ha 1 in the beginning and end of the simulation year respectively g s t e m b i o m a s s is annual npp allocated to stem growth eqn 9 and ρ w o o d is wood density kg m 3 v t r e e 2 is mean tree stem volume m3 in the end of the year and n 1 is the total number of trees per hectare in the beginning of the simulation year stand mean diameter after one year growth cm is calculated using a model based on structural relationships of v d and s d i fitted with nfi data formit project s tree level nfi data first measuring round 17 d 2 f v t r e e 2 s d i where d 2 is mean tree s diameter cm and s d i is stand density index eqn 14 stand mean height after one year growth m is calculated as 18 h 2 v t r e e 2 f f o r m π 0 5 d 2 100 2 where f f o r m is form factor calculated using mean height and mean diameter in the beginning of the simulation year as 19 f f o r m v t r e e 1 h 1 π 0 5 d 1 100 2 mean crown base height m is assumed to rise based on average spacing or stand sparsity of the trees in the stand using the equations by valentine et al 1994 and valentine and mäkelä 2005 as 20 h c 2 h c 1 m c b h 2 h 1 h 1 β c x h c 1 h c 1 h 1 β c x h c 1 where m cb is a parameter β c is the ratio of crown length to tree spacing after closure β c 2 0 valentine and mäkelä 2012 and x 100 n denotes the average spacing of trees m in case no thinnings occur in a simulation year the number of trees per hectare is estimated according to reineke 1933 rule as 21 n 2 min n 1 e a 1 605 ln d 1 where a is parameter natural damages e g caused by insects storms or fire may lower the growth rates of stands considerably natural damages were included by annually assigning a prescribed share of plots as damaged then selecting this share randomly from among all plots we used the share of severely damaged forests as reported by forest statistics for 2010 and subsequently applied the shares predicted by seidl et al 2014 on the damaged plots the annual potential gpp was lowered by 50 in the first damage year after which the full growth potential was regained linearly within 20 years if thinning takes place in the simulation year the number of trees in the end of the year is 22 n 2 n a f t e r t h i n n i n g where n a f t e r t h i n n i n g is the number of trees per hectare left in the stand after thinning thinnings can also be expressed through basal area as b a n π 0 5 d 100 2 soil carbon content is estimated using the yasso07 soil carbon model tuomi et al 2009 2011 yasso07 estimates decomposition of non woody fine root and foliage and woody litter branches stem coarse roots modelling litterfall using turnover rates and biomass provide litterfall estimates that largely agree with observations if regional species specific parameters are used neumann et at 2018 we used a similar approach and estimated annual litterfall kg dw ha 1 based on published biomass turnover rates as 23 l x f w x where l x denotes the litterfall of biomass compartment x eqn 10 the decomposition rates depend on mean annual temperature temperature amplitude between the annual minimum and maximum of mean monthly temperatures and annual precipitation annual change in soil carbon δc s g c m 2 yr 1 is estimated as 24 δ c s c s 2 c s 1 where c s 1 g c m 2 yr 1 is soil carbon at the beginning of the simulation year and c s 2 g c m 2 yr 1 is soil carbon at the beginning of the next simulation year net ecosystem exchange nee g c m 2 yr 1 denoted by e n e t can be expressed based on net primary production p n r n p p g p p p litterfall l t o t and annual soil carbon change δ c s as 25 e n e t p n l t o t δ c s negative nee indicates that the forest is a carbon sink and positive nee indicates that it is a carbon source initial steady states were obtained from yasso07 runs tuomi et al 2011 2 2 model formulation and parameter estimation the quantification of the model was based on regions and species groups due to insufficient data in the south eastern region we combined the southern countries to one mediterranean region the country groups were selected to provide an approximate representation of biomes and climates boreal northern temperate continental east central temperate maritime west continental and mediterranean nfi data was available for a subgroup of countries in the regions table 1 silvicultural management as well as growth and carbon storage properties are largely species specific as the number of species is large we reduced the number of cases to cover by grouping the species on the basis of their ecology table 2 the regional functions and parameters were based on data from the countries with nfi data using the nfi data and previously published results table 3 the models were parameterised for species groups relevant for each country group table 1 using the most common representative of the species group as a basis a more detailed description of the parameterisation is provided in supplementary information 2 3 description of forest management 2 3 1 silvicultural systems the description of forest management was based on seven silvicultural systems table 4 that were defined as management chains with values of control variables described with submodels for each combination of species silvicultural system and country group termed forest management unit fmu for definitions see supplementary information the following control variables were defined for each fmu planting density harvest frequency rotation length harvested yield fractions timber pulp waste retained trees and coarse woody debris forest management scenarios were defined on the basis of these silvicultural systems a business as usual bau scenario was defined as reference to represent the current management practices in the country groups while the scenarios by definition determined the timing and intensity of harvests for each fmu a fraction of these scenario based harvests was omitted if the overall harvest level determined by the roundwood demand was lower than the supply based on forest growth and the applied harvest rules see below the rules for thinning and final cut were generally based on the mean diameter and height of the standing stock with variation caused by site quality regeneration in the bau management was done with the same species as currently occurring the details of the rules were defined on the basis of expert opinion among the participants in the formit project and are provided in the supplementary information the impact of alternative forest management options on forest development and carbon stocks was analysed by defining alternative management scenarios where changes relative to the bau scenario were specified the alternative management scenarios considered here are defined separately for each case study see section 2 5 2 3 2 cutting levels the timber cuttings were decided in three different ways labelled respectively demand limited supply limited and constant harvests in the demand limited cuttings the level of total cuttings per country for the coming years was decided using the economic equilibrium market model efi gtm kallio and solberg 2018 moiseyev et al 2014 to secure consistency between roundwood harvests and demand for each year and country including considerations of import and export the boundary conditions in efi gtm depended on the management scenario but not on the rcp scenario the equilibrium was found by repeated iterations between formit m and the efi gtm in order to obtain a situation where for each country the harvests and forest growing stock in efi gtm equalled within satisfactorily limits the harvests and growing stock in formit m for the respective forest management scenario analysed in the initial iteration formit m gave the first estimate of the harvest supply by country and assortment based on the state of the stand and the management rules and efi gtm calculated the demand of different species by country corresponding to the pre specified global demand for forest industry products in the next iteration the formit m cuttings were modified to satisfy the former efi gtm harvest but not exceeding the cuttings possible by the specified harvest rules see tables 2 1 2 4 in supplementary information and the growing stock estimates from formit m were used in efi gtm s growing stock sub module such iterations were continued until the two models were in balance the actual harvest operations were applied to a new random set of plots each year such that the annual total harvest corresponded to the demand in the country the demand included a split between conifers and hardwood as well as a specification of assortments timber pulp biomass the plots to be managed were selected among the plots in silvicultural systems 2 7 that were mature for cutting according to the defined harvest rules the second simulated cutting method labelled supply limited was carried out by considering only the prescribed forest management so that all stands where harvested whenever the management rules allowed for it in other words it was assumed that the prescribed harvest quantities would be supplied independent of the timber prices in the third option constant harvest levels a prescribed harvest level was specified and followed throughout the simulation 2 4 simulation setup the simulation setup of formit m was based on nfi data points the model was initialised and simulated at all nfi points available initialisation was done by updating all the nfi plots from the year of measurement to the year 2010 by running formit m with rcp 4 5 climate data average for 2000 2010 period 2010 cutting levels and bau forest management note that historical climate is characterised with the same statistics in all rcps the results for all scenarios were aggregated to the fmu level on the basis of country silvicultural system and species group all output variables were presented in these aggregated units the individual nfi plot simulations were not used for the results as they cannot be regarded representative on their own the initial shares of each silvicultural system in each country were determined on the basis of a questionnaire sent to forestry professionals in each country as part of the formit project cardellini et al 2018 where ever possible the replies were derived from forestry statistics but as official statistics do not necessarily record the silvicultural systems and fmus used in this study the shares were partly based on expert opinion for initialising the simulation the country level information about the shares of silvicultural systems was disaggregated to each nfi point in the calculation using a prescribed random selection procedure except for the unmanaged plots which were selected based on their location natura 2000 map of protected areas in europe european environment agency 2011 however in many areas in europe forest management may occur in protected areas to support the aims of protection and unmanaged forests may occur outside of protected areas on one hand if the mapped protected area was smaller than unmanaged area reported in the statistics a random selection of the remaining nfi plots was excluded from all management on the other hand if less unmanaged area was reported than the share of mapped protected area the shares of the rest of the silvicultural systems were scaled up accordingly the nfi plots to represent the rest of the silvicultural systems were selected randomly from the remaining plots such that the total shares of each silvicultural system corresponded with those reported in the statistics yet the location of the plots does not necessarily correspond to the real locations the nfi plots were then simulated according to the management scenario specific definitions for each silvicultural system as noted above utilizable nfi data was only available for 11 european countries table 1 in order to obtain european wide estimates we extended the simulated results to those european countries where no nfi data was available to the project henceforth called non nfi countries by multiplying their fmu areas by the nearest nfi country s simulated average result in the corresponding fmu supplementary information the initial area of fmus in each non nfi country was obtained from a spatial analysis where the fmu areas were calculated based on the natura 2000 protected area map european environment agency 2011 species map and age class map produced using a k nn algorithm moreno et al 2017 the development of the age class distribution was calculated by transferring 1 20 of the age class area age classes are defined in 20 year periods to the next age class each year species and management class distributions were kept as they were initially further the share of clear cut plots in the simulations was used for determining which share of area is annually moved to the first age class in the non nfi countries as described above daily weather data was required for aggregating the annual level maximum potential gross primary production to be used as input for the model the weather data was generated by the mpi m mpi esm lr model version cclm4 8 17 which was run by the eu consortium clmcom clm community with contributions by btu dwd ethz ucd wegc and provided by the knot of the german climate calculating centre carbon dkrz de http www mpimet mpg de en science models mpi esm james special issue html we used three scenarios defined as rcp2 6 rcp4 5 and rcp8 5 representative concentration pathways the climate scenarios were run for 100 years from 2000 to 2100 for scenarios with current climate we repeated the scenario data from 2006 to 2010 the simulator is available at mendeley data formit m simulator https doi org 10 17632 344n6ts3tg 1 2 5 case studies in order to demonstrate the applicability of formit m we present three case studies where we analyse impacts of different management and climate scenarios in different regions in europe the case studies include 1 a comparison of the bau scenario with an intensive bioenergy management scenario with a range of total cutting levels demands in the nordic countries 2 a comparison of the bau scenario with a scenario to increase biodiversity with a range of total cutting levels in selected central european countries and 3 a comparison of climate scenarios using bau management in selected south european countries 2 5 1 increased harvests for bioenergy in the nordic countries in sweden finland and norway forests cover about 2 3 of the land area and forestry based bioeconomy has widely been regarded as a potential means of climate change mitigation lundmark et al 2014 suggested that if forest management was intensified in sweden a considerable additional biomass production could be obtained that could be used to substitute fossil fuels and energy intensive materials and thus increase the contribution of forestry to climate change mitigation however several other nordic country level studies have concluded that using forests for bioenergy is not an efficient management strategy for climate change mitigation repo et al 2011 holtsmark 2012 kallio et al 2013 here we consider the development of nordic forests using six different forest management scenarios where bau management is compared with intensified management for increased bioenergy production both bau and management for bioenergy are considered under three different cutting levels current cutting level 30 increase to the current level and supply limited cuttings the bioenergy scenario is defined thus 66 of the harvest residues are removed from the forest for bioenergy use spruce stumps are harvested from fertile site quality classes no thinning takes place clear cut is made in the year of the stand s maximum mean average increment mai of stem branches and coarse root biomass birch or norway spruce are planted on semi fertile and fertile site classes 2 3 after clear cut scots pine on dry sites class 1 2 5 2 increased biodiversity in central europe biodiversity and tree species selection has received a lot of attention in the recent discussions of forest management strategies in central europe e g kraus and krumm 2013 for example in germany only 30 of the forest area is covered by native species which is considered as a key indicator of biodiversity if spruce in lowlands is considered as a non native species one of the concerns is that the non native species may be more susceptible to climate change induced damages compared to natural vegetation netherer and schopf 2010 here we compare the development of forests in selected central european countries germany austria poland and the czech republic under bau management and alternatively under a management strategy aimed for increasing biodiversity and conservation a general outline of management strategies that countries have adopted to achieve these goals can be found in the criteria and indicators of sustainable forest management by forest europe 2011 the biodiversity and conservation bdc strategy differs from bau in the following aspects 20 of the plots are left unmanaged the plots located on protected areas randomly selected plots regeneration is done with species groups representing the potential natural vegetation of europe 20 of the harvested stems are left as dead wood final cut is postponed 25 longer rotation time harvest residues are left in the forest not used as bioenergy no difference to bau 2 5 3 impacts of climate change in southern europe mediterranean forests are expected to be the most severely affected by climate change in europe as the climate is projected to become significantly dryer especially during the summer months and drought is already a key limiting factor to growth in southern europe seppälä et al 2009 here we compare the effect of the different climate scenarios rcp2 6 rcp4 5 and rcp8 5 on the forest carbon budget in southern europe italy spain and portugal using the demand limited bau scenario the combined scenarios are termed bau26 bau45 and bau85 3 results 3 1 comparison with data on growing stock increment and harvests the growing stock corresponded quite well with the estimates presented by european forest statistics for 2010 forest europe 2011 r2 0 938 with an average overestimation of 15 in all countries and 11 in the countries for which we had data available the largest over estimations were found in spain and in romania fig 2 a the harvest levels coincided well with statistics with only about 1 overestimation both in the entire data set and in the nfi data fig 2b however volume increment was about 20 overestimated both in the entire data set and in the nfi data fig 2c compared with the respective statistics in forest europe 2011 3 2 bau in all europe the climate change impact in formit m operates through the maximum potential annual gpp showing an increasing trend in northern europe and a decreasing trend in southern europe except under rcp2 6 where no marked change was detected in southern europe fig 3 the average impact in bau i e under rcp 4 5 had an increasing trend with increasing latitude fig 4 1 in supplementary information in the bau scenarios with cuttings at the level predicted by the efi gtm model a common trend in europe was that growing stocks kept increasing because the demand of wood and forest biomass was predicted to be less than its supply table 5 this resulted in an increasing trend in both tree stand and soil carbon stocks fig 4 a at the same time the harvests increased modestly in pace with the increasing demand but gross increment was predicted to saturate towards the end of the century fig 4b the development of the growing stocks and harvests was rather insensitive to the climate change scenario under the demand driven management scenarios despite this common trend the simulated stocks and harvests behaved very differently in different countries partly due to the current age structure and differences in raw material demand as predicted by the economic model table 5 but also due to the different species and assortment structures in different countries 3 3 nordic case study the development of the growing stock volume varied among the scenarios fig 5 a in the constant demand scenarios the growing stock increased steadily during the simulation period the increase being highest in the scenarios with the lowest current cutting level in the supply limited scenarios there was a sudden decrease of growing stock at the beginning reflecting the fact that a large proportion of the growing stock was initially over mature relative to the pre specified cutting recommendations after the initial dip the standing growing stock started to increase again in both scenarios reaching the initial level around 2040 in the bau scenario but remaining lower in the bioenergy scenario stemwood increment increased in all scenarios from 2010 to 2100 the pattern of increase being very similar between all the demand limited scenarios with a slightly higher level in the bioenergy scenario compared with the respective bau scenario fig 5b in the supply limited bau scenarios there was also an increase of stem growth but this generally remained lower and showed strong fluctuations the supply limited bioenergy scenarios had the lowest average productivity but the average growth of the supply limited bioenergy scenario scenario 6 periodically exceeded that of the other scenarios around 2030 2060 the choice of forest management had a strong effect on the age distributions of stands fig 6 in the demand limited scenarios distribution averages moved towards older forests in the supply limited scenarios the majority of forests at the end of the simulation period consisted of productive young or middle aged forests 3 4 central european case study the most distinct effect of the bdc45 scenario in comparison with the bau45 scenario was that harvests were reduced by about a quarter from the beginning of the simulation and the difference between the scenarios increased with time fig 7 a the reduction of harvests caused the total increment to stabilize towards the end of the century whereas in the bau45 scenario the increment continued to increase as a consequence of the reduced harvests the age distribution shifted towards older stands in the bdc45 simulation compared with bau45 fig 4 2 in supplementary information the bdc management scenario favoured regeneration with species belonging to the potential natural vegetation cover and hence the proportion of species groups 1 pine and larch and 2 spruce decreased and that of 5 oak and 6 beech increased towards the end of the simulation fig 8 the tree stand carbon pool increased more rapidly in the bdc45 than in the bau45 scenario especially towards the end of the simulation fig 7b however the soil carbon pool slightly decreased in the bdc45 scenario fig 7b this was related 1 to a decrease in lying deadwood as a result of reduced frequency of harvests and therefore in harvest residues left to the sites not shown and 2 to the fact that deciduous litter was assumed to decompose faster than conifer litter the total ecosystem carbon pool remained larger in the bdc45 than the bau45 scenario throughout the simulation fig 7b 3 5 south european case study the harvests in the mediterranean countries were predicted to almost double over the century in the bau scenario with efi gtm demand fig 9 a whereas the increment was predicted to increase only modestly under the rcp2 6 climate and decrease with rcp4 5 and rcp8 5 because the increment nevertheless remained considerably above total harvests the ecosystem carbon stock was predicted to increase both in the tree stand and soil the accumulation of soil carbon was largest for rcp2 6 and smallest for rcp8 5 although there were hardly any differences in the tree stand carbon stock fig 9b 4 discussion here we presented the structure and example results of a new semi empirical hybrid climate sensitive forest growth simulator intended for predicting european forest development under different management and climate scenarios the functioning of the simulator was demonstrated in three different case studies northern central europe and southern europe with region specific management scenarios in addition to future socioeconomic development and political decisions considerable uncertainty is related to climate change projections due to differences between climate models and their regional down scaling as well as to uncertainties about the impact mechanisms lang et al 2017 kalliokoski et al 2018 here we used only one climate model mpi m mpi esm lr model version cclm4 8 17 the projections of which are fairly conservative compared with many others but which on the other hand has been regarded as particularly applicable to europe brands et al 2013 we also treated the climate impacts on forest growth with a very simple approach assuming that any direct co2 effects would be largely down regulated by water and nutrient limitation hyvönen et al 2007 norby and zak 2011 smith et al 2016 however despite our simple and straightforward approach our results are consistent with the general understanding of impacts on productivity in the different vegetation zones in europe seppälä et al 2009 ipcc 2014 the results are also in line with other forest model projections reyer et al 2014 gustafson et al 2017 in the north productivity is expected to increase with increasing temperature as no considerable drought limitation is expected to take place in contrast higher temperatures are expected to be accompanied with severe drought effects in the mediterranean countries leading to clear reductions in productivity european forestry statistics are available for comparison in the early simulation years formit m estimated the total growing stock in 2010 to be 34 0 109 m3 which was 24 larger than the values 27 4 109 m3 reported by forest europe 2011 the total carbon stock in europe in 2015 was estimated by formit m to be 12 9 gt c in the tree stand 21 5 gt c in soils 0 249 gt c in deadwood and 0 520 gt c in new litter here we should bear in mind that the model does not simulate carbon stocks in peatlands and will therefore underestimate the total c storage in soils the vegetation pool reported by forest europe 2015 was 12 5 gt c ha which was about half of the soil pool the other pools being considerably smaller the litter pool was about 10 fold compared with that reported here but here we only accounted for the most recent litter an increasing trend in all pools was also reported by the statistics as the simulations were started a few years earlier than 2010 the model result is a combination of initial state and simulation however the short simulations before 2010 were used only to produce a more consistent initial state and had little effect on the overall outcome of the model this suggests that the nfi measurements show some difference in comparison with the statistics reported to forest europe in accordance with other european schelhaas et al 2015 and country level e g lundmark et al 2014 kalliokoski et al 2018 studies formit m projected an increase in the total growing stock and ecosystem carbon content in the bau scenario this is caused by harvests remaining below forest growth increment in the bau demand scenario prescribed by efi gtm the increasing potential productivity in the northern part of europe had a minor additional impact on this trend in the iterative simulation keeping the cuttings at the level of the demand meant that forests were generally not harvested as intensively as could be acceptable according to forest management rules and therefore a lot of potentially harvestable wood is accumulating in the european forests according to good silvicultural practices e g smith et al 1997 this situation has been considered undesirable because postponing thinnings particularly in young stands reduces timber quality and increases the risk of damage due to wind and pests delaying final cuts increases the proportion of old stands that are considered less productive and susceptible to damage fig 6 fig 2c shows relatively high differences between modelled and actual forest increment in 2010 the over estimation of increments is bigger in countries where the stocks have also been over estimated notably finland france and spain fig 2a this could be related to discrepancies between forest areas used for scaling likely in finland and france or differences between the nfi data available to us and those used by forest europe likely in spain one possible cause for over estimation by the model could be the method used for deciding and allocating site quality classes our scenarios of supply limited cuttings in the nordic case study demonstrated the largely hypothetical situation that all cuttings are done according to the assumed good management practices without delay this gives surely an upper limit of harvests for a given set of management recommendations the level of cuttings obviously depends on the recommended intensity of thinnings and the recommended rotation lengths because the initial age structure of managed forests was already influenced by delayed cuttings in the past under the supply limited scenarios a large proportion of forest area was immediately cut in the simulations after that the cuttings stabilised to a somewhat higher level than the constant cutting scenario on average as virtually all of the stemwood increment was harvested however because the initial age structure of the forests was uneven large fluctuations occurred in the annual harvests the supply limited scenarios also resulted in very low and fluctuating growing stocks fig 5 with a low proportion of old stands fig 6 although the cuttings in the supply limited scenario are clearly exaggerated they demonstrate the fact that more cuttings lead to lower standing stocks in the forests and that the shorter the rotation length implied by the management scenario the lower the standing stocks a bioenergy scenario therefore generally leads to lower stocks than e g the biodiversity and conservation scenario because more carbon is taken out of the forest sites with harvests the soil carbon stocks are also reduced as a result achat et al 2015 a similar trend was seen in the central european case study with the bdc scenario although much less pronounced in that case the differences between the carbon stocks in the bau and bdc scenario were also influenced by the change in species from conifers towards broadleaves influencing the retention time of carbon originating in foliage litter in the soil tuomi et al 2011 the mediterranean case study demonstrated that volume increment would start to decline already around 2040 under the most severe climate change projection rcp8 5 and in general that climate change would have a detrimental effect on the growth potential in the mediterranean area fig 9 this is consistent with other studies morales et al 2007 marques et al 2018 however we should note that our result is likely an underestimation of the effects in the mediterranean as no additional risks such as increased probability of forest fire were considered here seidl et al 2014 2017 here we have demonstrated the use of the model with a number of european wide alternative management scenarios and climate scenarios produced by one general circulation model as also demonstrated in the case studies the actual management questions and management alternatives may be quite different in different regions the model provides a framework for defining country wise management scenarios where more realistic details can be included in the management alternatives than here our approach to disturbance was strongly simplified excluding any dynamic effects considerable uncertainty is related to disturbances and in general disturbance rates are expected to increase under climate change seidl et al 2014 2017 different disturbances act in different parts of europe drought events and fires being prevalent in southern europe wind disturbances followed by insect attacks in central europe and possibly an increase in storm events and insect damage occurring in the northern parts of the continent seidl et al 2014 accounting for these would likely reduce the projected growth and carbon sequestration rates because formit m is operating on stand level considering only the mean characteristics of dominant species the simulations in regions with high share of mixed forests are likely to be more uncertain than in regions where the majority of forest stands is dominated by one species also simulations for continuous cover forests were based on a strong simplification and in reality the development of continuous cover forests can be a much more complex process further model development should therefore focus on improving the description of forest structure which has been found to influence not only the size distribution and species relationships but also the impacts of climate change on production de cáceres et al 2015 bohn et al 2018 another important direction of model development is to make the entire growth process more clearly process based currently the model considers the effect of climate to be mediated by photosynthesis while species differences are accounted for in species specific allocation of photosynthetic carbon to respiration and organ growth inclusion of more direct growth impacts of climate could improve the results particularly in drought prone areas sánchez salguero et al 2017 a better description of nutrient impacts is particularly important for short rotation and bioenergy management which tends to drain the natural nutrient supplies schulze et al 2012 the challenge of model development for large scale applications is to retain its simplicity in relation to required inputs and parameters as well as its faithfulness to empirical observation of growth from nfi type data because of the development needs listed above the present simulation results are likely more realistic in the northern part of europe than in central and southern europe this is due to both simpler species composition and lower share of mixed stands in the north than further south and due to the fact that drought impacts are probably not properly described obviously the availability of actual nfi data is crucial for the reliability of the results and the projections for the countries that were simulated using forestry maps and neighboring countries as proxies could be made much more reliable if real nfi data were made available despite the shortcomings in the current formulation of formit m its general structure holds a strong potential for descriptions of the future development of european forests this is because it combines in a modular manner a productivity submodel making the system responsive to climate change and a forest structure and growth module based on large scale monitoring of actual forest resources a crucial component of the model development for creating this link was that we had empirical estimates of npp in different biomass components for a large number of nfi plots which could be connected to measured tree growth on one hand and to our process based estimates of growth on the other hand secondly the linkage of the model with the economic efi gtm simulator allowed us to incorporate realistic demand scenarios which influence the future growth and carbon balance dynamics our bau simulations with the demand limited harvest rates also suggest that we have been able to adequately describe the management in different countries this basic modular setup provides a framework for future model development and a quantification of the potential amount of harvestable wood the photosynthesis module and the soil carbon module can be independently replaced by some alternative models and the growth equations including site quality allocation can be improved as more test material becomes available also the integration between this model and economic modelling can be improved for example by applying dynamic forest sector modelling like shown in sjølie et al 2015 acknowledgements funding this work was supported by the european union seventh framework programme grant 311970 estonian ministry of education and research grant iut21 4 the polish research was supported by funds for science in the years 2013 2016 allocated to an international co financed project the check republic supported the research with institutional project extemit k no cz 02 1 01 0 0 0 0 15 003 0000433 the authors thank jari liski for making the yasso model code available for the study appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2019 02 009 
26239,regional crop production forecasting is growing in importance in both the public and private sectors to ensure food security optimize agricultural management practices and use of resources and anticipate market fluctuations thus a model and data driven easy to use forecasting and a risk assessment system can be an essential tool for end users at different levels this paper provides an overview of the approaches algorithms design and capabilities of the ccafs regional agricultural forecasting toolbox craft for gridded crop modeling and yield forecasting along with risk analysis and climate impact studies craft is a flexible and adaptable software platform designed with a user friendly interface to produce multiple simulation scenarios maps and interactive visualizations using a crop engine that can run the pre installed crop models dssat apsim and sarra h in concert with the climate predictability tool cpt for seasonal climate forecasts its integrated and modular design allows for easy adaptation of the system to different regional and scientific domains craft requires gridded input data to run the crop simulations on spatial scales of 5 and 30 arc minutes case studies for south asia for two crops including wheat and rice shows its potential application for risk assessment and in season yield forecasting keywords ensemble simulations decision support crop model yield forecast food security 1 introduction the ability to predict agricultural production losses associated with extreme natural events through monitoring and forecasting creates an opportunity for governments international aid organizations ngos and donors to provide targeted assistance for replacing lost food income and maintaining some level of food security timely assistance stabilizes consumption allowing households and communities to move towards economic security and sustainability however any delay in identifying and initiating a response to emerging food crises will greatly increase the long term impacts on livelihoods and the cost of aid cabot venton et al 2012 clarke and hill 2013 haile 2005 when a crisis requires external food aid it can take up to several months before aid reaches affected populations as a result populations in crisis may already have suffered adverse health effects divested productive resources or migrated in food insecure regions such as in africa or southeast asia early warning systems based on remote sensing of vegetation and monitoring of local commodity markets can provide an early indication of likely food shortfalls hallegatte 2012 verdin and klaver 2002 thus food aid organizations in developing countries are increasingly interested in seasonal agricultural forecasts to provide lead time in response to extreme weather events that affect current agricultural production operational crop forecasting and early warning systems for food security exist in many regions to help support market and policy decisions cantelaube and terres 2005 motha 2011 verdin and klaver 2002 vossen and rijks 1995 often they are based on monitoring weather and crop conditions during the growing season and incorporate regionally calibrated crop models to estimate yield uncertainty crop models are computerized representations of crop growth and development and predict yield through mathematical equations as functions of soil properties weather conditions and management practices hoogenboom 2000 there has been significant progress in the application of crop models to define strategies for more efficient crop production improved risk management sustainable cropping systems and to study the impact of climate change on agricultural systems holzworth et al 2015 crop model integrated decision support tools as a computer based technology to support complex decision making have long been used to assess climate risk in agriculture risk refers to a likelihood that can be assessed using prior information but when the likelihood cannot be estimated then uncertainty applies both risk and uncertainty are contributing factors in the choice of appropriate management practices for decision makers han et al 2017 selvaraju 2013 in addition to risk analysis and assessment crop models have also been used for yield forecasting bannayan et al 2003 yun 2003 crop yield forecasts can be conducted prior to planting or during the actual growing season and the results produced by the models can be used to make appropriate management decisions and to provide farmers and others with alternative options for their farming system hoogenboom 2000 skillful seasonal forecasts provide additional information that can increase the accuracy of within season production forecasts based on monitoring and simulation alone particularly early during the growing season cantelaube and terres 2005 hansen et al 2004 stephens et al 2000 one of the main approaches for spatial crop simulations müller et al 2017 is based on field scale crop models and various degree of gis integration hartkamp et al 1999 current well known spatial crop modeling systems include aegis mars bioma gepic psims mink simplace and geosim for geostatistical and spatial analysis of crop modeling the agricultural and environmental geographic information system aegis aegis win was created linking the decision support system for agrotechnology transfer dssat v3 with the geographic mapping tools arcinfo and arcview using an object oriented macro programming language lal et al 1993 engel et al 1997 in the 1990s the european crop growth monitoring system eu cgms and yield forecasting system was developed by the mars project coordinated by the joint research centre jrc vossen and rijks 1995 supit 1997 to simulate the impacts of climate change on agriculture and to evaluate adaptation strategies the jrc uses the biophysical models applications bioma framework donatelli et al 2012 a gis based epic model gepic is another spatial tool that integrates a bio physical epic environmental policy integrated climate model with a gis to simulate the spatial and temporal dynamics of the major processes of the soil crop atmosphere management system liu et al 2007 within the impetus research project of the global change and hydrological cycle glowa program of the german government the smile scientific model integration pipeline engine framework enders et al 2010 and its improved version called simplace http www simplace net were developed to facilitate climate impact modeling elliott et al 2014 developed the parallel system for integrating impacts models and sectors psims that is designed to support integration of site based applications and allow researchers to use high performance computing to run simulations over large spatial extents at the international food policy research institute ifpri a global scale crop modeling system using a gridded approach known as mink robertson 2017 was created to provide gridded simulated crop data for the international model for policy analysis of agricultural commodities and trade impact robinson et al 2015 thorp and bronson 2013 developed the geospatial simulation geosim tool as a plug in for quantum gis to manage point based model simulations at multiple locations these spatial crop modeling systems have been designed for specific applications and accordingly have certain requirements and limitations that could restrict the implementation in developing countries some of these tools are now obsolete aegis others are very robust use scripting languages and must be run on clusters or on high performance computers psims mink while some have associated implementation and maintenance issues mars that might be costly or they lack functionality such as yield forecast geosim in order to increase the capacity of developing regions for within season forecasting of the impacts of climate fluctuations on crop production the cgiar research program on climate change agriculture and food security program ccafs convened a workshop on seasonal weather forecasts linked pre harvest estimates of crop production methodological approaches negombo sri lanka 16 18 april 2012 following a participatory approach voinov et al 2016 the intention was to bring together various stakeholders scientists with expertise in problem domains crop modeling yield forecast and monitoring systems climate and other actors to jointly assess and identify key challenges of existing yield forecasting tools for research and operational use in the ccafs focus regions the identified challenges were to recognize the need for convenient and easy to use software platform to facilitate crop yield forecasting for researchers and operational institutions and to develop such a platform that could be accessible cost free and adaptable to support multiple crop models as a result ccafs initiated the development of the ccafs regional agricultural forecasting toolbox craft to support within season forecasting of crop production and secondarily risk analysis and climate change impacts studies the main research questions to be explored and then implement in the software included management of spatial data and crop simulations integration of seasonal forecasts hindcast spatial aggregation probabilistic analysis post simulation calibration risk analysis climate change impact and visualization the objectives of this paper are to a provide the basic concepts of gridded simulations and algorithms used for yield forecasting in craft b describe the toolbox architecture and its main components c present the current version and its main functionality and d demonstrate risk assessment and yield forecasting case studies 2 algorithms for crop production forecasts in craft 2 1 gridded crop simulation and empirical calibration process oriented crop models predict crop growth development and yield for a variety of environmental conditions and management options at a point or field scale in order to run point based models at a regional scale first the region is divided into grid cells that are considered as points and then a crop model is run for each individual grid cell of the region finally the results of the point based simulations are aggregated to a region to determine spatial crop production a similar approach has been implemented in craft the reference grids in craft are world grids wgs84 projection with two different spatial resolutions of 5 and 30 arc minutes fig 1 a each grid cell of the reference grid can be assigned a unique id identification number starting from one at the top left corner and moving from west to east 180 to 180 long and from north to south 90 to 90 lat the process of generating a cell id for each cell of the grid using the shape file of the region is considered the schematization process and schema generation is one of craft s functionalities it should be noted that the boundary of the shape could be arbitrary and not necessarily coincide with an administrative boundary as an example fig 1c is a grid that comprises 112 cells within administrative boundaries in a 5 arc minutes resolution grid cell ids were defined during schema generation and exported in text format fig 1b the corresponding cell ids are used for preparation of the input files for creating relations between the tables of the underlying database and for processing storing and retrieving data from the database yield often shows an increasing trend over time which can be attributed to technological improvements such as new varieties or enhanced crop management therefore prior to calibrating simulated yield time series of the observed yield data optionally should be detrended in craft two different methods for detrending the observed yield time series namely linear and quadratic detrending algorithms have been implemented various studies lu et al 2017 have used these methods for detrending crop yield time series data both regression models can be fitted over time using the least squares method after simulating the trend with the appropriate statistical model a decomposition model is applied to remove the simulated trend after the observed yield with optional detrending procedure is overlaid on the region the calibration process is applied to the simulated yield in craft most of the crop model calibration methods are applicable to deterministic simulations and crop model parameters are adjusted in order that simulated phenology yield and yield components values better match their corresponding observed values such a detailed calibration is generally not performed in gridded applications due to a lack of available reference data instead cultivar parameters of models are typically calibrated at a set of points and then the key parameters are extrapolated with relatively simple algorithms elliott and müller 2015 alternatively a yield correction factor can be applied to the regional yield aggregated from the simulated yield on a field scale in order to minimize the root mean square error rmse with observed regional yield challinor et al 2005 hansen and jones 2000 using the latter approach the calibration process in craft is based on long term regional observed yield data after cultivar parameters of models are optionally calibrated for a set of cells as part of this empirical calibration process yield is simulated for all years for which observed yield is available and then by fitting a linear regression between the observed and the simulated yield a value for the calibration modification factor is determined 2 2 integration of seasonal climate forecasts with cpt craft uses a statistical approach to integrate the seasonal climate forecast with the crop yield forecast this method was evaluated in a proof of concept study in queensland australia for operational wheat production forecasting hansen et al 2004 the same method was later employed to improve sorghum yield forecasts mishra et al 2008 to prepare a forecast for a certain date during the growing season for the current year yield is simulated first with observed antecedent weather data for the current year up to the forecast date and then complemented with weather data from available historic years until final harvest the resulting time series of simulated yield are treated as the predictand and used with a time series of appropriate seasonal climate predictor fields e g fields of sea surface temperatures ssts to fit a multivariate statistical model the expected yield value for the current season is forecast from current seasonal climate predictor observations and the fitted statistical model the yield forecast distribution is obtained from cross validated hindcast residuals centered on the expected value of the forecast because the proportion of total uncertainty due to climate decreases during the growing season the potential improvement in accuracy from incorporating seasonal forecasts is expected to be greatest early during the growing season hansen et al 2004 2006 a flowchart for the process of yield forecasting is provided in fig 2 craft uses the climate predictability tool cpt developed by the international research institute for climate and society iri mason and tippett 2016 which is widely used by national meteorological services and researchers throughout the world as a statistical forecast package cpt was designed for producing seasonal climate forecasts using gridded outputs from gcms and ssts as predictors it uses principal components pcs or empirical orthogonal functions eofs to interact efficiently with gridded data as predictors thereby reducing problems associated with multiplicity and collinearity finally the tool performs rigorous cross validation to avoid artificial skill the statistical modeling component of craft is implemented by running cpt in batch mode canonical correlation analysis cca or principal components regression pcr settings are used for yield forecasting it is recommended that the appropriateness and skill of a seasonal forecast system first be established before seasonal predictors are used 2 3 probability distribution of the forecast and transformation of non normal data methods that have been developed for deriving and evaluating probabilistic climate forecasts are generally relevant to forecasts of agricultural impacts including forecast distributions from hindcast residuals historical analogs and forecast distributions from dynamic climate model ensembles hansen and indeje 2004 hansen et al 2006 in craft the first approach was implemented i e estimating a forecast probability distribution as the distribution of hindcast residuals centered on the expected value of the current forecast hansen et al 2006 the following are the steps for deriving a probabilistic forecast from hindcast residuals a time series of hindcast residuals ε i is calculated as follows 1 ε i y i y ˆ i where y i is yield time series simulated with current year of weather data through forecast date and complemented with the ith year weather data through harvest from available historic weather data for n years y ˆ i are hindcasts calibrated to observations for example by pcr or cca and i is an index for the year in the time series ε i is then sorted to derive a residual distribution and cumulative density function cdf of residuals the forecast distribution for a given forecast year is obtained by adding its expected value y ˆ to each ε i the method accounts for the overall prediction error of the forecast system and is generally applicable to statistical or dynamic forecast models artificial forecast skill and systematic underestimation of the dispersion of probabilistic forecasts are inherent risks in statistical forecasting as the error of statistical forecast models tends to be smaller for the period used to calibrate the model than for predictions outside the calibration data hansen et al 2006 to reduce the risk of artificial skill the forecast distribution in a given year is derived from cross validated regression residuals methods for deriving probabilistic forecasts differ in their ability to handle changes in predictability from year to year one source of apparent variation in predictability between years is the skewness of the underlying distributions for strongly skewed variables the magnitude of forecast residuals and therefore the spread of forecast distribution tends to increase in the direction of skewness several studies have shown that after applying a normalizing power series transformation box and cox 1964 to reduce the positive skewness of the rainfall series the mean separation remains but variances were constant kruskal and wallis 1952 levene 1960 in craft a normalizing transformation to the predictand time series is used so that hindcast residuals can account for the effects of skewness on forecast dispersion a forecast distribution in transformed space is derived and then applied as an inverse transformation to convert the forecast distributions into the original yield units hansen et al 2004 2 4 spatial aggregation from yield to production the simulated output of crop models can be scaled up at aggregate levels to account for the heterogeneity of environment and management of spatial data sets hansen and jones 2000 in craft the level of aggregation ranges from point to a grid cell and from grid cell to a region because the toolbox simulates on a grid cell base two aggregation steps are applied the first step simulates multiple treatments within a grid cell and then after calculating yield and other outputs weighted by the share of the area under different soils for a given cell it aggregates yield to obtain an average value at a grid cell level in the second step average yield and cell area account for crop production on a grid cell level and then production by grid cells is aggregated to polygons thus resulting in regional level production uncertainties in yield forecasting at a regional level are represented in terms of probability distributions on the aggregated level the aggregation of the forecast probability distribution is derived from cross validated regression residuals based on the simulated y i j and the hindcast y ˆ i j yields for ith year and jth grid cell aggregated to a polygon level by taking their weighted linear combination according to the following equations 2 y i j 1 m w j y i j 3 y ˆ i j 1 m w j y ˆ i j where y i and y ˆ i are aggregated to the area simulated and hindcast yields w j s j s is the share of the cell area s j over the area of the region s and m is the total number of cells in the area of aggregation the weights w j are non negative and their total is one then a time series of hindcast residuals ε i is calculated similar to eq 1 but applied to the aggregated values of the simulated and hindcast yields 4 ε i y i y ˆ i i 1 2 n where n is a number of years finally a time series of hindcast residuals ε i is sorted to derive a cdf of residuals the forecast distribution for a given forecast year is then obtained by adding its expected value y to each hindcast residual ε i thus the aggregated probability distribution summarizes the accumulated information on yield by grid cells over the area 3 software architecture 3 1 overview the craft application is based on the microsoft net windows platform and includes a user friendly client application developed in c that provides the interface with crop models and a mysql database implementation the database contains all input and output data for the crop models including crop management soil weather and climate data as well as crop model related information the toolbox is integrated with two external engines namely a crop model engine for linking and executing the crop models and the cpt engine for running cpt as a statistical package the application architecture follows object oriented programming oop paradigms uses software design patterns gamma et al 1995 and is designed as a multi tiered system to allow for modularity and scalability the overall system uses a model view view model mvvm design pattern and windows presentation foundation wpf concepts since the view is part of the graphical user interface gui of the application the modules and components that are part of craft are shown in fig 3 the integrated design and structure of the toolbox allows for easy adaptation of the system to other spatial domains and crop models the three main tiers of the system are presentation business and data the presentation tier contains the components that implement and display the user interface and it manages interaction with net base windows forms it also acquires and validates data input the business tier implements the logic for the system functionality and treats data as objects not considering how the data are stored or displayed it manages a client s requests on information as well the business tier is designed to address scalability of the application and it contains three entities interface factory class and implementation class the interface separates the implementation and defines the structure the factory class contains the methods that encapsulate the creation of objects the implementation class inherits the interface and stores the logic to implement the interface method in the data tier the data access layer is designed to abstract the logic necessary to access the database using a separate data layer makes the application easier to configure and maintain and it hides the details of the database from other layers of the application data transfer objects dtos are used when interacting with other layers and to pass the data between layers 3 2 input data and storage gridded simulations by craft can be conducted for any region for up to three scale levels which for example could be a country a state province and a district if the administrative area is the region of interest the toolbox is built with a schema generation feature which allows for the generation of schema files through user specified shape files that correspond to up to three spatial scales for the region after completing the schema generating process a schema folder will contain the respective schema files by the administrative or other specified boundaries fig 4 the schema files then can be uploaded in the database using the data upload module craft works on a gridded region with each grid cell representing an area along with its attributes therefore gridded input data are required the input data include information necessary to run the crop models such as daily weather soil properties initial conditions cultivar or varieties and crop management downloadable templates are available to facilitate data preparation in the specific formats required by the toolbox arcgis shape files are used for data associated with aerial mappings including soil and crop coverage and crop management fig 5 the data loader module is designed to manage uploading and downloading various datasets it enforces rules to ensure the completeness of the data and adherence of the data to the defined data structures the mysql database is used as a central database to store all input and output data of the simulations fig 3 the central database contains the configuration data location specific information such as the coordinates and properties of each grid cell the dynamic time series data etc the dynamic series data can either be imported from external sources or produced through internal data manipulation methods and crop model simulations 3 3 linkage between craft and external modules the crop simulation models and cpt have been kept independent from craft as external modules hence the data should be passed from the database to the external modules and from the external modules back to the database the toolbox has two engines for linking to them one is the crop engine for spatial crop simulations and the other is the cpt engine for seasonal climate forecasting functionalities of the engines are to translate the internal database into a format that can be recognized by the external modules and to transfer the output data from the external modules into craft s specific format the engines also handle any errors that might occur during the operation of the external modules because craft works on a grid model and inputs are set at the time of model run creation the grid cells are processed one by one and the data for each individual grid cell are provided to the crop engine as objects the crop engine uses these objects to execute the crop model and returns the crop model run results to the application for further processing and storage in the database fig 6 the crop engine uses the dssat cropping system model csm as a crop model jones et al 2003 hoogenboom et al 2017 the data formats of crop models vary widely and in order to extend the operational capabilities of the toolbox to additional crop models the agmip data translator tool porter et al 2014 that comprises various formats and utilities has been implemented using this tool craft currently includes apsim agricultural production systems simulator holzworth et al 2014 and sarra h baron et al 2003 as two additional crop simulation models 3 4 output module report generation and mapping integration the output module is designed to optimize retrieval and visualization of the result datasets the final report generation is available in two types of forms the first report option is a series of tables that can be exported in csv file format and the second report option is a map mapwingis a geographic information system programming activex control and application programming interface api ames et al 2007 is used to provide craft with the mapping functionality using the gis shape files maps along with the grid cells can be displayed and the various output variables from the crop model simulations can be depicted in thematic maps 4 use of craft 4 1 graphical user interface the craft application provides net base windows forms for various inputs and outputs a summary of the main features of its gui is described in table 1 the home window fig 7 provides a summary of the most recently used projects a link to create a new project basic information for the last selected project and the run that has been executed the project name link allows navigation to the current state of the workflow the toolbox can be configured via configuration with the desired database and schema generation functionality that allows generation of schema files compatible with an application through user specified shape files 4 2 input module data loader and configuration the data loader gui is a tabular interface for the data import export option e g fig 8 it enables uploading various data sets that are required by the modeling engines into the central mysql database after checks that reject incomplete or erroneous data during the upload process the input module provides support for spatial input data through the use of 5 and 30 arc minutes resolution grids input data should adhere to the data structure of the grid and be consistent with the cell resolution the datasets that can be uploaded are weather data for climate change crop mask soil mask irrigation mask etc in text txt format file fig 3 the data loader also provides an export delete option to download data files and schema from the database or to delete uploaded data based on selection criteria the management options that can be selected or entered as levels through the interface are the following detailed information related to field initial conditions crop variety planting dates irrigation fertilizer inorganic and organic and environment fig 3 these inputs need to be applied to the project run and the highest resolution for the application is the district level or level 3 all grid cells that fall within a district inherit the data applied for that particular district the configuration module also provides additional functionalities for dataset input in the central database such as uploading varieties cultivars for different crops and crop models and uploading new or updating existing soil profiles 4 3 projects a project is defined by its spatial domain based on the selected boundary level the spatial resolution the project type crop and the crop model there are four types of projects that can be created and executed calibration yield forecast risk characterization and climate change the calibration type project allows for the calculation of the modification factor and the equation for transforming simulated yield to the regional level yield based on observed regional yield the yield forecast type project runs the crop model uses the calibration modifier to determine the calibrated yield and executes cpt resulting in the in season yield forecast the risk characterization type project runs the crop model for various environmental and management scenarios and estimates the associated risk the climate change type project assesses future climate risk for crop production and determines high climate risk areas for crop yield in this case the weather datasets should be associated with baseline and various future weather projections by general circulation models gcms for four emissions scenarios representative concentration pathways rcps adopted by the ipcc for its 5th assessment and reflect changes in atmospheric conditions particularly in temperatures or and precipitation additionally as the elevated atmospheric co2 concentrations have a direct impact on crop growth and yield either current or future co2 concentration level can also be included in a project during the climate change project run adaptation measures can be considered using different management scenarios as input the climate change study is only restricted by soil and climate characteristics and is independent of present or future land use patterns for each project type different simulation settings and scenarios can be created by changing the data source the crop model and the date span 4 4 summary statistics and visualization the final step of the gridded simulation process is the generation of information that can then be disseminated for decision support upon successful completion of simulations and after saving the results final information can be viewed or exported to a file based on the selection criteria various output variables yield at harvest maturity above ground biomass at maturity pod or grain weight harvest index the maximum leaf area index total seasonal transpiration soil evaporation and evapotranspiration and total precipitation runoff and drainage are displayed the selected output variables are supported with summary statistics mean standard deviation median percentiles coefficient of variance and maximum and minimum values that can be used for improved analysis of the results or regional summaries the toolbox also has two options for comparing the simulations results for the given parameter a calculation of the differences and a calculation of the deviation between the simulations the final step in the workflow is to visualize the underlying information craft generates interactive thematic maps representing up to ten different classes for all output variables their summary statistics and the results of comparing simulations 5 case studies we conducted and discuss three cases to illustrate the application of the toolbox two are for risk characterization cases 1 and 2 and one is for yield forecast case 3 the primary steps for setting up the simulations were selecting the weather and soil data and defining the levels for field history crop variety and details for planting fertilizer and irrigation daily weather data included solar radiation maximum and minimum temperatures and rain obtained from the nasa prediction of worldwide energy resource power data base https power larc nasa gov cgi bin cgiwrap solar agro cgi with a data resolution 1 1 sliced to 5 arc minutes details of the physical and hydraulic soil properties of the soil layer profiles were provided in the wise database 5 1 case study 1 the impact of transplanting date on rice production the barisal district of bangladesh is among the major rice growing regions of bangladesh the study region consists of 82 cells at a 5 arc minute resolution grid the impact of transplanting date on rice production was simulated with the dssat crop engine using the csm ceres rice module for 26 years 1984 2009 local crop management details were adopted from basak et al 2010 table 2 the cultivar coefficients for the rice variety br14 were obtained from a local calibration conducted by basak 2012 the transplanting dates that were evaluated included january 1 5 10 15 and 25 rice growth development and yield were simulated for each grid cell year and transplanting date yield was summarized for each grid cell aggregated for the region and summarized by planting date fig 9 top after completion of the simulations the results were exported in ms excel and visualized in general the simulations showed the lowest yield 2000 kg ha 1 for the early planting date january 1 and the highest yield for the january 25 planting date 5490 kg ha 1 fig 9 bottom the simulated yield also showed seasonal variation due to annual weather variability the standard deviation for yield over the selected planting dates ranged from 552 kg ha 1 january 1 planting to 671 kg ha 1 january 25 planting 5 2 case study 2 the effect of sowing dates on wheat yield the ludhiana district is among the major wheat growing regions of india the study region consists of 69 cells at a 5 arc minute resolution grid the csm ceres wheat module of the dssat crop engine was used to estimate the long term 1984 2008 mean yield and variability for the wheat variety pbw175 the cultivar coefficients for the wheat variety pbw175 were obtained from a local calibration conducted by vashisht et al 2013 local crop management details were adopted from timsina et al 2008 table 2 five sowing dates in fortnightly intervals ranging from early october to early december were evaluated table 2 weeds pests and diseases were considered to be well controlled wheat growth development and yield were simulated for each grid cell year and sowing date yield was summarized for each grid cell aggregated for the region and summarized by sowing date fig 10 top after completion of the simulations the data were exported into ms excel and graphed potential yield varied across years and sowing dates fig 10 bottom with mean yield ranging from 1870 kg ha 1 october 10 sowing to 2180 kg ha 1 october 25 sowing yield was highest for the sowings between october 25 and november 25 and smallest for the december 10 sowing date yield variability due to seasonal weather variability was greater than the variation across sowing dates for example for the october 25 sowing the yield ranged from 1260 to 3240 kg ha 1 the standard deviation for yield over the selected sowing dates ranged from 533 kg ha 1 october 25 sowing to 753 kg ha 1 december 10 sowing the crop model underestimated yield for all years and all sowing dates which remains a concern and needs to be addressed by adjusting the management input 5 3 case study 3 yield forecast for rice the csm ceres rice module of the dssat crop engine was used to forecast yield for the rice variety pr114 the study region of the ludhiana district of punjab state of india consists of 69 cells in a 5 arc minute resolution grid the genetic coefficients for the rice variety pr114 were obtained from the cultivar information distributed with dssat v4 7 hoogenboom et al 2017 the crop management data that were used in the simulations table 2 were adapted from basak et al 2010 soil and crop masks were provided by craft the observed rice yield 1998 2009 for the region was first detrended prior to the calibration run to determine the modification factor a yield forecast type project was then created for the ludhiana district the crop model was run and the simulated results were calibrated with the modification factor the simulation start date was selected as june 10 and the yield forecast date as july 25 2010 the yield forecast mode was run using cpt cca was selected for the forecast statistical method and sst for the gridded predictor file the training period for the statistical model was 24 years 1986 2009 and the yield forecast was conducted for each year using the predictor file containing sst fields for january 16 and for the forecasting year of 2010 fig 11 top for each grid cell the rice yield forecast for 2010 y ˆ 2010 was 4431 kg ha 1 with lead time of 2 months fig 11 bottom standard descriptive measures of goodness of fit and forecast accuracy were applied to evaluate the accuracy of rice yield predictions including rmse of prediction mean absolute error mae mean bias error mbe and mean absolute percentage error mape we evaluated the accuracy of rice yield predictions against available 1998 2009 observed yield the aggregated forecasted yield varied across years with a mean yield of 4435 kg ha 1 the errors associated with rice yield forecasts were occasionally very large such as 1998 and 1999 when residuals ε i were 1316 kg ha 1 and 1144 kg ha 1 respectively and absolute percentage errors of 41 8 and 34 2 the most accurate predictions were obtained for 2002 through 2006 with residuals of less than 150 kg ha 1 and forecast errors less than 3 4 the overall forecast accuracy measures such as rmse mae mbe and mape were 617 kg ha 1 439 kg ha 1 376 kg ha 1 and 12 3 respectively 6 discussion there has been an increased interest in spatial crop simulations in the past decade and at the same time greater availability of various global geospatial data sets from a wide variety of data collection platforms therefore there is a growing need for spatial crop simulation that employ tools and frameworks of different complexity and approaches including approaches that allow running existing field scale crop models on a spatial scale holzworth et al 2015 geographic information systems are often a logical part of such systems as they can effectively support with functionality related to shapes polygons etc geospatial data from diverse sources including soil management application and crop maps can be provided within the craft database as masks data are summarized in a format that permits realizations of the crop model simulations for each grid cell and then the toolbox provides functionality for easily performing the necessary geospatial data processing tasks and conducting spatial simulations statistical seasonal climate forecasts have successfully supported agricultural applications using various approaches these include historic analogs de jager et al 1998 hammer et al 2001 and combining gcm based seasonal rainfall forecasts with a crop model hansen et al 2004 mishra et al 2008 seasonal clime forecasts are somewhat constrained since the accuracy of statistical models is primarily limited by the length and quality of the historical observational record and by assumption on the stationarity of the climate system hansen et al 2004 a detailed review of advances in seasonal climate forecasting with a focus on agriculture is provided by klemm and mcpherson 2017 craft is integrated with seasonal climate forecasts along with historic and monitored weather data and other gridded data sets to produce probabilistic forecasts of crop yields and area aggregated production it incorporates multivariate statistical forecast using cpt to connect the predictable components of seasonal climate with the crop simulation instead of developing the downscaled seasonal forecast model on historic weather data it is developed from crop yields simulated with historic weather data therefore various methods of climate science and crop production forecasting are built into the toolbox the presented case studies demonstrate the main functionalities of craft as dssat has already been evaluated extensively for the study region it was selected as a crop model additionally varieties and cultivar coefficients in the case studies are taken from sources that already calibrated and evaluated dssat for their respective regions most importantly a lack of observed data limited our capacity to evaluate the simulations it is the user s responsibility to prepare detailed inputs for cases that are more comprehensive and such tasks are beyond of the scope of the current paper it is worth noting that several case studies have shown that the toolbox can help institutional stakeholders by providing useful and reliable information on the spatial and temporal variability of crop production and yield forecasts iwmi 2014 neksap 2016 17 stakeholder interaction and potential user involvement is crucial for development and future success of such system voinov et al 2016 volk et al 2010 therefore a wide range of stakeholders was involved to help develop the variety of objectives that are covered by the toolbox the feedback oriented development procedure ensured engagement with stakeholders during the entire project stakeholders gave feedback on the system structure the models and objectives as well on the design of the user interface training workshops with the potential users of the system gave additional insights in design improvements craft s main advantage over other systems is its integration of seasonal forecast with cpt by inclusion of historic monitored and forecast weather information sst fields and gcm outputs for regional forecasts made at any point in the growing season by using an ensemble of crop models dssat apsim sarra h and corresponding gis shape files on two spatial resolutions for any region the majority of the spatial simulations were carried out for 0 5 resolution grids the toolbox can also conduct simulations at a finer resolution of 0 083 operation of the system requires basic knowledge of gis type software visualization of the results considerably improves stakeholder interaction with the system the toolbox is not reliant upon a specific crop model and assumes that any supported crop models can be pre installed on the computer system this approach permits the software to be extended to different crop models for integration into craft a crop model should be able to communicate via ascii files to its input output and must be able to be called from the command line if these conditions are satisfied it takes advantage of the agmip data translator tool for crop model interoperability or the crop engine can be extended to this particular crop model to demonstrate this feature it was used to run an ensemble of crop models for the same geospatial data sets at a field site although the models had somewhat different data input requirements the toolbox was able to manipulate the input data to conform to the model requirements and conduct simulations across the region with each model shelia et al 2018 craft is a freely accessible windows desktop application that can be easily deployed using the installation tool its flexibility permits modelers and researchers with diverse objectives to combine geospatial data processing with their modeling analyses the software description and case studies provided herein demonstrate possible applications that include risk assessment related to crop production and yield forecast as well as the impact of climate change projections on yield and the potential for adaptation using different crop management scenarios the main shortcoming of the toolbox is its inability to run multithreaded simulations as a result time to run multiple simulations may vary significantly depending upon the area of interest therefore craft is best recommended for country and or regional level scale that are relevant to food security early warning and market applications the functionalities to generate and upload schema require the esri arcgis version 10 1 or higher which can be considered as a limitation the current database already contains schemas at three administrative levels for several asian countries for future releases the number of supported countries will be increased and additionally alternate options working with a schema will be provided via r https www r project org and gdal https www gdal org spatial libraries future development plans include extending the number of crop models incorporating an additional crop model such as infocrop aggarwal et al 2006 to make the toolbox a cross platform system we intend to use mono an open source implementation of microsoft s net framework by xamarin microsoft http www mono project com in the future we are also planning to establish a repository for open source development of craft 7 summary and conclusions craft offers an integrated modeling framework for within season yield forecasting risk analysis and climate change impact studies the core of the system is based on three tiers the user interface computation modules and the database the toolbox provides support for spatial data through the use of 5 and 30 arc minutes resolution grids in the current version of craft the crop simulations are based on dssat apsim and sarra h however any crop model for which an agmip data translator has been developed can be used the toolbox integrates seasonal climate forecasts using the cpt engine crop model calibration uses historic agricultural statistics for regional yield craft provides spatial aggregation and probabilistic analysis of the forecast uncertainty and visualization of the results using thematic maps although the toolbox can be used for simulations on the global scale its primary use is at the country or regional scale craft has been designed to address the needs of planners and policy makers by offering improved access to a platform that simulates crop production systems using an ensemble of models the case studies show that it can help a diverse range of stakeholders regional policy makers government agencies and researchers by providing reliable information on the spatial and temporal variability of crop production thus enabling improved risk management for agriculture associated with increasing climate variability acknowledgements we are very grateful to dr simon mason iri for his contribution in craft development and especially in cpt implementation the final product has greatly benefited from his expertise this project was implemented by the university of florida in collaboration with the international research institute for climate and society iri the asia risk centre and washington state university it is part of the cgiar research program on climate change agriculture and food security ccafs which is carried out with support from the cgiar trust fund and through bilateral funding agreements for details please visit https ccafs cgiar org donors the views expressed in this document cannot be taken to reflect the official opinions of these organizations software availability name of the software craft ccafs regional agricultural forecasting toolbox developer university of florida in cooperation with iri and ccafs contact address department of agricultural and biological engineering university of florida gainesville florida 32611 usa phone 1 352 392 1864 e mail vakhtang shelia ufl edu year first available 2014 hardware required desktop laptop with 2 5 ghz cpu 6 gb ram hdd with 70 gb or more free space software required arcgis version 10 1 or higher program languages and database c java mysql platform ms windows 7 8 10 program size with the sample db 3 63 gb availability and cost freely available https dssat net s craft submit x 0 submit y 0 appendix a list of abbreviations aegis agricultural and environmental geographic information system agmip the agricultural model intercomparison and improvement project api application programming interface apsim the agricultural production systems simulator bioma biophysical models applications framework cca canonical correlation analysis ccafs cgiar research program on climate change agriculture and food security cdf cumulative density function cgiar consultative group for international agricultural research craft ccafs regional agricultural forecasting toolbox cpt climate predictability tool csm cropping system model dssat decision support system for agrotechnology transfer dto data transfer object eof empirical orthogonal functions eu european union gcm general circulation model gis geographic information system gui graphical user interface id identification number ifpri international food policy research institute iri international research institute for climate and society jrc joint research centre mvvm model view viewmodel ngo non governmental organization pc principal component pcr principal components regression psims parallel system for integrating impacts models and sectors rmse root mean square error sarra h system for regional analysis of agro climatic risks sst sea surface temperature wpf windows presentation foundation 
26239,regional crop production forecasting is growing in importance in both the public and private sectors to ensure food security optimize agricultural management practices and use of resources and anticipate market fluctuations thus a model and data driven easy to use forecasting and a risk assessment system can be an essential tool for end users at different levels this paper provides an overview of the approaches algorithms design and capabilities of the ccafs regional agricultural forecasting toolbox craft for gridded crop modeling and yield forecasting along with risk analysis and climate impact studies craft is a flexible and adaptable software platform designed with a user friendly interface to produce multiple simulation scenarios maps and interactive visualizations using a crop engine that can run the pre installed crop models dssat apsim and sarra h in concert with the climate predictability tool cpt for seasonal climate forecasts its integrated and modular design allows for easy adaptation of the system to different regional and scientific domains craft requires gridded input data to run the crop simulations on spatial scales of 5 and 30 arc minutes case studies for south asia for two crops including wheat and rice shows its potential application for risk assessment and in season yield forecasting keywords ensemble simulations decision support crop model yield forecast food security 1 introduction the ability to predict agricultural production losses associated with extreme natural events through monitoring and forecasting creates an opportunity for governments international aid organizations ngos and donors to provide targeted assistance for replacing lost food income and maintaining some level of food security timely assistance stabilizes consumption allowing households and communities to move towards economic security and sustainability however any delay in identifying and initiating a response to emerging food crises will greatly increase the long term impacts on livelihoods and the cost of aid cabot venton et al 2012 clarke and hill 2013 haile 2005 when a crisis requires external food aid it can take up to several months before aid reaches affected populations as a result populations in crisis may already have suffered adverse health effects divested productive resources or migrated in food insecure regions such as in africa or southeast asia early warning systems based on remote sensing of vegetation and monitoring of local commodity markets can provide an early indication of likely food shortfalls hallegatte 2012 verdin and klaver 2002 thus food aid organizations in developing countries are increasingly interested in seasonal agricultural forecasts to provide lead time in response to extreme weather events that affect current agricultural production operational crop forecasting and early warning systems for food security exist in many regions to help support market and policy decisions cantelaube and terres 2005 motha 2011 verdin and klaver 2002 vossen and rijks 1995 often they are based on monitoring weather and crop conditions during the growing season and incorporate regionally calibrated crop models to estimate yield uncertainty crop models are computerized representations of crop growth and development and predict yield through mathematical equations as functions of soil properties weather conditions and management practices hoogenboom 2000 there has been significant progress in the application of crop models to define strategies for more efficient crop production improved risk management sustainable cropping systems and to study the impact of climate change on agricultural systems holzworth et al 2015 crop model integrated decision support tools as a computer based technology to support complex decision making have long been used to assess climate risk in agriculture risk refers to a likelihood that can be assessed using prior information but when the likelihood cannot be estimated then uncertainty applies both risk and uncertainty are contributing factors in the choice of appropriate management practices for decision makers han et al 2017 selvaraju 2013 in addition to risk analysis and assessment crop models have also been used for yield forecasting bannayan et al 2003 yun 2003 crop yield forecasts can be conducted prior to planting or during the actual growing season and the results produced by the models can be used to make appropriate management decisions and to provide farmers and others with alternative options for their farming system hoogenboom 2000 skillful seasonal forecasts provide additional information that can increase the accuracy of within season production forecasts based on monitoring and simulation alone particularly early during the growing season cantelaube and terres 2005 hansen et al 2004 stephens et al 2000 one of the main approaches for spatial crop simulations müller et al 2017 is based on field scale crop models and various degree of gis integration hartkamp et al 1999 current well known spatial crop modeling systems include aegis mars bioma gepic psims mink simplace and geosim for geostatistical and spatial analysis of crop modeling the agricultural and environmental geographic information system aegis aegis win was created linking the decision support system for agrotechnology transfer dssat v3 with the geographic mapping tools arcinfo and arcview using an object oriented macro programming language lal et al 1993 engel et al 1997 in the 1990s the european crop growth monitoring system eu cgms and yield forecasting system was developed by the mars project coordinated by the joint research centre jrc vossen and rijks 1995 supit 1997 to simulate the impacts of climate change on agriculture and to evaluate adaptation strategies the jrc uses the biophysical models applications bioma framework donatelli et al 2012 a gis based epic model gepic is another spatial tool that integrates a bio physical epic environmental policy integrated climate model with a gis to simulate the spatial and temporal dynamics of the major processes of the soil crop atmosphere management system liu et al 2007 within the impetus research project of the global change and hydrological cycle glowa program of the german government the smile scientific model integration pipeline engine framework enders et al 2010 and its improved version called simplace http www simplace net were developed to facilitate climate impact modeling elliott et al 2014 developed the parallel system for integrating impacts models and sectors psims that is designed to support integration of site based applications and allow researchers to use high performance computing to run simulations over large spatial extents at the international food policy research institute ifpri a global scale crop modeling system using a gridded approach known as mink robertson 2017 was created to provide gridded simulated crop data for the international model for policy analysis of agricultural commodities and trade impact robinson et al 2015 thorp and bronson 2013 developed the geospatial simulation geosim tool as a plug in for quantum gis to manage point based model simulations at multiple locations these spatial crop modeling systems have been designed for specific applications and accordingly have certain requirements and limitations that could restrict the implementation in developing countries some of these tools are now obsolete aegis others are very robust use scripting languages and must be run on clusters or on high performance computers psims mink while some have associated implementation and maintenance issues mars that might be costly or they lack functionality such as yield forecast geosim in order to increase the capacity of developing regions for within season forecasting of the impacts of climate fluctuations on crop production the cgiar research program on climate change agriculture and food security program ccafs convened a workshop on seasonal weather forecasts linked pre harvest estimates of crop production methodological approaches negombo sri lanka 16 18 april 2012 following a participatory approach voinov et al 2016 the intention was to bring together various stakeholders scientists with expertise in problem domains crop modeling yield forecast and monitoring systems climate and other actors to jointly assess and identify key challenges of existing yield forecasting tools for research and operational use in the ccafs focus regions the identified challenges were to recognize the need for convenient and easy to use software platform to facilitate crop yield forecasting for researchers and operational institutions and to develop such a platform that could be accessible cost free and adaptable to support multiple crop models as a result ccafs initiated the development of the ccafs regional agricultural forecasting toolbox craft to support within season forecasting of crop production and secondarily risk analysis and climate change impacts studies the main research questions to be explored and then implement in the software included management of spatial data and crop simulations integration of seasonal forecasts hindcast spatial aggregation probabilistic analysis post simulation calibration risk analysis climate change impact and visualization the objectives of this paper are to a provide the basic concepts of gridded simulations and algorithms used for yield forecasting in craft b describe the toolbox architecture and its main components c present the current version and its main functionality and d demonstrate risk assessment and yield forecasting case studies 2 algorithms for crop production forecasts in craft 2 1 gridded crop simulation and empirical calibration process oriented crop models predict crop growth development and yield for a variety of environmental conditions and management options at a point or field scale in order to run point based models at a regional scale first the region is divided into grid cells that are considered as points and then a crop model is run for each individual grid cell of the region finally the results of the point based simulations are aggregated to a region to determine spatial crop production a similar approach has been implemented in craft the reference grids in craft are world grids wgs84 projection with two different spatial resolutions of 5 and 30 arc minutes fig 1 a each grid cell of the reference grid can be assigned a unique id identification number starting from one at the top left corner and moving from west to east 180 to 180 long and from north to south 90 to 90 lat the process of generating a cell id for each cell of the grid using the shape file of the region is considered the schematization process and schema generation is one of craft s functionalities it should be noted that the boundary of the shape could be arbitrary and not necessarily coincide with an administrative boundary as an example fig 1c is a grid that comprises 112 cells within administrative boundaries in a 5 arc minutes resolution grid cell ids were defined during schema generation and exported in text format fig 1b the corresponding cell ids are used for preparation of the input files for creating relations between the tables of the underlying database and for processing storing and retrieving data from the database yield often shows an increasing trend over time which can be attributed to technological improvements such as new varieties or enhanced crop management therefore prior to calibrating simulated yield time series of the observed yield data optionally should be detrended in craft two different methods for detrending the observed yield time series namely linear and quadratic detrending algorithms have been implemented various studies lu et al 2017 have used these methods for detrending crop yield time series data both regression models can be fitted over time using the least squares method after simulating the trend with the appropriate statistical model a decomposition model is applied to remove the simulated trend after the observed yield with optional detrending procedure is overlaid on the region the calibration process is applied to the simulated yield in craft most of the crop model calibration methods are applicable to deterministic simulations and crop model parameters are adjusted in order that simulated phenology yield and yield components values better match their corresponding observed values such a detailed calibration is generally not performed in gridded applications due to a lack of available reference data instead cultivar parameters of models are typically calibrated at a set of points and then the key parameters are extrapolated with relatively simple algorithms elliott and müller 2015 alternatively a yield correction factor can be applied to the regional yield aggregated from the simulated yield on a field scale in order to minimize the root mean square error rmse with observed regional yield challinor et al 2005 hansen and jones 2000 using the latter approach the calibration process in craft is based on long term regional observed yield data after cultivar parameters of models are optionally calibrated for a set of cells as part of this empirical calibration process yield is simulated for all years for which observed yield is available and then by fitting a linear regression between the observed and the simulated yield a value for the calibration modification factor is determined 2 2 integration of seasonal climate forecasts with cpt craft uses a statistical approach to integrate the seasonal climate forecast with the crop yield forecast this method was evaluated in a proof of concept study in queensland australia for operational wheat production forecasting hansen et al 2004 the same method was later employed to improve sorghum yield forecasts mishra et al 2008 to prepare a forecast for a certain date during the growing season for the current year yield is simulated first with observed antecedent weather data for the current year up to the forecast date and then complemented with weather data from available historic years until final harvest the resulting time series of simulated yield are treated as the predictand and used with a time series of appropriate seasonal climate predictor fields e g fields of sea surface temperatures ssts to fit a multivariate statistical model the expected yield value for the current season is forecast from current seasonal climate predictor observations and the fitted statistical model the yield forecast distribution is obtained from cross validated hindcast residuals centered on the expected value of the forecast because the proportion of total uncertainty due to climate decreases during the growing season the potential improvement in accuracy from incorporating seasonal forecasts is expected to be greatest early during the growing season hansen et al 2004 2006 a flowchart for the process of yield forecasting is provided in fig 2 craft uses the climate predictability tool cpt developed by the international research institute for climate and society iri mason and tippett 2016 which is widely used by national meteorological services and researchers throughout the world as a statistical forecast package cpt was designed for producing seasonal climate forecasts using gridded outputs from gcms and ssts as predictors it uses principal components pcs or empirical orthogonal functions eofs to interact efficiently with gridded data as predictors thereby reducing problems associated with multiplicity and collinearity finally the tool performs rigorous cross validation to avoid artificial skill the statistical modeling component of craft is implemented by running cpt in batch mode canonical correlation analysis cca or principal components regression pcr settings are used for yield forecasting it is recommended that the appropriateness and skill of a seasonal forecast system first be established before seasonal predictors are used 2 3 probability distribution of the forecast and transformation of non normal data methods that have been developed for deriving and evaluating probabilistic climate forecasts are generally relevant to forecasts of agricultural impacts including forecast distributions from hindcast residuals historical analogs and forecast distributions from dynamic climate model ensembles hansen and indeje 2004 hansen et al 2006 in craft the first approach was implemented i e estimating a forecast probability distribution as the distribution of hindcast residuals centered on the expected value of the current forecast hansen et al 2006 the following are the steps for deriving a probabilistic forecast from hindcast residuals a time series of hindcast residuals ε i is calculated as follows 1 ε i y i y ˆ i where y i is yield time series simulated with current year of weather data through forecast date and complemented with the ith year weather data through harvest from available historic weather data for n years y ˆ i are hindcasts calibrated to observations for example by pcr or cca and i is an index for the year in the time series ε i is then sorted to derive a residual distribution and cumulative density function cdf of residuals the forecast distribution for a given forecast year is obtained by adding its expected value y ˆ to each ε i the method accounts for the overall prediction error of the forecast system and is generally applicable to statistical or dynamic forecast models artificial forecast skill and systematic underestimation of the dispersion of probabilistic forecasts are inherent risks in statistical forecasting as the error of statistical forecast models tends to be smaller for the period used to calibrate the model than for predictions outside the calibration data hansen et al 2006 to reduce the risk of artificial skill the forecast distribution in a given year is derived from cross validated regression residuals methods for deriving probabilistic forecasts differ in their ability to handle changes in predictability from year to year one source of apparent variation in predictability between years is the skewness of the underlying distributions for strongly skewed variables the magnitude of forecast residuals and therefore the spread of forecast distribution tends to increase in the direction of skewness several studies have shown that after applying a normalizing power series transformation box and cox 1964 to reduce the positive skewness of the rainfall series the mean separation remains but variances were constant kruskal and wallis 1952 levene 1960 in craft a normalizing transformation to the predictand time series is used so that hindcast residuals can account for the effects of skewness on forecast dispersion a forecast distribution in transformed space is derived and then applied as an inverse transformation to convert the forecast distributions into the original yield units hansen et al 2004 2 4 spatial aggregation from yield to production the simulated output of crop models can be scaled up at aggregate levels to account for the heterogeneity of environment and management of spatial data sets hansen and jones 2000 in craft the level of aggregation ranges from point to a grid cell and from grid cell to a region because the toolbox simulates on a grid cell base two aggregation steps are applied the first step simulates multiple treatments within a grid cell and then after calculating yield and other outputs weighted by the share of the area under different soils for a given cell it aggregates yield to obtain an average value at a grid cell level in the second step average yield and cell area account for crop production on a grid cell level and then production by grid cells is aggregated to polygons thus resulting in regional level production uncertainties in yield forecasting at a regional level are represented in terms of probability distributions on the aggregated level the aggregation of the forecast probability distribution is derived from cross validated regression residuals based on the simulated y i j and the hindcast y ˆ i j yields for ith year and jth grid cell aggregated to a polygon level by taking their weighted linear combination according to the following equations 2 y i j 1 m w j y i j 3 y ˆ i j 1 m w j y ˆ i j where y i and y ˆ i are aggregated to the area simulated and hindcast yields w j s j s is the share of the cell area s j over the area of the region s and m is the total number of cells in the area of aggregation the weights w j are non negative and their total is one then a time series of hindcast residuals ε i is calculated similar to eq 1 but applied to the aggregated values of the simulated and hindcast yields 4 ε i y i y ˆ i i 1 2 n where n is a number of years finally a time series of hindcast residuals ε i is sorted to derive a cdf of residuals the forecast distribution for a given forecast year is then obtained by adding its expected value y to each hindcast residual ε i thus the aggregated probability distribution summarizes the accumulated information on yield by grid cells over the area 3 software architecture 3 1 overview the craft application is based on the microsoft net windows platform and includes a user friendly client application developed in c that provides the interface with crop models and a mysql database implementation the database contains all input and output data for the crop models including crop management soil weather and climate data as well as crop model related information the toolbox is integrated with two external engines namely a crop model engine for linking and executing the crop models and the cpt engine for running cpt as a statistical package the application architecture follows object oriented programming oop paradigms uses software design patterns gamma et al 1995 and is designed as a multi tiered system to allow for modularity and scalability the overall system uses a model view view model mvvm design pattern and windows presentation foundation wpf concepts since the view is part of the graphical user interface gui of the application the modules and components that are part of craft are shown in fig 3 the integrated design and structure of the toolbox allows for easy adaptation of the system to other spatial domains and crop models the three main tiers of the system are presentation business and data the presentation tier contains the components that implement and display the user interface and it manages interaction with net base windows forms it also acquires and validates data input the business tier implements the logic for the system functionality and treats data as objects not considering how the data are stored or displayed it manages a client s requests on information as well the business tier is designed to address scalability of the application and it contains three entities interface factory class and implementation class the interface separates the implementation and defines the structure the factory class contains the methods that encapsulate the creation of objects the implementation class inherits the interface and stores the logic to implement the interface method in the data tier the data access layer is designed to abstract the logic necessary to access the database using a separate data layer makes the application easier to configure and maintain and it hides the details of the database from other layers of the application data transfer objects dtos are used when interacting with other layers and to pass the data between layers 3 2 input data and storage gridded simulations by craft can be conducted for any region for up to three scale levels which for example could be a country a state province and a district if the administrative area is the region of interest the toolbox is built with a schema generation feature which allows for the generation of schema files through user specified shape files that correspond to up to three spatial scales for the region after completing the schema generating process a schema folder will contain the respective schema files by the administrative or other specified boundaries fig 4 the schema files then can be uploaded in the database using the data upload module craft works on a gridded region with each grid cell representing an area along with its attributes therefore gridded input data are required the input data include information necessary to run the crop models such as daily weather soil properties initial conditions cultivar or varieties and crop management downloadable templates are available to facilitate data preparation in the specific formats required by the toolbox arcgis shape files are used for data associated with aerial mappings including soil and crop coverage and crop management fig 5 the data loader module is designed to manage uploading and downloading various datasets it enforces rules to ensure the completeness of the data and adherence of the data to the defined data structures the mysql database is used as a central database to store all input and output data of the simulations fig 3 the central database contains the configuration data location specific information such as the coordinates and properties of each grid cell the dynamic time series data etc the dynamic series data can either be imported from external sources or produced through internal data manipulation methods and crop model simulations 3 3 linkage between craft and external modules the crop simulation models and cpt have been kept independent from craft as external modules hence the data should be passed from the database to the external modules and from the external modules back to the database the toolbox has two engines for linking to them one is the crop engine for spatial crop simulations and the other is the cpt engine for seasonal climate forecasting functionalities of the engines are to translate the internal database into a format that can be recognized by the external modules and to transfer the output data from the external modules into craft s specific format the engines also handle any errors that might occur during the operation of the external modules because craft works on a grid model and inputs are set at the time of model run creation the grid cells are processed one by one and the data for each individual grid cell are provided to the crop engine as objects the crop engine uses these objects to execute the crop model and returns the crop model run results to the application for further processing and storage in the database fig 6 the crop engine uses the dssat cropping system model csm as a crop model jones et al 2003 hoogenboom et al 2017 the data formats of crop models vary widely and in order to extend the operational capabilities of the toolbox to additional crop models the agmip data translator tool porter et al 2014 that comprises various formats and utilities has been implemented using this tool craft currently includes apsim agricultural production systems simulator holzworth et al 2014 and sarra h baron et al 2003 as two additional crop simulation models 3 4 output module report generation and mapping integration the output module is designed to optimize retrieval and visualization of the result datasets the final report generation is available in two types of forms the first report option is a series of tables that can be exported in csv file format and the second report option is a map mapwingis a geographic information system programming activex control and application programming interface api ames et al 2007 is used to provide craft with the mapping functionality using the gis shape files maps along with the grid cells can be displayed and the various output variables from the crop model simulations can be depicted in thematic maps 4 use of craft 4 1 graphical user interface the craft application provides net base windows forms for various inputs and outputs a summary of the main features of its gui is described in table 1 the home window fig 7 provides a summary of the most recently used projects a link to create a new project basic information for the last selected project and the run that has been executed the project name link allows navigation to the current state of the workflow the toolbox can be configured via configuration with the desired database and schema generation functionality that allows generation of schema files compatible with an application through user specified shape files 4 2 input module data loader and configuration the data loader gui is a tabular interface for the data import export option e g fig 8 it enables uploading various data sets that are required by the modeling engines into the central mysql database after checks that reject incomplete or erroneous data during the upload process the input module provides support for spatial input data through the use of 5 and 30 arc minutes resolution grids input data should adhere to the data structure of the grid and be consistent with the cell resolution the datasets that can be uploaded are weather data for climate change crop mask soil mask irrigation mask etc in text txt format file fig 3 the data loader also provides an export delete option to download data files and schema from the database or to delete uploaded data based on selection criteria the management options that can be selected or entered as levels through the interface are the following detailed information related to field initial conditions crop variety planting dates irrigation fertilizer inorganic and organic and environment fig 3 these inputs need to be applied to the project run and the highest resolution for the application is the district level or level 3 all grid cells that fall within a district inherit the data applied for that particular district the configuration module also provides additional functionalities for dataset input in the central database such as uploading varieties cultivars for different crops and crop models and uploading new or updating existing soil profiles 4 3 projects a project is defined by its spatial domain based on the selected boundary level the spatial resolution the project type crop and the crop model there are four types of projects that can be created and executed calibration yield forecast risk characterization and climate change the calibration type project allows for the calculation of the modification factor and the equation for transforming simulated yield to the regional level yield based on observed regional yield the yield forecast type project runs the crop model uses the calibration modifier to determine the calibrated yield and executes cpt resulting in the in season yield forecast the risk characterization type project runs the crop model for various environmental and management scenarios and estimates the associated risk the climate change type project assesses future climate risk for crop production and determines high climate risk areas for crop yield in this case the weather datasets should be associated with baseline and various future weather projections by general circulation models gcms for four emissions scenarios representative concentration pathways rcps adopted by the ipcc for its 5th assessment and reflect changes in atmospheric conditions particularly in temperatures or and precipitation additionally as the elevated atmospheric co2 concentrations have a direct impact on crop growth and yield either current or future co2 concentration level can also be included in a project during the climate change project run adaptation measures can be considered using different management scenarios as input the climate change study is only restricted by soil and climate characteristics and is independent of present or future land use patterns for each project type different simulation settings and scenarios can be created by changing the data source the crop model and the date span 4 4 summary statistics and visualization the final step of the gridded simulation process is the generation of information that can then be disseminated for decision support upon successful completion of simulations and after saving the results final information can be viewed or exported to a file based on the selection criteria various output variables yield at harvest maturity above ground biomass at maturity pod or grain weight harvest index the maximum leaf area index total seasonal transpiration soil evaporation and evapotranspiration and total precipitation runoff and drainage are displayed the selected output variables are supported with summary statistics mean standard deviation median percentiles coefficient of variance and maximum and minimum values that can be used for improved analysis of the results or regional summaries the toolbox also has two options for comparing the simulations results for the given parameter a calculation of the differences and a calculation of the deviation between the simulations the final step in the workflow is to visualize the underlying information craft generates interactive thematic maps representing up to ten different classes for all output variables their summary statistics and the results of comparing simulations 5 case studies we conducted and discuss three cases to illustrate the application of the toolbox two are for risk characterization cases 1 and 2 and one is for yield forecast case 3 the primary steps for setting up the simulations were selecting the weather and soil data and defining the levels for field history crop variety and details for planting fertilizer and irrigation daily weather data included solar radiation maximum and minimum temperatures and rain obtained from the nasa prediction of worldwide energy resource power data base https power larc nasa gov cgi bin cgiwrap solar agro cgi with a data resolution 1 1 sliced to 5 arc minutes details of the physical and hydraulic soil properties of the soil layer profiles were provided in the wise database 5 1 case study 1 the impact of transplanting date on rice production the barisal district of bangladesh is among the major rice growing regions of bangladesh the study region consists of 82 cells at a 5 arc minute resolution grid the impact of transplanting date on rice production was simulated with the dssat crop engine using the csm ceres rice module for 26 years 1984 2009 local crop management details were adopted from basak et al 2010 table 2 the cultivar coefficients for the rice variety br14 were obtained from a local calibration conducted by basak 2012 the transplanting dates that were evaluated included january 1 5 10 15 and 25 rice growth development and yield were simulated for each grid cell year and transplanting date yield was summarized for each grid cell aggregated for the region and summarized by planting date fig 9 top after completion of the simulations the results were exported in ms excel and visualized in general the simulations showed the lowest yield 2000 kg ha 1 for the early planting date january 1 and the highest yield for the january 25 planting date 5490 kg ha 1 fig 9 bottom the simulated yield also showed seasonal variation due to annual weather variability the standard deviation for yield over the selected planting dates ranged from 552 kg ha 1 january 1 planting to 671 kg ha 1 january 25 planting 5 2 case study 2 the effect of sowing dates on wheat yield the ludhiana district is among the major wheat growing regions of india the study region consists of 69 cells at a 5 arc minute resolution grid the csm ceres wheat module of the dssat crop engine was used to estimate the long term 1984 2008 mean yield and variability for the wheat variety pbw175 the cultivar coefficients for the wheat variety pbw175 were obtained from a local calibration conducted by vashisht et al 2013 local crop management details were adopted from timsina et al 2008 table 2 five sowing dates in fortnightly intervals ranging from early october to early december were evaluated table 2 weeds pests and diseases were considered to be well controlled wheat growth development and yield were simulated for each grid cell year and sowing date yield was summarized for each grid cell aggregated for the region and summarized by sowing date fig 10 top after completion of the simulations the data were exported into ms excel and graphed potential yield varied across years and sowing dates fig 10 bottom with mean yield ranging from 1870 kg ha 1 october 10 sowing to 2180 kg ha 1 october 25 sowing yield was highest for the sowings between october 25 and november 25 and smallest for the december 10 sowing date yield variability due to seasonal weather variability was greater than the variation across sowing dates for example for the october 25 sowing the yield ranged from 1260 to 3240 kg ha 1 the standard deviation for yield over the selected sowing dates ranged from 533 kg ha 1 october 25 sowing to 753 kg ha 1 december 10 sowing the crop model underestimated yield for all years and all sowing dates which remains a concern and needs to be addressed by adjusting the management input 5 3 case study 3 yield forecast for rice the csm ceres rice module of the dssat crop engine was used to forecast yield for the rice variety pr114 the study region of the ludhiana district of punjab state of india consists of 69 cells in a 5 arc minute resolution grid the genetic coefficients for the rice variety pr114 were obtained from the cultivar information distributed with dssat v4 7 hoogenboom et al 2017 the crop management data that were used in the simulations table 2 were adapted from basak et al 2010 soil and crop masks were provided by craft the observed rice yield 1998 2009 for the region was first detrended prior to the calibration run to determine the modification factor a yield forecast type project was then created for the ludhiana district the crop model was run and the simulated results were calibrated with the modification factor the simulation start date was selected as june 10 and the yield forecast date as july 25 2010 the yield forecast mode was run using cpt cca was selected for the forecast statistical method and sst for the gridded predictor file the training period for the statistical model was 24 years 1986 2009 and the yield forecast was conducted for each year using the predictor file containing sst fields for january 16 and for the forecasting year of 2010 fig 11 top for each grid cell the rice yield forecast for 2010 y ˆ 2010 was 4431 kg ha 1 with lead time of 2 months fig 11 bottom standard descriptive measures of goodness of fit and forecast accuracy were applied to evaluate the accuracy of rice yield predictions including rmse of prediction mean absolute error mae mean bias error mbe and mean absolute percentage error mape we evaluated the accuracy of rice yield predictions against available 1998 2009 observed yield the aggregated forecasted yield varied across years with a mean yield of 4435 kg ha 1 the errors associated with rice yield forecasts were occasionally very large such as 1998 and 1999 when residuals ε i were 1316 kg ha 1 and 1144 kg ha 1 respectively and absolute percentage errors of 41 8 and 34 2 the most accurate predictions were obtained for 2002 through 2006 with residuals of less than 150 kg ha 1 and forecast errors less than 3 4 the overall forecast accuracy measures such as rmse mae mbe and mape were 617 kg ha 1 439 kg ha 1 376 kg ha 1 and 12 3 respectively 6 discussion there has been an increased interest in spatial crop simulations in the past decade and at the same time greater availability of various global geospatial data sets from a wide variety of data collection platforms therefore there is a growing need for spatial crop simulation that employ tools and frameworks of different complexity and approaches including approaches that allow running existing field scale crop models on a spatial scale holzworth et al 2015 geographic information systems are often a logical part of such systems as they can effectively support with functionality related to shapes polygons etc geospatial data from diverse sources including soil management application and crop maps can be provided within the craft database as masks data are summarized in a format that permits realizations of the crop model simulations for each grid cell and then the toolbox provides functionality for easily performing the necessary geospatial data processing tasks and conducting spatial simulations statistical seasonal climate forecasts have successfully supported agricultural applications using various approaches these include historic analogs de jager et al 1998 hammer et al 2001 and combining gcm based seasonal rainfall forecasts with a crop model hansen et al 2004 mishra et al 2008 seasonal clime forecasts are somewhat constrained since the accuracy of statistical models is primarily limited by the length and quality of the historical observational record and by assumption on the stationarity of the climate system hansen et al 2004 a detailed review of advances in seasonal climate forecasting with a focus on agriculture is provided by klemm and mcpherson 2017 craft is integrated with seasonal climate forecasts along with historic and monitored weather data and other gridded data sets to produce probabilistic forecasts of crop yields and area aggregated production it incorporates multivariate statistical forecast using cpt to connect the predictable components of seasonal climate with the crop simulation instead of developing the downscaled seasonal forecast model on historic weather data it is developed from crop yields simulated with historic weather data therefore various methods of climate science and crop production forecasting are built into the toolbox the presented case studies demonstrate the main functionalities of craft as dssat has already been evaluated extensively for the study region it was selected as a crop model additionally varieties and cultivar coefficients in the case studies are taken from sources that already calibrated and evaluated dssat for their respective regions most importantly a lack of observed data limited our capacity to evaluate the simulations it is the user s responsibility to prepare detailed inputs for cases that are more comprehensive and such tasks are beyond of the scope of the current paper it is worth noting that several case studies have shown that the toolbox can help institutional stakeholders by providing useful and reliable information on the spatial and temporal variability of crop production and yield forecasts iwmi 2014 neksap 2016 17 stakeholder interaction and potential user involvement is crucial for development and future success of such system voinov et al 2016 volk et al 2010 therefore a wide range of stakeholders was involved to help develop the variety of objectives that are covered by the toolbox the feedback oriented development procedure ensured engagement with stakeholders during the entire project stakeholders gave feedback on the system structure the models and objectives as well on the design of the user interface training workshops with the potential users of the system gave additional insights in design improvements craft s main advantage over other systems is its integration of seasonal forecast with cpt by inclusion of historic monitored and forecast weather information sst fields and gcm outputs for regional forecasts made at any point in the growing season by using an ensemble of crop models dssat apsim sarra h and corresponding gis shape files on two spatial resolutions for any region the majority of the spatial simulations were carried out for 0 5 resolution grids the toolbox can also conduct simulations at a finer resolution of 0 083 operation of the system requires basic knowledge of gis type software visualization of the results considerably improves stakeholder interaction with the system the toolbox is not reliant upon a specific crop model and assumes that any supported crop models can be pre installed on the computer system this approach permits the software to be extended to different crop models for integration into craft a crop model should be able to communicate via ascii files to its input output and must be able to be called from the command line if these conditions are satisfied it takes advantage of the agmip data translator tool for crop model interoperability or the crop engine can be extended to this particular crop model to demonstrate this feature it was used to run an ensemble of crop models for the same geospatial data sets at a field site although the models had somewhat different data input requirements the toolbox was able to manipulate the input data to conform to the model requirements and conduct simulations across the region with each model shelia et al 2018 craft is a freely accessible windows desktop application that can be easily deployed using the installation tool its flexibility permits modelers and researchers with diverse objectives to combine geospatial data processing with their modeling analyses the software description and case studies provided herein demonstrate possible applications that include risk assessment related to crop production and yield forecast as well as the impact of climate change projections on yield and the potential for adaptation using different crop management scenarios the main shortcoming of the toolbox is its inability to run multithreaded simulations as a result time to run multiple simulations may vary significantly depending upon the area of interest therefore craft is best recommended for country and or regional level scale that are relevant to food security early warning and market applications the functionalities to generate and upload schema require the esri arcgis version 10 1 or higher which can be considered as a limitation the current database already contains schemas at three administrative levels for several asian countries for future releases the number of supported countries will be increased and additionally alternate options working with a schema will be provided via r https www r project org and gdal https www gdal org spatial libraries future development plans include extending the number of crop models incorporating an additional crop model such as infocrop aggarwal et al 2006 to make the toolbox a cross platform system we intend to use mono an open source implementation of microsoft s net framework by xamarin microsoft http www mono project com in the future we are also planning to establish a repository for open source development of craft 7 summary and conclusions craft offers an integrated modeling framework for within season yield forecasting risk analysis and climate change impact studies the core of the system is based on three tiers the user interface computation modules and the database the toolbox provides support for spatial data through the use of 5 and 30 arc minutes resolution grids in the current version of craft the crop simulations are based on dssat apsim and sarra h however any crop model for which an agmip data translator has been developed can be used the toolbox integrates seasonal climate forecasts using the cpt engine crop model calibration uses historic agricultural statistics for regional yield craft provides spatial aggregation and probabilistic analysis of the forecast uncertainty and visualization of the results using thematic maps although the toolbox can be used for simulations on the global scale its primary use is at the country or regional scale craft has been designed to address the needs of planners and policy makers by offering improved access to a platform that simulates crop production systems using an ensemble of models the case studies show that it can help a diverse range of stakeholders regional policy makers government agencies and researchers by providing reliable information on the spatial and temporal variability of crop production thus enabling improved risk management for agriculture associated with increasing climate variability acknowledgements we are very grateful to dr simon mason iri for his contribution in craft development and especially in cpt implementation the final product has greatly benefited from his expertise this project was implemented by the university of florida in collaboration with the international research institute for climate and society iri the asia risk centre and washington state university it is part of the cgiar research program on climate change agriculture and food security ccafs which is carried out with support from the cgiar trust fund and through bilateral funding agreements for details please visit https ccafs cgiar org donors the views expressed in this document cannot be taken to reflect the official opinions of these organizations software availability name of the software craft ccafs regional agricultural forecasting toolbox developer university of florida in cooperation with iri and ccafs contact address department of agricultural and biological engineering university of florida gainesville florida 32611 usa phone 1 352 392 1864 e mail vakhtang shelia ufl edu year first available 2014 hardware required desktop laptop with 2 5 ghz cpu 6 gb ram hdd with 70 gb or more free space software required arcgis version 10 1 or higher program languages and database c java mysql platform ms windows 7 8 10 program size with the sample db 3 63 gb availability and cost freely available https dssat net s craft submit x 0 submit y 0 appendix a list of abbreviations aegis agricultural and environmental geographic information system agmip the agricultural model intercomparison and improvement project api application programming interface apsim the agricultural production systems simulator bioma biophysical models applications framework cca canonical correlation analysis ccafs cgiar research program on climate change agriculture and food security cdf cumulative density function cgiar consultative group for international agricultural research craft ccafs regional agricultural forecasting toolbox cpt climate predictability tool csm cropping system model dssat decision support system for agrotechnology transfer dto data transfer object eof empirical orthogonal functions eu european union gcm general circulation model gis geographic information system gui graphical user interface id identification number ifpri international food policy research institute iri international research institute for climate and society jrc joint research centre mvvm model view viewmodel ngo non governmental organization pc principal component pcr principal components regression psims parallel system for integrating impacts models and sectors rmse root mean square error sarra h system for regional analysis of agro climatic risks sst sea surface temperature wpf windows presentation foundation 
