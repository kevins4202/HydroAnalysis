index,text
25900,storm water management model swmm a hydrodynamic rainfall runoff and urban drainage simulation model is widely applied in planning analysis and design it is worth mentioning that the hydrological and hydrodynamic simulation functions of swmm can also provide decision support for real time urban stormwater management however it remains challenging to directly apply traditional swmm to real time urban stormwater management based on web technology here we designed and implemented a web service framework based on swmm web swmm which can provide real time computing services for urban water management to test the functionality efficiency and stability of the web swmm web swmm was applied to an urban area in china test results show that web swmm could provide real time computing services stably quickly and accurately in general the implementation of web swmm enables traditional swmm to be quickly and efficiently applied in real time urban stormwater management what is more the web based hydrological model framework proposed in this paper also applicable to most existing hydrological models keywords swmm model urban stormwater management web services real time computing 1 introduction nowadays urban flooding due to global climate change population growth urbanization and maladaptive drainage systems jamali et al 2020 mignot et al 2019 rezende et al 2019 zhou et al 2019 has become a problem we have to face in the past few decades urban flooding has caused considerable damage to many cities around the world hammond et al 2015 wang et al 2019 for example a torrential storm event in beijing in july 2012 led to 79 deaths and a loss of 1 86 billion tan et al 2019 these colossal losses are warning us that it is urgent to reduce the harm of urban flooding urban water management is not only an essential aspect of sustainable urban development nguyen et al 2019 but also a crucial non engineering measure to mitigate urban flooding loss van den brandeler et al 2019 urban water management covers all components of the urban water system such as water supply godskesen et al 2013 wastewater delre et al 2019 and stormwater brudler et al 2019 among them stormwater from storm event is the leading cause of urban flooding therefore it is necessary for us to focus on urban stormwater management web based applications have an advantage in urban water management over desktop based applications the development of urban water management has benefited from the rapid growth of computer software and communication technologies these revolutionary technologies make urban water management gradually become more and more intelligent nguyen et al 2018 sharvelle et al 2017 wu et al 2020 yuan et al 2019 urban water managers can control water management processes such as data acquisition data assimilation model calculation information release and data analysis through applications deployed on the computer kurtz et al 2017 by querying these applications urban water managers can quickly obtain the real time status of runoff and water quality in a specific urban area no doubt these applications play a crucial role for urban water managers to make correct decisions in the past 20 years a significant amount of applications had been applied to water management and have achieved excellent results chen et al 2010 glass et al 2018 perera et al 2005 puigjaner et al 2000 depending on how these applications are deployed they can be categorized as client side desktop applications and client side web applications large numbers of practical experience have proven that client side web applications can provide a more responsive and interactive user experience brendel et al 2019 kanwar et al 2010 zhang et al 2019 besides some simulation modelers also have realized the potential advantages of using the web as a platform for simulation modeling byrne et al 2010 glass et al 2018 walker and chapra 2014 in general web based applications have become a trend in application development and the development of applications that provide decision support for urban stormwater management is no exception real time urban stormwater management provides essential information for real time response to the storm event practices have proved that real time is essential not only for control of urban drainage systems garcia et al 2015 and flood forecasting barbetta et al 2018 xu et al 2017 but also for urban stormwater management kurtz et al 2017 the loss of property and life will be caused by our failure to take adequate measures on time when a storm event occurs nevertheless the occurrence of urban water problems such as urban flooding water pollution and pipeline leaks is uncertain and random therefore it is challenging to be able to take measures quickly to deal with urban water problems that may occur at any time to make sure that we can take action as soon as possible the decision support provided by the urban stormwater management application should be as real time as possible real time urban stormwater management requires mathematical models to provide decision support bakhtiari et al 2020 ghodsi et al 2016 pena guzman et al 2017 pingale et al 2014 as we all know data is the foundation of management every decision made by urban water managers requires much data to support it although we can obtain some data through data collection equipment such as water level meter flow meter and the meteorological station the data obtained in this way are limited and expensive instead we can get more valuable information by combining mathematical models with data acquisition equipment which is a more economical way storm water management model swmm developed by the united states environmental protection agency us epa is a dynamic precipitation runoff simulation model used to simulate a single precipitation event or long term water and water quality simulation in urban areas gironas et al 2010 swmm has been extensively applied in planning analysis and design rossman 2009 it is worth mentioning that the swmm s functions including drainage simulation and runoff amount simulation also can provide scientific decision support for urban stormwater management babaei et al 2018 beck et al 2017 cun et al 2019 raei et al 2019 however it is challenging to directly apply the swmm to real time urban stormwater management based on web technology the main reasons for this difficulty are summarized as follows swmm a client side desktop application can neither provide web services or exchange data with other applications swmm cannot provide real time computing services for real time urban stormwater management it is challenging to apply swmm to real time urban stormwater management by modifying the model source code herein we designed and developed the web swmm which can provide decision support for real time urban stormwater management based on web technology web swmm with web service functions is built using a microservice framework spring boot https spring io projects spring boot and uses mybatis https mybatis org mybatis 3 as a persistence layer framework to implement the real time computing function of swmm we designed four modules including a data acquisition equipment module the model database module the external database module and an urban water management system module the coordinated operation of the four modules ensures the regular running of web swmm besides we designed four core tasks for web swmm to implement the coordinated operation of the above four modules web swmm was applied to an urban area in china and test results demonstrate that web swmm could provide real time computing services stably quickly and accurately for real time urban stormwater management the purpose of designing and implementing web swmm mainly includes two aspects when a storm event occurs in the city urban water managers have to take adequate protective measures to avoid losses the real time hydrological and hydraulic status information of rainwater pipe networks sub catchments and natural channels in urban areas plays a vital role in formulating measures for urban water managers however swmm which is good at modeling cannot provide the above mentioned important information to urban water managers in real time therefore the primary purpose of this article is to develop an swmm based web service framework that can provide real time hydrological and hydraulic status information of sub catchments rainwater pipe networks and rivers in urban areas for real time urban storm management to test the function efficiency and stability of web swmm web swmm was applied to urban areas in china it is worth noting that some excellent hydrological models such as hspf yazdi et al 2019a mike she demetriou and punthakey 1999 modflow jones 1997 and swat arnold et al 1998 are also facing problems that are difficult to apply in real time urban water management therefore the second purpose of this article is to provide demonstration and reference for the application of more hydrological models in real time urban water management 2 design and implementation of web swmm web swmm is a web server framework that provides decision support for real time urban stormwater management rather than a new hydrological model that can replace swmm as shown in fig 1 urban water managers can access the urban water management system uwms to obtain the decision support provided by web swmm the successful running of web swmm also requires the cooperation of four modules including the uwms module data acquisition da module basic database bdb module and model database mdb module fig 1 shows these modules and the collaborative relationship between each module below we will briefly introduce the collaboration relationship between each module and the detailed functionality of each module 2 1 collaborative relationship between modules the four modules da bdb mdb and umws are the basis for the successful running of web swmm the occurrence of storm event is random and uncertain therefore only by continuously monitoring the object of urban water management in real time can we find the urban water problems which may occur at any time to monitor the city s water status in real time web swmm needs to be on call in other words web swmm will run uninterrupted after startup unless web swmm is forced to terminate as shown in fig 1 multiple urban water managers n users shown in fig 1 interact directly with uwms according to their particular needs for example urban water managers want to obtain real time hydrological and hydraulic status information of rainwater pipe networks sub catchment and natural channels within their jurisdiction when the request from user 1 for uwms requires support from swmm uwms will send a hypertext transfer protocol http request to web swmm web swmm will quickly respond to the specific request of uwms after web swmm receives a request from uwms as can be seen from the service request process web swmm is passively triggered and needs to be ready to wait for requests from uwms at any time web swmm supports concurrent access which means that web swmm allows uwms to send multiple service requests at the same time the ability to access concurrently ensures that multiple users can work at the same time which dramatically improves user productivity in general the main functions of the da module bdb module and mdb module include the following two aspects 1 providing input data for running swmm 2 managing various data required to maintain the regular running of web swmm 2 2 description of four modules 2 2 1 da module da is a module for measuring hydrological and meteorological data hydrological data which mainly include surface water groundwater water quality data and the lake terrain can be monitored by rain sensors water gauges flow meters industrial cameras or other instrument transmitters meteorological data are a series of weather reflecting data to obtain valuable meteorological data many countries around the world have established various types of meteorological observatories such as ground stations sounding stations and automatic meteorological stations most of the judgments and decisions of urban water managers are based on these basic data therefore ensuring the accuracy of data from the da module is particularly crucial for web swmm 2 2 2 bdb module bdb is a module for storing data such as hydrological data meteorological data and equipment information data etc the above data are measured by the monitoring equipment in the da module also these data are updated in real time as the monitoring equipment is updated this operation of updating data in real time ensures the real time performance of model calculation bdb sets different access rights for different users web swmm can only perform data selection operation on bdb and users who provide data to bdb have all access rights to bdb this method of setting access rights is also to make sure that the security of data 2 2 3 mdb module mdb is a module dedicated to storing the model input and output data among them the swmm calculation results are the model output data and the basic data required to drive the swmm are the model input data the same as bdb mdb sets different access rights for different users web swmm can perform operations of adding deleting updating and selecting data in mdb during the running of web swmm web swmm will frequently access the mdb so that mdb has relatively high access pressure 2 2 4 uwms module the system that is applied to urban water management can be called uwms which is used in scenarios such as water quality management rainstorm and flood management and drainage network management as shown in fig 1 uwms contains multiple subsystems each with different functions and access rights for example the wastewater management system jung et al 2018 and the flood forecast system adams and dymond 2019 yuan et al 2018 are both sub systems in uwms however only the environmental protection department has the authority to access the wastewater management system and the real time flood forecast system can only be accessed by the hydrological department the division of function and management authority makes urban water management more detailed and reasonable which will help to improve the quality and efficiency of urban water management uwms integrates urban water information from multiple terminals including hydrologic related basic data monitoring data and simulation data etc these data integrated into uwms can provide a scientific basis for the decision of urban water management to sum up uwms is a management system that integrates water information from multiple sources and the function of web swmm is to enable swmm to provide real time rainstorm and flood information to uwms thus providing new decision support for users in urban water management 2 3 four core tasks of web swmm the four tasks as shown in fig 2 guarantee the regular running of web swmm before describing each task in detail it is necessary to introduce the relationship between the tasks and the modules data acquisition and processing task task 1 obtains the hydrological or meteorological data needed to run swmm from bdb task 1 1 and then stores these pre processed model input data into mdb task 1 2 these hydrological or meteorological data stored in mdb will be used when executing model calculation and results storage task task 3 computing service task task 2 is responsible for providing computing services for uwms when a user sends an http request to uwms that requires swmm to provide computing support uwms will send an http request to web swmm and computing service task task 2 will start immediately the time it takes for web swmm to receive an http request from uwms and return a request to uwms is called service response time srt the short srt will give users a better experience so we must spare no effort to reduce the srt to reduce the srt web swmm continuously updates the simulation results stored in the mdb and data is pulled from the mdb when users make a request in the uwms computing service task task 2 gets data from mdb task 2 1 and then return these data to uwms task 2 2 model calculation and results storage task task 3 is designed to store the results of swmm in the mdb in advance and these model output data stored in the mdb will be offered to computing service task task 2 for use during the running of web swmm a large amount of data will be continuously stored in the mdb however the capacity of mdb is limited so we need to manage the data reasonably we designed the data management task that periodically deletes historical data from mdb to address this issue the input data stored in mdb includes not only basic data including land cover data dem data and rainwater pipe network data that do not change with time but also rainfall water level and flow data that change with time as shown in table 1 the swmm simulation object consists of five basic units junction link outfall sub catchment and section among them junction link and outfall are the three main components of the rainwater pipe network the output data stored in mdb contains the time series results and summary results of each swmm simulation object and each type of object contains multiple parameters the above output data will support real time decision making of urban stormwater management 2 3 1 data acquisition and processing task 2 3 1 1 implementation web swmm mainly includes the following three numerical simulation functions 1 hydrological simulation of sub catchments 2 hydraulic simulation of rainwater pipe network 3 hydraulic simulation of natural channels the operation of the above three simulation functions requires input data and output data will also be generated as shown in fig 4 we established eight database tables for storing model input and output data among them three database tables including obs rainfall obs waterlevel and obs discharge are used to store the rainfall water level and discharge data recorded by the observation station respectively the data stored in the above database tables are not obtained directly from the observation equipment but the bdb the remaining five database tables are used to store the calculation results of swmm among them the database tables res junctions res outfalls and res conduits are used to store hydraulic simulation results of the rainwater pipe network the database table res subcatchments is used to store hydrological simulation results of the sub catchments and the database table res sections is used to store hydraulic simulation results of natural channels the primary function of data acquisition and processing task is to obtain and process the input data required for model calculation specifically data acquisition and processing task will continuously preprocess the observation data obtained from the bdb and then store them in the database tables obs rainfall obs waterlevel and obs discharge also the primary function of data management task is to delete the data in the eight database tables shown in fig 4 according to the rules set in advance 2 3 1 2 workflow design data acquisition and processing task starts running as the web swmm is started and stops running as web swmm stops fig 5 shows how data acquisition and processing task runs and the detailed steps for data acquisition and processing task are as follows in step 3 t1 1 t1 2 indicates that there is a new data update in the model input table of bdb otherwise there is no data update data updates in the bdb are intermittent because the data measured by the monitoring device in the da module is discontinuous for example water level and discharge monitoring devices are typically measured every 5 min so the hydrological data stored in the bdb take at least 5 min to be updated if the wait time in step 5 is set to zero data acquisition and processing task will be executed multiple times within 5 min however data acquisition and processing task can obtain new data from the bdb only once in multiple runs within 5 min therefore setting the task waiting step can reduce the number of invalid executions of data acquisition and processing task and also greatly reduce the pressure of database access task waiting time is generally equal to the data update time in bdb 2 3 2 computing service task 2 3 2 1 implementation the implementation of the computing service task faces two problems 1 how to publish web services 2 how to exchange data between uwms and web swmm for question 1 the tomcat server enables the computing service task to provide external web services for question 2 data is transferred between uwms and web swmm using json javascript object notation format data json is a lightweight data exchange format the concise and clear hierarchy makes json an ideal data exchange language to meet the needs of users the computing service task provides the following web services 1 obtain the hydraulic simulation results of the rainwater pipe network 2 obtain the hydrological simulation results of the sub catchment 3 obtain the hydraulic simulation results of the natural channel 4 obtain the summary results of all the above simulation objects in short we can get the model calculation results that traditional desktop software swmm can provide from web swmm 2 3 2 2 workflow design computing service task is triggered when uwms sends an http request to web swmm http request sent by uwms carries request information related to the actual needs of users the request information consists of three main aspects the steps of computing service task are described in the below see fig 6 step 1 computing service task starts running after uwms sends an http request to web swmm step 2 get data from mdb according to uwms request conditions step 3 return the data obtained from mdb to uwms step 4 end of computing service task computing service task supports concurrent access which enables uwms to send multiple http requests to web swmm at the same time 2 3 3 model calculation and results storage task 2 3 3 1 implementation as shown in fig 7 preparing data running model and storing data are the main processes of model calculation and results storage task the file with the file extension inp is an input file that contains the attribute data ad and measurement data md required to run the swmm data that does not change over time such as the area of the catchment the number of pipes and the shape of the cross section are attribute data on the contrary data such as rainfall water level and discharge that change with time are measurement data which are measured by monitoring stations in order to reduce the number of invalid accesses to data files by web swmm we use the ad file and md file to store attribute data and measurement data separately the data in the md file is obtained from the mdb while the data in the ad file is obtained from the water management bureau merge the ad file and md file to generate an input file with the inp as the extension which is the swmm input file the end time of swmm simulation is the time corresponding to the latest rainfall water level and flow data measured in each station and stored in the mdb the length of the simulation period is 3 h in other words we use the rainfall water level and flow data in the last 3 h as the input of swmm besides the time step of the swmm simulation and the measurement time interval of the monitoring station are both 5 min swmm developers provide a dynamic link library swmm dll and an executable program swmm exe for users to invoke in this paper we run swmm by invoking the swmm numerical engine swmm dll the two files with the file extensions out and rpt are the two output files generated after the swmm simulation ends among them the binary file with the file extension out completely records the time series results of swmm and the file with rpt as the file extension records the summary results of swmm fig 8 shows seven functions for java developers to invoke by invoking these functions we can get the following information 1 the summary results and time series results of swmm 2 the length of the period 3 the number of objects junctions outfalls conduits sub catchments and sections simultaneously we can implement the two functions by invoking these functions shown in fig 8 1 run swmm 2 open the binary file that stores the time series results of swmm the summary results and time series results obtained from the output file of the swmm simulation are finally stored in the mdb see fig 9 2 3 3 2 workflow design model calculation and results storage task is responsible for the model calculation and storing model calculation results the steps of this task are described in the below in step 6 of saving the calculation result to the database an error may occur in which the primary key of the database is duplicated the main reason for this error is that some of the data saved in the mdb may already exist we address this issue by covering the historical data with the latest calculation results 2 3 4 data management task 2 3 4 1 implementation the real time simulation results of swmm in web swmm are saved in the five database tables res junctions res outfalls res conduits res sections and res subcatchments shown in fig 4 these database tables in mdb continuously receive data from web swmm during web swmm running however the storage space of the mdb is limited to solve the above problems we limit the database tables that store smmm simulation results in mdb to store only the most recent period of time data we set the time parameter to 72 h which means that these data tables storing swmm simulation results can only store data within 72 h we implemented the above functions through the following methods after data acquisition and processing task model calculation and results storage task data management task and task waiting are executed once web swmm identifies data for more than 72 h by examining the data in the database table where the swmm simulation results are stored and then delete these data the following workflow design part will introduce in detail the method of how to identify which data in the database table is outside the past 72 h in addition we implement task waiting that are important for web swmm running through the thread sleep method provided by java 2 3 4 2 workflow design considering the limited memory of the mdb data management task will periodically clean up the historical data in the database before introducing the steps of the data management task we made some assumptions suppose we only keep the data in the last n hours in the mdb with m tables meanwhile assume that data management task is executed at time t 4 the steps of the data management task are described in the below the flow chart of data management task can be shown in fig 10 2 4 framework and development tools table 2 shows the frameworks and tools used to develop web swmm more details about these frameworks and tools can be learned by visiting the website provided in table 2 3 application of web swmm to test the function stability and efficiency of web swmm web swmm was applied to urban areas in detail the objectives of the web swmm application mainly include the following three aspects first verify whether the web swmm runs as designed secondly test the efficiency that web swmm provides to uwms finally compare the application of web swmm and swmm in urban rainwater management and summarize their respective advantages and disadvantages 3 1 study area and data the urban area which is located in the sucheng district see fig 11 a of suqian city in china was selected for testing web swmm it located within the geographical coordinates of 118 10 e to 118 33 e latitude and 33 47 n to 34 1 n longitude the 21 51 km2 study area approximately 57 of which is covered by open spaces and residential areas and spreads throughout an elevation range from 20 to 30 m above sea level fig 11 a and b show the distribution of land in the study area among them open spaces account for the largest portion of the total area 32 08 followed by residential areas 25 20 commercial areas 18 30 and roads 16 27 the smallest proportions in the total area are lawns 7 23 and stadiums 0 91 influenced by a monsoon climate precipitation mainly occurs in spring and summer the long term annual mean temperature and precipitation are 14 1 c and 892 3 mm respectively also the annual mean sunshine and total solar radiations are 2315 h and 117 kcal cm2 respectively fig 12 shows the monthly average rainfall of suqian city in 2019 july had the largest rainfall 219 2 mm and the total rainfall in 2019 was 1020 6 mm the basic data required for swmm including the land cover data 5 m 5 m dem data 5 m 5 m and the rainwater pipe network data provided by suqian water management bureau the rainfall data recorded by an automated meteorological station the discharge data measured by stream gauge stations the water level data measured by water level station both stream gauge stations and water level stations were installed on the natural channel the above data were essential for swmm modeling these basic data were preprocessed to meet the requirements of swmm modeling according to the rainwater pipe network and land cover types the study area has been discretized into 956 sub catchments by the thiessen polygon method damant et al 1983 first we combined the terrain natural channels and main streets to delineate larger sub basins secondly we used the tyson polygon method to further subdivide the sub catchment according to node distribution finally some adjustments were made according to the actual engineering situation sub catchments are hydrologic units of study area whose topography and the rainwater pipe network elements direct surface runoff to a single discharge point junction outfall and conduit are three principal components of the rainwater pipe network fig 13 shows that the entire rainwater pipe network consists of 5033 junctions 177 outfalls and 5266 conduits the natural channels in the study area were obtained using the arcgis software and srtm data more details on the above data are presented in fig 13 a heavy rainfall event see fig 14 a measured by the meteorological station r01 were used as the inputs to the hydrological and hydraulic simulations of sub catchments and rainwater pipe network respectively moreover the hydrological data measured by the water level station w01 and stream gauge stations s01 s02 and s03 were used as inputs for the hydraulic modeling of the natural channels among them the hydrological data measured by s01 s03 and w01 were used as a boundary condition for hydraulic modeling and the discharge data measured by s02 were used to validate the calculation results of the model the above precipitation and hydrological data were collected at the field stations within the period from 9 00 a m on june 18 2019 to 12 00 a m on june 18 2019 and measured with time intervals of 5 min more detail on these measurement data is presented in fig 14 3 2 installation and configuration of web swmm web swmm needs to be deployed on a computer to run table 3 shows the configuration of the computer used to deploy web swwm during testing in this paper besides web swmm needs internet support when receiving and sending http requests table 3 shows the configuration of the web proxy used for testing before deploying web swmm maven tomcat and java virtual machines had been installed and configured on this computer because the performance of web swmm in different configurations of computers and network environments may be different the test results of web swmm only represent the performance in the test environment shown in table 3 3 3 results and discussion 3 3 1 running process of web swmm as shown in fig 15 data acquisition and processing task model calculation and results storage task and data management task started running with the start of web swmm the window shown in fig 15 completely presented the running process of these tasks records show that data acquisition and processing task took one rainfall data one water level and one discharge data from the bdb and then stored them in the mdb the monitoring station shown in fig 13 measured these new data model calculation and results storage task got the rainfall data the water level data and the discharge data from the mdb for the last 3 h and then wrote them to the md file subsequently model calculation and results storage task generated an input data file for driving the swmm by merging the md file and ad file prepared in advance after completing the data preparation model calculation and results storage task run swmm by invoking the swmm numerical engine swmm dll and then stored the model calculation results to the mdb before running data management task the time parameter of data management task had been set to 72 h which means that the tables used to store model input and output data only store data within the last 72 h because these tables did not store data monitored before 72 h ago the number of deleted data in each table was zero after running three tasks web swmm waited for 60 s before continuing to run at this point web swmm had been successfully run once running results show that the above three tasks are being performed according to the design scheme as shown in fig 15 the total time spent in task execution and task waiting of web swmm is 301 s which slightly larger than the time intervals of updating measured data in bdb that is after the web swmm runs once there must be a new measured data update in the bdb when the monitoring equipment is working properly as expected test results show that web swmm successfully obtained one rainfall data one water level and one discharge data from bdb when executing data acquisition and processing task for the second time on the contrary if there is no task waiting in web swmm then the total time it takes for web swmm to execute once will be reduced from 301 s to 241 s obviously the measured data in the bdb has not been updated when the web swmm is rerun therefore the design of the task waiting in web swmm is necessary and reasonable records show that model calculation and results storage task took nearly 3 min to run the swmm if the web swmm is returning the simulation results obtained by running swmm in real time to the uwms then uwms will take at least 3 min to get feedback form web swmm after making an http request to web swmm such a long srt is unacceptable for users visiting uwms obviously it is more appropriate for web swmm to get pre stored data from mdb and return it to uwms it can be seen from the test results that the design of task waiting improves the success rate of data acquisition and processing task in acquiring new data moreover data acquisition and processing task provides continuous input data for the running of model calculation and results storage task and data management task make sure mdb has enough space for data storage overall the design of three tasks is reasonable and the three tasks cooperation ensures that web swmm can run regularly 3 3 2 test results and discussion of computing service task postman a software used to debug and send http requests for web pages was used to test the performance of web swmm postman plays the role of uwms in web swmm testing the study area used to test includes both ground and underground parts the sub catchments and natural channels cover the ground and the rainwater pipe network shown in fig 13 is distributed underground in the following we will present and discuss the rainwater pipe network s test results sub catchments and natural channels 3 3 2 1 rainwater pipe network thirty six objects see fig 16 representing the rainwater pipe network were selected to participate in the test for the computing service task specifically test objects include 8 outfalls 15 conduits and 13 junctions before sending an http request to web swmm some parameters were set as shown in fig 17 b the time parameter hour in the http request was set to 3 h and the ids of the test object was specified the time parameter can also be set by giving the start and end time see fig 17 a after sending an http request to web swmm we quickly got the request result shown in fig 17 in fact the request result obtained from web swmm are data in json format to show them more intuitively we plotted the json format data into curves shown in fig 17 fig 17 a shows the process of water depth and total inflow within nearly 3 h at each of the 8 outfalls fig 17 b shows the process of flow rate and capacity within nearly 3 h at each of the 15 conduits fig 17 c shows the process of water depth and total inflow within nearly 3 h at each of the 13 junctions according to the data obtained from web swmm urban water managers can accurately understand the rainwater pipe network s real time state which is of great significance to fine management as shown in fig 17 the request time of each http request is greater than the latest time of the request result as shown in fig 17 c the http request was sent at 12 03 00 p m on june 18 2019 however the newest time for the request result returned by web swmm was 12 00 00 p m on june 18 2019 the reason for the time mentioned above delay is that the data measurement of the monitoring equipment has time intervals and data transmission also takes time it turns out that we cannot get real time computing services due to monitoring equipment constraints but we can minimize data latency as much as possible overall all tests are being performed according to the design scheme the rainwater pipe network often overflows and overloads during heavy rains uwms can obtain real time status information of conduits junctions and outfalls in the rainwater pipe network through web swmm real time status information can be used to analyze the rainwater pipe network s overflow and overload situation besides the historical status information of each rainwater pipe network can be used to complete the following important work 1 analyze the overflow and overload status of the rainwater pipe network 2 summarize the reasons for the insufficient drainage capacity of the pipeline 3 explore measures to improve the drainage capacity of the drainage network system 4 propose the optimal design scheme of the rainwater pipe network it can be seen that these data can provide guidance for real time urban stormwater management and provide scientific support for the optimization and transformation of rainwater pipe networks 3 3 2 2 natural channels the natural channels shown in fig 18 a was selected as a test object the stream gauge station s02 was installed on the section sec034 of the natural channel the cross sectional shape of this section is shown in fig 18 a the water level data and discharge data recorded by monitoring stations provided boundary conditions for the hydraulic calculation of natural channels and the discharge data measured by s02 was used to verify the model calculation results of sec034 in addition to the above data 77 sections measured manually were also essential data for hydraulic modeling as shown in fig 18 b we sent a get request to web swmm the time parameter hour in the request was set to 3 h and the parameter ids was set to sec034 the http request was sent at 12 04 25 p m on june 18 2019 and web swmm returned the discharge process of sec034 in the period from 9 a m to 12 a m on june 18 2019 the latest time 12 a m june 18 2019 of the results returned by web swmm is less than the time the http request was sent as with the rainwater pipe network s test results the results returned by web swmm in this test were also delayed fig 18 b shows the discharge data of the sec034 returned by the web swmm to evaluate the model s performance the nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 was used to estimate the goodness of fit the nash sutcliffe efficiency coefficient proposed by nash and sutcliffe is expressed as n s e 1 q i q ˆ i 2 q i q c 2 100 where q i is the observed discharge m3 s q ˆ i is the simulated discharge m3 s and q c is the mean observed discharge m3 s nash sutcliffe efficiency coefficient corresponding to sec034 was 0 85 which was greater than 70 it indicated that swmm performed well in the hydraulic calculation of the natural channels urban water managers can determine the performance of swmm by comparing the observed discharge with the simulated discharge and can also be used to calibrate the swmm urban water managers set a warning level for important rivers in china when the river s water level exceeds the warning level water managers will take timely flood prevention measures uwms can obtain the water level of the river section from web swmm in real time when the real time water level of a section exceeds the river s warning water level uwms can send an early warning message to water managers to remind water managers to take flood control measures 3 3 2 3 sub catchments as shown in fig 19 a eight sub catchments in the study area were selected for testing infiltration capacity and flow as shown in fig 19 b are the two physical parameters that characterize sub catchment fig 17 a shows the process of infiltration loss and runoff flow within nearly 3 h at each of the 8 sub catchments by analyzing the calculation results fed back by web swmm in real time urban water managers can work out more effective flood prevention and disaster reduction measures as shown in fig 19 b we sent a post request to web swmm the time parameter hour in the request was set to 3 h and the parameter id was set the http request was sent at 12 03 50 p m on june 18 2019 and web swmm returned the results from 9 00 00 a m to 12 00 00 a m on june 18 2019 obviously the result returned by web swmm has a delay of 230 s as with the delay of the rainwater pipe network and natural channels delays in sub catchments testing are caused by time intervals and monitoring equipment transmission the larger impervious area with a high runoff peak in the sub catchments is generally potentially flood prone uwms can obtain real time information on the peak runoff distribution of the sub catchments by accessing web swmm and then feed this information back to the urban water managers urban water managers should focus on these areas when obtaining this critical information from uwms and then take timely flood control and drainage measures 3 3 3 efficiency analysis of computing service task fig 20 shows the srt of all test subjects participating in the test for the computing service task the average srt of all test subjects was 40 ms which is entirely acceptable to web swmm users throughout the testing process web swmm was able to respond quickly and stably to http requests issued by postman simultaneously swmm performed well in the hydrological and hydraulic simulation of rainwater pipe networks sub catchments and natural rivers although there have been delays in tests in the rainwater pipe network natural channels and sub catchments this delay is unavoidable after analysis and summary we found that the following three reasons caused the test delay 1 the time interval of data monitoring equipment 2 data transmission between modules 3 it takes time to run web swmm overall the computing service task s design is reasonable 3 3 4 comparison of web swmm and swmm a large number of practical applications show that swmm is an excellent hydrological model however swmm still has some disadvantages as the software used in practice traditional swmm a client side desktop application is primarily used for planning analysis and design limited by the software architecture of swmm we can only use pre prepared historical data for swmm modeling when the application scenario of the model changes we must prepare new model input data the data preparation process requires manual operation so that the swmm is not suitable for modeling under the real time change scenario of input data this inefficient modeling and model calculation method cannot meet the application requirements for a complex urban water environment that is continuously changing compared with the traditional swmm the web swmm designed and implemented in this paper has the following advantages web swmm provides an interface for browsers to access to interact with other applications very conveniently web swmm which can be connected to the database can meet the real time simulation requirements of swmm the client web application web swmm is easier to deploy and install than the client desktop application swmm traditional swmm also has its advantages for example swmm has a significant advantage in modeling because of its friendly interface besides swmm has all the benefits that client desktop applications have web swmm is a web server framework that can make swmm more widely used rather than a new hydrological model that can replace swmm we did not specially design and developed a graphical user interface for web swmm the main reason is that web swmm is not a software for urban water managers directly but a service framework that provides services for uwms the main contribution web swmm can make to provide an excellent convenience for application developers who do not understand the complex principles of swmm with the advantages of web swmm developers can also develop more excellent urban water management applications in general web swmm and swmm need to be used together to play their respective advantages 4 conclusions we designed and developed web swmm for the purpose that swmm can be easily applied to real time urban stormwater management based on web technology web swmm is a framework for providing web services in the form of a web url in general the case study of sucheng district proves the applicability of web swmm in real time urban stormwater management specifically we obtained the following important conclusions web swmm could provide real time computing services stably quickly average srt less than 40 ms and accurately web swmm provides multiple interfaces for external access through http requests these interfaces enable web swmm to provide web services and exchange data with other applications web swmm connected with data monitoring equipment and database can obtain real time data in the study area thereby ensuring that swmm can provide real time computing services due to the time interval and data transmission of the monitoring equipment there is a delay when the user obtains the swmm simulation results through uwms which is inevitable and acceptable the web swmm proposed in this paper is not a theoretical improvement of swmm but makes the traditional swmm more suitable for urban stormwater management in applying swmm to practice we fully acknowledge the performance of swmm and regret the shortcomings of swmm this paper is to make up for the shortage of swmm in urban stormwater management applications we designed and implemented only some of the simulation functions of swmm in web swmm including hydrologic simulations of sub basins and hydraulic simulations of drainage networks and natural channel it is worth noting that swmm also has more functions such as water quality simulation yazdi et al 2019b and low impact development simulation zhu et al 2019 are not yet implemented in web swmm in the future we will continue to enhance the development of web swmm so that more swmm simulation functions can be applied to urban stormwater management besides we consider connecting meteorological data into web swmm to make web swmm have real time forecasting function which will provide more favorable decision support for urban stormwater management software and data availability program title web swmm developer zhiqiang zeng contact address zengzhiqiang hust edu cn source code available and data https github com zengzhiqianghust web swmm git program required internet browser tested on firefox chrome edge and internet explorer tomcat 8 5 33 jdk 1 8 0 maven 3 6 1 intellij idea 2019 3 4 used for secondary development test tool postman year first available 2019 program language java availability and cost open source declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national natural science foundation of china nos 52079101 51379080 open fund of hubei provincial key laboratory for operation and control of cascaded hydropower station in china three gorges university no 2019kjx02 and open fund of the state key laboratory of operation and control of renewable energy storage systems for china electric power research institute nyb51201901206 
25900,storm water management model swmm a hydrodynamic rainfall runoff and urban drainage simulation model is widely applied in planning analysis and design it is worth mentioning that the hydrological and hydrodynamic simulation functions of swmm can also provide decision support for real time urban stormwater management however it remains challenging to directly apply traditional swmm to real time urban stormwater management based on web technology here we designed and implemented a web service framework based on swmm web swmm which can provide real time computing services for urban water management to test the functionality efficiency and stability of the web swmm web swmm was applied to an urban area in china test results show that web swmm could provide real time computing services stably quickly and accurately in general the implementation of web swmm enables traditional swmm to be quickly and efficiently applied in real time urban stormwater management what is more the web based hydrological model framework proposed in this paper also applicable to most existing hydrological models keywords swmm model urban stormwater management web services real time computing 1 introduction nowadays urban flooding due to global climate change population growth urbanization and maladaptive drainage systems jamali et al 2020 mignot et al 2019 rezende et al 2019 zhou et al 2019 has become a problem we have to face in the past few decades urban flooding has caused considerable damage to many cities around the world hammond et al 2015 wang et al 2019 for example a torrential storm event in beijing in july 2012 led to 79 deaths and a loss of 1 86 billion tan et al 2019 these colossal losses are warning us that it is urgent to reduce the harm of urban flooding urban water management is not only an essential aspect of sustainable urban development nguyen et al 2019 but also a crucial non engineering measure to mitigate urban flooding loss van den brandeler et al 2019 urban water management covers all components of the urban water system such as water supply godskesen et al 2013 wastewater delre et al 2019 and stormwater brudler et al 2019 among them stormwater from storm event is the leading cause of urban flooding therefore it is necessary for us to focus on urban stormwater management web based applications have an advantage in urban water management over desktop based applications the development of urban water management has benefited from the rapid growth of computer software and communication technologies these revolutionary technologies make urban water management gradually become more and more intelligent nguyen et al 2018 sharvelle et al 2017 wu et al 2020 yuan et al 2019 urban water managers can control water management processes such as data acquisition data assimilation model calculation information release and data analysis through applications deployed on the computer kurtz et al 2017 by querying these applications urban water managers can quickly obtain the real time status of runoff and water quality in a specific urban area no doubt these applications play a crucial role for urban water managers to make correct decisions in the past 20 years a significant amount of applications had been applied to water management and have achieved excellent results chen et al 2010 glass et al 2018 perera et al 2005 puigjaner et al 2000 depending on how these applications are deployed they can be categorized as client side desktop applications and client side web applications large numbers of practical experience have proven that client side web applications can provide a more responsive and interactive user experience brendel et al 2019 kanwar et al 2010 zhang et al 2019 besides some simulation modelers also have realized the potential advantages of using the web as a platform for simulation modeling byrne et al 2010 glass et al 2018 walker and chapra 2014 in general web based applications have become a trend in application development and the development of applications that provide decision support for urban stormwater management is no exception real time urban stormwater management provides essential information for real time response to the storm event practices have proved that real time is essential not only for control of urban drainage systems garcia et al 2015 and flood forecasting barbetta et al 2018 xu et al 2017 but also for urban stormwater management kurtz et al 2017 the loss of property and life will be caused by our failure to take adequate measures on time when a storm event occurs nevertheless the occurrence of urban water problems such as urban flooding water pollution and pipeline leaks is uncertain and random therefore it is challenging to be able to take measures quickly to deal with urban water problems that may occur at any time to make sure that we can take action as soon as possible the decision support provided by the urban stormwater management application should be as real time as possible real time urban stormwater management requires mathematical models to provide decision support bakhtiari et al 2020 ghodsi et al 2016 pena guzman et al 2017 pingale et al 2014 as we all know data is the foundation of management every decision made by urban water managers requires much data to support it although we can obtain some data through data collection equipment such as water level meter flow meter and the meteorological station the data obtained in this way are limited and expensive instead we can get more valuable information by combining mathematical models with data acquisition equipment which is a more economical way storm water management model swmm developed by the united states environmental protection agency us epa is a dynamic precipitation runoff simulation model used to simulate a single precipitation event or long term water and water quality simulation in urban areas gironas et al 2010 swmm has been extensively applied in planning analysis and design rossman 2009 it is worth mentioning that the swmm s functions including drainage simulation and runoff amount simulation also can provide scientific decision support for urban stormwater management babaei et al 2018 beck et al 2017 cun et al 2019 raei et al 2019 however it is challenging to directly apply the swmm to real time urban stormwater management based on web technology the main reasons for this difficulty are summarized as follows swmm a client side desktop application can neither provide web services or exchange data with other applications swmm cannot provide real time computing services for real time urban stormwater management it is challenging to apply swmm to real time urban stormwater management by modifying the model source code herein we designed and developed the web swmm which can provide decision support for real time urban stormwater management based on web technology web swmm with web service functions is built using a microservice framework spring boot https spring io projects spring boot and uses mybatis https mybatis org mybatis 3 as a persistence layer framework to implement the real time computing function of swmm we designed four modules including a data acquisition equipment module the model database module the external database module and an urban water management system module the coordinated operation of the four modules ensures the regular running of web swmm besides we designed four core tasks for web swmm to implement the coordinated operation of the above four modules web swmm was applied to an urban area in china and test results demonstrate that web swmm could provide real time computing services stably quickly and accurately for real time urban stormwater management the purpose of designing and implementing web swmm mainly includes two aspects when a storm event occurs in the city urban water managers have to take adequate protective measures to avoid losses the real time hydrological and hydraulic status information of rainwater pipe networks sub catchments and natural channels in urban areas plays a vital role in formulating measures for urban water managers however swmm which is good at modeling cannot provide the above mentioned important information to urban water managers in real time therefore the primary purpose of this article is to develop an swmm based web service framework that can provide real time hydrological and hydraulic status information of sub catchments rainwater pipe networks and rivers in urban areas for real time urban storm management to test the function efficiency and stability of web swmm web swmm was applied to urban areas in china it is worth noting that some excellent hydrological models such as hspf yazdi et al 2019a mike she demetriou and punthakey 1999 modflow jones 1997 and swat arnold et al 1998 are also facing problems that are difficult to apply in real time urban water management therefore the second purpose of this article is to provide demonstration and reference for the application of more hydrological models in real time urban water management 2 design and implementation of web swmm web swmm is a web server framework that provides decision support for real time urban stormwater management rather than a new hydrological model that can replace swmm as shown in fig 1 urban water managers can access the urban water management system uwms to obtain the decision support provided by web swmm the successful running of web swmm also requires the cooperation of four modules including the uwms module data acquisition da module basic database bdb module and model database mdb module fig 1 shows these modules and the collaborative relationship between each module below we will briefly introduce the collaboration relationship between each module and the detailed functionality of each module 2 1 collaborative relationship between modules the four modules da bdb mdb and umws are the basis for the successful running of web swmm the occurrence of storm event is random and uncertain therefore only by continuously monitoring the object of urban water management in real time can we find the urban water problems which may occur at any time to monitor the city s water status in real time web swmm needs to be on call in other words web swmm will run uninterrupted after startup unless web swmm is forced to terminate as shown in fig 1 multiple urban water managers n users shown in fig 1 interact directly with uwms according to their particular needs for example urban water managers want to obtain real time hydrological and hydraulic status information of rainwater pipe networks sub catchment and natural channels within their jurisdiction when the request from user 1 for uwms requires support from swmm uwms will send a hypertext transfer protocol http request to web swmm web swmm will quickly respond to the specific request of uwms after web swmm receives a request from uwms as can be seen from the service request process web swmm is passively triggered and needs to be ready to wait for requests from uwms at any time web swmm supports concurrent access which means that web swmm allows uwms to send multiple service requests at the same time the ability to access concurrently ensures that multiple users can work at the same time which dramatically improves user productivity in general the main functions of the da module bdb module and mdb module include the following two aspects 1 providing input data for running swmm 2 managing various data required to maintain the regular running of web swmm 2 2 description of four modules 2 2 1 da module da is a module for measuring hydrological and meteorological data hydrological data which mainly include surface water groundwater water quality data and the lake terrain can be monitored by rain sensors water gauges flow meters industrial cameras or other instrument transmitters meteorological data are a series of weather reflecting data to obtain valuable meteorological data many countries around the world have established various types of meteorological observatories such as ground stations sounding stations and automatic meteorological stations most of the judgments and decisions of urban water managers are based on these basic data therefore ensuring the accuracy of data from the da module is particularly crucial for web swmm 2 2 2 bdb module bdb is a module for storing data such as hydrological data meteorological data and equipment information data etc the above data are measured by the monitoring equipment in the da module also these data are updated in real time as the monitoring equipment is updated this operation of updating data in real time ensures the real time performance of model calculation bdb sets different access rights for different users web swmm can only perform data selection operation on bdb and users who provide data to bdb have all access rights to bdb this method of setting access rights is also to make sure that the security of data 2 2 3 mdb module mdb is a module dedicated to storing the model input and output data among them the swmm calculation results are the model output data and the basic data required to drive the swmm are the model input data the same as bdb mdb sets different access rights for different users web swmm can perform operations of adding deleting updating and selecting data in mdb during the running of web swmm web swmm will frequently access the mdb so that mdb has relatively high access pressure 2 2 4 uwms module the system that is applied to urban water management can be called uwms which is used in scenarios such as water quality management rainstorm and flood management and drainage network management as shown in fig 1 uwms contains multiple subsystems each with different functions and access rights for example the wastewater management system jung et al 2018 and the flood forecast system adams and dymond 2019 yuan et al 2018 are both sub systems in uwms however only the environmental protection department has the authority to access the wastewater management system and the real time flood forecast system can only be accessed by the hydrological department the division of function and management authority makes urban water management more detailed and reasonable which will help to improve the quality and efficiency of urban water management uwms integrates urban water information from multiple terminals including hydrologic related basic data monitoring data and simulation data etc these data integrated into uwms can provide a scientific basis for the decision of urban water management to sum up uwms is a management system that integrates water information from multiple sources and the function of web swmm is to enable swmm to provide real time rainstorm and flood information to uwms thus providing new decision support for users in urban water management 2 3 four core tasks of web swmm the four tasks as shown in fig 2 guarantee the regular running of web swmm before describing each task in detail it is necessary to introduce the relationship between the tasks and the modules data acquisition and processing task task 1 obtains the hydrological or meteorological data needed to run swmm from bdb task 1 1 and then stores these pre processed model input data into mdb task 1 2 these hydrological or meteorological data stored in mdb will be used when executing model calculation and results storage task task 3 computing service task task 2 is responsible for providing computing services for uwms when a user sends an http request to uwms that requires swmm to provide computing support uwms will send an http request to web swmm and computing service task task 2 will start immediately the time it takes for web swmm to receive an http request from uwms and return a request to uwms is called service response time srt the short srt will give users a better experience so we must spare no effort to reduce the srt to reduce the srt web swmm continuously updates the simulation results stored in the mdb and data is pulled from the mdb when users make a request in the uwms computing service task task 2 gets data from mdb task 2 1 and then return these data to uwms task 2 2 model calculation and results storage task task 3 is designed to store the results of swmm in the mdb in advance and these model output data stored in the mdb will be offered to computing service task task 2 for use during the running of web swmm a large amount of data will be continuously stored in the mdb however the capacity of mdb is limited so we need to manage the data reasonably we designed the data management task that periodically deletes historical data from mdb to address this issue the input data stored in mdb includes not only basic data including land cover data dem data and rainwater pipe network data that do not change with time but also rainfall water level and flow data that change with time as shown in table 1 the swmm simulation object consists of five basic units junction link outfall sub catchment and section among them junction link and outfall are the three main components of the rainwater pipe network the output data stored in mdb contains the time series results and summary results of each swmm simulation object and each type of object contains multiple parameters the above output data will support real time decision making of urban stormwater management 2 3 1 data acquisition and processing task 2 3 1 1 implementation web swmm mainly includes the following three numerical simulation functions 1 hydrological simulation of sub catchments 2 hydraulic simulation of rainwater pipe network 3 hydraulic simulation of natural channels the operation of the above three simulation functions requires input data and output data will also be generated as shown in fig 4 we established eight database tables for storing model input and output data among them three database tables including obs rainfall obs waterlevel and obs discharge are used to store the rainfall water level and discharge data recorded by the observation station respectively the data stored in the above database tables are not obtained directly from the observation equipment but the bdb the remaining five database tables are used to store the calculation results of swmm among them the database tables res junctions res outfalls and res conduits are used to store hydraulic simulation results of the rainwater pipe network the database table res subcatchments is used to store hydrological simulation results of the sub catchments and the database table res sections is used to store hydraulic simulation results of natural channels the primary function of data acquisition and processing task is to obtain and process the input data required for model calculation specifically data acquisition and processing task will continuously preprocess the observation data obtained from the bdb and then store them in the database tables obs rainfall obs waterlevel and obs discharge also the primary function of data management task is to delete the data in the eight database tables shown in fig 4 according to the rules set in advance 2 3 1 2 workflow design data acquisition and processing task starts running as the web swmm is started and stops running as web swmm stops fig 5 shows how data acquisition and processing task runs and the detailed steps for data acquisition and processing task are as follows in step 3 t1 1 t1 2 indicates that there is a new data update in the model input table of bdb otherwise there is no data update data updates in the bdb are intermittent because the data measured by the monitoring device in the da module is discontinuous for example water level and discharge monitoring devices are typically measured every 5 min so the hydrological data stored in the bdb take at least 5 min to be updated if the wait time in step 5 is set to zero data acquisition and processing task will be executed multiple times within 5 min however data acquisition and processing task can obtain new data from the bdb only once in multiple runs within 5 min therefore setting the task waiting step can reduce the number of invalid executions of data acquisition and processing task and also greatly reduce the pressure of database access task waiting time is generally equal to the data update time in bdb 2 3 2 computing service task 2 3 2 1 implementation the implementation of the computing service task faces two problems 1 how to publish web services 2 how to exchange data between uwms and web swmm for question 1 the tomcat server enables the computing service task to provide external web services for question 2 data is transferred between uwms and web swmm using json javascript object notation format data json is a lightweight data exchange format the concise and clear hierarchy makes json an ideal data exchange language to meet the needs of users the computing service task provides the following web services 1 obtain the hydraulic simulation results of the rainwater pipe network 2 obtain the hydrological simulation results of the sub catchment 3 obtain the hydraulic simulation results of the natural channel 4 obtain the summary results of all the above simulation objects in short we can get the model calculation results that traditional desktop software swmm can provide from web swmm 2 3 2 2 workflow design computing service task is triggered when uwms sends an http request to web swmm http request sent by uwms carries request information related to the actual needs of users the request information consists of three main aspects the steps of computing service task are described in the below see fig 6 step 1 computing service task starts running after uwms sends an http request to web swmm step 2 get data from mdb according to uwms request conditions step 3 return the data obtained from mdb to uwms step 4 end of computing service task computing service task supports concurrent access which enables uwms to send multiple http requests to web swmm at the same time 2 3 3 model calculation and results storage task 2 3 3 1 implementation as shown in fig 7 preparing data running model and storing data are the main processes of model calculation and results storage task the file with the file extension inp is an input file that contains the attribute data ad and measurement data md required to run the swmm data that does not change over time such as the area of the catchment the number of pipes and the shape of the cross section are attribute data on the contrary data such as rainfall water level and discharge that change with time are measurement data which are measured by monitoring stations in order to reduce the number of invalid accesses to data files by web swmm we use the ad file and md file to store attribute data and measurement data separately the data in the md file is obtained from the mdb while the data in the ad file is obtained from the water management bureau merge the ad file and md file to generate an input file with the inp as the extension which is the swmm input file the end time of swmm simulation is the time corresponding to the latest rainfall water level and flow data measured in each station and stored in the mdb the length of the simulation period is 3 h in other words we use the rainfall water level and flow data in the last 3 h as the input of swmm besides the time step of the swmm simulation and the measurement time interval of the monitoring station are both 5 min swmm developers provide a dynamic link library swmm dll and an executable program swmm exe for users to invoke in this paper we run swmm by invoking the swmm numerical engine swmm dll the two files with the file extensions out and rpt are the two output files generated after the swmm simulation ends among them the binary file with the file extension out completely records the time series results of swmm and the file with rpt as the file extension records the summary results of swmm fig 8 shows seven functions for java developers to invoke by invoking these functions we can get the following information 1 the summary results and time series results of swmm 2 the length of the period 3 the number of objects junctions outfalls conduits sub catchments and sections simultaneously we can implement the two functions by invoking these functions shown in fig 8 1 run swmm 2 open the binary file that stores the time series results of swmm the summary results and time series results obtained from the output file of the swmm simulation are finally stored in the mdb see fig 9 2 3 3 2 workflow design model calculation and results storage task is responsible for the model calculation and storing model calculation results the steps of this task are described in the below in step 6 of saving the calculation result to the database an error may occur in which the primary key of the database is duplicated the main reason for this error is that some of the data saved in the mdb may already exist we address this issue by covering the historical data with the latest calculation results 2 3 4 data management task 2 3 4 1 implementation the real time simulation results of swmm in web swmm are saved in the five database tables res junctions res outfalls res conduits res sections and res subcatchments shown in fig 4 these database tables in mdb continuously receive data from web swmm during web swmm running however the storage space of the mdb is limited to solve the above problems we limit the database tables that store smmm simulation results in mdb to store only the most recent period of time data we set the time parameter to 72 h which means that these data tables storing swmm simulation results can only store data within 72 h we implemented the above functions through the following methods after data acquisition and processing task model calculation and results storage task data management task and task waiting are executed once web swmm identifies data for more than 72 h by examining the data in the database table where the swmm simulation results are stored and then delete these data the following workflow design part will introduce in detail the method of how to identify which data in the database table is outside the past 72 h in addition we implement task waiting that are important for web swmm running through the thread sleep method provided by java 2 3 4 2 workflow design considering the limited memory of the mdb data management task will periodically clean up the historical data in the database before introducing the steps of the data management task we made some assumptions suppose we only keep the data in the last n hours in the mdb with m tables meanwhile assume that data management task is executed at time t 4 the steps of the data management task are described in the below the flow chart of data management task can be shown in fig 10 2 4 framework and development tools table 2 shows the frameworks and tools used to develop web swmm more details about these frameworks and tools can be learned by visiting the website provided in table 2 3 application of web swmm to test the function stability and efficiency of web swmm web swmm was applied to urban areas in detail the objectives of the web swmm application mainly include the following three aspects first verify whether the web swmm runs as designed secondly test the efficiency that web swmm provides to uwms finally compare the application of web swmm and swmm in urban rainwater management and summarize their respective advantages and disadvantages 3 1 study area and data the urban area which is located in the sucheng district see fig 11 a of suqian city in china was selected for testing web swmm it located within the geographical coordinates of 118 10 e to 118 33 e latitude and 33 47 n to 34 1 n longitude the 21 51 km2 study area approximately 57 of which is covered by open spaces and residential areas and spreads throughout an elevation range from 20 to 30 m above sea level fig 11 a and b show the distribution of land in the study area among them open spaces account for the largest portion of the total area 32 08 followed by residential areas 25 20 commercial areas 18 30 and roads 16 27 the smallest proportions in the total area are lawns 7 23 and stadiums 0 91 influenced by a monsoon climate precipitation mainly occurs in spring and summer the long term annual mean temperature and precipitation are 14 1 c and 892 3 mm respectively also the annual mean sunshine and total solar radiations are 2315 h and 117 kcal cm2 respectively fig 12 shows the monthly average rainfall of suqian city in 2019 july had the largest rainfall 219 2 mm and the total rainfall in 2019 was 1020 6 mm the basic data required for swmm including the land cover data 5 m 5 m dem data 5 m 5 m and the rainwater pipe network data provided by suqian water management bureau the rainfall data recorded by an automated meteorological station the discharge data measured by stream gauge stations the water level data measured by water level station both stream gauge stations and water level stations were installed on the natural channel the above data were essential for swmm modeling these basic data were preprocessed to meet the requirements of swmm modeling according to the rainwater pipe network and land cover types the study area has been discretized into 956 sub catchments by the thiessen polygon method damant et al 1983 first we combined the terrain natural channels and main streets to delineate larger sub basins secondly we used the tyson polygon method to further subdivide the sub catchment according to node distribution finally some adjustments were made according to the actual engineering situation sub catchments are hydrologic units of study area whose topography and the rainwater pipe network elements direct surface runoff to a single discharge point junction outfall and conduit are three principal components of the rainwater pipe network fig 13 shows that the entire rainwater pipe network consists of 5033 junctions 177 outfalls and 5266 conduits the natural channels in the study area were obtained using the arcgis software and srtm data more details on the above data are presented in fig 13 a heavy rainfall event see fig 14 a measured by the meteorological station r01 were used as the inputs to the hydrological and hydraulic simulations of sub catchments and rainwater pipe network respectively moreover the hydrological data measured by the water level station w01 and stream gauge stations s01 s02 and s03 were used as inputs for the hydraulic modeling of the natural channels among them the hydrological data measured by s01 s03 and w01 were used as a boundary condition for hydraulic modeling and the discharge data measured by s02 were used to validate the calculation results of the model the above precipitation and hydrological data were collected at the field stations within the period from 9 00 a m on june 18 2019 to 12 00 a m on june 18 2019 and measured with time intervals of 5 min more detail on these measurement data is presented in fig 14 3 2 installation and configuration of web swmm web swmm needs to be deployed on a computer to run table 3 shows the configuration of the computer used to deploy web swwm during testing in this paper besides web swmm needs internet support when receiving and sending http requests table 3 shows the configuration of the web proxy used for testing before deploying web swmm maven tomcat and java virtual machines had been installed and configured on this computer because the performance of web swmm in different configurations of computers and network environments may be different the test results of web swmm only represent the performance in the test environment shown in table 3 3 3 results and discussion 3 3 1 running process of web swmm as shown in fig 15 data acquisition and processing task model calculation and results storage task and data management task started running with the start of web swmm the window shown in fig 15 completely presented the running process of these tasks records show that data acquisition and processing task took one rainfall data one water level and one discharge data from the bdb and then stored them in the mdb the monitoring station shown in fig 13 measured these new data model calculation and results storage task got the rainfall data the water level data and the discharge data from the mdb for the last 3 h and then wrote them to the md file subsequently model calculation and results storage task generated an input data file for driving the swmm by merging the md file and ad file prepared in advance after completing the data preparation model calculation and results storage task run swmm by invoking the swmm numerical engine swmm dll and then stored the model calculation results to the mdb before running data management task the time parameter of data management task had been set to 72 h which means that the tables used to store model input and output data only store data within the last 72 h because these tables did not store data monitored before 72 h ago the number of deleted data in each table was zero after running three tasks web swmm waited for 60 s before continuing to run at this point web swmm had been successfully run once running results show that the above three tasks are being performed according to the design scheme as shown in fig 15 the total time spent in task execution and task waiting of web swmm is 301 s which slightly larger than the time intervals of updating measured data in bdb that is after the web swmm runs once there must be a new measured data update in the bdb when the monitoring equipment is working properly as expected test results show that web swmm successfully obtained one rainfall data one water level and one discharge data from bdb when executing data acquisition and processing task for the second time on the contrary if there is no task waiting in web swmm then the total time it takes for web swmm to execute once will be reduced from 301 s to 241 s obviously the measured data in the bdb has not been updated when the web swmm is rerun therefore the design of the task waiting in web swmm is necessary and reasonable records show that model calculation and results storage task took nearly 3 min to run the swmm if the web swmm is returning the simulation results obtained by running swmm in real time to the uwms then uwms will take at least 3 min to get feedback form web swmm after making an http request to web swmm such a long srt is unacceptable for users visiting uwms obviously it is more appropriate for web swmm to get pre stored data from mdb and return it to uwms it can be seen from the test results that the design of task waiting improves the success rate of data acquisition and processing task in acquiring new data moreover data acquisition and processing task provides continuous input data for the running of model calculation and results storage task and data management task make sure mdb has enough space for data storage overall the design of three tasks is reasonable and the three tasks cooperation ensures that web swmm can run regularly 3 3 2 test results and discussion of computing service task postman a software used to debug and send http requests for web pages was used to test the performance of web swmm postman plays the role of uwms in web swmm testing the study area used to test includes both ground and underground parts the sub catchments and natural channels cover the ground and the rainwater pipe network shown in fig 13 is distributed underground in the following we will present and discuss the rainwater pipe network s test results sub catchments and natural channels 3 3 2 1 rainwater pipe network thirty six objects see fig 16 representing the rainwater pipe network were selected to participate in the test for the computing service task specifically test objects include 8 outfalls 15 conduits and 13 junctions before sending an http request to web swmm some parameters were set as shown in fig 17 b the time parameter hour in the http request was set to 3 h and the ids of the test object was specified the time parameter can also be set by giving the start and end time see fig 17 a after sending an http request to web swmm we quickly got the request result shown in fig 17 in fact the request result obtained from web swmm are data in json format to show them more intuitively we plotted the json format data into curves shown in fig 17 fig 17 a shows the process of water depth and total inflow within nearly 3 h at each of the 8 outfalls fig 17 b shows the process of flow rate and capacity within nearly 3 h at each of the 15 conduits fig 17 c shows the process of water depth and total inflow within nearly 3 h at each of the 13 junctions according to the data obtained from web swmm urban water managers can accurately understand the rainwater pipe network s real time state which is of great significance to fine management as shown in fig 17 the request time of each http request is greater than the latest time of the request result as shown in fig 17 c the http request was sent at 12 03 00 p m on june 18 2019 however the newest time for the request result returned by web swmm was 12 00 00 p m on june 18 2019 the reason for the time mentioned above delay is that the data measurement of the monitoring equipment has time intervals and data transmission also takes time it turns out that we cannot get real time computing services due to monitoring equipment constraints but we can minimize data latency as much as possible overall all tests are being performed according to the design scheme the rainwater pipe network often overflows and overloads during heavy rains uwms can obtain real time status information of conduits junctions and outfalls in the rainwater pipe network through web swmm real time status information can be used to analyze the rainwater pipe network s overflow and overload situation besides the historical status information of each rainwater pipe network can be used to complete the following important work 1 analyze the overflow and overload status of the rainwater pipe network 2 summarize the reasons for the insufficient drainage capacity of the pipeline 3 explore measures to improve the drainage capacity of the drainage network system 4 propose the optimal design scheme of the rainwater pipe network it can be seen that these data can provide guidance for real time urban stormwater management and provide scientific support for the optimization and transformation of rainwater pipe networks 3 3 2 2 natural channels the natural channels shown in fig 18 a was selected as a test object the stream gauge station s02 was installed on the section sec034 of the natural channel the cross sectional shape of this section is shown in fig 18 a the water level data and discharge data recorded by monitoring stations provided boundary conditions for the hydraulic calculation of natural channels and the discharge data measured by s02 was used to verify the model calculation results of sec034 in addition to the above data 77 sections measured manually were also essential data for hydraulic modeling as shown in fig 18 b we sent a get request to web swmm the time parameter hour in the request was set to 3 h and the parameter ids was set to sec034 the http request was sent at 12 04 25 p m on june 18 2019 and web swmm returned the discharge process of sec034 in the period from 9 a m to 12 a m on june 18 2019 the latest time 12 a m june 18 2019 of the results returned by web swmm is less than the time the http request was sent as with the rainwater pipe network s test results the results returned by web swmm in this test were also delayed fig 18 b shows the discharge data of the sec034 returned by the web swmm to evaluate the model s performance the nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 was used to estimate the goodness of fit the nash sutcliffe efficiency coefficient proposed by nash and sutcliffe is expressed as n s e 1 q i q ˆ i 2 q i q c 2 100 where q i is the observed discharge m3 s q ˆ i is the simulated discharge m3 s and q c is the mean observed discharge m3 s nash sutcliffe efficiency coefficient corresponding to sec034 was 0 85 which was greater than 70 it indicated that swmm performed well in the hydraulic calculation of the natural channels urban water managers can determine the performance of swmm by comparing the observed discharge with the simulated discharge and can also be used to calibrate the swmm urban water managers set a warning level for important rivers in china when the river s water level exceeds the warning level water managers will take timely flood prevention measures uwms can obtain the water level of the river section from web swmm in real time when the real time water level of a section exceeds the river s warning water level uwms can send an early warning message to water managers to remind water managers to take flood control measures 3 3 2 3 sub catchments as shown in fig 19 a eight sub catchments in the study area were selected for testing infiltration capacity and flow as shown in fig 19 b are the two physical parameters that characterize sub catchment fig 17 a shows the process of infiltration loss and runoff flow within nearly 3 h at each of the 8 sub catchments by analyzing the calculation results fed back by web swmm in real time urban water managers can work out more effective flood prevention and disaster reduction measures as shown in fig 19 b we sent a post request to web swmm the time parameter hour in the request was set to 3 h and the parameter id was set the http request was sent at 12 03 50 p m on june 18 2019 and web swmm returned the results from 9 00 00 a m to 12 00 00 a m on june 18 2019 obviously the result returned by web swmm has a delay of 230 s as with the delay of the rainwater pipe network and natural channels delays in sub catchments testing are caused by time intervals and monitoring equipment transmission the larger impervious area with a high runoff peak in the sub catchments is generally potentially flood prone uwms can obtain real time information on the peak runoff distribution of the sub catchments by accessing web swmm and then feed this information back to the urban water managers urban water managers should focus on these areas when obtaining this critical information from uwms and then take timely flood control and drainage measures 3 3 3 efficiency analysis of computing service task fig 20 shows the srt of all test subjects participating in the test for the computing service task the average srt of all test subjects was 40 ms which is entirely acceptable to web swmm users throughout the testing process web swmm was able to respond quickly and stably to http requests issued by postman simultaneously swmm performed well in the hydrological and hydraulic simulation of rainwater pipe networks sub catchments and natural rivers although there have been delays in tests in the rainwater pipe network natural channels and sub catchments this delay is unavoidable after analysis and summary we found that the following three reasons caused the test delay 1 the time interval of data monitoring equipment 2 data transmission between modules 3 it takes time to run web swmm overall the computing service task s design is reasonable 3 3 4 comparison of web swmm and swmm a large number of practical applications show that swmm is an excellent hydrological model however swmm still has some disadvantages as the software used in practice traditional swmm a client side desktop application is primarily used for planning analysis and design limited by the software architecture of swmm we can only use pre prepared historical data for swmm modeling when the application scenario of the model changes we must prepare new model input data the data preparation process requires manual operation so that the swmm is not suitable for modeling under the real time change scenario of input data this inefficient modeling and model calculation method cannot meet the application requirements for a complex urban water environment that is continuously changing compared with the traditional swmm the web swmm designed and implemented in this paper has the following advantages web swmm provides an interface for browsers to access to interact with other applications very conveniently web swmm which can be connected to the database can meet the real time simulation requirements of swmm the client web application web swmm is easier to deploy and install than the client desktop application swmm traditional swmm also has its advantages for example swmm has a significant advantage in modeling because of its friendly interface besides swmm has all the benefits that client desktop applications have web swmm is a web server framework that can make swmm more widely used rather than a new hydrological model that can replace swmm we did not specially design and developed a graphical user interface for web swmm the main reason is that web swmm is not a software for urban water managers directly but a service framework that provides services for uwms the main contribution web swmm can make to provide an excellent convenience for application developers who do not understand the complex principles of swmm with the advantages of web swmm developers can also develop more excellent urban water management applications in general web swmm and swmm need to be used together to play their respective advantages 4 conclusions we designed and developed web swmm for the purpose that swmm can be easily applied to real time urban stormwater management based on web technology web swmm is a framework for providing web services in the form of a web url in general the case study of sucheng district proves the applicability of web swmm in real time urban stormwater management specifically we obtained the following important conclusions web swmm could provide real time computing services stably quickly average srt less than 40 ms and accurately web swmm provides multiple interfaces for external access through http requests these interfaces enable web swmm to provide web services and exchange data with other applications web swmm connected with data monitoring equipment and database can obtain real time data in the study area thereby ensuring that swmm can provide real time computing services due to the time interval and data transmission of the monitoring equipment there is a delay when the user obtains the swmm simulation results through uwms which is inevitable and acceptable the web swmm proposed in this paper is not a theoretical improvement of swmm but makes the traditional swmm more suitable for urban stormwater management in applying swmm to practice we fully acknowledge the performance of swmm and regret the shortcomings of swmm this paper is to make up for the shortage of swmm in urban stormwater management applications we designed and implemented only some of the simulation functions of swmm in web swmm including hydrologic simulations of sub basins and hydraulic simulations of drainage networks and natural channel it is worth noting that swmm also has more functions such as water quality simulation yazdi et al 2019b and low impact development simulation zhu et al 2019 are not yet implemented in web swmm in the future we will continue to enhance the development of web swmm so that more swmm simulation functions can be applied to urban stormwater management besides we consider connecting meteorological data into web swmm to make web swmm have real time forecasting function which will provide more favorable decision support for urban stormwater management software and data availability program title web swmm developer zhiqiang zeng contact address zengzhiqiang hust edu cn source code available and data https github com zengzhiqianghust web swmm git program required internet browser tested on firefox chrome edge and internet explorer tomcat 8 5 33 jdk 1 8 0 maven 3 6 1 intellij idea 2019 3 4 used for secondary development test tool postman year first available 2019 program language java availability and cost open source declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national natural science foundation of china nos 52079101 51379080 open fund of hubei provincial key laboratory for operation and control of cascaded hydropower station in china three gorges university no 2019kjx02 and open fund of the state key laboratory of operation and control of renewable energy storage systems for china electric power research institute nyb51201901206 
25901,the development of a shared understanding of current flood risk amongst stakeholders is one of the main goals of flood risk management this priority suggests that stakeholders must understand the possible impacts on their property and assets and measures they can take to mitigate the risk nowadays flood maps are considered to be a potentially valuable tool for improving this understanding but some drawbacks related to the use of flood maps for risk communication has been highlighted in the literature an alternative and novel approach is provided by 3 d representations of flood inundation so that supplementing flood maps with 3d visualization techniques is increasingly seen as a powerful tool with which to engage people with flood hazards in this context the detailed representation of the urban areas is important not only to set an accurate out of bank river model essential for reliable simulations of flow dynamics inside the urban districts but could be also a key element for the generation of realistic 3d views able to enhance risk perception and communication in the framework described so far 3d point cloud data provided by a terrestrial laser scanner could play an interesting role therefore the main novelty introduced by this work is the combination of 2d flood simulations 3d visual techniques and airborne terrestrial laser scanning in order to develop new approaches for risk communication and perceptions the potential of the methods developed here has been discussed in relation to a hypothetical flood event of the crati river flowing through the old city of cosenza south of italy keywords flood mapping 3d hazard maps remote sensing risk communication numerical schemes 1 introduction flooding is one of the most frequent and destructive natural hazards causing devastating damage to life and economies around the world jongman et al 2012 winsemius et al 2016 guerreiro et al 2018 gao et al 2019 the impacts of flooding are expected to increase in the future dottori et al 2018 zischg et al 2018 berndtsson et al 2019 and therefore they are attracting growing public and research concern due to the increasing large scale damage they cause in highly urbanized regions see for example vincendon et al 2016 li et al 2019 macchione et al 2019a bertilsson et al 2019 arrighi and campo 2019 the approach used to face flooding issues has been substantially changed in the last decade shifting from flood protection towards flood risk management in this context the development of a shared understanding of current flood risk amongst stakeholders is essential meaning that probability of flooding at their location the likely inundation zone of a flood of a particular magnitude possible impacts on their property and assets and measures they can take to mitigate the risk should be understood by everybody henstra et al 2019 this new approach in dealing with flooding issues is now common around the world thanks to european flood directive 2007 60 ec and the american society of civil engineering asce directive traver 2014 flood maps cartographic depictions of geographic areas that could be flooded are a potentially valuable tool for facilitating this understanding of disaster risk dransch et al 2010 flood mapping technology has evolved rapidly over the past decade thanks to the advance in modern two dimensional 2 d hydraulic flood modelling computing systems and increasingly available high quality data allow one to get local flood hazard information including flood depths velocities etc see for example cea and bladè 2015 fernández pato et al 2016 felder et al 2018 dazzi et al 2019 sanders and schubert 2019 flood maps used for risk communication generally seek to raise public awareness about flood impacts impart flood preparedness advice and increase transparency about government actions for reducing flood risk hagemeier klose and wagner 2009 arrighi et al 2019 henstra et al 2019 however some drawbacks related to the use of flood maps for risk communication have been highlighted in the literature fuchs et al 2017 rollason et al 2018a first of all the most significant data represented in the flood maps are communicated essentially according to a top down approach that means stakeholders are considered as just final receivers of information and are not directly involved in the overall production of the flood mapping process therefore the content of flood maps is not focused on the end users and this represents a major limitation in flood risk communication meyer et al 2012 moreover some technical information represented by hazard maps such as the return period expressed in a probabilistic way may not easily be understood by people not expert in this field and may not be suitable for the emergency authorities departments o sullivan et al 2012 strathie et al 2017 henstra et al 2019 these studies have highlighted how far we are from an effective application of flood risk management policy that is mainly based on minimizing flooding consequences and embracing participatory in which stakeholder engagement and communication activities are constantly complemented by modelling and communication tools maskrey et al 2016 basco carrera et al 2017 smith et al 2017 sanders et al 2020 or on citizen science in which citizens provide valuable and complementary information at all levels of flood risk management assumpção et al 2018 rollason et al 2018b sy et al 2019 re et al 2019 in this context perception plays an important role in how individuals and communities respond to risk and links between emotions risk perceptions and behaviours kreibich et al 2017 pilla et al 2019 thaler et al 2019 the manner in which people households businesses governance bodies etc perceive and understand flood risk is at the basis of the judgements they make and the actions they take in preparing for and responding to flood events bubeck et al 2012 morss et al 2016 fuchs et al 2017 up to now few scientists have tackled the integration of risk communication into flood risk management indicating that the risk communication strategy did increase flood risk perception increasing the level of awareness and enabling people to be more competent in facing a flash flood bodoque et al 2019 in this context it is worthwhile mentioning the work by luke et al 2018 who have shown how a set of baseline maps simulated by engineers using a 2 d modelling was further refined through end user focus groups that triggered additional modelling scenarios and map revisions an alternative and novel approach could be represented by making the advanced and complex 2 d flood modelling output useable for risk communication perception and flood risk management but in a different format to the 2 d maps in this context a significant contribution can be provided by 3 d representations of flood inundation through emerging formats in virtual and augmented realities which provide new platforms with which to engage in a substantive process with stakeholders voinov et al 2016 this approach is generally identified as realistic visualization the aim of which is to add drama to the scenarios while adhering to representation of accurate scientific representation kuser olsen et al 2018 more precisely as regards urban flooding there is some evidence that coping responses to flooding risks could be enhanced in a 3 d environment zaalberg and midden 2013 which at least improves the interpretability of disaster data and the effectiveness of decision making processes qiu et al 2017 this idea is further strengthened by dobson et al 2018 who studied the effects of a flood hazard visualization format on house purchasing decisions concluding that when hazard information is presented in map format individuals are less accurate in selecting lower hazard houses compared to when the same information is presented as a graphic representation of a house therefore the potential of 3 d visual representation in flood risk communication is gradually starting to be systematically discussed in the literature lai et al 2011 zhang et al 2013 2017 leskens et al 2017 haynes et al 2018 tomkins and lange 2019 vamvakeridou lyroudia et al 2020 showing that supplementing flood maps with 3d visualization techniques is increasingly seen as a powerful tool with which to engage people with flood hazards in particular macchione et al 2019b have introduced the idea of 3 d flood hazard mapping as a tool for flood risk communication in which the results obtained using complex 2 d simulations have been transformed into 3 d images in order to provide a vivid and immediate understanding of the hazard conditions that could characterize the flood evolution in that area the goal of this paper is to make a further important step towards an effective implementation of the 3 d flood hazard maps technology in particular the specific and novel research question addressed in this work is the development of a method able to provide the representation of the water levels simulated by the 2 d modelling in a 3d environment for which they appear as overlapped to vertical surfaces of the elements at risk buildings embankments vehicles and even people that cannot be represented in the classic 2d flood hazard maps in this context the combination of terrestrial laser scanning tls and airborne laser scanner als data for the 3d reconstruction of urban environments and city models could play an interesting role hadimlioglu and king 2019 therefore the main novelty introduced by this work is the combination of 2d flood simulations with 3d visual techniques and terrestrial laser scanning in order to provide a detailed representation of water levels superimposed to the vertical surfaces of the elements at risk aimed at an immediate understanding of the flood intensity in terms of water depth in respect to buildings faces and in relation to people the potential of the methods developed here has been discussed in relation to a hypothetical flood event of the crati river flowing through the old city of cosenza south of italy 2 case study and available data the field of application of the method presented in this work is the crati river that is the largest river of the calabria region south of italy in terms of drainage area and average and maximum discharge in particular the crati river runs through the old town of cosenza fig 1 this river reach is characterized by almost vertical masonry dykes that provide the defence of the urban area both on the left and right sides of the crati river at the end of the old town an important left tributary the busento river flows into the crati river fig 1 the width of the main channel is variable ranging from 20 m in the old town of cosenza to 90 m downstream from the confluence with the busento river the historical series of floods that have affected the town over the centuries highlights a significant risk of flooding due to the crati river overflow an innovative airborne lidar sensor riegl lms q560 was used to cover this area providing a sampling density of four points over 1 m2 different kinds of dem digital surface model digital terrain model with and without buildings and other objects covering the ground etc were produced at the end of this step and rearranged according to two regular grids the size of which were 0 5 m and 2 m respectively moreover acquisition of digital images was provided in order to generate several orthophotos of the areas this area has been already used by the authors in previous studies related to flood mapping using 1d and 2d models costabile and macchione 2015 costabile et al 2015a 2015b in particular the design of the computational grid has been carried out using aerial laser scanner data only see costabile and macchione 2015 contrarily to what has been done in this work as discussed in section 3 3 method the core of this paper is the evaluation of the potential associated to the use of tls point clouds in the reconstruction of 3 d virtual scenarios related to urban flood inundation for risk communication purposes the method followed here involves essentially five steps 1 choice of the mathematical modelling and assumptions for the representation of urban features 2 data acquisition 3 data processing 4 tls and ats data integration 5 improvement of the computational domain based on tls data flood simulation using the 2 d swes and representation of simulated water levels for visual flood risk communication 3 1 mathematical modelling and assumptions for the representation of urban features an accurate study of flood propagation for flood hazard mapping should be carried out using the well known 2 d shallow water equations 2d swes describing the conservation of the mass and the momentum along the two planar directions the 2d swes can be expressed as in eq 1 1 u t f x g y s in which u h h u h v f h u h u 2 g h 2 2 h u v g h v h u v h v 2 g h 2 2 s q g h s 0 x s f x g h s 0 y s f y where t t is time x y l are the horizontal coordinates h l is the water depth u v l t are the depth averaged flow velocities in x and y directions respectively g l t2 is the gravitational acceleration s 0x s 0y are the bed slopes in x and y directions s fx s fy are the friction slopes in x and y directions q is a lateral inflow l t the application of this 2 d modelling to flood inundation in urban areas can be considered as the reference approach to perform analysis of flood risk among the most recent ones see shen et al 2015 teng et al 2017 bazin et al 2017 ferrari et al 2019 costabile et al 2020a even at the building scale schubert and sanders 2012 amirebrahimi et al 2016 bermúdez and zischg 2018 macchione et al 2019a this approach is more and more used also in the rainfall runoff modelling both in urban areas and at the catchment scale vacondio et al 2017 costabile et al 2019 ferraro et al 2019 macchione et al 2019c echeverribar et al 2019 xia et al 2019 sanders and schubert 2019 3 1 1 representing buildings for flood simulation and communication purposes according to the approach used in this work building s representation involves not only numerical modelling assumption but also 3d techniques for virtual reconstruction of an urban area several studies have experimented the automatic reconstruction of 3d models of building s representation from point clouds acquired through aerial lidar technology for a review see biljecki et al 2015 which provides important information for different aspects of risk management see for example kolbe et al 2005 schröter et al 2018 in the context of the virtual 3d city models level of detail lod is a key concept since it defines the degree of abstraction of real world objects primarily designated to use an optimum amount of details according to the user s needs for the 3d objects the open standardized data model citygml defines five different standard levels of detail lod 0 4 which are differentiated mostly by the complexity of the geometries see fig 2 for visualization purposes in this study we could represent buildings model according to the lod4 because they are based on the point clouds obtained by the tls survey described in the next section however we have not visualized the buildings as 3d grid model but we have preferred to simply show the acquired point cloud this choice is different from that one selected for the numerical simulations that is substantially based on the lod1 model defined as the well known blocks model comprising prismatic buildings with flat roof structures open geospatial consortium 2012 the lod1 model contains no semantics on constituting geometries it is consistent with the assumption commonly introduced in the flood simulation model for building s representations that are mainly based on the building block and building hole methods specifically in the first approach spatially distributed ground elevation data are raised to the heights of rooftops while in the second one the computational mesh is generated with holes aligned with building walls where specific boundary conditions are enforced schubert and sanders 2012 the modelling approach used here is based on the building hole method that proved to be a reliable method to take into account not only the effects of buildings but also the bridge piers falling in the river bed costabile and macchione 2015 3 2 tls data acquisition generally the terrestrial laser scanning procedure requires some steps these include the following project planning one or more scans registration and georeferencing of scans filtering and data visualization before the data acquisition strong emphasis has to be put on project planning in order to check field of view and planning scan station locations data acquisition has been performed using a leica scanstation p20 laser scanner it uses an advanced time of flight range measurement waveform digitising wfd technology that enables it to achieve ultra high scan speeds and low noise performance at extended range up to 120 m for more information see leica scanstation p20 product specifications the survey took place within a 2 day time interval and ten scan positions fig 3 have been selected in the area of interest the point spacing was 6 mm at 10 m distance from the scanner in each position one or two scans have been performed including 360 horizontal rotations of the scanner with different vertical angles the scan positions have been selected based on object type to be detected in this case façades of buildings roads and embankments these are mostly open objects so it was necessary to move in parallel to ensure an effective overlap between the scans and acquire the complete object geometry furthermore a high overlap increases redundancy of point identification which improves the 3 d precision of the point cloud over two hundred million points have been acquired the average interval for all measurements was less than 10 m and based on product specifications it can be assumed that accuracy was kept below 6 mm for points recorded within this range 3 3 data processing the raw data from each scanning location has been processed using the leica geosystems hds software for global point cloud reconstruction some control points have been localized with a global navigation satellite system gnss receiver especially in heavily populated areas the use of satellite sensors for direct cloud registration represents an added value of the survey process although more expensive for this purpose a leica gs15 gnss receiver has been used which allowed orientation and placement of terrestrial laser scans and computational hydraulic domain in the same spatial coordinate system consequently ground control points have been used in co registration of tls and als data 3 4 als and tls data fusion for accurate set up of the river model aimed at flood simulation and risk communication the accurate topographic representation of an urbanized area provides essential information to the mathematical model used in this work since the elevation of the terrain involved in the momentum equations through the terms related to the bed slopes in the two spatial directions see eq 1 small scale urban features such as pavements narrow alleys arches influence the flow directions along the roads in courtyards and near the buildings the dynamics and final distribution of flooded areas in urban areas are highly sensitive to decimetric scale features of the urban topography russo et al 2013 especially the road topography close to junctions dictates whether flow diversions will occur or not see for example sampson et al 2012 ozdemir et al 2013 costabile macchione 2015 papaioannou et al 2016 de almeida et al 2018 these studies demonstrated that at such a small scale tls actually improves results quality given a sufficiently fine computational mesh therefore in this work we take for granted that including tls dataset into als survey leads to the improvements of modelling results and consequently the improvements related to the use of tls information are not explicitly explored we assume that the integration of als and tls data is required for detailed urban flood analyses beside the motivation linked to the flood simulation process als and tls data integration has been carried out in order to represent the water levels close to the vertical surfaces of the elements at risk so the simulations and the final rendering of the simulated water levels could be considered reliable and consistent with the main topographic and urban features of the area particular care has been devoted to overlapping areas between aerial and terrestrial scanning the greatest difficulty encountered was the identification of a sufficient number of overlapping points to complete the alignment point clouds alignment has been performed using iterative closest point icp algorithm proposed by besl and mckay 1992 it is based on an iterative numerical method and aims to find the transformation between a point cloud and another point cloud by minimizing the square errors between the corresponding entities als point cloud was used as reference data in the icp algorithm one point cloud the reference is kept fixed while the other one the source is transformed combining translation and rotation to best match the reference minimizing the distance from the source to the reference point cloud in its simplest form the algorithm is based on four steps 1 for each reference point in the source point cloud in this case tls data find the closest point in the reference cloud in this case als 2 use of a metric minimization technique such as the sum of squared differences between the coordinates of the matched pairs in order to estimate the best rotation and translation that align each source point to its match identified in the first step of the algorithm 3 application of the transformation evaluated in the previous step to the source points 4 iteration of the steps 1 4 to assess the goodness of the alignment the point to point difference algorithm cloud to cloud c2c was used a simple and rapid method for comparing 3 d point clouds which does not require mesh or raster or the calculation of normal to surfaces girardeau montaut et al 2005 these steps were processed with the open source software cloudcompare this multi view approach of combining top view with ground view lidar data shows a good potential for creating an accurate digital terrain model the final product is a digital terrain model derived from als and tls data fusion that potentially could help 2d simulations to obtain an accurate simulation of floodwater dynamics and inundation depths the dtm is the starting point for obtaining suitable computational domains and the design of the mesh type is very important in the process to simulate flood events kim et al 2014 hu et al 2018 ferraro et al 2020 in this context the most interesting methodological issues are discussed in the next section 3 5 computational grid improvements and 2d flood simulations it should be underlined that very often computational domain used for 2 d flood simulation is essentially based on als data whose maximum density of points is quite difficult to use for the design of computational grid for flood simulations in large areas this could represent a crucial point for the 2 d simulations because wrong predictions can be carried out in areas with strong topographic discontinuities not detected by the computational grid used for flood simulations for example the simulated water levels could appear as overtopping the levees when the top of levees are not correctly reproduced in the computational grid because of some smoothing process therefore unrealistic simulations and consequently visualizations could be generated near the levee water levels interface especially in areas with sub vertical wall banks with a thickness lower than a meter such as those that characterize this case study extra detail inherent in terrestrial laser scanning data is advantageous where accurate representation of surface features is required a typical example of this is represented by top level of levees that if not accurately represented in the dem could lead to significant variations in the overbank flow patterns some modifications have been introduced in the available computational unstructured grid first of all a grid refinement process has been carried out in order to reproduce the exact shape and size of the embankment along the river acquired by the terrestrial lidar survey the grid refinement process has been carried out according the following steps first of all two lines representing the plan development of the top of the embankment has been generated this operation has been performed automatically according to the local transversal gradient estimated by the available als data and then verified using the tls data then we put node grids along these lines approximately every 1 m 1 5 m grid refinement in such a way to generate a kind of cross sections delimited by the points themselves the height of these grid points has been set equal to the height of the point of the tls data set closer to the section delimited by the two grid points all the operations related to the grid generation and refinement has been carried out using the software sms surface water modelling system aquaveo sms aquaveotm after completing the dem previously obtained from the als data with the tls survey information the hydraulic simulation can be performed using the 2d swes model finally for visualization purposes one can select an instant of time just after the peak values for the representation of the simulated water depths and organize them as vertices of triangular cells of a surface mesh consistent with the calculation grid the mesh thus obtained has been imported into the 3 d environment together with the tls point clouds 4 results and discussion 4 1 3 d model of the study area based on the integration between als and tls data and grid refinement effect fig 4 shows the 3 d point model in the study area it offers the possibility to identify and map the most interesting features of the object by using its chromatic information and by processing the three dimensionality at different viewing levels the model can also be exported in various formats for example obj ply stl many of which can be viewed and queried using open source software the possibility of having the three dimensional model in different formats also makes it possible to integrate it with other products derived from surveys carried out with different instruments for example with data acquired from a mobile laser scanner or at different times fig 5 shows the overall result obtained by the integration of the als points and tls the point cloud from a terrestrial scanner has been taken as a reference then the als points have been aligned in particular fig 5a highlights the result of the alignment of the 3 d point clouds by intuitively evaluating through the histogram shown on the right of fig 5a the absolute distance c2c absolute difference between the points to be aligned specifically 12326 with respect to the reference ones the c2c histogram should be intended as a measure of the goodness of the alignment between als and tls data after the application of the icp algorithm in particular it shows that the most of the points have been aligned correctly since the c2c absolute distance is low blu part of the histogram the remaining points have greater value of c2c absolute distance green to orange part of the histogram the localization of all the points is depicted in fig 5b the colours are the same of the histogram so as highlighted in fig 5b the points with the grater c2c absolute distance are located essentially over the hills surroundings the urban areas that are not part of the computational domain the effects of the grid refinement procedure described in section 3 5 are shown in fig 6 as highlighted in fig 6a during the process of interpolation for the dem generation the levee s cross sections take on a triangular shape this is due to the fact the aerial lidar could acquire a single point at its top fig 6b shows a detail of the computational grid using only the als data whereas in fig 6c the correction effect induced by the integration with the tls data is highlighted 4 2 3 d visualization of the urban flood inundation for risk communication purposes and comparison to common flood hazard maps using the grid properly refined in order to take into account the information available from the tls data the 2d swes model has been applied using the same upstream boundary conditions and roughness distribution as in costabile and macchione 2015 and macchione et al 2019b in those references one can find the common format of flood hazard maps reporting the contour levels of the maximum simulated water depths in this work we prefer to use a specific criterion for flood hazard assessment in terms of different classes of hazard vulnerability specifically we refer to the approach proposed by smith et al 2014 and recommended by aidr 2017 due its simplicity and because it takes into account the main targets exposed to flood risk costabile et al 2020b it has been also discussed and compared to other methods in a recent review on vehicles stability during floods bocanegra et al 2020 very briefly this criterion is based on six levels of hazard classification according to the values assumed by the unit discharge velocity times water depth describing the progressive increase of unsafe conditions for vehicles people and buildings the application of this approach is presented in fig 7 the map presented above is undoubtedly useful for flood management plans because it allows different end users to gather information on the main targets exposed to flood risk people vehicles and buildings however for the reason explained in the introduction it might not be understood by the population at risk so the question we are posing now is how we can support this kind of map for flood communication purposes using 3d environments similar to that shown before the main goal is to improve the risk perception by showing in a 3d picture all the elements in particular people exposed to flood risk and in relation to the expected water levels to that purpose the 3 d model of points in fig 4 and the free surface calculated just after the time to peak have been imported into the cloudcompare software moreover the silhouette of a man with specific height indications every 0 5 m has been inserted into the 3d environment and used as a kind of human meter the final results can be seen in fig 8 in particular fig 8a shows a 3d view of a neighbourhood located to the right of the crati river see white circle in fig 7 in which the silhouette of the man has been put randomly in different locations adding the computed water levels we can obtain the results shown in fig 8b in which the simulated water depths are represented in single band pseudo colour this picture should be compared to the hazard map shown in fig 7 in that figure the perception of the risk depends only on the different colour used to represent the vulnerability class for which one can simply read the potential hazard for different elements at risk in that area in fig 8b the perception of the risk could be different or in any case could be enhanced by further information looking at the interfaces between water levels and elements at risk people vehicles and buildings anybody could realize the actual exposure that area for example one can immediately realize that the top of the embankments can be overtopped in different points causing significant inundations of the areas with water levels just below the height of the van or comparable to half that of the entrance door of commercial activities other end users could be interested in the local evaluation of water depth near the buildings this can be performed selecting the points on the wall in order to display the corresponding local z coordinate and evaluating the distribution of water depths along the contour of the buildings besides these considerations one of the most significant added values given by the approach discussed here is the visual understanding of different local hazard conditions that can affect people this idea can be explained by the analysis of fig 9 fig 9a represents the same area shown in fig 8 but taken from a different point of view in particular the picture shows an uphill alley inundated by the flow fig 9b what is important to observe is the immediate perception of the potential different effects induced by the inundation throughout the area specifically the silhouette of the man could be used as a visual indicator of the different hazard conditions in that street according to the degree of submergence that is the level of water in respect to the height of the man himself looking at fig 9b one may immediately realize that the water levels are very important in some parts of this area as they may cause even the full submergence of the man see the first four characters in the foreground of the figure then moving along the uphill alley the water levels progressively reduce but remain important since the farthest away character in fig 9b is waist deep in the water therefore a picture like this could help non expert people to understand better the map shown in fig 7 and give a visual understanding of the vulnerability classes which characterize that area it should be mentioned that the characters represented in fig 9b stay upright despite the expected loss of equilibrium due to significant water depths and or velocities a similar consideration holds for the van that could float away indeed the hazard classification shown in fig 7 takes into account the effects of depths and velocities on the elements at risk for this reason the 3 d representation of the flow inundation shown here should be intended as additional information that can be provided to the stakeholders that enriches rather than substitutes the common flood hazard maps 4 3 comparison with the texture mapping approach it may be useful to spend some words on the comparative analysis between the 3 d environment created with the texture mapping proposed by macchione et al 2019b and the urban model derived from terrestrial laser scanner acquisition the first model was developed in order to propose a quick and simple workflow which requires no special efforts in the pre and post processing stages allowing one the generation of realistic scenes thanks to the blender rendering engine in particular a 3 d visualization environment has been presented in which the buildings have been acquired extracting them from their 2d footprints in a shape file format in combination using airborne lidar point cloud fig 10 a a representative height of the building has been computed by averaging the heights of the lidar points inside the footprint then esri arcgis 10 3 geoprocessing tools have been used to generate a set of random sample points constrained by the buildings footprints fig 10b using an elevation derived from the lidar data finally a horizontal plane has been used to approximate the buildings roofs fig 10c finally the texture mapping technique is used to improve the realism of the buildings model façades and by the superimposition of the simulated water depths to visually communicate the hazard conditions in that area for this purpose sketchup make 2014 was used because it allows one to capture google maps street view imagery inserting texture on the facades of buildings giving them a realistic look using this procedure results similar to those shown in fig 11 can be obtained this approach is very useful to provide practical indications to the population on the possible scenario associated with the flood the model proposed in this paper has been thought also to other purposes that will discussed later on in this work however it is of no small importance to note here that the use of tls points x y z to represent building façades allows one to get detailed information on the levels reached by water at the scale of the individual building or part of it this result cannot be obtained by the previous approach because buildings could have faces with different distortions related to the quality of the photos and problems of stretching in the facades this aspect must be carefully considered in the quantitative assessment of the water depth at the buildings therefore the approach proposed here though more expensive is a further important step towards the development of a 3 d hazard map technology macchione et al 2019b finally it should be noted that the value of the tls data goes beyond the simple topographic metric and visual precision indeed it can provide information on the structural materials of faces very useful for the study of the risk of collapse of buildings also in relation to the hydrodynamic forces exerted by the flow 4 4 future perspective web based rendering of point clouds for the interactive representation of urban floods despite the fact that three dimensional surveying is now becoming the most established technology used for surveys the data acquired with this technology are still not very usable neither for the scientific community nor for the general public this is substantially due to the difficulties that can be encountered in the elaboration and management of 3 d point clouds by those who do not have specific technical skills in this area moreover this is also due to the lack of user friendly software available to untrained people allowing them to be at least able to carry out simple operations of visualization interactive exploration and measurements furthermore until a few years ago the spreading process had limits linked to the low transmission speed of large 3 d data volumes the high speed offered today by efficient communication networks allows us to overcome this limit giving an important boost to the development of web oriented platforms capable of accessing in real time data volumes that until a few years ago were unmanageable on the network the challenge of web browsers goes beyond the optimization of 3 d data transmission but it is focused mainly on developing approaches that optimize user information interaction proposing sites that have plug ins oriented to the display of point clouds 3 d so that dissemination and visualization are interconnected kehl 2015 one of the main advantages of 3d web visualization is to allow end users to interactively explore the results of hydraulic modelling using a standard browser without third party applications in order to explore this frontier aspect a preliminary web based rendering of point clouds for displaying flood scenarios is evaluated here in particular the implementation of the renderer presented here is based on potree www potree org developed by the institute of computer graphics and algorithms tu wien schütz 2016 which uses standard web technologies such as web graphics libraries gl three js and the javascript language and it does not require third party application potree relies on the reorganization of the point cloud data in a three level multi resolution data structure and validates raw point cloud data without the need for a mesh creation step which is computationally expensive fig 12 shows the potree format file opened in a local web server in this preliminary stage the water depths are not yet displayed in the user interface because the analysis of the potree viewer has been limited to the evaluation of the web rendering of the point cloud obviously the future goal is to create a product similar to the one shown in fig 12 but able to reproduce a realistic rendering of the water surface in order to generate a realistic web product accessible and usable by planners emergency managers useful for the development evaluation and visualization of adaptation strategies to support decisions to strengthen flood resilience risk managers would thus have a tool to better inform stakeholders about the impact of floods the variety of measurement tools also allows users to potentially analyze the depths of the water as a vertex point attribute this tool could have many advantages especially for visual analysis of evacuation routes furthermore the users can easily explore the 3 d space and view in detail the impact that a flood event can have on a single building and in the area of interest 5 discussion potential impacts of the research the study presented here although from a preliminary point of view in some frontier aspects has enormous potential in terms of applicative effects in particular in perspective this study aims to meet the different needs and different objectives that characterize different groups of end users in the area of flood risk management and communication in particular the results presented here are of interest to the following stakeholders 5 1 users involved in strategic planning the people in this group generally belong to institutes that produce the flood maps or to institutes that deal with risk management users of the products of this group are usually skilled professionals who use maps as a basic tool in decision making processes this group of users is able to understand technical contents such as the concept of return period average annual damage etc this group is usually also involved in contributing to the strategic management of flood risk but it is often located within a different organization or department 3d urban models can play a very important role in strategic planning which for the most part still stands at 2d representations furthermore these models represent the ideal starting point for bim building information modelling infrastructure design amirebrahimi et al 2016 until recently the difficulties in producing realistic 3d representations were caused by to the scarcity of data and by the cost of retrieving furthermore they were produced by complex and expensive software which in turn needed skilled and specialized operators fortunately today the new survey technologies based on the use of laser scanners and drones have brought down the costs and allow people to obtain in a short time 3d models formed by millions of points that then can be processed with open source software as widely shown in this paper therefore even professional planners who are not very familiar with these technologies can try to produce 3d virtual products easy to consult 3d interactive tools such as the one presented in this study could radically change the planning processes allowing the stimulation of a participatory approach important for the risk governance process 5 2 users involved in emergency management emergency or disaster management is an institutionally separate activity from strategic planning in terms of risk management local or regional institutions are usually responsible for emergency management even though firefighters and other armed forces are often involved in these activities in this case the map should provide quick access to strategic information such as areas affected in case of emergency people to be evacuated critical infrastructure or evacuation routes often these institutions are not adequately acknowledged as they do not have specific competence on floods therefore users in this group may be less familiar than users skilled in strategic planning with the scientific concept of risk and in dealing with flood maps furthermore the maps generalize the information contained in them to the mapping scale thus reducing the detail pile et al 2018 and could therefore be of little use in this context local information on water levels and critical speeds can be useful to show the accessibility of some areas in addition to ordinary information on hazards and risks indications on emergency management such as collection points hospitals coordination centres and emergency infrastructures should also be included but these structures can also be at risk of flooding therefore maps should include additional information on the level of floods of such risky emergency facilities furthermore the addition of textual information within the map could be particularly important during emergency activities where there is little time to read the maps in this way users do not have to continually refer to the legend to understand the information 5 3 the population citizens are usually not directly involved in the production of maps nor do they have technical skills in this regard however the recipient of the maps is often the population at risk as the aim is to raise their awareness literature shows that the use of flood hazard maps is generally infrequent by citizen and therefore it is likely that this group is not familiar with concepts such as probability of exceeding or average annual damage on the other hand the population is more likely to rely on detailed contextual knowledge obtained from previous experiences of floods they could therefore be able to provide valuable contributions to the mapping process providing a different kind of knowledge and information that enrich the content and the visualization of the map the informative content of the maps for the public therefore should be as simple as possible and focused only on the most important aspects the extent of the flood the depths the buildings involved and the paths practicable and not the different damage assessment models merz et al 2010 garrote et al 2016 englhardt et al 2019 put a strong emphasis on buildings given their importance both from an economic point of view and for the requirements of structural integrity necessary for human safety van de lindt and taggart 2009 damage curves provide an effective method for large scale applications merz et al 2004 but are considered unsuitable for the micro scale and in particular where a case by case assessment of flood impact on individual buildings is required pistrika and jonkman 2010 this limitation is mainly due to the ineffectiveness of these methods in capturing and incorporating a complete representation of each building and the lack of details on the structural parts affected by the damage such information plays an important role in revealing the sources of risk for a building the use of 3 d views can play an important role not only in terms of perception planning and emergency management but also in the context of the flood damage assessment fda as highlighted by amirebrahimi et al 2016 and zhou et al 2016 the 3d product presented in this study could favour an approach of validation of the results of the 2d simulation of the flood allowing us also to focus on the exposure and on the analysis of losses at the single building scale zischg et al 2018 thanks to the immediate consultation of water levels on the point model of the buildings 6 conclusion the traditional instruments of hazard representation such as the flooding maps are still used for the flood risk communication this work deals with the innovative methodology capable of transferring detailed local information to the stakeholders for a greater awareness of the flood hazard related to an event for this purpose the old town of cosenza has been used as field study the advance of this paper is represented by a further step towards the development of 3 d hazard map technology for flood risk management in our view this means to provide the flood mapping in 3d environments using the results obtained by 2 d simulations and overlapped to vertical surfaces of the elements at risk buildings embankments vehicles and even people that cannot be represented in the classic 2d flood hazard maps in particular an approach has been proposed for the realization of a 3 d virtual environment obtained using point clouds acquired by terrestrial laser scanner in order to visualize the results of two dimensional hydraulic simulations the method here proposed allows us to consider the facades of buildings and other buildings as a set of points with geodetic coordinates consequently once a suitable mesh is generated based on the merging of als and tls data the simulated flood levels can be analyzed without the need to create a legend but only by clicking directly on the point of interest which has the topographic coordinates as attributes in particular using this technique it is possible to read in the virtual images of the flood the water level reached at any point of the vertical surfaces of the elements at risk moreover it has been shown that the addition of the silhouette of a man could be used as a visual indicator of the different hazard conditions in that street according to the degree of submergence in this way one could improve the perception of the risk in a given area providing additional visual information useful for different kinds of end users for the future the implemented technique may be used to create interactive and navigable environments with a virtual pointer that allows the user to know the water level velocities and vulnerability class at the selected point it s important to highlight that despite the complexity of the models and the size of the involved data the 3 d created environment is accessible to all users using an open source renderer based on web gl technology such as potree the challenge of the research shown here is to provide a quick view manipulation and analysis of complex scenes of large scale 3 d environments and to implement a calculation framework based on web gl rendering technologies combining the hydrodynamic simulation with the real time rendering of calculated water surfaces this kind of representation is expected to improve also flood risk communication and perception but the qualitative assessment of our approach using the stakeholders reactions is not the goal of this work and it will be a specific question to address in the next future furthermore as future developments this research intends to create immersive environments within which the user can move freely through the combination of suitable software and hardware for vr visualizations dome vr viewers controllers motion sensors etc of which the images are only a preliminary result declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported in part by the funding project pon sila pona3 00341 a lampit laboratory head scientist f macchione 
25901,the development of a shared understanding of current flood risk amongst stakeholders is one of the main goals of flood risk management this priority suggests that stakeholders must understand the possible impacts on their property and assets and measures they can take to mitigate the risk nowadays flood maps are considered to be a potentially valuable tool for improving this understanding but some drawbacks related to the use of flood maps for risk communication has been highlighted in the literature an alternative and novel approach is provided by 3 d representations of flood inundation so that supplementing flood maps with 3d visualization techniques is increasingly seen as a powerful tool with which to engage people with flood hazards in this context the detailed representation of the urban areas is important not only to set an accurate out of bank river model essential for reliable simulations of flow dynamics inside the urban districts but could be also a key element for the generation of realistic 3d views able to enhance risk perception and communication in the framework described so far 3d point cloud data provided by a terrestrial laser scanner could play an interesting role therefore the main novelty introduced by this work is the combination of 2d flood simulations 3d visual techniques and airborne terrestrial laser scanning in order to develop new approaches for risk communication and perceptions the potential of the methods developed here has been discussed in relation to a hypothetical flood event of the crati river flowing through the old city of cosenza south of italy keywords flood mapping 3d hazard maps remote sensing risk communication numerical schemes 1 introduction flooding is one of the most frequent and destructive natural hazards causing devastating damage to life and economies around the world jongman et al 2012 winsemius et al 2016 guerreiro et al 2018 gao et al 2019 the impacts of flooding are expected to increase in the future dottori et al 2018 zischg et al 2018 berndtsson et al 2019 and therefore they are attracting growing public and research concern due to the increasing large scale damage they cause in highly urbanized regions see for example vincendon et al 2016 li et al 2019 macchione et al 2019a bertilsson et al 2019 arrighi and campo 2019 the approach used to face flooding issues has been substantially changed in the last decade shifting from flood protection towards flood risk management in this context the development of a shared understanding of current flood risk amongst stakeholders is essential meaning that probability of flooding at their location the likely inundation zone of a flood of a particular magnitude possible impacts on their property and assets and measures they can take to mitigate the risk should be understood by everybody henstra et al 2019 this new approach in dealing with flooding issues is now common around the world thanks to european flood directive 2007 60 ec and the american society of civil engineering asce directive traver 2014 flood maps cartographic depictions of geographic areas that could be flooded are a potentially valuable tool for facilitating this understanding of disaster risk dransch et al 2010 flood mapping technology has evolved rapidly over the past decade thanks to the advance in modern two dimensional 2 d hydraulic flood modelling computing systems and increasingly available high quality data allow one to get local flood hazard information including flood depths velocities etc see for example cea and bladè 2015 fernández pato et al 2016 felder et al 2018 dazzi et al 2019 sanders and schubert 2019 flood maps used for risk communication generally seek to raise public awareness about flood impacts impart flood preparedness advice and increase transparency about government actions for reducing flood risk hagemeier klose and wagner 2009 arrighi et al 2019 henstra et al 2019 however some drawbacks related to the use of flood maps for risk communication have been highlighted in the literature fuchs et al 2017 rollason et al 2018a first of all the most significant data represented in the flood maps are communicated essentially according to a top down approach that means stakeholders are considered as just final receivers of information and are not directly involved in the overall production of the flood mapping process therefore the content of flood maps is not focused on the end users and this represents a major limitation in flood risk communication meyer et al 2012 moreover some technical information represented by hazard maps such as the return period expressed in a probabilistic way may not easily be understood by people not expert in this field and may not be suitable for the emergency authorities departments o sullivan et al 2012 strathie et al 2017 henstra et al 2019 these studies have highlighted how far we are from an effective application of flood risk management policy that is mainly based on minimizing flooding consequences and embracing participatory in which stakeholder engagement and communication activities are constantly complemented by modelling and communication tools maskrey et al 2016 basco carrera et al 2017 smith et al 2017 sanders et al 2020 or on citizen science in which citizens provide valuable and complementary information at all levels of flood risk management assumpção et al 2018 rollason et al 2018b sy et al 2019 re et al 2019 in this context perception plays an important role in how individuals and communities respond to risk and links between emotions risk perceptions and behaviours kreibich et al 2017 pilla et al 2019 thaler et al 2019 the manner in which people households businesses governance bodies etc perceive and understand flood risk is at the basis of the judgements they make and the actions they take in preparing for and responding to flood events bubeck et al 2012 morss et al 2016 fuchs et al 2017 up to now few scientists have tackled the integration of risk communication into flood risk management indicating that the risk communication strategy did increase flood risk perception increasing the level of awareness and enabling people to be more competent in facing a flash flood bodoque et al 2019 in this context it is worthwhile mentioning the work by luke et al 2018 who have shown how a set of baseline maps simulated by engineers using a 2 d modelling was further refined through end user focus groups that triggered additional modelling scenarios and map revisions an alternative and novel approach could be represented by making the advanced and complex 2 d flood modelling output useable for risk communication perception and flood risk management but in a different format to the 2 d maps in this context a significant contribution can be provided by 3 d representations of flood inundation through emerging formats in virtual and augmented realities which provide new platforms with which to engage in a substantive process with stakeholders voinov et al 2016 this approach is generally identified as realistic visualization the aim of which is to add drama to the scenarios while adhering to representation of accurate scientific representation kuser olsen et al 2018 more precisely as regards urban flooding there is some evidence that coping responses to flooding risks could be enhanced in a 3 d environment zaalberg and midden 2013 which at least improves the interpretability of disaster data and the effectiveness of decision making processes qiu et al 2017 this idea is further strengthened by dobson et al 2018 who studied the effects of a flood hazard visualization format on house purchasing decisions concluding that when hazard information is presented in map format individuals are less accurate in selecting lower hazard houses compared to when the same information is presented as a graphic representation of a house therefore the potential of 3 d visual representation in flood risk communication is gradually starting to be systematically discussed in the literature lai et al 2011 zhang et al 2013 2017 leskens et al 2017 haynes et al 2018 tomkins and lange 2019 vamvakeridou lyroudia et al 2020 showing that supplementing flood maps with 3d visualization techniques is increasingly seen as a powerful tool with which to engage people with flood hazards in particular macchione et al 2019b have introduced the idea of 3 d flood hazard mapping as a tool for flood risk communication in which the results obtained using complex 2 d simulations have been transformed into 3 d images in order to provide a vivid and immediate understanding of the hazard conditions that could characterize the flood evolution in that area the goal of this paper is to make a further important step towards an effective implementation of the 3 d flood hazard maps technology in particular the specific and novel research question addressed in this work is the development of a method able to provide the representation of the water levels simulated by the 2 d modelling in a 3d environment for which they appear as overlapped to vertical surfaces of the elements at risk buildings embankments vehicles and even people that cannot be represented in the classic 2d flood hazard maps in this context the combination of terrestrial laser scanning tls and airborne laser scanner als data for the 3d reconstruction of urban environments and city models could play an interesting role hadimlioglu and king 2019 therefore the main novelty introduced by this work is the combination of 2d flood simulations with 3d visual techniques and terrestrial laser scanning in order to provide a detailed representation of water levels superimposed to the vertical surfaces of the elements at risk aimed at an immediate understanding of the flood intensity in terms of water depth in respect to buildings faces and in relation to people the potential of the methods developed here has been discussed in relation to a hypothetical flood event of the crati river flowing through the old city of cosenza south of italy 2 case study and available data the field of application of the method presented in this work is the crati river that is the largest river of the calabria region south of italy in terms of drainage area and average and maximum discharge in particular the crati river runs through the old town of cosenza fig 1 this river reach is characterized by almost vertical masonry dykes that provide the defence of the urban area both on the left and right sides of the crati river at the end of the old town an important left tributary the busento river flows into the crati river fig 1 the width of the main channel is variable ranging from 20 m in the old town of cosenza to 90 m downstream from the confluence with the busento river the historical series of floods that have affected the town over the centuries highlights a significant risk of flooding due to the crati river overflow an innovative airborne lidar sensor riegl lms q560 was used to cover this area providing a sampling density of four points over 1 m2 different kinds of dem digital surface model digital terrain model with and without buildings and other objects covering the ground etc were produced at the end of this step and rearranged according to two regular grids the size of which were 0 5 m and 2 m respectively moreover acquisition of digital images was provided in order to generate several orthophotos of the areas this area has been already used by the authors in previous studies related to flood mapping using 1d and 2d models costabile and macchione 2015 costabile et al 2015a 2015b in particular the design of the computational grid has been carried out using aerial laser scanner data only see costabile and macchione 2015 contrarily to what has been done in this work as discussed in section 3 3 method the core of this paper is the evaluation of the potential associated to the use of tls point clouds in the reconstruction of 3 d virtual scenarios related to urban flood inundation for risk communication purposes the method followed here involves essentially five steps 1 choice of the mathematical modelling and assumptions for the representation of urban features 2 data acquisition 3 data processing 4 tls and ats data integration 5 improvement of the computational domain based on tls data flood simulation using the 2 d swes and representation of simulated water levels for visual flood risk communication 3 1 mathematical modelling and assumptions for the representation of urban features an accurate study of flood propagation for flood hazard mapping should be carried out using the well known 2 d shallow water equations 2d swes describing the conservation of the mass and the momentum along the two planar directions the 2d swes can be expressed as in eq 1 1 u t f x g y s in which u h h u h v f h u h u 2 g h 2 2 h u v g h v h u v h v 2 g h 2 2 s q g h s 0 x s f x g h s 0 y s f y where t t is time x y l are the horizontal coordinates h l is the water depth u v l t are the depth averaged flow velocities in x and y directions respectively g l t2 is the gravitational acceleration s 0x s 0y are the bed slopes in x and y directions s fx s fy are the friction slopes in x and y directions q is a lateral inflow l t the application of this 2 d modelling to flood inundation in urban areas can be considered as the reference approach to perform analysis of flood risk among the most recent ones see shen et al 2015 teng et al 2017 bazin et al 2017 ferrari et al 2019 costabile et al 2020a even at the building scale schubert and sanders 2012 amirebrahimi et al 2016 bermúdez and zischg 2018 macchione et al 2019a this approach is more and more used also in the rainfall runoff modelling both in urban areas and at the catchment scale vacondio et al 2017 costabile et al 2019 ferraro et al 2019 macchione et al 2019c echeverribar et al 2019 xia et al 2019 sanders and schubert 2019 3 1 1 representing buildings for flood simulation and communication purposes according to the approach used in this work building s representation involves not only numerical modelling assumption but also 3d techniques for virtual reconstruction of an urban area several studies have experimented the automatic reconstruction of 3d models of building s representation from point clouds acquired through aerial lidar technology for a review see biljecki et al 2015 which provides important information for different aspects of risk management see for example kolbe et al 2005 schröter et al 2018 in the context of the virtual 3d city models level of detail lod is a key concept since it defines the degree of abstraction of real world objects primarily designated to use an optimum amount of details according to the user s needs for the 3d objects the open standardized data model citygml defines five different standard levels of detail lod 0 4 which are differentiated mostly by the complexity of the geometries see fig 2 for visualization purposes in this study we could represent buildings model according to the lod4 because they are based on the point clouds obtained by the tls survey described in the next section however we have not visualized the buildings as 3d grid model but we have preferred to simply show the acquired point cloud this choice is different from that one selected for the numerical simulations that is substantially based on the lod1 model defined as the well known blocks model comprising prismatic buildings with flat roof structures open geospatial consortium 2012 the lod1 model contains no semantics on constituting geometries it is consistent with the assumption commonly introduced in the flood simulation model for building s representations that are mainly based on the building block and building hole methods specifically in the first approach spatially distributed ground elevation data are raised to the heights of rooftops while in the second one the computational mesh is generated with holes aligned with building walls where specific boundary conditions are enforced schubert and sanders 2012 the modelling approach used here is based on the building hole method that proved to be a reliable method to take into account not only the effects of buildings but also the bridge piers falling in the river bed costabile and macchione 2015 3 2 tls data acquisition generally the terrestrial laser scanning procedure requires some steps these include the following project planning one or more scans registration and georeferencing of scans filtering and data visualization before the data acquisition strong emphasis has to be put on project planning in order to check field of view and planning scan station locations data acquisition has been performed using a leica scanstation p20 laser scanner it uses an advanced time of flight range measurement waveform digitising wfd technology that enables it to achieve ultra high scan speeds and low noise performance at extended range up to 120 m for more information see leica scanstation p20 product specifications the survey took place within a 2 day time interval and ten scan positions fig 3 have been selected in the area of interest the point spacing was 6 mm at 10 m distance from the scanner in each position one or two scans have been performed including 360 horizontal rotations of the scanner with different vertical angles the scan positions have been selected based on object type to be detected in this case façades of buildings roads and embankments these are mostly open objects so it was necessary to move in parallel to ensure an effective overlap between the scans and acquire the complete object geometry furthermore a high overlap increases redundancy of point identification which improves the 3 d precision of the point cloud over two hundred million points have been acquired the average interval for all measurements was less than 10 m and based on product specifications it can be assumed that accuracy was kept below 6 mm for points recorded within this range 3 3 data processing the raw data from each scanning location has been processed using the leica geosystems hds software for global point cloud reconstruction some control points have been localized with a global navigation satellite system gnss receiver especially in heavily populated areas the use of satellite sensors for direct cloud registration represents an added value of the survey process although more expensive for this purpose a leica gs15 gnss receiver has been used which allowed orientation and placement of terrestrial laser scans and computational hydraulic domain in the same spatial coordinate system consequently ground control points have been used in co registration of tls and als data 3 4 als and tls data fusion for accurate set up of the river model aimed at flood simulation and risk communication the accurate topographic representation of an urbanized area provides essential information to the mathematical model used in this work since the elevation of the terrain involved in the momentum equations through the terms related to the bed slopes in the two spatial directions see eq 1 small scale urban features such as pavements narrow alleys arches influence the flow directions along the roads in courtyards and near the buildings the dynamics and final distribution of flooded areas in urban areas are highly sensitive to decimetric scale features of the urban topography russo et al 2013 especially the road topography close to junctions dictates whether flow diversions will occur or not see for example sampson et al 2012 ozdemir et al 2013 costabile macchione 2015 papaioannou et al 2016 de almeida et al 2018 these studies demonstrated that at such a small scale tls actually improves results quality given a sufficiently fine computational mesh therefore in this work we take for granted that including tls dataset into als survey leads to the improvements of modelling results and consequently the improvements related to the use of tls information are not explicitly explored we assume that the integration of als and tls data is required for detailed urban flood analyses beside the motivation linked to the flood simulation process als and tls data integration has been carried out in order to represent the water levels close to the vertical surfaces of the elements at risk so the simulations and the final rendering of the simulated water levels could be considered reliable and consistent with the main topographic and urban features of the area particular care has been devoted to overlapping areas between aerial and terrestrial scanning the greatest difficulty encountered was the identification of a sufficient number of overlapping points to complete the alignment point clouds alignment has been performed using iterative closest point icp algorithm proposed by besl and mckay 1992 it is based on an iterative numerical method and aims to find the transformation between a point cloud and another point cloud by minimizing the square errors between the corresponding entities als point cloud was used as reference data in the icp algorithm one point cloud the reference is kept fixed while the other one the source is transformed combining translation and rotation to best match the reference minimizing the distance from the source to the reference point cloud in its simplest form the algorithm is based on four steps 1 for each reference point in the source point cloud in this case tls data find the closest point in the reference cloud in this case als 2 use of a metric minimization technique such as the sum of squared differences between the coordinates of the matched pairs in order to estimate the best rotation and translation that align each source point to its match identified in the first step of the algorithm 3 application of the transformation evaluated in the previous step to the source points 4 iteration of the steps 1 4 to assess the goodness of the alignment the point to point difference algorithm cloud to cloud c2c was used a simple and rapid method for comparing 3 d point clouds which does not require mesh or raster or the calculation of normal to surfaces girardeau montaut et al 2005 these steps were processed with the open source software cloudcompare this multi view approach of combining top view with ground view lidar data shows a good potential for creating an accurate digital terrain model the final product is a digital terrain model derived from als and tls data fusion that potentially could help 2d simulations to obtain an accurate simulation of floodwater dynamics and inundation depths the dtm is the starting point for obtaining suitable computational domains and the design of the mesh type is very important in the process to simulate flood events kim et al 2014 hu et al 2018 ferraro et al 2020 in this context the most interesting methodological issues are discussed in the next section 3 5 computational grid improvements and 2d flood simulations it should be underlined that very often computational domain used for 2 d flood simulation is essentially based on als data whose maximum density of points is quite difficult to use for the design of computational grid for flood simulations in large areas this could represent a crucial point for the 2 d simulations because wrong predictions can be carried out in areas with strong topographic discontinuities not detected by the computational grid used for flood simulations for example the simulated water levels could appear as overtopping the levees when the top of levees are not correctly reproduced in the computational grid because of some smoothing process therefore unrealistic simulations and consequently visualizations could be generated near the levee water levels interface especially in areas with sub vertical wall banks with a thickness lower than a meter such as those that characterize this case study extra detail inherent in terrestrial laser scanning data is advantageous where accurate representation of surface features is required a typical example of this is represented by top level of levees that if not accurately represented in the dem could lead to significant variations in the overbank flow patterns some modifications have been introduced in the available computational unstructured grid first of all a grid refinement process has been carried out in order to reproduce the exact shape and size of the embankment along the river acquired by the terrestrial lidar survey the grid refinement process has been carried out according the following steps first of all two lines representing the plan development of the top of the embankment has been generated this operation has been performed automatically according to the local transversal gradient estimated by the available als data and then verified using the tls data then we put node grids along these lines approximately every 1 m 1 5 m grid refinement in such a way to generate a kind of cross sections delimited by the points themselves the height of these grid points has been set equal to the height of the point of the tls data set closer to the section delimited by the two grid points all the operations related to the grid generation and refinement has been carried out using the software sms surface water modelling system aquaveo sms aquaveotm after completing the dem previously obtained from the als data with the tls survey information the hydraulic simulation can be performed using the 2d swes model finally for visualization purposes one can select an instant of time just after the peak values for the representation of the simulated water depths and organize them as vertices of triangular cells of a surface mesh consistent with the calculation grid the mesh thus obtained has been imported into the 3 d environment together with the tls point clouds 4 results and discussion 4 1 3 d model of the study area based on the integration between als and tls data and grid refinement effect fig 4 shows the 3 d point model in the study area it offers the possibility to identify and map the most interesting features of the object by using its chromatic information and by processing the three dimensionality at different viewing levels the model can also be exported in various formats for example obj ply stl many of which can be viewed and queried using open source software the possibility of having the three dimensional model in different formats also makes it possible to integrate it with other products derived from surveys carried out with different instruments for example with data acquired from a mobile laser scanner or at different times fig 5 shows the overall result obtained by the integration of the als points and tls the point cloud from a terrestrial scanner has been taken as a reference then the als points have been aligned in particular fig 5a highlights the result of the alignment of the 3 d point clouds by intuitively evaluating through the histogram shown on the right of fig 5a the absolute distance c2c absolute difference between the points to be aligned specifically 12326 with respect to the reference ones the c2c histogram should be intended as a measure of the goodness of the alignment between als and tls data after the application of the icp algorithm in particular it shows that the most of the points have been aligned correctly since the c2c absolute distance is low blu part of the histogram the remaining points have greater value of c2c absolute distance green to orange part of the histogram the localization of all the points is depicted in fig 5b the colours are the same of the histogram so as highlighted in fig 5b the points with the grater c2c absolute distance are located essentially over the hills surroundings the urban areas that are not part of the computational domain the effects of the grid refinement procedure described in section 3 5 are shown in fig 6 as highlighted in fig 6a during the process of interpolation for the dem generation the levee s cross sections take on a triangular shape this is due to the fact the aerial lidar could acquire a single point at its top fig 6b shows a detail of the computational grid using only the als data whereas in fig 6c the correction effect induced by the integration with the tls data is highlighted 4 2 3 d visualization of the urban flood inundation for risk communication purposes and comparison to common flood hazard maps using the grid properly refined in order to take into account the information available from the tls data the 2d swes model has been applied using the same upstream boundary conditions and roughness distribution as in costabile and macchione 2015 and macchione et al 2019b in those references one can find the common format of flood hazard maps reporting the contour levels of the maximum simulated water depths in this work we prefer to use a specific criterion for flood hazard assessment in terms of different classes of hazard vulnerability specifically we refer to the approach proposed by smith et al 2014 and recommended by aidr 2017 due its simplicity and because it takes into account the main targets exposed to flood risk costabile et al 2020b it has been also discussed and compared to other methods in a recent review on vehicles stability during floods bocanegra et al 2020 very briefly this criterion is based on six levels of hazard classification according to the values assumed by the unit discharge velocity times water depth describing the progressive increase of unsafe conditions for vehicles people and buildings the application of this approach is presented in fig 7 the map presented above is undoubtedly useful for flood management plans because it allows different end users to gather information on the main targets exposed to flood risk people vehicles and buildings however for the reason explained in the introduction it might not be understood by the population at risk so the question we are posing now is how we can support this kind of map for flood communication purposes using 3d environments similar to that shown before the main goal is to improve the risk perception by showing in a 3d picture all the elements in particular people exposed to flood risk and in relation to the expected water levels to that purpose the 3 d model of points in fig 4 and the free surface calculated just after the time to peak have been imported into the cloudcompare software moreover the silhouette of a man with specific height indications every 0 5 m has been inserted into the 3d environment and used as a kind of human meter the final results can be seen in fig 8 in particular fig 8a shows a 3d view of a neighbourhood located to the right of the crati river see white circle in fig 7 in which the silhouette of the man has been put randomly in different locations adding the computed water levels we can obtain the results shown in fig 8b in which the simulated water depths are represented in single band pseudo colour this picture should be compared to the hazard map shown in fig 7 in that figure the perception of the risk depends only on the different colour used to represent the vulnerability class for which one can simply read the potential hazard for different elements at risk in that area in fig 8b the perception of the risk could be different or in any case could be enhanced by further information looking at the interfaces between water levels and elements at risk people vehicles and buildings anybody could realize the actual exposure that area for example one can immediately realize that the top of the embankments can be overtopped in different points causing significant inundations of the areas with water levels just below the height of the van or comparable to half that of the entrance door of commercial activities other end users could be interested in the local evaluation of water depth near the buildings this can be performed selecting the points on the wall in order to display the corresponding local z coordinate and evaluating the distribution of water depths along the contour of the buildings besides these considerations one of the most significant added values given by the approach discussed here is the visual understanding of different local hazard conditions that can affect people this idea can be explained by the analysis of fig 9 fig 9a represents the same area shown in fig 8 but taken from a different point of view in particular the picture shows an uphill alley inundated by the flow fig 9b what is important to observe is the immediate perception of the potential different effects induced by the inundation throughout the area specifically the silhouette of the man could be used as a visual indicator of the different hazard conditions in that street according to the degree of submergence that is the level of water in respect to the height of the man himself looking at fig 9b one may immediately realize that the water levels are very important in some parts of this area as they may cause even the full submergence of the man see the first four characters in the foreground of the figure then moving along the uphill alley the water levels progressively reduce but remain important since the farthest away character in fig 9b is waist deep in the water therefore a picture like this could help non expert people to understand better the map shown in fig 7 and give a visual understanding of the vulnerability classes which characterize that area it should be mentioned that the characters represented in fig 9b stay upright despite the expected loss of equilibrium due to significant water depths and or velocities a similar consideration holds for the van that could float away indeed the hazard classification shown in fig 7 takes into account the effects of depths and velocities on the elements at risk for this reason the 3 d representation of the flow inundation shown here should be intended as additional information that can be provided to the stakeholders that enriches rather than substitutes the common flood hazard maps 4 3 comparison with the texture mapping approach it may be useful to spend some words on the comparative analysis between the 3 d environment created with the texture mapping proposed by macchione et al 2019b and the urban model derived from terrestrial laser scanner acquisition the first model was developed in order to propose a quick and simple workflow which requires no special efforts in the pre and post processing stages allowing one the generation of realistic scenes thanks to the blender rendering engine in particular a 3 d visualization environment has been presented in which the buildings have been acquired extracting them from their 2d footprints in a shape file format in combination using airborne lidar point cloud fig 10 a a representative height of the building has been computed by averaging the heights of the lidar points inside the footprint then esri arcgis 10 3 geoprocessing tools have been used to generate a set of random sample points constrained by the buildings footprints fig 10b using an elevation derived from the lidar data finally a horizontal plane has been used to approximate the buildings roofs fig 10c finally the texture mapping technique is used to improve the realism of the buildings model façades and by the superimposition of the simulated water depths to visually communicate the hazard conditions in that area for this purpose sketchup make 2014 was used because it allows one to capture google maps street view imagery inserting texture on the facades of buildings giving them a realistic look using this procedure results similar to those shown in fig 11 can be obtained this approach is very useful to provide practical indications to the population on the possible scenario associated with the flood the model proposed in this paper has been thought also to other purposes that will discussed later on in this work however it is of no small importance to note here that the use of tls points x y z to represent building façades allows one to get detailed information on the levels reached by water at the scale of the individual building or part of it this result cannot be obtained by the previous approach because buildings could have faces with different distortions related to the quality of the photos and problems of stretching in the facades this aspect must be carefully considered in the quantitative assessment of the water depth at the buildings therefore the approach proposed here though more expensive is a further important step towards the development of a 3 d hazard map technology macchione et al 2019b finally it should be noted that the value of the tls data goes beyond the simple topographic metric and visual precision indeed it can provide information on the structural materials of faces very useful for the study of the risk of collapse of buildings also in relation to the hydrodynamic forces exerted by the flow 4 4 future perspective web based rendering of point clouds for the interactive representation of urban floods despite the fact that three dimensional surveying is now becoming the most established technology used for surveys the data acquired with this technology are still not very usable neither for the scientific community nor for the general public this is substantially due to the difficulties that can be encountered in the elaboration and management of 3 d point clouds by those who do not have specific technical skills in this area moreover this is also due to the lack of user friendly software available to untrained people allowing them to be at least able to carry out simple operations of visualization interactive exploration and measurements furthermore until a few years ago the spreading process had limits linked to the low transmission speed of large 3 d data volumes the high speed offered today by efficient communication networks allows us to overcome this limit giving an important boost to the development of web oriented platforms capable of accessing in real time data volumes that until a few years ago were unmanageable on the network the challenge of web browsers goes beyond the optimization of 3 d data transmission but it is focused mainly on developing approaches that optimize user information interaction proposing sites that have plug ins oriented to the display of point clouds 3 d so that dissemination and visualization are interconnected kehl 2015 one of the main advantages of 3d web visualization is to allow end users to interactively explore the results of hydraulic modelling using a standard browser without third party applications in order to explore this frontier aspect a preliminary web based rendering of point clouds for displaying flood scenarios is evaluated here in particular the implementation of the renderer presented here is based on potree www potree org developed by the institute of computer graphics and algorithms tu wien schütz 2016 which uses standard web technologies such as web graphics libraries gl three js and the javascript language and it does not require third party application potree relies on the reorganization of the point cloud data in a three level multi resolution data structure and validates raw point cloud data without the need for a mesh creation step which is computationally expensive fig 12 shows the potree format file opened in a local web server in this preliminary stage the water depths are not yet displayed in the user interface because the analysis of the potree viewer has been limited to the evaluation of the web rendering of the point cloud obviously the future goal is to create a product similar to the one shown in fig 12 but able to reproduce a realistic rendering of the water surface in order to generate a realistic web product accessible and usable by planners emergency managers useful for the development evaluation and visualization of adaptation strategies to support decisions to strengthen flood resilience risk managers would thus have a tool to better inform stakeholders about the impact of floods the variety of measurement tools also allows users to potentially analyze the depths of the water as a vertex point attribute this tool could have many advantages especially for visual analysis of evacuation routes furthermore the users can easily explore the 3 d space and view in detail the impact that a flood event can have on a single building and in the area of interest 5 discussion potential impacts of the research the study presented here although from a preliminary point of view in some frontier aspects has enormous potential in terms of applicative effects in particular in perspective this study aims to meet the different needs and different objectives that characterize different groups of end users in the area of flood risk management and communication in particular the results presented here are of interest to the following stakeholders 5 1 users involved in strategic planning the people in this group generally belong to institutes that produce the flood maps or to institutes that deal with risk management users of the products of this group are usually skilled professionals who use maps as a basic tool in decision making processes this group of users is able to understand technical contents such as the concept of return period average annual damage etc this group is usually also involved in contributing to the strategic management of flood risk but it is often located within a different organization or department 3d urban models can play a very important role in strategic planning which for the most part still stands at 2d representations furthermore these models represent the ideal starting point for bim building information modelling infrastructure design amirebrahimi et al 2016 until recently the difficulties in producing realistic 3d representations were caused by to the scarcity of data and by the cost of retrieving furthermore they were produced by complex and expensive software which in turn needed skilled and specialized operators fortunately today the new survey technologies based on the use of laser scanners and drones have brought down the costs and allow people to obtain in a short time 3d models formed by millions of points that then can be processed with open source software as widely shown in this paper therefore even professional planners who are not very familiar with these technologies can try to produce 3d virtual products easy to consult 3d interactive tools such as the one presented in this study could radically change the planning processes allowing the stimulation of a participatory approach important for the risk governance process 5 2 users involved in emergency management emergency or disaster management is an institutionally separate activity from strategic planning in terms of risk management local or regional institutions are usually responsible for emergency management even though firefighters and other armed forces are often involved in these activities in this case the map should provide quick access to strategic information such as areas affected in case of emergency people to be evacuated critical infrastructure or evacuation routes often these institutions are not adequately acknowledged as they do not have specific competence on floods therefore users in this group may be less familiar than users skilled in strategic planning with the scientific concept of risk and in dealing with flood maps furthermore the maps generalize the information contained in them to the mapping scale thus reducing the detail pile et al 2018 and could therefore be of little use in this context local information on water levels and critical speeds can be useful to show the accessibility of some areas in addition to ordinary information on hazards and risks indications on emergency management such as collection points hospitals coordination centres and emergency infrastructures should also be included but these structures can also be at risk of flooding therefore maps should include additional information on the level of floods of such risky emergency facilities furthermore the addition of textual information within the map could be particularly important during emergency activities where there is little time to read the maps in this way users do not have to continually refer to the legend to understand the information 5 3 the population citizens are usually not directly involved in the production of maps nor do they have technical skills in this regard however the recipient of the maps is often the population at risk as the aim is to raise their awareness literature shows that the use of flood hazard maps is generally infrequent by citizen and therefore it is likely that this group is not familiar with concepts such as probability of exceeding or average annual damage on the other hand the population is more likely to rely on detailed contextual knowledge obtained from previous experiences of floods they could therefore be able to provide valuable contributions to the mapping process providing a different kind of knowledge and information that enrich the content and the visualization of the map the informative content of the maps for the public therefore should be as simple as possible and focused only on the most important aspects the extent of the flood the depths the buildings involved and the paths practicable and not the different damage assessment models merz et al 2010 garrote et al 2016 englhardt et al 2019 put a strong emphasis on buildings given their importance both from an economic point of view and for the requirements of structural integrity necessary for human safety van de lindt and taggart 2009 damage curves provide an effective method for large scale applications merz et al 2004 but are considered unsuitable for the micro scale and in particular where a case by case assessment of flood impact on individual buildings is required pistrika and jonkman 2010 this limitation is mainly due to the ineffectiveness of these methods in capturing and incorporating a complete representation of each building and the lack of details on the structural parts affected by the damage such information plays an important role in revealing the sources of risk for a building the use of 3 d views can play an important role not only in terms of perception planning and emergency management but also in the context of the flood damage assessment fda as highlighted by amirebrahimi et al 2016 and zhou et al 2016 the 3d product presented in this study could favour an approach of validation of the results of the 2d simulation of the flood allowing us also to focus on the exposure and on the analysis of losses at the single building scale zischg et al 2018 thanks to the immediate consultation of water levels on the point model of the buildings 6 conclusion the traditional instruments of hazard representation such as the flooding maps are still used for the flood risk communication this work deals with the innovative methodology capable of transferring detailed local information to the stakeholders for a greater awareness of the flood hazard related to an event for this purpose the old town of cosenza has been used as field study the advance of this paper is represented by a further step towards the development of 3 d hazard map technology for flood risk management in our view this means to provide the flood mapping in 3d environments using the results obtained by 2 d simulations and overlapped to vertical surfaces of the elements at risk buildings embankments vehicles and even people that cannot be represented in the classic 2d flood hazard maps in particular an approach has been proposed for the realization of a 3 d virtual environment obtained using point clouds acquired by terrestrial laser scanner in order to visualize the results of two dimensional hydraulic simulations the method here proposed allows us to consider the facades of buildings and other buildings as a set of points with geodetic coordinates consequently once a suitable mesh is generated based on the merging of als and tls data the simulated flood levels can be analyzed without the need to create a legend but only by clicking directly on the point of interest which has the topographic coordinates as attributes in particular using this technique it is possible to read in the virtual images of the flood the water level reached at any point of the vertical surfaces of the elements at risk moreover it has been shown that the addition of the silhouette of a man could be used as a visual indicator of the different hazard conditions in that street according to the degree of submergence in this way one could improve the perception of the risk in a given area providing additional visual information useful for different kinds of end users for the future the implemented technique may be used to create interactive and navigable environments with a virtual pointer that allows the user to know the water level velocities and vulnerability class at the selected point it s important to highlight that despite the complexity of the models and the size of the involved data the 3 d created environment is accessible to all users using an open source renderer based on web gl technology such as potree the challenge of the research shown here is to provide a quick view manipulation and analysis of complex scenes of large scale 3 d environments and to implement a calculation framework based on web gl rendering technologies combining the hydrodynamic simulation with the real time rendering of calculated water surfaces this kind of representation is expected to improve also flood risk communication and perception but the qualitative assessment of our approach using the stakeholders reactions is not the goal of this work and it will be a specific question to address in the next future furthermore as future developments this research intends to create immersive environments within which the user can move freely through the combination of suitable software and hardware for vr visualizations dome vr viewers controllers motion sensors etc of which the images are only a preliminary result declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported in part by the funding project pon sila pona3 00341 a lampit laboratory head scientist f macchione 
25902,the increase in water salinisation in catchments has led to increased concern in assessing major ion loadings in freshwater environments in this study we couple a globally fitted model on chemical weathering to the soil and water assessment tool swat for the estimation of daily geochemical loadings at the catchment scale swatlitho the enhancements include i a modification on the discretisation of the catchment area by integrating a layer describing lithology qswatlitho and ii the development of an extra module to compute the ionic loads derived from the chemical weathering of rocks the model is sensitive to input data resolution yielding the best results when including local data larger spatial and temporal discrepancies are found in one tributary associated with point sources impacting the loadings while these discrepancies are lower at headwater subbasins results suggest that despite of these discrepancies the average simulation of the daily ionic loadings is reasonable keywords model coupling geochemical loadings chemical weathering downscaling 1 introduction chemical quality assessment of river waters is crucial for understanding and assessing the potential impacts of threats to biodiversity drinking water safety and crop yields cañedo argüelles et al 2018 kaushal et al 2017 one of these threats is the rise in major ion concentration i e salinisation meybeck and helmer 1989 which despite having a relevant role in efficient ecosystem management cañedo argüelles et al 2018 has received little attention in the past traditionally two approaches tackling freshwater chemical assessments exist the analysis of water samples framed within a monitoring program e g martínez santos et al 2015 and the use of hydrogeochemical models to simulate the study area and possible scenarios e g m nassri et al 2019 water sampling is a common practice in many places yielding real valuable data but spatially and temporally homogeneous information is obtained through modelling the integration of these two approaches complements the assessment of chemical threats models may be based on physical laws or data regression equations for representing the system object of the study being classified as mechanistic or empirical respectively nowadays there exists a number of mechanistic hydrogeochemical models such as phreeqc version 3 in parkhust and appelo 2013 minteqa2 allison et al 1991 or witch goddéris et al 2006 but their applicability is commonly limited to areas where extensive necessary data mineral abundance the chemical profile of soil water initial boundary condition etc is available as input in other cases simplifications or assumptions are needed in order to apply this kind of model increasing the model s prediction uncertainty a different solution is to develop simpler models to replace these complex configurations schoups et al 2006 as an alternative to mechanistic models several empirical models focusing on single processes have been built such as the global erosion model for co2 gem co2 amiotte suchet and probst 1995 the chemical weathering rate model cwr hartmann et al 2014 and ionic fluxes derived from chemical weathering of rocks model icwr lechuga crespo et al 2020a which have yielded a static output over worldwide scale assessments i e the annual average result regarding chemical weathering rates and associated products atmospheric co2 consumption p release ionic loadings to rivers etc to date and to the best of the authors knowledge none of them have been tested on a local scale and under a dynamic approach while management decisions are usually taken at a catchment scale and need the temporal evolution within a year in the present study an empirically based model has been coupled to a physically based hydrological model to compute daily geochemical loadings from the chemical weathering of rocks the swat model has long been used to quantify the loads and concentrations of matter and nutrients from land to the catchment s outlet arnold et al 2012 fu et al 2019 as well as its evolution at different time scales however it is not possible to estimate the geochemical loadings with this model as there is no subroutine or module implemented with this purpose in this sense the icwr model lechuga crespo et al 2020a has been applied to the global scale it has yielded the first map on average annual ionic fluxes derived from the chemical weathering of rocks to rivers nevertheless its ability to simulate the dynamics of chemical weathering derived ionic loads and its performance on local catchments have not been tested yet in this sense the coupling of the swat and icwr models poses an opportunity to evaluate spatially explicit geochemical fluxes since a basin s hydrology in swat is described using the hydrological response unit s hru semi distributed approach consequently ionic loadings from chemical weathering may be assessed and if the atmospheric contribution is known this tool may work with observed data to estimate how much anthropogenic saline effluent found in a catchment it is important to note that a similar approach has been recently published by bailey et al 2019 where they present the coupling of a mechanistic model for major ion chemical partitioning within the swat hydrological code such mechanistic methodology presents the same constraints in application as the other mechanistic approaches the availability of input data and the establishment of boundary conditions for simulation the objective of this study is to downscale the icwr model spatially and temporally as well as explore the performance in a case study where a geochemistry monitoring program has been taken this case is exploratory and the model objectives are to simulate the daily geochemical loads of major ions and their spatial distribution given the modelling framework and the constraints of both models the processes to be simulated are chemical weathering of rocks mass transport and routing from catchment subbasins to the outlet the model s spatial definition is conditioned by the hru delimitation of the modified model which is explained in section 2 2 while the simulation s time step is daily a chemical equilibrium is assumed between rock and water at the temporal scale of simulation then loadings are expected to be dependent on the discharge distribution among groundwater lateral and surface fluxes the lithological groups in the underlying rock and the soil types 2 methods 2 1 overview of the swat and the icwr models the ionic fluxes derived from chemical weathering of rocks icwr lechuga crespo et al 2020a model is empirically based and its parameters have been fitted at a global scale for the estimation of spatially explicit fluxes of chemical weathering of rocks f measured in mol m 2 y 1 for each major ion ca2 mg2 na k so4 2 cl and alkalinity commonly associated with hco3 the model configuration is based on the multivariable regression shown in eq 1 the input data needed for this model includes the specific discharge q ann measured in mm the lithological composition of the rocks l i expressed as the percentage of the catchment area covered by a lithological group the soil covering the bedrock layer for the estimation of the soil shielding effect factor f sx which is different for each ion x and the parameter of the equation c xi representing the water concentration on every ion further explanation of the development calibration and limitations of the model can be seen in lechuga crespo et al 2020a the output of this model is an annual average specific flux of major ion loads originating from the chemical weathering of rocks to rivers which together with atmospheric deposition and anthropogenic inputs is the main reservoir of saline exports of a basin 1 f x q ann f s x l i c x i the swat is a physically based and semi distributed model developed to assess water sediments and nutrients in agronomic catchments at yearly monthly daily and sub daily time steps arnold et al 1998 water matter and nutrient balances are simulated in homogeneous spatial units hrus a combination of unique slope land use and soil type areas which are then aggregated to the subbasin scale and routed through tributaries and channels towards the outlet of the catchment the hrus together with the weather data at least precipitation and temperature time series provide the input data for the simulation a more detailed description of the model is available in the swat2012 theoretical handbook neitsch et al 2011 2 2 coupling the icwr model to swat the approach to spatially discretising the catchment area in the swat model has been modified to include a fourth layer in the definition of the hrus the lithological groups this modification has been performed in the qgis geographic information system plugin used to set up the model qswat dile et al 2016 the modified version is hereby called qswatlitho the swat code has not been modified to maintain the possibility of using external software such as swat cup abbaspour et al 2007 for autocalibration instead an extra module swatlitho py has been written to read the qswatlitho and swat outputs and compute the geochemical fluxes and loads the workflow of the model s configuration is shown in fig 1 2 2 1 qswatlitho traditionally a qswat model setup consists of three main phases the delineation of the watershed and subbasins the delimitation of the hrus and the write of the input tables for swat modelling for the qswatlitho implementation the second step has been modified by changing the hrus py dbutils py and qswatutils py files in the original plugin causing the inclusion of a new layer to the delimitation of the hrus now every hru contains a unique combination of slope land use soil type and lithological group and the water balance is defined for each one of them the first consequence of this change is an increased number of hrus when setting up a project causing a finer definition on the spatial distribution of the model outputs and an increase in the time used for the swat simulation the qswatlitho may be found and downloaded at https swat tamu edu software swat litho 2 2 2 icwr module swatlitho once a qswatlitho project has been set up the calibration of the hydrology is needed since this is the main dynamic input data for the icwr model because the chemical weathering process occurs mainly in the vadose zone of the water cycle the main water fluxes to be considered are groundwater q gw and lateral flows q lf the icwr model has been adapted to include them q lf q gw instead of the total average specific discharge q ann which would also include runoff here the runoff is considered as the main driver for the dilution of the total load rather than including it in the calculation of the daily geochemical loads a new module has been created so that the user can use the swat results in combination with the qswatlitho tables to obtain geochemical loadings daily time series the module consists of six main steps that are integrated into two loops for each hru data like area lithological group and soil type is extracted from the hrus lithology csv file a modified version of the hrus file in the project mdb and if necessary used to set the soil shielding effect f sx cf lechuga crespo et al 2020a then the output hru file is read to obtain the specific discharge in the lateral and groundwater fluxes to the river with this information together with the globally fitted parameters the geochemical loads are calculated for each time step of the simulation and each hru this process generates a table with the loads of each hru to the river stream for each time step then all of the loadings are summarised at the subbasin scale in each time step and saved as output the geochemical loadings are routed by adding the upstream loadings if such exists to the contribution of each subbasin draining area a workflow summary is shown in fig 2 and the modified version of the icwr regression equation 1 is shown in equation 2 where l x represents the loading of ion x in each hru in mg d 1 a is the area of the catchment in m 2 q gw lt accounts for lateral and groundwater specific discharge mm respectively f sx represents the soil shielding effect dimensionless and c lit x is the globally fitted parameter for each lithological unit and ion mol l 1 note that units are adjusted depending on the ion that is being considered and that this modification considers each hru to be a monolithic unit to the river stream 2 l x a h r u q g w l t f s x c l i t x the lithological groups used in the icwr model development study are kept unaltered in the present development evaporites ev metamorphics mt plutonic acid pa plutonic basic pb plutonic intermediate pi pyroclastics py sediment carbonates sc mixed sediments sm sediment siliciclastic ss sediment unconsolidated su volcanic acid va volcanic basic vb volcanic intermediate vi water bodies wb ice and glaciers ig and no data nd according to the description presented in hartmann and moosdorf 2012 and dürr et al 2005 2 3 case study deba river catchment a case study is set up to explore the model s application the validation comprises three steps first the annual comparison of the results to evaluate the model s sensitivity and select the input data among different combinations second the analysis of geochemical loadings in all subbasins derived from the qswatlitho swatlitho combination spatial downscaling and last the comparison of the daily representation in three gauging stations temporal downscaling the case study selected for this purpose is the deba river catchment fig 3 on which numerous studies related to urban and industrial pollution on its sediments and waters have been conducted martínez santos et al 2015 garcía garcía et al 2019 unda calvo et al 2019 lechuga crespo et al 2020b there are eleven sampling locations along its main channel and tributaries where a monitoring campaign was established between april 2014 and january 2017 samples were taken in a monthly or bi monthly time step in addition there are three gauging stations measuring among other variables discharge and electrical conductivity every 10 min 2 3 1 study area the deba river basin has a complete drainage area of 538 km2 and 60 km of main stream a maximum slope of 40 and an elevation varying from 0 at sea level to 1320 m in botreatiz the highest mountain which is located in the northern part of spain in the gipuzkoa province in the basque country fig 3 regarding its hydrometeorology there is a strong variation between humid and dry years as well as a strong seasonal variability about 30 of the total annual water volume is exported in december and january and in dry summers the specific discharge can reach 0 6 mm the average annual precipitation is estimated to be 1613 mm while the mean temperature is 12 7 c leading to the highest potential evapotranspiration etp of the surrounding catchments at 871 mm in terms of the occupation of this catchment there is a strong presence of industries with a population of 135 000 inhabitants grouped into four important villages arrasate oñati bergara eibar and deba 37 of the area is occupied by pinus spp 27 is covered by autochthonous forest and 11 is given to farmlands and pastures this catchment is commonly located over evaporitic rocks gypsum and anhydride deposits included in detrital rocks which according to the classification proposed by hartmann and moosdorf 2012 and dürr et al 2005 correspond to a mix of siliciclastic carbonate and mixed sediments together with other lithological groups a detailed description of the geology of the zone is addressed in ábalos et al 2008 and iribar and ábalos 2011 historically this catchment has suffered a strong urban and industrial pressure gipuzkoa council accessed on october 2019 and previous studies on the pollution in this catchment martínez santos et al 2015 garcía garcía et al 2019 unda calvo et al 2019 have highlighted the inputs of urban and residual industrial effluents treated through wastewater treatment plants wwtp located in the middle of the catchment where phosphorus is eliminated using cl3fe only from may 1st to october 15th resulting in the presence of metals in the water and sediment matrixes the analysis of this anthropogenic influence has been monitored from april 2014 to january 2017 in 11 sampling locations in the main channel and tributaries highlighting the nutrients and metal input of urban and industrial effluents furthermore a recent study on this catchment has focused on the major ion chemistry of its waters assessing the main geochemical processes input in relation to the anthropogenic input lechuga crespo et al 2020b while emphasising the influence of an evaporitic saline spring in the southwest part of the catchment which exerts a great impact on the water chemistry downstream to the outlet of the catchment 2 3 2 set up of the qswatlitho project a local digital elevation map dem 25 m resolution cell was used to create the stream network locate the outlet of the catchment and delimit the drainage area subbasins were merged to obtain their draining to the sampling locations of the monitoring campaigns a european land use map from the corine land cover project 100 m resolution a soil map from the harmonized world database a 30 arc second resolution and a local lithological map reclassified for the categories found in hartmann and moosdorf 2012 were combined with the dem derived slope map to create the hrus the description and source of the datasets may be seen in table 1 table 2 and fig 3 while setting up the model three slope ranges were established 0 5 5 10 10 and no simplification was performed to reduce the number of hrus the weather input data was obtained from a hydrometeorological station located close to the outlet fig 3 consisting of precipitation as well as maximum and minimum temperature daily time series from january 1994 to december 2017 the observed data for discharge was covered from january 2004 to december 2017 for three gauging stations located close to the outlet and near the outlet of the two major subbasins of this catchment see fig 3 swat has been used to compute the hydrological representation of the case study using the qswatlitho hru definition for the spatial discretisation but using the same water balance as the swat model observed data for riverine chemical concentration ranged from april 2014 to january 2017 a monitoring program samples the river waters monthly or bimonthly using a pre washed polypropylene bottle which was carried to the laboratory at 4 c and filtered through 0 45 μm filters one replicate was acidified to 0 2 with hno3 68 for base cations ca2 mg2 na and k using icp oes perkinelmer optima 2000 the other non acidified replicate was used to analyse anions cl no3 so4 2 through ion chromatography dionex ics 3000 alkalinity was measured using a total organic carbon analyzer toc l shimadzu the ionic charge balance icb was within 10 for all samples used in this study for the modelling of the geochemical loads groundwater and lateral flows from the swat hydrological representation have been used as a source of lithological chemical weathering derived loads while runoff has been attributed to lower concentrations inducing dilution in the stream s concentration following the recommendations of asabe 2017 three periods were defined in this project a warmup period to reduce the effect of state variables initial values six years january 1998 december 2003 a calibration period to optimise the parameters ten years january 2004 december 2013 and a validation period to test the model capabilities in an independent dataset four years january 2014 december 2017 the model s performance evaluation has been carried out for the calibration and validation periods independently using graphical methods time series between observed and simulated and relative statistical measures coefficient of determination r2 nash sutcliffe efficiency nse pbias and kling gupta kge the moriasi et al 2015 standard has been considered in this study to evaluate the model s performance however the authors have found no reference when comparing the daily loads of major ions so the exploration of the results would yield the first reference for future similar analysis 2 3 3 discharge parameterisation the geochemical reactions responsible for ionic loads derived from rocks to the river are assumed to be in equilibrium at daily scales however other sources like human input or atmospheric deposition are expected to vary in these temporal ranges thus the simulation both calibration and validation has been done at a daily time step the first step is to calibrate the discharge in surface runoff lateral flow and groundwater flow which will be the main drivers in the temporal application of the icwr model the discharge has been calibrated using the parameters found in table 3 through both manual calibration and autocalibration with the sufi 2 algorithm in swat cup abbaspour et al 2007 three gauging stations have been used to evaluate the model performance on discharge calibration using four statistical criteria the coefficient of determination r2 the nash sutcliff efficiency nse the percent of bias pbias and the kling gupta efficiency kge all the statistics are applied to the simulated and observed values r2 focuses in the fit between the trends varying from 0 no fit to 1 perfect fit pbias calculates the global over negative value or underestimation positive value nse evaluates the trends similar to r2 but varying from to 1 perfect fit and kge is based on pearson s coefficient r including bias and variability ranging from to 1 perfect fit where values 0 41 could be considered as a reasonable performance knoben et al 2019 2 3 4 downscaling the icwr model the original icwr model lechuga crespo et al 2020a was developed for an annual average specific flux output for which only the average specific discharge was needed for hydrology to explore the possibilities of applying this model at lower spatial and temporal scales three assessments have been performed a model s sensitivity analysis a spatial evaluation and a temporal assessment the model s sensitivity to input data was evaluated by testing different global and local datasets combinations two lithological maps one clipped from the global lithological map glim hartmann and moosdorf 2012 and a local one obtained from the gipuzkoa council geoeuskadi eus together with two annual average specific discharges one obtained from a global dataset unh grd fekete et al 2002 and other from the gipuzkoa council hydrological department www gipuzkoa eus were combined to obtain four output datasets the comparison with observed data indicated the best input data setup for building the qswatlitho project these results are shown and discussed in section 3 1 model s sensitivity to input data before applying the swatlitho module it is necessary to calibrate the water balance the model setup and the calibration of hydrology are discussed in section 3 2 case study set up and discharge calibration once the model was built and hydrology was calibrated a simulation was conducted period january 2014 to december 2017 the application of the swatlitho module allowed the evaluation of the model s spatial and temporal performance no calibration of the icwr parameters has been done and globally fitted values were used lechuga crespo et al 2020a the model s spatial downscaling evaluation was done by contrasting simulated geochemical loadings at the subbasin outlet with observed loadings at the corresponding sampling location see fig 3a results are presented in section 3 3 spatial downscaling the temporal downscale was evaluated at three gauging stations where daily loadings were derived from punctual data and continuous registries integration the results are shown in section 3 4 temporal downscaling finally model limitations improvement suggestions and alternatives are presented in section 3 5 swatlitho limitations and alternatives even though the wide applicability of the model makes this approach versatile its setup may be constrained by input data availability a proposed alternative approach is the use of digital filters to deconvolute the hydrological signal between surface and groundwater fluxes in this sense we computed the hydrological deconvolution using the eckhardt digital filter eckhardt 2005 xie et al 2020 this test has been performed at the three gauging stations of the catchment 3 results and discussion 3 1 model s sensitivity to input data average annual loadings obtained for the four input data combinations are shown in table 4 the original icwr model lechuga crespo et al 2020a was calibrated and validated using global data method unh glim in table 4 and data on rivers worldwide from the glorich database the highest values among all methods considered are found for the unh glim method and the greatest differences are found not between the two hydrological datasets but between the lithological maps this confirms that the lithological representation has a major impact on the loadings computed by the model regarding the values obtained with the four datasets in comparison with the observed values gauging station in table 4 the closest values are found for the eus geus method the local data for hydrology and lithology nevertheless the difference between the observed and the modelled values are different between ions and gauging stations both the altzola and san prudentzio gauging stations present the highest differences in ca2 na k and cl while the differences between the observed and the simulated values are lower for other ions such differences are not found in the oñati tributary where the highest difference is found for mg2 cl and so4 2 but which is still lower than the altzola and the san prudentzio bias for the previously noted ions the common pattern in the differences found for altzola and san prudentzio and the difference for the oñati stream suggest that there is a common phenomenon not captured by the model s performance in the san prudentzio draining basin which affects downstream at the outlet of the catchment the monitoring program and previous studies in the area iribar and ábalos 2011 martínez santos et al 2015 have shown that the southeastern part of the catchment has the highest values of ca2 na k and cl which is related to the presence of gypsum intrusions and a spring altering the local water s composition in both lithological maps used the intrusion of gypsum evaporites in the southwest part of the catchment seems to be underestimated in addition according to iribar and ábalos 2011 the southern part of the catchment contains a combination of different geological registries albian and aptian albian where there is a common presence of springs with saline waters within this catchment the leintz gatzaga spring contains one of the most concentrated effluents to the streams 230 6 g l 1 according to iribar and ábalos 2011 this suggests that the impact of the saline is not properly mapped in either the global or the local lithological maps but that it exerts a strong influence on the chemical characteristics of this area downstream lechuga crespo et al 2020b for this reason the observed data on na k and cl are higher than those modelled especially in the san prudentzio subbasin the inclusion of a local lithological map with a finer spatial resolution of lithology has decreased the loads to around half of those obtained with the previous map these new values are closer to reality when considering mg2 hco3 and so4 2 which are the elements less affected by the spring inputs the inclusion of a spatially distributed lithology has improved the results of the model leading to the conclusion that increasing the spatial resolution of the lithology input data has a major effect on the output of the model from the model s sensitivity analysis we conclude that when applying the icwr model to local studies local lithological data should be applied moreover consideration of saline springs should be taken into account when evaluating the model s performance 3 2 case study set up and discharge calibration the combination of slope land use soil types and lithological classes in this catchment leads to a spatial discretisation consisting of 11 subbasins and 985 hrus when building the same project considering land use soil type and slope layers in the hru definition step the number of spatial units reaches 286 hrus a more detailed project regarding spatial distribution increases the computation time but the water balance calibration is more comprehensive which is a key input for the geochemical loads computation and the model s temporal downscaling regarding the calibration of hydrology at the daily time step fig 4 most of the parameterisation has been focused on calibrating groundwater and lateral flow which account for almost 96 of the annual discharge at the catchment s outlet the parameterisation of the model has yielded the results summarised in table 5 and moriasi et al 2015 qualifies the simulation as satisfactory for calibration and validation according to these results the model has been considered enough to represent the hydrology of the catchment studied nse is used based on its performance which is better when the variable s range of variation is large however in low flows the denominator tends towards 0 leading to higher values when the errors are small oeurng et al 2011 the higher values for r2 in comparison to the nse suggest a good representation of the dynamic but a worse depiction of the exact discharge value indicating a difference between observed and simulated values which is stronger in lower flow periods this can also be seen in the pbias where the calibration for san prudentzio has yielded a value classified as non satisfactory according to moriasi et al 2015 a negative value of the pbias proposes an underestimation of the model which is attributed to peaks in the drier period of the simulation fluctuations are related to the way groundwater is calculated in swat not using a spatially diffused flow but pulses in each hru bailey et al 2019 improvements in the model performance for hydrology may be expected by incorporating a more detailed soil map as the present resolution seems too coarse for the needs of this modelling the most sensible parameters are the scs curve number cn2 mgt which was decreased to adjust the peak discharge in combination with the maximum canopy storage canmx hru the baseflow recession constant alpha bf gw and the lateral flow travel time lat ttime hru the lateral flow has a relevant role in the hydrology of this catchment baseflow was adjusted using the delay of water passing through the last soil layer gwdelay gw and the water threshold in the shallow aquifer needed for groundwater flow to occur gwqmin gw all specific changes are shown in table 3 3 3 spatial downscaling the geochemical loadings derived from rock s chemical weathering are carried out by the rivers to oceans and lakes disregarding instream transformation outgassing biological uptake secondary precipitation or ionic exchange processes loadings are added along the river network fig 5 presents the comparison of these loadings at the outlet of each subbasin which has a corresponding sampling location only fluxes from sampling campaigns are considered cf lechuga crespo et al 2020b as expected there is a corresponding generally increasing trend between the two signals downstream sampling locations have higher exports than upstream subbasins however the trend is different for each ion fig 5 mg2 so4 2 and hco3 present the best spatial collinearity among all ions and the mean loadings in each sampling location are scattered around the perfect fit line the largest deviations are na and cl where observed values are higher than the simulation ones nevertheless since loadings are added through the routing network upstream errors are carried downstream specific attention to the d2 and d3 sampling locations subbasins 2 and 7 respectively indicate underestimation for all ions especially na and cl this suggests that this area contains an ionic point source loaded with these ions which is not captured by the model this results in the worst representation among all of the catchments among the headwater sampling locations d1 e1 m1 and o1 and subbasins 8 3 5 and 6 respectively the oñati stream presents the largest loadings in which ions are commonly located close to the perfect fit line except for mg2 and so4 2 this overestimation compensates for the underestimation found in d3 for these ions improving the overall representation of the model further analysis of this stream s temporal evolution is found in section 3 4 temporal downscaling the application of the model to this case study supports that headwater locations present lower discrepancies than downstream subbasins this spatial analysis indicates that point sources exert a great impact on the model s performance since downstream locations are conditioned by incoming loadings 3 4 temporal downscaling fig 6 presents a graphical assessment of the swatlitho performance comparing the simulated and observed time series at three gauging stations altzola san prudentzio and oñati fig 3a a visual evaluation shows that the global fitted parameters applied to the calibrated qswatlitho project yield geochemical loads showing a varying degree of similarity between the simulated and the observed values suggesting the model performs differently depending on the ion and drainage basin being considered besides table 6 contains the statistical results for each pair of time series and the average values for each gauging station considering altzola results as representative of the catchment scale performance of the model the average statistics show a reasonable performance from the model r2 0 74 0 02 pbias 17 96 85 02 kge 0 08 0 48 according to the criterion presented by knoben et al 2019 regarding kge focusing on the subbasin scale each mean statistic yields a different pattern for the model s performance the mean coefficient of determination r2 is comparable among gauging stations suggesting that dynamic representation is homogeneous at the subbasin level the mean percentage of deviation pbias indicates that the altzola gauging station is the closest to reality while oñati presents the largest discrepancies the kling gupta efficiency factor kge as a summary statistic is best for san prudentzio and worst for oñati however the analysis of the standard deviation highlights the presence of two outliers in oñati mg2 and so4 2 excluding these outliers from the analysis yields the best values for oñati in all statistics kge 0 59 0 19 pbias 13 22 34 68 and r2 0 75 0 01 and worst for san prudentzio the altzola gauging station which receives waters from oñati san prudentzio and other tributaries in the main channel presents intermediate statistics suggesting that the differences present in the upper part of the catchment are routed downstream to the outlet this can also be seen in the times series in fig 6 where the deviations between the observed and the simulated values are similar in altzola and san prudentzio while they are independent at the oñati stream using the kge as an integrative measure of the model s performance values 0 41 are considered reasonable knoben et al 2019 this criterion yields a valid representation of the average ionic loadings in all gauging stations previous studies in the area using in situ samplings have highlighted the sulphate water composition in the oñati stream of the catchment lechuga crespo et al 2020b which could be related to the evaporitic presence in the upper part of the catchment iribar and ábalos 2011 however despite the evaporitic presence in the input data largest percentage the in draining catchment table 2 a karstic presence has also been reported in the area iribar and ábalos 2011 which could be a source of diluted water to system a complex interaction of these saline and diluted water sources may be responsible for the discrepancies found between the simulated and the observed values for mg2 and so4 2 in addition the presence of springs i e wells with saline water is common in the san prudentzio stream iribar and ábalos 2011 particularly the leintz gatzaga spring which provides one of the most concentrated effluents with 230 6 g l 1 of total dissolved solids and over 85 g l 1 of cl iribar and ábalos 2011 the vertical pathway of this spring is over 384 m iribar and ábalos 2011 which explains the different dynamics of cl na and k present in this area as the input from the spring is steadier than the rapid response of the groundwater and the lateral flow of the remaining catchment changing the relative contribution of these ions to the total cation concentration with time lechuga crespo et al 2020b there are few models similar to this one but a recent publication bailey et al 2019 introduced a saline module based on physical equations at chemical equilibrium into the swat code to analyse of the fate and transport of the ions in catchments in addition the researchers in that study reported problems of underestimation of the model s value regarding unmapped mineral presence in the input data which also occurred in the present study both studies have shown the importance of measured concentrations in rivers as a proxy for the geochemical minerals affecting the riverine loads in the present case the monitoring campaigns together with the gauging station s data have recorded the effect of the spring input which the model did not capture 3 5 swatlitho limitations and alternatives a recent study has presented a physically based module for assessing the fate and transport of saline ions in catchments integrated on the swat model bailey et al 2019 that model has been developed to evaluate the best irrigation management practices and their impacts on the salinisation of freshwater environments within a catchment the setup requirements are a discharge calibrated swat project the initial concentrations of the ions in the soil and the aquifer and the percentage of five solid species present in each hru to compute the chemical equilibrium bailey et al 2019 in contrast the model introduced in the present study focuses solely onthe process of chemical weathering it computes the geochemical loadings derived from lithology to the river streams based on empirical equations uses a lithological and soil description as well as hydrology as its input data the swatlitho model is not based on a spatial mineralogical representation but on lithological groups of minerals that are available worldwide cf hartmann and moosdorf 2012 or commonly available in finer resolution for local studies however it lacks point source data for irrigation saline springs or other anthropogenic inputs in fact even though the swat model has been widely applied fu et al 2019 there may be occasions when it is not possible to set up the model even though there is interest exists in assessing the chemical weathering derived geochemical loadings in a dynamic way applying the swatlitho model to evaluate daily loadings at a local scale has yielded reasonable results for representing the dynamic r2 0 73 however applying the model to local scale studies to quantify daily draining loads at the catchment s outlet is conditioned by a detailed representation of the area s lithology and the lack of other relevant salt sources when considering the altzola gauging station as a reference for the catchment scale model application the mean percentage of deviation of the model is 17 96 table 6 the results shown here do not include any variation in the mineral dissolution constant c xi in eq 1 which is likely to occur with changes in groundwater or lateral flow water temperature a more mechanistic model is needed to account for this evolution as well as the chemical equilibrium between phases as done in bailey et al 2019 however the more mechanistic a model is the harder it is to find available input data in the present study a digital filter to deconvolute the hydrograph distinguish surface runoff from baseflow and lateral flow with the total discharge time series has been tested as a potential alternative when it is not possible to set up qswatlitho projects either because of a lack of input data or computational resources constraints interannual daily loads mean first and third quartiles are shown monthly in fig 7 spatial and temporal limitations of the swatlitho model have been discussed in previous sections 3 1 3 and 3 1 4 but all three results in the oñati drainage catchment observed swatlitho and eckhardt present a similar temporal pattern however the swatlitho presents a peak for all ions in september this is not present in the other two methods supporting the idea that the swat s groundwater flux computation is affected by pulses calculated in each hru instead of a diffuse load which is better represented by graphical separation in an eckhardt model nonetheless the variances of the two methods have yielded discrete values though a welch s test for the differences between the loadings swatlitho and the eckhardt module has yield a p 0 05 which does not demonstrate enough significance to indicate that the loadings are dissimilar the visual inspection and the test demonstrate that the eckhardt digital filter may be applied when a qswatlitho project cannot be set up one of the limitations of the icwr model is the presence of spring waters or point sources that alter the streams composition those impacts are not presented in the model at this stage and should be considered when assessing the chemical loads from catchments with springs within their hydrogeological basin or groundwater inputs that are sourced outside the hydromorphological basin when it comes to the model s performance from various input data the greatest distinctions among results in the loadings have been found when changing the lithological map yielding results closer to the observed values future improvements of the swatlitho model should allow the inclusion of saline point sources which could represent natural saline springs or anthropogenic inputs and permit the calibration of the cxi parameters for each catchment which could adjust the contribution of each lithology for each location as done in the common swat calibration procedure 4 conclusion an empirical model used to estimate the annual average geochemical loads to rivers through chemical weathering has been downscaled from global to local scale and shifted from an annual average estimation to a daily dynamic output based on the coupling with swat an extended hydrological model the coupling method is described along with the case study using different input datasets to check the influence of hydrology and lithology resolution in the outputs of the model the use of globally fitted parameters for the model has yielded average loadings with a model underestimation of 17 96 with regards to the observed data though the model s performance is reasonable on the representation of spatially explicit daily geochemical loadings to stream the a catchment level the limitations of the model have been addressed such as the poor performance of the model when springs are present in the study area or when the lithological input dataset does not contain information hydrogeochemically relevant units such as gypsum intrusions which are too small to be mapped but relevant enough to affect the water chemistry and loadings an alternative has also been presented for those cases in which a qswatlitho project cannot be set up the application of a digital filter to measure data in a gauging station together with the drainage basin description lithology and soil classes the results do not present significant differences from those of the swatlitho which suggests that both methods may be applied when it is not possible to set the first one up or that spatially explicit results are not in the scope of the modelling the present work introduces a hydrogeochemical tool which is useful for estimating dynamic chemical weathering loadings out of a catchment at a local scale and also for the estimating of ionic fluxes that derive from the chemical weathering of rocks in a spatiotemporal context 4 1 software availability the soil and water assessment tool swat is freely available in https swat tamu edu software the qgis plugin for swat qswat is freely available in https swat tamu edu software qswat the modified qgis plugin that is presented in this study qswatlitho as well as the swatlitho module written in python are freely available in https swat tamu edu software swat litho declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors wish to thank the consolidated group hydro environmental processes it 1029 16 basque government the university of the basque country upv ehu ufi 11 26 and the institut national polytechnique de toulouse inpt for supporting this project the authors declare no conflict of interest author contributions j l l c helped with the conceptualisation methodology software validation formal analysis data curation investigation writing original draft review and editing and in visualization s s worked on the conceptualisation methodology validation writing review and editing resources investigation supervision and project administration e r r collaborated during the investigation validation resources data curation supervision and funding acquisition c g assisted with during the methodology software validation resources and writing review and editing j m s p supported during conceptualisation methodology software validation investigation resources writing review and editing supervision and project administration appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104893 
25902,the increase in water salinisation in catchments has led to increased concern in assessing major ion loadings in freshwater environments in this study we couple a globally fitted model on chemical weathering to the soil and water assessment tool swat for the estimation of daily geochemical loadings at the catchment scale swatlitho the enhancements include i a modification on the discretisation of the catchment area by integrating a layer describing lithology qswatlitho and ii the development of an extra module to compute the ionic loads derived from the chemical weathering of rocks the model is sensitive to input data resolution yielding the best results when including local data larger spatial and temporal discrepancies are found in one tributary associated with point sources impacting the loadings while these discrepancies are lower at headwater subbasins results suggest that despite of these discrepancies the average simulation of the daily ionic loadings is reasonable keywords model coupling geochemical loadings chemical weathering downscaling 1 introduction chemical quality assessment of river waters is crucial for understanding and assessing the potential impacts of threats to biodiversity drinking water safety and crop yields cañedo argüelles et al 2018 kaushal et al 2017 one of these threats is the rise in major ion concentration i e salinisation meybeck and helmer 1989 which despite having a relevant role in efficient ecosystem management cañedo argüelles et al 2018 has received little attention in the past traditionally two approaches tackling freshwater chemical assessments exist the analysis of water samples framed within a monitoring program e g martínez santos et al 2015 and the use of hydrogeochemical models to simulate the study area and possible scenarios e g m nassri et al 2019 water sampling is a common practice in many places yielding real valuable data but spatially and temporally homogeneous information is obtained through modelling the integration of these two approaches complements the assessment of chemical threats models may be based on physical laws or data regression equations for representing the system object of the study being classified as mechanistic or empirical respectively nowadays there exists a number of mechanistic hydrogeochemical models such as phreeqc version 3 in parkhust and appelo 2013 minteqa2 allison et al 1991 or witch goddéris et al 2006 but their applicability is commonly limited to areas where extensive necessary data mineral abundance the chemical profile of soil water initial boundary condition etc is available as input in other cases simplifications or assumptions are needed in order to apply this kind of model increasing the model s prediction uncertainty a different solution is to develop simpler models to replace these complex configurations schoups et al 2006 as an alternative to mechanistic models several empirical models focusing on single processes have been built such as the global erosion model for co2 gem co2 amiotte suchet and probst 1995 the chemical weathering rate model cwr hartmann et al 2014 and ionic fluxes derived from chemical weathering of rocks model icwr lechuga crespo et al 2020a which have yielded a static output over worldwide scale assessments i e the annual average result regarding chemical weathering rates and associated products atmospheric co2 consumption p release ionic loadings to rivers etc to date and to the best of the authors knowledge none of them have been tested on a local scale and under a dynamic approach while management decisions are usually taken at a catchment scale and need the temporal evolution within a year in the present study an empirically based model has been coupled to a physically based hydrological model to compute daily geochemical loadings from the chemical weathering of rocks the swat model has long been used to quantify the loads and concentrations of matter and nutrients from land to the catchment s outlet arnold et al 2012 fu et al 2019 as well as its evolution at different time scales however it is not possible to estimate the geochemical loadings with this model as there is no subroutine or module implemented with this purpose in this sense the icwr model lechuga crespo et al 2020a has been applied to the global scale it has yielded the first map on average annual ionic fluxes derived from the chemical weathering of rocks to rivers nevertheless its ability to simulate the dynamics of chemical weathering derived ionic loads and its performance on local catchments have not been tested yet in this sense the coupling of the swat and icwr models poses an opportunity to evaluate spatially explicit geochemical fluxes since a basin s hydrology in swat is described using the hydrological response unit s hru semi distributed approach consequently ionic loadings from chemical weathering may be assessed and if the atmospheric contribution is known this tool may work with observed data to estimate how much anthropogenic saline effluent found in a catchment it is important to note that a similar approach has been recently published by bailey et al 2019 where they present the coupling of a mechanistic model for major ion chemical partitioning within the swat hydrological code such mechanistic methodology presents the same constraints in application as the other mechanistic approaches the availability of input data and the establishment of boundary conditions for simulation the objective of this study is to downscale the icwr model spatially and temporally as well as explore the performance in a case study where a geochemistry monitoring program has been taken this case is exploratory and the model objectives are to simulate the daily geochemical loads of major ions and their spatial distribution given the modelling framework and the constraints of both models the processes to be simulated are chemical weathering of rocks mass transport and routing from catchment subbasins to the outlet the model s spatial definition is conditioned by the hru delimitation of the modified model which is explained in section 2 2 while the simulation s time step is daily a chemical equilibrium is assumed between rock and water at the temporal scale of simulation then loadings are expected to be dependent on the discharge distribution among groundwater lateral and surface fluxes the lithological groups in the underlying rock and the soil types 2 methods 2 1 overview of the swat and the icwr models the ionic fluxes derived from chemical weathering of rocks icwr lechuga crespo et al 2020a model is empirically based and its parameters have been fitted at a global scale for the estimation of spatially explicit fluxes of chemical weathering of rocks f measured in mol m 2 y 1 for each major ion ca2 mg2 na k so4 2 cl and alkalinity commonly associated with hco3 the model configuration is based on the multivariable regression shown in eq 1 the input data needed for this model includes the specific discharge q ann measured in mm the lithological composition of the rocks l i expressed as the percentage of the catchment area covered by a lithological group the soil covering the bedrock layer for the estimation of the soil shielding effect factor f sx which is different for each ion x and the parameter of the equation c xi representing the water concentration on every ion further explanation of the development calibration and limitations of the model can be seen in lechuga crespo et al 2020a the output of this model is an annual average specific flux of major ion loads originating from the chemical weathering of rocks to rivers which together with atmospheric deposition and anthropogenic inputs is the main reservoir of saline exports of a basin 1 f x q ann f s x l i c x i the swat is a physically based and semi distributed model developed to assess water sediments and nutrients in agronomic catchments at yearly monthly daily and sub daily time steps arnold et al 1998 water matter and nutrient balances are simulated in homogeneous spatial units hrus a combination of unique slope land use and soil type areas which are then aggregated to the subbasin scale and routed through tributaries and channels towards the outlet of the catchment the hrus together with the weather data at least precipitation and temperature time series provide the input data for the simulation a more detailed description of the model is available in the swat2012 theoretical handbook neitsch et al 2011 2 2 coupling the icwr model to swat the approach to spatially discretising the catchment area in the swat model has been modified to include a fourth layer in the definition of the hrus the lithological groups this modification has been performed in the qgis geographic information system plugin used to set up the model qswat dile et al 2016 the modified version is hereby called qswatlitho the swat code has not been modified to maintain the possibility of using external software such as swat cup abbaspour et al 2007 for autocalibration instead an extra module swatlitho py has been written to read the qswatlitho and swat outputs and compute the geochemical fluxes and loads the workflow of the model s configuration is shown in fig 1 2 2 1 qswatlitho traditionally a qswat model setup consists of three main phases the delineation of the watershed and subbasins the delimitation of the hrus and the write of the input tables for swat modelling for the qswatlitho implementation the second step has been modified by changing the hrus py dbutils py and qswatutils py files in the original plugin causing the inclusion of a new layer to the delimitation of the hrus now every hru contains a unique combination of slope land use soil type and lithological group and the water balance is defined for each one of them the first consequence of this change is an increased number of hrus when setting up a project causing a finer definition on the spatial distribution of the model outputs and an increase in the time used for the swat simulation the qswatlitho may be found and downloaded at https swat tamu edu software swat litho 2 2 2 icwr module swatlitho once a qswatlitho project has been set up the calibration of the hydrology is needed since this is the main dynamic input data for the icwr model because the chemical weathering process occurs mainly in the vadose zone of the water cycle the main water fluxes to be considered are groundwater q gw and lateral flows q lf the icwr model has been adapted to include them q lf q gw instead of the total average specific discharge q ann which would also include runoff here the runoff is considered as the main driver for the dilution of the total load rather than including it in the calculation of the daily geochemical loads a new module has been created so that the user can use the swat results in combination with the qswatlitho tables to obtain geochemical loadings daily time series the module consists of six main steps that are integrated into two loops for each hru data like area lithological group and soil type is extracted from the hrus lithology csv file a modified version of the hrus file in the project mdb and if necessary used to set the soil shielding effect f sx cf lechuga crespo et al 2020a then the output hru file is read to obtain the specific discharge in the lateral and groundwater fluxes to the river with this information together with the globally fitted parameters the geochemical loads are calculated for each time step of the simulation and each hru this process generates a table with the loads of each hru to the river stream for each time step then all of the loadings are summarised at the subbasin scale in each time step and saved as output the geochemical loadings are routed by adding the upstream loadings if such exists to the contribution of each subbasin draining area a workflow summary is shown in fig 2 and the modified version of the icwr regression equation 1 is shown in equation 2 where l x represents the loading of ion x in each hru in mg d 1 a is the area of the catchment in m 2 q gw lt accounts for lateral and groundwater specific discharge mm respectively f sx represents the soil shielding effect dimensionless and c lit x is the globally fitted parameter for each lithological unit and ion mol l 1 note that units are adjusted depending on the ion that is being considered and that this modification considers each hru to be a monolithic unit to the river stream 2 l x a h r u q g w l t f s x c l i t x the lithological groups used in the icwr model development study are kept unaltered in the present development evaporites ev metamorphics mt plutonic acid pa plutonic basic pb plutonic intermediate pi pyroclastics py sediment carbonates sc mixed sediments sm sediment siliciclastic ss sediment unconsolidated su volcanic acid va volcanic basic vb volcanic intermediate vi water bodies wb ice and glaciers ig and no data nd according to the description presented in hartmann and moosdorf 2012 and dürr et al 2005 2 3 case study deba river catchment a case study is set up to explore the model s application the validation comprises three steps first the annual comparison of the results to evaluate the model s sensitivity and select the input data among different combinations second the analysis of geochemical loadings in all subbasins derived from the qswatlitho swatlitho combination spatial downscaling and last the comparison of the daily representation in three gauging stations temporal downscaling the case study selected for this purpose is the deba river catchment fig 3 on which numerous studies related to urban and industrial pollution on its sediments and waters have been conducted martínez santos et al 2015 garcía garcía et al 2019 unda calvo et al 2019 lechuga crespo et al 2020b there are eleven sampling locations along its main channel and tributaries where a monitoring campaign was established between april 2014 and january 2017 samples were taken in a monthly or bi monthly time step in addition there are three gauging stations measuring among other variables discharge and electrical conductivity every 10 min 2 3 1 study area the deba river basin has a complete drainage area of 538 km2 and 60 km of main stream a maximum slope of 40 and an elevation varying from 0 at sea level to 1320 m in botreatiz the highest mountain which is located in the northern part of spain in the gipuzkoa province in the basque country fig 3 regarding its hydrometeorology there is a strong variation between humid and dry years as well as a strong seasonal variability about 30 of the total annual water volume is exported in december and january and in dry summers the specific discharge can reach 0 6 mm the average annual precipitation is estimated to be 1613 mm while the mean temperature is 12 7 c leading to the highest potential evapotranspiration etp of the surrounding catchments at 871 mm in terms of the occupation of this catchment there is a strong presence of industries with a population of 135 000 inhabitants grouped into four important villages arrasate oñati bergara eibar and deba 37 of the area is occupied by pinus spp 27 is covered by autochthonous forest and 11 is given to farmlands and pastures this catchment is commonly located over evaporitic rocks gypsum and anhydride deposits included in detrital rocks which according to the classification proposed by hartmann and moosdorf 2012 and dürr et al 2005 correspond to a mix of siliciclastic carbonate and mixed sediments together with other lithological groups a detailed description of the geology of the zone is addressed in ábalos et al 2008 and iribar and ábalos 2011 historically this catchment has suffered a strong urban and industrial pressure gipuzkoa council accessed on october 2019 and previous studies on the pollution in this catchment martínez santos et al 2015 garcía garcía et al 2019 unda calvo et al 2019 have highlighted the inputs of urban and residual industrial effluents treated through wastewater treatment plants wwtp located in the middle of the catchment where phosphorus is eliminated using cl3fe only from may 1st to october 15th resulting in the presence of metals in the water and sediment matrixes the analysis of this anthropogenic influence has been monitored from april 2014 to january 2017 in 11 sampling locations in the main channel and tributaries highlighting the nutrients and metal input of urban and industrial effluents furthermore a recent study on this catchment has focused on the major ion chemistry of its waters assessing the main geochemical processes input in relation to the anthropogenic input lechuga crespo et al 2020b while emphasising the influence of an evaporitic saline spring in the southwest part of the catchment which exerts a great impact on the water chemistry downstream to the outlet of the catchment 2 3 2 set up of the qswatlitho project a local digital elevation map dem 25 m resolution cell was used to create the stream network locate the outlet of the catchment and delimit the drainage area subbasins were merged to obtain their draining to the sampling locations of the monitoring campaigns a european land use map from the corine land cover project 100 m resolution a soil map from the harmonized world database a 30 arc second resolution and a local lithological map reclassified for the categories found in hartmann and moosdorf 2012 were combined with the dem derived slope map to create the hrus the description and source of the datasets may be seen in table 1 table 2 and fig 3 while setting up the model three slope ranges were established 0 5 5 10 10 and no simplification was performed to reduce the number of hrus the weather input data was obtained from a hydrometeorological station located close to the outlet fig 3 consisting of precipitation as well as maximum and minimum temperature daily time series from january 1994 to december 2017 the observed data for discharge was covered from january 2004 to december 2017 for three gauging stations located close to the outlet and near the outlet of the two major subbasins of this catchment see fig 3 swat has been used to compute the hydrological representation of the case study using the qswatlitho hru definition for the spatial discretisation but using the same water balance as the swat model observed data for riverine chemical concentration ranged from april 2014 to january 2017 a monitoring program samples the river waters monthly or bimonthly using a pre washed polypropylene bottle which was carried to the laboratory at 4 c and filtered through 0 45 μm filters one replicate was acidified to 0 2 with hno3 68 for base cations ca2 mg2 na and k using icp oes perkinelmer optima 2000 the other non acidified replicate was used to analyse anions cl no3 so4 2 through ion chromatography dionex ics 3000 alkalinity was measured using a total organic carbon analyzer toc l shimadzu the ionic charge balance icb was within 10 for all samples used in this study for the modelling of the geochemical loads groundwater and lateral flows from the swat hydrological representation have been used as a source of lithological chemical weathering derived loads while runoff has been attributed to lower concentrations inducing dilution in the stream s concentration following the recommendations of asabe 2017 three periods were defined in this project a warmup period to reduce the effect of state variables initial values six years january 1998 december 2003 a calibration period to optimise the parameters ten years january 2004 december 2013 and a validation period to test the model capabilities in an independent dataset four years january 2014 december 2017 the model s performance evaluation has been carried out for the calibration and validation periods independently using graphical methods time series between observed and simulated and relative statistical measures coefficient of determination r2 nash sutcliffe efficiency nse pbias and kling gupta kge the moriasi et al 2015 standard has been considered in this study to evaluate the model s performance however the authors have found no reference when comparing the daily loads of major ions so the exploration of the results would yield the first reference for future similar analysis 2 3 3 discharge parameterisation the geochemical reactions responsible for ionic loads derived from rocks to the river are assumed to be in equilibrium at daily scales however other sources like human input or atmospheric deposition are expected to vary in these temporal ranges thus the simulation both calibration and validation has been done at a daily time step the first step is to calibrate the discharge in surface runoff lateral flow and groundwater flow which will be the main drivers in the temporal application of the icwr model the discharge has been calibrated using the parameters found in table 3 through both manual calibration and autocalibration with the sufi 2 algorithm in swat cup abbaspour et al 2007 three gauging stations have been used to evaluate the model performance on discharge calibration using four statistical criteria the coefficient of determination r2 the nash sutcliff efficiency nse the percent of bias pbias and the kling gupta efficiency kge all the statistics are applied to the simulated and observed values r2 focuses in the fit between the trends varying from 0 no fit to 1 perfect fit pbias calculates the global over negative value or underestimation positive value nse evaluates the trends similar to r2 but varying from to 1 perfect fit and kge is based on pearson s coefficient r including bias and variability ranging from to 1 perfect fit where values 0 41 could be considered as a reasonable performance knoben et al 2019 2 3 4 downscaling the icwr model the original icwr model lechuga crespo et al 2020a was developed for an annual average specific flux output for which only the average specific discharge was needed for hydrology to explore the possibilities of applying this model at lower spatial and temporal scales three assessments have been performed a model s sensitivity analysis a spatial evaluation and a temporal assessment the model s sensitivity to input data was evaluated by testing different global and local datasets combinations two lithological maps one clipped from the global lithological map glim hartmann and moosdorf 2012 and a local one obtained from the gipuzkoa council geoeuskadi eus together with two annual average specific discharges one obtained from a global dataset unh grd fekete et al 2002 and other from the gipuzkoa council hydrological department www gipuzkoa eus were combined to obtain four output datasets the comparison with observed data indicated the best input data setup for building the qswatlitho project these results are shown and discussed in section 3 1 model s sensitivity to input data before applying the swatlitho module it is necessary to calibrate the water balance the model setup and the calibration of hydrology are discussed in section 3 2 case study set up and discharge calibration once the model was built and hydrology was calibrated a simulation was conducted period january 2014 to december 2017 the application of the swatlitho module allowed the evaluation of the model s spatial and temporal performance no calibration of the icwr parameters has been done and globally fitted values were used lechuga crespo et al 2020a the model s spatial downscaling evaluation was done by contrasting simulated geochemical loadings at the subbasin outlet with observed loadings at the corresponding sampling location see fig 3a results are presented in section 3 3 spatial downscaling the temporal downscale was evaluated at three gauging stations where daily loadings were derived from punctual data and continuous registries integration the results are shown in section 3 4 temporal downscaling finally model limitations improvement suggestions and alternatives are presented in section 3 5 swatlitho limitations and alternatives even though the wide applicability of the model makes this approach versatile its setup may be constrained by input data availability a proposed alternative approach is the use of digital filters to deconvolute the hydrological signal between surface and groundwater fluxes in this sense we computed the hydrological deconvolution using the eckhardt digital filter eckhardt 2005 xie et al 2020 this test has been performed at the three gauging stations of the catchment 3 results and discussion 3 1 model s sensitivity to input data average annual loadings obtained for the four input data combinations are shown in table 4 the original icwr model lechuga crespo et al 2020a was calibrated and validated using global data method unh glim in table 4 and data on rivers worldwide from the glorich database the highest values among all methods considered are found for the unh glim method and the greatest differences are found not between the two hydrological datasets but between the lithological maps this confirms that the lithological representation has a major impact on the loadings computed by the model regarding the values obtained with the four datasets in comparison with the observed values gauging station in table 4 the closest values are found for the eus geus method the local data for hydrology and lithology nevertheless the difference between the observed and the modelled values are different between ions and gauging stations both the altzola and san prudentzio gauging stations present the highest differences in ca2 na k and cl while the differences between the observed and the simulated values are lower for other ions such differences are not found in the oñati tributary where the highest difference is found for mg2 cl and so4 2 but which is still lower than the altzola and the san prudentzio bias for the previously noted ions the common pattern in the differences found for altzola and san prudentzio and the difference for the oñati stream suggest that there is a common phenomenon not captured by the model s performance in the san prudentzio draining basin which affects downstream at the outlet of the catchment the monitoring program and previous studies in the area iribar and ábalos 2011 martínez santos et al 2015 have shown that the southeastern part of the catchment has the highest values of ca2 na k and cl which is related to the presence of gypsum intrusions and a spring altering the local water s composition in both lithological maps used the intrusion of gypsum evaporites in the southwest part of the catchment seems to be underestimated in addition according to iribar and ábalos 2011 the southern part of the catchment contains a combination of different geological registries albian and aptian albian where there is a common presence of springs with saline waters within this catchment the leintz gatzaga spring contains one of the most concentrated effluents to the streams 230 6 g l 1 according to iribar and ábalos 2011 this suggests that the impact of the saline is not properly mapped in either the global or the local lithological maps but that it exerts a strong influence on the chemical characteristics of this area downstream lechuga crespo et al 2020b for this reason the observed data on na k and cl are higher than those modelled especially in the san prudentzio subbasin the inclusion of a local lithological map with a finer spatial resolution of lithology has decreased the loads to around half of those obtained with the previous map these new values are closer to reality when considering mg2 hco3 and so4 2 which are the elements less affected by the spring inputs the inclusion of a spatially distributed lithology has improved the results of the model leading to the conclusion that increasing the spatial resolution of the lithology input data has a major effect on the output of the model from the model s sensitivity analysis we conclude that when applying the icwr model to local studies local lithological data should be applied moreover consideration of saline springs should be taken into account when evaluating the model s performance 3 2 case study set up and discharge calibration the combination of slope land use soil types and lithological classes in this catchment leads to a spatial discretisation consisting of 11 subbasins and 985 hrus when building the same project considering land use soil type and slope layers in the hru definition step the number of spatial units reaches 286 hrus a more detailed project regarding spatial distribution increases the computation time but the water balance calibration is more comprehensive which is a key input for the geochemical loads computation and the model s temporal downscaling regarding the calibration of hydrology at the daily time step fig 4 most of the parameterisation has been focused on calibrating groundwater and lateral flow which account for almost 96 of the annual discharge at the catchment s outlet the parameterisation of the model has yielded the results summarised in table 5 and moriasi et al 2015 qualifies the simulation as satisfactory for calibration and validation according to these results the model has been considered enough to represent the hydrology of the catchment studied nse is used based on its performance which is better when the variable s range of variation is large however in low flows the denominator tends towards 0 leading to higher values when the errors are small oeurng et al 2011 the higher values for r2 in comparison to the nse suggest a good representation of the dynamic but a worse depiction of the exact discharge value indicating a difference between observed and simulated values which is stronger in lower flow periods this can also be seen in the pbias where the calibration for san prudentzio has yielded a value classified as non satisfactory according to moriasi et al 2015 a negative value of the pbias proposes an underestimation of the model which is attributed to peaks in the drier period of the simulation fluctuations are related to the way groundwater is calculated in swat not using a spatially diffused flow but pulses in each hru bailey et al 2019 improvements in the model performance for hydrology may be expected by incorporating a more detailed soil map as the present resolution seems too coarse for the needs of this modelling the most sensible parameters are the scs curve number cn2 mgt which was decreased to adjust the peak discharge in combination with the maximum canopy storage canmx hru the baseflow recession constant alpha bf gw and the lateral flow travel time lat ttime hru the lateral flow has a relevant role in the hydrology of this catchment baseflow was adjusted using the delay of water passing through the last soil layer gwdelay gw and the water threshold in the shallow aquifer needed for groundwater flow to occur gwqmin gw all specific changes are shown in table 3 3 3 spatial downscaling the geochemical loadings derived from rock s chemical weathering are carried out by the rivers to oceans and lakes disregarding instream transformation outgassing biological uptake secondary precipitation or ionic exchange processes loadings are added along the river network fig 5 presents the comparison of these loadings at the outlet of each subbasin which has a corresponding sampling location only fluxes from sampling campaigns are considered cf lechuga crespo et al 2020b as expected there is a corresponding generally increasing trend between the two signals downstream sampling locations have higher exports than upstream subbasins however the trend is different for each ion fig 5 mg2 so4 2 and hco3 present the best spatial collinearity among all ions and the mean loadings in each sampling location are scattered around the perfect fit line the largest deviations are na and cl where observed values are higher than the simulation ones nevertheless since loadings are added through the routing network upstream errors are carried downstream specific attention to the d2 and d3 sampling locations subbasins 2 and 7 respectively indicate underestimation for all ions especially na and cl this suggests that this area contains an ionic point source loaded with these ions which is not captured by the model this results in the worst representation among all of the catchments among the headwater sampling locations d1 e1 m1 and o1 and subbasins 8 3 5 and 6 respectively the oñati stream presents the largest loadings in which ions are commonly located close to the perfect fit line except for mg2 and so4 2 this overestimation compensates for the underestimation found in d3 for these ions improving the overall representation of the model further analysis of this stream s temporal evolution is found in section 3 4 temporal downscaling the application of the model to this case study supports that headwater locations present lower discrepancies than downstream subbasins this spatial analysis indicates that point sources exert a great impact on the model s performance since downstream locations are conditioned by incoming loadings 3 4 temporal downscaling fig 6 presents a graphical assessment of the swatlitho performance comparing the simulated and observed time series at three gauging stations altzola san prudentzio and oñati fig 3a a visual evaluation shows that the global fitted parameters applied to the calibrated qswatlitho project yield geochemical loads showing a varying degree of similarity between the simulated and the observed values suggesting the model performs differently depending on the ion and drainage basin being considered besides table 6 contains the statistical results for each pair of time series and the average values for each gauging station considering altzola results as representative of the catchment scale performance of the model the average statistics show a reasonable performance from the model r2 0 74 0 02 pbias 17 96 85 02 kge 0 08 0 48 according to the criterion presented by knoben et al 2019 regarding kge focusing on the subbasin scale each mean statistic yields a different pattern for the model s performance the mean coefficient of determination r2 is comparable among gauging stations suggesting that dynamic representation is homogeneous at the subbasin level the mean percentage of deviation pbias indicates that the altzola gauging station is the closest to reality while oñati presents the largest discrepancies the kling gupta efficiency factor kge as a summary statistic is best for san prudentzio and worst for oñati however the analysis of the standard deviation highlights the presence of two outliers in oñati mg2 and so4 2 excluding these outliers from the analysis yields the best values for oñati in all statistics kge 0 59 0 19 pbias 13 22 34 68 and r2 0 75 0 01 and worst for san prudentzio the altzola gauging station which receives waters from oñati san prudentzio and other tributaries in the main channel presents intermediate statistics suggesting that the differences present in the upper part of the catchment are routed downstream to the outlet this can also be seen in the times series in fig 6 where the deviations between the observed and the simulated values are similar in altzola and san prudentzio while they are independent at the oñati stream using the kge as an integrative measure of the model s performance values 0 41 are considered reasonable knoben et al 2019 this criterion yields a valid representation of the average ionic loadings in all gauging stations previous studies in the area using in situ samplings have highlighted the sulphate water composition in the oñati stream of the catchment lechuga crespo et al 2020b which could be related to the evaporitic presence in the upper part of the catchment iribar and ábalos 2011 however despite the evaporitic presence in the input data largest percentage the in draining catchment table 2 a karstic presence has also been reported in the area iribar and ábalos 2011 which could be a source of diluted water to system a complex interaction of these saline and diluted water sources may be responsible for the discrepancies found between the simulated and the observed values for mg2 and so4 2 in addition the presence of springs i e wells with saline water is common in the san prudentzio stream iribar and ábalos 2011 particularly the leintz gatzaga spring which provides one of the most concentrated effluents with 230 6 g l 1 of total dissolved solids and over 85 g l 1 of cl iribar and ábalos 2011 the vertical pathway of this spring is over 384 m iribar and ábalos 2011 which explains the different dynamics of cl na and k present in this area as the input from the spring is steadier than the rapid response of the groundwater and the lateral flow of the remaining catchment changing the relative contribution of these ions to the total cation concentration with time lechuga crespo et al 2020b there are few models similar to this one but a recent publication bailey et al 2019 introduced a saline module based on physical equations at chemical equilibrium into the swat code to analyse of the fate and transport of the ions in catchments in addition the researchers in that study reported problems of underestimation of the model s value regarding unmapped mineral presence in the input data which also occurred in the present study both studies have shown the importance of measured concentrations in rivers as a proxy for the geochemical minerals affecting the riverine loads in the present case the monitoring campaigns together with the gauging station s data have recorded the effect of the spring input which the model did not capture 3 5 swatlitho limitations and alternatives a recent study has presented a physically based module for assessing the fate and transport of saline ions in catchments integrated on the swat model bailey et al 2019 that model has been developed to evaluate the best irrigation management practices and their impacts on the salinisation of freshwater environments within a catchment the setup requirements are a discharge calibrated swat project the initial concentrations of the ions in the soil and the aquifer and the percentage of five solid species present in each hru to compute the chemical equilibrium bailey et al 2019 in contrast the model introduced in the present study focuses solely onthe process of chemical weathering it computes the geochemical loadings derived from lithology to the river streams based on empirical equations uses a lithological and soil description as well as hydrology as its input data the swatlitho model is not based on a spatial mineralogical representation but on lithological groups of minerals that are available worldwide cf hartmann and moosdorf 2012 or commonly available in finer resolution for local studies however it lacks point source data for irrigation saline springs or other anthropogenic inputs in fact even though the swat model has been widely applied fu et al 2019 there may be occasions when it is not possible to set up the model even though there is interest exists in assessing the chemical weathering derived geochemical loadings in a dynamic way applying the swatlitho model to evaluate daily loadings at a local scale has yielded reasonable results for representing the dynamic r2 0 73 however applying the model to local scale studies to quantify daily draining loads at the catchment s outlet is conditioned by a detailed representation of the area s lithology and the lack of other relevant salt sources when considering the altzola gauging station as a reference for the catchment scale model application the mean percentage of deviation of the model is 17 96 table 6 the results shown here do not include any variation in the mineral dissolution constant c xi in eq 1 which is likely to occur with changes in groundwater or lateral flow water temperature a more mechanistic model is needed to account for this evolution as well as the chemical equilibrium between phases as done in bailey et al 2019 however the more mechanistic a model is the harder it is to find available input data in the present study a digital filter to deconvolute the hydrograph distinguish surface runoff from baseflow and lateral flow with the total discharge time series has been tested as a potential alternative when it is not possible to set up qswatlitho projects either because of a lack of input data or computational resources constraints interannual daily loads mean first and third quartiles are shown monthly in fig 7 spatial and temporal limitations of the swatlitho model have been discussed in previous sections 3 1 3 and 3 1 4 but all three results in the oñati drainage catchment observed swatlitho and eckhardt present a similar temporal pattern however the swatlitho presents a peak for all ions in september this is not present in the other two methods supporting the idea that the swat s groundwater flux computation is affected by pulses calculated in each hru instead of a diffuse load which is better represented by graphical separation in an eckhardt model nonetheless the variances of the two methods have yielded discrete values though a welch s test for the differences between the loadings swatlitho and the eckhardt module has yield a p 0 05 which does not demonstrate enough significance to indicate that the loadings are dissimilar the visual inspection and the test demonstrate that the eckhardt digital filter may be applied when a qswatlitho project cannot be set up one of the limitations of the icwr model is the presence of spring waters or point sources that alter the streams composition those impacts are not presented in the model at this stage and should be considered when assessing the chemical loads from catchments with springs within their hydrogeological basin or groundwater inputs that are sourced outside the hydromorphological basin when it comes to the model s performance from various input data the greatest distinctions among results in the loadings have been found when changing the lithological map yielding results closer to the observed values future improvements of the swatlitho model should allow the inclusion of saline point sources which could represent natural saline springs or anthropogenic inputs and permit the calibration of the cxi parameters for each catchment which could adjust the contribution of each lithology for each location as done in the common swat calibration procedure 4 conclusion an empirical model used to estimate the annual average geochemical loads to rivers through chemical weathering has been downscaled from global to local scale and shifted from an annual average estimation to a daily dynamic output based on the coupling with swat an extended hydrological model the coupling method is described along with the case study using different input datasets to check the influence of hydrology and lithology resolution in the outputs of the model the use of globally fitted parameters for the model has yielded average loadings with a model underestimation of 17 96 with regards to the observed data though the model s performance is reasonable on the representation of spatially explicit daily geochemical loadings to stream the a catchment level the limitations of the model have been addressed such as the poor performance of the model when springs are present in the study area or when the lithological input dataset does not contain information hydrogeochemically relevant units such as gypsum intrusions which are too small to be mapped but relevant enough to affect the water chemistry and loadings an alternative has also been presented for those cases in which a qswatlitho project cannot be set up the application of a digital filter to measure data in a gauging station together with the drainage basin description lithology and soil classes the results do not present significant differences from those of the swatlitho which suggests that both methods may be applied when it is not possible to set the first one up or that spatially explicit results are not in the scope of the modelling the present work introduces a hydrogeochemical tool which is useful for estimating dynamic chemical weathering loadings out of a catchment at a local scale and also for the estimating of ionic fluxes that derive from the chemical weathering of rocks in a spatiotemporal context 4 1 software availability the soil and water assessment tool swat is freely available in https swat tamu edu software the qgis plugin for swat qswat is freely available in https swat tamu edu software qswat the modified qgis plugin that is presented in this study qswatlitho as well as the swatlitho module written in python are freely available in https swat tamu edu software swat litho declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors wish to thank the consolidated group hydro environmental processes it 1029 16 basque government the university of the basque country upv ehu ufi 11 26 and the institut national polytechnique de toulouse inpt for supporting this project the authors declare no conflict of interest author contributions j l l c helped with the conceptualisation methodology software validation formal analysis data curation investigation writing original draft review and editing and in visualization s s worked on the conceptualisation methodology validation writing review and editing resources investigation supervision and project administration e r r collaborated during the investigation validation resources data curation supervision and funding acquisition c g assisted with during the methodology software validation resources and writing review and editing j m s p supported during conceptualisation methodology software validation investigation resources writing review and editing supervision and project administration appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104893 
25903,constructed wetlands cws are engineering systems recognized as an efficient and sustainable option to wastewater treatment due to the growing interest in cws for waste management the number of works analyzing their footprint and impact has risen in the last years thus the study of these systems and their components in construction operation and demolition phases is important to characterize the technology and achieve a fully environmental friendly approach until now no complete tools for measuring both direct and indirect greenhouse gas ghg emissions in cws have been reported in the field some efforts in this line are life cycle assessment tools which can be economically expensive and usually require specific training therefore this work aims to present a web application as an open and complete tool for the estimation of ghg emissions in cws including both direct and indirect emissions and considering all the stages involved in their management keywords constructed wetlands wastewater treatment carbon footprint web application development 1 introduction over the last 200 years the amount of greenhouse gases ghgs in the atmosphere has increased due to anthropogenic causes such as fossil fuel production and use agricultural and industrial activities and the unsustainable exploitation of natural resources el fadel and massoud 2001 these anthropogenic ghg emissions are recognized as primarily responsible for global warming gw and climate change escriva bou et al 2018 if current emission levels are sustained over time they may lead to potentially catastrophic changes in climate patterns moreover evidence suggests that researchers have been conservative in their predictions in this sense brysse et al 2013 while a reduction in ghg emissions particularly co2 could help to a global temperature stabilization this challenge imperatively requires international cooperation and commitment as those reached at the paris conference in december 2015 recently ratified and reinforced at the madrid conference in december 2019 obergassel et al 2020 in turn abatement technologies are needed to reduce ghg emissions and the associated negative effects de richter et al 2016 in line with this the objective of wastewater treatment is to reduce the environmental impact caused by waste discharges however this process can also contribute to ghgs through the production of n2o ch4 and co2 including emissions as a consequence of the energy required in wastewater treatment plants wwtp the ch4 produced from wastewater treatment was found to account for about 5 out of global ch4 emissions el fadel and massoud 2001 among the new abatement technologies for wastewater treatment are constructed wetlands cws which are engineered systems designed for the utilization of natural processes such as wetland vegetation soils and microbial assemblages to assist in wastewater treatment vymazal 2014 besides cws have proved to work at the same efficiency levels as those achieved in wwtps kadlec and wallace 2008 muñoz et al 2006 vymazal 2014 wu et al 2014 when analyzing the impact of cws it is important to compare the emissions generated in these systems with the emissions resulting from the operation of conventional wwtps søvik and kløve 2007 as a representative case chen et al 2011 quantified and compared the ghg emissions per m3 of treated wastewater in a horizontal sub surface flow constructed wetland hf cw and in a cycle active sludge system cass obtaining 0 20 and 0 74 kg co2eq respectively taking into account these figures together with the fact that more than 100 000 cws worldwide currently treat over one million m3 of water per day türker et al 2014 it can be estimated that up to 540 000 kg co2eq per day could be saved due to the use of cws therefore the widespread use of cw technology to treat wastewater could contribute to mitigating global warming among many other environmental benefits over the last years the scientific community has estimated evaluated ghg emissions by cws from a holistic perspective using the life cycle assessment lca methodology chen et al 2011 dixon et al 2003 fuchs et al 2011 lopsik 2013 machado et al 2007 pan et al 2011 uggetti et al 2012 zhao and liu 2013 lca is a method used for compiling and evaluating the inputs outputs and potential environmental impacts of a product or service throughout its whole life cycle and it is regulated by the iso 14040 2006 and iso 14044 2006 series besides lca is data intensive and requires a lot of high quality databases specifically its key issues are spatial boundaries the time scale over which life cycle comparison is made the scale at which comparison is made and the level of detail into which the study goes into lopsik 2013 a large number of full lca tools and databases including several of great quality and detail can be found elsewhere see section 2 2 however to the best of authors knowledge there are still no available databases to calculate direct ghg emissions generated in wastewater treatment in cws e g denitrification nitrification or methanogenesis as indicated in the review reported by mander et al 2014 the detailed and accurate datasets available in this field could be structured and exploited for database development on the other hand there are plenty of databases available to calculate indirect ghg emissions that could be used for estimations related to the construction operation management energy consumption and demolition of cws nevertheless these indirect emissions can be very different from direct ones chen et al 2011 zhao and liu 2013 hence both direct and indirect emissions must be taken into account to offer an exhaustive view of the impact posed by cws which requires the design of specific lca tools lca tools can be economically expensive and usually require specific training so their management is frequently limited to the engineering community they can also carry high complexity in terms of structure to be implemented in cw projects intuitively and lca software normally runs natively only in windows operating systems thus this work aims to present an open web application for calculating ghg emissions in cws and devoted to anyone interested in the field for this purpose reported data of the scientific literature have been considered according to the lca methodology for the estimation of direct and indirect ghg emissions and integrated into a web application to offer a useful tool for emission calculation in cws the present paper is organized as follows section 2 presents a background in cws and associated lca methodologies in section 3 the materials and methods used in this work are detailed section 4 shows the main results of the web application designed for calculating ghg emissions in cws finally section 5 summarizes the conclusions of this work 2 related work this section reviews the relevance of cws as an alternative technology for wastewater treatment with several advantages over conventional processes in terms of ghg emissions it also analyzes several well known lca methods and software tools that have been specifically applied or developed in the field 2 1 constructed wetlands for wastewater treatment constructed wetlands are engineering systems recognized as an efficient and sustainable option for wastewater treatment cws utilize the natural processes involving wetland vegetation soils and associated microbial community these systems are based on reed beds with several advantages over traditional technologies including activated slugged processed and trickling filters scholz and lee 2005 vymazal 2014 conventionally cws have been applied for the treatment of municipal wastewater but over the last years their use has extended to the treatment of industrial and agricultural wastewater among others vymazal 2019 the main advantages of cws are i these systems provide a cost efficient treatment solution both in terms of investment and operation ii cws can operate without the addition of other chemical substances used in conventional treatment plants lowering the associated environmental impacts iii the number of resources needed including energy consumption is significantly reduced and iv production of by products are minimal in cw operation since sludge can be accumulated and dewatered within the system it is worth noting however that cws cannot directly compete with conventional technologies when it is required to treat high volumes of wastewater as in urban areas due to the need for large tracts of land in this case cws could be used as complementary technology stefanakis 2020 cws are frequently classified according to the water flow direction and the type of vegetation used in this sense cw systems are usually planted with rooted emergent macrophyte species according to the flow pattern they can be classified into two main groups free water surface cws and subsurface flow cws in the first case water flows over substrate media creating a free water surface of few centimeters of depth in subsurface flow cws water flows through a porous substrate and in such case and depending on the specific flow direction the systems within this group can be subdivided into horizontal and vertical subsurface flow cws hf and vf respectively giraldi et al 2010 stefanakis et al 2014 the main difference between both typologies is that in horizontal systems there is no water surface exposed to the atmosphere as water horizontally flows below the substrate porous medium it is also possible to find hybrid cws combining both vertical and horizontal stages vymazal 2013 the significance of cws has increased over the last years and are subjected to intensive research to overcome their limitations through innovative strategies and approaches the most important limitations of the systems are related to the necessity of large land areas the possible dependence of treatment efficiency as a result of seasonal conditions which promotes changes in environmental conditions the resistance capacity of bio components to the presence of toxic compounds and the lack of standard and optimal designs for widespread used cws act as sources sinks or transformers of compounds according to the system configuration hydrological conditions and water residence time therefore important factors influencing treatment capacity are flow type substrate features plant species used hydraulic loading rate and temperature hijosa valsero et al 2010 maier et al 2009 pálfy et al 2017 vymazal 2019 in line with the increasing interest in cws the number of studies analyzing their footprint and impacts has risen in the last years to create sustainable technological solutions based on these systems it is important the proper selection of construction materials and operating conditions that make it possible to minimize the impact on the environment fuchs et al 2011 machado et al 2007 wang et al 2018 this way cws would represent not only an advantageous wastewater treatment but also a fully environmental friendly approach gkika et al 2015 in this context this work tries to offer a useful tool for the estimations of footprints of cws through an open web based application that helps to analyze the impact of the systems according to the characteristics and operating conditions 2 2 methodologies and software tools for life cycle assessment in constructed wetlands some of the most relevant tools for lca are impact 2002 jolliet et al 2003 recipe lopsik 2013 and simapro fuchs et al 2011 firstly impact 2002 is a methodology that combines two damage models midpoint oriented method and endpoint oriented method the methodology incorporates different categories of medium impact human toxicity respiratory effects ionizing radiation ozone depletion photochemical oxidant formation aquatic and terrestrial eco toxicity aquatic eutrophication terrestrial eutrophication and acidification land cover global warming non renewable energy and mineral extraction through the midpoint categories the inventory results are linked to four categories of endpoint damage which in this case also correspond to the areas of environmental protection human health ecological system quality climate change and resources the normalization factors are based on the european average values such as annual impact scores for an average citizen regarding the recipe methodology it utilizes indicators of emission characterization and indicators of resource use to score the relative severity of a category for an environmental impact recipe calculates the characterization factors at the middle and end levels thus there are 18 midpoint indicators and 3 endpoint ones midpoint indicators focus on unique environmental problems such as climate change or acidification endpoint indicators show environmental impact at the three highest levels effects on human health biodiversity and resource scarcity converting mid points to endpoints simplifies the interpretation of results however the uncertainty in the results increases with each simplification finally simapro is a tool that allows the evaluation of the environmental impacts of products either services or goods activities and processes it also allows lca to be carried out using both bibliographic databases and databases created by the users themselves simapro is also able to store analyze and track the environmental performance of services and or products this tool facilitates the analysis and graphical representation of complex cycles in a systematic and insightful way this software includes a user interface a life cycle unit process database an impact assessment database and a calculator that combines the databases according to the modeling entered through the user interface apart from the above methodologies there are some specific tools for the construction sector such as dubocalc davidson and wir 2003 and palate nathman 2008 the former calculates all the effects of material and energy consumption from the conception of the project to the end of its life or from extraction to demolition and the reuse phase all relevant environmental effects during the entire life cycle are included in the calculation likewise palate pavement life cycle assessment tool for environmental and economic effects takes the information entered by the user for the design initial construction maintenance equipment usage and costs of a road in this manner palate provides results for the environmental effects and costs of the pavement and road life cycle the environmental effects investigated include energy consumption and emissions of co2 nox and pm10 among others in general all these software tools and methodologies are implemented as desktop applications and commonly developed in excel which requires installations on the user s computer our approach is to offer a web based tool to be used anywhere without the need of installing specific software furthermore these methodologies and applications are more focused either on general products and services or towards specific engineering works and therefore their databases have a different target to the goal of estimating the carbon footprint of cws that is proposed in this work 3 material and methods this section firstly explains the sources and methods used for data gathering and for calculating ghg emissions in cws then the methodology and software tools used to develop the web application are explained in detail 3 1 design of a constructed wetland database at the end of 2012 3787 publications were dealing with cws corresponding to the period from 1991 to 2011 the number of publications for the years 2017 and 2018 predicted by previous field growth models based on the data from the two previous decades is three times higher than in 2011 zhi and ji 2012 which was recently proved elsewhere andreo martínez et al 2020 this shows that this is a research field of great interest to the scientific community given the substantial increase in scientific works on technologies for the mitigation of ghg effects a specific spreadsheet for the estimation of the carbon footprint emitted by cws was developed in 2018 by the authors of the present manuscript the lca methodology was used for this purpose martínez rocamora et al 2016 in which the final amount of emitted ghgs by cws is calculated as the sum of all emissions of all the elements taken into account expressed as kg of co2eq per m3 of wastewater treated among other parameters the system boundaries include construction operation and demolition phases the assembly of the system together with the emissions and sources associated with each considered component are detailed in the supplementary material although some authors have excluded the end of life of the infrastructures and equipment assuming that this stage has not significant influence on the overall impact corbella et al 2017 other authors reported that these indirect emissions should be taken into account lopsik 2013 the spreadsheet was divided into three sections materials and construction operation and summary in addition concepts not previously considered in other works such as the drafting phase of the engineering project the possible construction of an operation house or the excavation work in the construction and demolition phases were also considered once the data and calculations related to all the development stages in cws were gathered in a spreadsheet the next step was the creation of a web application to query these data and calculations the development of this web application arises as a more friendly user tool in comparison to a spreadsheet 3 2 development of a web application for constructed wetlands the development of the web application has followed the scrum methodology schwaber and beedle 2001 scrum is an agile methodology that allows adapting to change in project requirements in a rapid manner based on iterations or sprints that enable an incremental development of the application in this project the role of product owner namely the responsible for monitoring and optimizing the technical value of the application was taken by dr joaquín quesada medina head of green chemical process engineering research group of university of murcia at that time dr pedro andreo martínez acted as the scrum master i e the responsible for coordinating the development team which in turn was composed of the three remaining authors of this paper a total of 6 sprints plus a sprint 0 kick off iteration were needed for the development of the application comprising a total of 255 h with an initial product backlog of 55 user stories and 430 story points which yields an average of 1 7 story points per hour approximately this section highlights the main software artifacts utilized in the development of the web application following this methodology namely the software architecture of the application the database and the user interface design the technologies employed in the development of the web application are apache server and php language for the back end whereas the front end has been developed through the frameworks codeigniter and bootstrap using the jquery library and the javascript language the database has been implemented using the mysql database management system the application has been developed in a docker container to ease its deployment in any environment 3 2 1 architecture of the web application the software architecture of the web application follows the model view controller mvc design pattern leff and rayfield 2001 in this approach the users are shown a view they interact with this view launches requests that are processed by the controllers using the models usually a database to retrieve the information this information is processed and sent back to the views to be shown to the user this design pattern decouples these components allowing code reusability and parallel development fig 1 shows a scheme of the application architecture following the mvc pattern and how the different components interact with each other to manage the information from the user to the database and vice versa the view components indicate the different interfaces web pages in this case by which the user can interact with the application apart from the sign in and sign up operations the user can manage the information about the emission factors and materials from the cw create projects to calculate the cw emissions through the operation view and obtain a summary report for each project as an example the materials construction view shows information to the user about the different emission factors of the cw materials and at the same time the user can insert update or delete this information in the database when the user updates the information the materials construction controller is called again and it uses the materials model to save the information using the insert method 3 2 2 database our database is based on two main types of tables the emission factor tables which are the tables where the different factors eligible for emission calculations are stored these data are taken from the spreadsheet indicated in section 3 1 table 1 shows the complete list of these tables in the database to represent all the available emission factors and fig 2 shows a specific table for the concept constructed wetland as an example the administration tables that help to manage the application these tables allow managing the creation of projects and users for emission calculations checking the different emission factors chosen during the execution of a test as well as storing the different calculations obtained these tables are identified with the prefix tbl in order to differentiate them from the previous ones table 2 shows the complete list of these tables whereas fig 3 shows a partial view on the design of the database for the application for the sake of readability only the most relevant tables are shown in the figure note that as shown in fig 3 three options of cws bed 1 and 2 with a slope of 45 and bed 3 with a slope of 30 have been considered in case of using a hybrid system with different dimensions fillers or configurations 3 2 3 user interface design with the aim of increasing the usability of the proposed tool several principles of user interface design have been adopted that can be found elsewhere lynch and horton 2016 stone et al 2005 in particular we have chosen a minimalistic design to avoid information overload the use of bootstrap templates has helped greatly in achieving this minimalistic design moreover the web pages are written using html5 and css3 allowing the incorporation of widgets that help to show the results and graphs obtained from the carbon footprint calculation in a separate and clear manner these web pages follow a responsive web design to avoid screen size problems the interface allows the user to work interactively with the different calculation options and returns a real time response when the calculations are submitted moreover documentation is shown throughout the main input data elements to guide the user in the introduction of data especially for the materials and construction section errors are controlled by preventing the user from entering wrong values e g entering text in numeric fields the process of the user interface design aimed to improve the user experience is a process that should be continuously revisited in this first version of the tool the interface offers a minimalistic design that complies with some of the most relevant usability principles as the ones mentioned above 4 results and discussion 4 1 web portal the web application for managing cws emissions is deployed at https crftpr herokuapp com and it is available in english after signing up the user is presented with the home page shown in fig 4 the top menu shows the different sections into which the application is divided namely materials construction operation data entry views summary where the results are shown and emission factors where such factors used in the calculations are shown the left menu allows controlling the project being worked on creating new ones or resetting an existing one the use of the web application is fully guided through detailed instructions written in each web page of the application helping the user to introduce the required data 4 2 validation of the web based application the validation of the web based application was accomplished using the data of carbon footprint generated by different types of constructed wetlands previously reported in the scientific literature the works considered were selected according to the parameters employed for carbon footprint calculation chen et al 2011 pan et al 2011 uggetti et al 2012 zhao and liu 2013 specifically these works used at least the seven following parameters for the estimation of greenhouse gas emissions size type of constructed wetland amount of wastewater to be treated influent and effluent characteristics energy consumption and operating time this criterion was fixed since the carbon footprint of constructed wetlands co2eq emissions calculated by the web application considered these parameters as the basics for estimation however the application allows the introduction of a large number of additional parameters to offer a holistic approach of the process and to obtain a realistic and accurate estimation of co2eq emission on the other hand as a specific case in those processes in which sludge treatment is performed with no energy consumption requirements the minimum number of parameters necessary to calculate the amount of co2eq emitted is reduced to 4 type and size of the constructed wetland flow to be treated and operating time uggetti et al 2012 table 3 summarizes the technical and operating parameters of the constructed wetlands reported in the literature and used for comparison and validation purposes in this work these data include the parameters needed for the calculation of carbon footprint in terms of co2eq through the developed web application it is worth noting that the types of constructed wetland comprised cover both horizontal flow hf and vertical flow vf systems with varying sizes from 210 to 2000 m2 and wide operating time horizon from 1 to 20 years moreover two types of main functionalities are included treatment of wastewater with standard flow rates from 200 m3 day and treatment of sludge sludge drying thus the data include varying operating conditions and designs for constructed wetlands the carbon footprint of the constructed wetlands co2eq emissions reported in the selected works are compared with the estimations calculated with the web application in table 4 for its validation as can be seen the relative differences between both values can significantly vary in each case the greatest relative difference between the reported and estimated values being of 21 9 and the smallest relative difference of 5 respectively although the relative differences can be deemed relatively high in some cases 21 9 and 20 4 it is considered that relative differences in terms of ghg emissions of up to 183 are usual in turn these differences lie in the type of lca database used martínez rocamora et al 2016 on the other hand the relative differences for 4 out of 6 estimations performed are below or equal to 16 6 which can be considered negligible therefore given these results the developed web application for the calculation of the carbon footprint co2eq of cws can be considered as an effective tool 4 3 running example the web application proposed in this work was used to calculate the co2eq emissions generated in a pig farm as a case of study the exploitation facilities are located in the south east of spain and include 4200 units of breeding stock the facilities and characteristics of the pig farm data for the construction phase of the wetland and additional technical data necessary to calculate the amount of co2eq emitted are summarized in table 5 as observed in table 5 the parameters considered are related to both the construction phase and the operating horizon time of 20 years the estimation of the co2eq emissions calculated by the excel spreadsheet and the web applications were compared to observe any possible differences the results obtained with the excel spreadsheet were 2 21 kg co2eq per m3 of purified slurry and 0 44 kg co2eq per kg of bod5 removed the results achieved with the web application were identical which validates its implementation the total co2eq emissions include the construction operation and elimination phases of the wetland system the comparison of both estimations is provided as supplementary material therefore in view of the results obtained it can be concluded that the use test was satisfactory furthermore the web application offers several advantages i no software installation required since access it is possible using a browser ii no requirement for specific operating systems nor the installation of additional applications iii access is free and the application is free of licenses iv it can be used anywhere simply with internet access on the other hand in terms of co2eq emissions the results of the current study show that the construction phase has a significant impact on the environment when compared to the use phase for 20 years fig 5 shows the relative contribution of general concepts to the total co2eq emissions as well as the total emission per each phase construction operation and elimination phase of the cw in comparison to the other authors larsen and hauschild 2008 have noted that although some authors argue that the impact from the construction phase is negligible in the context of the whole life cycle and that therefore this phase can be excluded from analysis the construction phase impact may be of importance for a certain type of treatment systems e g wetlands sand filter conventional active sludge treatment microfiltration and ozoning vlasopoulos et al 2006 results show that the environmental impact of the construction phase can account for 1 96 of the total impact of the treatment system depending on the technology and impact assessment methods especially in the case of cws therefore the web application can be used to obtain a comprehensive analysis of the impact of the system on the environment 5 conclusion and future works constructed wetlands cws have gained growing importance as a sustainable alternative for wastewater treatment with recognized advantages over conventional technologies including low energy consumption the widespread use of these systems either as single technology for wastewater treatment in small capacity facilities or as complementary units in high capacity installations could contribute to increasing the sustainability in the treatment of water discharges and to the mitigation of emissions in this type of operation therefore the analysis of the impact of cws in terms of ghg emissions is required to characterize the systems and to deploy fully sustainable cw options in this context a web based application for calculating co2 emissions in cw systems is presented taking into account all the stages involved in their management the web application is intended to offer an effective tool that is freely accessible through https crftpr herokuapp com since no complete tools for measuring direct and indirect ghg emissions generated in cws are available validation tests and a running example have been performed to demonstrate the accuracy of the web application proposed in this work the application allows the calculation of the overall co2eq emissions according to the characteristics and operational variables of installations and it also provides the co2eq emissions generated in the different phases construction operation and demolition stages thus a comprehensive tool for the assessment of cw impacts has been reported as a limitation of this work it should be noted that the usability of the application has not been evaluated yet by external users therefore we do not have any report on how intuitive and user friendly the tool is perceived by them in order to obtain feedback on the usability of the application we plan to conduct a survey among the registered users as a future work the web application could be extended to calculate other emissions typologies nh4 sox nox thus having a much more complete study of the cws emissions and their possible adverse effects for the environment in addition project cloning to facilitate data entry sending and sharing of projects between users or adaptation to mobile devices could also be implemented in future versions of the application declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was partially supported by the fundación séneca del centro de coordinación de la investigación de la región de murcia under project 20813 pi 18 and by the spanish ministry of science innovation and universities under project rtc 2017 6389 5 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104898 
25903,constructed wetlands cws are engineering systems recognized as an efficient and sustainable option to wastewater treatment due to the growing interest in cws for waste management the number of works analyzing their footprint and impact has risen in the last years thus the study of these systems and their components in construction operation and demolition phases is important to characterize the technology and achieve a fully environmental friendly approach until now no complete tools for measuring both direct and indirect greenhouse gas ghg emissions in cws have been reported in the field some efforts in this line are life cycle assessment tools which can be economically expensive and usually require specific training therefore this work aims to present a web application as an open and complete tool for the estimation of ghg emissions in cws including both direct and indirect emissions and considering all the stages involved in their management keywords constructed wetlands wastewater treatment carbon footprint web application development 1 introduction over the last 200 years the amount of greenhouse gases ghgs in the atmosphere has increased due to anthropogenic causes such as fossil fuel production and use agricultural and industrial activities and the unsustainable exploitation of natural resources el fadel and massoud 2001 these anthropogenic ghg emissions are recognized as primarily responsible for global warming gw and climate change escriva bou et al 2018 if current emission levels are sustained over time they may lead to potentially catastrophic changes in climate patterns moreover evidence suggests that researchers have been conservative in their predictions in this sense brysse et al 2013 while a reduction in ghg emissions particularly co2 could help to a global temperature stabilization this challenge imperatively requires international cooperation and commitment as those reached at the paris conference in december 2015 recently ratified and reinforced at the madrid conference in december 2019 obergassel et al 2020 in turn abatement technologies are needed to reduce ghg emissions and the associated negative effects de richter et al 2016 in line with this the objective of wastewater treatment is to reduce the environmental impact caused by waste discharges however this process can also contribute to ghgs through the production of n2o ch4 and co2 including emissions as a consequence of the energy required in wastewater treatment plants wwtp the ch4 produced from wastewater treatment was found to account for about 5 out of global ch4 emissions el fadel and massoud 2001 among the new abatement technologies for wastewater treatment are constructed wetlands cws which are engineered systems designed for the utilization of natural processes such as wetland vegetation soils and microbial assemblages to assist in wastewater treatment vymazal 2014 besides cws have proved to work at the same efficiency levels as those achieved in wwtps kadlec and wallace 2008 muñoz et al 2006 vymazal 2014 wu et al 2014 when analyzing the impact of cws it is important to compare the emissions generated in these systems with the emissions resulting from the operation of conventional wwtps søvik and kløve 2007 as a representative case chen et al 2011 quantified and compared the ghg emissions per m3 of treated wastewater in a horizontal sub surface flow constructed wetland hf cw and in a cycle active sludge system cass obtaining 0 20 and 0 74 kg co2eq respectively taking into account these figures together with the fact that more than 100 000 cws worldwide currently treat over one million m3 of water per day türker et al 2014 it can be estimated that up to 540 000 kg co2eq per day could be saved due to the use of cws therefore the widespread use of cw technology to treat wastewater could contribute to mitigating global warming among many other environmental benefits over the last years the scientific community has estimated evaluated ghg emissions by cws from a holistic perspective using the life cycle assessment lca methodology chen et al 2011 dixon et al 2003 fuchs et al 2011 lopsik 2013 machado et al 2007 pan et al 2011 uggetti et al 2012 zhao and liu 2013 lca is a method used for compiling and evaluating the inputs outputs and potential environmental impacts of a product or service throughout its whole life cycle and it is regulated by the iso 14040 2006 and iso 14044 2006 series besides lca is data intensive and requires a lot of high quality databases specifically its key issues are spatial boundaries the time scale over which life cycle comparison is made the scale at which comparison is made and the level of detail into which the study goes into lopsik 2013 a large number of full lca tools and databases including several of great quality and detail can be found elsewhere see section 2 2 however to the best of authors knowledge there are still no available databases to calculate direct ghg emissions generated in wastewater treatment in cws e g denitrification nitrification or methanogenesis as indicated in the review reported by mander et al 2014 the detailed and accurate datasets available in this field could be structured and exploited for database development on the other hand there are plenty of databases available to calculate indirect ghg emissions that could be used for estimations related to the construction operation management energy consumption and demolition of cws nevertheless these indirect emissions can be very different from direct ones chen et al 2011 zhao and liu 2013 hence both direct and indirect emissions must be taken into account to offer an exhaustive view of the impact posed by cws which requires the design of specific lca tools lca tools can be economically expensive and usually require specific training so their management is frequently limited to the engineering community they can also carry high complexity in terms of structure to be implemented in cw projects intuitively and lca software normally runs natively only in windows operating systems thus this work aims to present an open web application for calculating ghg emissions in cws and devoted to anyone interested in the field for this purpose reported data of the scientific literature have been considered according to the lca methodology for the estimation of direct and indirect ghg emissions and integrated into a web application to offer a useful tool for emission calculation in cws the present paper is organized as follows section 2 presents a background in cws and associated lca methodologies in section 3 the materials and methods used in this work are detailed section 4 shows the main results of the web application designed for calculating ghg emissions in cws finally section 5 summarizes the conclusions of this work 2 related work this section reviews the relevance of cws as an alternative technology for wastewater treatment with several advantages over conventional processes in terms of ghg emissions it also analyzes several well known lca methods and software tools that have been specifically applied or developed in the field 2 1 constructed wetlands for wastewater treatment constructed wetlands are engineering systems recognized as an efficient and sustainable option for wastewater treatment cws utilize the natural processes involving wetland vegetation soils and associated microbial community these systems are based on reed beds with several advantages over traditional technologies including activated slugged processed and trickling filters scholz and lee 2005 vymazal 2014 conventionally cws have been applied for the treatment of municipal wastewater but over the last years their use has extended to the treatment of industrial and agricultural wastewater among others vymazal 2019 the main advantages of cws are i these systems provide a cost efficient treatment solution both in terms of investment and operation ii cws can operate without the addition of other chemical substances used in conventional treatment plants lowering the associated environmental impacts iii the number of resources needed including energy consumption is significantly reduced and iv production of by products are minimal in cw operation since sludge can be accumulated and dewatered within the system it is worth noting however that cws cannot directly compete with conventional technologies when it is required to treat high volumes of wastewater as in urban areas due to the need for large tracts of land in this case cws could be used as complementary technology stefanakis 2020 cws are frequently classified according to the water flow direction and the type of vegetation used in this sense cw systems are usually planted with rooted emergent macrophyte species according to the flow pattern they can be classified into two main groups free water surface cws and subsurface flow cws in the first case water flows over substrate media creating a free water surface of few centimeters of depth in subsurface flow cws water flows through a porous substrate and in such case and depending on the specific flow direction the systems within this group can be subdivided into horizontal and vertical subsurface flow cws hf and vf respectively giraldi et al 2010 stefanakis et al 2014 the main difference between both typologies is that in horizontal systems there is no water surface exposed to the atmosphere as water horizontally flows below the substrate porous medium it is also possible to find hybrid cws combining both vertical and horizontal stages vymazal 2013 the significance of cws has increased over the last years and are subjected to intensive research to overcome their limitations through innovative strategies and approaches the most important limitations of the systems are related to the necessity of large land areas the possible dependence of treatment efficiency as a result of seasonal conditions which promotes changes in environmental conditions the resistance capacity of bio components to the presence of toxic compounds and the lack of standard and optimal designs for widespread used cws act as sources sinks or transformers of compounds according to the system configuration hydrological conditions and water residence time therefore important factors influencing treatment capacity are flow type substrate features plant species used hydraulic loading rate and temperature hijosa valsero et al 2010 maier et al 2009 pálfy et al 2017 vymazal 2019 in line with the increasing interest in cws the number of studies analyzing their footprint and impacts has risen in the last years to create sustainable technological solutions based on these systems it is important the proper selection of construction materials and operating conditions that make it possible to minimize the impact on the environment fuchs et al 2011 machado et al 2007 wang et al 2018 this way cws would represent not only an advantageous wastewater treatment but also a fully environmental friendly approach gkika et al 2015 in this context this work tries to offer a useful tool for the estimations of footprints of cws through an open web based application that helps to analyze the impact of the systems according to the characteristics and operating conditions 2 2 methodologies and software tools for life cycle assessment in constructed wetlands some of the most relevant tools for lca are impact 2002 jolliet et al 2003 recipe lopsik 2013 and simapro fuchs et al 2011 firstly impact 2002 is a methodology that combines two damage models midpoint oriented method and endpoint oriented method the methodology incorporates different categories of medium impact human toxicity respiratory effects ionizing radiation ozone depletion photochemical oxidant formation aquatic and terrestrial eco toxicity aquatic eutrophication terrestrial eutrophication and acidification land cover global warming non renewable energy and mineral extraction through the midpoint categories the inventory results are linked to four categories of endpoint damage which in this case also correspond to the areas of environmental protection human health ecological system quality climate change and resources the normalization factors are based on the european average values such as annual impact scores for an average citizen regarding the recipe methodology it utilizes indicators of emission characterization and indicators of resource use to score the relative severity of a category for an environmental impact recipe calculates the characterization factors at the middle and end levels thus there are 18 midpoint indicators and 3 endpoint ones midpoint indicators focus on unique environmental problems such as climate change or acidification endpoint indicators show environmental impact at the three highest levels effects on human health biodiversity and resource scarcity converting mid points to endpoints simplifies the interpretation of results however the uncertainty in the results increases with each simplification finally simapro is a tool that allows the evaluation of the environmental impacts of products either services or goods activities and processes it also allows lca to be carried out using both bibliographic databases and databases created by the users themselves simapro is also able to store analyze and track the environmental performance of services and or products this tool facilitates the analysis and graphical representation of complex cycles in a systematic and insightful way this software includes a user interface a life cycle unit process database an impact assessment database and a calculator that combines the databases according to the modeling entered through the user interface apart from the above methodologies there are some specific tools for the construction sector such as dubocalc davidson and wir 2003 and palate nathman 2008 the former calculates all the effects of material and energy consumption from the conception of the project to the end of its life or from extraction to demolition and the reuse phase all relevant environmental effects during the entire life cycle are included in the calculation likewise palate pavement life cycle assessment tool for environmental and economic effects takes the information entered by the user for the design initial construction maintenance equipment usage and costs of a road in this manner palate provides results for the environmental effects and costs of the pavement and road life cycle the environmental effects investigated include energy consumption and emissions of co2 nox and pm10 among others in general all these software tools and methodologies are implemented as desktop applications and commonly developed in excel which requires installations on the user s computer our approach is to offer a web based tool to be used anywhere without the need of installing specific software furthermore these methodologies and applications are more focused either on general products and services or towards specific engineering works and therefore their databases have a different target to the goal of estimating the carbon footprint of cws that is proposed in this work 3 material and methods this section firstly explains the sources and methods used for data gathering and for calculating ghg emissions in cws then the methodology and software tools used to develop the web application are explained in detail 3 1 design of a constructed wetland database at the end of 2012 3787 publications were dealing with cws corresponding to the period from 1991 to 2011 the number of publications for the years 2017 and 2018 predicted by previous field growth models based on the data from the two previous decades is three times higher than in 2011 zhi and ji 2012 which was recently proved elsewhere andreo martínez et al 2020 this shows that this is a research field of great interest to the scientific community given the substantial increase in scientific works on technologies for the mitigation of ghg effects a specific spreadsheet for the estimation of the carbon footprint emitted by cws was developed in 2018 by the authors of the present manuscript the lca methodology was used for this purpose martínez rocamora et al 2016 in which the final amount of emitted ghgs by cws is calculated as the sum of all emissions of all the elements taken into account expressed as kg of co2eq per m3 of wastewater treated among other parameters the system boundaries include construction operation and demolition phases the assembly of the system together with the emissions and sources associated with each considered component are detailed in the supplementary material although some authors have excluded the end of life of the infrastructures and equipment assuming that this stage has not significant influence on the overall impact corbella et al 2017 other authors reported that these indirect emissions should be taken into account lopsik 2013 the spreadsheet was divided into three sections materials and construction operation and summary in addition concepts not previously considered in other works such as the drafting phase of the engineering project the possible construction of an operation house or the excavation work in the construction and demolition phases were also considered once the data and calculations related to all the development stages in cws were gathered in a spreadsheet the next step was the creation of a web application to query these data and calculations the development of this web application arises as a more friendly user tool in comparison to a spreadsheet 3 2 development of a web application for constructed wetlands the development of the web application has followed the scrum methodology schwaber and beedle 2001 scrum is an agile methodology that allows adapting to change in project requirements in a rapid manner based on iterations or sprints that enable an incremental development of the application in this project the role of product owner namely the responsible for monitoring and optimizing the technical value of the application was taken by dr joaquín quesada medina head of green chemical process engineering research group of university of murcia at that time dr pedro andreo martínez acted as the scrum master i e the responsible for coordinating the development team which in turn was composed of the three remaining authors of this paper a total of 6 sprints plus a sprint 0 kick off iteration were needed for the development of the application comprising a total of 255 h with an initial product backlog of 55 user stories and 430 story points which yields an average of 1 7 story points per hour approximately this section highlights the main software artifacts utilized in the development of the web application following this methodology namely the software architecture of the application the database and the user interface design the technologies employed in the development of the web application are apache server and php language for the back end whereas the front end has been developed through the frameworks codeigniter and bootstrap using the jquery library and the javascript language the database has been implemented using the mysql database management system the application has been developed in a docker container to ease its deployment in any environment 3 2 1 architecture of the web application the software architecture of the web application follows the model view controller mvc design pattern leff and rayfield 2001 in this approach the users are shown a view they interact with this view launches requests that are processed by the controllers using the models usually a database to retrieve the information this information is processed and sent back to the views to be shown to the user this design pattern decouples these components allowing code reusability and parallel development fig 1 shows a scheme of the application architecture following the mvc pattern and how the different components interact with each other to manage the information from the user to the database and vice versa the view components indicate the different interfaces web pages in this case by which the user can interact with the application apart from the sign in and sign up operations the user can manage the information about the emission factors and materials from the cw create projects to calculate the cw emissions through the operation view and obtain a summary report for each project as an example the materials construction view shows information to the user about the different emission factors of the cw materials and at the same time the user can insert update or delete this information in the database when the user updates the information the materials construction controller is called again and it uses the materials model to save the information using the insert method 3 2 2 database our database is based on two main types of tables the emission factor tables which are the tables where the different factors eligible for emission calculations are stored these data are taken from the spreadsheet indicated in section 3 1 table 1 shows the complete list of these tables in the database to represent all the available emission factors and fig 2 shows a specific table for the concept constructed wetland as an example the administration tables that help to manage the application these tables allow managing the creation of projects and users for emission calculations checking the different emission factors chosen during the execution of a test as well as storing the different calculations obtained these tables are identified with the prefix tbl in order to differentiate them from the previous ones table 2 shows the complete list of these tables whereas fig 3 shows a partial view on the design of the database for the application for the sake of readability only the most relevant tables are shown in the figure note that as shown in fig 3 three options of cws bed 1 and 2 with a slope of 45 and bed 3 with a slope of 30 have been considered in case of using a hybrid system with different dimensions fillers or configurations 3 2 3 user interface design with the aim of increasing the usability of the proposed tool several principles of user interface design have been adopted that can be found elsewhere lynch and horton 2016 stone et al 2005 in particular we have chosen a minimalistic design to avoid information overload the use of bootstrap templates has helped greatly in achieving this minimalistic design moreover the web pages are written using html5 and css3 allowing the incorporation of widgets that help to show the results and graphs obtained from the carbon footprint calculation in a separate and clear manner these web pages follow a responsive web design to avoid screen size problems the interface allows the user to work interactively with the different calculation options and returns a real time response when the calculations are submitted moreover documentation is shown throughout the main input data elements to guide the user in the introduction of data especially for the materials and construction section errors are controlled by preventing the user from entering wrong values e g entering text in numeric fields the process of the user interface design aimed to improve the user experience is a process that should be continuously revisited in this first version of the tool the interface offers a minimalistic design that complies with some of the most relevant usability principles as the ones mentioned above 4 results and discussion 4 1 web portal the web application for managing cws emissions is deployed at https crftpr herokuapp com and it is available in english after signing up the user is presented with the home page shown in fig 4 the top menu shows the different sections into which the application is divided namely materials construction operation data entry views summary where the results are shown and emission factors where such factors used in the calculations are shown the left menu allows controlling the project being worked on creating new ones or resetting an existing one the use of the web application is fully guided through detailed instructions written in each web page of the application helping the user to introduce the required data 4 2 validation of the web based application the validation of the web based application was accomplished using the data of carbon footprint generated by different types of constructed wetlands previously reported in the scientific literature the works considered were selected according to the parameters employed for carbon footprint calculation chen et al 2011 pan et al 2011 uggetti et al 2012 zhao and liu 2013 specifically these works used at least the seven following parameters for the estimation of greenhouse gas emissions size type of constructed wetland amount of wastewater to be treated influent and effluent characteristics energy consumption and operating time this criterion was fixed since the carbon footprint of constructed wetlands co2eq emissions calculated by the web application considered these parameters as the basics for estimation however the application allows the introduction of a large number of additional parameters to offer a holistic approach of the process and to obtain a realistic and accurate estimation of co2eq emission on the other hand as a specific case in those processes in which sludge treatment is performed with no energy consumption requirements the minimum number of parameters necessary to calculate the amount of co2eq emitted is reduced to 4 type and size of the constructed wetland flow to be treated and operating time uggetti et al 2012 table 3 summarizes the technical and operating parameters of the constructed wetlands reported in the literature and used for comparison and validation purposes in this work these data include the parameters needed for the calculation of carbon footprint in terms of co2eq through the developed web application it is worth noting that the types of constructed wetland comprised cover both horizontal flow hf and vertical flow vf systems with varying sizes from 210 to 2000 m2 and wide operating time horizon from 1 to 20 years moreover two types of main functionalities are included treatment of wastewater with standard flow rates from 200 m3 day and treatment of sludge sludge drying thus the data include varying operating conditions and designs for constructed wetlands the carbon footprint of the constructed wetlands co2eq emissions reported in the selected works are compared with the estimations calculated with the web application in table 4 for its validation as can be seen the relative differences between both values can significantly vary in each case the greatest relative difference between the reported and estimated values being of 21 9 and the smallest relative difference of 5 respectively although the relative differences can be deemed relatively high in some cases 21 9 and 20 4 it is considered that relative differences in terms of ghg emissions of up to 183 are usual in turn these differences lie in the type of lca database used martínez rocamora et al 2016 on the other hand the relative differences for 4 out of 6 estimations performed are below or equal to 16 6 which can be considered negligible therefore given these results the developed web application for the calculation of the carbon footprint co2eq of cws can be considered as an effective tool 4 3 running example the web application proposed in this work was used to calculate the co2eq emissions generated in a pig farm as a case of study the exploitation facilities are located in the south east of spain and include 4200 units of breeding stock the facilities and characteristics of the pig farm data for the construction phase of the wetland and additional technical data necessary to calculate the amount of co2eq emitted are summarized in table 5 as observed in table 5 the parameters considered are related to both the construction phase and the operating horizon time of 20 years the estimation of the co2eq emissions calculated by the excel spreadsheet and the web applications were compared to observe any possible differences the results obtained with the excel spreadsheet were 2 21 kg co2eq per m3 of purified slurry and 0 44 kg co2eq per kg of bod5 removed the results achieved with the web application were identical which validates its implementation the total co2eq emissions include the construction operation and elimination phases of the wetland system the comparison of both estimations is provided as supplementary material therefore in view of the results obtained it can be concluded that the use test was satisfactory furthermore the web application offers several advantages i no software installation required since access it is possible using a browser ii no requirement for specific operating systems nor the installation of additional applications iii access is free and the application is free of licenses iv it can be used anywhere simply with internet access on the other hand in terms of co2eq emissions the results of the current study show that the construction phase has a significant impact on the environment when compared to the use phase for 20 years fig 5 shows the relative contribution of general concepts to the total co2eq emissions as well as the total emission per each phase construction operation and elimination phase of the cw in comparison to the other authors larsen and hauschild 2008 have noted that although some authors argue that the impact from the construction phase is negligible in the context of the whole life cycle and that therefore this phase can be excluded from analysis the construction phase impact may be of importance for a certain type of treatment systems e g wetlands sand filter conventional active sludge treatment microfiltration and ozoning vlasopoulos et al 2006 results show that the environmental impact of the construction phase can account for 1 96 of the total impact of the treatment system depending on the technology and impact assessment methods especially in the case of cws therefore the web application can be used to obtain a comprehensive analysis of the impact of the system on the environment 5 conclusion and future works constructed wetlands cws have gained growing importance as a sustainable alternative for wastewater treatment with recognized advantages over conventional technologies including low energy consumption the widespread use of these systems either as single technology for wastewater treatment in small capacity facilities or as complementary units in high capacity installations could contribute to increasing the sustainability in the treatment of water discharges and to the mitigation of emissions in this type of operation therefore the analysis of the impact of cws in terms of ghg emissions is required to characterize the systems and to deploy fully sustainable cw options in this context a web based application for calculating co2 emissions in cw systems is presented taking into account all the stages involved in their management the web application is intended to offer an effective tool that is freely accessible through https crftpr herokuapp com since no complete tools for measuring direct and indirect ghg emissions generated in cws are available validation tests and a running example have been performed to demonstrate the accuracy of the web application proposed in this work the application allows the calculation of the overall co2eq emissions according to the characteristics and operational variables of installations and it also provides the co2eq emissions generated in the different phases construction operation and demolition stages thus a comprehensive tool for the assessment of cw impacts has been reported as a limitation of this work it should be noted that the usability of the application has not been evaluated yet by external users therefore we do not have any report on how intuitive and user friendly the tool is perceived by them in order to obtain feedback on the usability of the application we plan to conduct a survey among the registered users as a future work the web application could be extended to calculate other emissions typologies nh4 sox nox thus having a much more complete study of the cws emissions and their possible adverse effects for the environment in addition project cloning to facilitate data entry sending and sharing of projects between users or adaptation to mobile devices could also be implemented in future versions of the application declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was partially supported by the fundación séneca del centro de coordinación de la investigación de la región de murcia under project 20813 pi 18 and by the spanish ministry of science innovation and universities under project rtc 2017 6389 5 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104898 
25904,this study s objective is to assess the sensitivity analysis potential for application in the context of the stochastic input based modelling of fluvial morphodynamics the corresponding work involved 1 an analysis of the work available in the literature and 2 an independent application of sensitivity analysis for comparison the application of sensitivity analysis was accomplished by using a numerical hydro morphodynamic model to represent the natural morphodynamical processes response to the uncertainty in a selected set of variables the resulting morphodynamical sensitivities were quantified and a characterization of the relationship between the variables effects and morphodynamics was produced the potential generalization of the results of sensitivity analysis for the purposes of validating stochastic modelling across different case studies was assessed resulting sensitivities were found to be strongly case specific with little generalization potential indicating that sensitivity analysis in the context of fluvial morphodynamics is likely of little scientific interest keywords numerical modelling fluvial morphodynamics sensitivity analysis validation of stochastic modelling 1 introduction the process of simulating and particularly forecasting fluvial morphodynamics is always permeated by a certain amount of uncertainty this uncertainty is a result both of the convolution of effects from the large number of associated variables and their respective inter dependencies and of the difficulty involved in estimating their values and effects in the morphodynamical processes no two natural river channels are alike in terms of the characteristics and the relative importance of these variables as such fluvial morphodynamics i e the erosive deposition processes can be considered as having a strong probabilistic nature turowski 2011 hu and guo 2010 concurrently the importance of stochastic modelling in the analysis of fluvial morphodynamics has long been recognized in the study areas of hydrology and geomorphology van vuren 2005 posner e and duan 2012 the main objective of this study is to explore and analyse the potential usefulness of sensitivity analysis in validating the results of stochastic numerical modelling of fluvial morphodynamics sensitivity analysis is the process of characterizing the relevance of individual variables towards the overall uncertainty of morphodynamics as a characterization of a system s inherent relationships it has often been used to validate the results of stochastic modelling van vliet et al 2016 kleijnen 1999 sargent et al 2016 this study is intended to analyse the possibility of performing this task in a fluvial context namely one where morphodynamics is represented by way of a numerical hydrodynamic and morphodynamic hm model stochastic modelling in this instance refers not to the modelling itself being stochastic in nature such as in bohorquez and ancey 2015 but specifically to when the input of the hm model is stochastically generated resulting in a stochastic application i e recurrent and with stochastically generated inputs of the numerical hm models in the vast majority of the situations the individual simulations which are a part of stochastic numerical modelling hold no inherent value unless understood in the context of all of the simulations the validation of applications of stochastic modelling is therefore most often based on the validation of certain characteristic behaviours of the underlying processes in turn represented by the corresponding models which are deemed to be virtually universal across case studies concordantly the potential for the validation of stochastic modelling by way of sensitivity analysis is directly tied with the potential generalization of the results of sensitivity analysis from a different perspective the validation of the stochastic modelling s application requires the existence of repetitive behavioural patterns in the morphodynamical processes and or the bed level change i e consistent patterns in the underlying dynamics of morphodynamical change in order to assess the generalizability of the results of sensitivity analysis both a review of existing studies on this subject in the context of bed morphodynamics and a reference case study i e a term of comparison regarding sensitivity analysis have been developed that reference case was created by applying the sensitivity analysis to a straight channel defined based on a simplification of a real case study and simulated using a hm model by estimating and comparing the morphodynamical sensitivities between the reference case and the results available in the literature conclusions can be drawn regarding the potential generalization of sensitivity analysis results while directly simulating a large number of case studies could be a simple approach for assessing the generalization potential of sensitivity analysis issues with data availability and the large computational requirements of these simulations impede this solution as an alternative the available literature s results regarding the magnitudes of morphodynamical sensitivities along with the methods used in quantifying the sensitivities in the literature were analysed and compared with the reference case s results in search for potential common generalizable aspects in sensitivity analysis based on this comparison results of sensitivity analyses were assessed in terms of the generalization potential of the sensitivities magnitudes and of other characteristics of the stochastic simulations a stylized straight channel with an initial well defined cross section and constant longitudinal slope was adopted for performing a series of simulations for varying combinations of variables values and flood events i e in unsteady flow conditions this straight channel corresponds to a simplified representation of a stretch of a river in portugal the mondego river and was defined based on the simplification of its overall shape as obtained from the corresponding data the results of the present study are intended to serve as term of comparison for understanding and interpreting the results of existing sensitivity studies in the literature the analysis of a simplified stylized case study is intended to reduce the effects of the complexity of fluvial morphodynamics in particular its natural tendencies in terms of bed level evolution thereby producing a clearer description of the relationships between the variables and morphodynamics as well as the corresponding morphodynamical sensitivities additionally the clearer nature of the results also lends itself to the production of more informative analyses using appropriate sensitivity analysis tools this is because in more intricate case studies the superposition of morphodynamical effects can obscure the results of sensitivity analysis both independent and joint sensitivity analysis were performed regarding the variables impact on morphodynamics the relative influence of the different variables was quantified for different aspects of channel morphology e g mean bed level change spatial distribution of bed level change etc in order to better represent the non linear aspects of morphodynamics and the interdependency between variables the numerical hydro and morphodynamic model used in this study was the cche2d zhang 2005 specifically using the cche gui 3 29 and cche mesh 3 programs all of which are available at the website of the national centre for computational hydroscience and engineering of the university of mississippi ncche 2017 considering that the hm model s sensitivities in the context of sensitivity analysis are unique to the model itself they are of no interest for the validation of stochastic modelling as they are by definition not generalizable this study therefore focused specifically on morphodynamical sensitivities and the sensitivities of morphodynamical processes which in theory all models should correctly portray concurrently theoretical considerations regarding the veracity or the appropriateness of the many different potential numerical representations of the mechanics of sediment transport and bed dynamics e g the bed load sediment continuity or semi empirical formulas involved in the hm modelling were deemed as irrelevant for the intended purpose of this study 1 1 literature review sensitivity analysis is a type of analysis which is intended to provide a description of the relative sensitivity of a model s outputs to each of its input variables parameters accordingly it is an important step in any stochastic application of models as it provides important information on the relationships represented by the numerical model at the same time sensitivity analysis is virtually the only general purpose tool for validating the results of numerical modelling stochastic or not with randomly stochastically generated inputs saltelli et al 2008 looking at the sensitivity analysis results for the different case studies available in the literature along with a case study developed in this paper for comparison purposes the generalization potential of sensitivity analysis can be assessed this section summarizes the methods and results which may be used for validating stochastic modelling by way of sensitivity analysis the representation of the variables uncertainty for sensitivity analysis can be performed by using a variety of methods such as for example the first order second moment method fosm the second order reliability methods or the scatter analysis faber 2012 in fact several studies kopmann and schmidt 2010 villaret et al 2016 have chosen to analyse morphodynamics based on these approaches particularly in what regards the sensitivity analysis of the equations involved in the modelling of fluvial morphodynamics whilst this indeed qualifies as sensitivity analysis of morphodynamics these approaches by their very nature generally disregards the temporal and spatial complexities involved in morphodynamical processes pinto and freire 2006 kopmann et al 2012 additionally these methods are only applicable in relatively simple potentially linear or linearizable models for these reasons the monte carlo simulation mcs dimov 2008 was used in the present study as a tool for simulating and representing the statistical variability of fluvial morphodynamics the mcs while often costly to develop provides a more complete and reliable description of the effect of the different variables uncertainties in the hm models results regarding the parameters and characteristics of the models themselves many studies in the areas of hydraulics and hydrology have simulated a specific variable s uncertainty and analysed the sensitivity of morphodynamics in regards to this same variable such as bed material shear resistance granulometry zhang et al 2016 kopmann and schmidt 2010 stochastic particle entrainment and deposition bohorquez and ancey 2015 ancey 2010 and the erosive action over the bed posner e and duan 2012 zhang et al 2015 table 1 presents an exhaustive list of all of the variables whose uncertainty i e their inherent variability in the context of bed morphodynamics has been analysed simulated in the literature jointly or separately from other variables via the application of a numerical hm model while generally speaking the most widely recognized sources of uncertainty in morphological change in the literature are the hydrological inputs i e streamflow other variables have also been found to be important different studies generally compare different sets of variables in accordance with the studies own purpose goals data environment e g coastal estuarine fluvial and limitations table 2 displays the variables from the list presented in table 1 which were determined by way of sensitivity analysis to be the most relevant within the corresponding studies in the literature namely in terms of the importance of those variables uncertainty for fluvial morphodynamics notice that not all of the variables were simulated in every study a factor which can influence the choice of the most relevant variable s for fluvial morphodynamics as can be observed from table 2 regarding river specific variables the literature offers no consensus regarding what variables are most important to fluvial morphodynamics morphodynamical sensitivities appear to be very volatile in nature and are probably not generalizable from one case study to another different approaches to the simulation of the variables uncertainty also produce wildly different results the sensitivity analysis to be performed in this study is intended to provide some clarity regarding the causes for these results in the discussion section the available examples of quantitative sensitivity measurements from the literature are compared with the results of this study 1 2 criteria for variable selection based on principles suggested in the literature e g in saltelli et al 2008 guyon e and elisseeff 2003 and in the authors experience the best criteria for selecting the variables to be considered in the uncertainty modelling of fluvial morphodynamics are the same as for any type of stochastic modelling simulated variables should be demonstrably relevant not for the modelling itself but for the uncertainty of fluvial morphodynamics parameters or elements of the hm model such as the shields parameters the adaptation length the slope effect parameter or the choice of sediment transport formula are very likely to be virtually deterministic in real life fluvial morphodynamics and therefore should not be considered when specifically analysing the sensitivity of fluvial morphodynamics the independent representation of the uncertainty from significantly related variables such as sediment grain size density and angle of repose should be avoided this is because ignoring the effects of these inherent dependencies can reduce the quality of the sensitivity analysis e g when certain combinations of the variables values are not realistic despite the individual values being within the variables likely uncertainty ranges where the definition of a variable s uncertainty range is difficult or even impossible the corresponding variable should be excluded from consideration due to the significant danger of over under estimating the variable s effects of fluvial morphodynamics examples of this type of uncertainty are for example the bathymetrical uncertainty whose values can only be improved upon and not included in the sensitivity analysis using these criteria the potential universe of variables to be considered which can be reasonably defined based on the variables included in the numerical hm models common sense and the available literature can be significantly reduced concurrently the number of variables which may be relevant for fluvial morphodynamics was narrowed down to four namely 1 the channel s overall granulometry 2 the channel s bed roughness 3 the streamflow discharge at the boundaries or flood events and 4 the sediment input at the boundaries granulometry determines the sediments resistance to sediment transport while discharge determines the water s overall velocity bed roughness regulates the near bed velocities and shear stress and sediment input controls the availability of sediment in its vicinity for sediment transport all of these variables have been observed to have a very significant influence in morphodynamics on multiple instances van vuren 2005 visconti and ridolfi 2010 kasyi et al 2015 and their respective uncertainty was therefore simulated in this study adding a large number of variables in sensitivity analysis does not necessarily equal added quality but can instead reduce the representativeness of the simulated variables concomitantly regarding the excluded variables in numerical modelling the best option is to simply set them to their most likely accurate value 1 3 regarding the numerical model the numerical model used in this study cche2d is a finite element numerical hm model based on the depth integrated reynolds averaged navier stokes and continuity equations which it solves using an implicit scheme of time marching jia e and wang 2001 it is capable of dynamic flow and sediment transport modelling including various options for turbulence modelling and the calculation of bed load transport by way of the corresponding empirical formulas bed level change is computed using an equilibrium sediment transport model based on the bed load transport formulas solved using a first order upwind scheme and adjusted by the effects of bed slope and channel curvature the cche2d model is capable of simulating the behaviour of non uniform sediment mixtures this model has been successfully used in multiple instances in the past for the simulation of hms in fluvial environments kim et al 2010 negm et al 2010 nassar 2011 for this application the eddy viscosity in the model was computed using the available depth integrated mixing length eddy viscosity model in addition the wu et al formula wu et al 2000 was used to represent the flow s sediment transport capacity throughout the channel the underlying equations can be found in the corresponding manual jia e and wang 2001 1 4 case study the area upon which this study was based corresponds to a reach of the mondego river in portugal this river is born in the estrela mountain range in portugal and its mouth faces the atlantic ocean near the city of figueira da foz this is a regulated river with 11 large dams the raiva and fronhas dams form the nearest upstream reservoirs and are situated at approximately 23 and 40 km from the study reach respectively in the mondego river and in one of its tributaries the alva river the reach of the mondego river in question is situated between the palheiros levee the upstream boundary of the model and the portela bridge the downstream boundary of the model situated about 4 km upstream from the centre of the city of coimbra whose locations are represented in fig 1 this reach is approximately 3350 m long with an average width of 50 m and an average water depth of the main channel defined based on the edge of the vegetation line of 3 5 m and is represented in fig 2 the river channel is mostly straight with a sinuosity index mueller 1968 of 1 075 the entirety of the reach was simulated as part of the hm simulations the present study analysed the behaviour and sensitivities of morphodynamics based on a simple straight geometrization of the river reach created using data from in situ measurements and historical data to criteriously define the variables characteristics using a simplified representation of this channel will help in producing clearer straightforward and representative results of potential real river conditions 1 5 channel geometry a stylized straight longitudinally symmetric channel for representing the study channel the shape and other geometrical characteristics of the study channel were simplified and averaged in order to define the desired straight channel the resulting channel shape consists of a simplified cross section defined in fig 3 with an overall geometrical shape virtually identical to the river s mean cross section a mean thalweg slope of 0 066 was adopted for the straight channel in accordance with the field data the initial conditions for the numerical simulations correspond to a steady flow of 10 m3 s along the channel the boundary conditions used to represent the limits of the numerical model in terms of hydrodynamics in the simulations were as follows for the upstream boundary a flow hydrograph time series defined for a given return period the exact definition of the flow hydrographs simulated which was based on recorded streamflow data is presented in the variable definition section of this paper for the downstream boundary a stage flow curve corresponding to uniform flow conditions adjusted as a function of the value of n as taken from the manning strickler formula only bed load was considered in the numerical hydro morphodynamic simulations i e suspended load was not considered relevant to the channel s morphodynamic behaviour the wu et al formula wu et al 2000 was used to represent the flow s sediment transport capacity throughout the channel considering that this case study consists of a uniform channel some influx of sediments at the upstream boundary is to be expected whose uncertainty as referred in the literature review section is one of the variables in this study the same wu et al formula was used to define the sediment input at the upstream boundary as a function of the corresponding flow hydrograph on the other hand uniform steady flow conditions i e defined using the manning strickler formula had to be assumed in order to define the sediment input at the upstream boundary and the stage flow curve for the downstream boundary due to that a disparity exists between the sediment transport at the boundary defined for uniform flow conditions and in the channel defined for unsteady flow conditions directly by the cche2d model such approximations at the boundaries are however virtually inevitable considering that the hm model represents a river channel and not of an idealized conceptual channel this imperfect representation of the boundaries is unlikely to significantly detract from the goals of the related sensitivity analysis and is therefore deemed sufficient the channel was simulated using a depth averaged two dimensional 2dh numerical modelling grid defined by a longitudinal spacing of 2 m over a length of 1000 m totalling 51 cross sections and a transversal spacing which coincides with the 15 defining points of the channel s cross section presented in fig 3 for a total of 765 grid cells 1 6 variable definition the sensitivity of fluvial morphodynamics was analysed in respect to four different variables channel granulometry expressed by the median grain diameter d 50 channel s bed roughness expressed by a uniform manning s roughness parameter n streamflow expressed by a flood magnitude parameter q which characterizes the intensity of the simulated flood event definition given below sediment input a percentage deviation δ qs relative to the sediment input estimate at the upstream boundary the variability ranges of these quantities d 50 n q δ qs represent the uncertainty of the corresponding variables in this instance the definition of such ranges was essentially based on the available literature and the information from these variables values as taken from the mondego river data both d 50 and n were simulated as uniform constant parameters along the entire channel while in real river situations d 50 and particularly n are rarely uniform the representation of the effects resulting from such complexity in a straight channel could be to some extent unrealistic and may therefore be more appropriately defined by adjusting the corresponding variability ranges the d 50 s variability range was based on granulometric data from the mondego river this data pertains to six granulometric curves approximately evenly spread out over a longer reach 40 km long including the study reach and it has been deemed to be approximately representative of the granulometry s variability in accordance with the simplified nature of the adopted case study a uniform sediment size was adopted to be represented by a corresponding d 50 a range of 1 5 30 mm was adopted for the d 50 s variability range which is virtually identical to the observed range of d 50 values the values of n were estimated based on the available literature schall et al 2008 arcement e and schneider 1984 chow 1959 for the mean n values in a river channel given that the straight channel is intended to represent a river channel and that the large number of factors which define n in a river channel is so large e g vegetation granulometry bed forms slope etc the channel s mean n was assumed to be independent of the grain size and to have values between 0 03 and 0 04 which are common reference values in the literature for a natural river channel the adopted values of n are intended to represent the combined effects of all relevant roughness factors e g the grain roughness the form roughness and the vegetative roughness a uniform distribution was assumed for representing the probability density function pdf of n the stage flow curve which determines the outflow at the downstream boundary was adjusted in conformity with the value of adopted n the streamflow data which was available consisted of a four and a half year long hourly streamflow series measured at the reservoirs upstream from the selected reach of the mondego river as this quantity of data is relatively insufficient to qualify the exact shape of flood events a standardized flood hydrograph based on a fréchet distribution for its shape was adopted the relative proportion of the synthetic hydrograph s temporal and flow scale was adjusted calibrated to match that of the available data the main reference flood event for this calibration is of a maximum value of around 600 m3 s which was observed in multiple instances for a duration of around 100 h to have a flow magnitude above 140 m3 s the selected flood magnitude parameter corresponds to a scaling parameter for the simulated synthetic hydrograph identical to the maximum flow magnitude of the hydrograph each simulated hydrograph therefore corresponds to that standardized hydrograph presented in fig 4 for a unitary value of q multiplied by the q parameter in terms of its flow magnitude and temporal scale the standardized hydrograph is intended to represent the overall conceptual shape of a real flood event while the q parameter is intended to represent the corresponding flood event s intensity fig 5 represents the estimated pdf of the streamflow data s peak flood magnitudes and therefore by extension the pdf of the q parameter for this case study the δ qs variable i e the uncertainty surrounding the sediment input in a reach while being known to be relevant for fluvial morphodynamics is hard to be characterized its uncertainty can change greatly from case to case depending on a multiplicity of factors such as the channel slope the flow regime the granulometry and the characteristics of the sediments themselves both locally at the boundary and significantly upstream from the boundary for the lack of a more detailed alternative in the literature the δ qs variable was expressed as a constant percentage deviation within each simulation of the sediment input at the upstream boundary concretely for each simulation the sediment input at the boundary estimated using the wu et al formula under uniform flow conditions as a function of the corresponding flow hydrograph was adjusted by a fixed factor of δ qs in order to represent the sediment input s uncertainty across simulations a uniform distribution was assumed for the δ qs s uncertainty the range of this uncertainty was set to 10 of its estimated value as suggested by topping et al topping and vierra 2000 for a large river fig 7 represents the final choices for the uncertainty distributions for all variables as said uniform distributions were assumed for the granulometry d 50 1 5 30 mm roughness n 0 03 0 04 s m1 3 and sediment input δ qs 10 10 for the water discharge its variability was defined by fitting a weibull to the recorded values of peak flood magnitude for the purposes of this simulation these variability ranges were assumed as adequate nevertheless while other values could possibly be assumed given the exemplificative nature of this case it is considered that there is no added value in further postulating on their distribution as a reference the resulting distribution of simulated mobility parameters defined as the effective shear stress divided by the critical shear stress calculated using the shields diagram for the maximum flow in each simulation and assuming uniform i e unidimensional steady flow conditions i e estimated using the manning strickler formula is presented in fig 6 each point represents one simulation s maximum mobility parameter calculated under the uniform steady flow assumption the process of simulating and representing the morphodynamical change of the straight channel as a function of its respective hydrodynamics and the selected morphodynamically relevant variables was accomplished by applying the selected numerical hm model for the data presented in the previous section for each application of the model the geometrical data of the channel along with sampled values of the different variables was used to simulate the morphodynamical uncertainty resulting from these variables the entire group of simulations jointly represents the uncertainty and the probability distribution of fluvial morphodynamical change as a function of the different variables for the purposes of the sensitivity analysis each simulation s morphodynamical change was summarized by a set of statistics described below and the variables effects on each of these statistics was analysed by either independent sensitivity analysis isa or joint sensitivity analysis jsa this process is graphically described in fig 7 given the large computational capacity required by the numerical hm model a crude monte carlo to stochastic modelling is not viable the values of the variables which are to be simulated cannot therefore be randomly sampled in this study specific quantile values of each variable were selected to represent their respective pdfs for simulation purposes the entirety of both the d 50 s the n s and the δ qs s variability ranges were sampled concerning parameter q since the corresponding pdf is unbounded the more extreme values of the variability range are not realistic such as a null valued or a virtually infinite parameter accordingly the variability of q was represented by the corresponding pdf s 5th to 95th quantiles for each of the variables a set of seven values was used to represent their respective pdf matching the 0th 17th 33rd 50th 67th 83rd and 100th quantiles for the d 50 n and δ qs variables and the 5th 20th 35th 50th 65th 80th and 95th quantiles for q the modelling of all of the potential combinations of these values results in a total of 74 2401 simulations the number of combinations of the seven values for each of the four variables when necessary these simulations have been individually identified by the ranking of their respective quantiles for example the 0th 1st value 17th 2nd value 65th 5th value and 100th 6th value quantiles of the d 50 n q and δ qs are symbolized as 1 2 5 7 in order for the extensive information on simulated bed level change dh across the channel which results from the stochastic modelling to be useable for sensitivity analysis it must be summarized using a series of statistics each of these statistics is meant to represent a quantification of a feature of the morphodynamical behaviour for each simulation each simulation would therefore have one value for each individual statistics the statistics analysed in this paper defined for an n number of grid cells in the simulations in this case 765 cells were overall mean absolute dh omac corresponding to the mean value of the absolute dh measured over along the entire channel eq 1 eq 1 omac 1 n i 1 n d h i f o r n g r i d n o d e s localized mean absolute dh lmac similar to omac but measured solely in areas where the dh is non null consisting of the mean absolute dh in the channel measured where dh 0 eq 2 eq 2 lmac 1 i 1 n 0 i f d h i 0 1 i f d h i 0 i 1 n d h i f o r n g r i d n o d e s localized mean dh lmc similar to lmac by in relative terms consisting of the mean dh in the channel measured where dh 0 eq 3 this statistic serves as an indication of the average tendency of dh i e towards erosion or sedimentation eq 3 lmc 1 i 1 n 0 i f d h i 0 1 i f d h i 0 i 1 n d h i f o r n g r i d n o d e s mean absolute dh in the central channel cmac and in the banks bmac similar to omac but measured solely in the centre and banks of the channel respectively corresponding to the central 7 nodes and the outermost 8 grid nodes percentage of channel area flooded pfa the percentage of the simulated area measured as projected in a horizontal plane wetted during the flood events represented in eq 4 this value is measured as the percentage of the channel area where dh is non null because computationally any area which is flooded is subject to erosion or deposition even if only to a very small degree eq 4 pfa 1 n i 1 n 0 i f d h i 0 1 i f d h i 0 spatial variability of morphodynamics a measurement of the spatial irregularity of dh as defined by the 2nd order variability derivate of dh in the longitudinal and transversal direction masv eq 5 corresponds to the average 2nd order differentiated dh along the grid designated as δ 2 d h i j for grid node i j corresponding to the curvature of dh standardized by the dh s variance i e var d h thereby being adimensional larger values of this statistic indicate that the discontinuity of dh represented by elevated curvatures in dh relative to the overall variability of dh is larger and vice versa eq 5 masv 1 n i 2 n t 1 j 2 n l 1 δ 2 d h i j 2 var d h where n l and n t refer to the number of grid nodes in the longitudinal and transversal direction and n corresponds to the number of nodes where the δ 2 d h can be calculated viz which have other grid nodes around them all of these statistics were analysed in the context of the jsa the isa on the other hand was performed based solely on the lmac and lmc statistics 2 results of the simulations given the stochastic nature of the model s application individual simulations hold no individual value nonetheless as examples of the simulated of dh fig 8 displays three examples of simulations with parameters 3 2 2 1 4 5 7 3 and 5 7 7 5 the corresponding omac lmac cmac bmac pfa and masv statistics are presented in table 3 on average over all of the simulations dh in the channel tends towards erosion while both generalized erosion and generalized sedimentation cases are present simulations involving erosion have generally higher magnitudes of dh in addition a significant portion of dh tends to concentrate in the vicinity of the model s boundaries both of these effects are likely a result of the previously referred imperfections in the definition of the model s boundary conditions because the purpose of these simulations is the simplified representation of a real channel these tendencies are not necessarily harmful to the simulations goals as real rivers always possess some amount of natural trends unlike idealized channels which have none as can be observed the first and second examples for parameters 3 2 2 1 and 4 5 7 3 have very similar lmacs but very different omacs this is a result of the smaller flows and n which reduce the area affected by dh with a smaller pfa in the former relative to the latter resulting in the same average magnitude of dh but different average dh channel wide the cmac and bmac statistics further confirm the concentration of morphodynamical change in the centre of the channel with higher cmacs and lower bmacs in the presence of higher magnitude more concentrated dh the masv decreases successively with each case as the dh shifts from a more intense and concentrated and thereby irregular distribution in the first case 3 2 2 1 to a more widespread and continuous distribution in the last example 5 7 7 5 the choice of statistics performed in this study is meant to capture these different aspects of morphodynamics for the evaluation of morphodynamical sensitivities across the simulations the values of the selected statistics can vary significantly table 4 summarizes the range of values of these statistics for the 2401 simulations performed the sensitivity analysis of the simulations performed in this study was separated into an isa and a jsa the isa focused on describing the relationship between the channel s morphodynamics and each of the different variables namely the characteristics of the relationship e g linear non linear and the respective magnitudes in terms of bed change of the variables individual effects in the channel s morphodynamics regarding the jsa the objective was to assess the relative sensitivities and respective inter dependencies for the different variables regarding a variety of different aspects based on variance based global sensitivity analysis saltelli et al 2008 multiple combinations of values of the different variables selected from the distributions presented in fig 5 were simulated in order to represent not only their relative importance for fluvial morphodynamics but also to take into account the inter dependencies between the variables and their respective sensitivities 2 1 independent sensitivity analysis isa the individual effects produced by the different variables were assessed in terms of the localized mean absolute dh and the localized mean dh lmac and lmc respectively the independent sensitivity of each variable was measured by setting the remaining three variables to their median value e g the representative lmac and lmc values for the granulometry 1 x x x is obtained by setting the values of the n q and δ qs variables to the 50th quantile of their pdfs i e to values x 4 4 4 fig 9 presents the relationship between the simulated dh and each of the different variables the relationships between the morphodynamics and the selected variables can be clearly observed in fig 9 they are clearly non linear potentially following an exponential power decay albeit its shape for the δ qs variable is only observable on a smaller scale considering that the channel s natural tendency leans towards erosion the d 50 n and δ qs variables are inversely correlated with the lmac statistic while the q variable is directly correlated with lmac if the channel s dh tendency was towards sedimentation the relationship between dh and q would most likely be reversed in terms of the lmc statistic the effects of the q variable in particular grow more complicated and the variable itself clearly loses a significant amount of importance relative to the other variables in terms of the morphodynamical sensitivities the variables hierarchy regarding lmac is not entirely clear the d 50 is always the most important variable with a δlmac 0 027 m and a δlmc 0 024 m according to fig 9 and the δ qs variable produces the least impact on the statistics with a δlmac 0 0002 m and a δlmc 0 0002 m the q and n variables however while having a very similar importance regarding the lmac statistic with δlmacs of 0 00351 m and 0 00352 m respectively have very different effects regarding the lmc statistic with δlmcs of 0 0014 m and 0 0004 m respectively these results clearly evidentiate the importance of using multiple statistics to capture the different aspects which characterize morphodynamical change while the values of these statistics are relatively small this is to be expected considering that they pertain to the effects of single flood events which are naturally limited in terms of their morphodynamical capacity in addition these are average statistics meant to characterize the reach as a whole and not the more extreme values of dh further discussion on these results can be found in the discussion section 2 2 joint sensitivity analysis jsa the jsa was applied based on the results of the numerical hm simulations of the previously described straight channel performed for different values of the variables under analysis i e d 50 n q and δ qs as described in the variable definition section the sensitivity analysis of the results was performed in terms of variance based sensitivity measurements namely by way of the total effect index tei calculated by way of eq 6 which provides a measure of the importance of the variable i for the overall variability of statistic y i e y x i large value of tei close to 1 for a variable i indicate that this variable plays an important part in the definition of the statistic s magnitude saltelli et al 2004 conversely in the case of a small tei close to 0 the choice of the corresponding variable s value is likely not important because it will not significantly affect the results regarding the y statistic eq 6 tei y x i e var y x i var y 1 var e y x i var y where var x represents the variance of x e x is the mean expected value of x i can be any of the selected variables y x i is the values of the statistic y after the variability introduced by variable i is removed by averaging over the corresponding simulations and y x i is the values of the statistic y for a set value of variable i by visual analysis of the relative relationships between pairs of variables regarding each individual statistic this visual analysis also designated as pairwise comparisons was constructed by for every statistic y and every pair of variables i and j averaging over the remaining two variables as is expressed in eq 7 eq 7 y i j e y x k l w h e r e i j k l d 50 n q δ q s this sensitivity analysis was detailed in terms of all of the different statistics referred at the start of the simulation section thereby analysing different aspects and underlying characteristics of the channel s morphodynamics fig 10 displays the values of the tei calculated for the different statistics normalized so that each statistics teis sum up to unity as can be observed in this section the different statistics with the exception of the pfa are generally in agreement regarding the hierarchy of the variables in terms of their relative importance for morphodynamical variability however while the hierarchy itself is identical the relative importance of the variables changes very significantly in terms of the teis in decreasing order of importance the d 50 s the q s the n s and the δ qs s importances fluctuate between 43 and 66 30 and 40 3 and 18 and 0 and 2 the choice of statistic in particular can have a very significant impact in the variables relative importances for example the relative importance of q relative to n can change between two times higher in the masv statistic to ten times higher in the cmac statistic fig 11 fig 12 and fig 13 represent the pairwise comparison between the effects of the four variables under analysis for the lmac lmc and masv statistics the remaining statistics were not represented as they produced very similar results to the lmac lmc statistics and do not provide additional information these graphical representations provide a qualitative description of the relative importance of the different variables much in the same way as the tei and in comparison with statistics based approaches a more complete description of the relationships between the variables and their respective influences on fluvial morphodynamics for reference purposes the main criteria for interpreting the information represented in these figures is as follows the more perpendicular the contour lines are to a given axis the more important the corresponding variable is to the morphodynamical statistic under analysis very irregular contour lines are strong indicators of an independence between the variables effects regarding that particular morphodynamical statistic generally speaking situations like this occur when the inherent complexity and aleatory nature of morphodynamical change is more significant than the variables relationship in determining the statistics values continuous contour lines i e where a clear pattern can be observed in their progression as a function of the variables are indicative of an observable potentially replicable and structured relationship between the variables effects analysing multiple statistics is not only important in the analysis of the teis but also in the pairwise comparisons while significant similarities can be found between different statistics the lmc statistic for example captures an inflexion points in the channel s morphodynamical behaviour which is not present in the other statistics namely in the relationship between the q and the d 50 variables portrayed by the diversion of the contour lines as the simulations dh trend changes from erosion to sedimentation in this particular case study no clear example of an independence between the variables effects was observed with varying degrees of intensity an organized structure has been observed to relate the different variables effects on the statistics for the purposes of better understanding the variables interactions the exact nature of the structured relationships between the variables effects may be determined by way of additional sensitivity studies determining whether these relationships are the result of a superposition of effects and therefore the effects of the variables on the statistics are statistically independent or if there is a dependency between the variables effects can be better founded by looking into case studies with different characteristics and variable definitions regarding their nature and magnitude nonetheless in a complex system as is the case of fluvial morphodynamics where strong spatial and temporal dependencies are present a complete independence between any two variables is not likely the full analysis of these results and their likely causes and consequences is detailed in the discussion section of this study 3 discussion in the available literature only two examples of studies villaret et al 2016 van vuren 2005 could be found were two or more of the selected variables are analysed and a quantitative description of morphodynamical sensitivities is calculated table 5 summarizes the normalized sensitivities obtained in these studies as can be observed there is no agreement between these results and the results obtained in this study the variables determined to be the most important were q and n respectively in each of the two examples whereas in the case study it was the d 50 this disparity along with the highly variable importance hierarchy which has been determined in some other studies on the subject referred in table 2 shows that the morphodynamical sensitivities are significantly case dependent and cannot be readily generalized the scientific relevance of any set of individual sensitivities can therefore be concluded to be virtually limited to the corresponding case study while these values may be useful for comprehending a specific situation they are clearly not extendable to other situations the highly complex and compounding effects of the spatial and temporal dependencies of morphodynamics also observed by van vuren van vuren 2005 along with the strong case specificity of the variability ranges of the variables are likely to render most comparisons across case studies ineffective the present study simulated only single event floods a fact which is potentially responsible for the low importance of the δ qs variable observations indicate that this variable s importance for morphodynamics should increase with the time span of the simulations in the current study that possibility is strengthened by the morphodynamical sensitivities to this variable which were observed to be seven times larger at the start of the channel defined in terms of the omac statistic for the first three sections of the river than for the channel as a whole according to the normal definition of omac very likely for longer events this higher sensitivity would propagate downstream along the channel ultimately the 10 uncertainty adopted for the δ qs variable despite being in accordance with the available literature may also play a part in the comparatively low importance displayed in the present study as can be concluded the magnitudes of individual sensitivities are very unlikely to be comparable across significantly different cases this fact for the purposes of the validation of stochastic modelling is undesirable as was previously stated the validation of stochastic modelling is linked to the potential existence of a common generalizable behaviour across case studies the only remaining alternative solution is to identify replicable relative characteristics of the stochastic modelling s results examples of these relative characteristics may be the relationships between the different variables and morphodynamics represented in fig 9 of the isa and the relationships or lack thereof between the variables effects on morphodynamics represented in figs 11 13 of the jsa characteristics such as the direct or inverse correlation of the curves or contour lines and the features of their respective curvatures should be from a theoretical point of view a consequence of the morphodynamical processes inherent to the hm modelling and not of the variables themselves unfortunately there is no term of comparison available for these results regarding potential relative characteristics as there are virtually no recent studies which have quantified overall comparisons between the variables values and their effects on morphodynamics until such relative characteristics which should theoretically exist are found the validation of the stochastic modelling of fluvial morphodynamics is practically limited to the comparison of sensitivities between very similar case studies unfortunately data on such case studies is often not readily available regarding sensitivity analysis specifically even within the same type of environment numerical model and uncertainty simulation the choice of morphodynamical and sensitivity statistics can have a great impact on the results this much was observed in this study when comparing the results of the isa and the jsa which used respectively a range based statistic and a variance statistic to quantify morphodynamical sensitivities in this instance the hierarchy of the importance of the q and n variables changed depending on the choice in addition the relative importance of the d 50 variable changes from nearly ten times larger than any other variable in the range statistics to a maximum of two and half times in the variance statistic in the work by van vuren van vuren 2005 the sensitivity of q in particular more than doubled when switching from a correlation statistic to a variance statistic while a definitive answer on what is the optimal statistic cannot be forcefully stated from a conceptual point of view the variance statistic should be a more appropriate choice because it is less unstable than the range based values used to assess dh statistics in isa i e the δlmac and δlmc values which are calculated based on the extreme values of the dh produced by each of the corresponding variables in addition the variance statistic also does not assume a linear relationship between the variables and morphodynamics as does the correlation statistic the use of multiple morphodynamical statistics omac lmac lmc etc was observed to be relevant in capturing different aspects of morphodynamics producing different magnitudes of sensitivities and even a different hierarchical order in the isa in order to fully understand a fluvial system these statistics can help in producing a much clearer picture of the variables effects and interactions with fluvial morphodynamics the results show that future studies involving sensitivity analysis in a fluvial context should make use of multiple morphodynamical variance based statistics in order to provide a more stable and complete description of morphodynamics 4 conclusions in this study an analysis of the concept and usefulness of sensitivity analysis was performed namely in the context of the stochastic modelling of fluvial morphodynamics with this purpose in mind a review on applications of sensitivity analysis in a fluvial environment was conducted along with an original application of sensitivity analysis in a straight channel the main question which was to be answered is whether sensitivity analysis can be used for the validation of the stochastic modelling itself a common approach to validation in other areas of study or if its usefulness is limited to providing an understanding on the specific case study whether the results of sensitivity analysis can or not be generalized across different situations is overall the determining factor in answering this question by taking into consideration different statistics themselves representative of different aspects of morphodynamics this study was intended to move away from the typically case specific morphodynamical sensitivity studies were the analysis of sensitivities is restricted to observing the variable induced variability ranges and to focus more on the morphodynamical processes themselves using different morphodynamical and sensitivity statistics in the independent and the joint sensitivity analysis provided a significantly clearer understanding on the variables effects on morphodynamics nonetheless the results are clear morphodynamical sensitivities cannot be generalized across case studies with significant differences in terms of either the temporal or spatial scales of the simulations or the characteristics and variability ranges of the variables and parameters involved other potential uses of sensitivity analysis such as the prioritization of the variables definition are also undermined by the non generalizable nature of sensitivities in a fluvial environment theoretically similar cases produce similar sensitivities and can be used in the validation of stochastic modelling the difficulty in this option lies in defining the point up to which two case studies can be considered reasonably similar primarily due to the complexity of the inherent processes nevertheless certain aspects of the relationships between the variables effects and morphodynamical change such as the curvature and other shape characteristics represented in figs 9 and 11 13 due to their relative nature have a significant potential for generalization and may offer an alternative solution for sensitivity analysis based validation of stochastic modelling in future studies on this subject these relationships between the sources of morphodynamical uncertainty and morphodynamics itself will be further evaluated using different case studies with different sets of data and different time frames and compared with the results of this study only then can a general definition of reproducible relative relationships be estimated which in turn can allow for a sensitivity analysis based validation of stochastic modelling additional morphodynamical statistics preferably of a more adimensional nature should also be considered as they may assist in detecting patterns in the variables relationships declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the present work has been developed under a scholarship funded by the fundação para a ciência e a tecnologia of portugal with the scholarship reference number pd bi 128053 2016 
25904,this study s objective is to assess the sensitivity analysis potential for application in the context of the stochastic input based modelling of fluvial morphodynamics the corresponding work involved 1 an analysis of the work available in the literature and 2 an independent application of sensitivity analysis for comparison the application of sensitivity analysis was accomplished by using a numerical hydro morphodynamic model to represent the natural morphodynamical processes response to the uncertainty in a selected set of variables the resulting morphodynamical sensitivities were quantified and a characterization of the relationship between the variables effects and morphodynamics was produced the potential generalization of the results of sensitivity analysis for the purposes of validating stochastic modelling across different case studies was assessed resulting sensitivities were found to be strongly case specific with little generalization potential indicating that sensitivity analysis in the context of fluvial morphodynamics is likely of little scientific interest keywords numerical modelling fluvial morphodynamics sensitivity analysis validation of stochastic modelling 1 introduction the process of simulating and particularly forecasting fluvial morphodynamics is always permeated by a certain amount of uncertainty this uncertainty is a result both of the convolution of effects from the large number of associated variables and their respective inter dependencies and of the difficulty involved in estimating their values and effects in the morphodynamical processes no two natural river channels are alike in terms of the characteristics and the relative importance of these variables as such fluvial morphodynamics i e the erosive deposition processes can be considered as having a strong probabilistic nature turowski 2011 hu and guo 2010 concurrently the importance of stochastic modelling in the analysis of fluvial morphodynamics has long been recognized in the study areas of hydrology and geomorphology van vuren 2005 posner e and duan 2012 the main objective of this study is to explore and analyse the potential usefulness of sensitivity analysis in validating the results of stochastic numerical modelling of fluvial morphodynamics sensitivity analysis is the process of characterizing the relevance of individual variables towards the overall uncertainty of morphodynamics as a characterization of a system s inherent relationships it has often been used to validate the results of stochastic modelling van vliet et al 2016 kleijnen 1999 sargent et al 2016 this study is intended to analyse the possibility of performing this task in a fluvial context namely one where morphodynamics is represented by way of a numerical hydrodynamic and morphodynamic hm model stochastic modelling in this instance refers not to the modelling itself being stochastic in nature such as in bohorquez and ancey 2015 but specifically to when the input of the hm model is stochastically generated resulting in a stochastic application i e recurrent and with stochastically generated inputs of the numerical hm models in the vast majority of the situations the individual simulations which are a part of stochastic numerical modelling hold no inherent value unless understood in the context of all of the simulations the validation of applications of stochastic modelling is therefore most often based on the validation of certain characteristic behaviours of the underlying processes in turn represented by the corresponding models which are deemed to be virtually universal across case studies concordantly the potential for the validation of stochastic modelling by way of sensitivity analysis is directly tied with the potential generalization of the results of sensitivity analysis from a different perspective the validation of the stochastic modelling s application requires the existence of repetitive behavioural patterns in the morphodynamical processes and or the bed level change i e consistent patterns in the underlying dynamics of morphodynamical change in order to assess the generalizability of the results of sensitivity analysis both a review of existing studies on this subject in the context of bed morphodynamics and a reference case study i e a term of comparison regarding sensitivity analysis have been developed that reference case was created by applying the sensitivity analysis to a straight channel defined based on a simplification of a real case study and simulated using a hm model by estimating and comparing the morphodynamical sensitivities between the reference case and the results available in the literature conclusions can be drawn regarding the potential generalization of sensitivity analysis results while directly simulating a large number of case studies could be a simple approach for assessing the generalization potential of sensitivity analysis issues with data availability and the large computational requirements of these simulations impede this solution as an alternative the available literature s results regarding the magnitudes of morphodynamical sensitivities along with the methods used in quantifying the sensitivities in the literature were analysed and compared with the reference case s results in search for potential common generalizable aspects in sensitivity analysis based on this comparison results of sensitivity analyses were assessed in terms of the generalization potential of the sensitivities magnitudes and of other characteristics of the stochastic simulations a stylized straight channel with an initial well defined cross section and constant longitudinal slope was adopted for performing a series of simulations for varying combinations of variables values and flood events i e in unsteady flow conditions this straight channel corresponds to a simplified representation of a stretch of a river in portugal the mondego river and was defined based on the simplification of its overall shape as obtained from the corresponding data the results of the present study are intended to serve as term of comparison for understanding and interpreting the results of existing sensitivity studies in the literature the analysis of a simplified stylized case study is intended to reduce the effects of the complexity of fluvial morphodynamics in particular its natural tendencies in terms of bed level evolution thereby producing a clearer description of the relationships between the variables and morphodynamics as well as the corresponding morphodynamical sensitivities additionally the clearer nature of the results also lends itself to the production of more informative analyses using appropriate sensitivity analysis tools this is because in more intricate case studies the superposition of morphodynamical effects can obscure the results of sensitivity analysis both independent and joint sensitivity analysis were performed regarding the variables impact on morphodynamics the relative influence of the different variables was quantified for different aspects of channel morphology e g mean bed level change spatial distribution of bed level change etc in order to better represent the non linear aspects of morphodynamics and the interdependency between variables the numerical hydro and morphodynamic model used in this study was the cche2d zhang 2005 specifically using the cche gui 3 29 and cche mesh 3 programs all of which are available at the website of the national centre for computational hydroscience and engineering of the university of mississippi ncche 2017 considering that the hm model s sensitivities in the context of sensitivity analysis are unique to the model itself they are of no interest for the validation of stochastic modelling as they are by definition not generalizable this study therefore focused specifically on morphodynamical sensitivities and the sensitivities of morphodynamical processes which in theory all models should correctly portray concurrently theoretical considerations regarding the veracity or the appropriateness of the many different potential numerical representations of the mechanics of sediment transport and bed dynamics e g the bed load sediment continuity or semi empirical formulas involved in the hm modelling were deemed as irrelevant for the intended purpose of this study 1 1 literature review sensitivity analysis is a type of analysis which is intended to provide a description of the relative sensitivity of a model s outputs to each of its input variables parameters accordingly it is an important step in any stochastic application of models as it provides important information on the relationships represented by the numerical model at the same time sensitivity analysis is virtually the only general purpose tool for validating the results of numerical modelling stochastic or not with randomly stochastically generated inputs saltelli et al 2008 looking at the sensitivity analysis results for the different case studies available in the literature along with a case study developed in this paper for comparison purposes the generalization potential of sensitivity analysis can be assessed this section summarizes the methods and results which may be used for validating stochastic modelling by way of sensitivity analysis the representation of the variables uncertainty for sensitivity analysis can be performed by using a variety of methods such as for example the first order second moment method fosm the second order reliability methods or the scatter analysis faber 2012 in fact several studies kopmann and schmidt 2010 villaret et al 2016 have chosen to analyse morphodynamics based on these approaches particularly in what regards the sensitivity analysis of the equations involved in the modelling of fluvial morphodynamics whilst this indeed qualifies as sensitivity analysis of morphodynamics these approaches by their very nature generally disregards the temporal and spatial complexities involved in morphodynamical processes pinto and freire 2006 kopmann et al 2012 additionally these methods are only applicable in relatively simple potentially linear or linearizable models for these reasons the monte carlo simulation mcs dimov 2008 was used in the present study as a tool for simulating and representing the statistical variability of fluvial morphodynamics the mcs while often costly to develop provides a more complete and reliable description of the effect of the different variables uncertainties in the hm models results regarding the parameters and characteristics of the models themselves many studies in the areas of hydraulics and hydrology have simulated a specific variable s uncertainty and analysed the sensitivity of morphodynamics in regards to this same variable such as bed material shear resistance granulometry zhang et al 2016 kopmann and schmidt 2010 stochastic particle entrainment and deposition bohorquez and ancey 2015 ancey 2010 and the erosive action over the bed posner e and duan 2012 zhang et al 2015 table 1 presents an exhaustive list of all of the variables whose uncertainty i e their inherent variability in the context of bed morphodynamics has been analysed simulated in the literature jointly or separately from other variables via the application of a numerical hm model while generally speaking the most widely recognized sources of uncertainty in morphological change in the literature are the hydrological inputs i e streamflow other variables have also been found to be important different studies generally compare different sets of variables in accordance with the studies own purpose goals data environment e g coastal estuarine fluvial and limitations table 2 displays the variables from the list presented in table 1 which were determined by way of sensitivity analysis to be the most relevant within the corresponding studies in the literature namely in terms of the importance of those variables uncertainty for fluvial morphodynamics notice that not all of the variables were simulated in every study a factor which can influence the choice of the most relevant variable s for fluvial morphodynamics as can be observed from table 2 regarding river specific variables the literature offers no consensus regarding what variables are most important to fluvial morphodynamics morphodynamical sensitivities appear to be very volatile in nature and are probably not generalizable from one case study to another different approaches to the simulation of the variables uncertainty also produce wildly different results the sensitivity analysis to be performed in this study is intended to provide some clarity regarding the causes for these results in the discussion section the available examples of quantitative sensitivity measurements from the literature are compared with the results of this study 1 2 criteria for variable selection based on principles suggested in the literature e g in saltelli et al 2008 guyon e and elisseeff 2003 and in the authors experience the best criteria for selecting the variables to be considered in the uncertainty modelling of fluvial morphodynamics are the same as for any type of stochastic modelling simulated variables should be demonstrably relevant not for the modelling itself but for the uncertainty of fluvial morphodynamics parameters or elements of the hm model such as the shields parameters the adaptation length the slope effect parameter or the choice of sediment transport formula are very likely to be virtually deterministic in real life fluvial morphodynamics and therefore should not be considered when specifically analysing the sensitivity of fluvial morphodynamics the independent representation of the uncertainty from significantly related variables such as sediment grain size density and angle of repose should be avoided this is because ignoring the effects of these inherent dependencies can reduce the quality of the sensitivity analysis e g when certain combinations of the variables values are not realistic despite the individual values being within the variables likely uncertainty ranges where the definition of a variable s uncertainty range is difficult or even impossible the corresponding variable should be excluded from consideration due to the significant danger of over under estimating the variable s effects of fluvial morphodynamics examples of this type of uncertainty are for example the bathymetrical uncertainty whose values can only be improved upon and not included in the sensitivity analysis using these criteria the potential universe of variables to be considered which can be reasonably defined based on the variables included in the numerical hm models common sense and the available literature can be significantly reduced concurrently the number of variables which may be relevant for fluvial morphodynamics was narrowed down to four namely 1 the channel s overall granulometry 2 the channel s bed roughness 3 the streamflow discharge at the boundaries or flood events and 4 the sediment input at the boundaries granulometry determines the sediments resistance to sediment transport while discharge determines the water s overall velocity bed roughness regulates the near bed velocities and shear stress and sediment input controls the availability of sediment in its vicinity for sediment transport all of these variables have been observed to have a very significant influence in morphodynamics on multiple instances van vuren 2005 visconti and ridolfi 2010 kasyi et al 2015 and their respective uncertainty was therefore simulated in this study adding a large number of variables in sensitivity analysis does not necessarily equal added quality but can instead reduce the representativeness of the simulated variables concomitantly regarding the excluded variables in numerical modelling the best option is to simply set them to their most likely accurate value 1 3 regarding the numerical model the numerical model used in this study cche2d is a finite element numerical hm model based on the depth integrated reynolds averaged navier stokes and continuity equations which it solves using an implicit scheme of time marching jia e and wang 2001 it is capable of dynamic flow and sediment transport modelling including various options for turbulence modelling and the calculation of bed load transport by way of the corresponding empirical formulas bed level change is computed using an equilibrium sediment transport model based on the bed load transport formulas solved using a first order upwind scheme and adjusted by the effects of bed slope and channel curvature the cche2d model is capable of simulating the behaviour of non uniform sediment mixtures this model has been successfully used in multiple instances in the past for the simulation of hms in fluvial environments kim et al 2010 negm et al 2010 nassar 2011 for this application the eddy viscosity in the model was computed using the available depth integrated mixing length eddy viscosity model in addition the wu et al formula wu et al 2000 was used to represent the flow s sediment transport capacity throughout the channel the underlying equations can be found in the corresponding manual jia e and wang 2001 1 4 case study the area upon which this study was based corresponds to a reach of the mondego river in portugal this river is born in the estrela mountain range in portugal and its mouth faces the atlantic ocean near the city of figueira da foz this is a regulated river with 11 large dams the raiva and fronhas dams form the nearest upstream reservoirs and are situated at approximately 23 and 40 km from the study reach respectively in the mondego river and in one of its tributaries the alva river the reach of the mondego river in question is situated between the palheiros levee the upstream boundary of the model and the portela bridge the downstream boundary of the model situated about 4 km upstream from the centre of the city of coimbra whose locations are represented in fig 1 this reach is approximately 3350 m long with an average width of 50 m and an average water depth of the main channel defined based on the edge of the vegetation line of 3 5 m and is represented in fig 2 the river channel is mostly straight with a sinuosity index mueller 1968 of 1 075 the entirety of the reach was simulated as part of the hm simulations the present study analysed the behaviour and sensitivities of morphodynamics based on a simple straight geometrization of the river reach created using data from in situ measurements and historical data to criteriously define the variables characteristics using a simplified representation of this channel will help in producing clearer straightforward and representative results of potential real river conditions 1 5 channel geometry a stylized straight longitudinally symmetric channel for representing the study channel the shape and other geometrical characteristics of the study channel were simplified and averaged in order to define the desired straight channel the resulting channel shape consists of a simplified cross section defined in fig 3 with an overall geometrical shape virtually identical to the river s mean cross section a mean thalweg slope of 0 066 was adopted for the straight channel in accordance with the field data the initial conditions for the numerical simulations correspond to a steady flow of 10 m3 s along the channel the boundary conditions used to represent the limits of the numerical model in terms of hydrodynamics in the simulations were as follows for the upstream boundary a flow hydrograph time series defined for a given return period the exact definition of the flow hydrographs simulated which was based on recorded streamflow data is presented in the variable definition section of this paper for the downstream boundary a stage flow curve corresponding to uniform flow conditions adjusted as a function of the value of n as taken from the manning strickler formula only bed load was considered in the numerical hydro morphodynamic simulations i e suspended load was not considered relevant to the channel s morphodynamic behaviour the wu et al formula wu et al 2000 was used to represent the flow s sediment transport capacity throughout the channel considering that this case study consists of a uniform channel some influx of sediments at the upstream boundary is to be expected whose uncertainty as referred in the literature review section is one of the variables in this study the same wu et al formula was used to define the sediment input at the upstream boundary as a function of the corresponding flow hydrograph on the other hand uniform steady flow conditions i e defined using the manning strickler formula had to be assumed in order to define the sediment input at the upstream boundary and the stage flow curve for the downstream boundary due to that a disparity exists between the sediment transport at the boundary defined for uniform flow conditions and in the channel defined for unsteady flow conditions directly by the cche2d model such approximations at the boundaries are however virtually inevitable considering that the hm model represents a river channel and not of an idealized conceptual channel this imperfect representation of the boundaries is unlikely to significantly detract from the goals of the related sensitivity analysis and is therefore deemed sufficient the channel was simulated using a depth averaged two dimensional 2dh numerical modelling grid defined by a longitudinal spacing of 2 m over a length of 1000 m totalling 51 cross sections and a transversal spacing which coincides with the 15 defining points of the channel s cross section presented in fig 3 for a total of 765 grid cells 1 6 variable definition the sensitivity of fluvial morphodynamics was analysed in respect to four different variables channel granulometry expressed by the median grain diameter d 50 channel s bed roughness expressed by a uniform manning s roughness parameter n streamflow expressed by a flood magnitude parameter q which characterizes the intensity of the simulated flood event definition given below sediment input a percentage deviation δ qs relative to the sediment input estimate at the upstream boundary the variability ranges of these quantities d 50 n q δ qs represent the uncertainty of the corresponding variables in this instance the definition of such ranges was essentially based on the available literature and the information from these variables values as taken from the mondego river data both d 50 and n were simulated as uniform constant parameters along the entire channel while in real river situations d 50 and particularly n are rarely uniform the representation of the effects resulting from such complexity in a straight channel could be to some extent unrealistic and may therefore be more appropriately defined by adjusting the corresponding variability ranges the d 50 s variability range was based on granulometric data from the mondego river this data pertains to six granulometric curves approximately evenly spread out over a longer reach 40 km long including the study reach and it has been deemed to be approximately representative of the granulometry s variability in accordance with the simplified nature of the adopted case study a uniform sediment size was adopted to be represented by a corresponding d 50 a range of 1 5 30 mm was adopted for the d 50 s variability range which is virtually identical to the observed range of d 50 values the values of n were estimated based on the available literature schall et al 2008 arcement e and schneider 1984 chow 1959 for the mean n values in a river channel given that the straight channel is intended to represent a river channel and that the large number of factors which define n in a river channel is so large e g vegetation granulometry bed forms slope etc the channel s mean n was assumed to be independent of the grain size and to have values between 0 03 and 0 04 which are common reference values in the literature for a natural river channel the adopted values of n are intended to represent the combined effects of all relevant roughness factors e g the grain roughness the form roughness and the vegetative roughness a uniform distribution was assumed for representing the probability density function pdf of n the stage flow curve which determines the outflow at the downstream boundary was adjusted in conformity with the value of adopted n the streamflow data which was available consisted of a four and a half year long hourly streamflow series measured at the reservoirs upstream from the selected reach of the mondego river as this quantity of data is relatively insufficient to qualify the exact shape of flood events a standardized flood hydrograph based on a fréchet distribution for its shape was adopted the relative proportion of the synthetic hydrograph s temporal and flow scale was adjusted calibrated to match that of the available data the main reference flood event for this calibration is of a maximum value of around 600 m3 s which was observed in multiple instances for a duration of around 100 h to have a flow magnitude above 140 m3 s the selected flood magnitude parameter corresponds to a scaling parameter for the simulated synthetic hydrograph identical to the maximum flow magnitude of the hydrograph each simulated hydrograph therefore corresponds to that standardized hydrograph presented in fig 4 for a unitary value of q multiplied by the q parameter in terms of its flow magnitude and temporal scale the standardized hydrograph is intended to represent the overall conceptual shape of a real flood event while the q parameter is intended to represent the corresponding flood event s intensity fig 5 represents the estimated pdf of the streamflow data s peak flood magnitudes and therefore by extension the pdf of the q parameter for this case study the δ qs variable i e the uncertainty surrounding the sediment input in a reach while being known to be relevant for fluvial morphodynamics is hard to be characterized its uncertainty can change greatly from case to case depending on a multiplicity of factors such as the channel slope the flow regime the granulometry and the characteristics of the sediments themselves both locally at the boundary and significantly upstream from the boundary for the lack of a more detailed alternative in the literature the δ qs variable was expressed as a constant percentage deviation within each simulation of the sediment input at the upstream boundary concretely for each simulation the sediment input at the boundary estimated using the wu et al formula under uniform flow conditions as a function of the corresponding flow hydrograph was adjusted by a fixed factor of δ qs in order to represent the sediment input s uncertainty across simulations a uniform distribution was assumed for the δ qs s uncertainty the range of this uncertainty was set to 10 of its estimated value as suggested by topping et al topping and vierra 2000 for a large river fig 7 represents the final choices for the uncertainty distributions for all variables as said uniform distributions were assumed for the granulometry d 50 1 5 30 mm roughness n 0 03 0 04 s m1 3 and sediment input δ qs 10 10 for the water discharge its variability was defined by fitting a weibull to the recorded values of peak flood magnitude for the purposes of this simulation these variability ranges were assumed as adequate nevertheless while other values could possibly be assumed given the exemplificative nature of this case it is considered that there is no added value in further postulating on their distribution as a reference the resulting distribution of simulated mobility parameters defined as the effective shear stress divided by the critical shear stress calculated using the shields diagram for the maximum flow in each simulation and assuming uniform i e unidimensional steady flow conditions i e estimated using the manning strickler formula is presented in fig 6 each point represents one simulation s maximum mobility parameter calculated under the uniform steady flow assumption the process of simulating and representing the morphodynamical change of the straight channel as a function of its respective hydrodynamics and the selected morphodynamically relevant variables was accomplished by applying the selected numerical hm model for the data presented in the previous section for each application of the model the geometrical data of the channel along with sampled values of the different variables was used to simulate the morphodynamical uncertainty resulting from these variables the entire group of simulations jointly represents the uncertainty and the probability distribution of fluvial morphodynamical change as a function of the different variables for the purposes of the sensitivity analysis each simulation s morphodynamical change was summarized by a set of statistics described below and the variables effects on each of these statistics was analysed by either independent sensitivity analysis isa or joint sensitivity analysis jsa this process is graphically described in fig 7 given the large computational capacity required by the numerical hm model a crude monte carlo to stochastic modelling is not viable the values of the variables which are to be simulated cannot therefore be randomly sampled in this study specific quantile values of each variable were selected to represent their respective pdfs for simulation purposes the entirety of both the d 50 s the n s and the δ qs s variability ranges were sampled concerning parameter q since the corresponding pdf is unbounded the more extreme values of the variability range are not realistic such as a null valued or a virtually infinite parameter accordingly the variability of q was represented by the corresponding pdf s 5th to 95th quantiles for each of the variables a set of seven values was used to represent their respective pdf matching the 0th 17th 33rd 50th 67th 83rd and 100th quantiles for the d 50 n and δ qs variables and the 5th 20th 35th 50th 65th 80th and 95th quantiles for q the modelling of all of the potential combinations of these values results in a total of 74 2401 simulations the number of combinations of the seven values for each of the four variables when necessary these simulations have been individually identified by the ranking of their respective quantiles for example the 0th 1st value 17th 2nd value 65th 5th value and 100th 6th value quantiles of the d 50 n q and δ qs are symbolized as 1 2 5 7 in order for the extensive information on simulated bed level change dh across the channel which results from the stochastic modelling to be useable for sensitivity analysis it must be summarized using a series of statistics each of these statistics is meant to represent a quantification of a feature of the morphodynamical behaviour for each simulation each simulation would therefore have one value for each individual statistics the statistics analysed in this paper defined for an n number of grid cells in the simulations in this case 765 cells were overall mean absolute dh omac corresponding to the mean value of the absolute dh measured over along the entire channel eq 1 eq 1 omac 1 n i 1 n d h i f o r n g r i d n o d e s localized mean absolute dh lmac similar to omac but measured solely in areas where the dh is non null consisting of the mean absolute dh in the channel measured where dh 0 eq 2 eq 2 lmac 1 i 1 n 0 i f d h i 0 1 i f d h i 0 i 1 n d h i f o r n g r i d n o d e s localized mean dh lmc similar to lmac by in relative terms consisting of the mean dh in the channel measured where dh 0 eq 3 this statistic serves as an indication of the average tendency of dh i e towards erosion or sedimentation eq 3 lmc 1 i 1 n 0 i f d h i 0 1 i f d h i 0 i 1 n d h i f o r n g r i d n o d e s mean absolute dh in the central channel cmac and in the banks bmac similar to omac but measured solely in the centre and banks of the channel respectively corresponding to the central 7 nodes and the outermost 8 grid nodes percentage of channel area flooded pfa the percentage of the simulated area measured as projected in a horizontal plane wetted during the flood events represented in eq 4 this value is measured as the percentage of the channel area where dh is non null because computationally any area which is flooded is subject to erosion or deposition even if only to a very small degree eq 4 pfa 1 n i 1 n 0 i f d h i 0 1 i f d h i 0 spatial variability of morphodynamics a measurement of the spatial irregularity of dh as defined by the 2nd order variability derivate of dh in the longitudinal and transversal direction masv eq 5 corresponds to the average 2nd order differentiated dh along the grid designated as δ 2 d h i j for grid node i j corresponding to the curvature of dh standardized by the dh s variance i e var d h thereby being adimensional larger values of this statistic indicate that the discontinuity of dh represented by elevated curvatures in dh relative to the overall variability of dh is larger and vice versa eq 5 masv 1 n i 2 n t 1 j 2 n l 1 δ 2 d h i j 2 var d h where n l and n t refer to the number of grid nodes in the longitudinal and transversal direction and n corresponds to the number of nodes where the δ 2 d h can be calculated viz which have other grid nodes around them all of these statistics were analysed in the context of the jsa the isa on the other hand was performed based solely on the lmac and lmc statistics 2 results of the simulations given the stochastic nature of the model s application individual simulations hold no individual value nonetheless as examples of the simulated of dh fig 8 displays three examples of simulations with parameters 3 2 2 1 4 5 7 3 and 5 7 7 5 the corresponding omac lmac cmac bmac pfa and masv statistics are presented in table 3 on average over all of the simulations dh in the channel tends towards erosion while both generalized erosion and generalized sedimentation cases are present simulations involving erosion have generally higher magnitudes of dh in addition a significant portion of dh tends to concentrate in the vicinity of the model s boundaries both of these effects are likely a result of the previously referred imperfections in the definition of the model s boundary conditions because the purpose of these simulations is the simplified representation of a real channel these tendencies are not necessarily harmful to the simulations goals as real rivers always possess some amount of natural trends unlike idealized channels which have none as can be observed the first and second examples for parameters 3 2 2 1 and 4 5 7 3 have very similar lmacs but very different omacs this is a result of the smaller flows and n which reduce the area affected by dh with a smaller pfa in the former relative to the latter resulting in the same average magnitude of dh but different average dh channel wide the cmac and bmac statistics further confirm the concentration of morphodynamical change in the centre of the channel with higher cmacs and lower bmacs in the presence of higher magnitude more concentrated dh the masv decreases successively with each case as the dh shifts from a more intense and concentrated and thereby irregular distribution in the first case 3 2 2 1 to a more widespread and continuous distribution in the last example 5 7 7 5 the choice of statistics performed in this study is meant to capture these different aspects of morphodynamics for the evaluation of morphodynamical sensitivities across the simulations the values of the selected statistics can vary significantly table 4 summarizes the range of values of these statistics for the 2401 simulations performed the sensitivity analysis of the simulations performed in this study was separated into an isa and a jsa the isa focused on describing the relationship between the channel s morphodynamics and each of the different variables namely the characteristics of the relationship e g linear non linear and the respective magnitudes in terms of bed change of the variables individual effects in the channel s morphodynamics regarding the jsa the objective was to assess the relative sensitivities and respective inter dependencies for the different variables regarding a variety of different aspects based on variance based global sensitivity analysis saltelli et al 2008 multiple combinations of values of the different variables selected from the distributions presented in fig 5 were simulated in order to represent not only their relative importance for fluvial morphodynamics but also to take into account the inter dependencies between the variables and their respective sensitivities 2 1 independent sensitivity analysis isa the individual effects produced by the different variables were assessed in terms of the localized mean absolute dh and the localized mean dh lmac and lmc respectively the independent sensitivity of each variable was measured by setting the remaining three variables to their median value e g the representative lmac and lmc values for the granulometry 1 x x x is obtained by setting the values of the n q and δ qs variables to the 50th quantile of their pdfs i e to values x 4 4 4 fig 9 presents the relationship between the simulated dh and each of the different variables the relationships between the morphodynamics and the selected variables can be clearly observed in fig 9 they are clearly non linear potentially following an exponential power decay albeit its shape for the δ qs variable is only observable on a smaller scale considering that the channel s natural tendency leans towards erosion the d 50 n and δ qs variables are inversely correlated with the lmac statistic while the q variable is directly correlated with lmac if the channel s dh tendency was towards sedimentation the relationship between dh and q would most likely be reversed in terms of the lmc statistic the effects of the q variable in particular grow more complicated and the variable itself clearly loses a significant amount of importance relative to the other variables in terms of the morphodynamical sensitivities the variables hierarchy regarding lmac is not entirely clear the d 50 is always the most important variable with a δlmac 0 027 m and a δlmc 0 024 m according to fig 9 and the δ qs variable produces the least impact on the statistics with a δlmac 0 0002 m and a δlmc 0 0002 m the q and n variables however while having a very similar importance regarding the lmac statistic with δlmacs of 0 00351 m and 0 00352 m respectively have very different effects regarding the lmc statistic with δlmcs of 0 0014 m and 0 0004 m respectively these results clearly evidentiate the importance of using multiple statistics to capture the different aspects which characterize morphodynamical change while the values of these statistics are relatively small this is to be expected considering that they pertain to the effects of single flood events which are naturally limited in terms of their morphodynamical capacity in addition these are average statistics meant to characterize the reach as a whole and not the more extreme values of dh further discussion on these results can be found in the discussion section 2 2 joint sensitivity analysis jsa the jsa was applied based on the results of the numerical hm simulations of the previously described straight channel performed for different values of the variables under analysis i e d 50 n q and δ qs as described in the variable definition section the sensitivity analysis of the results was performed in terms of variance based sensitivity measurements namely by way of the total effect index tei calculated by way of eq 6 which provides a measure of the importance of the variable i for the overall variability of statistic y i e y x i large value of tei close to 1 for a variable i indicate that this variable plays an important part in the definition of the statistic s magnitude saltelli et al 2004 conversely in the case of a small tei close to 0 the choice of the corresponding variable s value is likely not important because it will not significantly affect the results regarding the y statistic eq 6 tei y x i e var y x i var y 1 var e y x i var y where var x represents the variance of x e x is the mean expected value of x i can be any of the selected variables y x i is the values of the statistic y after the variability introduced by variable i is removed by averaging over the corresponding simulations and y x i is the values of the statistic y for a set value of variable i by visual analysis of the relative relationships between pairs of variables regarding each individual statistic this visual analysis also designated as pairwise comparisons was constructed by for every statistic y and every pair of variables i and j averaging over the remaining two variables as is expressed in eq 7 eq 7 y i j e y x k l w h e r e i j k l d 50 n q δ q s this sensitivity analysis was detailed in terms of all of the different statistics referred at the start of the simulation section thereby analysing different aspects and underlying characteristics of the channel s morphodynamics fig 10 displays the values of the tei calculated for the different statistics normalized so that each statistics teis sum up to unity as can be observed in this section the different statistics with the exception of the pfa are generally in agreement regarding the hierarchy of the variables in terms of their relative importance for morphodynamical variability however while the hierarchy itself is identical the relative importance of the variables changes very significantly in terms of the teis in decreasing order of importance the d 50 s the q s the n s and the δ qs s importances fluctuate between 43 and 66 30 and 40 3 and 18 and 0 and 2 the choice of statistic in particular can have a very significant impact in the variables relative importances for example the relative importance of q relative to n can change between two times higher in the masv statistic to ten times higher in the cmac statistic fig 11 fig 12 and fig 13 represent the pairwise comparison between the effects of the four variables under analysis for the lmac lmc and masv statistics the remaining statistics were not represented as they produced very similar results to the lmac lmc statistics and do not provide additional information these graphical representations provide a qualitative description of the relative importance of the different variables much in the same way as the tei and in comparison with statistics based approaches a more complete description of the relationships between the variables and their respective influences on fluvial morphodynamics for reference purposes the main criteria for interpreting the information represented in these figures is as follows the more perpendicular the contour lines are to a given axis the more important the corresponding variable is to the morphodynamical statistic under analysis very irregular contour lines are strong indicators of an independence between the variables effects regarding that particular morphodynamical statistic generally speaking situations like this occur when the inherent complexity and aleatory nature of morphodynamical change is more significant than the variables relationship in determining the statistics values continuous contour lines i e where a clear pattern can be observed in their progression as a function of the variables are indicative of an observable potentially replicable and structured relationship between the variables effects analysing multiple statistics is not only important in the analysis of the teis but also in the pairwise comparisons while significant similarities can be found between different statistics the lmc statistic for example captures an inflexion points in the channel s morphodynamical behaviour which is not present in the other statistics namely in the relationship between the q and the d 50 variables portrayed by the diversion of the contour lines as the simulations dh trend changes from erosion to sedimentation in this particular case study no clear example of an independence between the variables effects was observed with varying degrees of intensity an organized structure has been observed to relate the different variables effects on the statistics for the purposes of better understanding the variables interactions the exact nature of the structured relationships between the variables effects may be determined by way of additional sensitivity studies determining whether these relationships are the result of a superposition of effects and therefore the effects of the variables on the statistics are statistically independent or if there is a dependency between the variables effects can be better founded by looking into case studies with different characteristics and variable definitions regarding their nature and magnitude nonetheless in a complex system as is the case of fluvial morphodynamics where strong spatial and temporal dependencies are present a complete independence between any two variables is not likely the full analysis of these results and their likely causes and consequences is detailed in the discussion section of this study 3 discussion in the available literature only two examples of studies villaret et al 2016 van vuren 2005 could be found were two or more of the selected variables are analysed and a quantitative description of morphodynamical sensitivities is calculated table 5 summarizes the normalized sensitivities obtained in these studies as can be observed there is no agreement between these results and the results obtained in this study the variables determined to be the most important were q and n respectively in each of the two examples whereas in the case study it was the d 50 this disparity along with the highly variable importance hierarchy which has been determined in some other studies on the subject referred in table 2 shows that the morphodynamical sensitivities are significantly case dependent and cannot be readily generalized the scientific relevance of any set of individual sensitivities can therefore be concluded to be virtually limited to the corresponding case study while these values may be useful for comprehending a specific situation they are clearly not extendable to other situations the highly complex and compounding effects of the spatial and temporal dependencies of morphodynamics also observed by van vuren van vuren 2005 along with the strong case specificity of the variability ranges of the variables are likely to render most comparisons across case studies ineffective the present study simulated only single event floods a fact which is potentially responsible for the low importance of the δ qs variable observations indicate that this variable s importance for morphodynamics should increase with the time span of the simulations in the current study that possibility is strengthened by the morphodynamical sensitivities to this variable which were observed to be seven times larger at the start of the channel defined in terms of the omac statistic for the first three sections of the river than for the channel as a whole according to the normal definition of omac very likely for longer events this higher sensitivity would propagate downstream along the channel ultimately the 10 uncertainty adopted for the δ qs variable despite being in accordance with the available literature may also play a part in the comparatively low importance displayed in the present study as can be concluded the magnitudes of individual sensitivities are very unlikely to be comparable across significantly different cases this fact for the purposes of the validation of stochastic modelling is undesirable as was previously stated the validation of stochastic modelling is linked to the potential existence of a common generalizable behaviour across case studies the only remaining alternative solution is to identify replicable relative characteristics of the stochastic modelling s results examples of these relative characteristics may be the relationships between the different variables and morphodynamics represented in fig 9 of the isa and the relationships or lack thereof between the variables effects on morphodynamics represented in figs 11 13 of the jsa characteristics such as the direct or inverse correlation of the curves or contour lines and the features of their respective curvatures should be from a theoretical point of view a consequence of the morphodynamical processes inherent to the hm modelling and not of the variables themselves unfortunately there is no term of comparison available for these results regarding potential relative characteristics as there are virtually no recent studies which have quantified overall comparisons between the variables values and their effects on morphodynamics until such relative characteristics which should theoretically exist are found the validation of the stochastic modelling of fluvial morphodynamics is practically limited to the comparison of sensitivities between very similar case studies unfortunately data on such case studies is often not readily available regarding sensitivity analysis specifically even within the same type of environment numerical model and uncertainty simulation the choice of morphodynamical and sensitivity statistics can have a great impact on the results this much was observed in this study when comparing the results of the isa and the jsa which used respectively a range based statistic and a variance statistic to quantify morphodynamical sensitivities in this instance the hierarchy of the importance of the q and n variables changed depending on the choice in addition the relative importance of the d 50 variable changes from nearly ten times larger than any other variable in the range statistics to a maximum of two and half times in the variance statistic in the work by van vuren van vuren 2005 the sensitivity of q in particular more than doubled when switching from a correlation statistic to a variance statistic while a definitive answer on what is the optimal statistic cannot be forcefully stated from a conceptual point of view the variance statistic should be a more appropriate choice because it is less unstable than the range based values used to assess dh statistics in isa i e the δlmac and δlmc values which are calculated based on the extreme values of the dh produced by each of the corresponding variables in addition the variance statistic also does not assume a linear relationship between the variables and morphodynamics as does the correlation statistic the use of multiple morphodynamical statistics omac lmac lmc etc was observed to be relevant in capturing different aspects of morphodynamics producing different magnitudes of sensitivities and even a different hierarchical order in the isa in order to fully understand a fluvial system these statistics can help in producing a much clearer picture of the variables effects and interactions with fluvial morphodynamics the results show that future studies involving sensitivity analysis in a fluvial context should make use of multiple morphodynamical variance based statistics in order to provide a more stable and complete description of morphodynamics 4 conclusions in this study an analysis of the concept and usefulness of sensitivity analysis was performed namely in the context of the stochastic modelling of fluvial morphodynamics with this purpose in mind a review on applications of sensitivity analysis in a fluvial environment was conducted along with an original application of sensitivity analysis in a straight channel the main question which was to be answered is whether sensitivity analysis can be used for the validation of the stochastic modelling itself a common approach to validation in other areas of study or if its usefulness is limited to providing an understanding on the specific case study whether the results of sensitivity analysis can or not be generalized across different situations is overall the determining factor in answering this question by taking into consideration different statistics themselves representative of different aspects of morphodynamics this study was intended to move away from the typically case specific morphodynamical sensitivity studies were the analysis of sensitivities is restricted to observing the variable induced variability ranges and to focus more on the morphodynamical processes themselves using different morphodynamical and sensitivity statistics in the independent and the joint sensitivity analysis provided a significantly clearer understanding on the variables effects on morphodynamics nonetheless the results are clear morphodynamical sensitivities cannot be generalized across case studies with significant differences in terms of either the temporal or spatial scales of the simulations or the characteristics and variability ranges of the variables and parameters involved other potential uses of sensitivity analysis such as the prioritization of the variables definition are also undermined by the non generalizable nature of sensitivities in a fluvial environment theoretically similar cases produce similar sensitivities and can be used in the validation of stochastic modelling the difficulty in this option lies in defining the point up to which two case studies can be considered reasonably similar primarily due to the complexity of the inherent processes nevertheless certain aspects of the relationships between the variables effects and morphodynamical change such as the curvature and other shape characteristics represented in figs 9 and 11 13 due to their relative nature have a significant potential for generalization and may offer an alternative solution for sensitivity analysis based validation of stochastic modelling in future studies on this subject these relationships between the sources of morphodynamical uncertainty and morphodynamics itself will be further evaluated using different case studies with different sets of data and different time frames and compared with the results of this study only then can a general definition of reproducible relative relationships be estimated which in turn can allow for a sensitivity analysis based validation of stochastic modelling additional morphodynamical statistics preferably of a more adimensional nature should also be considered as they may assist in detecting patterns in the variables relationships declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the present work has been developed under a scholarship funded by the fundação para a ciência e a tecnologia of portugal with the scholarship reference number pd bi 128053 2016 
