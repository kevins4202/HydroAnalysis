index,text
6150,the accuracy of four evolutionary neuro fuzzy methods adaptive neuro fuzzy inference system with particle swarm optimization anfis pso anfis with genetic algorithm anfis ga anfis with ant colony algorithm anfis aco and anfis with butterfly optimization algorithm anfis boa is investigated and compared with classical anfis method in forecasting various time scales of standard precipitation index spi monthly precipitation data of abbasabad biarjmand and ebrahim abad stations iran are used in the case study the comparison is made according to the three indexes root mean square error rmse mean absolute error and index of agreement it is observed that the evolutionary neuro fuzzy methods perform superior to the classical anfis in forecasting all spi indexes spi 3 spi 6 spi 9 and spi12 in all three stations the rmse of the classic method is increased roughly by 11 4 16 7 11 3 32 4 9 8 34 4 30 6 46 7 for the spi 3 spi 6 spi 9 and spi 12 respectively in ebrahim abad station the best accuracy is observed from the anfis pso method for all drought indexes while there is not a dominant method in abbasabad and biarjmand stations keywords drought forecasting particle swarm genetic algorithm ant colony butterfly optimization neuro fuzzy computation 1 introduction a drought means a climatological period of low precipitation within the controlled region resulting from long term deficits including the water supply surface water and groundwater and so on mckee et al 1993 this phenomenon may cause shortages of crop yields low flow for sustainable river system severe deficits in the drinking water and potential problems for the environment belayneh et al 2016 nearly 1 4 billion people in the world have been affected by drought directly or indirectly since 1967 obasi 1994 in general drought can be classified by four categories including climatological meteorological agricultural and hydrological types mishra and desai 2005 2006 mishra et al 2007 a climatological drought can be quantified using effective drought index edi and standardized precipitation index spi byun and wilhite 1999 mckee et al 1993 palmer drought severity index pdsi palmer 1965 and soil moisture drought index smdi hollinger et al 1993 have been included in meteorological and agricultural droughts respectively hydrological drought means shortage of water in addition aggregated drought index adi can cover all droughts categories e g meteorological hydrological and agricultural using the suitable parameters keyantash and dracup 2004 therefore since the different people e g meteorologist hydrologist and agricultural scientist may interpret drought for their purposes it can be the part of policy makers politicians and diverse managers wilhite et al 1986 extensive researches have been accomplished to forecast accurate drought since 1960 s yevjevich 1967 saldarriaga and yevjevich 1970 şen 1977 dracup et al 1980 frick et al 1990 chung and salas 2000 cancelliere and salas 2004 salas et al 2005 mishra and singh 2010 2011 madadgar and moradkhani 2013 diverse indices e g edi spi pdsi smdi and adi and stochastic methods have been developed for the drought modeling palmer 1965 alley 1985 hollinger et al 1993 mckee et al 1993 byun and wilhite 1999 mishra and desai 2005 paulo and pereira 2007 barua et al 2010 2012 khalili et al 2011 the researches on the drought forecasting using heuristic approaches have been investigated and continued now mishra and desai 2006 morid et al 2007 bacanli et al 2009 cutore et al 2009 keskin et al 2009 santos et al 2009 barua et al 2010 2012 dastorani and afkhami 2011 farokhnia et al 2011 keskin et al 2011 belayneh and adamowski 2012 2013 özger et al 2012 rezaeian zadeh and tabari 2012 shirmohammadi et al 2013 choubin et al 2014 mehr et al 2014 deo and şahin 2015 hosseini moghari and araghinejad 2015 maca and pech 2016 deo et al 2017a the dominant applications for forecasting accurate droughts have been progressed into the diverse scientific combinations with heuristic approaches mishra et al 2007 özger et al 2012 belayneh and adamowski 2012 belayneh et al 2014 mehr et al 2014 jalalkamali et al 2015 rezaeianzadeh et al 2016 mishra and desai 2005 combined the artificial neural networks ann and linear stochastic models using spi series in kansabati river basin india the combination model forecasted drought with a good accuracy shirmohammadi et al 2013 used the wavelet transform wt technique and adaptive neuro fuzzy inference system anfis for meteorological drought forecasting in east azerbaijan province iran they provided that the accuracy of wavelet based anfis model was better than ann and anfis models dehghani et al 2014 developed multi layer perceptron mlp model embedded with monte carlo method using standardized hydrological drought index shdi in karoon river iran results showed that the hybrid model forecasted drought within 95 confidence intervals belayneh et al 2016 applied the wt bootstrap and boosting ensemble methods to predict accurate drought using spi series in awash river basin ethiopia results explained that the accuracy of wavelet based boosting support vector regression svr approach was the best among the proposed models djerbouai and souag gamane 2016 developed the wavelet based model using spi series for drought forecasting in algerois basin algeria they showed that the accuracy of wavelet based ann model was better than ann and stochastic models deo et al 2017b proposed the wavelet based extreme learning machine elm for forecasting drought indices in three stations australia they proved that the wavelet based elm model was better than other models e g elm ann least squares support vector regression lssvr wavelet based ann and wavelet based lssvr hosseini moghari et al 2017 conjugated the imperialist competitive algorithm ica to recursive mlp rmlp and recursive svr rsvr models for drought forecasting in gorganrood iran they suggested that ica rmlp and ica rsvr models surpassed the stochastic model although there have been previous researches for the conjunction of heuristic approaches and optimization methods specific investigation on drought forecasting using hybrid methods has been limited so far this paper investigates the accuracies of new anfis models combined with meta heuristic algorithms e g genetic algorithm ga particle swarm optimization pso ant colony algorithm acb butterfly optimization algorithm boa in drought forecasting research compares the performances of new models with conventional anfis model according to the review of the authors the anfis with the mentioned heuristic algorithms has not been applied for drought forecasting till now the applied hybrid methods are very important approaches for drought forecasting in three stations e g abbasabad biarjmand and ebrahim abad iran the model performances are evaluated using model efficiency indices and graphical comparison the paper is analyzed as follows the second chapter provides the methodology including anfis and different optimization methods respectively the third chapter presents study area and data and the fourth chapter gives results and discussion conclusions are found in the last 2 materials and methods 2 1 study area finding the clear knowledge about the variations of the climatic and hydrologic parameters in arid and semi arid areas is a vital issue semnan province as a semi arid area located in the north of iran at 34 17 to 37 00 north latitude and 51 58 to 57 58 east longitude the average altitude of the study area is about 1630 m and its area is 97 491 square kilometers fig 1 shows the general view of the study area due to poor botanical cover and the spatial situation of the study area precise monitoring of the hydrologic parameters is necessary the maximum and minimum absolute temperatures in the study area are 25 and 11 c respectively the long term average precipitation amount is 120 mm while the annual average evaporation reaches to 220 9 mm 2 2 standard precipitation index the precipitation analysis is a complicated process due to its temporal and spatial multiplicity considering that an applicable drought index is needed to be used and spi is one of the most appropriate ones spi is a meteorological drought index and has various time scales such as 1 3 6 9 12 and 24 months spi is an appropriate quantifying model for various drought events szalai and szinell 2000 and each time scale can be used for a specific aim zhang et al 2017 monthly precipitation data should be completed for a certain time scale hayes et al 1999 spi is mathematically based on the cumulative probability of observational precipitation data and it has been proved that the precipitation shows the gamma distribution thom 1958 edwards and mckee 1997 gamma probability density function is expressed as below 1 g x 1 β α γ α x α 1 e x β for x 0 where γ α 0 x α 1 e x d x α 1 4 a 1 1 4 a 3 a ln x ln x n and β x α the cumulative probability g x then can be obtained as below 2 g x 0 x g x since the precipitation may be zero the cumulative probability will be changed to 3 h x q 1 q g x where q m n and m and n are the numbers of zero precipitation data and observation number of precipitation respectively then the spi can be calculated as below based on lloyd hughes and saunders 2002 4 spi t c 0 c 1 t c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 0 h x 0 5 5 spi t c 0 c 1 t c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 0 5 h x 1 0 where the expression form of t is 6 t ln 1 h x 2 0 h x 0 5 7 t ln 1 1 h x 2 0 5 h x 1 0 in the equations above c0 2 515517 c1 0 802853 c2 0 010328 d1 1 432788 d2 0 189269 and d3 0 001308 mckee et al 1993 drought classification of spi can be obtained from previous literature mckee et al 1993 deo et al 2017a 2 3 soft computing methods in the present study the adaptive neuro fuzzy inference system anfis is used as a soft computing technique for forecasting spi3 spi6 spi9 and spi12 in this regard in addition to the classic anfis four other conjunctive anfis models embedded with meta heuristic optimization algorithms ga pso aco boa are also applied brief description of these methods is given below 2 3 1 adaptive neuro fuzzy inference system the adaptive neuro fuzzy inference system features the capabilities of both artificial neural networks and fuzzy inference system which is used for modeling non linear complex functions anfis is composed of a fuzzy inference system which was first introduced by jang 1993 in anfis model the fuzzy system is allowed to use the adaptive back propagation training algorithm in order for training the parameters fig 2 demonstrates a schematic view of the anfis structure as shown in fig 2 the anfis structure consists of five layers each node of the first layer determines the degree of membership of the input parameters the fuzzification layer at this layer different membership functions such as gaussian triangular trapezoid and bell functions can be used the second layer is known as the rule base layer which uses the multiplication operator output of the third layer is the normalized form of the previous layer the fourth layer is the defuzzification layer and the fifth layer includes the output nodes by means of the summation of the outputs of the forth layer for further information on anfis refer to zounemat kermani and teshnehlab 2008 2 3 2 genetic algorithm genetic algorithm ga is an inspirational search algorithm that has proved its great capability and robustness in optimizing complex problems based on the biological evolution mechanism this meta heuristic algorithm belongs to the class of evolutionary algorithms which generate and develop solutions to the wide range of complex problems using some inspired natural evolution techniques such as crossover and mutation from the parents to the offspring the general modelling procedure of the ga can be briefly addressed as 1 generation of random candidate solutions 2 evaluating the fitness of the candidates 3 creating the next generation considering the principle of proportionate and natural evolution approaches such as mutation and 4 continuing the re production process until reaching the desired result according to the convergence criteria detailed information about the application of ga in engineering problems can be found in numerous published studies kisi et al 2012 ravansalar et al 2016 naghibi et al 2017 2 3 3 particle swarm optimization algorithm the idea of pso particle swarm optimization algorithm was first proposed by kennedy and eberhart 1995 pso algorithm is an evolutionary algorithm based on repetitions which has been inspired by the social behavior of animals such as movement of the massive flocks of birds and fish the principles and basis of working with this algorithm is such that first a series of particles is assumed each particle has a velocity vector and position vector which tend to move toward optimal points in accordance with their velocities any change in the position of each particle occurs on the basis of the experience of the particle itself as well as the experiences of the neighboring particles in fact each particle is well aware of its superiority or non superiority over its neighboring particles as well as the entire group and thus changes its position regarding these cases each particle has an xi position vector which includes the optimization parameters and its dimension is equivalent to the number of parameters value of the objective function is calculated for each particle then the best position is determined for the particle afterwards the new position of each particle is calculated via the following equations 8 v i k ω v i k 1 c 1 r 1 k x b x i k 1 c 2 r 2 k x g x i k 1 9 x i k x i k 1 v i k where ω is the inertia weight vi is velocity of the ith particle xb is the individual best position xg is the global best position r1 and r2 are random numbers and c1 and c2 are learning coefficients and k is iteration number marini and walczak 2015 2 3 4 ant colony algorithm the ant colony aco algorithm is an optimization algorithm inspired by the behavior of ants this algorithm was primarily proposed for solving the optimization problems in a discrete space but later it was developed for continuous space as well socha and dorigo 2008 in aco algorithm in a discrete space in each step an ant creates its route based on a probabilistic relation in which the route with more pheromone is more likely to be selected this probabilistic structure is founded on the basis of the discrete probability distribution however in acor algorithm this discrete probability distribution has been converted into a continuous probability density function in the acor algorithm an archive is used to store the set of solutions for a system with n decision variables k single gaussian functions are assumed for each decision variable in the given archive so that selecting each of them and generating a new solution will result in a status for each variable that is indeed equivalent to a kernel gaussian function the solutions existing in the archive are sorted and stored in accordance with their quality in a descending order liao et al 2014 the process of pheromone content updating in acor algorithm is accomplished by storing the superior solutions and eliminating the poor solutions in the archive of solutions 2 3 5 butterfly optimization algorithm the butterfly optimization algorithm boa is a newly nature inspired optimization algorithm arora and singh 2017 arora and singh 2018 for solving global optimization problems this algorithm mimics the procedure of food search and the mating of butterflies in the nature the foraging strategy of butterflies is the main framework of this optimization technique in other words the main idea of developing the boa is inspired by the cooperative movement of the butterflies toward the position of the food sources using their potential ability of tracking the smell of food source mate in the air readers are referred to the original published study by arora and singh 2018 for more detailed information about this algorithm 3 results and discussion in the present study four evolutionary anfis models anfis pso anfis ga anfis boa and anfis acor were applied for forecasting drought indexes spi 3 spi 6 spi 9 and spi 12 and results were compared with classic anfis to see the accuracy improvement of the new methods for this purpose the following measures were considered 10 r o o t m e a n s q u a r e e r r o r r m s e i 1 n y i o y i m 2 n 11 m e a n a b s o l u t e e r r o r m a e i 1 n y i o y i m n 12 i n d e x o f a g r e e m e n t i a 1 i 1 n y i m y i o 2 i 1 n y i m y o y i o y o 2 where y i m is the model s output y i o is the observed value y 0 is the mean of the observed value and n is number of data data were split into three parts training validation and test the number of data and optimal input structures of the applied models are reported in table 1 in this table spi3 1 refers the 1 lag spi value and vice versa the model inputs were identified by applying correlation analysis the most effective lags obtained from correlation analysis auto correlation and partial autocorrelation were considered as inputs to the neuro fuzzy models to forecast drought indexes of each station for sp3 forecasting the most effective lags of spi3 series were searched for spi6 forecasting the optimal lags of spi3 and spi6 series were investigated and vice versa table 2 provides the parameters used for development of each method in forecasting spi tables 3 and 4 sums up the training validation and test results of the applied neuro fuzzy methods in forecasting spi 3 of three stations it is obvious that the classic anfis model has higher accuracy in approximating drought index than the evolutionary anfis models whereas the latter performs superior to the first in validation and test stages in the validation stage the anfis acor has the lowest rmse and mae and the highest r2 and ia for the abbasabad and biarjmand stations while the anfis pso gives the best statistics in ebrahim abad station in the test stage however anfis ga has the best score with respect to various criteria for the biarjmand station the rmse mae accuracy of the classic anfis model in forecasting spi 3 was increased by 11 4 11 6 11 7 11 5 and 16 7 16 9 using acor ga and pso algorithms for the abbasabad biarjmand and ebrahim abad stations respectively training validation and test statistics of the different neuro fuzzy methods in forecasting spi 6 are given in tables 5 and 6 here also the performances of the models vary with respect to three stages training validation and testing the anfis ga anfis and anfis ga have the best approximation in training stage of the abbasabad biarjmand and ebrahim abad while the anfis ga anfis ga and anfis pso perform superior to the other models in validation stage for the same stations respectively classic anfis has slightly higher rmse than the anfis ga in abbasabad station in testing stage different trends are shown by the employed methods the best performance was reached using anfis pso anfis acor and anfis pso models in forecasting spi 6 with respect to rmse r2 mae and ia statistics at abbasabad biarjmand and ebrahim abad stations respectively the best hybrid neuro fuzzy models improved the rmse mae accuracy of the classic anfis model by 11 3 12 2 32 4 32 3 and 25 2 26 2 in abbasabad biarjmand and ebrahim abad respectively tables 7 and 8 reports the training validation and test measures of the different neuro fuzzy methods in forecasting spi 9 according to the training measures anfis pso anfis and anfis acor provide the best exactness in abbasabad and ebrahim abad in biarjmand the anfis pso has the lowest mae 0 294 and the highest r2 0 822 the rmse and r2 of the anfis pso however are slightly different from those of the anfis acor therefore it can be said that anfis pso has the best accuracy in validation stage of biarjmand sattion in the test stage different results are obtained compared to training and validation stages in abbasabad station the anfis boa is ranked as the first with the lowest rmse 0 398 and mae 0 301 and the highest r2 0 771 followed by the anfis acor anfis ga anfis and anfis pso respectively in biarjmand also the anfis boa provides the best accuracy with the lowest rmse 0 398 and mae 0 301 and the highest r2 0 877 and ia 0 964 followed by the anfis ga anfis acor anfis pso and anfis respectively in ebrahim abad station the anfis pso has the first rank with the lowest rmse 0 409 and mae 0 288 and the highest r2 0 669 followed by the anfis ga anfis acor anfis boa and anfis respectively the rmse mae accuracy of the classic anfis model in forecasting spi 9 was increased by 17 3 12 2 34 4 35 and 9 8 12 4 using boa boa and pso algorithms for the abbasabad biarjmand and ebrahim abad stations respectively the models accuracies are compared in tables 9 and 10 in forecasting spi 12 of three stations as clearly seen from table 9 the anfis has better approximation than the other models in biarjmand and ebrahim abad stations while for the abbasabad the anfis ga provides the lowest rmse and mae and the highest r2 and ia in training stage in the validation stage however the anfis ga anfis pso and anfis boa models have the highest performance for the abbasabad biarjmand and ebrahim abad respectively in the test stage different trends are observed from the results the anfis pso produces the lowest rmse 0 334 and mae 0 230 and the highest r2 0 831 and ia 0 954 while for the biarjmand and ebrahim abad the anfis ga and anfis pso performed the best in forecasting spi 12 respectively the best hybrid neuro fuzzy models increased the rmse mae accuracy of the classic anfis model by 30 6 32 9 46 7 53 6 and 30 6 40 6 in abbasabad biarjmand and ebrahim abad respectively the overall accuracies of the applied methods in forecasting spi 3 spi 6 spi 9 and spi 12 are compared in table 11 in the table 1 means the best accuracy and 5 means the worst one it is clear there is not a dominant model all drought indexes in abbasabad and biarjmand stations in ebrahim abad station the anfis pso has the first accuracy in forecasting all indexes for the abbasabad station the anfis acor anfis pso anfis boa and anfis pso has the best accuracy in forecasting spi 3 spi 6 spi 9 and spi 12 respectively while the anfis ga anfis acor anfis boa and anfis ga provide the best performance in forecasting corresponding indexes in biarjmand station from table 11 it is apparent that the new anfis models outperform the classic anfis model accuracy in drought forecasting the evolutionary anfis models are graphically compared in figs 3 and 4 in forecasting spi 12 of abbasabad station in the test stage it can be clearly seen from scatterplots that the trendline of the anfis pso is closer to the 1 1 line compare the slope coefficients of the trendline equations with a lower r2 0 831 than the anfis ga anfis boa and anfis acor figs 5 and 6 illustrates the spi 12 forecasts of the evolutionary anfis models for the biarjmand station in the test stage the r2 values of the anfis boa and anfis ga are equal to each other but the trendline of the latter model is closer to the 1 1 line compared to first one for the ebrahim abad stations the models are compared in figs 7 and 8 in forecasting spi 12 in the test stage it is observed from the scatterplots that the anfis pso less scattered estimates compared to other three models there is a slight difference between the anfis pso and anfis acor models this confirms the test measures provided in table 10 all the applied methods provided different results in validation and testing stages and this indicated the necessity of separation data in three parts in the literature data are generally separated in two parts training and validation and models are obtained with respect to validation accuracy e g keskin et al 2009 2011 deo and şahin 2015 and this may mislead the modeler in selecting the optimal models for the studied phenomenon dividing data into three parts and thus testing models with the third part which was not used in model development stage should be preferred for better evaluation of the models the other way to evaluate data driven models may be use of cross validation methods 4 conclusion in the current study the ability of four evolutionary neuro fuzzy methods anfis pso anfis ga anfis boa and anfis acor was evaluated in forecasting four standard precipitation indexes spi 3 spi 6 spi 9 and spi 12 and they compared with classical anfis monthly precipitation data from three stations abbasabad biarjmand and ebrahim abad in semnan province iran were utilized in the applications the following conclusions can be reached from the applications in all stations and for all spi indexes the evolutionary neuro fuzzy methods outperformed the classical one the improvement of classical anfis models with respect to rmse range from 11 4 16 7 11 3 32 4 9 8 34 4 30 6 46 7 for the spi 3 spi 6 spi 9 and spi 12 respectively it may be said that improvement increases by the increment in index time scale among the four new methods the anfis pso performed superior to the anfis ga anfis boa and anfis acor in forecasting spi 3 spi 6 spi 9 and spi 12 in ebrahim abad station for the biarjmand station anfis ga anfis acor anfis boa and anfis ga showed the best accuracy while the anfis acor anfis pso anfis boa and anfis pso has the best rank in the abbasabad station in forecasting spi 3 spi 6 spi 9 and spi 12 respectively the results obtained from the present study may be useful for hydrologists agriculturalists and water resources planners in making strategic decisions especially in the arid and semi arid regions like iran declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
6150,the accuracy of four evolutionary neuro fuzzy methods adaptive neuro fuzzy inference system with particle swarm optimization anfis pso anfis with genetic algorithm anfis ga anfis with ant colony algorithm anfis aco and anfis with butterfly optimization algorithm anfis boa is investigated and compared with classical anfis method in forecasting various time scales of standard precipitation index spi monthly precipitation data of abbasabad biarjmand and ebrahim abad stations iran are used in the case study the comparison is made according to the three indexes root mean square error rmse mean absolute error and index of agreement it is observed that the evolutionary neuro fuzzy methods perform superior to the classical anfis in forecasting all spi indexes spi 3 spi 6 spi 9 and spi12 in all three stations the rmse of the classic method is increased roughly by 11 4 16 7 11 3 32 4 9 8 34 4 30 6 46 7 for the spi 3 spi 6 spi 9 and spi 12 respectively in ebrahim abad station the best accuracy is observed from the anfis pso method for all drought indexes while there is not a dominant method in abbasabad and biarjmand stations keywords drought forecasting particle swarm genetic algorithm ant colony butterfly optimization neuro fuzzy computation 1 introduction a drought means a climatological period of low precipitation within the controlled region resulting from long term deficits including the water supply surface water and groundwater and so on mckee et al 1993 this phenomenon may cause shortages of crop yields low flow for sustainable river system severe deficits in the drinking water and potential problems for the environment belayneh et al 2016 nearly 1 4 billion people in the world have been affected by drought directly or indirectly since 1967 obasi 1994 in general drought can be classified by four categories including climatological meteorological agricultural and hydrological types mishra and desai 2005 2006 mishra et al 2007 a climatological drought can be quantified using effective drought index edi and standardized precipitation index spi byun and wilhite 1999 mckee et al 1993 palmer drought severity index pdsi palmer 1965 and soil moisture drought index smdi hollinger et al 1993 have been included in meteorological and agricultural droughts respectively hydrological drought means shortage of water in addition aggregated drought index adi can cover all droughts categories e g meteorological hydrological and agricultural using the suitable parameters keyantash and dracup 2004 therefore since the different people e g meteorologist hydrologist and agricultural scientist may interpret drought for their purposes it can be the part of policy makers politicians and diverse managers wilhite et al 1986 extensive researches have been accomplished to forecast accurate drought since 1960 s yevjevich 1967 saldarriaga and yevjevich 1970 şen 1977 dracup et al 1980 frick et al 1990 chung and salas 2000 cancelliere and salas 2004 salas et al 2005 mishra and singh 2010 2011 madadgar and moradkhani 2013 diverse indices e g edi spi pdsi smdi and adi and stochastic methods have been developed for the drought modeling palmer 1965 alley 1985 hollinger et al 1993 mckee et al 1993 byun and wilhite 1999 mishra and desai 2005 paulo and pereira 2007 barua et al 2010 2012 khalili et al 2011 the researches on the drought forecasting using heuristic approaches have been investigated and continued now mishra and desai 2006 morid et al 2007 bacanli et al 2009 cutore et al 2009 keskin et al 2009 santos et al 2009 barua et al 2010 2012 dastorani and afkhami 2011 farokhnia et al 2011 keskin et al 2011 belayneh and adamowski 2012 2013 özger et al 2012 rezaeian zadeh and tabari 2012 shirmohammadi et al 2013 choubin et al 2014 mehr et al 2014 deo and şahin 2015 hosseini moghari and araghinejad 2015 maca and pech 2016 deo et al 2017a the dominant applications for forecasting accurate droughts have been progressed into the diverse scientific combinations with heuristic approaches mishra et al 2007 özger et al 2012 belayneh and adamowski 2012 belayneh et al 2014 mehr et al 2014 jalalkamali et al 2015 rezaeianzadeh et al 2016 mishra and desai 2005 combined the artificial neural networks ann and linear stochastic models using spi series in kansabati river basin india the combination model forecasted drought with a good accuracy shirmohammadi et al 2013 used the wavelet transform wt technique and adaptive neuro fuzzy inference system anfis for meteorological drought forecasting in east azerbaijan province iran they provided that the accuracy of wavelet based anfis model was better than ann and anfis models dehghani et al 2014 developed multi layer perceptron mlp model embedded with monte carlo method using standardized hydrological drought index shdi in karoon river iran results showed that the hybrid model forecasted drought within 95 confidence intervals belayneh et al 2016 applied the wt bootstrap and boosting ensemble methods to predict accurate drought using spi series in awash river basin ethiopia results explained that the accuracy of wavelet based boosting support vector regression svr approach was the best among the proposed models djerbouai and souag gamane 2016 developed the wavelet based model using spi series for drought forecasting in algerois basin algeria they showed that the accuracy of wavelet based ann model was better than ann and stochastic models deo et al 2017b proposed the wavelet based extreme learning machine elm for forecasting drought indices in three stations australia they proved that the wavelet based elm model was better than other models e g elm ann least squares support vector regression lssvr wavelet based ann and wavelet based lssvr hosseini moghari et al 2017 conjugated the imperialist competitive algorithm ica to recursive mlp rmlp and recursive svr rsvr models for drought forecasting in gorganrood iran they suggested that ica rmlp and ica rsvr models surpassed the stochastic model although there have been previous researches for the conjunction of heuristic approaches and optimization methods specific investigation on drought forecasting using hybrid methods has been limited so far this paper investigates the accuracies of new anfis models combined with meta heuristic algorithms e g genetic algorithm ga particle swarm optimization pso ant colony algorithm acb butterfly optimization algorithm boa in drought forecasting research compares the performances of new models with conventional anfis model according to the review of the authors the anfis with the mentioned heuristic algorithms has not been applied for drought forecasting till now the applied hybrid methods are very important approaches for drought forecasting in three stations e g abbasabad biarjmand and ebrahim abad iran the model performances are evaluated using model efficiency indices and graphical comparison the paper is analyzed as follows the second chapter provides the methodology including anfis and different optimization methods respectively the third chapter presents study area and data and the fourth chapter gives results and discussion conclusions are found in the last 2 materials and methods 2 1 study area finding the clear knowledge about the variations of the climatic and hydrologic parameters in arid and semi arid areas is a vital issue semnan province as a semi arid area located in the north of iran at 34 17 to 37 00 north latitude and 51 58 to 57 58 east longitude the average altitude of the study area is about 1630 m and its area is 97 491 square kilometers fig 1 shows the general view of the study area due to poor botanical cover and the spatial situation of the study area precise monitoring of the hydrologic parameters is necessary the maximum and minimum absolute temperatures in the study area are 25 and 11 c respectively the long term average precipitation amount is 120 mm while the annual average evaporation reaches to 220 9 mm 2 2 standard precipitation index the precipitation analysis is a complicated process due to its temporal and spatial multiplicity considering that an applicable drought index is needed to be used and spi is one of the most appropriate ones spi is a meteorological drought index and has various time scales such as 1 3 6 9 12 and 24 months spi is an appropriate quantifying model for various drought events szalai and szinell 2000 and each time scale can be used for a specific aim zhang et al 2017 monthly precipitation data should be completed for a certain time scale hayes et al 1999 spi is mathematically based on the cumulative probability of observational precipitation data and it has been proved that the precipitation shows the gamma distribution thom 1958 edwards and mckee 1997 gamma probability density function is expressed as below 1 g x 1 β α γ α x α 1 e x β for x 0 where γ α 0 x α 1 e x d x α 1 4 a 1 1 4 a 3 a ln x ln x n and β x α the cumulative probability g x then can be obtained as below 2 g x 0 x g x since the precipitation may be zero the cumulative probability will be changed to 3 h x q 1 q g x where q m n and m and n are the numbers of zero precipitation data and observation number of precipitation respectively then the spi can be calculated as below based on lloyd hughes and saunders 2002 4 spi t c 0 c 1 t c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 0 h x 0 5 5 spi t c 0 c 1 t c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 0 5 h x 1 0 where the expression form of t is 6 t ln 1 h x 2 0 h x 0 5 7 t ln 1 1 h x 2 0 5 h x 1 0 in the equations above c0 2 515517 c1 0 802853 c2 0 010328 d1 1 432788 d2 0 189269 and d3 0 001308 mckee et al 1993 drought classification of spi can be obtained from previous literature mckee et al 1993 deo et al 2017a 2 3 soft computing methods in the present study the adaptive neuro fuzzy inference system anfis is used as a soft computing technique for forecasting spi3 spi6 spi9 and spi12 in this regard in addition to the classic anfis four other conjunctive anfis models embedded with meta heuristic optimization algorithms ga pso aco boa are also applied brief description of these methods is given below 2 3 1 adaptive neuro fuzzy inference system the adaptive neuro fuzzy inference system features the capabilities of both artificial neural networks and fuzzy inference system which is used for modeling non linear complex functions anfis is composed of a fuzzy inference system which was first introduced by jang 1993 in anfis model the fuzzy system is allowed to use the adaptive back propagation training algorithm in order for training the parameters fig 2 demonstrates a schematic view of the anfis structure as shown in fig 2 the anfis structure consists of five layers each node of the first layer determines the degree of membership of the input parameters the fuzzification layer at this layer different membership functions such as gaussian triangular trapezoid and bell functions can be used the second layer is known as the rule base layer which uses the multiplication operator output of the third layer is the normalized form of the previous layer the fourth layer is the defuzzification layer and the fifth layer includes the output nodes by means of the summation of the outputs of the forth layer for further information on anfis refer to zounemat kermani and teshnehlab 2008 2 3 2 genetic algorithm genetic algorithm ga is an inspirational search algorithm that has proved its great capability and robustness in optimizing complex problems based on the biological evolution mechanism this meta heuristic algorithm belongs to the class of evolutionary algorithms which generate and develop solutions to the wide range of complex problems using some inspired natural evolution techniques such as crossover and mutation from the parents to the offspring the general modelling procedure of the ga can be briefly addressed as 1 generation of random candidate solutions 2 evaluating the fitness of the candidates 3 creating the next generation considering the principle of proportionate and natural evolution approaches such as mutation and 4 continuing the re production process until reaching the desired result according to the convergence criteria detailed information about the application of ga in engineering problems can be found in numerous published studies kisi et al 2012 ravansalar et al 2016 naghibi et al 2017 2 3 3 particle swarm optimization algorithm the idea of pso particle swarm optimization algorithm was first proposed by kennedy and eberhart 1995 pso algorithm is an evolutionary algorithm based on repetitions which has been inspired by the social behavior of animals such as movement of the massive flocks of birds and fish the principles and basis of working with this algorithm is such that first a series of particles is assumed each particle has a velocity vector and position vector which tend to move toward optimal points in accordance with their velocities any change in the position of each particle occurs on the basis of the experience of the particle itself as well as the experiences of the neighboring particles in fact each particle is well aware of its superiority or non superiority over its neighboring particles as well as the entire group and thus changes its position regarding these cases each particle has an xi position vector which includes the optimization parameters and its dimension is equivalent to the number of parameters value of the objective function is calculated for each particle then the best position is determined for the particle afterwards the new position of each particle is calculated via the following equations 8 v i k ω v i k 1 c 1 r 1 k x b x i k 1 c 2 r 2 k x g x i k 1 9 x i k x i k 1 v i k where ω is the inertia weight vi is velocity of the ith particle xb is the individual best position xg is the global best position r1 and r2 are random numbers and c1 and c2 are learning coefficients and k is iteration number marini and walczak 2015 2 3 4 ant colony algorithm the ant colony aco algorithm is an optimization algorithm inspired by the behavior of ants this algorithm was primarily proposed for solving the optimization problems in a discrete space but later it was developed for continuous space as well socha and dorigo 2008 in aco algorithm in a discrete space in each step an ant creates its route based on a probabilistic relation in which the route with more pheromone is more likely to be selected this probabilistic structure is founded on the basis of the discrete probability distribution however in acor algorithm this discrete probability distribution has been converted into a continuous probability density function in the acor algorithm an archive is used to store the set of solutions for a system with n decision variables k single gaussian functions are assumed for each decision variable in the given archive so that selecting each of them and generating a new solution will result in a status for each variable that is indeed equivalent to a kernel gaussian function the solutions existing in the archive are sorted and stored in accordance with their quality in a descending order liao et al 2014 the process of pheromone content updating in acor algorithm is accomplished by storing the superior solutions and eliminating the poor solutions in the archive of solutions 2 3 5 butterfly optimization algorithm the butterfly optimization algorithm boa is a newly nature inspired optimization algorithm arora and singh 2017 arora and singh 2018 for solving global optimization problems this algorithm mimics the procedure of food search and the mating of butterflies in the nature the foraging strategy of butterflies is the main framework of this optimization technique in other words the main idea of developing the boa is inspired by the cooperative movement of the butterflies toward the position of the food sources using their potential ability of tracking the smell of food source mate in the air readers are referred to the original published study by arora and singh 2018 for more detailed information about this algorithm 3 results and discussion in the present study four evolutionary anfis models anfis pso anfis ga anfis boa and anfis acor were applied for forecasting drought indexes spi 3 spi 6 spi 9 and spi 12 and results were compared with classic anfis to see the accuracy improvement of the new methods for this purpose the following measures were considered 10 r o o t m e a n s q u a r e e r r o r r m s e i 1 n y i o y i m 2 n 11 m e a n a b s o l u t e e r r o r m a e i 1 n y i o y i m n 12 i n d e x o f a g r e e m e n t i a 1 i 1 n y i m y i o 2 i 1 n y i m y o y i o y o 2 where y i m is the model s output y i o is the observed value y 0 is the mean of the observed value and n is number of data data were split into three parts training validation and test the number of data and optimal input structures of the applied models are reported in table 1 in this table spi3 1 refers the 1 lag spi value and vice versa the model inputs were identified by applying correlation analysis the most effective lags obtained from correlation analysis auto correlation and partial autocorrelation were considered as inputs to the neuro fuzzy models to forecast drought indexes of each station for sp3 forecasting the most effective lags of spi3 series were searched for spi6 forecasting the optimal lags of spi3 and spi6 series were investigated and vice versa table 2 provides the parameters used for development of each method in forecasting spi tables 3 and 4 sums up the training validation and test results of the applied neuro fuzzy methods in forecasting spi 3 of three stations it is obvious that the classic anfis model has higher accuracy in approximating drought index than the evolutionary anfis models whereas the latter performs superior to the first in validation and test stages in the validation stage the anfis acor has the lowest rmse and mae and the highest r2 and ia for the abbasabad and biarjmand stations while the anfis pso gives the best statistics in ebrahim abad station in the test stage however anfis ga has the best score with respect to various criteria for the biarjmand station the rmse mae accuracy of the classic anfis model in forecasting spi 3 was increased by 11 4 11 6 11 7 11 5 and 16 7 16 9 using acor ga and pso algorithms for the abbasabad biarjmand and ebrahim abad stations respectively training validation and test statistics of the different neuro fuzzy methods in forecasting spi 6 are given in tables 5 and 6 here also the performances of the models vary with respect to three stages training validation and testing the anfis ga anfis and anfis ga have the best approximation in training stage of the abbasabad biarjmand and ebrahim abad while the anfis ga anfis ga and anfis pso perform superior to the other models in validation stage for the same stations respectively classic anfis has slightly higher rmse than the anfis ga in abbasabad station in testing stage different trends are shown by the employed methods the best performance was reached using anfis pso anfis acor and anfis pso models in forecasting spi 6 with respect to rmse r2 mae and ia statistics at abbasabad biarjmand and ebrahim abad stations respectively the best hybrid neuro fuzzy models improved the rmse mae accuracy of the classic anfis model by 11 3 12 2 32 4 32 3 and 25 2 26 2 in abbasabad biarjmand and ebrahim abad respectively tables 7 and 8 reports the training validation and test measures of the different neuro fuzzy methods in forecasting spi 9 according to the training measures anfis pso anfis and anfis acor provide the best exactness in abbasabad and ebrahim abad in biarjmand the anfis pso has the lowest mae 0 294 and the highest r2 0 822 the rmse and r2 of the anfis pso however are slightly different from those of the anfis acor therefore it can be said that anfis pso has the best accuracy in validation stage of biarjmand sattion in the test stage different results are obtained compared to training and validation stages in abbasabad station the anfis boa is ranked as the first with the lowest rmse 0 398 and mae 0 301 and the highest r2 0 771 followed by the anfis acor anfis ga anfis and anfis pso respectively in biarjmand also the anfis boa provides the best accuracy with the lowest rmse 0 398 and mae 0 301 and the highest r2 0 877 and ia 0 964 followed by the anfis ga anfis acor anfis pso and anfis respectively in ebrahim abad station the anfis pso has the first rank with the lowest rmse 0 409 and mae 0 288 and the highest r2 0 669 followed by the anfis ga anfis acor anfis boa and anfis respectively the rmse mae accuracy of the classic anfis model in forecasting spi 9 was increased by 17 3 12 2 34 4 35 and 9 8 12 4 using boa boa and pso algorithms for the abbasabad biarjmand and ebrahim abad stations respectively the models accuracies are compared in tables 9 and 10 in forecasting spi 12 of three stations as clearly seen from table 9 the anfis has better approximation than the other models in biarjmand and ebrahim abad stations while for the abbasabad the anfis ga provides the lowest rmse and mae and the highest r2 and ia in training stage in the validation stage however the anfis ga anfis pso and anfis boa models have the highest performance for the abbasabad biarjmand and ebrahim abad respectively in the test stage different trends are observed from the results the anfis pso produces the lowest rmse 0 334 and mae 0 230 and the highest r2 0 831 and ia 0 954 while for the biarjmand and ebrahim abad the anfis ga and anfis pso performed the best in forecasting spi 12 respectively the best hybrid neuro fuzzy models increased the rmse mae accuracy of the classic anfis model by 30 6 32 9 46 7 53 6 and 30 6 40 6 in abbasabad biarjmand and ebrahim abad respectively the overall accuracies of the applied methods in forecasting spi 3 spi 6 spi 9 and spi 12 are compared in table 11 in the table 1 means the best accuracy and 5 means the worst one it is clear there is not a dominant model all drought indexes in abbasabad and biarjmand stations in ebrahim abad station the anfis pso has the first accuracy in forecasting all indexes for the abbasabad station the anfis acor anfis pso anfis boa and anfis pso has the best accuracy in forecasting spi 3 spi 6 spi 9 and spi 12 respectively while the anfis ga anfis acor anfis boa and anfis ga provide the best performance in forecasting corresponding indexes in biarjmand station from table 11 it is apparent that the new anfis models outperform the classic anfis model accuracy in drought forecasting the evolutionary anfis models are graphically compared in figs 3 and 4 in forecasting spi 12 of abbasabad station in the test stage it can be clearly seen from scatterplots that the trendline of the anfis pso is closer to the 1 1 line compare the slope coefficients of the trendline equations with a lower r2 0 831 than the anfis ga anfis boa and anfis acor figs 5 and 6 illustrates the spi 12 forecasts of the evolutionary anfis models for the biarjmand station in the test stage the r2 values of the anfis boa and anfis ga are equal to each other but the trendline of the latter model is closer to the 1 1 line compared to first one for the ebrahim abad stations the models are compared in figs 7 and 8 in forecasting spi 12 in the test stage it is observed from the scatterplots that the anfis pso less scattered estimates compared to other three models there is a slight difference between the anfis pso and anfis acor models this confirms the test measures provided in table 10 all the applied methods provided different results in validation and testing stages and this indicated the necessity of separation data in three parts in the literature data are generally separated in two parts training and validation and models are obtained with respect to validation accuracy e g keskin et al 2009 2011 deo and şahin 2015 and this may mislead the modeler in selecting the optimal models for the studied phenomenon dividing data into three parts and thus testing models with the third part which was not used in model development stage should be preferred for better evaluation of the models the other way to evaluate data driven models may be use of cross validation methods 4 conclusion in the current study the ability of four evolutionary neuro fuzzy methods anfis pso anfis ga anfis boa and anfis acor was evaluated in forecasting four standard precipitation indexes spi 3 spi 6 spi 9 and spi 12 and they compared with classical anfis monthly precipitation data from three stations abbasabad biarjmand and ebrahim abad in semnan province iran were utilized in the applications the following conclusions can be reached from the applications in all stations and for all spi indexes the evolutionary neuro fuzzy methods outperformed the classical one the improvement of classical anfis models with respect to rmse range from 11 4 16 7 11 3 32 4 9 8 34 4 30 6 46 7 for the spi 3 spi 6 spi 9 and spi 12 respectively it may be said that improvement increases by the increment in index time scale among the four new methods the anfis pso performed superior to the anfis ga anfis boa and anfis acor in forecasting spi 3 spi 6 spi 9 and spi 12 in ebrahim abad station for the biarjmand station anfis ga anfis acor anfis boa and anfis ga showed the best accuracy while the anfis acor anfis pso anfis boa and anfis pso has the best rank in the abbasabad station in forecasting spi 3 spi 6 spi 9 and spi 12 respectively the results obtained from the present study may be useful for hydrologists agriculturalists and water resources planners in making strategic decisions especially in the arid and semi arid regions like iran declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
6151,the multi metric assessment of model performance in a dominantly single domain modeling approach i e surface may not be sufficient to gauge the validity of the model to represent the hydrologic system consequently rating metrics can mathematically validate model results as satisfactory even when some of the simulated hydrologic processes are incorrectly represented during the calibration process in this paper we argue that to properly represent the hydrologic system calibration tasks focused on modifying model parameters should account for equifinality model inadequacy and constraint inadequacy to demonstrate our argument we conducted a traditional calibration using the soil and water assessment tool swat coupled to the modular finite difference flow model modflow to simulate the hydrologic processes in the fort cobb reservoir experimental watershed fcrew in central western oklahoma the results indicated that model calibration based on metrics from a single domain in this case using swat did not necessarily guarantee an appropriate representation of water circulation moreover unsupervised calibration techniques based on the objective function optimization e g inverse calibration using swat cup sufi2 algorithm may not be sufficient if model constraints in multiple domains are not properly set resulting in distorted parameters this practice can result in the misrepresentation of water circulation and can have adverse impacts on environmental model results used to support policies and decisions keywords multi domain calibration equifinality swat modflow swatmf 1 introduction hydrologic numerical models aim to represent water circulation in natural systems including complex processes e g erosion transport of pollutants and their interactions with other earth and anthropogenic systems natural systems are commonly represented by open or closed systemic abstractions in which continuum phenomena i e physical chemical and biological are lumped contextualized in time and space by discrete processes using conceptual physically based or data driven approaches beven and freer 2001 these abstractions are intended to represent water movement and feedback fluxes in a controlled volume defined by the extent of the model application and the dynamics associated with processes linked to vegetation transport of pollutants and water use to mention a few the information generated by hydrologic models are commonly used to reconstruct historical events or to assess the system response under present or future scenarios e g climate variability land use change contrasting soil management practices since hydrologic models play a vital role in regulatory planning research and decision making activities harmel et al 2014 the national judicial college 2010 they ought to be well structured stable and tested to be reliable from a strict scientific point of view moriasi et al 2007 2015 however the application of hydrologic models is limited to the achievable level of process representation within sub systems aka domains e g surface and its relationship with other domains e g atmosphere the overall uncertainty associated with their predictions depends largely on observations as well as the limitations in the mathematical abstractions representing the heterogeneous reality for instance the lack of scale theory dimensionality and constraints integration bahremand 2016 beven 1989 advances in data acquisition from the last 50 years have resulted in the collection of comprehensive datasets near the earth s surface and from space observations that provide an improved understanding of water circulation in the biosphere including the atmosphere surface and subsurface domains moreover integration of these datasets with information systems e g geographic social etc data analytics and cyberinfrastructure are advancing our capability to de convolute the uncertainties associated with the applications of hydrologic models this is expected to improve our assessments of water circulation on a historical basis at different scales that can be used to better asses scenario based outcomes however because the approaches that we use in optimizing the parameters of these models are deeply rooted in tradition any improvements in measurements hydrologic knowledge and data analytics do not guarantee the robustness of the models that we produce for example a major part of the modeling endeavor is devoted to model parameterization based on the evaluation of model performance from sparse metrics derived from observed and simulated data however in most cases the abstraction and constraints of the system are naively assumed to be sufficient as they are commonly dictated by the model structural adequacy without a clear view of the information embedded in the model gupta and nearing 2014 to simplify the burden of calibrating a model numerous authors bennet et al 2013 biondi et al 2012 daggupati et al 2015 legates and mccabe 1999 moriasi et al 2007 2015 ritter and muñoz carpena 2013 encouraged assessment of the model performance through the use of a set of metrics based on recommended statistical and graphical evaluation techniques in particular moriasi et al 2007 upon reviewing previous studies focused on modeling endeavors proposed a general performance rating based on commonly used statistical performance metrics they suggested that a watershed model simulation based on streamflow observations can be considered as satisfactory if nse nash sutcliffe efficiency coefficient 0 50 rsr ratio of rmse to the standard deviation of observed values 0 70 and pbias percent bias 25 not without criticism ritter and muñoz carpena 2013 suggested that nse should be greater than 0 65 to be considered satisfactory based on the criteria that at that point the ratio of the standard deviation and mean error of the observations became greater than 0 7 however gupta et al 2009 argued that in order to maximize nse the variability has to be underestimated which turns out to be an important feature of watersheds as a function of scale and geographical location moriasi et al 2007 was in fact not the first attempt to provide guidelines for metric calibration but in a unique way this publication led to the idea of establishing metrics thresholds legates and mccabe 1999 compared three metrics r2 nse and the index of agreement and concluded that although nse represents an improvement over correlation based metrics which are considered inappropriate for model evaluation nse remained overly sensitive to extreme values to overcome this issue they proposed a modified coefficient of efficiency that replaced square differences by absolute values they also proposed some guidelines for reporting model performance and recommended the use of bootstrapping techniques when statistically significant differences among models are important in a different approach yilmaz et al 2008 assessed model evaluation through hydrological context using multiple signature measures derived from data targeted to identify watershed model inadequacies they concluded that although this methodology resulted in an improved water balance and hydrograph timing estimates other hydrological responses e g vertical soil moisture were less successful most likely due to model structural uncertainty although moriasi et al 2007 emphasized that in addition to performance metrics ideal model calibration should include checking water balance sediment and nutrient components to ensure that major processes are represented relatively well still some modelers use these metrics alone to assess the reliability of models in representing the hydrologic system moreover in many cases these metrics do not directly measure the performance of the model in representing the interactions among domains e g atmosphere surface subsurface nor the critical hydrologic responses from a contrasting shift in the climate regime i e wet to dry and vice versa metrics summarize convoluted physical processes in a single number that does not translate back to any physicality of the system ritter and muñoz carpena 2013 jain and sudheer 2008 legates and mccabe 1999 suffice it to say there still exists some disconnect between the way we set up and parameterize hydrologic models and their ability to represent the hydrologic system bahremand 2016 a valid question however is whether a single or a set of metrics in a single domain system is sufficient to gauge the ability of the model to replicate the behavior of a multi faceted natural system in this paper we will argue that to properly represent the hydrologic system calibration tasks focused on modifying model parameters should account for equifinality model inadequacy and constraint inadequacy to demonstrate our argument we used the soil and water assessment tool swat model arnold et al 1998 coupled with the modular finite difference flow model modflow mcdonald and harbaugh 1988 also known as swatmf guzman et al 2015 to simulate the hydrologic processes in the fort cobb reservoir experimental watershed fcrew in central western oklahoma the selection of swat was prompted by its popularity among practitioners in evaluating the impacts of climate and land management practices on water resources and contaminant transport at the watershed scale douglas mankin et al 2010 gassman et al 2007 swat s minimal user input data requirement low computational cost and ease of use that does not require a thorough understanding of the hydrologic system make it an easy model to set up and parameterize in fact these characteristics in a model combined with model performance guidelines moriasi et al 2007 make it easy for practitioners to set up and calibrate a hydrologic model with the assumption of adequacy when representing the hydrologic system under investigation 2 materials and methods 2 1 study area the fcrew is located at the fringe of a humid subtropical and semi arid region of the central great plains ecoregion in central western oklahoma usa fig 1 a its drainage area is approximately 800 km2 predominantly of cultivated crops 60 and grassland herbaceous 29 nlcd 2011 homer et al 2015 the topography within the watershed is irregular hilly in the north with a mean slope of 3 and elevations that range from 384 to 564 m above mean sea level the soils are mostly fine sandy loams eastern and northern southern central side and silt loams western side composed of 2 5 horizons that can extend to a maximum depth of 2 24 m steiner et al 2008 soil survey staff 2016 the fort cobb reservoir which was constructed in 1959 by the bureau of reclamation serves as a public and private water supply for domestic and industrial use and as a recreational lake oklahoma conservation commission 2009 the fcrew rests on the rush springs aquifer rsa also known as the permian age rush springs formation in which approximately 78 of the withdrawn water is used for irrigation the rsa is mainly unconfined with recharge from infiltration becker and runkle 1998 ketchum 2013 the rsa formation is fine grained cross bedded sandstone with a thickness ranging from approximately 50 100 m in which irregular dolomite or gypsum lenses are present underlain the rsa is the marlow formation serving as an aquitard precipitation in the fcrew follows a bimodal distribution with an average annual depth of approximately 800 mm in which the occurrence of local events with high intense precipitation of short duration are common guzman et al 2015 the selection of the fcrew to assess the model representation of water circulation from model benchmarking was founded on the availability of a rich dataset at the atmospheric surface and sub surface domains starks et al 2014 furthermore a shift in climate comprised of 1 a long term wet period occurring approximately between 1980 and 2000 and 2 a long term dry period that started in 2000 and extended for at least 15 years guzman et al 2018 including an extreme drought event between 2010 and 2012 made fcrew a complex system to represent although data from the atmosphere and surface domains were sufficient to warrant model set up and evaluation for a longer period continuous groundwater records were not available until 2011 2 2 model setup the swatmf guzman et al 2015 developed by the usda ars grazinglands research laboratory integrates the swat and modflow models and was used to develop the fcrew surface water groundwater model swatmf couples the models using lookup tables that link a gridded map of swat hydrologic response units hrus to modflow s grid cells in which the spatial resolution of the hrus must be greater than or equal to the modflow grid thus this allows associating one or more percolating and extraction fluxes from swat to a single cell in modflow swat requires geospatial land use soil and topography data and daily time series of meteorological variables in swat the spatial heterogeneity is considered by initially discretizing the watersheds into sub basins using topography and then by further dividing sub basins into hrus which are unique combinations of soil type land cover and slope class neitsch et al 2011 curve number model the land use map and the digital elevation model dem at 30 m 1 arc second resolution were obtained from the national land cover database nlcd and the 3d elevation program 3dep while the soil properties were extracted from the usda soil survey geographic database ssurgo surface spatial discretization was constrained to 12 sub basins and flow aggregation in the stream network was limited to a maximum area of 27 km2 limiting the number of hrus to 1000 these constraints provided sufficient information to account for the variability across the watershed that does not significantly affect water yield and streamflow estimation her et al 2015 time series of daily precipitation solar radiation relative humidity and temperature were retrieved from fifteen micronet starks et al 2014 three mesonet mcpherson et al 2007 and one cocorahs stations fig 1 three usgs stream monitoring points located upstream of the fort cobb reservoir at cobb creek lake creek and willow creek usgs 2016 fig 1 were used for calibration to set up modflow two gridded layers of 280 by 280 m cell size were defined with the following boundaries 1 a top boundary that intersects swat s lower boundary 2 a boundary between the layers located at the middle of the aquifer thickness and 3 a lower boundary defined by the marlow formation aquitard restricting vertical flow fig 1b initial conditions were estimated based on available data and the following assumptions 1 initial heads were spatially interpolated from 5 piezometers at the initial day of the model simulation 2 an initial recharge map was synthetically generated with values smaller than the expected percolating fluxes 3 incoming lateral fluxes from adjacent watersheds were assumed to be defined as head dependent flux boundaries additional constraints were set for the cells where the stream network and rsa were in contact they were defined as head dependent flux boundaries forcing the output fluxes to remain equal to zero unless the head of one of these cells surpasses a certain threshold the hydraulic properties of the rsa i e hydraulic conductivities specific yield and specific storage needed to set up the modflow upw package were initially assumed from guzman et al 2015 and modified through calibration river conductance and reservoir bed hydraulic conductivity data were estimated based on the ssurgo soil database infiltration fluxes from the fort cobb reservoir to the rsa were accounted as a function of the reservoir flooded area estimated from the time series of the water pool elevation and the calibrated conductance of the sediment thickness recharges at the lower swat boundary and wells extraction volumes from the auto irrigation module were estimated at the surface domain at daily time steps and transferred to daily stress periods to modflow irrigation demands were estimated by defining an area of influence at each well and linking them to the water depths generated by the swat auto irrigation routine for all cultivated lands i e all hrus with land cover agrr likewise three usgs monitoring wells i e eakly core2 and alfalfa usgs 2016 and a total of 655 extraction wells primarily used for irrigation were identified within fcrew using the owrb groundwater wells database owrb 2018 fig 1a it is however important to note that one of the limitations of the swatmf integration framework is that feedbacks fluxes from modflow to swat were not considered 2 3 model calibration the calibration of swatmf followed the traditional approach of trial and error parameter adjustment using an automated optimization tool for the surface and manual adjustment of the groundwater parameters the trial and error approach allowed the optimization of parameters to better represent water circulation based on the spatial variability of the groundwater table and infiltration fluxes and also the intersection of groundwater table and the river network this approach was preferred especially for the groundwater domain as hydrogeological properties the occurrence of clay lenses in the geological formation horizontal transmissivities at the river network and percolating fluxes are mainly unknown in contrast due to the large availability of surface data the calibration of the swat model was automated using swat cup first swat was calibrated independently until acceptable model performance metrics were obtained the calibrated swat model was then coupled to the modflow model to manually adjust their parameters the model calibration for the surface domain was performed using metrics computed from the comparison of the observed and simulated daily streamflow at three gauging stations along a 9 year period 2009 2017 the first two years were used to set up the initial conditions of the surface domain the calibration of swat followed the typical calibration procedure being implemented by practitioners today that is using trial and error or automated optimization approaches the built in semi automated sufi 2 algorithm abbaspour et al 2004 abbaspour 2015 of the swat cup software was used to identify the best fitting surface model based on maximizing the nash sutcliffe efficiency coefficient nse and minimizing the percent bias pbias the most common calibration parameters were first identified from arnold et al 2012a and abbaspour 2007 expressing them within recommended ranges arnold et al 2012b neitsch et al 2011 the swat model was then run in a set of 2000 simulations based on a latin hypercube sampling followed by a global sensitivity analysis through a t test of a multiple regression system of the generated parameters against the values of the objective function abbaspour 2015 during the streamflow calibration eleven parameters 11 were observed to be the most sensitive table 1 which included groundwater parameters affecting baseflow return flow and aquifer s recharge the remaining swat parameters non optimized were left as the values set by default in arcswat during the model set up once the most sensitive parameters were identified the swat model was run in sets of hundreds of iterations until acceptable model performance metrics were obtained 2 3 1 swat modflow coupling and calibration for a given set of daily percolating and extracted fluxes hydraulic properties in the modflow model were initially assumed from geological studies becker and runkle 1998 penderson 1999 ketchum 2013 and then manually adjusted to maximize the nse metrics at three piezometers eakly core2 and alfalfa usgs 2016 fig 1 in the absence of hydrogeological measurements the vertical and horizontal hydraulic conductivities and the specific yield were observed to be the most sensitive variables in addition to the river conductance at some sections of the tributary channels the spatial distribution of the geologic features was used to constrain the adjusted values of these variables the specific storage on the other hand was fixed to the values reported by guzman et al 2015 since distinct tested values did not significantly affect the simulated groundwater levels likewise the input parameters for the newton solver were set constant during the entire calibration process following the suggested values for a moderate model complexity usgs 2017 the following considerations were evaluated during calibration 1 visual evaluation of daily simulated maps of groundwater heads 2 stability of the modflow solver and 3 stability of head depletion at stream cells and reservoir representation if during this process the model showed an excessive zonal aquifer recharges that resulted in inadequate simulation of groundwater heads e g heads excessively surpassing the modflow upper boundary the swat parameter controlling deep aquifer percolation fluxes rchrg dp were adjusted where necessary at the subbasin or hru level and swat s performance metrics were evaluated anew also special attention was given to the solver s instability resulting from low conductance in cells in contact with the river network these steps were repeated until the surface subsurface interface presented a stable and consistent behavior in the two domains best matching the measured stream discharge and groundwater heads at monitoring points 3 results and discussion 3 1 swatmf calibration the calibration of the model was initially developed based on goodness of fit metrics using the nse and pbias the swat model with the best nse estimated at three streamflow stations was coupled with modflow to assess the groundwater flow the nse from the calibrated swat model ranged from 0 52 to 0 61 and 0 61 to 0 91 on daily and monthly time steps respectively while the pbias was from 4 to 14 these metrics fell within the satisfactory category based on moriasi et al 2007 the groundwater parameters in modflow e g hydraulic conductivities specific yield and specific storage were then adjusted to improve the fit between the observed and simulated groundwater levels at eakly core2 and alfalfa monitoring wells however it was not possible to attain a groundwater nse higher than 0 5 even though the relative error pbias was below 5 in addition visual assessment of the groundwater heads on daily maps fig 2 a and c indicated the occurrence of excessive zonal recharges despite streamflow metrics being in the acceptable ranges these large local recharge or extraction fluxes triggered local numerical instabilities in the modflow solver as a result heads from stable modflow simulations resulted in unrealistic water columns e g 700 m of water column over the surface fig 2d in the central and western parts of the watershed fig 2a while other cells tend to become too dry due to excessive extraction the results from swatmf therefore suggested that a validated swat surface model although performed satisfactorily in simulating streamflow did not guarantee an appropriate representation of gw recharge and neither gw levels to improve the performance metrics in modflow it was necessary to calibrate swat anew focusing on percolating fluxes and groundwater parameters at the sub basin scale e g lake and cobb creek while maintaining acceptable metrics at the surface domain the updated swat model resulted in nse ranging from 0 54 to 0 64 and pbias of 7 8 to 26 9 at daily time steps nse and pbias metrics in modflow were found to be greater than 0 65 and close to zero respectively with a more realistic representation of groundwater levels fig 3 moreover this model better represented the effects of the shift in the hydrologic regime 2015 in fig 3b that occurred at the surface domain between 2013 and 2014 when the precipitation shifted from a long term dry period to a wet condition guzman et al 2018 the calibration exercise described above elicited some important concerns when calibrating a model representing an open system for instance how can modelers assess the cross domain fluxes e g percolation and extraction evapotranspiration for which there are no available observations should modelers feel confident based on metrics that showed the model is well calibrated these questions cannot be answered without taking into account equifinality model inadequacy and constrains inadequacy 3 2 equifinality hydrologic models that operate on open system descriptions are prone to equifinality that is the occurrence of multiple sets of parameters i e solutions that satisfy the description of the system in which the validity of the model is commonly assessed through model performance given some objective functions aka performance metrics or goodness of fit equifinality found its roots in inadequate constraints that when combined with overparameterized models result in an underdetermined system where the number of unknown parameters largely surpasses the number of realizations of the system observations this implies that by well or naively defined model constraints e g boundary conditions model inputs spatial discretization contrasting sets of model parameter combinations may have similar outcomes at observation points e g streamflow but may yield different spatial systemic responses the problem now is that model practitioners can inadvertently choose the suggested performance ratings to conclude that the model satisfactorily represents water circulation this situation become more troublesome as model performance is assessed on metrics derived at a single domain e g surface even though the evaluation can occur at multiple points due to the fact that water fluxes moving through the upper and lower boundary conditions of an open systemic representation can be tweaked to satisfy the model practitioners perception of validity to illustrate this after 103 iterations swatmf reached a reasonable representation of the water circulation at the surface and subsurface domains fig 4 we examined 12 iterations that showed acceptable metrics nse and pbias in the surface domain we then mapped the parameter controlling the percolating fluxes from swat to modflow i e rchrg dp across the watershed fig 4a to show the pattern in which water is transferred to the subsurface domain i e modflow in these 12 cases metrics from swat fig 4a indicated that streamflow was reasonably estimated at the three gauging stations however the rchrg dp in these 12 iterations showed varying patterns indicating varying percolation behavior with some iterations manifesting more variability within subbasins fig 4a this suggested that although the streamflow response of these 12 cases may be similar the hydrologic responses of the system were different in each case fig 4a is an illustration of a single domain calibration subjected to the effects of equifinality similarly at the groundwater domain the varying average values of hydraulic properties fig 4b indicated that a well fitted single domain calibration might not always result in a proper representation of the groundwater flow and consequently the water circulation in short term simulations e g less or equal to the calibration period derived model parameters from a model calibration targeting to represent a fast responding dominant hydrologic process e g streamflow may not be problematic however results from the case study illustrated that simulations of water movement in a 2 year period were critical this assessment was reached by roughly estimating the necessary time that excess percolating fluxes became evident at monitoring wells as the shift in groundwater heads that occurred in the year 2015 fig 3b an explanation for this excess in percolating fluxes was then associated to the change in the precipitation regime from a long term dry to a wet condition that occurred between 2013 and 2014 in this watershed guzman et al 2018 3 3 model inadequacy understanding the way models represent reality through mathematical physical or logical abstractions is key in a realistic representation of the hydrologic system in swat hydrologic processes are commonly represented conceptually at compartmentalized layers using the water balance equation the domain of the swat model is not exclusively restricted to the surface as it includes simulation of processes across the soil profile a shallow aquifer lateral flow and a loosely integrated deep aquifer water transfer at the hru is accounted for between layers and then in the sub basins controlled by parameters requiring calibration this approach provides a fast solution allowing the representation of simplified heterogenic conditions in lieu of the representative volume solved by a differential equation such as the flow in modflow all points in space and time must be differentiable however in order to set a proper representation of water movement in swat practitioners need a high level of hydrologic expertise deep knowledge of the code and computational tools because in most cases swat parameters do not have physical meaning nor are they measurable but are constrained to recommended ranges the most problematic issue with swat is that the spatial discretization and parameterization represent a distributed model when in reality what is distributed is the process of lumping the variables that define the curve number model when using arcswat as an example fig 5 illustrates this issue when the swat model is used to estimate the irrigation needs necessary to propagate the volume of water extracted to modflow a single hru navy blue area in fig 5 that results from a unique combination of soil land cover and slope may occur in several patches across the sub basin green area in fig 5 because of this spatial discretization irrigation needs for a certain irrigated area red square in fig 5 may be estimated from areas that are not relevant to the well extraction navy blue area moreover infiltrated water from irrigation may result in percolation fluxes at non corresponding modflow cells to minimize the effects of this spatial discretization model inadequacy changes in the swat auto irrigation module and swatmf were necessary to match the irrigation application to the well extraction area of influence the swat model is hybrid in the sense that it integrates physically based and conceptual approaches in representing the hydrologic processes while modflow is fundamentally a modular integration of a physically based conceptualization solution of the groundwater flow equation in addition their spatial representations are dissimilar with modflow being based on the definition of layered three dimensional grids while swat lumps hydrologic response units hrus intended to represent specific processes at the sub basin scale in swat streamflow at monitoring points is estimated from the convoluted responses of thousands of hrus in which baseflow a fundamental component of runoff is loosely accounted for similarly the calibration of the hydraulic properties of the aquifer in the modflow model relies on the spatial percolation and extraction fluxes subrogated by the surface model in which each potential satisfactory surface calibration may result in several satisfactory sub surface calibrations this situation can be exacerbated as streamflow responses follow different temporal scales baffaut et al 2015 compared with other domains e g subsurface in which even if they were modelled the temporal scale of some processes may fall outside of the chosen or available calibration period 3 4 constraint inadequacy constraints are initially invoked when setting up the model by defining its extent the granularity at which processes are simulated and data is used and the conditions of fluxes between domains fig 6 in this regard the swat and modflow models are problematic due to the fact that the planar extent of the domains surface and subsurface watershed are not necessarily identical and the conceptualization of the hydrologic processes and their abstractions are dissimilar in the two models both models represent open systems in which critical contributions and feedback fluxes are unaccounted for for instance in swat baseflow fluxes from a deep aquifer are unaccounted while percolation is a loss in the system moreover estimated irrigation fluxes in which the source of water originated from the deep aquifer are loosely represented since swat cannot model groundwater flow fig 6a in modflow on the other hand baseflow is also a loss in the system fig 6b therefore in a single surface domain representation there are two open boundaries i e atmosphere and subsurface while in a subsurface domain there are three at the surface subsurface interface an aquifer lateral boundary and a bottom boundary however it is common that groundwater modelers are able to decrease these problematic boundaries to a single boundary by identifying limited flow e g aquitards and gradient flow conditions for the lower and lateral boundaries respectively furthermore there are cases in which the groundwater domain may need to be extended over several surface domains in order to estimate lateral flow contributions model calibration is the process of constraining the model parameters targeted to represent the response of the conceptualized hydrologic processes that are linked to a given model definition fig 6 in this process practitioners target to constraint the values of fluxes by spatially adjusting the model parameters as a function of commonly derived metrics using convoluted observations in a single domain e g streamflow groundwater levels however these convoluted observations are the result of inter domain interactions red arrows in fig 6 and thus metrics may not account for constraints inadequacies for instance streamflow is linked to baseflow contributions that may originate from the groundwater domain similarly groundwater levels are linked to percolation and extraction fluxes that originate at the surface domain therefore the integration of more than a single domain in the calibration process allows practitioners to exert distributed inter domain constraints in order to favor the representation of water circulation rather than the convoluted processes 3 5 what does calibration do the occurrence of contrasting swat model parameters that resulted in streamflow calibration metrics over thresholds and the different combinations of groundwater parameters that did not significant change the metrics at the surface domain fig 4 suggested the presence of equifinality for instance the nse and the pbias did not vary significantly in the surface domain but the swat parameter controlling the fraction of percolating fluxes to the deep aquifer rchrg dp showed significant variation across the watershed fig 4a this was explained by the absence of feedback fluxes i e baseflow from the groundwater to the surface domain the sensitivity of the nse to extreme values legates and mccabe 1999 and the differences in temporal scales of streamflow and groundwater heads these results indicated that model calibration based on metrics from a single domain in this case swat did not necessarily guarantee an appropriate representation of water circulation moreover unsupervised calibration techniques based on the objective function optimization e g inverse calibration using swat cup sufi2 algorithm may not be sufficient if model constraints in multiple domains are not properly set resulting in distorted parameters calibration of streamflow does not account for the individual physical processes in the hydrologic system for instance calibration techniques do not account for the differences in velocity of water propagation across the domains and within the domain but rather rather they assess the estimated convoluted fluxes the behavior of the groundwater domain depends on the distributed fluxes entering and leaving e g percolation and inflow the domain e g wells extraction and outflow where manual or automated calibration force a combination of parameters e g hydraulic conductivities and specific yields to change to reach solution convergence similarly at the surface domain calibration adjust diverse set of parameters with contrasting temporal responses e g stream and surface routing soil moisture redistribution interflow etc at the subsurface domain water movement is controlled by matric potential that varies by orders of magnitude as water content in the soil varies due to changes in processes such as evapotranspiration and feedback fluxes across the capillary fringe to mention a few therefore the calibration process seeks to find a combination of parameters that satisfy the objective function through metrics rather than the evaluation of the processes and water circulation the ease with which the surface processes were calibrated in swat obtaining numerous solution that satisfy the model performance requirements illustrated equifinality aggravated by the model s inadequate constraints despite the use of optimization techniques in calibrating swat and using multiple streamflow stations to assess model performance the representativeness of the whole systemic response was not attained until outputs from another domain were used in the calibration process it is therefore misleading to assume that a given model is deemed sufficient to represent the hydrologic response of a system when its performance is tested using objective functions from one domain to claim that a hydrologic model is valid it must properly represent the behavior of the different domains of the system being investigated and within these domains the dominant processes and also the interactions among the domains i e fluxes and feedback fluxes 4 conclusion we presented a case study that elucidated the effects of traditional calibration focusing on performance metrics without considering the occurrence of equifinality inadequacy of model constraints and the limitations of the model itself in representing the hydrologic system calibration endeavors focused on adjusting the model parameters to satisfy some performance metrics are more likely to misrepresent the hydrologic system if proper boundary constraints are not implemented to reduce the occurrence of equifinality moreover understanding the model structure that is how the model represent reality is crucial in interpreting the outcomes of the model it is common that once the modeler attains a goodness of fit metric that is deemed satisfactory the modeling process is completed and the model is considered satisfactory in representing the hydrologic system our study has shown that this practice can result in the misrepresentation of water circulation and can have adverse impacts on environmental model simulation results and outputs used to support policy and decision making we therefore strongly encourage model practitioners to include evaluating equifinality providing sufficient constraints and understanding model structure in their modeling repertoire to produce models that are sound representation of the hydrologic system furthermore future research is necessary to evaluate the degrees of freedom in single e g swat modflow and coupled domain e g swatmf hydrologic systems to determine the additional information or changes in the model conceptualization that might be required to constrain such systems declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the u s department of agriculture national institute for food and agriculture nifa 2018 68002 27918 the authors would like to thank dr hoshin gupta for his valuable contributions to this manuscript 
6151,the multi metric assessment of model performance in a dominantly single domain modeling approach i e surface may not be sufficient to gauge the validity of the model to represent the hydrologic system consequently rating metrics can mathematically validate model results as satisfactory even when some of the simulated hydrologic processes are incorrectly represented during the calibration process in this paper we argue that to properly represent the hydrologic system calibration tasks focused on modifying model parameters should account for equifinality model inadequacy and constraint inadequacy to demonstrate our argument we conducted a traditional calibration using the soil and water assessment tool swat coupled to the modular finite difference flow model modflow to simulate the hydrologic processes in the fort cobb reservoir experimental watershed fcrew in central western oklahoma the results indicated that model calibration based on metrics from a single domain in this case using swat did not necessarily guarantee an appropriate representation of water circulation moreover unsupervised calibration techniques based on the objective function optimization e g inverse calibration using swat cup sufi2 algorithm may not be sufficient if model constraints in multiple domains are not properly set resulting in distorted parameters this practice can result in the misrepresentation of water circulation and can have adverse impacts on environmental model results used to support policies and decisions keywords multi domain calibration equifinality swat modflow swatmf 1 introduction hydrologic numerical models aim to represent water circulation in natural systems including complex processes e g erosion transport of pollutants and their interactions with other earth and anthropogenic systems natural systems are commonly represented by open or closed systemic abstractions in which continuum phenomena i e physical chemical and biological are lumped contextualized in time and space by discrete processes using conceptual physically based or data driven approaches beven and freer 2001 these abstractions are intended to represent water movement and feedback fluxes in a controlled volume defined by the extent of the model application and the dynamics associated with processes linked to vegetation transport of pollutants and water use to mention a few the information generated by hydrologic models are commonly used to reconstruct historical events or to assess the system response under present or future scenarios e g climate variability land use change contrasting soil management practices since hydrologic models play a vital role in regulatory planning research and decision making activities harmel et al 2014 the national judicial college 2010 they ought to be well structured stable and tested to be reliable from a strict scientific point of view moriasi et al 2007 2015 however the application of hydrologic models is limited to the achievable level of process representation within sub systems aka domains e g surface and its relationship with other domains e g atmosphere the overall uncertainty associated with their predictions depends largely on observations as well as the limitations in the mathematical abstractions representing the heterogeneous reality for instance the lack of scale theory dimensionality and constraints integration bahremand 2016 beven 1989 advances in data acquisition from the last 50 years have resulted in the collection of comprehensive datasets near the earth s surface and from space observations that provide an improved understanding of water circulation in the biosphere including the atmosphere surface and subsurface domains moreover integration of these datasets with information systems e g geographic social etc data analytics and cyberinfrastructure are advancing our capability to de convolute the uncertainties associated with the applications of hydrologic models this is expected to improve our assessments of water circulation on a historical basis at different scales that can be used to better asses scenario based outcomes however because the approaches that we use in optimizing the parameters of these models are deeply rooted in tradition any improvements in measurements hydrologic knowledge and data analytics do not guarantee the robustness of the models that we produce for example a major part of the modeling endeavor is devoted to model parameterization based on the evaluation of model performance from sparse metrics derived from observed and simulated data however in most cases the abstraction and constraints of the system are naively assumed to be sufficient as they are commonly dictated by the model structural adequacy without a clear view of the information embedded in the model gupta and nearing 2014 to simplify the burden of calibrating a model numerous authors bennet et al 2013 biondi et al 2012 daggupati et al 2015 legates and mccabe 1999 moriasi et al 2007 2015 ritter and muñoz carpena 2013 encouraged assessment of the model performance through the use of a set of metrics based on recommended statistical and graphical evaluation techniques in particular moriasi et al 2007 upon reviewing previous studies focused on modeling endeavors proposed a general performance rating based on commonly used statistical performance metrics they suggested that a watershed model simulation based on streamflow observations can be considered as satisfactory if nse nash sutcliffe efficiency coefficient 0 50 rsr ratio of rmse to the standard deviation of observed values 0 70 and pbias percent bias 25 not without criticism ritter and muñoz carpena 2013 suggested that nse should be greater than 0 65 to be considered satisfactory based on the criteria that at that point the ratio of the standard deviation and mean error of the observations became greater than 0 7 however gupta et al 2009 argued that in order to maximize nse the variability has to be underestimated which turns out to be an important feature of watersheds as a function of scale and geographical location moriasi et al 2007 was in fact not the first attempt to provide guidelines for metric calibration but in a unique way this publication led to the idea of establishing metrics thresholds legates and mccabe 1999 compared three metrics r2 nse and the index of agreement and concluded that although nse represents an improvement over correlation based metrics which are considered inappropriate for model evaluation nse remained overly sensitive to extreme values to overcome this issue they proposed a modified coefficient of efficiency that replaced square differences by absolute values they also proposed some guidelines for reporting model performance and recommended the use of bootstrapping techniques when statistically significant differences among models are important in a different approach yilmaz et al 2008 assessed model evaluation through hydrological context using multiple signature measures derived from data targeted to identify watershed model inadequacies they concluded that although this methodology resulted in an improved water balance and hydrograph timing estimates other hydrological responses e g vertical soil moisture were less successful most likely due to model structural uncertainty although moriasi et al 2007 emphasized that in addition to performance metrics ideal model calibration should include checking water balance sediment and nutrient components to ensure that major processes are represented relatively well still some modelers use these metrics alone to assess the reliability of models in representing the hydrologic system moreover in many cases these metrics do not directly measure the performance of the model in representing the interactions among domains e g atmosphere surface subsurface nor the critical hydrologic responses from a contrasting shift in the climate regime i e wet to dry and vice versa metrics summarize convoluted physical processes in a single number that does not translate back to any physicality of the system ritter and muñoz carpena 2013 jain and sudheer 2008 legates and mccabe 1999 suffice it to say there still exists some disconnect between the way we set up and parameterize hydrologic models and their ability to represent the hydrologic system bahremand 2016 a valid question however is whether a single or a set of metrics in a single domain system is sufficient to gauge the ability of the model to replicate the behavior of a multi faceted natural system in this paper we will argue that to properly represent the hydrologic system calibration tasks focused on modifying model parameters should account for equifinality model inadequacy and constraint inadequacy to demonstrate our argument we used the soil and water assessment tool swat model arnold et al 1998 coupled with the modular finite difference flow model modflow mcdonald and harbaugh 1988 also known as swatmf guzman et al 2015 to simulate the hydrologic processes in the fort cobb reservoir experimental watershed fcrew in central western oklahoma the selection of swat was prompted by its popularity among practitioners in evaluating the impacts of climate and land management practices on water resources and contaminant transport at the watershed scale douglas mankin et al 2010 gassman et al 2007 swat s minimal user input data requirement low computational cost and ease of use that does not require a thorough understanding of the hydrologic system make it an easy model to set up and parameterize in fact these characteristics in a model combined with model performance guidelines moriasi et al 2007 make it easy for practitioners to set up and calibrate a hydrologic model with the assumption of adequacy when representing the hydrologic system under investigation 2 materials and methods 2 1 study area the fcrew is located at the fringe of a humid subtropical and semi arid region of the central great plains ecoregion in central western oklahoma usa fig 1 a its drainage area is approximately 800 km2 predominantly of cultivated crops 60 and grassland herbaceous 29 nlcd 2011 homer et al 2015 the topography within the watershed is irregular hilly in the north with a mean slope of 3 and elevations that range from 384 to 564 m above mean sea level the soils are mostly fine sandy loams eastern and northern southern central side and silt loams western side composed of 2 5 horizons that can extend to a maximum depth of 2 24 m steiner et al 2008 soil survey staff 2016 the fort cobb reservoir which was constructed in 1959 by the bureau of reclamation serves as a public and private water supply for domestic and industrial use and as a recreational lake oklahoma conservation commission 2009 the fcrew rests on the rush springs aquifer rsa also known as the permian age rush springs formation in which approximately 78 of the withdrawn water is used for irrigation the rsa is mainly unconfined with recharge from infiltration becker and runkle 1998 ketchum 2013 the rsa formation is fine grained cross bedded sandstone with a thickness ranging from approximately 50 100 m in which irregular dolomite or gypsum lenses are present underlain the rsa is the marlow formation serving as an aquitard precipitation in the fcrew follows a bimodal distribution with an average annual depth of approximately 800 mm in which the occurrence of local events with high intense precipitation of short duration are common guzman et al 2015 the selection of the fcrew to assess the model representation of water circulation from model benchmarking was founded on the availability of a rich dataset at the atmospheric surface and sub surface domains starks et al 2014 furthermore a shift in climate comprised of 1 a long term wet period occurring approximately between 1980 and 2000 and 2 a long term dry period that started in 2000 and extended for at least 15 years guzman et al 2018 including an extreme drought event between 2010 and 2012 made fcrew a complex system to represent although data from the atmosphere and surface domains were sufficient to warrant model set up and evaluation for a longer period continuous groundwater records were not available until 2011 2 2 model setup the swatmf guzman et al 2015 developed by the usda ars grazinglands research laboratory integrates the swat and modflow models and was used to develop the fcrew surface water groundwater model swatmf couples the models using lookup tables that link a gridded map of swat hydrologic response units hrus to modflow s grid cells in which the spatial resolution of the hrus must be greater than or equal to the modflow grid thus this allows associating one or more percolating and extraction fluxes from swat to a single cell in modflow swat requires geospatial land use soil and topography data and daily time series of meteorological variables in swat the spatial heterogeneity is considered by initially discretizing the watersheds into sub basins using topography and then by further dividing sub basins into hrus which are unique combinations of soil type land cover and slope class neitsch et al 2011 curve number model the land use map and the digital elevation model dem at 30 m 1 arc second resolution were obtained from the national land cover database nlcd and the 3d elevation program 3dep while the soil properties were extracted from the usda soil survey geographic database ssurgo surface spatial discretization was constrained to 12 sub basins and flow aggregation in the stream network was limited to a maximum area of 27 km2 limiting the number of hrus to 1000 these constraints provided sufficient information to account for the variability across the watershed that does not significantly affect water yield and streamflow estimation her et al 2015 time series of daily precipitation solar radiation relative humidity and temperature were retrieved from fifteen micronet starks et al 2014 three mesonet mcpherson et al 2007 and one cocorahs stations fig 1 three usgs stream monitoring points located upstream of the fort cobb reservoir at cobb creek lake creek and willow creek usgs 2016 fig 1 were used for calibration to set up modflow two gridded layers of 280 by 280 m cell size were defined with the following boundaries 1 a top boundary that intersects swat s lower boundary 2 a boundary between the layers located at the middle of the aquifer thickness and 3 a lower boundary defined by the marlow formation aquitard restricting vertical flow fig 1b initial conditions were estimated based on available data and the following assumptions 1 initial heads were spatially interpolated from 5 piezometers at the initial day of the model simulation 2 an initial recharge map was synthetically generated with values smaller than the expected percolating fluxes 3 incoming lateral fluxes from adjacent watersheds were assumed to be defined as head dependent flux boundaries additional constraints were set for the cells where the stream network and rsa were in contact they were defined as head dependent flux boundaries forcing the output fluxes to remain equal to zero unless the head of one of these cells surpasses a certain threshold the hydraulic properties of the rsa i e hydraulic conductivities specific yield and specific storage needed to set up the modflow upw package were initially assumed from guzman et al 2015 and modified through calibration river conductance and reservoir bed hydraulic conductivity data were estimated based on the ssurgo soil database infiltration fluxes from the fort cobb reservoir to the rsa were accounted as a function of the reservoir flooded area estimated from the time series of the water pool elevation and the calibrated conductance of the sediment thickness recharges at the lower swat boundary and wells extraction volumes from the auto irrigation module were estimated at the surface domain at daily time steps and transferred to daily stress periods to modflow irrigation demands were estimated by defining an area of influence at each well and linking them to the water depths generated by the swat auto irrigation routine for all cultivated lands i e all hrus with land cover agrr likewise three usgs monitoring wells i e eakly core2 and alfalfa usgs 2016 and a total of 655 extraction wells primarily used for irrigation were identified within fcrew using the owrb groundwater wells database owrb 2018 fig 1a it is however important to note that one of the limitations of the swatmf integration framework is that feedbacks fluxes from modflow to swat were not considered 2 3 model calibration the calibration of swatmf followed the traditional approach of trial and error parameter adjustment using an automated optimization tool for the surface and manual adjustment of the groundwater parameters the trial and error approach allowed the optimization of parameters to better represent water circulation based on the spatial variability of the groundwater table and infiltration fluxes and also the intersection of groundwater table and the river network this approach was preferred especially for the groundwater domain as hydrogeological properties the occurrence of clay lenses in the geological formation horizontal transmissivities at the river network and percolating fluxes are mainly unknown in contrast due to the large availability of surface data the calibration of the swat model was automated using swat cup first swat was calibrated independently until acceptable model performance metrics were obtained the calibrated swat model was then coupled to the modflow model to manually adjust their parameters the model calibration for the surface domain was performed using metrics computed from the comparison of the observed and simulated daily streamflow at three gauging stations along a 9 year period 2009 2017 the first two years were used to set up the initial conditions of the surface domain the calibration of swat followed the typical calibration procedure being implemented by practitioners today that is using trial and error or automated optimization approaches the built in semi automated sufi 2 algorithm abbaspour et al 2004 abbaspour 2015 of the swat cup software was used to identify the best fitting surface model based on maximizing the nash sutcliffe efficiency coefficient nse and minimizing the percent bias pbias the most common calibration parameters were first identified from arnold et al 2012a and abbaspour 2007 expressing them within recommended ranges arnold et al 2012b neitsch et al 2011 the swat model was then run in a set of 2000 simulations based on a latin hypercube sampling followed by a global sensitivity analysis through a t test of a multiple regression system of the generated parameters against the values of the objective function abbaspour 2015 during the streamflow calibration eleven parameters 11 were observed to be the most sensitive table 1 which included groundwater parameters affecting baseflow return flow and aquifer s recharge the remaining swat parameters non optimized were left as the values set by default in arcswat during the model set up once the most sensitive parameters were identified the swat model was run in sets of hundreds of iterations until acceptable model performance metrics were obtained 2 3 1 swat modflow coupling and calibration for a given set of daily percolating and extracted fluxes hydraulic properties in the modflow model were initially assumed from geological studies becker and runkle 1998 penderson 1999 ketchum 2013 and then manually adjusted to maximize the nse metrics at three piezometers eakly core2 and alfalfa usgs 2016 fig 1 in the absence of hydrogeological measurements the vertical and horizontal hydraulic conductivities and the specific yield were observed to be the most sensitive variables in addition to the river conductance at some sections of the tributary channels the spatial distribution of the geologic features was used to constrain the adjusted values of these variables the specific storage on the other hand was fixed to the values reported by guzman et al 2015 since distinct tested values did not significantly affect the simulated groundwater levels likewise the input parameters for the newton solver were set constant during the entire calibration process following the suggested values for a moderate model complexity usgs 2017 the following considerations were evaluated during calibration 1 visual evaluation of daily simulated maps of groundwater heads 2 stability of the modflow solver and 3 stability of head depletion at stream cells and reservoir representation if during this process the model showed an excessive zonal aquifer recharges that resulted in inadequate simulation of groundwater heads e g heads excessively surpassing the modflow upper boundary the swat parameter controlling deep aquifer percolation fluxes rchrg dp were adjusted where necessary at the subbasin or hru level and swat s performance metrics were evaluated anew also special attention was given to the solver s instability resulting from low conductance in cells in contact with the river network these steps were repeated until the surface subsurface interface presented a stable and consistent behavior in the two domains best matching the measured stream discharge and groundwater heads at monitoring points 3 results and discussion 3 1 swatmf calibration the calibration of the model was initially developed based on goodness of fit metrics using the nse and pbias the swat model with the best nse estimated at three streamflow stations was coupled with modflow to assess the groundwater flow the nse from the calibrated swat model ranged from 0 52 to 0 61 and 0 61 to 0 91 on daily and monthly time steps respectively while the pbias was from 4 to 14 these metrics fell within the satisfactory category based on moriasi et al 2007 the groundwater parameters in modflow e g hydraulic conductivities specific yield and specific storage were then adjusted to improve the fit between the observed and simulated groundwater levels at eakly core2 and alfalfa monitoring wells however it was not possible to attain a groundwater nse higher than 0 5 even though the relative error pbias was below 5 in addition visual assessment of the groundwater heads on daily maps fig 2 a and c indicated the occurrence of excessive zonal recharges despite streamflow metrics being in the acceptable ranges these large local recharge or extraction fluxes triggered local numerical instabilities in the modflow solver as a result heads from stable modflow simulations resulted in unrealistic water columns e g 700 m of water column over the surface fig 2d in the central and western parts of the watershed fig 2a while other cells tend to become too dry due to excessive extraction the results from swatmf therefore suggested that a validated swat surface model although performed satisfactorily in simulating streamflow did not guarantee an appropriate representation of gw recharge and neither gw levels to improve the performance metrics in modflow it was necessary to calibrate swat anew focusing on percolating fluxes and groundwater parameters at the sub basin scale e g lake and cobb creek while maintaining acceptable metrics at the surface domain the updated swat model resulted in nse ranging from 0 54 to 0 64 and pbias of 7 8 to 26 9 at daily time steps nse and pbias metrics in modflow were found to be greater than 0 65 and close to zero respectively with a more realistic representation of groundwater levels fig 3 moreover this model better represented the effects of the shift in the hydrologic regime 2015 in fig 3b that occurred at the surface domain between 2013 and 2014 when the precipitation shifted from a long term dry period to a wet condition guzman et al 2018 the calibration exercise described above elicited some important concerns when calibrating a model representing an open system for instance how can modelers assess the cross domain fluxes e g percolation and extraction evapotranspiration for which there are no available observations should modelers feel confident based on metrics that showed the model is well calibrated these questions cannot be answered without taking into account equifinality model inadequacy and constrains inadequacy 3 2 equifinality hydrologic models that operate on open system descriptions are prone to equifinality that is the occurrence of multiple sets of parameters i e solutions that satisfy the description of the system in which the validity of the model is commonly assessed through model performance given some objective functions aka performance metrics or goodness of fit equifinality found its roots in inadequate constraints that when combined with overparameterized models result in an underdetermined system where the number of unknown parameters largely surpasses the number of realizations of the system observations this implies that by well or naively defined model constraints e g boundary conditions model inputs spatial discretization contrasting sets of model parameter combinations may have similar outcomes at observation points e g streamflow but may yield different spatial systemic responses the problem now is that model practitioners can inadvertently choose the suggested performance ratings to conclude that the model satisfactorily represents water circulation this situation become more troublesome as model performance is assessed on metrics derived at a single domain e g surface even though the evaluation can occur at multiple points due to the fact that water fluxes moving through the upper and lower boundary conditions of an open systemic representation can be tweaked to satisfy the model practitioners perception of validity to illustrate this after 103 iterations swatmf reached a reasonable representation of the water circulation at the surface and subsurface domains fig 4 we examined 12 iterations that showed acceptable metrics nse and pbias in the surface domain we then mapped the parameter controlling the percolating fluxes from swat to modflow i e rchrg dp across the watershed fig 4a to show the pattern in which water is transferred to the subsurface domain i e modflow in these 12 cases metrics from swat fig 4a indicated that streamflow was reasonably estimated at the three gauging stations however the rchrg dp in these 12 iterations showed varying patterns indicating varying percolation behavior with some iterations manifesting more variability within subbasins fig 4a this suggested that although the streamflow response of these 12 cases may be similar the hydrologic responses of the system were different in each case fig 4a is an illustration of a single domain calibration subjected to the effects of equifinality similarly at the groundwater domain the varying average values of hydraulic properties fig 4b indicated that a well fitted single domain calibration might not always result in a proper representation of the groundwater flow and consequently the water circulation in short term simulations e g less or equal to the calibration period derived model parameters from a model calibration targeting to represent a fast responding dominant hydrologic process e g streamflow may not be problematic however results from the case study illustrated that simulations of water movement in a 2 year period were critical this assessment was reached by roughly estimating the necessary time that excess percolating fluxes became evident at monitoring wells as the shift in groundwater heads that occurred in the year 2015 fig 3b an explanation for this excess in percolating fluxes was then associated to the change in the precipitation regime from a long term dry to a wet condition that occurred between 2013 and 2014 in this watershed guzman et al 2018 3 3 model inadequacy understanding the way models represent reality through mathematical physical or logical abstractions is key in a realistic representation of the hydrologic system in swat hydrologic processes are commonly represented conceptually at compartmentalized layers using the water balance equation the domain of the swat model is not exclusively restricted to the surface as it includes simulation of processes across the soil profile a shallow aquifer lateral flow and a loosely integrated deep aquifer water transfer at the hru is accounted for between layers and then in the sub basins controlled by parameters requiring calibration this approach provides a fast solution allowing the representation of simplified heterogenic conditions in lieu of the representative volume solved by a differential equation such as the flow in modflow all points in space and time must be differentiable however in order to set a proper representation of water movement in swat practitioners need a high level of hydrologic expertise deep knowledge of the code and computational tools because in most cases swat parameters do not have physical meaning nor are they measurable but are constrained to recommended ranges the most problematic issue with swat is that the spatial discretization and parameterization represent a distributed model when in reality what is distributed is the process of lumping the variables that define the curve number model when using arcswat as an example fig 5 illustrates this issue when the swat model is used to estimate the irrigation needs necessary to propagate the volume of water extracted to modflow a single hru navy blue area in fig 5 that results from a unique combination of soil land cover and slope may occur in several patches across the sub basin green area in fig 5 because of this spatial discretization irrigation needs for a certain irrigated area red square in fig 5 may be estimated from areas that are not relevant to the well extraction navy blue area moreover infiltrated water from irrigation may result in percolation fluxes at non corresponding modflow cells to minimize the effects of this spatial discretization model inadequacy changes in the swat auto irrigation module and swatmf were necessary to match the irrigation application to the well extraction area of influence the swat model is hybrid in the sense that it integrates physically based and conceptual approaches in representing the hydrologic processes while modflow is fundamentally a modular integration of a physically based conceptualization solution of the groundwater flow equation in addition their spatial representations are dissimilar with modflow being based on the definition of layered three dimensional grids while swat lumps hydrologic response units hrus intended to represent specific processes at the sub basin scale in swat streamflow at monitoring points is estimated from the convoluted responses of thousands of hrus in which baseflow a fundamental component of runoff is loosely accounted for similarly the calibration of the hydraulic properties of the aquifer in the modflow model relies on the spatial percolation and extraction fluxes subrogated by the surface model in which each potential satisfactory surface calibration may result in several satisfactory sub surface calibrations this situation can be exacerbated as streamflow responses follow different temporal scales baffaut et al 2015 compared with other domains e g subsurface in which even if they were modelled the temporal scale of some processes may fall outside of the chosen or available calibration period 3 4 constraint inadequacy constraints are initially invoked when setting up the model by defining its extent the granularity at which processes are simulated and data is used and the conditions of fluxes between domains fig 6 in this regard the swat and modflow models are problematic due to the fact that the planar extent of the domains surface and subsurface watershed are not necessarily identical and the conceptualization of the hydrologic processes and their abstractions are dissimilar in the two models both models represent open systems in which critical contributions and feedback fluxes are unaccounted for for instance in swat baseflow fluxes from a deep aquifer are unaccounted while percolation is a loss in the system moreover estimated irrigation fluxes in which the source of water originated from the deep aquifer are loosely represented since swat cannot model groundwater flow fig 6a in modflow on the other hand baseflow is also a loss in the system fig 6b therefore in a single surface domain representation there are two open boundaries i e atmosphere and subsurface while in a subsurface domain there are three at the surface subsurface interface an aquifer lateral boundary and a bottom boundary however it is common that groundwater modelers are able to decrease these problematic boundaries to a single boundary by identifying limited flow e g aquitards and gradient flow conditions for the lower and lateral boundaries respectively furthermore there are cases in which the groundwater domain may need to be extended over several surface domains in order to estimate lateral flow contributions model calibration is the process of constraining the model parameters targeted to represent the response of the conceptualized hydrologic processes that are linked to a given model definition fig 6 in this process practitioners target to constraint the values of fluxes by spatially adjusting the model parameters as a function of commonly derived metrics using convoluted observations in a single domain e g streamflow groundwater levels however these convoluted observations are the result of inter domain interactions red arrows in fig 6 and thus metrics may not account for constraints inadequacies for instance streamflow is linked to baseflow contributions that may originate from the groundwater domain similarly groundwater levels are linked to percolation and extraction fluxes that originate at the surface domain therefore the integration of more than a single domain in the calibration process allows practitioners to exert distributed inter domain constraints in order to favor the representation of water circulation rather than the convoluted processes 3 5 what does calibration do the occurrence of contrasting swat model parameters that resulted in streamflow calibration metrics over thresholds and the different combinations of groundwater parameters that did not significant change the metrics at the surface domain fig 4 suggested the presence of equifinality for instance the nse and the pbias did not vary significantly in the surface domain but the swat parameter controlling the fraction of percolating fluxes to the deep aquifer rchrg dp showed significant variation across the watershed fig 4a this was explained by the absence of feedback fluxes i e baseflow from the groundwater to the surface domain the sensitivity of the nse to extreme values legates and mccabe 1999 and the differences in temporal scales of streamflow and groundwater heads these results indicated that model calibration based on metrics from a single domain in this case swat did not necessarily guarantee an appropriate representation of water circulation moreover unsupervised calibration techniques based on the objective function optimization e g inverse calibration using swat cup sufi2 algorithm may not be sufficient if model constraints in multiple domains are not properly set resulting in distorted parameters calibration of streamflow does not account for the individual physical processes in the hydrologic system for instance calibration techniques do not account for the differences in velocity of water propagation across the domains and within the domain but rather rather they assess the estimated convoluted fluxes the behavior of the groundwater domain depends on the distributed fluxes entering and leaving e g percolation and inflow the domain e g wells extraction and outflow where manual or automated calibration force a combination of parameters e g hydraulic conductivities and specific yields to change to reach solution convergence similarly at the surface domain calibration adjust diverse set of parameters with contrasting temporal responses e g stream and surface routing soil moisture redistribution interflow etc at the subsurface domain water movement is controlled by matric potential that varies by orders of magnitude as water content in the soil varies due to changes in processes such as evapotranspiration and feedback fluxes across the capillary fringe to mention a few therefore the calibration process seeks to find a combination of parameters that satisfy the objective function through metrics rather than the evaluation of the processes and water circulation the ease with which the surface processes were calibrated in swat obtaining numerous solution that satisfy the model performance requirements illustrated equifinality aggravated by the model s inadequate constraints despite the use of optimization techniques in calibrating swat and using multiple streamflow stations to assess model performance the representativeness of the whole systemic response was not attained until outputs from another domain were used in the calibration process it is therefore misleading to assume that a given model is deemed sufficient to represent the hydrologic response of a system when its performance is tested using objective functions from one domain to claim that a hydrologic model is valid it must properly represent the behavior of the different domains of the system being investigated and within these domains the dominant processes and also the interactions among the domains i e fluxes and feedback fluxes 4 conclusion we presented a case study that elucidated the effects of traditional calibration focusing on performance metrics without considering the occurrence of equifinality inadequacy of model constraints and the limitations of the model itself in representing the hydrologic system calibration endeavors focused on adjusting the model parameters to satisfy some performance metrics are more likely to misrepresent the hydrologic system if proper boundary constraints are not implemented to reduce the occurrence of equifinality moreover understanding the model structure that is how the model represent reality is crucial in interpreting the outcomes of the model it is common that once the modeler attains a goodness of fit metric that is deemed satisfactory the modeling process is completed and the model is considered satisfactory in representing the hydrologic system our study has shown that this practice can result in the misrepresentation of water circulation and can have adverse impacts on environmental model simulation results and outputs used to support policy and decision making we therefore strongly encourage model practitioners to include evaluating equifinality providing sufficient constraints and understanding model structure in their modeling repertoire to produce models that are sound representation of the hydrologic system furthermore future research is necessary to evaluate the degrees of freedom in single e g swat modflow and coupled domain e g swatmf hydrologic systems to determine the additional information or changes in the model conceptualization that might be required to constrain such systems declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the u s department of agriculture national institute for food and agriculture nifa 2018 68002 27918 the authors would like to thank dr hoshin gupta for his valuable contributions to this manuscript 
6152,groundwater level forecasting is a useful tool for a more efficient and sustainable groundwater resource management developing models that can accurately reproduce groundwater level response to meteorological conditions can lead to a better understanding of the groundwater resource availability here an autoregressive neural network nnarx approach is proposed and compared with autoregressive linear models with exogenous input arx in order to forecast groundwater level in an aquifer system where a linear groundwater level response to recharge by rainfall is observed a well known problem regarding neural networks consists in the high risk of overfitting here three nnarx model were trained using different methods to avoid overfitting early stopping bayesian regularization and a combination of both the results show that on the short term forecasting up to 15 days the performance of nnarx and arx are comparable but the arx model generalizes better while the nnarx trained with bayesian regularization outperforms the linear models and the other nnarx models on longer scenarios on the test set as linear models are less time demanding and do not require high computational power they can be considered as suitable tools for short term groundwater level forecasting in linear systems while when longer scenarios are needed neural networks can be considered more reliable and training them with bayesian regularization allows to minimize the risk of overfitting keywords bayesian regularization groundwater level forecasting linear model neural networks overfitting 1 introduction groundwater level forecasting is a useful tool for supporting the sustainable management of water resources particularly short term forecasting few days ahead can help the assessment of groundwater resources availability for fulfilling human water needs while long term forecasting can be useful in terms of running scenarios for a changing climate in the last decades the attention kept growing toward data driven techniques as tools to perform groundwater level forecasting as alternatives to physically based models a main advantage of data driven models with respect to physically based models is that they do not require information on the hydrogeological parameters of the aquifer adamowski and chan 2011 that also need to be accurately calibrated burrows and doherty 2015 2016 gianni et al 2019 stefania et al 2018 therefore data driven models can be more suitable when exhaustive data on subsurface properties are not available moreover data driven models have been proven to be preferable to physically based models for simulating and forecasting groundwater level variations since they can overcome data limitations parameter uncertainty and the challenging problems related to the applicability of physically based models banerjee et al 2009 juan et al 2015 maskey et al 2000 nikolos et al 2008 yoon et al 2011 zhang et al 2018 the successful application of data driven models for forecasting groundwater level variations is shown by many previous works that demonstrated their applicability in a variety of hydrological settings and hydrogeological contexts wunsch et al 2018 such as hard rock systems banerjee et al 2009 river islands mohanty et al 2010 costal aquifers taormina et al 2012 yoon et al 2011 and arid zones yang et al 2009 data driven models have however some limitations with respect to physically based models a main disadvantage of data driven model is that they require long time series of hydrological and meteorological data to be trained other limitations are related to the quantification of the uncertainty and the management of overfitting discussed in detail below among data driven models two widely used techniques for groundwater level forecasting are a neural networks and b linear models neural networks consist in black box models which can provide relatively accurate predictions of groundwater levels coppola et al 2013 huang et al 2013 izady et al 2013 khalil et al 2015 nayak et al 2006 shirmohammadi et al 2013 tsanis et al 2008 uddameri 2007 advantages of neural networks are that they can better handle dynamic behaviors and non linearity adamowski and chan 2011 daliakopoulos et al 2005 a well known problem regarding the development of neural networks consists in avoiding overfitting which means improving the network generalization overfitting is defined as the problem that occurs when a network has been trained too hard to fit the training data resulting in a network which learned to reproduce noise and peculiarities in the training data rather than to find a general predictive rule dietterich 1995 if overfitting occurs the accuracy of the developed models may deteriorate significantly outside the range of the recharge and hydrogeological conditions that prevailed during the training period khalil et al 2015 generalization is the opposite of overfitting a network generalizes well when the accuracy of the network output is acceptable also when working with data that are not included in the training set rosin and fierens 1995 to have a measure of the overfitting problem and to compare different models the performance of the model is usually measured on data which were not part of the training set kang et al 2018 srivastava et al 2014 wan et al 2013 zaremba et al 2014 currently avoiding overfitting and improving the generalization of neural networks is a crucial challenge in the development of groundwater level forecasting models since an increase of hydroclimatic extremes can be expected in mid latitude regions such as the mediterranean hartmann et al 2014 the occurrence of hydroclimatic extremes leads to hydroclimatic conditions which exceed the range of the past data that were used to develop forecasting models therefore to test the reliability of data driven models for extrapolative prediction it becomes important to test the model on observational data or time period representing more extreme conditions than those in the training set bennett et al 2013 harmel et al 2014 moreover other disadvantages of neural networks are that they require several parameters to be chosen and tested carefully in order to produce good results and testing a wide variety of different parameters could become computationally expensive examples embrace network type size and architecture neuron activation functions learning algorithms stop criterion loss functions etc furthermore neural networks are often trained starting from random weights and biases this means that there is no guarantee of converging to the global minima of the error function leading to a higher uncertainty and instability of the models sudheer and kasiviswanathan 2017 linear models as well have been widely used to model groundwater level variations in several hydrological contexts ahn and salas 1997 ginocchi et al 2016 lee et al 2009 valipour et al 2013 advantages of linear models are that their training demands less time and computational effort however the main disadvantage is that they can struggle handling non linearity another limitation of linear models is that they can be properly applied only under the following assumptions a stationarity of the input time series and b the residuals must be a white noise i e their mean should be zero and there should be no autocorrelation and no cross correlation between the input and the residuals choubin and malekian 2017 thus several authors tend to neglect linear models because they may not always perform well when applied on hydrological time series which are often nonlinear khalil et al 2015 shirmohammadi et al 2013 tokar and johnson 1999 however other authors beriro et al 2012 choubin and malekian 2017 argued that linear models can be more appropriate to model simple systems characterized by linear relationships between the hydrological variables this work presents the modelling of groundwater level fluctuations in a fractured carbonate aquifer hosting thermal waters in tuscany region central italy where a linear hydraulic head response to recharge by rainfall was previously observed grassi et al 2011 thus this might be the case where a linear model can successfully capture the dynamics of the system the main aims of this work are a to compare the effectiveness of a linear autoregressive model with exogenous input arx with neural network arx combined models nnarx on short and long term forecasting and b to test different methods to avoid overfitting for the nnarx models to address the latter the levenberg marquardt algorithm which has been proven to be a fast and reliable method to train neural networks for time series forecasting adamowski and chan 2011 adamowski and karapataki 2010 daliakopoulos et al 2005 sreekanth et al 2009 is coupled with two different strategies to avoid overfitting that are the early stopping and bayesian regularization results are compared in order to understand which strategy achieves a better performance on data outside the range of the training set compared with the other strategies and with the linear models arx avoiding overfitting and thus improving model generalization is a key challenge for modelling groundwater fluctuations in the study area since here hydroclimatic extremes could cause problems for the local inhabitants indeed flooding of underground structures due to an inefficient drainage of groundwater has been reported in the study area and this can be aggravated by intense precipitations leading to groundwater level rises on the other hand the opposite extreme i e drought periods together with an increase in groundwater demand for thermal baths could lead to subsidence phenomena with damage to buildings as happened in other sites in tuscany region local authorities urge to analyse the existing groundwater level data to develop tools capable to deal with hydroclimatic extremes for improving their water resources management 2 materials and methods 2 1 study area the study covers an area of 9 km2 located north east of the village of monsummano terme in tuscany region central italy fig 1 at the transition between the northern apennines and the arno plain the aquifer system consists of a fractured carbonate hosting thermal groundwater owing to its small extension about 1 2 km long and 600 700 m thick and the absence of interconnections with surface water bodies and the downstream alluvial aquifer hosted by the arno plain grassi et al 2011 the monsummano terme aquifer can be considered as a closed system this means that the aquifer has a simple groundwater recharge discharge the recharge of the system comes mainly by local precipitation in a neighbouring hilly area with carbonate outcrops monsummano alto at 150 300 m a s l approximately whereas the discharge is downstream through natural springs and well abstractions located nearby the village of monsummano terme 20 m a s l approximately in detail groundwater circulation in the monsummano terme system can be described by the following three steps grassi et al 2011 firstly precipitation infiltrates in the recharge area with a downward flow direction toward the aquifer bottom at 600 700 m depth due to the predominant vertical fracturing successively the groundwater flow direction assumes a predominant horizontal component flowing parallel to the aquifer bottom towards the discharge area in this phase the interactions with deep thermal fluid determines a groundwater temperature increase finally in proximity of the discharge area the water reaches lower permeability deposits at the transition between carbonates and alluvial deposits consequentially due to its lower density and the consequential increased temperature moves upward the previous work by grassi et al 2011 identified a linear and quick response of the groundwater levels in the discharge area to the precipitation in the recharge area as a result of the immediate pressure propagation within the fractures of the aquifer this together with the absence of factors determining nonlinearity in the groundwater response to precipitation such as snow accumulation strong evapotranspiration and interactions with surface water bodies allows to consider the monsummano terme aquifer as a linear system 2 2 available data the data considered in the present study were provided by regione toscana that is in charge of protecting water resources the dataset fig 2 consists in a daily groundwater level automatically measured by a pressure transducer connected to a data logger at the monitoring well of grotta giusti fig 1 b daily cumulative precipitation and c maximum temperature registered at the montecatini terme station that is 5 km far from monsummano terme and can be considered as representative of the precipitation and temperature in the recharge area of the monsummano terme system 2 3 forecasting models in this study an arx model has been compared with a nnarx for groundwater level forecasting moreover three nnarx models have been developed with the levenberg marquardt training algorithm and different methods to avoid overfitting during the implementation of the neural networks have been compared the early stopping method bayesian regularization and the combination of both in the training phase of nnarx have been tested to measure the relative efficiency of the techniques to avoid overfitting after the training the models have been applied to a test set fig 2 which contains also extremes outside of the range of the training set all the models were developed using the neural network time series tool in the matlab r2017 software package 2 3 1 models inputs for the development of the model one output variable i e groundwater level data and three input variables were considered two meteorological variables i e precipitation and temperature and a time variable several studies consider a time variable e g time of the day or day of the year as an input candanedo et al 2018 lu et al 2015 ozbalta et al 2012 thomas and soleimani mohseni 2007 in the present study the information regarding the month of the year was considered by inserting as an input the average groundwater level of all the available data collected in that specific month that leads to a time variable with a cyclic trend that has only twelve possible values i e the average groundwater level of each month repeating over time depending on the month of the year in this way it has been avoided working with the 1 12 month index which would not have a cyclic trend the months december and january would have index 1 and 12 respectively which have the maximum difference even if they are temporally close fig 2 shows the training and test sets and the trends of the output and input data allowing to notice the seasonal trends in the groundwater level series groundwater levels show a maximum during winter that is the rainiest season and minimum during summer which is the driest several missing data in the groundwater level time series were found between december 2011 and october 2012 due to a malfunction of the measuring instrument this part of the dataset was excluded from the modelling since continuous series of data are needed to train and test the networks both linear and nonlinear models require choosing a number of previous values of groundwater level and meteorological exogenous inputs i e precipitation and temperature that are needed for the prediction of the successive time step in this study this choice was based on an in depth exploratory analysis zanotti et al 2019 which identified the significant number of previous groundwater levels and precipitation values based on the autocorrelation partial autocorrelation cross correlation and impulse response these are techniques aimed at quantifying the memory effect that corresponds to the influence of previous value of a variable on successive values of the same variable or of a different one chiaudani et al 2017 particularly the autocorrelation fig s1 function highlights a significant linear correlation between groundwater level values registered at different days the partial autocorrelation shows that the last significant partial autocorrelation value is at day 9 therefore the number of lags days considered as model input was 9 precipitation shows a significant linear cross correlation with the groundwater level the impulse response which indicates the cross correlation after removing the effect of the autocorrelation indicates that only the previous 10 precipitation days have a significant effect on the groundwater level of a certain day since the considered system is linear the input selection based on linear correlation has been considered valid also for the neural network models even if they would not specifically require linear correlation the main physical role of atmospheric temperature and the time variable consists in affecting the relationship between precipitation and groundwater level through the evapotranspiration process therefore the number of temperature values considered as model input was kept equal to the precipitation values i e 10 consequentially in this study both linear models and neural networks are trained to forecast groundwater level at a certain time based on the previous 9 groundwater levels and 10 precipitation temperature and time variable values 2 3 2 arx given k the current instant the arx model of the hydraulic heads sequence y eq 1 states that each groundwater level value at time t y t is a linear combination of n previous groundwater level values y and p previous values of the exogenous input variables u with coefficients θj and φj assumed to be constant 1 y t j 1 n ϑ j y t j j 1 p φ j u t j ε t the residual term εt is a white noise with zero mean to apply linear models the input time series must be stationary in this study phillips perron pp test was used to assess the stationarity of groundwater level precipitation temperature and time variable and in each case the time series could be considered stationary with a significance level of 0 05 meaning that they could be used without transformations to prove that the error term εt consists in a white noise signal a residual analysis of the arx model has been performed investigating the average of the residuals their randomness their autocorrelation and their cross correlation with the exogenous input variables 2 3 3 nnarx neural networks are flexible computing techniques designed after the biological neuron system these models have been widely applied in a variety of scientific technological fields involving time series analysis classification pattern recognition image processing etc several different model structures have been developed in the last decades the most common neural network structure called multilayer perceptron network mlp rumelhart and mcclelland 1986 was employed in this study it consists in one input layer one output layer and at least one hidden layer fig 3 the defining equation of nnarx model is 2 y t f y t 1 y t 2 y t n y t 1 i t 2 i t p in this kind of network each processing unit called neuron or perceptron is connected to those in the preceding layers and each connection is characterized by a weight inputs i coming into the neuron are weighted and summed up together with a bias element with its own weight and only then they are passed through the activation function of the neuron fig 3 in this study sigmoid function was used with the exception of the output layer that has linear transfer functions particularly among different kinds of sigmoid activation functions tan sigmoid has been proven be the best pertinent transfer function to fit hydrological variables with neural network trained with levenberg marquardt algorithm yonaba et al 2010 in this study a comparison has been performed with linear activation functions and the tan sigmoid showed the best performance results of the comparison are shown in fig s2 to train the networks the sum of squared error sse is minimized 3 sse i 1 n y i å i 2 where yi is the i th target value of groundwater level ŷi is the i th groundwater level value calculated by the model n is the total amount of data in the sequence in feed forward neural networks data are fed from the input layer to the output layer through the hidden layers and no flow of information occurs in the opposite direction in recurrent neural networks the output of the network can flow from the output layer to the input one and it can be used as an input to perform multi step ahead predictions to favour the convergence of the network data were scaled between 1 and 1 which is the range of the chosen activation functions lecun et al 2012 in this study after the network has been trained with the feed forward structure a connection between the output and the input layer was created leading to a recurrent neural network structure i e closed loop structure with this re arranged structure it is possible to perform multi step ahead forecasting by providing to the network only the external input data i e precipitation temperature and time variable while the output data i e groundwater level calculated by the network are inserted again into the network through the input layer to perform the successive predictions to perform the x step ahead forecasting the measured groundwater level until time t are fed into the network then the forecast is performed with the closed loop structure until time t x this kind of forecasts can be useful for groundwater management on a daily basis for example in the scope of predicting groundwater level threshold values exceedance based on actual weather forecast which are only reliable for short time windows furthermore the simulation mode has been tested only the initial measured groundwater level values are fed into the network and the forecast is performed using the closed loop network for the whole time window considered this kind of forecasts could be useful when investigating the potential effect of extreme seasons e g a dry summer or a wet winter or in the scope of climate change studies the most common workflow is to develop and train the network in the open loop structure and then use the closed loop structure in a second phase to perform the multi step ahead forecasts beale et al 2016 which make the training more effective and fast wunsch et al 2018 in this work each network has been trained in the open loop structure and then applied on the training set in the simulation mode with the closed loop structure the choice of the hyper parameter i e the parameter that are not learned by the training algorithm but must be chosen by the developer has been based on the comparison of the sse on the training set with the simulation mode the choice of the number of neuron and hidden layers has been performed through a grid search particularly 10 to 40 neurons where tested for the first hidden layer then at each step a second layer was added with an increasing number of neurons from 1 to 10 fig s3 s5 the choice of the hyper parameters has been performed working with the pseudo random generator seed number 1 crane 2018 highlights that to avoid the problem of different pseudo random generators it is advisable to report the results of neural network as a distribution of results obtained from a range of different seeds to investigate the effect of the random initialization of weights and biases after choosing the hyperparameters i e number of neurons activation functions etc the selected models have been trained on five different runs variating the seed of the random number generator results are reported as mean and standard deviation over these different runs 2 3 3 1 levenberg marquardt training algorithm levenberg marquardt algorithm is an optimization method designed to work with loss functions with the form of a sum of squared error similarly to the quasi newton method it was developed to approach a second order optimization problem by approximating the hessian matrix h as follows 4 h j t j so that the gradient g can be computed as 5 g j t e where j is the jacobian matrix containing the first derivative of the error function with respect to the biases and weights of the network and e is the vector of network errors backpropagation is used to calculate the jacobian matrix j of the error function with respect to the weights and biases in the present study biases and weights are initialized as random numbers within 1 and 1 at each k iteration of the training process the gradient and the approximation of the hessian matrix are calculated and consequentially the biases and weights xk of the network are updated according to the levenberg marquardt method 6 x k x k 1 j t j μ i 1 j t e the scalar µ is the levenberg marquardt parameter which has a role similar to a learning rate when µ is zero eq 6 is a quasi newton method on the other hand when µ is large eq 6 becomes a gradient descent with a small learning rate the newton s method is more accurate and faster close to a minimum of the error function therefore the parameter µ is decreased by a certain factor after each iteration resulting in a decrease of the error function while it is increased by a certain factor when tentative step would increase the performance function this means that the value of µ is increased until the change applied to weights and biases would result in a reduced performance value training stops when the maximum µ has been reached or when the minimum gradient or a performance goal i e a minimum value of sse have been achieved alternatively if a maximum number of iteration occurred after testing different initial values of the parameter µ from 0 0001 to 0 01 it has been chosen to set it to 0 001 for the network trained with the levenberg marquardt algorithm and early stopping procedure and to 0 005 for the networks trained with levenberg marquardt algorithm and bayesian regularization these values gave the best performance as it can be shown by fig s6 the minimum gradient was set to 1e 7 maximum number of iterations to 10000 the performance goal to 0 2 3 3 2 early stopping early stopping is a widely used technique to foster network generalization working on the stopping criteria of the training algorithm it consists in separating a subset of data from the training set and using them as a validation set at each iteration of the training algorithm the error function is calculated on both the training and the validation sets weights and biases are updated based on the error on the training set while the error function on the validation set is compared with those obtained in the previous iterations the learning stops if the error function on the validation set increases for 10 iterations this method prevents the network to overfit the training data which should lead to a better performance on different data to the purpose of training the models with the early stopping procedure the training set fig 2 was divided randomly into two subsets 70 of the data were used as a proper training set while the remaining 30 as validation set training and validation data must possess the same statistical properties maier and dandy 2000 to this purpose mean and standard deviations of the two subsets have been analysed verifying their similarity the means of the selected training and validation data are respectively 57 63 and 57 62 while the standard deviations are respectively 1 22 and 1 24 the percentage of training and validation set influences the accuracy of the networks therefore the training has been performed with several different percentages and the resulting networks were tested on the simulation mode the best accuracy was reached with 70 for training and 30 for validation performances on the simulation mode of the network trained with different percentages of training and validation data are shown in fig s7 2 3 3 3 bayesian regularization another method to deflect overfitting is called regularization it consists in customizing the error function by adding an additional term that penalizes weights and biases with higher absolute values in this study regularization was implemented in the form of sum of the weights and biases resulting in the following error function 7 e α s s e β i 1 w w i where wi are the weights of the network and w is the total number of weights if the scalar β is zero the error function has the form of a normal sum of square error by increasing the value of β with respect to α the relevance of the regularization term increases using this modified error function causes the network to have smaller weights and biases and this determines a smoother network response and reduces the chances of overfitting usually α and β belong to the family of the hyperparameters several approaches have been studied to choose the hyperparameters and in this study the bayesian approach is used to optimize α and β mackay 1992 the bayesian approach considers weights and biases of the network as random variables with zero mean gaussian prior distributions the regularization parameters are related to the unknown variances associated with these distributions these parameters are then optimized at each iteration according to the bayes rule in this way the objective function parameters are changing at each iteration of the training phase leading to a changing objective function for a more detailed description of the bayesian regularization applied to neural network refer to foresee and hagan 1997 to combine the bayesian regularization and the early stopping procedure training data were split into training and validation sets the error function at eq 7 is used during the training phase updating α and β at each iterations using only the training data and the iterations stop when the error on the validation set stops decreasing and starts increasing for ten consecutive iterations 2 3 4 model comparison in order to compare the effectiveness of the developed models several statistical measures can be used to describe the error associated to the model output after each model has been trained its performance can be compared in terms of statistical measures of accuracy in this study sse eq 3 the mean square error mse and the root mean squared error rmse have been taken into account to compare the efficiency of the models as predictive tools sse is a measure of the residual variance while mse and rmse are a measure of the standard deviation of the residuals 8 mse sse n 9 rmse sse n where yi is the i th target value of groundwater level ŷi is the i th groundwater level value calculated by the model n is the total amount of data in the sequence the smaller the values of sse mse and rmse the better the model performance a variety of performance criteria can help evaluating the performance of the models as different criteria can generally emphasize different aspects of the models predictive power maier et al 2010 here nash sutcliffe efficiency nse kling gupta efficiency kge and akaike information criterion aic have been calculated 10 nse 1 mse σ o 2 11 kge 1 r 1 2 α 1 2 β 1 2 w i t h α σ s σ o μ μ s μ o 12 aic n l o g sse n 2 p where σo and µo are respectively the mean and the standard deviation of the observed values while σs and µs are the mean and standard deviation of the simulated values the scalar p is the number of parameters of the model that are calculated during the training which means the number of coefficients for the linear models and the number of weights and biases for the neural networks the nse is one of the most widely used criteria for assessment of the hydrological models performance providing a measure of ability of the model to predict observed values shoaib et al 2016 kge is a reformulation of nse based on the euclidian distance of the three nse components from the ideal point which overcomes the issues related to nse gupta et al 2009 information criteria such as the aic consider also model complexity in addition to model error consequently they have the potential to result in more parsimonious models maier et al 2010 all the metrics have been calculated on non standardized data so that the values of the residuals are expressed in meters the implemented models were tested on the one day ahead forecasting as well as on multi day ahead forecasting moreover the models were tested in the simulation mode only the initial measured values of groundwater level are fed into the network and then the closed loop structure is used so that the model reproduces a complete multi year scenario 3 results and discussion the results of the network size search show that the best performing network trained with the early stopping method has 24 neurons in the first hidden layer and 4 in the second one fig s3 the best performing network among those trained with both early stopping and bayesian regularization has 30 neurons in the first hidden layer and 9 in the second one fig s4 while the network trained with bayesian regularization that outperformed the others is composed by 15 neurons in the first hidden layer and 1 in the second one fig s5 the final setup of the selected neural networks are presented in table 1 table 2 shows the performance statistics of the elaborated models on the training and the test set based on the different forecasting horizons in terms of average performances over different runs and their standard deviations the neural network trained with bayesian regularization significantly outperforms the other models on both short and long term forecasting on the training set on the other hand in the simulation mode the model trained with the early stopping procedure shows the highest performance on the training set as regards the test set results two different situations can be distinguished the short term forecasting up to 15 days ahead and the long term forecasting from 30 days ahead up to the simulation mode in the first case when the considered forecasting horizon is close to the number of time lags considered by the model i e 10 days the linear model outperforms the neural networks particularly the performance of the linear model is significantly better when considering the 1 and 5 days ahead forecasting while the statistical measures are comparable on the 7 day ahead forecasting for the longer scenarios 30 days ahead and the simulation mode the neural network trained with bayesian regularization shows a higher accuracy compared to the other networks and to the linear model fig 4 shows the comparison of real groundwater levels used as test set which presents hydrological extremes exceeding the range of the training set with those obtained by the linear model and by the neural network trained with the bayesian regularization the results of the neural network are the average over the five different runs performed with different initial weight and biases and the standard deviation is represented by the grey error bars fig 4a to e show the results of respectively 5 7 15 30 steps ahead forecasting while fig 4f shows the comparison on the simulation mode fig 4a shows that both the arx and nnarx have a high accuracy on the 1 day ahead forecasting and that the results of the nnarx are robust with a reduced uncertainty fig 4b and c highlight a noisier behaviour of the nnarx in these cases the arx model reproduces the two highest peaks that are outside of the range of the training set with a higher accuracy the peaks reproduced by the arx model appear shifted in time nnarx on the other hand slightly underestimates those peaks but reaches its maximum on the same days as the real groundwater level with regard to the 15 days ahead forecasting results fig 4d shows that the nnarx reproduces the peaks and the summer decrease with a higher accuracy while the temporal shift of the results of the arx model are more evident for the 30 days ahead forecasting and on the simulation mode fig 4e and f nnarx clearly outperforms the arx model that underestimates more than one half of the considered time series and fails at reconstructing the summer decrease and the second considered winter the uncertainty on the results of the nnarx varies in the considered time window on the 30 days ahead forecasting and the simulation mode uncertainty appears to be higher especially at the beginning of the decreasing phase table 2 shows that the performance of the neural network trained with early stopping is comparable with the one of the arx model on the simulation mode while the performance of the network trained with both early stopping and bayesian regularization is lower particularly in both cases the standard deviations of the results are higher as compared to the network trained with bayesian regularization this means that even if single runs have higher performances than the arx model minimum sse over the single runs on the simulation mode are 151 11 for early stopping and 178 06 for early stopping with bayesian regularization the averaged results over multiple runs show a lower performance fig s8 shows the averaged results of these two nnarx models on the test set with the simulation mode the nnarx trained with early stopping reproduces the groundwater level more correctly compared to the arx model apart from the spring 2014 when the arx model outperforms the nnarx the neural network trained with both early stopping and bayesian regularization shows higher uncertainties and lower performance compared to the other neural networks and the linear model arx compared to the previous arx model zanotti et al 2019 which considers only the precipitation as input variable the performance of the current arx model is increased due to the presence of the input variables temperature and time variable the residual analysis of the linear model arx shows that the average of the residual is 3 8e 06 m and that there is no autocorrelation among the residuals and no cross correlation between the residuals and the exogenous input variables fig 5 to test the randomness of the residuals a runs test has been performed which returns a decision for the null hypothesis that the values of the error vector come in a random order against the alternative hypothesis that they do not the test is based on the number of consecutive values above or below the mean of the residuals vector the resulting p value of 0 56 indicates that the test does not reject the null hypothesis that the values in the residuals vector are in random order the residual analysis results indicate that the error can be associated to a white noise suggesting that the system can be successfully represented by a linear model these results confirm that the linear models can be a suitable and easy applicable tool for short term groundwater level forecasting when the system can be considered linear as their simplicity naturally prevents the risk of overfitting this leads to a more reliable prediction even when hydrological conditions differ from those that prevailed during the training period on the other hand when longer scenarios are needed for example in the scope of evaluating possible effects of dryer or rainier seasons neural networks can offer a higher accuracy especially if during the training phase proper precautions to avoid overfitting have been implemented the higher accuracy of the nnarx model on longer scenarios does not undermine the validity of the assumptions about the linearity of the considered system which are confirmed by the results of the arx model and its residual analysis indeed neural networks can solve both nonlinear and linear time series forecasting problems zhang 2001 furthermore the fact that nnarx can reach a higher accuracy on long term forecasts suggests that they could be a more suitable tool when studying long term scenarios for example in the scope of climate changes the arx model reproduces more correctly the amplitude of the peaks on the short term forecasting but the results appear shifted in time this is due to the simple structure of the arx model which relies with a strong dependency on the observed groundwater data leading to results that are shifted in time of a number of days close to the forecasting horizon ginocchi et al 2016 valipour et al 2013 and this aspect must be taken into account when using the model for managing purposes on the other hand neural networks whose structure have been chosen based on their performance on the simulation mode on the training set show a weaker dependency on the observed groundwater data and offer a higher accuracy even when working with their own output as groundwater level input in most cases neural networks applied to groundwater level forecasting problems have only one hidden layer banerjee et al 2009 mohanty et al 2010 taormina et al 2012 yang et al 2009 this study highlights that in the considered case study adding a second hidden layer can improve the network performance among the different techniques to avoid overfitting considered in this study bayesian regularization shows a higher accuracy compared to early stopping when applied to a test set combining bayesian regularization and early stopping decreases the accuracy of the model bayesian regularization in fact requires a higher number of iterations to converge while early stopping works by limiting the number of iterations and thus avoids the bayesian regularization to reach a proper convergence table 1 the higher number of iterations required by the bayesian regularization table 1 could become computationally and time consuming in this case for example the chosen bayesian regularization network hidden layers sizes 15 1 took ca 5 min to conclude the 777 iterations while the biggest network tested hidden layers sizes 40 10 took ca 20 h to conclude the 870 iterations using an intel core i7 7700hq with ram 16 gb this means that if larger datasets are used e g hourly data developing and testing a wide range of networks could become more time consuming on the other hand this study shows that when it is possible to properly apply this technique it can be considered a reliable tool to prevent overfitting when implementing feed forward neural networks 4 conclusion this work presents the comparison between linear models arx and neural networks nnarx for groundwater level forecasting in a system where a linear relationship can be assumed between groundwater level and precipitation for the neural networks which are known for their tendency to overfit a special focus has been made on the ability of the different models to avoid overfitting three different methods to avoid overfitting have been tested early stopping bayesian regularization and the combination of both the main conclusions highlighted by the results of this work are data driven models developed on the studied system have been proven to be effective tools to fulfil the need highlighted by the local authorities of models capable to deal with hydroclimatic extremes which can support a more effective and sustainable water resource management linear models can be a suitable and easy applicable tool for short term groundwater level forecasting when the system can be considered linear since the complexity of the model is reduced in the case of arx the risk of overfitting is also naturally reduced neural networks are more reliable when longer scenarios are needed for example in the scope of evaluating possible effects of hydroclimatic extremes e g dryer or rainier seasons if proper techniques to avoid overfitting are implemented during the training phase bayesian regularization can be considered as a valid technique to prevent overfitting but coupling it with early stopping could decrease its performance therefore if the dataset is too large to manage the amount of iterations required by bayesian regularization e g hourly data early stopping alone can be considered as an alternative on the other hand early stopping showed a higher instability so that when averaged over different runs the resulting performance was lower and comparable to the performance of linear models even if usually one hidden layer is considered sufficient these results highlight that adding a second hidden layer can increase the performance of the network the methodology here presented allows researchers to choose between linear and non linear forecasting models and avoid overfitting in systems where a linear recharge groundwater level response can be assumed on the basis of the hydrogeological conceptual models groundwater level forecasting can be a useful tool to support decision makers but the developed model has to some extent be considered reliable also outside the range of the training set to be able to cope with hydroclimatic extremes declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124015 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6152,groundwater level forecasting is a useful tool for a more efficient and sustainable groundwater resource management developing models that can accurately reproduce groundwater level response to meteorological conditions can lead to a better understanding of the groundwater resource availability here an autoregressive neural network nnarx approach is proposed and compared with autoregressive linear models with exogenous input arx in order to forecast groundwater level in an aquifer system where a linear groundwater level response to recharge by rainfall is observed a well known problem regarding neural networks consists in the high risk of overfitting here three nnarx model were trained using different methods to avoid overfitting early stopping bayesian regularization and a combination of both the results show that on the short term forecasting up to 15 days the performance of nnarx and arx are comparable but the arx model generalizes better while the nnarx trained with bayesian regularization outperforms the linear models and the other nnarx models on longer scenarios on the test set as linear models are less time demanding and do not require high computational power they can be considered as suitable tools for short term groundwater level forecasting in linear systems while when longer scenarios are needed neural networks can be considered more reliable and training them with bayesian regularization allows to minimize the risk of overfitting keywords bayesian regularization groundwater level forecasting linear model neural networks overfitting 1 introduction groundwater level forecasting is a useful tool for supporting the sustainable management of water resources particularly short term forecasting few days ahead can help the assessment of groundwater resources availability for fulfilling human water needs while long term forecasting can be useful in terms of running scenarios for a changing climate in the last decades the attention kept growing toward data driven techniques as tools to perform groundwater level forecasting as alternatives to physically based models a main advantage of data driven models with respect to physically based models is that they do not require information on the hydrogeological parameters of the aquifer adamowski and chan 2011 that also need to be accurately calibrated burrows and doherty 2015 2016 gianni et al 2019 stefania et al 2018 therefore data driven models can be more suitable when exhaustive data on subsurface properties are not available moreover data driven models have been proven to be preferable to physically based models for simulating and forecasting groundwater level variations since they can overcome data limitations parameter uncertainty and the challenging problems related to the applicability of physically based models banerjee et al 2009 juan et al 2015 maskey et al 2000 nikolos et al 2008 yoon et al 2011 zhang et al 2018 the successful application of data driven models for forecasting groundwater level variations is shown by many previous works that demonstrated their applicability in a variety of hydrological settings and hydrogeological contexts wunsch et al 2018 such as hard rock systems banerjee et al 2009 river islands mohanty et al 2010 costal aquifers taormina et al 2012 yoon et al 2011 and arid zones yang et al 2009 data driven models have however some limitations with respect to physically based models a main disadvantage of data driven model is that they require long time series of hydrological and meteorological data to be trained other limitations are related to the quantification of the uncertainty and the management of overfitting discussed in detail below among data driven models two widely used techniques for groundwater level forecasting are a neural networks and b linear models neural networks consist in black box models which can provide relatively accurate predictions of groundwater levels coppola et al 2013 huang et al 2013 izady et al 2013 khalil et al 2015 nayak et al 2006 shirmohammadi et al 2013 tsanis et al 2008 uddameri 2007 advantages of neural networks are that they can better handle dynamic behaviors and non linearity adamowski and chan 2011 daliakopoulos et al 2005 a well known problem regarding the development of neural networks consists in avoiding overfitting which means improving the network generalization overfitting is defined as the problem that occurs when a network has been trained too hard to fit the training data resulting in a network which learned to reproduce noise and peculiarities in the training data rather than to find a general predictive rule dietterich 1995 if overfitting occurs the accuracy of the developed models may deteriorate significantly outside the range of the recharge and hydrogeological conditions that prevailed during the training period khalil et al 2015 generalization is the opposite of overfitting a network generalizes well when the accuracy of the network output is acceptable also when working with data that are not included in the training set rosin and fierens 1995 to have a measure of the overfitting problem and to compare different models the performance of the model is usually measured on data which were not part of the training set kang et al 2018 srivastava et al 2014 wan et al 2013 zaremba et al 2014 currently avoiding overfitting and improving the generalization of neural networks is a crucial challenge in the development of groundwater level forecasting models since an increase of hydroclimatic extremes can be expected in mid latitude regions such as the mediterranean hartmann et al 2014 the occurrence of hydroclimatic extremes leads to hydroclimatic conditions which exceed the range of the past data that were used to develop forecasting models therefore to test the reliability of data driven models for extrapolative prediction it becomes important to test the model on observational data or time period representing more extreme conditions than those in the training set bennett et al 2013 harmel et al 2014 moreover other disadvantages of neural networks are that they require several parameters to be chosen and tested carefully in order to produce good results and testing a wide variety of different parameters could become computationally expensive examples embrace network type size and architecture neuron activation functions learning algorithms stop criterion loss functions etc furthermore neural networks are often trained starting from random weights and biases this means that there is no guarantee of converging to the global minima of the error function leading to a higher uncertainty and instability of the models sudheer and kasiviswanathan 2017 linear models as well have been widely used to model groundwater level variations in several hydrological contexts ahn and salas 1997 ginocchi et al 2016 lee et al 2009 valipour et al 2013 advantages of linear models are that their training demands less time and computational effort however the main disadvantage is that they can struggle handling non linearity another limitation of linear models is that they can be properly applied only under the following assumptions a stationarity of the input time series and b the residuals must be a white noise i e their mean should be zero and there should be no autocorrelation and no cross correlation between the input and the residuals choubin and malekian 2017 thus several authors tend to neglect linear models because they may not always perform well when applied on hydrological time series which are often nonlinear khalil et al 2015 shirmohammadi et al 2013 tokar and johnson 1999 however other authors beriro et al 2012 choubin and malekian 2017 argued that linear models can be more appropriate to model simple systems characterized by linear relationships between the hydrological variables this work presents the modelling of groundwater level fluctuations in a fractured carbonate aquifer hosting thermal waters in tuscany region central italy where a linear hydraulic head response to recharge by rainfall was previously observed grassi et al 2011 thus this might be the case where a linear model can successfully capture the dynamics of the system the main aims of this work are a to compare the effectiveness of a linear autoregressive model with exogenous input arx with neural network arx combined models nnarx on short and long term forecasting and b to test different methods to avoid overfitting for the nnarx models to address the latter the levenberg marquardt algorithm which has been proven to be a fast and reliable method to train neural networks for time series forecasting adamowski and chan 2011 adamowski and karapataki 2010 daliakopoulos et al 2005 sreekanth et al 2009 is coupled with two different strategies to avoid overfitting that are the early stopping and bayesian regularization results are compared in order to understand which strategy achieves a better performance on data outside the range of the training set compared with the other strategies and with the linear models arx avoiding overfitting and thus improving model generalization is a key challenge for modelling groundwater fluctuations in the study area since here hydroclimatic extremes could cause problems for the local inhabitants indeed flooding of underground structures due to an inefficient drainage of groundwater has been reported in the study area and this can be aggravated by intense precipitations leading to groundwater level rises on the other hand the opposite extreme i e drought periods together with an increase in groundwater demand for thermal baths could lead to subsidence phenomena with damage to buildings as happened in other sites in tuscany region local authorities urge to analyse the existing groundwater level data to develop tools capable to deal with hydroclimatic extremes for improving their water resources management 2 materials and methods 2 1 study area the study covers an area of 9 km2 located north east of the village of monsummano terme in tuscany region central italy fig 1 at the transition between the northern apennines and the arno plain the aquifer system consists of a fractured carbonate hosting thermal groundwater owing to its small extension about 1 2 km long and 600 700 m thick and the absence of interconnections with surface water bodies and the downstream alluvial aquifer hosted by the arno plain grassi et al 2011 the monsummano terme aquifer can be considered as a closed system this means that the aquifer has a simple groundwater recharge discharge the recharge of the system comes mainly by local precipitation in a neighbouring hilly area with carbonate outcrops monsummano alto at 150 300 m a s l approximately whereas the discharge is downstream through natural springs and well abstractions located nearby the village of monsummano terme 20 m a s l approximately in detail groundwater circulation in the monsummano terme system can be described by the following three steps grassi et al 2011 firstly precipitation infiltrates in the recharge area with a downward flow direction toward the aquifer bottom at 600 700 m depth due to the predominant vertical fracturing successively the groundwater flow direction assumes a predominant horizontal component flowing parallel to the aquifer bottom towards the discharge area in this phase the interactions with deep thermal fluid determines a groundwater temperature increase finally in proximity of the discharge area the water reaches lower permeability deposits at the transition between carbonates and alluvial deposits consequentially due to its lower density and the consequential increased temperature moves upward the previous work by grassi et al 2011 identified a linear and quick response of the groundwater levels in the discharge area to the precipitation in the recharge area as a result of the immediate pressure propagation within the fractures of the aquifer this together with the absence of factors determining nonlinearity in the groundwater response to precipitation such as snow accumulation strong evapotranspiration and interactions with surface water bodies allows to consider the monsummano terme aquifer as a linear system 2 2 available data the data considered in the present study were provided by regione toscana that is in charge of protecting water resources the dataset fig 2 consists in a daily groundwater level automatically measured by a pressure transducer connected to a data logger at the monitoring well of grotta giusti fig 1 b daily cumulative precipitation and c maximum temperature registered at the montecatini terme station that is 5 km far from monsummano terme and can be considered as representative of the precipitation and temperature in the recharge area of the monsummano terme system 2 3 forecasting models in this study an arx model has been compared with a nnarx for groundwater level forecasting moreover three nnarx models have been developed with the levenberg marquardt training algorithm and different methods to avoid overfitting during the implementation of the neural networks have been compared the early stopping method bayesian regularization and the combination of both in the training phase of nnarx have been tested to measure the relative efficiency of the techniques to avoid overfitting after the training the models have been applied to a test set fig 2 which contains also extremes outside of the range of the training set all the models were developed using the neural network time series tool in the matlab r2017 software package 2 3 1 models inputs for the development of the model one output variable i e groundwater level data and three input variables were considered two meteorological variables i e precipitation and temperature and a time variable several studies consider a time variable e g time of the day or day of the year as an input candanedo et al 2018 lu et al 2015 ozbalta et al 2012 thomas and soleimani mohseni 2007 in the present study the information regarding the month of the year was considered by inserting as an input the average groundwater level of all the available data collected in that specific month that leads to a time variable with a cyclic trend that has only twelve possible values i e the average groundwater level of each month repeating over time depending on the month of the year in this way it has been avoided working with the 1 12 month index which would not have a cyclic trend the months december and january would have index 1 and 12 respectively which have the maximum difference even if they are temporally close fig 2 shows the training and test sets and the trends of the output and input data allowing to notice the seasonal trends in the groundwater level series groundwater levels show a maximum during winter that is the rainiest season and minimum during summer which is the driest several missing data in the groundwater level time series were found between december 2011 and october 2012 due to a malfunction of the measuring instrument this part of the dataset was excluded from the modelling since continuous series of data are needed to train and test the networks both linear and nonlinear models require choosing a number of previous values of groundwater level and meteorological exogenous inputs i e precipitation and temperature that are needed for the prediction of the successive time step in this study this choice was based on an in depth exploratory analysis zanotti et al 2019 which identified the significant number of previous groundwater levels and precipitation values based on the autocorrelation partial autocorrelation cross correlation and impulse response these are techniques aimed at quantifying the memory effect that corresponds to the influence of previous value of a variable on successive values of the same variable or of a different one chiaudani et al 2017 particularly the autocorrelation fig s1 function highlights a significant linear correlation between groundwater level values registered at different days the partial autocorrelation shows that the last significant partial autocorrelation value is at day 9 therefore the number of lags days considered as model input was 9 precipitation shows a significant linear cross correlation with the groundwater level the impulse response which indicates the cross correlation after removing the effect of the autocorrelation indicates that only the previous 10 precipitation days have a significant effect on the groundwater level of a certain day since the considered system is linear the input selection based on linear correlation has been considered valid also for the neural network models even if they would not specifically require linear correlation the main physical role of atmospheric temperature and the time variable consists in affecting the relationship between precipitation and groundwater level through the evapotranspiration process therefore the number of temperature values considered as model input was kept equal to the precipitation values i e 10 consequentially in this study both linear models and neural networks are trained to forecast groundwater level at a certain time based on the previous 9 groundwater levels and 10 precipitation temperature and time variable values 2 3 2 arx given k the current instant the arx model of the hydraulic heads sequence y eq 1 states that each groundwater level value at time t y t is a linear combination of n previous groundwater level values y and p previous values of the exogenous input variables u with coefficients θj and φj assumed to be constant 1 y t j 1 n ϑ j y t j j 1 p φ j u t j ε t the residual term εt is a white noise with zero mean to apply linear models the input time series must be stationary in this study phillips perron pp test was used to assess the stationarity of groundwater level precipitation temperature and time variable and in each case the time series could be considered stationary with a significance level of 0 05 meaning that they could be used without transformations to prove that the error term εt consists in a white noise signal a residual analysis of the arx model has been performed investigating the average of the residuals their randomness their autocorrelation and their cross correlation with the exogenous input variables 2 3 3 nnarx neural networks are flexible computing techniques designed after the biological neuron system these models have been widely applied in a variety of scientific technological fields involving time series analysis classification pattern recognition image processing etc several different model structures have been developed in the last decades the most common neural network structure called multilayer perceptron network mlp rumelhart and mcclelland 1986 was employed in this study it consists in one input layer one output layer and at least one hidden layer fig 3 the defining equation of nnarx model is 2 y t f y t 1 y t 2 y t n y t 1 i t 2 i t p in this kind of network each processing unit called neuron or perceptron is connected to those in the preceding layers and each connection is characterized by a weight inputs i coming into the neuron are weighted and summed up together with a bias element with its own weight and only then they are passed through the activation function of the neuron fig 3 in this study sigmoid function was used with the exception of the output layer that has linear transfer functions particularly among different kinds of sigmoid activation functions tan sigmoid has been proven be the best pertinent transfer function to fit hydrological variables with neural network trained with levenberg marquardt algorithm yonaba et al 2010 in this study a comparison has been performed with linear activation functions and the tan sigmoid showed the best performance results of the comparison are shown in fig s2 to train the networks the sum of squared error sse is minimized 3 sse i 1 n y i å i 2 where yi is the i th target value of groundwater level ŷi is the i th groundwater level value calculated by the model n is the total amount of data in the sequence in feed forward neural networks data are fed from the input layer to the output layer through the hidden layers and no flow of information occurs in the opposite direction in recurrent neural networks the output of the network can flow from the output layer to the input one and it can be used as an input to perform multi step ahead predictions to favour the convergence of the network data were scaled between 1 and 1 which is the range of the chosen activation functions lecun et al 2012 in this study after the network has been trained with the feed forward structure a connection between the output and the input layer was created leading to a recurrent neural network structure i e closed loop structure with this re arranged structure it is possible to perform multi step ahead forecasting by providing to the network only the external input data i e precipitation temperature and time variable while the output data i e groundwater level calculated by the network are inserted again into the network through the input layer to perform the successive predictions to perform the x step ahead forecasting the measured groundwater level until time t are fed into the network then the forecast is performed with the closed loop structure until time t x this kind of forecasts can be useful for groundwater management on a daily basis for example in the scope of predicting groundwater level threshold values exceedance based on actual weather forecast which are only reliable for short time windows furthermore the simulation mode has been tested only the initial measured groundwater level values are fed into the network and the forecast is performed using the closed loop network for the whole time window considered this kind of forecasts could be useful when investigating the potential effect of extreme seasons e g a dry summer or a wet winter or in the scope of climate change studies the most common workflow is to develop and train the network in the open loop structure and then use the closed loop structure in a second phase to perform the multi step ahead forecasts beale et al 2016 which make the training more effective and fast wunsch et al 2018 in this work each network has been trained in the open loop structure and then applied on the training set in the simulation mode with the closed loop structure the choice of the hyper parameter i e the parameter that are not learned by the training algorithm but must be chosen by the developer has been based on the comparison of the sse on the training set with the simulation mode the choice of the number of neuron and hidden layers has been performed through a grid search particularly 10 to 40 neurons where tested for the first hidden layer then at each step a second layer was added with an increasing number of neurons from 1 to 10 fig s3 s5 the choice of the hyper parameters has been performed working with the pseudo random generator seed number 1 crane 2018 highlights that to avoid the problem of different pseudo random generators it is advisable to report the results of neural network as a distribution of results obtained from a range of different seeds to investigate the effect of the random initialization of weights and biases after choosing the hyperparameters i e number of neurons activation functions etc the selected models have been trained on five different runs variating the seed of the random number generator results are reported as mean and standard deviation over these different runs 2 3 3 1 levenberg marquardt training algorithm levenberg marquardt algorithm is an optimization method designed to work with loss functions with the form of a sum of squared error similarly to the quasi newton method it was developed to approach a second order optimization problem by approximating the hessian matrix h as follows 4 h j t j so that the gradient g can be computed as 5 g j t e where j is the jacobian matrix containing the first derivative of the error function with respect to the biases and weights of the network and e is the vector of network errors backpropagation is used to calculate the jacobian matrix j of the error function with respect to the weights and biases in the present study biases and weights are initialized as random numbers within 1 and 1 at each k iteration of the training process the gradient and the approximation of the hessian matrix are calculated and consequentially the biases and weights xk of the network are updated according to the levenberg marquardt method 6 x k x k 1 j t j μ i 1 j t e the scalar µ is the levenberg marquardt parameter which has a role similar to a learning rate when µ is zero eq 6 is a quasi newton method on the other hand when µ is large eq 6 becomes a gradient descent with a small learning rate the newton s method is more accurate and faster close to a minimum of the error function therefore the parameter µ is decreased by a certain factor after each iteration resulting in a decrease of the error function while it is increased by a certain factor when tentative step would increase the performance function this means that the value of µ is increased until the change applied to weights and biases would result in a reduced performance value training stops when the maximum µ has been reached or when the minimum gradient or a performance goal i e a minimum value of sse have been achieved alternatively if a maximum number of iteration occurred after testing different initial values of the parameter µ from 0 0001 to 0 01 it has been chosen to set it to 0 001 for the network trained with the levenberg marquardt algorithm and early stopping procedure and to 0 005 for the networks trained with levenberg marquardt algorithm and bayesian regularization these values gave the best performance as it can be shown by fig s6 the minimum gradient was set to 1e 7 maximum number of iterations to 10000 the performance goal to 0 2 3 3 2 early stopping early stopping is a widely used technique to foster network generalization working on the stopping criteria of the training algorithm it consists in separating a subset of data from the training set and using them as a validation set at each iteration of the training algorithm the error function is calculated on both the training and the validation sets weights and biases are updated based on the error on the training set while the error function on the validation set is compared with those obtained in the previous iterations the learning stops if the error function on the validation set increases for 10 iterations this method prevents the network to overfit the training data which should lead to a better performance on different data to the purpose of training the models with the early stopping procedure the training set fig 2 was divided randomly into two subsets 70 of the data were used as a proper training set while the remaining 30 as validation set training and validation data must possess the same statistical properties maier and dandy 2000 to this purpose mean and standard deviations of the two subsets have been analysed verifying their similarity the means of the selected training and validation data are respectively 57 63 and 57 62 while the standard deviations are respectively 1 22 and 1 24 the percentage of training and validation set influences the accuracy of the networks therefore the training has been performed with several different percentages and the resulting networks were tested on the simulation mode the best accuracy was reached with 70 for training and 30 for validation performances on the simulation mode of the network trained with different percentages of training and validation data are shown in fig s7 2 3 3 3 bayesian regularization another method to deflect overfitting is called regularization it consists in customizing the error function by adding an additional term that penalizes weights and biases with higher absolute values in this study regularization was implemented in the form of sum of the weights and biases resulting in the following error function 7 e α s s e β i 1 w w i where wi are the weights of the network and w is the total number of weights if the scalar β is zero the error function has the form of a normal sum of square error by increasing the value of β with respect to α the relevance of the regularization term increases using this modified error function causes the network to have smaller weights and biases and this determines a smoother network response and reduces the chances of overfitting usually α and β belong to the family of the hyperparameters several approaches have been studied to choose the hyperparameters and in this study the bayesian approach is used to optimize α and β mackay 1992 the bayesian approach considers weights and biases of the network as random variables with zero mean gaussian prior distributions the regularization parameters are related to the unknown variances associated with these distributions these parameters are then optimized at each iteration according to the bayes rule in this way the objective function parameters are changing at each iteration of the training phase leading to a changing objective function for a more detailed description of the bayesian regularization applied to neural network refer to foresee and hagan 1997 to combine the bayesian regularization and the early stopping procedure training data were split into training and validation sets the error function at eq 7 is used during the training phase updating α and β at each iterations using only the training data and the iterations stop when the error on the validation set stops decreasing and starts increasing for ten consecutive iterations 2 3 4 model comparison in order to compare the effectiveness of the developed models several statistical measures can be used to describe the error associated to the model output after each model has been trained its performance can be compared in terms of statistical measures of accuracy in this study sse eq 3 the mean square error mse and the root mean squared error rmse have been taken into account to compare the efficiency of the models as predictive tools sse is a measure of the residual variance while mse and rmse are a measure of the standard deviation of the residuals 8 mse sse n 9 rmse sse n where yi is the i th target value of groundwater level ŷi is the i th groundwater level value calculated by the model n is the total amount of data in the sequence the smaller the values of sse mse and rmse the better the model performance a variety of performance criteria can help evaluating the performance of the models as different criteria can generally emphasize different aspects of the models predictive power maier et al 2010 here nash sutcliffe efficiency nse kling gupta efficiency kge and akaike information criterion aic have been calculated 10 nse 1 mse σ o 2 11 kge 1 r 1 2 α 1 2 β 1 2 w i t h α σ s σ o μ μ s μ o 12 aic n l o g sse n 2 p where σo and µo are respectively the mean and the standard deviation of the observed values while σs and µs are the mean and standard deviation of the simulated values the scalar p is the number of parameters of the model that are calculated during the training which means the number of coefficients for the linear models and the number of weights and biases for the neural networks the nse is one of the most widely used criteria for assessment of the hydrological models performance providing a measure of ability of the model to predict observed values shoaib et al 2016 kge is a reformulation of nse based on the euclidian distance of the three nse components from the ideal point which overcomes the issues related to nse gupta et al 2009 information criteria such as the aic consider also model complexity in addition to model error consequently they have the potential to result in more parsimonious models maier et al 2010 all the metrics have been calculated on non standardized data so that the values of the residuals are expressed in meters the implemented models were tested on the one day ahead forecasting as well as on multi day ahead forecasting moreover the models were tested in the simulation mode only the initial measured values of groundwater level are fed into the network and then the closed loop structure is used so that the model reproduces a complete multi year scenario 3 results and discussion the results of the network size search show that the best performing network trained with the early stopping method has 24 neurons in the first hidden layer and 4 in the second one fig s3 the best performing network among those trained with both early stopping and bayesian regularization has 30 neurons in the first hidden layer and 9 in the second one fig s4 while the network trained with bayesian regularization that outperformed the others is composed by 15 neurons in the first hidden layer and 1 in the second one fig s5 the final setup of the selected neural networks are presented in table 1 table 2 shows the performance statistics of the elaborated models on the training and the test set based on the different forecasting horizons in terms of average performances over different runs and their standard deviations the neural network trained with bayesian regularization significantly outperforms the other models on both short and long term forecasting on the training set on the other hand in the simulation mode the model trained with the early stopping procedure shows the highest performance on the training set as regards the test set results two different situations can be distinguished the short term forecasting up to 15 days ahead and the long term forecasting from 30 days ahead up to the simulation mode in the first case when the considered forecasting horizon is close to the number of time lags considered by the model i e 10 days the linear model outperforms the neural networks particularly the performance of the linear model is significantly better when considering the 1 and 5 days ahead forecasting while the statistical measures are comparable on the 7 day ahead forecasting for the longer scenarios 30 days ahead and the simulation mode the neural network trained with bayesian regularization shows a higher accuracy compared to the other networks and to the linear model fig 4 shows the comparison of real groundwater levels used as test set which presents hydrological extremes exceeding the range of the training set with those obtained by the linear model and by the neural network trained with the bayesian regularization the results of the neural network are the average over the five different runs performed with different initial weight and biases and the standard deviation is represented by the grey error bars fig 4a to e show the results of respectively 5 7 15 30 steps ahead forecasting while fig 4f shows the comparison on the simulation mode fig 4a shows that both the arx and nnarx have a high accuracy on the 1 day ahead forecasting and that the results of the nnarx are robust with a reduced uncertainty fig 4b and c highlight a noisier behaviour of the nnarx in these cases the arx model reproduces the two highest peaks that are outside of the range of the training set with a higher accuracy the peaks reproduced by the arx model appear shifted in time nnarx on the other hand slightly underestimates those peaks but reaches its maximum on the same days as the real groundwater level with regard to the 15 days ahead forecasting results fig 4d shows that the nnarx reproduces the peaks and the summer decrease with a higher accuracy while the temporal shift of the results of the arx model are more evident for the 30 days ahead forecasting and on the simulation mode fig 4e and f nnarx clearly outperforms the arx model that underestimates more than one half of the considered time series and fails at reconstructing the summer decrease and the second considered winter the uncertainty on the results of the nnarx varies in the considered time window on the 30 days ahead forecasting and the simulation mode uncertainty appears to be higher especially at the beginning of the decreasing phase table 2 shows that the performance of the neural network trained with early stopping is comparable with the one of the arx model on the simulation mode while the performance of the network trained with both early stopping and bayesian regularization is lower particularly in both cases the standard deviations of the results are higher as compared to the network trained with bayesian regularization this means that even if single runs have higher performances than the arx model minimum sse over the single runs on the simulation mode are 151 11 for early stopping and 178 06 for early stopping with bayesian regularization the averaged results over multiple runs show a lower performance fig s8 shows the averaged results of these two nnarx models on the test set with the simulation mode the nnarx trained with early stopping reproduces the groundwater level more correctly compared to the arx model apart from the spring 2014 when the arx model outperforms the nnarx the neural network trained with both early stopping and bayesian regularization shows higher uncertainties and lower performance compared to the other neural networks and the linear model arx compared to the previous arx model zanotti et al 2019 which considers only the precipitation as input variable the performance of the current arx model is increased due to the presence of the input variables temperature and time variable the residual analysis of the linear model arx shows that the average of the residual is 3 8e 06 m and that there is no autocorrelation among the residuals and no cross correlation between the residuals and the exogenous input variables fig 5 to test the randomness of the residuals a runs test has been performed which returns a decision for the null hypothesis that the values of the error vector come in a random order against the alternative hypothesis that they do not the test is based on the number of consecutive values above or below the mean of the residuals vector the resulting p value of 0 56 indicates that the test does not reject the null hypothesis that the values in the residuals vector are in random order the residual analysis results indicate that the error can be associated to a white noise suggesting that the system can be successfully represented by a linear model these results confirm that the linear models can be a suitable and easy applicable tool for short term groundwater level forecasting when the system can be considered linear as their simplicity naturally prevents the risk of overfitting this leads to a more reliable prediction even when hydrological conditions differ from those that prevailed during the training period on the other hand when longer scenarios are needed for example in the scope of evaluating possible effects of dryer or rainier seasons neural networks can offer a higher accuracy especially if during the training phase proper precautions to avoid overfitting have been implemented the higher accuracy of the nnarx model on longer scenarios does not undermine the validity of the assumptions about the linearity of the considered system which are confirmed by the results of the arx model and its residual analysis indeed neural networks can solve both nonlinear and linear time series forecasting problems zhang 2001 furthermore the fact that nnarx can reach a higher accuracy on long term forecasts suggests that they could be a more suitable tool when studying long term scenarios for example in the scope of climate changes the arx model reproduces more correctly the amplitude of the peaks on the short term forecasting but the results appear shifted in time this is due to the simple structure of the arx model which relies with a strong dependency on the observed groundwater data leading to results that are shifted in time of a number of days close to the forecasting horizon ginocchi et al 2016 valipour et al 2013 and this aspect must be taken into account when using the model for managing purposes on the other hand neural networks whose structure have been chosen based on their performance on the simulation mode on the training set show a weaker dependency on the observed groundwater data and offer a higher accuracy even when working with their own output as groundwater level input in most cases neural networks applied to groundwater level forecasting problems have only one hidden layer banerjee et al 2009 mohanty et al 2010 taormina et al 2012 yang et al 2009 this study highlights that in the considered case study adding a second hidden layer can improve the network performance among the different techniques to avoid overfitting considered in this study bayesian regularization shows a higher accuracy compared to early stopping when applied to a test set combining bayesian regularization and early stopping decreases the accuracy of the model bayesian regularization in fact requires a higher number of iterations to converge while early stopping works by limiting the number of iterations and thus avoids the bayesian regularization to reach a proper convergence table 1 the higher number of iterations required by the bayesian regularization table 1 could become computationally and time consuming in this case for example the chosen bayesian regularization network hidden layers sizes 15 1 took ca 5 min to conclude the 777 iterations while the biggest network tested hidden layers sizes 40 10 took ca 20 h to conclude the 870 iterations using an intel core i7 7700hq with ram 16 gb this means that if larger datasets are used e g hourly data developing and testing a wide range of networks could become more time consuming on the other hand this study shows that when it is possible to properly apply this technique it can be considered a reliable tool to prevent overfitting when implementing feed forward neural networks 4 conclusion this work presents the comparison between linear models arx and neural networks nnarx for groundwater level forecasting in a system where a linear relationship can be assumed between groundwater level and precipitation for the neural networks which are known for their tendency to overfit a special focus has been made on the ability of the different models to avoid overfitting three different methods to avoid overfitting have been tested early stopping bayesian regularization and the combination of both the main conclusions highlighted by the results of this work are data driven models developed on the studied system have been proven to be effective tools to fulfil the need highlighted by the local authorities of models capable to deal with hydroclimatic extremes which can support a more effective and sustainable water resource management linear models can be a suitable and easy applicable tool for short term groundwater level forecasting when the system can be considered linear since the complexity of the model is reduced in the case of arx the risk of overfitting is also naturally reduced neural networks are more reliable when longer scenarios are needed for example in the scope of evaluating possible effects of hydroclimatic extremes e g dryer or rainier seasons if proper techniques to avoid overfitting are implemented during the training phase bayesian regularization can be considered as a valid technique to prevent overfitting but coupling it with early stopping could decrease its performance therefore if the dataset is too large to manage the amount of iterations required by bayesian regularization e g hourly data early stopping alone can be considered as an alternative on the other hand early stopping showed a higher instability so that when averaged over different runs the resulting performance was lower and comparable to the performance of linear models even if usually one hidden layer is considered sufficient these results highlight that adding a second hidden layer can increase the performance of the network the methodology here presented allows researchers to choose between linear and non linear forecasting models and avoid overfitting in systems where a linear recharge groundwater level response can be assumed on the basis of the hydrogeological conceptual models groundwater level forecasting can be a useful tool to support decision makers but the developed model has to some extent be considered reliable also outside the range of the training set to be able to cope with hydroclimatic extremes declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124015 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6153,in any aquatic system analysis the modelling water quality parameters are of considerable significance the traditional modelling methodologies are dependent on datasets that involve large amount of unknown or unspecified input data and generally consist of time consuming processes the implementation of artificial intelligence ai leads to a flexible mathematical structure that has the capability to identify non linear and complex relationships between input and output data there has been a major degradation of the johor river basin because of several developmental and human activities therefore setting up of a water quality prediction model for better water resource management is of critical importance and will serve as a powerful tool the different modelling approaches that have been implemented include adaptive neuro fuzzy inference system anfis radial basis function neural networks rbf ann and multi layer perceptron neural networks mlp ann however data obtained from monitoring stations and experiments are possibly polluted by noise signals as a result of random and systematic errors due to the presence of noise in the data it is relatively difficult to make an accurate prediction hence a neuro fuzzy inference system wdt anfis based augmented wavelet de noising technique has been recommended that depends on historical data of the water quality parameter in the domain of interests the water quality parameters primarily include ammoniacal nitrogen an suspended solid ss and ph in order to evaluate the impacts on the model three evaluation techniques or assessment processes have been used the first assessment process is dependent on the partitioning of the neural network connection weights that ascertains the significance of every input parameter in the network on the other hand the second and third assessment processes ascertain the most effectual input that has the potential to construct the models using a single and a combination of parameters respectively during these processes two scenarios were introduced scenario 1 and scenario 2 scenario 1 constructs a prediction model for water quality parameters at every station while scenario 2 develops a prediction model on the basis of the value of the same parameter at the previous station upstream both the scenarios are based on the value of the twelve input parameters the field data from 2009 to 2010 was used to validate wdt anfis the wdt anfis model exhibited a significant improvement in predicting accuracy for all the water quality parameters and outperformed all the recommended models also the performance of scenario 2 was observed to be more adequate than scenario 1 with substantial improvement in the range of 0 5 to 5 for all the water quality parameters at all stations on validating the recommended model it was found that the model satisfactorily predicted all the water quality parameters r2 values equal or bigger than 0 9 keywords water quality parameters machine learning wdt anfis 1 introduction rivers are considered as one of the most critical sources of water for irrigation purposes industrial needs and other uses the dynamic nature of the river systems and their easy accessibility for waste disposal make the river systems most vulnerable to the adverse effects of environmental pollution the term water quality refers to the state or condition of water which takes into account the physical chemical and biological properties of the water in conducting the study of any aquatic system modelling the water quality parameters is of utmost significance evaluation and prediction of the surface water quality is necessary for effective management of river basins so that sufficient measures can be adopted to ensure that the pollution levels remain within permissible limits accurate prediction of future phenomena in relation to the water quality is the essence of optimal water resources management the conventional process based modelling methods offer comparatively accurate predictions for water quality parameters however these models have limitations as they depend on data sets that require a substantial amount of processing time and a huge amount of input data that is often unknown nearly 60 of the major rivers in malaysia are used for agricultural household and industrial applications did 2000 as per rosnani ibrahim ibrahim 2001 the major sources of pollution that affect these rivers are dumping of sewage waste releases from medium and small sized industries not having proper waste matter treatment equipment clearing of land and groundwork activities on the basis of the records of 1999 50 catchments that is 42 of river were contaminated with ss suspended solids caused by badly planned and unregulated earth clearing attempts and 33 catchments that is 28 of river were polluted with an ammoniacal nitrogen from activities related to cattle breeding and household sewage dumping johor river is regarded as somewhat polluted as per doe department of environment doe 2007 because of the developmental activities alongside the bank of the river moreover the river continues to be chocked and dumped by waste and litter due to lack of enforcement by the local administration these pollutants ultimately end up in the joho river tributaries rich areas for nourishment and breeding of poultry and fish consequently several statistical frameworks and computer simulations must be introduced as powerful and critical tools for planning and monitoring the maintenance of the water bodies growing concerns regarding environment along with scarce funding are giving rise to a growing interest in cost effective and judicious strategies for the management of water quality since the quality of water directly affects the health of the humans quality improvement of the water accessible for human use will play a significant role in decreasing health related hazards the project of water pollution regulation is based on the management of water quality it estimates the kind of water quality from the present water quality condition as well as from the rules of disposal of the pollutants into the river moreover many models for water quality like stochastic and deterministic models have been created so as to provide best processes to conserve the quality of water hull et al 2008 nevertheless getting efficient and precise water quality model in complex water resources is still difficult because of the variations and complications in the actual world the ambiguities in the framework and variables of the model and the deviations in the field data thus conventional methods for data processing are not sufficiently efficient anymore for solving issues related to the water quality additional efforts are required to improve the consistency of the findings of the model deterministic models try to represent all the chemical and physical processes included in statistical terms with variables acquired either from past data or obtained empirically or computed by experience or examination generally the differential equations are simplified so as to find solutions suitable for the model solution of the involved equations may need suppositions and simplifications which are derived from the performance of the model and usually practical experience is necessitated from the user prior to achievement of optimal outcomes statistical models attempt to seek general rules from the experimental data which can be done by obtaining information from the field data statistical modelling and assessment involve a meticulous selection of techniques for analysis and validation of suppositions as well as data a majority of such models are quite complex and involve a substantial field data amount to conduct the analysis moreover several statistical based models of water quality which assume the association among the prediction and the response variables are distributed normally and linear in nature nevertheless since the quality of water can be impacted by several parameters conventional techniques for data processing are not sufficiently efficient anymore for solving this issue and as such parameters show a complex non linear relation to the water quality prediction parameters thus using statistical techniques generally does not have high accuracy of late the ai artificial intelligence approach has been recognised as an effective alternative method for modelling of complicated non linear systems generally such models do not take into account the internal process but develop models through the inputs and outputs correlation presently ai is used exhaustively for estimating several water related regions muttil and chau 2006 recently ai has offered the techniques for operation optimisation and selection of equipment and problem solving that involve large quantities of data that cannot be processed by humans for the purpose of decision making for this purpose ai methods are proficient to replicate this behaviour and balance the deficiency thus the growth of technology of efficient parallel computing and growing computing power have facilitated the researchers to employ the ai approaches for instance ann artificial neural network and anfis adaptive neuro fuzzy inference system for field data modelling solutions the neuro fuzzy technique has been used effectively in certain fields of water bodies engineering like the rainfall runoff model chang and chen 2001 and basin operation chang and chang 2006 chang et al 2005 anfis has been known to enhance the accuracy of day to day estimation of evaporation kişi 2006 reservoir water level prediction chang chang 2006 and prediction of the river flow firat and güngör 2007 the data obtained from experimentation and examination may be corrupted by signals of noise because of objective and or subjective errors for instance experimental faults may be caused by measuring recording reading and external situations as this noise can possibly distort the model outcomes it is essential to eliminate them i e signal de noising prior to the use of this data the noisy signals can be de noised by applying a series of linear filters bell and martin 2004 nonetheless these filters are more suitable for linear systems rather than the non linear ones moreover the fat fourier analysis technique is a standard tool for de noising though it is only favourable for de noising signals or data involving stable noises in addition as there are unstable noises in real situations it cannot be applied effectively thus to solve the issues of conventional de noising methods more complex methods like the wdt wavelet de noising technique have been recommended above all wdt is effective for de noising multi dimensional temporal or spatial signals having stable or unstable noises also it has been extensively applied to industrial systems for information finding and patterns recognition avci 2007 tirtom et al 2008 nonetheless some of these investigations were employed for water quality monitoring where its data was utilised for estimation of parameters dohan and whitfield 1997 in malaysia wqip requires extensive calculations and transformations two studies have been proposed to use artificial intelligence techniques ai in malaysia in order to develop an accurate predictive model to wqp however many studies show that ai needs pre processing tool to enhance the accuracy of the model practically in dealing with measured water quality data which is often contain noise han et al 2011 the main objective of this investigation is to evolve a computationally proficient and robust method for the estimation of water quality variables decreasing the labour and cost for measurement of those parameters this study focuses on the malaysian johor river situated in johor state where the water quality dynamics are significantly altered this research has many primary objectives as follows to evaluate and assess the correlation among the parameters of water quality on the basis of the experimental data using ann artificial neural network to propose various ann approaches like mlp multi layer perceptron neural network and rbf radial basis function neural network so as to confirm the effectiveness of these techniques in the estimation of the parameters of water quality to get familiar with the correctness of the anfis adaptive neuro fuzzy inference system in the prediction of the parameters of water quality to develop an augmented wdt anfis wavelet de noising technique with the neuro fuzzy inference system to examine the effectiveness of the suggested model for spatial position by presenting two different situations the first situation scenario 1 is designed to set the model prediction at each station pertaining to the water parameters by considering the 13 input parameters from the same station where for scenario 2 the input parameters for this scenario based on the measured water quality parameters from the same station and the predicted parameter from upstream station to validate the augmented wdt anfis wavelet de noising technique with the neuro fuzzy inference system based on the experimental data for the duration 2009 2010 2 case study johor river basin johor state is regarded as the third largest region in malaysia with an area of 19 984 km2 it comprises of eight districts namely are kota tinggi muar pontian johor bahru segamat kluang and lastly batu pahat which is considered as the second largest districts in johor with an area of 187 702 06 ha johor state has five principal rivers which are sungai muar sungai johor sungai endau sungai batu pahat and sungai sedilfi this research sheds the light solely on sungai johor river the johor river basin is located in the southeast of peninsular malaysia at an altitude of 1010 m the johor river orginates from the gunung belumut and from bukit gemuruh at an altitude of 109 m un the north the river has irregular shape its drainage area is around 2636 km2 and its length is approximately 122 7 km the river flows southeast into the johor straits an average annual precipitation of 2470 mm added to the river while during the period of 1963 1992 the annual mean discharge at rantau panjang was found to be 37 5 m3 s the johor river and its tributaries play a significant role as water suppliers for the state of johor as well as for singapore many factors contribute to the deterioration of the water quality of johor river mainly include the release of different kinds of pollutants at levels exceeding the allowed limits with the absence of local authorities enforcement these pollutants travel through johor river and ultimately end in the estuaries of the rivers which are known to be a natural feeding area for poultries and fishes and a natural environment that provide spawning fig 1 depicts the location map of the surveying area which compromises of four monitoring stations on johor river 3 methodology 3 1 multi layer perceptron neural network mlp ann a feed forward network is the multi layer perceptron neural network mlpnn that includes many layers of neurons where one neuron s output is propagated to the other neuron s input that is in the next layer fig 2 presents the multi layer perceptron neural network in mlpnn the input layer s nodes only propagate the input values of the first hidden layer s nodes in the hidden layers each node s input output relationship can be presented as follows 1 y f j w j x j b where x j signifies the output from the previous layer s j node w j denotes the connection weight between the current node and j node b represents the current node s bias and f defines a non linear transfer function usually of the sigmoid form as shown in eqs 3 4 2 f z 1 1 exp z where z denotes the weighted sum pertaining to the input to the neuron and f z signifies the neuron output the output nodes input output relationship is comparable to the one defined by eqs 3 4 with the exception of the case where the network is employed for function approximation and the type of function f could vary e g linear function the units define a mlpnn architecture which allows computation of a non linear function in terms of the scalar product pertaining to the weight vector and input vector overall the mlpnn models performance relies on the network s inherent architecture apart from the number of hidden layers as well as the number of neurons pertaining to each layer it also includes the computation type applied to each neuron 3 2 adaptive neuro fuzzy inference system anfis jang 1993 first put forward the adaptive neuro fuzzy inference system anfis that allowed realising a highly non linear mapping and compared with common linear methods it is considered to be superior in yielding non linear time series jang 1993 the anfis architecture was employed throughout this research for the first order sugeno fuzzy model sugeno and kang 1988 anfis can be defined as a multi layer feed forward network that employs neural network learning algorithms as well as fuzzy reasoning to aid in mapping input space with that of the output space chang and chang 2006 considering that for a first order sugeno fuzzy model the fuzzy inference system has one output f and two inputs x and y a common rule set that includes two fuzzy if then rules can be defined as follows 3 rule 1 i f x i s a 1 a n d y i s b 1 t h e n f 1 p 1 x q 1 y r 1 4 rule 2 i f x i s a 2 a n d y i s b 2 t h e n f 2 p 2 x q 2 y r 2 where a1 a2 and b1 b2 signify the membership functions mfs pertaining to inputs x and y respectively pi qi and ri i 1 or 2 represent the linear parameters pertaining to the first order sugeno fuzzy model s consequent part fig 3 a represents the fuzzy reasoning mechanism pertaining to this sugeno model that also allows deriving the output function f from that of inputs x and y fig 3 b presents the corresponding equivalent anfis architecture in which similar functions are associated with the same layer s nodes anfis comprises five layers as stated below 3 3 wavelet de noising the next logical step is characterised by wavelet analysis post the short time fourier transforms stft this is with regards to the windowing technique that includes variable sized regions with the help of wavelet transform wt long time intervals can be employed in those areas where more precise low frequency information is needed as well as for shorter regions in which high frequency information is needed overall the key benefit provided by the wavelets is allowing conducting local analysis for localised area pertaining to a larger signal the discrete time wt pertaining to a time domain signal x k can be expressed as follows dohan and whitfield 1997 5 d w t m n 1 2 m k x k ψ 2 m n k here n defines the mother wavelet while m represents the scaling and k denotes the shifting indices the dwt logarithmic frequency coverage is provided through scaling as opposed to the uniform frequency coverage of stft this analysis technique includes segmenting a signal into components at various frequency levels which are linked by the powers of two a dyadic scale the filtering approach that is applied to multi resolution wt involves formation of a series of half band filters that segment a spectrum into low and high frequency bands the formulation is based on a wavelet function or high pass up filter as well as a scaling function or low pass lp filter wavelet multi resolution analysis wmra allows constructing a pyramidal structure that needs an iterative application of wavelet functions and scaling to high pass and low pass filters respectively at the beginning these filters are first applied to the entire signal band under high frequency small scale values and then the signal band is decreased at every stage gradually as presented in fig 4 the detail coefficients of dl d2 and d3 define the high frequency band outputs while the approximation coefficients of al a2 and a3 define the low frequency band outputs numerous factors need to be accounted when wavelets are employed to de noise the wqp data examples of such choices include the level of decomposition wavelet and thresholding methods to be employed matlab provides various families of wavelets such as morlet meyer mexican hat coiflets haar symlets daubechies and spline biorthogonal wavelets and also offers additional documentation regarding these wavelet families wavelet toolbox matlab 2019 only orthogonal wavelets need to be accounted to get perfect reconstruction results certain advantages are associated with the orthogonal wavelet transform it can be characterised as being relatively concise permitting perfect reconstruction of the original signal and relatively easy to calculate the two common employed approaches for thresholding a signal include hard thresholding and soft thresholding which are employed in the matlab wavelet toolbox although the easiest method is hard thresholding better results are achieved through soft thresholding versus hard thresholding thus this study uses soft thresholding four threshold selection rules can be used with the wavelet toolbox which employ statistical regression pertaining to the noisy coefficients over time that allows getting a non parametric estimation regarding the reconstructed signal absent noise this study examined just sqtwolog wherein a fixed form of threshold is employed leading to minimax performance that is multiplied by a factor proportional of signal length s logarithm in this research in terms of the decomposition level we can conclude that a level 4 decomposition offered reasonable results post applying the trial and error method to all modules 3 4 model performance evaluation it is necessary to clearly recognise the criteria that are associated with judging the model s performance the criteria employed to assess the performance of the model in this study were clearly mentioned in the literature dogan et al dogan et al 2009 employed the average absolute relative error aare which not only provides the performance index with regards to predicting water quality parameters but also demonstrates the prediction errors distribution to examine the performance of the model singh et al 2009 employed the bias statistical index the bias signifies the mean of all the individual errors as well as allows determining if the dependent variable is underestimated or overestimated by the model in this study correlation coefficient as well as root mean square error rmse was employed to examine the model s performance soyupak et al 2003 zhao et al 2007 usually the model performance is assessed through coefficient of determination as put forward by nash and sutcliffe 1970 while mse is employed to check the level of fitness between the network output and desired output in this research work the models performances were assessed based on three statistical indexes as mentioned by nash and sutcliffe 1970 coefficient of efficiency ce is commonly employed to assess the performance of the model 6 ce 1 i 1 n x m x p 2 i 1 n x m x m 2 where n represents the number of observations x m and x p define the measured and predicted parameters respectively and x m signifies the average of measured parameter mean square error mse is employed to see the level of fitness between network output and the desired output better performances are guaranteed with smaller mse values it is defined as follows 7 mse 1 n i 1 n x m x p 2 more commonly the coefficient of correlation cc is employed to examine the linear relationship between the measured and predicted dissolved oxygen this can be expressed as follows 8 cc i 1 n x m x m x p x p i 1 n x m x m 2 i 1 n x p x p 2 further for visual comparison of the predicted and measured values the scatter plot was employed kuo et al 2007 3 5 input variables and data processing one of the key functions of ann is to identify the model input parameters that could impact the output parameters considerably as indicated above the selection of input parameters depends on a priori knowledge regarding causal variables as well as statistical analysis pertaining to the potential outputs and inputs in the literature different input parameters were employed to develop the model to determine water quality parameters as presented in table 1 on the basis of the literature the following water quality parameters were chosen for ann modelling temperature temp electrical conductivity cond salinity sal nitrate no3 turbidity turb phosphate po4 chloride ci potassium k sodium na magnesium mg iron fe and escherichia coli e coli the basic statistical parameters i e mean minimum maximum standard deviation s d and coefficient of variation cv of the input and output parameters deployed in this study are depicted in tables 2 and table 3 based on the concentration levels of both output and input parameters large changes between the samples were seen along with a high coefficient of variation i e 254 94 for an and 325 96 for e coli the coefficient of variation cv can be defined as a measure of statistical dispersion pertaining to the data for a given data set it is the mean normalised standard deviation cv that can be computed as standard deviation mean 100 the existence of large disparity in the parameters concentrations can be attributed to the types non point and point and nature of sources that have been distributed in the river basin s wide geographical area during the course the river flows through different townships and many tributaries and wastewater drains pouring large quantities of untreated wastewater into the river s main channel a coefficient of variation in the range of 3 08 and 325 96 was seen with the parameters such variability that exists amongst the samples could be due to large geographical variations in climate as well as seasonal effects pertaining to the study region for the various sampling sites a spatial and significant variation was seen in terms of johor river s turbidity which varied from 0 2 to 343 ntu it was higher which could because of the mixing of industrial effluents and domestic sewerage water in johor river the rise in turbidity near downstream sites can be attributed to settling factors and flow turbulences at downstream sites the observed trend of turbidity i e sn02 sn03 and sn04 was seen to support the above mentioned hypothesis comparable patterns pertaining to spatial variations in turbidity were reported by khadse et al 2007 when investigating kanhan river s water quality amongst the sampling sites the conductivity of the johor river water was found to be considerably different in which the mean ranged from 54 to 64 μs although least significant difference was between sn01 and sn03 the high conductivity at sn04 and sn02 sites signify sewerage mixing into the river water the dilution of industrial and urban runoffs could be attributed to the lower conductivity seen in the downstream water nitrate is considered to be a crucial parameter of river water that could be an indicator for the pollution status and anthropogenic load in river water the mean of nitrate ranged from 0 66 to 163 5 mg l for johor river at the site wherein urban runoff mixing was noticed no3 was seen to be the maximum it is interesting to note that in the downstream non point pollution sites lower no3 was seen the concentration of chloride in water was deemed not to be harmful a higher concentration of chloride found in freshwater signified that pollutants are present moreover in johor river the chloride level fell in the range of 5 27 to 7 37 mg l nonetheless at various sampling sites a clear trend was not seen with chloride concentration in terms of the non point or point pollution sites the mixing of industrial effluents or urban wastewater in the river water is signified by higher levels of chloride content at sn04 ph of water indicates alkaline and acidic conditions doe doe 2007 suggested that ph for water in the range of 6 5 8 5 can be employed for any purposes in that respect the ranges showed that johor river had moderately alkaline water the change in mean ph ranged from 6 22 to 6 36 at various locations at some sites higher ph could be a result of carbonate and bicarbonates of magnesium and calcium in water the key source pertaining to such chemicals include industrial wastewater or urban runoff ss further signifies the river water s salinity behaviour the mean ss content pertaining to river water was found in the range of 72 61 to 91 01 mg l the chemical and biological oxygen demand increase in tandem with higher ss level in the water system which ultimately results in depletion of the dissolved oxygen level in water in water ss stems from natural sources industrial wastewater urban runoff sewage and chemicals employed in the water treatment process for the current neural network modelling the second assessment of selecting the input parameters is done by considering a statistical correlation analysis pertaining to the field data calculation of the correlation coefficient existing between the input and output parameters was done and listed in table 4 based on the table ph was clearly seen to be inversely associated with water temperature r 0 306 as well as potassium r 0 425 we performed an experiment by taking water quality variables that were accounted along with the parameters mentioned above pertaining to various models to realise the optimal predictive model as well as reduce the monitoring cost by accounting for fewer input parameters 3 6 stopping criteria normally there is a gradual decrease in the training error of ai since the training process is on going nonetheless this minimisation of training error does not guarantee enhancement of generalisation ability which gained our interest it is not necessary that ai showing good performance with the training set will do the same with the testing data therefore it is also sometime important to stop the training phase at the right time before over fitting occurs when a generalisation characteristic is lost by the neural network an over fitting issue follows however relations between the training inputs as well as their associated outputs to similar hidden patterns pertaining to the unobserved data cannot be generalised thus this occurs as a result of a difficult question that asks how long a network needs to be trained the issue of over fitting is usually solved by employing techniques like weight elimination weight decay and early stopping stopping criteria is the most commonly employed method to address this issue as noted by numerous researchers e g singh et al 2009 palani et al 2008 two frequently employed stopping criteria include stopping post a specific number of runs via the complete training data it needs to be noted that an epoch is defined as each run that passes through the complete training data and stopping on reaching some low level by the target error 3 7 different scenarios two different scenarios have been proposed in this study the concept behind the development of these both scenarios is based on the spatial pattern of the input output structure of the model mainly the reason behind proposing these scenarios is to examine the model performance considering the spatial dimension of the model input keeping in mind that the model output in both scenarios is the prediction values of the an ph and ss the input patterns has been changed in terms of the number of the inputs and location of the monitored data in order to clarify the structure and show the difference between these two scenarios an example for the structure of both scenarios to predict the an parameter will be presented for scenario i to predict an parameter at certain station different twelve input parameters were used that have been acquired at the same station while the structure of scenario ii is developed as in addition to the same twelve water quality parameters used as inputs in scenario i the value of an parameter that has been acquired from the upstream station will be added the prediction procedure can be defined as an operation that allows offering water quality parameter patterns for the future this research employs the wdt anfis along with its stochastic and non linear modelling capabilities to design a prediction model that mirrored the water quality parameter patterns pertaining to johor river with regards to the 12 input parameters scenario 1 cited earlier which is represented as follows 9 wqi p n f wdt a n f i s t e m p n c o n d n s a l n t u r n n o 3 n c i n p o 4 n f e n k n m g n n a n e c o l i n n 1 2 3 4 where wqipn signifies the water quality index parameters pertaining to station n and fwdt anfis defines the non linear function predictor built via the wdt anfis network thus at each station four models were built for predicting the parameters for water quality a majority of the recent studies were aimed at predicting the concentrations pertaining to the parameters of water quality at every station usually discharge via the local area from the upstream station causes an impact on the water pollution pertaining to a downstream station zaqoot et al 2009 therefore in the put forward model it was important to consider the impact cast by water parameters at the upstream station thus the second scenario scenario 2 was designed to set the model prediction at each station pertaining to the water parameters by considering the 13 input parameters at the previous station upstream the predicted wqip could be represented by following eq 10 repetition of this procedure involving the predicted wqip is done for the fourth and third stations at downstream fig 5 presents a schematic representation pertaining to the put forward networks for scenario 2 10 wqi p n 1 f wdt a n f i s t e m p n c o n d n s a l n t u r n n o 3 n c i n p o 4 n f e n k n m g n n a n e c o l i n w q i p pn 4 results and discussion 4 1 mlp ann training the construction of an ann model normally includes three steps the training stage is the first step in which the network is exposed to a training set pertaining to the input output patterns the second step involves the validation stage in which the network s performance is evaluated when patterns are not observed by the network in the training stage the third step includes the testing stage in which the network s performance is evaluated when the unknown patterns were not observed during the stages of validating and training bowden et al 2005 designing of three mlp ann architectures was done one for each parameter the levenberg marquardt back propagation algorithm lma is employed by all three networks in the entire training procedure this study employed three activation functions namely tan sigmoidal tansig log sigmoidal logsig function and linear transfer function purelin after initialising the network weights and biases during the training process iterative adjustments of the weights and biases pertaining to the network were carried out to decrease the network performance function pertaining to mean square error mse the average squared error between the target outputs and the network outputs we introduced different values of learning rate lr to the networks in a bid to achieve the optimum result pertaining to this study for back propagation learning algorithm the learning rate is important as it helps determine the level of weight changes however since the learning process tends to slow down when smaller learning rate values are employed for training it is not a favoured choice employing larger learning rates values for training could lead to network oscillation in the weight space one approach to enhance the gradient descent method is by introducing an additional momentum parameter mc that facilitates larger learning rates leading to faster convergence while decreasing the oscillation tendency rumelhart et al 1986 the momentum term is introduced so that the next weight changes are similarly aligned to the same direction as the previous one which allows minimising the oscillation impact of larger learning rates although there are certain systematic approaches to simultaneously choose the learning rate and momentum the best values pertaining to these learning parameters are normally selected based on experimentation since any value falling between 0 and 1 can be accounted by the learning rate and the momentum it becomes almost impossible to perform an exhaustive search to detect the best combinations pertaining to these training parameters in this research paper we evaluated different momentum and learning rates pertaining to both networks in real practice 0 9 and 0 95 were selected as momentum and optimum learning rate pertaining to ss an and ph models respectively 4 2 optimisations of the neurons number the number of neurons in the hidden layer is the key characteristic pertaining to ai technique the network fails to model the complex data that could lead to poor fitting if the number of neurons employed is insufficient on the flip side the training time could become unreasonably long as well as the network may also over fit the data if there are too many neurons employed in this paper to investigate the best performance various mlp ann architectures were employed in fact a formal and or mathematical approach does not exist which allows determination of appropriate optimal set pertaining to neural network s key parameters thus the trial and error method was selected to perform this task randomisation of the hidden layer s neurons was done from n 1 to 20 neurons in the hidden layer the best numbers of nodes are those that provide the lowest error lek et al 1996 based on two performance indices determination of the optimum number of neurons was done the root mean square error rmse value pertaining to the prediction error is the first index while the value of the maximum error is the second index to get both indices the ann model was evaluated by considering the wqp data between 1998 and 2007 when building such a predicting model that employs the neural network the model could do well during the training period and could give a higher level of error when assessment was done during either the testing or validation period based on this study these performance indices were employed to ensure that the put forward model would offer consistent accuracy levels during all periods as the performance indicator for the put forward model the key benefit of using these two statistical indices is to ensure that the highest error falls within the acceptable error range for the forecasting model when the performance is being evaluated this is done when rmse is employed and making sure that the summation of the error distribution is not high in the validation period consequently employing both indices ensures consistent level of errors and offers high potential to maintain the same error level while evaluating the model for unseen data during the testing period when the number of hidden neurons to the network is varied it has a clear impact to a considerable degree on the prediction performance it clearly demonstrates that there is a rise in prediction performance with increase in the number of hidden neurons from 1 to 18 along with subsequent decrease in rmse and maximum error pertaining to all parameters however a drop in prediction performance occurred when hidden neurons were added further 19 to 20 to the network for instance it can be seen that the best combination pertaining to the put forward statistical indices to examine the predicting model for the ph was when 18 neurons with rmse 0 15 were associated with the ann architecture and a maximum error as 3 22 the best combination pertaining to the put forward statistical indices to examine the predicting model for the ss was when 17 neurons with rmse 0 30 were associated with the ann architecture and a maximum error of 3 46 table 5 lists out the optimal numbers of neurons pertaining to the remaining parameters 4 3 water quality prediction model of mlp ann the mlp ann model for the estimation of the 6 parameters of water quality as the output which are ss an and ph was evaluated in this section fig 6 depicts the measured and estimated parameters of water quality for the most excellent network which provided the most precise estimation on the whole the predictive capability of this model was fairly good for each of the parameters of the water quality in the training duration though less accurate when the validation and testing stages were carried out the findings showed that it was challenging to develop a consistent model using the mlp ann models due to high variations and intrinsic non linear correlation among the parameters of the water quality because of the probabilistic nature and chemical procedure additionally the mlp ann models encountered delayed convergence during the training because of the necessity of comparatively a huge amount of hidden neurons also several researchers observed that these models failed to acquire values lying outside the scope of values included in the calibration data of mlp ann boundary values campolo et al 1999 dawson and wilby 1998 hsu et al 1995 karunanithi et al 1994 minns and hall 1996 this constraint arising chiefly due to the application of a logistic function to translate the output of the model makes these models inappropriate for several applications alternatively the rbf ann radial basis function network is commonly employed for strict interpolation issues in space with multiple dimensions which has equivalent abilities as the mlp ann in solving problems related to function estimations park and sandberg 1993 there are chiefly 2 benefits of the rbf ann a network training in shorter duration in comparison to mlp ann and b best solution estimation without managing the local minimums in addition rbf ann works as a local network in contrast to the feed forward networks which are global mapping networks also rbf ann employs one processing units set and every unit is most accessible to a local area of the input region due to this rbfns are employed more recently as a substitute nn model in function estimation applications and prediction of time series sheta and de jong 2001 yu et al 2008 thus the following section describes the attempt to get familiar with rbf ann suitability to be used as a model for predicting the parameters of water quality 4 4 sensitivity analysis to assess the input variables impact on the model 3 assessment methods were used first method was based on dividing the nn connection weights so as to establish the relative significance of every input variable in the network stern and garson 1999 in this research the recommended network comprises 12 environmental variables presuming the connection weights from the input nodes to the hidden nodes exhibit the relative predictive significance of the independent parameter the significance of every input parameter can be articulated as follows 11 ij m 1 m n h w jm ih k 1 ni w km ih w mn ho k 1 k n i m 1 m n h w jm ih k 1 ni w km ih w mn ho where ij represents the relative significance of jth input variable on the output variable ni and nh denote the quantities of input and hidden neurons correspondingly and w represents the connection weight also the superscripts i h and o signify the input hidden and output levels correspondingly while the subscripts k m and n signify the input hidden and output neurons correspondingly the first method of evaluation was to assess the relative significance of every input variable as calculated by eq 11 and illustrated in fig 7 the relative significance demonstrates the importance of a variable in comparison to the other variables belonging to the model even though the network did not essentially signify physical sense using weights it indicates that all the variables had intense effects on the estimation of all output variables in which the estimator contribution varied from 5 to 14 apparently the most useful inputs were considered to be those that involved oxygen containing nitrate no3 and phosphate po4 conversely ph and temp were discovered to be the least useful parameters additionally mg proved to be providing the greatest contribution for the recommended model for an for ph it was apparent that the most useful input was temp 4 5 water quality prediction model of anfis as a matter of fact among the difficulties in anfis based modelling is establishing its variables for optimal learning i e the membership function number and step size s initial value before training in a way that the optimal training is achieved two techniques have been proposed by several researchers for establishing these variables in anfis optimisation techniques hassanain et al 2004 and the trial and error approach kim et al 2002 while determining the variables for optimal learning could be ensured by the optimisation algorithms i e derivative based or derivative free optimisation this alternative has a downside of being computationally costly conversely the trial and error technique has been confirmed to be effective in case the target root mean square error can be realised this technique is also advantageous as it yields a knowledge rule base having a lower possibility of surpassing the data set of training in comparison to the optimisation technique thus this research did not include the optimisation technique and established the variables for optimal learning of anfis through the trial and error technique for every parameter related to the water quality this study employed the architectures proposed in the preceding section in which 12 inputs were utilised to estimate the wqip it is noteworthy that there is no systematic technique to establish the optimal quantity of mfs the optimal quantity of mfs is generally established inductively and validated empirically thus the quantity of mfs was selected using the trial and error method meanwhile it is to be observed that this study had tested 4 kinds of membership functions a triangular b gaussian c trapezoidal and d bell shaped to compose the fuzzy numbers following several trials the outcome revealed a distributed membership function having bell shaped nature in comparison to others which had acquired the minimal relative error table 6 demonstrates the kinds and quantity of mfs that were implemented in this study to develop the modules for demonstrating the performance of the suggested anfis model an evaluation of predicted against observed parameters of water quality during training validation and experimentation phases is displayed in the fig 8 it is apparent that the suggested anfis model procedure provided the estimated variables that mimicked the dynamics pattern in the noted values besides those boundary values measured during this time 4 6 water quality prediction model of wdt anfis the above findings were obtained with the general assumption that the mined data must be precise and reliable nevertheless the data acquired from the study test and simulation procedures may be corrupted by noise because of objective and or subjective errors li and shue 2004 for instance the errors arising in the experiment may be caused by measuring recording reading or external scenarios the errors from simulation might cover uncertainties of the model and parameters as well as computational errors as these noisy signals possibly distort the data mining outcomes it is necessary to eliminate them i e signal de noising process before the use of any initial data thus an augmented wdt anfis based on historical information for wqpp will be presented training and cross validation processes of the model of wdt anfis were carried out to reduce the root mean square error among the output as well as predicted responses the wdt anfis model outperformed the anfis model and provided improvement in estimation accuracy of all the variables while the anfis model performed inefficiently as the noise intensity increased it was obvious that wqp possibly had more accurate estimation values due to de noising of data this suggests the wdt superiority in data cleaning despite the occurrence of errors during stages of training validation and experimentation which were regarded as considerably high in comparison to the training and cross validation stages it had obtained a high precision for all variables the findings displayed in fig 9 demonstrate that the wdt anfis model could be regarded as a suitable technique for modelling for estimation like wqp 4 7 comparative analysis the models introduced in prior discussion were all compared for the purpose of providing precise predictions for each water quality parameter at johor river similar findings were achieved in determining models for predicting suspended solids concentrations ss wherein wdt anfis forecast ss with comparatively less accuracy in which errors for most records were below 10 peak ss values were more closely approximated using wdt anfis in comparison to that attained using other techniques as depicted in fig 10 the numbers of inaccurate ss forecasts decreased meaningfully using wdt anfis the use of physics based distributed processing in complex computer software is frequently problematic owing to the usage of idealised sedimentation components or the requirement of large volumes of detailed temporal and spatial data on the environment which is not always available cigizoglu 2004 it should be noted that ai approaches to determining suspended sediment data estimations remain sparse in the relevant literature abrahart and white 2001 the success attained in modelling dynamic systems implies that this strategy may well provide an efficient and productive means for simulating complex suspended sediment processes in rivers under conditions where precise knowledge of internal sub processes is not necessary each proposed model in this study was constructed on the assumption that land cover use would remain unchanged during this research however land cover use remains an important factor in the production and transport of sediments along with other factors more precise predictions of suspended sediments may be attained by including variables that represent land cover use status into the scheme we are planning such analytical studies soon enough in conclusion this research establishes wdt as an appropriate method along with classical anfis for modelling suspended sediments in river environments it is therefore worth considering the use of wdt anfis approaches in such analysis given the findings of studies regarding the physics embedded in anfis structures with regards to ph fig 11 depicts comparisons between anfis and other models performances based on the test data set in the figure it is clear that anfis performance exceeds that of the two ann methods furthermore the effort reveals the challenges in devising reliable schemes based on mlp ann rbf ann models as a result of the high variances as well as the inherent non linear associations among the water quality parameters as a result of the stochastic quality and chemical based process furthermore as depicted in fig 10 the findings show that wdt anfis based modules outperform anfis and also have the ability to improve predictive accuracy for ph albeit for mae with comparatively lesser accuracy whereby errors for most records were below 7 otherwise inefficient executions were observed based on the anfis module wherein most errors were above 15 clearly given increases in noise intensities wqp offers more precise predictions from data de noised with wdt than data without such de noising this suggests the advantage of using wdt to clean the data it is fact that the training process for big data using any of ai models is both time consuming and computation and memory intensive especially when several number of model inputs variables is used the computer specification that have been used to run models are intel processor core i7 12 m cache up to 4 60 ghz and ram 16 gb it is fact that in our study the data used is not big data to be considered as problem to the computational memory however due to the fact that the number of the model input variables is relatively big twelve or thirteen based on the structure of scenario i and scenario ii respectively the training process is slightly time consuming to achieve the performance goal table 7 summarize the training time for each models in seconds where it is noticeable that the anfis and wdt anfis models consuming more time than ann models mlp and rbf but it is still minimal 4 8 scenarios the comparatively low correlation among forecast and observed values during test phases was perhaps a result of the non homogenous nature of water quality parameters moreover ying et al zhao et al 2007 demonstrated that the selection of influential factors namely input parameters has a critical role as these factors greatly affect forecasts clearly the low correlations in this research can be attributed to the realisation that its input parameters had not included every relevant parameter furthermore pollution levels at downstream stations were associated with discharge from upstream stations to overcome this difficulty the researchers applied another approach i e scenario 2 such that higher levels of accuracy could be attained this strategy is associated with the prediction of each water quality parameter given the actual values measured at upstream stations as model inputs as described by eq 12 for a most appropriate analysis the researchers implemented an accuracy improvement ai index for the correlational coefficient statistical index in order to determine the significance of scenario 2 as against scenario 1 described as follows 12 ai c c s c e n 2 c c s c e n 1 c c s c e n 2 100 wherein ccscen2 denotes the coefficient of correlation for scenario 2 whereas ccscen1 denotes a similar statistical index for scenario 1 from table 8 it is clear that scenario 2 is more satisfactory than scenario 1 with meaningful improvements observed in every station which ranged from 0 5 to 5 predictive accuracy was meaningfully enhanced after introducing scenario 2 for every station as in the case for ph scenario 2 showed more satisfactory performance than scenario 2 with meaningful improvements observed in ai which ranged from 3 in station 2 to 5 in station 3 conversely less improvement was gained with an wherein ai was equal to 0 5 in stations 1 and 3 even though it is clear that scenario 2 was less efficient with an accuracy does increase by 2 once it is applied to station 3 furthermore the findings indicate that scenario 2 not only showed improved accuracy for certain parameters but this particular model had the ability to capture temporal patterns in water quality parameters this enabled the scheme to apply meaningful improvements to station scenarios 4 9 model validation models must be verified whenever resulting outputs and observed values are near enough to satisfy all validation criteria palani et al 2008 to investigate the effectiveness of this proposed scheme validation of the enhanced wavelet de noising method using the neuro fuzzy inference system wdt anfis in accordance with field measurements collected from 2009 to 2010 is therefore applied the scatter plots among the forecast and observed values for all 5 selected parameters for water quality are depicted in fig 12 clearly the majority of forecast water quality parameters had closely approximated actual observations as well r2 must be as near 1 as possible with values that exceed 0 9 implying very satisfactory model execution values from 0 6 to 0 9 implying fairly good execution and values below 0 5 indicating unsatisfactory execution based on these criteria the wdt anfis model s ability to predict both ph and ss concentrations is very satisfactory in that r2 values are at least 0 9 for every station but for an wherein models showed merely decent performances in that r2 values were below 0 9 for station 3 based on these findings wdt anfis can be said to demonstrate good predictive performance for predictions of water quality parameters using ai other researchers have advanced network modelling strategies that apply differing types of ai as well as input datasets moatar et al moatar et al 1999 applied solar radiation and discharge levels in predictions of ph with an r2 value equal to 0 86 for predictions of an wdt anfis predictive performance in this research managed better in comparison r2 ranging from 0 88 to 0 96 with ann predictive performance cigizoglu 2004 utilised ann models that were trained and then tested with daily flows for predicting ss concentrations a day ahead with r2 values ranging from 0 75 to 0 81 with upstream flows as inputs a comparable prediction for ss was similarly claimed by zhu et al zhao et al 2007 for predictions of ss the wdt anfis predictive performance in this research managed better in comparison r2 ranging from 0 91 to 0 95 to previous studies the proposed scheme demonstrated efficiency in its predictions of the concentrations of water quality parameters for the johor river which corresponds to the findings of other research the findings also show that the proposed scheme is a useful alternative that offers a comparatively fast algorithm featuring decent theoretical properties for predicting water quality parameters which could be extended to predictions of other water quality parameters 5 conclusion the study proposes the use of enhanced wavelet de noising techniques using neuro fuzzy inference systems wdt anfis according to historical water quality parametric data the effectiveness of each model was examined in order to predict key parameters that could be affected as a result of urbanisation surrounding rivers this area of research accords with the available secondary data for each water quality parameter of johor river the parameters comprise ammoniacal nitrogen an suspended solid ss and ph dual scenarios were presented the first scenario 1 was designed to confirm prediction models for water quality parameters at each stations according to 12 input parameters whereas the second scenario 2 is designed to confirm prediction models for water quality parameters according to 12 input parameters as well as the parametric values from prior upstream stations in evaluating the impact of input parameters on this scheme validation of enhanced wavelet de noising techniques using neuro fuzzy inference systems wdt anfis in accordance with measurements taken from 2009 to 2010 was thereby employed the findings showed the challenge of determining reliable schemes based on mlp ann models from the high variances as well as inherent non linear associations among the water quality parameters that emerge as a result of the stochastic quality and chemical based process furthermore mlp ann was subject to slow convergence during training as a result of the requirement for comparatively large numbers of hidden neurons in the example of rbf ann its predictive capability for water quality parameters in training phases was decent but showed less precision during validation and test phases the findings indicated that anfis determined solutions faster than alternative mlp ann and rbf ann methods and is the most precise and reliable method for processing large volumes of non linear as well as non parametric data of note is the performance of the wdt anfis scheme which exceeded that of anfis and improved predictive accuracy for every quality parameter in that this model achieves higher prediction accuracy overall generally wdt anfis can therefore be seen as having the best network architecture since it outperformed anfis the findings indicate that wdt anfis not only offered a means to improve accuracy but it also features the ability to capture temporal patterns in water quality this enables it to provide meaningful improvements in the generation of forecasts consequently the anfis model appears more capable at capturing the more complex and dynamic processes that are hidden within the data for wqp following enhancement with wdt in comparisons between scenarios 1 and 2 scenario 2 achieved higher accuracy in terms of simulating the patterns and magnitudes for every water quality parameter at every station the suggested wdt anfis model in scenario 2 gave predictions for water quality parameters that ably mimicked patterns dynamics in recorded values aside from extreme outliers observed within this period furthermore validation of wdt anfis according to measurements collected from 2009 to 2010 demonstrated that wdt anfis performed well in predicting both ph and ss concentrations with r2 values of at least 0 9 for every station but for an wherein models still showed decent performances with r2 values lower than 0 9 for station 3 since forecasts of water quality are readily influenced by external environments the acquired model would at times generate findings that deviated much from the observed values in general the methodology of the proposed models development for water quality has proved its effectiveness however it should be highlighted that there are no structured methods today to identify which network structure that can best in predicting water quality parameters moreover the optimal selection of the hyper parameters still requires to be achieved by augmenting the ai model with other advanced meta heuristic optimization algorithms overall this study integrates several analytical and modelling techniques that could become useful to institutions that are committed to river basin management within malaysia furthermore the approach utilised in this research could lay ground for better decision making that assists policy makers in maintaining and improving river basin management declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to appreciate the technical and financial support received from research grant coded j510050822 by innovation research management center irmc universiti tenaga nasional uniten and from research grant coded umrg rp025a 18sus funded by the university of malaya 
6153,in any aquatic system analysis the modelling water quality parameters are of considerable significance the traditional modelling methodologies are dependent on datasets that involve large amount of unknown or unspecified input data and generally consist of time consuming processes the implementation of artificial intelligence ai leads to a flexible mathematical structure that has the capability to identify non linear and complex relationships between input and output data there has been a major degradation of the johor river basin because of several developmental and human activities therefore setting up of a water quality prediction model for better water resource management is of critical importance and will serve as a powerful tool the different modelling approaches that have been implemented include adaptive neuro fuzzy inference system anfis radial basis function neural networks rbf ann and multi layer perceptron neural networks mlp ann however data obtained from monitoring stations and experiments are possibly polluted by noise signals as a result of random and systematic errors due to the presence of noise in the data it is relatively difficult to make an accurate prediction hence a neuro fuzzy inference system wdt anfis based augmented wavelet de noising technique has been recommended that depends on historical data of the water quality parameter in the domain of interests the water quality parameters primarily include ammoniacal nitrogen an suspended solid ss and ph in order to evaluate the impacts on the model three evaluation techniques or assessment processes have been used the first assessment process is dependent on the partitioning of the neural network connection weights that ascertains the significance of every input parameter in the network on the other hand the second and third assessment processes ascertain the most effectual input that has the potential to construct the models using a single and a combination of parameters respectively during these processes two scenarios were introduced scenario 1 and scenario 2 scenario 1 constructs a prediction model for water quality parameters at every station while scenario 2 develops a prediction model on the basis of the value of the same parameter at the previous station upstream both the scenarios are based on the value of the twelve input parameters the field data from 2009 to 2010 was used to validate wdt anfis the wdt anfis model exhibited a significant improvement in predicting accuracy for all the water quality parameters and outperformed all the recommended models also the performance of scenario 2 was observed to be more adequate than scenario 1 with substantial improvement in the range of 0 5 to 5 for all the water quality parameters at all stations on validating the recommended model it was found that the model satisfactorily predicted all the water quality parameters r2 values equal or bigger than 0 9 keywords water quality parameters machine learning wdt anfis 1 introduction rivers are considered as one of the most critical sources of water for irrigation purposes industrial needs and other uses the dynamic nature of the river systems and their easy accessibility for waste disposal make the river systems most vulnerable to the adverse effects of environmental pollution the term water quality refers to the state or condition of water which takes into account the physical chemical and biological properties of the water in conducting the study of any aquatic system modelling the water quality parameters is of utmost significance evaluation and prediction of the surface water quality is necessary for effective management of river basins so that sufficient measures can be adopted to ensure that the pollution levels remain within permissible limits accurate prediction of future phenomena in relation to the water quality is the essence of optimal water resources management the conventional process based modelling methods offer comparatively accurate predictions for water quality parameters however these models have limitations as they depend on data sets that require a substantial amount of processing time and a huge amount of input data that is often unknown nearly 60 of the major rivers in malaysia are used for agricultural household and industrial applications did 2000 as per rosnani ibrahim ibrahim 2001 the major sources of pollution that affect these rivers are dumping of sewage waste releases from medium and small sized industries not having proper waste matter treatment equipment clearing of land and groundwork activities on the basis of the records of 1999 50 catchments that is 42 of river were contaminated with ss suspended solids caused by badly planned and unregulated earth clearing attempts and 33 catchments that is 28 of river were polluted with an ammoniacal nitrogen from activities related to cattle breeding and household sewage dumping johor river is regarded as somewhat polluted as per doe department of environment doe 2007 because of the developmental activities alongside the bank of the river moreover the river continues to be chocked and dumped by waste and litter due to lack of enforcement by the local administration these pollutants ultimately end up in the joho river tributaries rich areas for nourishment and breeding of poultry and fish consequently several statistical frameworks and computer simulations must be introduced as powerful and critical tools for planning and monitoring the maintenance of the water bodies growing concerns regarding environment along with scarce funding are giving rise to a growing interest in cost effective and judicious strategies for the management of water quality since the quality of water directly affects the health of the humans quality improvement of the water accessible for human use will play a significant role in decreasing health related hazards the project of water pollution regulation is based on the management of water quality it estimates the kind of water quality from the present water quality condition as well as from the rules of disposal of the pollutants into the river moreover many models for water quality like stochastic and deterministic models have been created so as to provide best processes to conserve the quality of water hull et al 2008 nevertheless getting efficient and precise water quality model in complex water resources is still difficult because of the variations and complications in the actual world the ambiguities in the framework and variables of the model and the deviations in the field data thus conventional methods for data processing are not sufficiently efficient anymore for solving issues related to the water quality additional efforts are required to improve the consistency of the findings of the model deterministic models try to represent all the chemical and physical processes included in statistical terms with variables acquired either from past data or obtained empirically or computed by experience or examination generally the differential equations are simplified so as to find solutions suitable for the model solution of the involved equations may need suppositions and simplifications which are derived from the performance of the model and usually practical experience is necessitated from the user prior to achievement of optimal outcomes statistical models attempt to seek general rules from the experimental data which can be done by obtaining information from the field data statistical modelling and assessment involve a meticulous selection of techniques for analysis and validation of suppositions as well as data a majority of such models are quite complex and involve a substantial field data amount to conduct the analysis moreover several statistical based models of water quality which assume the association among the prediction and the response variables are distributed normally and linear in nature nevertheless since the quality of water can be impacted by several parameters conventional techniques for data processing are not sufficiently efficient anymore for solving this issue and as such parameters show a complex non linear relation to the water quality prediction parameters thus using statistical techniques generally does not have high accuracy of late the ai artificial intelligence approach has been recognised as an effective alternative method for modelling of complicated non linear systems generally such models do not take into account the internal process but develop models through the inputs and outputs correlation presently ai is used exhaustively for estimating several water related regions muttil and chau 2006 recently ai has offered the techniques for operation optimisation and selection of equipment and problem solving that involve large quantities of data that cannot be processed by humans for the purpose of decision making for this purpose ai methods are proficient to replicate this behaviour and balance the deficiency thus the growth of technology of efficient parallel computing and growing computing power have facilitated the researchers to employ the ai approaches for instance ann artificial neural network and anfis adaptive neuro fuzzy inference system for field data modelling solutions the neuro fuzzy technique has been used effectively in certain fields of water bodies engineering like the rainfall runoff model chang and chen 2001 and basin operation chang and chang 2006 chang et al 2005 anfis has been known to enhance the accuracy of day to day estimation of evaporation kişi 2006 reservoir water level prediction chang chang 2006 and prediction of the river flow firat and güngör 2007 the data obtained from experimentation and examination may be corrupted by signals of noise because of objective and or subjective errors for instance experimental faults may be caused by measuring recording reading and external situations as this noise can possibly distort the model outcomes it is essential to eliminate them i e signal de noising prior to the use of this data the noisy signals can be de noised by applying a series of linear filters bell and martin 2004 nonetheless these filters are more suitable for linear systems rather than the non linear ones moreover the fat fourier analysis technique is a standard tool for de noising though it is only favourable for de noising signals or data involving stable noises in addition as there are unstable noises in real situations it cannot be applied effectively thus to solve the issues of conventional de noising methods more complex methods like the wdt wavelet de noising technique have been recommended above all wdt is effective for de noising multi dimensional temporal or spatial signals having stable or unstable noises also it has been extensively applied to industrial systems for information finding and patterns recognition avci 2007 tirtom et al 2008 nonetheless some of these investigations were employed for water quality monitoring where its data was utilised for estimation of parameters dohan and whitfield 1997 in malaysia wqip requires extensive calculations and transformations two studies have been proposed to use artificial intelligence techniques ai in malaysia in order to develop an accurate predictive model to wqp however many studies show that ai needs pre processing tool to enhance the accuracy of the model practically in dealing with measured water quality data which is often contain noise han et al 2011 the main objective of this investigation is to evolve a computationally proficient and robust method for the estimation of water quality variables decreasing the labour and cost for measurement of those parameters this study focuses on the malaysian johor river situated in johor state where the water quality dynamics are significantly altered this research has many primary objectives as follows to evaluate and assess the correlation among the parameters of water quality on the basis of the experimental data using ann artificial neural network to propose various ann approaches like mlp multi layer perceptron neural network and rbf radial basis function neural network so as to confirm the effectiveness of these techniques in the estimation of the parameters of water quality to get familiar with the correctness of the anfis adaptive neuro fuzzy inference system in the prediction of the parameters of water quality to develop an augmented wdt anfis wavelet de noising technique with the neuro fuzzy inference system to examine the effectiveness of the suggested model for spatial position by presenting two different situations the first situation scenario 1 is designed to set the model prediction at each station pertaining to the water parameters by considering the 13 input parameters from the same station where for scenario 2 the input parameters for this scenario based on the measured water quality parameters from the same station and the predicted parameter from upstream station to validate the augmented wdt anfis wavelet de noising technique with the neuro fuzzy inference system based on the experimental data for the duration 2009 2010 2 case study johor river basin johor state is regarded as the third largest region in malaysia with an area of 19 984 km2 it comprises of eight districts namely are kota tinggi muar pontian johor bahru segamat kluang and lastly batu pahat which is considered as the second largest districts in johor with an area of 187 702 06 ha johor state has five principal rivers which are sungai muar sungai johor sungai endau sungai batu pahat and sungai sedilfi this research sheds the light solely on sungai johor river the johor river basin is located in the southeast of peninsular malaysia at an altitude of 1010 m the johor river orginates from the gunung belumut and from bukit gemuruh at an altitude of 109 m un the north the river has irregular shape its drainage area is around 2636 km2 and its length is approximately 122 7 km the river flows southeast into the johor straits an average annual precipitation of 2470 mm added to the river while during the period of 1963 1992 the annual mean discharge at rantau panjang was found to be 37 5 m3 s the johor river and its tributaries play a significant role as water suppliers for the state of johor as well as for singapore many factors contribute to the deterioration of the water quality of johor river mainly include the release of different kinds of pollutants at levels exceeding the allowed limits with the absence of local authorities enforcement these pollutants travel through johor river and ultimately end in the estuaries of the rivers which are known to be a natural feeding area for poultries and fishes and a natural environment that provide spawning fig 1 depicts the location map of the surveying area which compromises of four monitoring stations on johor river 3 methodology 3 1 multi layer perceptron neural network mlp ann a feed forward network is the multi layer perceptron neural network mlpnn that includes many layers of neurons where one neuron s output is propagated to the other neuron s input that is in the next layer fig 2 presents the multi layer perceptron neural network in mlpnn the input layer s nodes only propagate the input values of the first hidden layer s nodes in the hidden layers each node s input output relationship can be presented as follows 1 y f j w j x j b where x j signifies the output from the previous layer s j node w j denotes the connection weight between the current node and j node b represents the current node s bias and f defines a non linear transfer function usually of the sigmoid form as shown in eqs 3 4 2 f z 1 1 exp z where z denotes the weighted sum pertaining to the input to the neuron and f z signifies the neuron output the output nodes input output relationship is comparable to the one defined by eqs 3 4 with the exception of the case where the network is employed for function approximation and the type of function f could vary e g linear function the units define a mlpnn architecture which allows computation of a non linear function in terms of the scalar product pertaining to the weight vector and input vector overall the mlpnn models performance relies on the network s inherent architecture apart from the number of hidden layers as well as the number of neurons pertaining to each layer it also includes the computation type applied to each neuron 3 2 adaptive neuro fuzzy inference system anfis jang 1993 first put forward the adaptive neuro fuzzy inference system anfis that allowed realising a highly non linear mapping and compared with common linear methods it is considered to be superior in yielding non linear time series jang 1993 the anfis architecture was employed throughout this research for the first order sugeno fuzzy model sugeno and kang 1988 anfis can be defined as a multi layer feed forward network that employs neural network learning algorithms as well as fuzzy reasoning to aid in mapping input space with that of the output space chang and chang 2006 considering that for a first order sugeno fuzzy model the fuzzy inference system has one output f and two inputs x and y a common rule set that includes two fuzzy if then rules can be defined as follows 3 rule 1 i f x i s a 1 a n d y i s b 1 t h e n f 1 p 1 x q 1 y r 1 4 rule 2 i f x i s a 2 a n d y i s b 2 t h e n f 2 p 2 x q 2 y r 2 where a1 a2 and b1 b2 signify the membership functions mfs pertaining to inputs x and y respectively pi qi and ri i 1 or 2 represent the linear parameters pertaining to the first order sugeno fuzzy model s consequent part fig 3 a represents the fuzzy reasoning mechanism pertaining to this sugeno model that also allows deriving the output function f from that of inputs x and y fig 3 b presents the corresponding equivalent anfis architecture in which similar functions are associated with the same layer s nodes anfis comprises five layers as stated below 3 3 wavelet de noising the next logical step is characterised by wavelet analysis post the short time fourier transforms stft this is with regards to the windowing technique that includes variable sized regions with the help of wavelet transform wt long time intervals can be employed in those areas where more precise low frequency information is needed as well as for shorter regions in which high frequency information is needed overall the key benefit provided by the wavelets is allowing conducting local analysis for localised area pertaining to a larger signal the discrete time wt pertaining to a time domain signal x k can be expressed as follows dohan and whitfield 1997 5 d w t m n 1 2 m k x k ψ 2 m n k here n defines the mother wavelet while m represents the scaling and k denotes the shifting indices the dwt logarithmic frequency coverage is provided through scaling as opposed to the uniform frequency coverage of stft this analysis technique includes segmenting a signal into components at various frequency levels which are linked by the powers of two a dyadic scale the filtering approach that is applied to multi resolution wt involves formation of a series of half band filters that segment a spectrum into low and high frequency bands the formulation is based on a wavelet function or high pass up filter as well as a scaling function or low pass lp filter wavelet multi resolution analysis wmra allows constructing a pyramidal structure that needs an iterative application of wavelet functions and scaling to high pass and low pass filters respectively at the beginning these filters are first applied to the entire signal band under high frequency small scale values and then the signal band is decreased at every stage gradually as presented in fig 4 the detail coefficients of dl d2 and d3 define the high frequency band outputs while the approximation coefficients of al a2 and a3 define the low frequency band outputs numerous factors need to be accounted when wavelets are employed to de noise the wqp data examples of such choices include the level of decomposition wavelet and thresholding methods to be employed matlab provides various families of wavelets such as morlet meyer mexican hat coiflets haar symlets daubechies and spline biorthogonal wavelets and also offers additional documentation regarding these wavelet families wavelet toolbox matlab 2019 only orthogonal wavelets need to be accounted to get perfect reconstruction results certain advantages are associated with the orthogonal wavelet transform it can be characterised as being relatively concise permitting perfect reconstruction of the original signal and relatively easy to calculate the two common employed approaches for thresholding a signal include hard thresholding and soft thresholding which are employed in the matlab wavelet toolbox although the easiest method is hard thresholding better results are achieved through soft thresholding versus hard thresholding thus this study uses soft thresholding four threshold selection rules can be used with the wavelet toolbox which employ statistical regression pertaining to the noisy coefficients over time that allows getting a non parametric estimation regarding the reconstructed signal absent noise this study examined just sqtwolog wherein a fixed form of threshold is employed leading to minimax performance that is multiplied by a factor proportional of signal length s logarithm in this research in terms of the decomposition level we can conclude that a level 4 decomposition offered reasonable results post applying the trial and error method to all modules 3 4 model performance evaluation it is necessary to clearly recognise the criteria that are associated with judging the model s performance the criteria employed to assess the performance of the model in this study were clearly mentioned in the literature dogan et al dogan et al 2009 employed the average absolute relative error aare which not only provides the performance index with regards to predicting water quality parameters but also demonstrates the prediction errors distribution to examine the performance of the model singh et al 2009 employed the bias statistical index the bias signifies the mean of all the individual errors as well as allows determining if the dependent variable is underestimated or overestimated by the model in this study correlation coefficient as well as root mean square error rmse was employed to examine the model s performance soyupak et al 2003 zhao et al 2007 usually the model performance is assessed through coefficient of determination as put forward by nash and sutcliffe 1970 while mse is employed to check the level of fitness between the network output and desired output in this research work the models performances were assessed based on three statistical indexes as mentioned by nash and sutcliffe 1970 coefficient of efficiency ce is commonly employed to assess the performance of the model 6 ce 1 i 1 n x m x p 2 i 1 n x m x m 2 where n represents the number of observations x m and x p define the measured and predicted parameters respectively and x m signifies the average of measured parameter mean square error mse is employed to see the level of fitness between network output and the desired output better performances are guaranteed with smaller mse values it is defined as follows 7 mse 1 n i 1 n x m x p 2 more commonly the coefficient of correlation cc is employed to examine the linear relationship between the measured and predicted dissolved oxygen this can be expressed as follows 8 cc i 1 n x m x m x p x p i 1 n x m x m 2 i 1 n x p x p 2 further for visual comparison of the predicted and measured values the scatter plot was employed kuo et al 2007 3 5 input variables and data processing one of the key functions of ann is to identify the model input parameters that could impact the output parameters considerably as indicated above the selection of input parameters depends on a priori knowledge regarding causal variables as well as statistical analysis pertaining to the potential outputs and inputs in the literature different input parameters were employed to develop the model to determine water quality parameters as presented in table 1 on the basis of the literature the following water quality parameters were chosen for ann modelling temperature temp electrical conductivity cond salinity sal nitrate no3 turbidity turb phosphate po4 chloride ci potassium k sodium na magnesium mg iron fe and escherichia coli e coli the basic statistical parameters i e mean minimum maximum standard deviation s d and coefficient of variation cv of the input and output parameters deployed in this study are depicted in tables 2 and table 3 based on the concentration levels of both output and input parameters large changes between the samples were seen along with a high coefficient of variation i e 254 94 for an and 325 96 for e coli the coefficient of variation cv can be defined as a measure of statistical dispersion pertaining to the data for a given data set it is the mean normalised standard deviation cv that can be computed as standard deviation mean 100 the existence of large disparity in the parameters concentrations can be attributed to the types non point and point and nature of sources that have been distributed in the river basin s wide geographical area during the course the river flows through different townships and many tributaries and wastewater drains pouring large quantities of untreated wastewater into the river s main channel a coefficient of variation in the range of 3 08 and 325 96 was seen with the parameters such variability that exists amongst the samples could be due to large geographical variations in climate as well as seasonal effects pertaining to the study region for the various sampling sites a spatial and significant variation was seen in terms of johor river s turbidity which varied from 0 2 to 343 ntu it was higher which could because of the mixing of industrial effluents and domestic sewerage water in johor river the rise in turbidity near downstream sites can be attributed to settling factors and flow turbulences at downstream sites the observed trend of turbidity i e sn02 sn03 and sn04 was seen to support the above mentioned hypothesis comparable patterns pertaining to spatial variations in turbidity were reported by khadse et al 2007 when investigating kanhan river s water quality amongst the sampling sites the conductivity of the johor river water was found to be considerably different in which the mean ranged from 54 to 64 μs although least significant difference was between sn01 and sn03 the high conductivity at sn04 and sn02 sites signify sewerage mixing into the river water the dilution of industrial and urban runoffs could be attributed to the lower conductivity seen in the downstream water nitrate is considered to be a crucial parameter of river water that could be an indicator for the pollution status and anthropogenic load in river water the mean of nitrate ranged from 0 66 to 163 5 mg l for johor river at the site wherein urban runoff mixing was noticed no3 was seen to be the maximum it is interesting to note that in the downstream non point pollution sites lower no3 was seen the concentration of chloride in water was deemed not to be harmful a higher concentration of chloride found in freshwater signified that pollutants are present moreover in johor river the chloride level fell in the range of 5 27 to 7 37 mg l nonetheless at various sampling sites a clear trend was not seen with chloride concentration in terms of the non point or point pollution sites the mixing of industrial effluents or urban wastewater in the river water is signified by higher levels of chloride content at sn04 ph of water indicates alkaline and acidic conditions doe doe 2007 suggested that ph for water in the range of 6 5 8 5 can be employed for any purposes in that respect the ranges showed that johor river had moderately alkaline water the change in mean ph ranged from 6 22 to 6 36 at various locations at some sites higher ph could be a result of carbonate and bicarbonates of magnesium and calcium in water the key source pertaining to such chemicals include industrial wastewater or urban runoff ss further signifies the river water s salinity behaviour the mean ss content pertaining to river water was found in the range of 72 61 to 91 01 mg l the chemical and biological oxygen demand increase in tandem with higher ss level in the water system which ultimately results in depletion of the dissolved oxygen level in water in water ss stems from natural sources industrial wastewater urban runoff sewage and chemicals employed in the water treatment process for the current neural network modelling the second assessment of selecting the input parameters is done by considering a statistical correlation analysis pertaining to the field data calculation of the correlation coefficient existing between the input and output parameters was done and listed in table 4 based on the table ph was clearly seen to be inversely associated with water temperature r 0 306 as well as potassium r 0 425 we performed an experiment by taking water quality variables that were accounted along with the parameters mentioned above pertaining to various models to realise the optimal predictive model as well as reduce the monitoring cost by accounting for fewer input parameters 3 6 stopping criteria normally there is a gradual decrease in the training error of ai since the training process is on going nonetheless this minimisation of training error does not guarantee enhancement of generalisation ability which gained our interest it is not necessary that ai showing good performance with the training set will do the same with the testing data therefore it is also sometime important to stop the training phase at the right time before over fitting occurs when a generalisation characteristic is lost by the neural network an over fitting issue follows however relations between the training inputs as well as their associated outputs to similar hidden patterns pertaining to the unobserved data cannot be generalised thus this occurs as a result of a difficult question that asks how long a network needs to be trained the issue of over fitting is usually solved by employing techniques like weight elimination weight decay and early stopping stopping criteria is the most commonly employed method to address this issue as noted by numerous researchers e g singh et al 2009 palani et al 2008 two frequently employed stopping criteria include stopping post a specific number of runs via the complete training data it needs to be noted that an epoch is defined as each run that passes through the complete training data and stopping on reaching some low level by the target error 3 7 different scenarios two different scenarios have been proposed in this study the concept behind the development of these both scenarios is based on the spatial pattern of the input output structure of the model mainly the reason behind proposing these scenarios is to examine the model performance considering the spatial dimension of the model input keeping in mind that the model output in both scenarios is the prediction values of the an ph and ss the input patterns has been changed in terms of the number of the inputs and location of the monitored data in order to clarify the structure and show the difference between these two scenarios an example for the structure of both scenarios to predict the an parameter will be presented for scenario i to predict an parameter at certain station different twelve input parameters were used that have been acquired at the same station while the structure of scenario ii is developed as in addition to the same twelve water quality parameters used as inputs in scenario i the value of an parameter that has been acquired from the upstream station will be added the prediction procedure can be defined as an operation that allows offering water quality parameter patterns for the future this research employs the wdt anfis along with its stochastic and non linear modelling capabilities to design a prediction model that mirrored the water quality parameter patterns pertaining to johor river with regards to the 12 input parameters scenario 1 cited earlier which is represented as follows 9 wqi p n f wdt a n f i s t e m p n c o n d n s a l n t u r n n o 3 n c i n p o 4 n f e n k n m g n n a n e c o l i n n 1 2 3 4 where wqipn signifies the water quality index parameters pertaining to station n and fwdt anfis defines the non linear function predictor built via the wdt anfis network thus at each station four models were built for predicting the parameters for water quality a majority of the recent studies were aimed at predicting the concentrations pertaining to the parameters of water quality at every station usually discharge via the local area from the upstream station causes an impact on the water pollution pertaining to a downstream station zaqoot et al 2009 therefore in the put forward model it was important to consider the impact cast by water parameters at the upstream station thus the second scenario scenario 2 was designed to set the model prediction at each station pertaining to the water parameters by considering the 13 input parameters at the previous station upstream the predicted wqip could be represented by following eq 10 repetition of this procedure involving the predicted wqip is done for the fourth and third stations at downstream fig 5 presents a schematic representation pertaining to the put forward networks for scenario 2 10 wqi p n 1 f wdt a n f i s t e m p n c o n d n s a l n t u r n n o 3 n c i n p o 4 n f e n k n m g n n a n e c o l i n w q i p pn 4 results and discussion 4 1 mlp ann training the construction of an ann model normally includes three steps the training stage is the first step in which the network is exposed to a training set pertaining to the input output patterns the second step involves the validation stage in which the network s performance is evaluated when patterns are not observed by the network in the training stage the third step includes the testing stage in which the network s performance is evaluated when the unknown patterns were not observed during the stages of validating and training bowden et al 2005 designing of three mlp ann architectures was done one for each parameter the levenberg marquardt back propagation algorithm lma is employed by all three networks in the entire training procedure this study employed three activation functions namely tan sigmoidal tansig log sigmoidal logsig function and linear transfer function purelin after initialising the network weights and biases during the training process iterative adjustments of the weights and biases pertaining to the network were carried out to decrease the network performance function pertaining to mean square error mse the average squared error between the target outputs and the network outputs we introduced different values of learning rate lr to the networks in a bid to achieve the optimum result pertaining to this study for back propagation learning algorithm the learning rate is important as it helps determine the level of weight changes however since the learning process tends to slow down when smaller learning rate values are employed for training it is not a favoured choice employing larger learning rates values for training could lead to network oscillation in the weight space one approach to enhance the gradient descent method is by introducing an additional momentum parameter mc that facilitates larger learning rates leading to faster convergence while decreasing the oscillation tendency rumelhart et al 1986 the momentum term is introduced so that the next weight changes are similarly aligned to the same direction as the previous one which allows minimising the oscillation impact of larger learning rates although there are certain systematic approaches to simultaneously choose the learning rate and momentum the best values pertaining to these learning parameters are normally selected based on experimentation since any value falling between 0 and 1 can be accounted by the learning rate and the momentum it becomes almost impossible to perform an exhaustive search to detect the best combinations pertaining to these training parameters in this research paper we evaluated different momentum and learning rates pertaining to both networks in real practice 0 9 and 0 95 were selected as momentum and optimum learning rate pertaining to ss an and ph models respectively 4 2 optimisations of the neurons number the number of neurons in the hidden layer is the key characteristic pertaining to ai technique the network fails to model the complex data that could lead to poor fitting if the number of neurons employed is insufficient on the flip side the training time could become unreasonably long as well as the network may also over fit the data if there are too many neurons employed in this paper to investigate the best performance various mlp ann architectures were employed in fact a formal and or mathematical approach does not exist which allows determination of appropriate optimal set pertaining to neural network s key parameters thus the trial and error method was selected to perform this task randomisation of the hidden layer s neurons was done from n 1 to 20 neurons in the hidden layer the best numbers of nodes are those that provide the lowest error lek et al 1996 based on two performance indices determination of the optimum number of neurons was done the root mean square error rmse value pertaining to the prediction error is the first index while the value of the maximum error is the second index to get both indices the ann model was evaluated by considering the wqp data between 1998 and 2007 when building such a predicting model that employs the neural network the model could do well during the training period and could give a higher level of error when assessment was done during either the testing or validation period based on this study these performance indices were employed to ensure that the put forward model would offer consistent accuracy levels during all periods as the performance indicator for the put forward model the key benefit of using these two statistical indices is to ensure that the highest error falls within the acceptable error range for the forecasting model when the performance is being evaluated this is done when rmse is employed and making sure that the summation of the error distribution is not high in the validation period consequently employing both indices ensures consistent level of errors and offers high potential to maintain the same error level while evaluating the model for unseen data during the testing period when the number of hidden neurons to the network is varied it has a clear impact to a considerable degree on the prediction performance it clearly demonstrates that there is a rise in prediction performance with increase in the number of hidden neurons from 1 to 18 along with subsequent decrease in rmse and maximum error pertaining to all parameters however a drop in prediction performance occurred when hidden neurons were added further 19 to 20 to the network for instance it can be seen that the best combination pertaining to the put forward statistical indices to examine the predicting model for the ph was when 18 neurons with rmse 0 15 were associated with the ann architecture and a maximum error as 3 22 the best combination pertaining to the put forward statistical indices to examine the predicting model for the ss was when 17 neurons with rmse 0 30 were associated with the ann architecture and a maximum error of 3 46 table 5 lists out the optimal numbers of neurons pertaining to the remaining parameters 4 3 water quality prediction model of mlp ann the mlp ann model for the estimation of the 6 parameters of water quality as the output which are ss an and ph was evaluated in this section fig 6 depicts the measured and estimated parameters of water quality for the most excellent network which provided the most precise estimation on the whole the predictive capability of this model was fairly good for each of the parameters of the water quality in the training duration though less accurate when the validation and testing stages were carried out the findings showed that it was challenging to develop a consistent model using the mlp ann models due to high variations and intrinsic non linear correlation among the parameters of the water quality because of the probabilistic nature and chemical procedure additionally the mlp ann models encountered delayed convergence during the training because of the necessity of comparatively a huge amount of hidden neurons also several researchers observed that these models failed to acquire values lying outside the scope of values included in the calibration data of mlp ann boundary values campolo et al 1999 dawson and wilby 1998 hsu et al 1995 karunanithi et al 1994 minns and hall 1996 this constraint arising chiefly due to the application of a logistic function to translate the output of the model makes these models inappropriate for several applications alternatively the rbf ann radial basis function network is commonly employed for strict interpolation issues in space with multiple dimensions which has equivalent abilities as the mlp ann in solving problems related to function estimations park and sandberg 1993 there are chiefly 2 benefits of the rbf ann a network training in shorter duration in comparison to mlp ann and b best solution estimation without managing the local minimums in addition rbf ann works as a local network in contrast to the feed forward networks which are global mapping networks also rbf ann employs one processing units set and every unit is most accessible to a local area of the input region due to this rbfns are employed more recently as a substitute nn model in function estimation applications and prediction of time series sheta and de jong 2001 yu et al 2008 thus the following section describes the attempt to get familiar with rbf ann suitability to be used as a model for predicting the parameters of water quality 4 4 sensitivity analysis to assess the input variables impact on the model 3 assessment methods were used first method was based on dividing the nn connection weights so as to establish the relative significance of every input variable in the network stern and garson 1999 in this research the recommended network comprises 12 environmental variables presuming the connection weights from the input nodes to the hidden nodes exhibit the relative predictive significance of the independent parameter the significance of every input parameter can be articulated as follows 11 ij m 1 m n h w jm ih k 1 ni w km ih w mn ho k 1 k n i m 1 m n h w jm ih k 1 ni w km ih w mn ho where ij represents the relative significance of jth input variable on the output variable ni and nh denote the quantities of input and hidden neurons correspondingly and w represents the connection weight also the superscripts i h and o signify the input hidden and output levels correspondingly while the subscripts k m and n signify the input hidden and output neurons correspondingly the first method of evaluation was to assess the relative significance of every input variable as calculated by eq 11 and illustrated in fig 7 the relative significance demonstrates the importance of a variable in comparison to the other variables belonging to the model even though the network did not essentially signify physical sense using weights it indicates that all the variables had intense effects on the estimation of all output variables in which the estimator contribution varied from 5 to 14 apparently the most useful inputs were considered to be those that involved oxygen containing nitrate no3 and phosphate po4 conversely ph and temp were discovered to be the least useful parameters additionally mg proved to be providing the greatest contribution for the recommended model for an for ph it was apparent that the most useful input was temp 4 5 water quality prediction model of anfis as a matter of fact among the difficulties in anfis based modelling is establishing its variables for optimal learning i e the membership function number and step size s initial value before training in a way that the optimal training is achieved two techniques have been proposed by several researchers for establishing these variables in anfis optimisation techniques hassanain et al 2004 and the trial and error approach kim et al 2002 while determining the variables for optimal learning could be ensured by the optimisation algorithms i e derivative based or derivative free optimisation this alternative has a downside of being computationally costly conversely the trial and error technique has been confirmed to be effective in case the target root mean square error can be realised this technique is also advantageous as it yields a knowledge rule base having a lower possibility of surpassing the data set of training in comparison to the optimisation technique thus this research did not include the optimisation technique and established the variables for optimal learning of anfis through the trial and error technique for every parameter related to the water quality this study employed the architectures proposed in the preceding section in which 12 inputs were utilised to estimate the wqip it is noteworthy that there is no systematic technique to establish the optimal quantity of mfs the optimal quantity of mfs is generally established inductively and validated empirically thus the quantity of mfs was selected using the trial and error method meanwhile it is to be observed that this study had tested 4 kinds of membership functions a triangular b gaussian c trapezoidal and d bell shaped to compose the fuzzy numbers following several trials the outcome revealed a distributed membership function having bell shaped nature in comparison to others which had acquired the minimal relative error table 6 demonstrates the kinds and quantity of mfs that were implemented in this study to develop the modules for demonstrating the performance of the suggested anfis model an evaluation of predicted against observed parameters of water quality during training validation and experimentation phases is displayed in the fig 8 it is apparent that the suggested anfis model procedure provided the estimated variables that mimicked the dynamics pattern in the noted values besides those boundary values measured during this time 4 6 water quality prediction model of wdt anfis the above findings were obtained with the general assumption that the mined data must be precise and reliable nevertheless the data acquired from the study test and simulation procedures may be corrupted by noise because of objective and or subjective errors li and shue 2004 for instance the errors arising in the experiment may be caused by measuring recording reading or external scenarios the errors from simulation might cover uncertainties of the model and parameters as well as computational errors as these noisy signals possibly distort the data mining outcomes it is necessary to eliminate them i e signal de noising process before the use of any initial data thus an augmented wdt anfis based on historical information for wqpp will be presented training and cross validation processes of the model of wdt anfis were carried out to reduce the root mean square error among the output as well as predicted responses the wdt anfis model outperformed the anfis model and provided improvement in estimation accuracy of all the variables while the anfis model performed inefficiently as the noise intensity increased it was obvious that wqp possibly had more accurate estimation values due to de noising of data this suggests the wdt superiority in data cleaning despite the occurrence of errors during stages of training validation and experimentation which were regarded as considerably high in comparison to the training and cross validation stages it had obtained a high precision for all variables the findings displayed in fig 9 demonstrate that the wdt anfis model could be regarded as a suitable technique for modelling for estimation like wqp 4 7 comparative analysis the models introduced in prior discussion were all compared for the purpose of providing precise predictions for each water quality parameter at johor river similar findings were achieved in determining models for predicting suspended solids concentrations ss wherein wdt anfis forecast ss with comparatively less accuracy in which errors for most records were below 10 peak ss values were more closely approximated using wdt anfis in comparison to that attained using other techniques as depicted in fig 10 the numbers of inaccurate ss forecasts decreased meaningfully using wdt anfis the use of physics based distributed processing in complex computer software is frequently problematic owing to the usage of idealised sedimentation components or the requirement of large volumes of detailed temporal and spatial data on the environment which is not always available cigizoglu 2004 it should be noted that ai approaches to determining suspended sediment data estimations remain sparse in the relevant literature abrahart and white 2001 the success attained in modelling dynamic systems implies that this strategy may well provide an efficient and productive means for simulating complex suspended sediment processes in rivers under conditions where precise knowledge of internal sub processes is not necessary each proposed model in this study was constructed on the assumption that land cover use would remain unchanged during this research however land cover use remains an important factor in the production and transport of sediments along with other factors more precise predictions of suspended sediments may be attained by including variables that represent land cover use status into the scheme we are planning such analytical studies soon enough in conclusion this research establishes wdt as an appropriate method along with classical anfis for modelling suspended sediments in river environments it is therefore worth considering the use of wdt anfis approaches in such analysis given the findings of studies regarding the physics embedded in anfis structures with regards to ph fig 11 depicts comparisons between anfis and other models performances based on the test data set in the figure it is clear that anfis performance exceeds that of the two ann methods furthermore the effort reveals the challenges in devising reliable schemes based on mlp ann rbf ann models as a result of the high variances as well as the inherent non linear associations among the water quality parameters as a result of the stochastic quality and chemical based process furthermore as depicted in fig 10 the findings show that wdt anfis based modules outperform anfis and also have the ability to improve predictive accuracy for ph albeit for mae with comparatively lesser accuracy whereby errors for most records were below 7 otherwise inefficient executions were observed based on the anfis module wherein most errors were above 15 clearly given increases in noise intensities wqp offers more precise predictions from data de noised with wdt than data without such de noising this suggests the advantage of using wdt to clean the data it is fact that the training process for big data using any of ai models is both time consuming and computation and memory intensive especially when several number of model inputs variables is used the computer specification that have been used to run models are intel processor core i7 12 m cache up to 4 60 ghz and ram 16 gb it is fact that in our study the data used is not big data to be considered as problem to the computational memory however due to the fact that the number of the model input variables is relatively big twelve or thirteen based on the structure of scenario i and scenario ii respectively the training process is slightly time consuming to achieve the performance goal table 7 summarize the training time for each models in seconds where it is noticeable that the anfis and wdt anfis models consuming more time than ann models mlp and rbf but it is still minimal 4 8 scenarios the comparatively low correlation among forecast and observed values during test phases was perhaps a result of the non homogenous nature of water quality parameters moreover ying et al zhao et al 2007 demonstrated that the selection of influential factors namely input parameters has a critical role as these factors greatly affect forecasts clearly the low correlations in this research can be attributed to the realisation that its input parameters had not included every relevant parameter furthermore pollution levels at downstream stations were associated with discharge from upstream stations to overcome this difficulty the researchers applied another approach i e scenario 2 such that higher levels of accuracy could be attained this strategy is associated with the prediction of each water quality parameter given the actual values measured at upstream stations as model inputs as described by eq 12 for a most appropriate analysis the researchers implemented an accuracy improvement ai index for the correlational coefficient statistical index in order to determine the significance of scenario 2 as against scenario 1 described as follows 12 ai c c s c e n 2 c c s c e n 1 c c s c e n 2 100 wherein ccscen2 denotes the coefficient of correlation for scenario 2 whereas ccscen1 denotes a similar statistical index for scenario 1 from table 8 it is clear that scenario 2 is more satisfactory than scenario 1 with meaningful improvements observed in every station which ranged from 0 5 to 5 predictive accuracy was meaningfully enhanced after introducing scenario 2 for every station as in the case for ph scenario 2 showed more satisfactory performance than scenario 2 with meaningful improvements observed in ai which ranged from 3 in station 2 to 5 in station 3 conversely less improvement was gained with an wherein ai was equal to 0 5 in stations 1 and 3 even though it is clear that scenario 2 was less efficient with an accuracy does increase by 2 once it is applied to station 3 furthermore the findings indicate that scenario 2 not only showed improved accuracy for certain parameters but this particular model had the ability to capture temporal patterns in water quality parameters this enabled the scheme to apply meaningful improvements to station scenarios 4 9 model validation models must be verified whenever resulting outputs and observed values are near enough to satisfy all validation criteria palani et al 2008 to investigate the effectiveness of this proposed scheme validation of the enhanced wavelet de noising method using the neuro fuzzy inference system wdt anfis in accordance with field measurements collected from 2009 to 2010 is therefore applied the scatter plots among the forecast and observed values for all 5 selected parameters for water quality are depicted in fig 12 clearly the majority of forecast water quality parameters had closely approximated actual observations as well r2 must be as near 1 as possible with values that exceed 0 9 implying very satisfactory model execution values from 0 6 to 0 9 implying fairly good execution and values below 0 5 indicating unsatisfactory execution based on these criteria the wdt anfis model s ability to predict both ph and ss concentrations is very satisfactory in that r2 values are at least 0 9 for every station but for an wherein models showed merely decent performances in that r2 values were below 0 9 for station 3 based on these findings wdt anfis can be said to demonstrate good predictive performance for predictions of water quality parameters using ai other researchers have advanced network modelling strategies that apply differing types of ai as well as input datasets moatar et al moatar et al 1999 applied solar radiation and discharge levels in predictions of ph with an r2 value equal to 0 86 for predictions of an wdt anfis predictive performance in this research managed better in comparison r2 ranging from 0 88 to 0 96 with ann predictive performance cigizoglu 2004 utilised ann models that were trained and then tested with daily flows for predicting ss concentrations a day ahead with r2 values ranging from 0 75 to 0 81 with upstream flows as inputs a comparable prediction for ss was similarly claimed by zhu et al zhao et al 2007 for predictions of ss the wdt anfis predictive performance in this research managed better in comparison r2 ranging from 0 91 to 0 95 to previous studies the proposed scheme demonstrated efficiency in its predictions of the concentrations of water quality parameters for the johor river which corresponds to the findings of other research the findings also show that the proposed scheme is a useful alternative that offers a comparatively fast algorithm featuring decent theoretical properties for predicting water quality parameters which could be extended to predictions of other water quality parameters 5 conclusion the study proposes the use of enhanced wavelet de noising techniques using neuro fuzzy inference systems wdt anfis according to historical water quality parametric data the effectiveness of each model was examined in order to predict key parameters that could be affected as a result of urbanisation surrounding rivers this area of research accords with the available secondary data for each water quality parameter of johor river the parameters comprise ammoniacal nitrogen an suspended solid ss and ph dual scenarios were presented the first scenario 1 was designed to confirm prediction models for water quality parameters at each stations according to 12 input parameters whereas the second scenario 2 is designed to confirm prediction models for water quality parameters according to 12 input parameters as well as the parametric values from prior upstream stations in evaluating the impact of input parameters on this scheme validation of enhanced wavelet de noising techniques using neuro fuzzy inference systems wdt anfis in accordance with measurements taken from 2009 to 2010 was thereby employed the findings showed the challenge of determining reliable schemes based on mlp ann models from the high variances as well as inherent non linear associations among the water quality parameters that emerge as a result of the stochastic quality and chemical based process furthermore mlp ann was subject to slow convergence during training as a result of the requirement for comparatively large numbers of hidden neurons in the example of rbf ann its predictive capability for water quality parameters in training phases was decent but showed less precision during validation and test phases the findings indicated that anfis determined solutions faster than alternative mlp ann and rbf ann methods and is the most precise and reliable method for processing large volumes of non linear as well as non parametric data of note is the performance of the wdt anfis scheme which exceeded that of anfis and improved predictive accuracy for every quality parameter in that this model achieves higher prediction accuracy overall generally wdt anfis can therefore be seen as having the best network architecture since it outperformed anfis the findings indicate that wdt anfis not only offered a means to improve accuracy but it also features the ability to capture temporal patterns in water quality this enables it to provide meaningful improvements in the generation of forecasts consequently the anfis model appears more capable at capturing the more complex and dynamic processes that are hidden within the data for wqp following enhancement with wdt in comparisons between scenarios 1 and 2 scenario 2 achieved higher accuracy in terms of simulating the patterns and magnitudes for every water quality parameter at every station the suggested wdt anfis model in scenario 2 gave predictions for water quality parameters that ably mimicked patterns dynamics in recorded values aside from extreme outliers observed within this period furthermore validation of wdt anfis according to measurements collected from 2009 to 2010 demonstrated that wdt anfis performed well in predicting both ph and ss concentrations with r2 values of at least 0 9 for every station but for an wherein models still showed decent performances with r2 values lower than 0 9 for station 3 since forecasts of water quality are readily influenced by external environments the acquired model would at times generate findings that deviated much from the observed values in general the methodology of the proposed models development for water quality has proved its effectiveness however it should be highlighted that there are no structured methods today to identify which network structure that can best in predicting water quality parameters moreover the optimal selection of the hyper parameters still requires to be achieved by augmenting the ai model with other advanced meta heuristic optimization algorithms overall this study integrates several analytical and modelling techniques that could become useful to institutions that are committed to river basin management within malaysia furthermore the approach utilised in this research could lay ground for better decision making that assists policy makers in maintaining and improving river basin management declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to appreciate the technical and financial support received from research grant coded j510050822 by innovation research management center irmc universiti tenaga nasional uniten and from research grant coded umrg rp025a 18sus funded by the university of malaya 
6154,in this study we propose a nonlinear attachment detachment model with hysteresis for the transport of suspension colloidal particles sps in porous media the proposed model uses an adsorption function and scanning desorption isotherms to model the deposition process of sps this model shows that increasing or decreasing the seepage velocity results in substantial changes in the penetration concentration of sps which is closely related to the adsorption hysteresis and the deposition dynamics of sps studies show that previous linear attachment detachment models probably result in an overestimation of the adsorption capacity of porous media static deposition tests and dynamic transport experiments using pulse injection were performed to calibrate the transport parameters the effects of the seepage velocity injection concentration and particle size on the transport parameters and reaction rate constant were investigated experiments were also performed under variable injection concentrations and seepage velocities the results show that there is good agreement between the simulated and experimental breakthrough curves btcs keywords attachment detachment model hysteretic effect nonlinear process variable concentration unsteady flow 1 introduction the transport and deposition of substances such as soluble ions heavy metal pollutants bacteria and suspension colloidal particles sps in porous media is an important yet challenging topic in environmental geotechnics bedrikovetsky et al 2017 daghooghi and borazjani 2018 katzourakis and chrysikopoulos 2019 wyness et al 2018 as well as in many other fields such as groundwater exploitation water purification changes in the permeability of porous media petroleum exploration and the cotransport of pollutants akrouch et al 2016 chen et al 2018 shang et al 2013 a number of factors have been reported that affect the transport and deposition of sps such as the properties of the porous media and sps e g size morphology and concentration chemical composition of the solution ph and flow velocity ahfir et al 2009 bradford et al 2017 chrysikopoulos and katzourakis 2015 li et al 2018 wyness et al 2018 some laboratory experiments have been conducted in an effort to elucidate the transport processes of sps with different sizes shapes and injection concentrations in different porous media bennacer et al 2017 massei et al 2002 wang et al 2000 ahfir et al 2017 investigated the effects of the grain size distribution of the porous medium on the transport and deposition of polydispersed sps in a plexiglass column with an inner diameter of 4 4 cm and a length of 62 cm bai et al 2015 derived analytical solutions for contaminant transport in a semi infinite saturated porous medium using laplace and fourier transform techniques and investigated the effects of particle size concentration and flow velocity on the transport of contaminants later bai et al 2017 investigated the effects of flow velocity and the concentration of oh ions on the penetration processes of red mud filtrate in a porous medium however the transport of sps has been found to be characterized by first order deposition kinetics in most previous studies bai et al 2017 ahfir et al 2017 but this finding may be only applicable to the transport of sps under the conditions of constant flow velocity boundary concentration and particle size a key problem in understanding the transport of soluble pollutants and sps is the mathematical description of their nonlinear attachment detachment processes which involve temporal and spatial changes in the seepage velocity and in the size ma et al 2018 and concentration of the sps gavrilov and shebelev 2018 as well as complex physical and chemical processes caused by changes in the pore structure of the porous media daghooghi and borazjani 2018 li et al 2018 cinzia and luisa 2015 simulated the migration of radionuclides in the far field of a geological repository in a nonuniform groundwater flow field and investigated the effects of the distribution coefficient and hydraulic gradient farajzadeh et al 2016 proposed a filtration theory describing the mechanical entrapment on the polymer flow through porous media which was coupled to the langmuir equilibrium adsorption model bedrikovetsky et al 2017 investigated the release effect of sps in a porous medium under different flow velocities and derived an exact solution for the long term nonlinear injection of particles katzourakis and chrysikopoulos 2018 numerically investigated the effect of the spatially variable attachment coefficient on biocolloid transport in a heterogeneous porous stratum with a three dimensional mathematical model that they developed russell and bedrikovetsky 2018 proposed a method for the solution of colloid suspension transport in porous media considering the pore and sp size and investigated the effects of electrostatic interactions on ion diffusion ma et al 2018 proposed a time and distance dependent deposition model to describe the effects of hydrodynamic forces on the transport of polydispersed particles which was verified in a series of sand column experiments at different fluid velocities in three porous media given the impacts of colloid deposition on the flow structure and consequently the deposition of sps li et al 2018 simulated the deposition of colloidal particles in converging diverging capillaries using a unit bed approach ervin and ruiz ramírez 2018 investigated the filtration process whereby particulates were deposited in the flow domain causing the porosity of the region to decrease in that model the fluid flow was modeled as a coupled stokes darcy flow problem and the deposition was modeled using a nonlinear equation for the porosity however the deposition and release of sps depend not only on the concentration at a given time but also on the amount of deposited sps and changes in the matrix structure at that time bedrikovetsky et al 2012 chung et al 2015 taghavy et al 2018 implying that the attachment detachment process of sps is likely to be related to the deposition history of the porous medium ma et al 2018 russell and bedrikovetsky 2018 moreover previous models relying on the kinetics of particle capture seldom consider the hysteretic effects caused by the nonequilibrium interaction between the sps and the porous medium matrix in this study we propose a nonlinear attachment detachment model with hysteresis that uses an adsorption function and scanning desorption isotherms to model the deposition process of sps the proposed model takes into account the flow velocity that may influence the deposition history and unsteady changes in the concentration of sps with time and thus makes it possible to obtain better theoretical solutions for the transport of sps to verify the reliability of the proposed model experiments were performed under variable injection concentrations and seepage velocities the results show that there is good agreement between the simulated and experimental breakthrough curves btcs 2 transport model of sps under unsteady flow conditions 2 1 governing equations it is impossible to maintain an exactly constant flow velocity and direction in porous media and thus the concentration of sps or soluble pollutants that flow with water also changes constantly the transport of sps is the vector sum of their mechanical dispersion and molecular diffusion according to the law of mass conservation the convection diffusion equations for sps in porous media can be described as follows burnett and frind 1987 1 n c t n d c n u c f where c is the concentration of the sps or solute ml 3 n is the porosity t is the time t u is the average flow velocity vector in the porous medium lt 1 and f is the source term ml 3t 1 d is the dispersion coefficient tensor l2t 1 d d d d e where d d is the mechanical dispersion coefficient tensor and d e is the molecular diffusion coefficient tensor the porosity is assumed to be constant during the transport processes under one dimensional conditions and thus eq 1 can be rewritten as bai et al 2015 bedrikovetsky et al 2012 2 c t d 2 c x 2 u c x ρ s n σ t where x is the transport distance of the sps l d is the hydrodynamic dispersion coefficient which can be described as d α d u if the molecular diffusion d e is negligible in which α d is the hydrodynamic dispersivity l and u is the average internal velocity of the sps lt 1 σ is the attachment concentration of the sps mm 1 which refers to the mass of the sps adsorbed per unit mass of the solid matrix of the porous medium and ρ s is the density of the solid matrix ml 3 the third term on the right side of eq 2 is actually the deposition term a number of mathematical expressions have been developed based on first order deposition dynamics katzourakis and chrysikopoulos 2014 van genuchten and wierenga 1977 and some expressions even take into account the release ahfir et al 2017 bai et al 2017 or the dispersion of sps during the deposition process altoe et al 2006 however the influence of the deposition history or paths of sps and the consecutive change in the seepage velocity have received somewhat less attention 2 2 classical nonlinear isothermal adsorption model for typical nonlinear freundlich isothermal adsorption ahmed et al 2015 chung et al 2015 the relationship between the adsorption concentration and the solute concentration under static conditions can be described as 3 s k f c 1 n 0 where s is the equilibrium adsorption concentration k f is the freundlich adsorption equilibrium constant and 1 n 0 is a constant that is a measure of the adsorption capacity of the media eq 3 is actually an empirical equation it follows from eq 3 that s c k f n 0 c 1 n 0 n 0 the adsorption process is characterized by an increase in the adsorption concentration s while the desorption process is characterized by a decrease in the adsorption concentration s the solid matrix is assumed to have an infinite adsorption capacity in the freundlich isothermal adsorption model which clearly does not agree with the facts the nonlinear langmuir isothermal adsorption model that takes into account the maximum adsorption capacity of the porous media can be described as ahmed et al 2015 garcía and maría 2017 4 s k l c 1 k l c s max where kl is the langmuir constant and the higher the parameter kl is the higher the adsorption capacity of the porous media will be s max is the maximum adsorption concentration it follows from eq 4 that s c kl 1 kl c 2 s max 2 3 a new nonlinear attachment detachment model for the transient equilibrium attachment of sps the attachment concentration on the porous medium matrix is likely to be nonlinearly related to the concentration of sps in the solution which is apparently dependent on the deposition history of the porous media for instance for a fresh porous medium without the attachment of sps point o in fig 1 s 0 the rate of increase in the attachment concentration s will decrease as the concentration of sps in solution c increases accordingly the deposition path from point o to point a develops corresponding to the maximum attachment concentration s max saturated concentration through point b when the particle size of sps is smaller than a given value no obvious blocking will occur in the porous media bai et al 2017 and the adsorption capacity of the porous medium matrix decreases as c increases finally the attachment concentration will reach the theoretical maximum s max at a concentration of c m point a in fig 1 thus as c s s max which is referred to as the initial deposition process in this study o b a in fig 1 bedrikovetsky et al 2012 proposed the concept of maximum retention concentration to explain the effect of the particle concentration in the leachate and this concept stated that when the drag force moment acting on particles deposited onto the matrix surface by flowing water exceeds the attractive normal force moment no more particles will be captured by the matrix surface sps deposited on porous media can be resuspended when the suspension concentration c decreases below c m fig 1 which is referred to as the release detachment process a e accordingly the attachment concentration will decrease to the residual concentration s r m as the suspension concentration c decreases to c 0 however as the suspension concentration increases from c 0 point o to c c p point b and then decreases the release process will develop from point b to point d through point c b c d which is called a scanning desorption isotherm the concentration c p at point b is referred to as the previous concentration the scanning curves correspond to the region between the initial deposition curve c p and zero suspension concentration c 0 if the suspension concentration decreases to a certain value e g point c and then increases the deposition process develops via c b which is referred to as the redeposition process the redeposition process is assumed to be the same as that of b c in shape and it depends on the sp concentration during the deposition or release process and is determined by static deposition tests however when the suspension concentration c continues to increase above c p the deposition process develops again along the initial b a process the static deposition tests of chung et al 2015 showed that a nonlinear relationship exists between the attachment and injection concentration of orthophosphate in a porous medium oyster shell powder and that the attachment concentration tended to be stable as the injection concentration increased van genuchten and wierenga 1977 showed similar results for the transport of herbicide 2 4 5 t 2 4 5 trichlorophenoxyacetic acid through the glendale soil under static conditions thus a nonlinear static attachment detachment model considering the deposition history of the porous media can be established when c t 0 and c c p o b a in fig 1 the relationship between attachment concentration s and suspension concentration c can be described as 5 s s max 1 e β 1 c c l where c l is the characteristic concentration which is assumed to be c l 1 whose dimension is the same as that of c and β 1 is the dimensionless attenuation factor of the initial deposition process it follows from eq 5 that 6 s c κ d e β 1 c c l where κ d is the transient equilibrium constant during the initial deposition process m 1l3 κ d β 1 s max c l when c 0 s c κ d while when c s c 0 when c t 0 or when c t 0 and c c p the release and redeposition process b c d in fig 1 can be described as 7 s c κ r e β 2 c c p where κ r is the transient equilibrium constant during the release process m 1l3 and β 2 is the dimensionless attenuation factor of the release process the parameter c p discriminates each scanning curve the higher the parameters β 1 and β 2 are the quicker the attenuation process is and thus the lower the adsorption capacity of the porous media is when β 1 β 2 0 eqs 6 and 7 can be reduced to the linear nonequilibrium adsorption process while when β 1 β 2 0 and κ d κ r the conditions can be described by the freundlich linear adsorption model eq 3 n 0 1 2 4 deduction of the model based on the expression of κ d in eq 6 the maximum attachment concentration can be written as s max κ d c l β 1 it follows from eq 5 that when c c p the previous attachment concentration is 8 s p κ d c l β 1 1 e β 1 c p c l clearly during the release redeposition process b c d in fig 1 s s p when c c p using this condition the integration of eq 7 shows that the relationship between the attachment concentration s and suspension concentration c during the release redeposition process is 9 s κ d c l β 1 1 e β 1 c p c l κ r c p β 2 e β 2 c c p e β 2 for different previous concentrations of c p different scanning curves are produced then the residual concentration c 0 fig 1 is 10 s r κ d c l β 1 1 e β 1 c p c l κ r c p β 2 1 e β 2 when c p 0 s r 0 while when c p c m the residual concentration is 11 s r m κ d c l β 1 1 e β 1 c m c l κ r c m β 2 1 e β 2 where s r m is the maximum residual concentration of sps on the porous medium matrix which is lower than the potential attachment concentration s m fig 1 2 5 nonequilibrium process during the transport of sps given the existence of both convection and dispersion especially mechanical dispersion during the transport of sps in porous media the deposition of sps is essentially a nonequilibrium hydrodynamic process van genuchten and wierenga 1977 wyness et al 2018 the so called size exclusion effect or the preferential flow effect ahfir et al 2017 bai et al 2017 ma et al 2018 can further increase the nonequilibrium hydrodynamic process of the flow and deposition of sps let the concentration of sps in the solution at a given time t be c and let the attachment concentration on the matrix under nonequilibrium conditions be σ then the deposition rate or the release rate in eq 2 can be expressed as 12 σ t λ s σ where λ is the reaction rate constant t 1 in fact the parameter λ represents the mass conversion between flowing and deposited sps under water flow the mass conversion essentially exhibits a hysteretic characteristic of solid particle attachment on a porous medium matrix which can be determined based on the physical and chemical properties of the sps or solute and the porous media the equilibrium attachment concentration s in the initial deposition process of sps e g point c in fig 1 can be calculated from eq 5 whereas that in the equilibrium release redeposition process e g point c in fig 1 can be calculated from eq 9 in fact the deposition rate in the release redeposition process point c is equivalent to that at the same attachment concentration in the initial deposition process point c the parameter λ adopts a negative value when the concentration of sps in the flowing water decreases b c d resulting in the release process i e detachment it follows from eq 12 that σ t f s σ indicating that the deposition rate of sps is related not only to the sp concentration c in the solution but also to the attachment concentration σ on the porous medium matrix potential attachment amount s m and even the previous concentration c p when σ s σ t 0 and hence the deposition rate of sps is zero for the initial deposition and release redeposition processes the deposition rate of sps i e σ t reaches a maximum at σ 0 for the initial deposition process when t 0 σ 0 thus the attachment concentration of sps during the transport process can be calculated from eq 12 13 σ s 1 e λ t for the release redeposition process when t 0 σ s r at this time the attachment concentration of sps can be calculated from eq 12 14 σ s 1 e λ t s r e λ t the proposed attachment detachment model includes three unknowns c s and σ which can be solved from eqs 2 6 or 7 and 12 the completeness of the equation system can be satisfied 3 experimental methods and materials 3 1 static deposition test an experimental setup is specifically designed to determine the physical parameters involved in the static deposition and release of sps in porous media under variable injection concentrations the cylindrical chamber used in this study is made of organic materials with a height of h 20 cm and a diameter of ϕ 8 cm refer to fig 5 a in section 5 a water outlet 2 mm in diameter is located at the bottom of the chamber and a screen of 0 5 mm is placed 5 cm above the bottom the sample height is set to 15 mm and this setup can be considered a unit scale experiment to simulate static flow 500 cm3 of sp solution with a given concentration e g c p in fig 1 was injected into the cylinder through a specially designed disperser the bottom of the disperser was kept 10 cm above the top surface of the sample during the injection process until it was completely immersed in the suspension the outlet was opened to allow a slow discharge of the suspension at a controlled darcy velocity of v 0 01 cm s resulting in a static deposition of sps in the porous media the installation of the screen made it possible to prevent the discharge of the porous media while discharging the water the turbidity of the suspension was measured using a turbidity meter hach co usa type 2100n and then the suspension concentration was determined based on the calibrated relationship between the concentration and turbidity bai et al 2017 in addition the attachment concentration in porous media e g s p in fig 1 was also calculated then the suspension concentration was decreased to easily obtain the release process e g b c d in fig 1 similarly another release process e g a e in fig 1 could also be obtained in a similar vein quartz sand was used as the porous media and was composed of 26 particles with diameters of 1 2 mm and 74 particles with diameters of 2 3 5 mm the nonuniform coefficient was c u 1 5 the coefficient of curvature was c c 1 and the density was 2 65 g cm3 the sps used in this experiment were spherical sio2 particles made from natural silica sand with a density of 2 26 g cm3 prior to the experiment impurities were removed by washing the material in an acidic solution and high purity deionized water and drying it at 105 c for 24 h for future use the porosity of the sample was set to n 0 42 static deposition tests were performed with sps with median particle sizes of d 50 2 10 and 50 μm all experiments were performed at room temperature 22 24 c 3 2 column experiment column experiments were conducted to investigate the transport of sps in these experiments the sample height was h 30 cm and the diameter was ϕ 8 cm h ϕ 3 75 the experimental setup and mechanism are described in a previous study bai et al 2017 the soil column was packed layer by layer with a porosity of n 0 42 the same as the static deposition tests in section 3 1 and the water surface was kept 1 2 cm above the soil column to ensure saturation of the sample the flow velocity was controlled using a peristaltic pump longerpump bt600 2j baoding china and high purity deionized water was pumped from the feed tank a screen with a diameter of 0 5 mm was installed at both the inlet and outlet to allow for a uniform inflow into and outflow from the soil column as an example the calibration of transport parameters was illustrated using sps with a median particle size of d 50 10 μm as the seepage velocity reached a steady state v inj 30 ml of the sp solution was injected into the soil column instantaneously within t inj 2 s i e pulse pattern three seepage velocities v 0 087 0 173 and 0 260 cm s and four injection concentrations c inj 0 5 1 3 and 4 mg ml were used in this study the disturbance caused by the instantaneous injection of sps to the desired flow velocity e g v 0 087 cm s by the peristaltic pump could result in substantial changes in the actual flow velocity and injected sp concentration on the surface of the column which were corrected with the following equations 15 u 0 t u 0 v inj n a t inj 1 h t t inj 16 c 0 t m v inj q t inj 1 h t t inj where h t is the unit step function u 0 v n is the predetermined seepage velocity a is the cross sectional area of the soil column l2 q va is the flow rate l3t 1 t inj is the injection time t m is the total mass of sps injected into the porous media m and v inj is the injection volume l3 to verify the reliability of the proposed attachment detachment model the transport experiments of sps were also conducted in the case of continuous injection under variable injection concentration and seepage velocity conditions the two patterns of variable concentration for two particle sizes i e d 50 2 or 10 μm are as follows the injection concentration c inj 0 1 mg ml is increased to c inj 0 5 mg ml and then to c inj 2 mg ml after a predetermined time under three darcy velocities v 0 087 0 173 and 0 260 cm s or the injection concentration c inj 2 mg ml is decreased to c inj 0 5 mg ml and then to c inj 0 1 mg ml under a darcy velocity of v 0 260 cm s the four patterns of variable velocity for three particle sizes d 50 2 10 and 50 μm c inj 2 mg ml are as follows the darcy velocity is increased v 0 087 0 173 cm s v 0 087 0 260 cm s and v 0 173 0 260 cm s or decreased v 0 260 0 173 cm s 4 solution and parameter sensitivity analysis 4 1 coordinate transformation a one dimensional case is analyzed and the initial concentration of sps is zero the penetration rate m b is defined as the ratio of the mass of sps flowing through the cross section x at time t to the total mass of sps injected into the porous media 17 m b 0 t c x t u n a d t m clearly m a 1 m b is the amount of sps deposited in the range of 0 x in the column let the dimensionless time be t p unat nal ut l and the dimensionless concentration be c x t p c x nal t p una where l is the column length thus eq 17 becomes 18 m b nal 0 t p c x t p d t p m in fact t p is the ratio of the water volume q t q t unat passing through the cross section during time t to the pore volume of the column v 0 nal which can also be represented by the pore volume pv pv t p bai et al 2017 the derivative of eq 18 with respect to t p yields the relative concentration cr 19 c r v 0 m c x t p the transport process of sps in porous media is calculated using the pardiso solver of the comsol multiphysics software comsol co ltd then eq 2 is solved using the transport of diluted species interface and m b and cr are calculated using the global ordinary differential equations and differential algebraic equations 4 2 parameter sensitivity analysis if there is only a small difference between the bending shape of the initial deposition process o b a in fig 1 and the bending shape of the release redeposition process b c d in fig 1 then it can be assumed that β β 1 β 2 then η κ r κ d is defined to indicate the release effect on the deposition for harmonic changes in the concentration of sps on the surface of the column three parameters β η and λ in the attachment detachment model can affect the relative concentration cr in the outflow the injection concentration of sps is assumed to be fig 2 20 c c 0 sin 2 π t t where c 0 is the concentration amplitude and t is the period let c 0 2 mg ml t 120 s i e the injection time is 60 s and the injection velocity v 0 087 cm s fig 2 shows the sensitivity of parameters β η and λ to the penetration rate m b recovery rate of sps in the outflow where c out is the outflow concentration the calculation result shows that m b 82 6 when β 0 01 η 0 5 κ d 0 01 ml mg and λ 0 02 10 3 as the attenuation factor increases from β 0 to β 1 the penetration rate m b of sps increases and then remains steady thus the nonlinear deposition process β 0 can decrease the amount of sp deposition when β 1 the penetration rate can reach 98 7 indicating an obvious decrease in the deposition amount as the value η η κ r κ d η 0 1 increases the penetration rate m b increases almost linearly as a result m b 100 is obtained when η 1 fig 2 shows that as the injection concentration of sps decreases i e after c out c 0 1 the release effect increases with the increase in η e g η 0 2 0 5 0 9 indicating a more obvious tailing phenomenon the reaction rate constant λ indicates the interaction between sps and the porous medium matrix as the value λ increases the penetration rate m b decreases rapidly from m b 100 when there is no attachment or adsorption λ 0 to m b 0 when sps and the porous medium matrix are completely coupled λ 0 3 10 3 thus the value λ has an important influence on the calculation results and the range is λ 0 0 3 10 3 which is closely related to the physical and chemical properties of sps and the porous medium matrix 4 3 gaussian pulse injection of sps to test the applicability of the attachment detachment model the seepage velocity is assumed to decrease exponentially with time 21 u t u i e α t where u i is the initial seepage velocity and α is the attenuation parameter t 1 clearly a constant seepage velocity can be obtained when α 0 the injection concentration of sps on the surface of the column c 0 t f t is assumed to be a pulse periodic function fig 3 which can be described by the gaussian function 22 f t w 2 π e t t i n b 2 2 t i n t t i n 2 b 0 otherwise where t i n is the starting time of pulse n n is the cycle number b is the peak characteristic value of the gaussian function and w is the injection amount of sps for each pulse and thus w t i n t i n 2 b f t d t assume that v inj 30 ml of sps is injected over a period of t inj 2b 2 s for each pulse injection the initial seepage velocity in eq 21 is u i 0 15 cm s it is assumed that α d 0 4 cm β β 1 β 2 and α 0 001 s 1 when the velocity is attenuated fig 4 shows the variation in the relative concentration of sps in the flowing water with time at different positions x 5 10 20 and 30 cm from the injection surface where the injection period is t 60 s the attenuation factor β 0 01 the reaction rate constant λ 2 10 5 s 1 the transient equilibrium constant κ d 0 01 ml mg and κ r 0 005 ml mg the relative concentration of sps changes periodically at x 5 cm and the peak decreases as the pv increases indicating an increase in the interactions between the sps in flowing water and the porous medium matrix over time and consequently an increase in the deposition amount however as the distance from the injection surface increases the periodic change in the relative concentration of sps becomes less pronounced e g x 20 cm fig 4 c and even disappears e g x 30 cm fig 4 d due to the convection dispersion and adsorption effects there is a substantial amount of sps deposited on the porous media for instance at a constant velocity α 0 see the solid line in fig 4 the deposition amount is m a 16 6 m b 84 4 at x 0 5 cm and m a 27 5 m b 72 5 at x 0 30 cm thus the deposition amount at x 5 30 cm accounts for only 10 9 indicating that the deposition amount decreases rapidly with increasing transport distance fig 4 shows that there is a very low concentration of sps at x 5 cm when pv is larger than 1 5 as the distance from the injection surface increases to x 20 cm the relative concentration decreases to 0 at a pv of approximately 2 5 indicating an obvious retardation phenomenon in addition as the transport distance x increases the peak of the relative concentration decreases rapidly for instance c r 1 45 at x 5 cm and c r 0 58 at x 30 cm for the first peak when the attenuation parameter of the seepage velocity is α 0 001 s 1 the peak sp concentration c r is initially greater than the case without attenuation α 0 and then decreases as the cycle number increases in addition as the transport distance x increases the occurrence of the peak is delayed and the sp penetration rate m b decreases which can be attributed to the decrease in the seepage velocity during the later period the results show that for the proposed nonlinear model eqs 6 and 7 where κ d 0 08 ml mg κ r 0 04 ml mg and β 0 01 and its degenerated linear form β 0 the penetration rate is less than 100 after the cyclic deposition of sps a large difference in the pulse injection period will result in substantial differences in the concentration evolution process and the peak of sps in the outflow water as well as in the attachment amount of sps during the transport for instance the penetration rate at x 20 cm is m b 82 2 72 1 and 46 9 when t 6 60 and 120 s β 0 01 respectively in addition the shorter the time period e g t 6 s is the more rapid the increase in the penetration rate is and the higher the peak relative concentration c r is which is related to the reaction rate constant λ between the sps and the porous medium matrix i e nonequilibrium hydrodynamic process the result also shows that increasing the value β e g β 0 0 01 0 1 at t 60 s results in an increase in the penetration rate m b 63 7 72 1 74 4 thus it is possible that the use of linear models results in an overestimation of the adsorption capacity of porous media 5 experimental calibration of the transport parameters fig 5 shows the variation process of the static attachment concentration s with an increase or a decrease in the suspension concentration c and that the rate of increase in the attachment concentration of sps tends to decrease as the suspension concentration c increases observable adsorption occurs for small particle sizes such as d 50 2 μm whereas a straining effect occurs for large particle sizes such as d 50 50 μm as a result medium sized particles e g d 50 10 μm seem to show relatively smaller deposition amounts notably the release process of sps is relatively gentle at first and then becomes steeper and the final deposition amount differs significantly for sps with different particle sizes van genuchten and wierenga 1977 showed that the release process of 2 4 5 t a soluble compound was obvious at the very beginning and the final adsorption amount was very small which could be related to the particle size of the suspended substance soluble material or colloids the static deposition process curve was fitted using eq 6 and the parameter β 1 could be obtained the release process was fitted using eq 7 where the parameter β 2 was assumed to be equal for each release process i e scanning desorption isotherms and then the relationship between s and c c p for all release processes could be obtained origin 8 5 originlab corporation was used for the calculations the parameters β 1 and β 2 are shown in table 1 the coefficients of determination are r 2 0 99 and r 2 0 96 indicating good fitting fig 6 shows the experimental btcs of sps d 50 10 μm under pulse injection conditions and the calculated curves fitted using comsol multiphysics comsol co ltd the control parameters in the calculations are as follows the temporal discretization step is 3 s the spatial discretization step is 0 02 m the damping factor is 0 9 the iteration number is 4 and the relative tolerance is 0 0001 here there are six parameters β 1 β 2 κ d κ r α d and λ and β 1 and β 2 can be obtained from the static deposition tests generally the dispersivity increases with increasing particle size and slightly increases with increasing velocity ahfir et al 2009 chrysikopoulos and katzourakis 2015 it is not closely related to the injection concentration bai et al 2017 bennacer et al 2017 here the dispersivity α d is simply assumed to be α d 0 4 cm according the test results in this paper the remaining three parameters κ d κ r and λ can be uniquely fitted by the pulse injection experiments given in fig 6 the iteration is repeated until the required accuracy is reached when d 50 10 μm fig 6 the coefficient of determination is r 2 0 99 indicating good agreement between the results obtained from the nonlinear attachment detachment model and the experimental results the peak values of btcs generally lag e g pv 1 fig 6 which is related to the existence of adsorption hysteresis similar results were explained by altoe et al 2006 using a theoretical model considering the effect of the dispersive flux on the retention kinetics during the deposition process in particular the release of deposited sps is well illustrated in the latter part of the curves e g pv 2 which show that the penetration concentration of sps to be higher than 0 for a long time e g fig 6 d fig 6 shows that as the injection concentration increases the penetration rate of sps first decreases and then increases for instance the penetration rate at a darcy velocity of v 0 260 cm s is m b 65 8 58 3 70 0 and 76 6 at injection concentrations of c inj 0 5 1 3 and 4 mg ml respectively similar results can also be obtained at darcy velocities of v 0 087 and 0 173 cm s and the results are in line with previous findings bai et al 2017 chrysikopoulos et al 2017 thus there is a nonlinear relationship between the attachment concentration and suspension concentration indicating the existence of the maximum attachment concentration σ max at a low suspension concentration the dynamic attachment concentration σ on the matrix is not saturated and thus the matrix can still adsorb sps as a result the penetration rate m b decreases as the injection concentration increases when the suspension concentration is higher than a given value σ reaches a saturation level and the increment in the attachment concentration gradually approaches zero accordingly the porous medium matrix cannot adsorb more sps even at a high injection concentration and thus the penetration rate of sps increases the transport parameters β 1 β 2 κ d κ r α d and λ of sps in porous media can be affected by a wide variety of factors such as the seepage velocity injection concentration and particle size of the sps additionally the problem is more complex because these factors are interrelated and change constantly with the transport distance and time fig 7 shows the variations in κ d κ r and λ fitted in fig 6 as a function of the darcy velocity under different injection concentrations c inj 0 5 1 3 and 4 mg ml the results show that in the range of v 0 087 0 263 cm s the values of κ d and κ r remain almost unchanged with increasing seepage velocity which can be assumed to be constant in fact κ d and κ r are used to characterize the deposition of sps under static conditions because they are more related to the particle size of the suspended substance and the properties of the solution than to the seepage velocity thus the parameters κ d and κ r are taken to be the average of the fitted values table 1 for instance for d 50 10 μm κ d 0 69 ml mg and κ r 1 01 ml mg fig 7 shows that the parameter λ increases as the seepage velocity increases indicating an increase in the interaction between the sps and the porous medium matrix thus the seepage velocity evidently affects the transport process of sps 6 verification of the proposed model and discussion the experimental schemes are described in section 3 2 fig 8 shows the btcs of sps when the injection concentration is increased denoted by hollow dots or decreased denoted by solid dots fig 9 shows the btcs of sps when the seepage velocity is increased denoted by hollow dots or decreased denoted by solid dots figs 8 and 9 also give the simulated curves by the proposed nonlinear attachment detachment model and the adopted parameters can be seen in table 1 the transport processes of sps are calculated using the pardiso solver in comsol multiphysics comsol co ltd clearly there is good agreement between the simulated and experimental btcs with a coefficient of determination of r 2 0 91 for d 50 2 μm fig 8 a when the injection concentration is increased from c inj 0 1 mg ml to c inj 0 5 mg ml after pv 2 75 and then to c inj 2 mg ml after pv 4 61 the effluent concentration c out clearly increases this increase reflects the nonlinear deposition process of sps i e the relative decrease in the deposition amount in contrast the effluent concentration c out decreases when the injection concentration is decreased from c inj 2 mg ml to c inj 0 5 mg ml after pv 2 75 and then to c inj 0 1 mg ml after pv 4 61 certainly due to the decrease in the injection concentration the release effect of the already deposited sps prolongs the sp penetration process which produces a relatively high effluent concentration over a long period of time i e pv 4 61 similar results are also obtained when d 50 10 μm fig 8 b it is no more than that the effluent concentration c out is generally greater than that when d 50 2 μm fig 8 a and the required steady time is also shortened moreover with the increase in the injection concentration i e c inj 0 1 0 5 2 0 mg ml the rate of increase in the effluent concentration c out increases more obviously for d 50 10 μm than for d 50 2 μm fig 8 b this increase can be attributed to the weaker adsorption of large sized particles according to the static deposition tests see fig 5 c certainly with a further increase in particle size the straining effect of the porous medium pores on sps manifests which induces a decrease in the effluent concentration c out for example when the particle size increases from d 50 10 μm to d 50 50 μm c inj 2 mg ml v 0 260 cm s see the solid dots of fig 9 b and c the effluent concentration decreases from c out 0 94 mg ml to c out 0 50 mg ml fig 9 shows that increasing or decreasing the seepage velocity results in clear increases or decreases in effluent concentration c out respectively the influence of the seepage velocity mainly includes the two aspects of nonequilibrium adsorption and particle kinetic capture on the one hand the increase in the seepage velocity enhances the interaction between sps and the porous medium matrix i e increasing the reaction rate constant λ see fig 7 and correspondingly shortens the time to reach the adsorption equilibrium state which objectively accelerates the deposition of sps on the other hand the increase in the seepage velocity strengthens the hydrodynamic force acting on sps and actually enhances the movement of sps along the flowing water for small sized particles the sp matrix interaction plays a dominant role and is related to the aggregation capillary condensation and active energy of the suspended substances in contrast for large sized particles hydrodynamic forces play an important role except for the hysteresis caused by the collisions between sps and between sps and the matrix as a result the transport of sps exhibits an obvious nonlinear deposition process as shown in fig 9 when the particle size increases from d 50 2 μm to d 50 10 μm and then to d 50 50 μm at a given velocity the effluent concentration c out exhibits a trend of first increasing and then decreasing certainly there will be an increase in the effluent concentration c out when the seepage velocity increases e g v 0 087 0 260 cm s see the comparison of fig 9 b and c 7 conclusions a nonlinear attachment detachment model with adsorption hysteresis is proposed which uses an adsorption function and scanning desorption isotherms to model the deposition effect of sps the reaction rate constant related to hysteretic characteristics essentially reflects the nonequilibrium hydrodynamic process during the transport of sps static deposition tests and column experiments with pulse injection are used to calibrate the transport parameters column penetration experiments are performed under variable injection concentrations and seepage velocities the results show that there is good agreement between simulated and experimental btcs when the injection concentration is increased the effluent concentration clearly increases which actually reflects a nonlinear deposition process in contrast with a decrease in the injection concentration the release effect of the already deposited sps prolongs the penetration process which is also related to the hysteresis previously proposed linear attachment detachment models probably result in an overestimation of the adsorption capacity of porous media studies show that increasing the seepage velocity enhances the reaction rate constant between sps and the porous medium matrix and simultaneously strengthens the hydrodynamic force acting on sps which actually promotes the movement of sps along the flowing water for small particles the reaction rate constant is the dominant factor nevertheless for large particles the hydrodynamic force plays an important role except for the hysteretic effect caused by the collisions between sps and between sps and the solid matrix declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was financially supported by the beijing natural science foundation 8182046 and the national natural science foundation of china 51678043 51878035 the authors would like to thank the reviewers and editor for their constructive comments 
6154,in this study we propose a nonlinear attachment detachment model with hysteresis for the transport of suspension colloidal particles sps in porous media the proposed model uses an adsorption function and scanning desorption isotherms to model the deposition process of sps this model shows that increasing or decreasing the seepage velocity results in substantial changes in the penetration concentration of sps which is closely related to the adsorption hysteresis and the deposition dynamics of sps studies show that previous linear attachment detachment models probably result in an overestimation of the adsorption capacity of porous media static deposition tests and dynamic transport experiments using pulse injection were performed to calibrate the transport parameters the effects of the seepage velocity injection concentration and particle size on the transport parameters and reaction rate constant were investigated experiments were also performed under variable injection concentrations and seepage velocities the results show that there is good agreement between the simulated and experimental breakthrough curves btcs keywords attachment detachment model hysteretic effect nonlinear process variable concentration unsteady flow 1 introduction the transport and deposition of substances such as soluble ions heavy metal pollutants bacteria and suspension colloidal particles sps in porous media is an important yet challenging topic in environmental geotechnics bedrikovetsky et al 2017 daghooghi and borazjani 2018 katzourakis and chrysikopoulos 2019 wyness et al 2018 as well as in many other fields such as groundwater exploitation water purification changes in the permeability of porous media petroleum exploration and the cotransport of pollutants akrouch et al 2016 chen et al 2018 shang et al 2013 a number of factors have been reported that affect the transport and deposition of sps such as the properties of the porous media and sps e g size morphology and concentration chemical composition of the solution ph and flow velocity ahfir et al 2009 bradford et al 2017 chrysikopoulos and katzourakis 2015 li et al 2018 wyness et al 2018 some laboratory experiments have been conducted in an effort to elucidate the transport processes of sps with different sizes shapes and injection concentrations in different porous media bennacer et al 2017 massei et al 2002 wang et al 2000 ahfir et al 2017 investigated the effects of the grain size distribution of the porous medium on the transport and deposition of polydispersed sps in a plexiglass column with an inner diameter of 4 4 cm and a length of 62 cm bai et al 2015 derived analytical solutions for contaminant transport in a semi infinite saturated porous medium using laplace and fourier transform techniques and investigated the effects of particle size concentration and flow velocity on the transport of contaminants later bai et al 2017 investigated the effects of flow velocity and the concentration of oh ions on the penetration processes of red mud filtrate in a porous medium however the transport of sps has been found to be characterized by first order deposition kinetics in most previous studies bai et al 2017 ahfir et al 2017 but this finding may be only applicable to the transport of sps under the conditions of constant flow velocity boundary concentration and particle size a key problem in understanding the transport of soluble pollutants and sps is the mathematical description of their nonlinear attachment detachment processes which involve temporal and spatial changes in the seepage velocity and in the size ma et al 2018 and concentration of the sps gavrilov and shebelev 2018 as well as complex physical and chemical processes caused by changes in the pore structure of the porous media daghooghi and borazjani 2018 li et al 2018 cinzia and luisa 2015 simulated the migration of radionuclides in the far field of a geological repository in a nonuniform groundwater flow field and investigated the effects of the distribution coefficient and hydraulic gradient farajzadeh et al 2016 proposed a filtration theory describing the mechanical entrapment on the polymer flow through porous media which was coupled to the langmuir equilibrium adsorption model bedrikovetsky et al 2017 investigated the release effect of sps in a porous medium under different flow velocities and derived an exact solution for the long term nonlinear injection of particles katzourakis and chrysikopoulos 2018 numerically investigated the effect of the spatially variable attachment coefficient on biocolloid transport in a heterogeneous porous stratum with a three dimensional mathematical model that they developed russell and bedrikovetsky 2018 proposed a method for the solution of colloid suspension transport in porous media considering the pore and sp size and investigated the effects of electrostatic interactions on ion diffusion ma et al 2018 proposed a time and distance dependent deposition model to describe the effects of hydrodynamic forces on the transport of polydispersed particles which was verified in a series of sand column experiments at different fluid velocities in three porous media given the impacts of colloid deposition on the flow structure and consequently the deposition of sps li et al 2018 simulated the deposition of colloidal particles in converging diverging capillaries using a unit bed approach ervin and ruiz ramírez 2018 investigated the filtration process whereby particulates were deposited in the flow domain causing the porosity of the region to decrease in that model the fluid flow was modeled as a coupled stokes darcy flow problem and the deposition was modeled using a nonlinear equation for the porosity however the deposition and release of sps depend not only on the concentration at a given time but also on the amount of deposited sps and changes in the matrix structure at that time bedrikovetsky et al 2012 chung et al 2015 taghavy et al 2018 implying that the attachment detachment process of sps is likely to be related to the deposition history of the porous medium ma et al 2018 russell and bedrikovetsky 2018 moreover previous models relying on the kinetics of particle capture seldom consider the hysteretic effects caused by the nonequilibrium interaction between the sps and the porous medium matrix in this study we propose a nonlinear attachment detachment model with hysteresis that uses an adsorption function and scanning desorption isotherms to model the deposition process of sps the proposed model takes into account the flow velocity that may influence the deposition history and unsteady changes in the concentration of sps with time and thus makes it possible to obtain better theoretical solutions for the transport of sps to verify the reliability of the proposed model experiments were performed under variable injection concentrations and seepage velocities the results show that there is good agreement between the simulated and experimental breakthrough curves btcs 2 transport model of sps under unsteady flow conditions 2 1 governing equations it is impossible to maintain an exactly constant flow velocity and direction in porous media and thus the concentration of sps or soluble pollutants that flow with water also changes constantly the transport of sps is the vector sum of their mechanical dispersion and molecular diffusion according to the law of mass conservation the convection diffusion equations for sps in porous media can be described as follows burnett and frind 1987 1 n c t n d c n u c f where c is the concentration of the sps or solute ml 3 n is the porosity t is the time t u is the average flow velocity vector in the porous medium lt 1 and f is the source term ml 3t 1 d is the dispersion coefficient tensor l2t 1 d d d d e where d d is the mechanical dispersion coefficient tensor and d e is the molecular diffusion coefficient tensor the porosity is assumed to be constant during the transport processes under one dimensional conditions and thus eq 1 can be rewritten as bai et al 2015 bedrikovetsky et al 2012 2 c t d 2 c x 2 u c x ρ s n σ t where x is the transport distance of the sps l d is the hydrodynamic dispersion coefficient which can be described as d α d u if the molecular diffusion d e is negligible in which α d is the hydrodynamic dispersivity l and u is the average internal velocity of the sps lt 1 σ is the attachment concentration of the sps mm 1 which refers to the mass of the sps adsorbed per unit mass of the solid matrix of the porous medium and ρ s is the density of the solid matrix ml 3 the third term on the right side of eq 2 is actually the deposition term a number of mathematical expressions have been developed based on first order deposition dynamics katzourakis and chrysikopoulos 2014 van genuchten and wierenga 1977 and some expressions even take into account the release ahfir et al 2017 bai et al 2017 or the dispersion of sps during the deposition process altoe et al 2006 however the influence of the deposition history or paths of sps and the consecutive change in the seepage velocity have received somewhat less attention 2 2 classical nonlinear isothermal adsorption model for typical nonlinear freundlich isothermal adsorption ahmed et al 2015 chung et al 2015 the relationship between the adsorption concentration and the solute concentration under static conditions can be described as 3 s k f c 1 n 0 where s is the equilibrium adsorption concentration k f is the freundlich adsorption equilibrium constant and 1 n 0 is a constant that is a measure of the adsorption capacity of the media eq 3 is actually an empirical equation it follows from eq 3 that s c k f n 0 c 1 n 0 n 0 the adsorption process is characterized by an increase in the adsorption concentration s while the desorption process is characterized by a decrease in the adsorption concentration s the solid matrix is assumed to have an infinite adsorption capacity in the freundlich isothermal adsorption model which clearly does not agree with the facts the nonlinear langmuir isothermal adsorption model that takes into account the maximum adsorption capacity of the porous media can be described as ahmed et al 2015 garcía and maría 2017 4 s k l c 1 k l c s max where kl is the langmuir constant and the higher the parameter kl is the higher the adsorption capacity of the porous media will be s max is the maximum adsorption concentration it follows from eq 4 that s c kl 1 kl c 2 s max 2 3 a new nonlinear attachment detachment model for the transient equilibrium attachment of sps the attachment concentration on the porous medium matrix is likely to be nonlinearly related to the concentration of sps in the solution which is apparently dependent on the deposition history of the porous media for instance for a fresh porous medium without the attachment of sps point o in fig 1 s 0 the rate of increase in the attachment concentration s will decrease as the concentration of sps in solution c increases accordingly the deposition path from point o to point a develops corresponding to the maximum attachment concentration s max saturated concentration through point b when the particle size of sps is smaller than a given value no obvious blocking will occur in the porous media bai et al 2017 and the adsorption capacity of the porous medium matrix decreases as c increases finally the attachment concentration will reach the theoretical maximum s max at a concentration of c m point a in fig 1 thus as c s s max which is referred to as the initial deposition process in this study o b a in fig 1 bedrikovetsky et al 2012 proposed the concept of maximum retention concentration to explain the effect of the particle concentration in the leachate and this concept stated that when the drag force moment acting on particles deposited onto the matrix surface by flowing water exceeds the attractive normal force moment no more particles will be captured by the matrix surface sps deposited on porous media can be resuspended when the suspension concentration c decreases below c m fig 1 which is referred to as the release detachment process a e accordingly the attachment concentration will decrease to the residual concentration s r m as the suspension concentration c decreases to c 0 however as the suspension concentration increases from c 0 point o to c c p point b and then decreases the release process will develop from point b to point d through point c b c d which is called a scanning desorption isotherm the concentration c p at point b is referred to as the previous concentration the scanning curves correspond to the region between the initial deposition curve c p and zero suspension concentration c 0 if the suspension concentration decreases to a certain value e g point c and then increases the deposition process develops via c b which is referred to as the redeposition process the redeposition process is assumed to be the same as that of b c in shape and it depends on the sp concentration during the deposition or release process and is determined by static deposition tests however when the suspension concentration c continues to increase above c p the deposition process develops again along the initial b a process the static deposition tests of chung et al 2015 showed that a nonlinear relationship exists between the attachment and injection concentration of orthophosphate in a porous medium oyster shell powder and that the attachment concentration tended to be stable as the injection concentration increased van genuchten and wierenga 1977 showed similar results for the transport of herbicide 2 4 5 t 2 4 5 trichlorophenoxyacetic acid through the glendale soil under static conditions thus a nonlinear static attachment detachment model considering the deposition history of the porous media can be established when c t 0 and c c p o b a in fig 1 the relationship between attachment concentration s and suspension concentration c can be described as 5 s s max 1 e β 1 c c l where c l is the characteristic concentration which is assumed to be c l 1 whose dimension is the same as that of c and β 1 is the dimensionless attenuation factor of the initial deposition process it follows from eq 5 that 6 s c κ d e β 1 c c l where κ d is the transient equilibrium constant during the initial deposition process m 1l3 κ d β 1 s max c l when c 0 s c κ d while when c s c 0 when c t 0 or when c t 0 and c c p the release and redeposition process b c d in fig 1 can be described as 7 s c κ r e β 2 c c p where κ r is the transient equilibrium constant during the release process m 1l3 and β 2 is the dimensionless attenuation factor of the release process the parameter c p discriminates each scanning curve the higher the parameters β 1 and β 2 are the quicker the attenuation process is and thus the lower the adsorption capacity of the porous media is when β 1 β 2 0 eqs 6 and 7 can be reduced to the linear nonequilibrium adsorption process while when β 1 β 2 0 and κ d κ r the conditions can be described by the freundlich linear adsorption model eq 3 n 0 1 2 4 deduction of the model based on the expression of κ d in eq 6 the maximum attachment concentration can be written as s max κ d c l β 1 it follows from eq 5 that when c c p the previous attachment concentration is 8 s p κ d c l β 1 1 e β 1 c p c l clearly during the release redeposition process b c d in fig 1 s s p when c c p using this condition the integration of eq 7 shows that the relationship between the attachment concentration s and suspension concentration c during the release redeposition process is 9 s κ d c l β 1 1 e β 1 c p c l κ r c p β 2 e β 2 c c p e β 2 for different previous concentrations of c p different scanning curves are produced then the residual concentration c 0 fig 1 is 10 s r κ d c l β 1 1 e β 1 c p c l κ r c p β 2 1 e β 2 when c p 0 s r 0 while when c p c m the residual concentration is 11 s r m κ d c l β 1 1 e β 1 c m c l κ r c m β 2 1 e β 2 where s r m is the maximum residual concentration of sps on the porous medium matrix which is lower than the potential attachment concentration s m fig 1 2 5 nonequilibrium process during the transport of sps given the existence of both convection and dispersion especially mechanical dispersion during the transport of sps in porous media the deposition of sps is essentially a nonequilibrium hydrodynamic process van genuchten and wierenga 1977 wyness et al 2018 the so called size exclusion effect or the preferential flow effect ahfir et al 2017 bai et al 2017 ma et al 2018 can further increase the nonequilibrium hydrodynamic process of the flow and deposition of sps let the concentration of sps in the solution at a given time t be c and let the attachment concentration on the matrix under nonequilibrium conditions be σ then the deposition rate or the release rate in eq 2 can be expressed as 12 σ t λ s σ where λ is the reaction rate constant t 1 in fact the parameter λ represents the mass conversion between flowing and deposited sps under water flow the mass conversion essentially exhibits a hysteretic characteristic of solid particle attachment on a porous medium matrix which can be determined based on the physical and chemical properties of the sps or solute and the porous media the equilibrium attachment concentration s in the initial deposition process of sps e g point c in fig 1 can be calculated from eq 5 whereas that in the equilibrium release redeposition process e g point c in fig 1 can be calculated from eq 9 in fact the deposition rate in the release redeposition process point c is equivalent to that at the same attachment concentration in the initial deposition process point c the parameter λ adopts a negative value when the concentration of sps in the flowing water decreases b c d resulting in the release process i e detachment it follows from eq 12 that σ t f s σ indicating that the deposition rate of sps is related not only to the sp concentration c in the solution but also to the attachment concentration σ on the porous medium matrix potential attachment amount s m and even the previous concentration c p when σ s σ t 0 and hence the deposition rate of sps is zero for the initial deposition and release redeposition processes the deposition rate of sps i e σ t reaches a maximum at σ 0 for the initial deposition process when t 0 σ 0 thus the attachment concentration of sps during the transport process can be calculated from eq 12 13 σ s 1 e λ t for the release redeposition process when t 0 σ s r at this time the attachment concentration of sps can be calculated from eq 12 14 σ s 1 e λ t s r e λ t the proposed attachment detachment model includes three unknowns c s and σ which can be solved from eqs 2 6 or 7 and 12 the completeness of the equation system can be satisfied 3 experimental methods and materials 3 1 static deposition test an experimental setup is specifically designed to determine the physical parameters involved in the static deposition and release of sps in porous media under variable injection concentrations the cylindrical chamber used in this study is made of organic materials with a height of h 20 cm and a diameter of ϕ 8 cm refer to fig 5 a in section 5 a water outlet 2 mm in diameter is located at the bottom of the chamber and a screen of 0 5 mm is placed 5 cm above the bottom the sample height is set to 15 mm and this setup can be considered a unit scale experiment to simulate static flow 500 cm3 of sp solution with a given concentration e g c p in fig 1 was injected into the cylinder through a specially designed disperser the bottom of the disperser was kept 10 cm above the top surface of the sample during the injection process until it was completely immersed in the suspension the outlet was opened to allow a slow discharge of the suspension at a controlled darcy velocity of v 0 01 cm s resulting in a static deposition of sps in the porous media the installation of the screen made it possible to prevent the discharge of the porous media while discharging the water the turbidity of the suspension was measured using a turbidity meter hach co usa type 2100n and then the suspension concentration was determined based on the calibrated relationship between the concentration and turbidity bai et al 2017 in addition the attachment concentration in porous media e g s p in fig 1 was also calculated then the suspension concentration was decreased to easily obtain the release process e g b c d in fig 1 similarly another release process e g a e in fig 1 could also be obtained in a similar vein quartz sand was used as the porous media and was composed of 26 particles with diameters of 1 2 mm and 74 particles with diameters of 2 3 5 mm the nonuniform coefficient was c u 1 5 the coefficient of curvature was c c 1 and the density was 2 65 g cm3 the sps used in this experiment were spherical sio2 particles made from natural silica sand with a density of 2 26 g cm3 prior to the experiment impurities were removed by washing the material in an acidic solution and high purity deionized water and drying it at 105 c for 24 h for future use the porosity of the sample was set to n 0 42 static deposition tests were performed with sps with median particle sizes of d 50 2 10 and 50 μm all experiments were performed at room temperature 22 24 c 3 2 column experiment column experiments were conducted to investigate the transport of sps in these experiments the sample height was h 30 cm and the diameter was ϕ 8 cm h ϕ 3 75 the experimental setup and mechanism are described in a previous study bai et al 2017 the soil column was packed layer by layer with a porosity of n 0 42 the same as the static deposition tests in section 3 1 and the water surface was kept 1 2 cm above the soil column to ensure saturation of the sample the flow velocity was controlled using a peristaltic pump longerpump bt600 2j baoding china and high purity deionized water was pumped from the feed tank a screen with a diameter of 0 5 mm was installed at both the inlet and outlet to allow for a uniform inflow into and outflow from the soil column as an example the calibration of transport parameters was illustrated using sps with a median particle size of d 50 10 μm as the seepage velocity reached a steady state v inj 30 ml of the sp solution was injected into the soil column instantaneously within t inj 2 s i e pulse pattern three seepage velocities v 0 087 0 173 and 0 260 cm s and four injection concentrations c inj 0 5 1 3 and 4 mg ml were used in this study the disturbance caused by the instantaneous injection of sps to the desired flow velocity e g v 0 087 cm s by the peristaltic pump could result in substantial changes in the actual flow velocity and injected sp concentration on the surface of the column which were corrected with the following equations 15 u 0 t u 0 v inj n a t inj 1 h t t inj 16 c 0 t m v inj q t inj 1 h t t inj where h t is the unit step function u 0 v n is the predetermined seepage velocity a is the cross sectional area of the soil column l2 q va is the flow rate l3t 1 t inj is the injection time t m is the total mass of sps injected into the porous media m and v inj is the injection volume l3 to verify the reliability of the proposed attachment detachment model the transport experiments of sps were also conducted in the case of continuous injection under variable injection concentration and seepage velocity conditions the two patterns of variable concentration for two particle sizes i e d 50 2 or 10 μm are as follows the injection concentration c inj 0 1 mg ml is increased to c inj 0 5 mg ml and then to c inj 2 mg ml after a predetermined time under three darcy velocities v 0 087 0 173 and 0 260 cm s or the injection concentration c inj 2 mg ml is decreased to c inj 0 5 mg ml and then to c inj 0 1 mg ml under a darcy velocity of v 0 260 cm s the four patterns of variable velocity for three particle sizes d 50 2 10 and 50 μm c inj 2 mg ml are as follows the darcy velocity is increased v 0 087 0 173 cm s v 0 087 0 260 cm s and v 0 173 0 260 cm s or decreased v 0 260 0 173 cm s 4 solution and parameter sensitivity analysis 4 1 coordinate transformation a one dimensional case is analyzed and the initial concentration of sps is zero the penetration rate m b is defined as the ratio of the mass of sps flowing through the cross section x at time t to the total mass of sps injected into the porous media 17 m b 0 t c x t u n a d t m clearly m a 1 m b is the amount of sps deposited in the range of 0 x in the column let the dimensionless time be t p unat nal ut l and the dimensionless concentration be c x t p c x nal t p una where l is the column length thus eq 17 becomes 18 m b nal 0 t p c x t p d t p m in fact t p is the ratio of the water volume q t q t unat passing through the cross section during time t to the pore volume of the column v 0 nal which can also be represented by the pore volume pv pv t p bai et al 2017 the derivative of eq 18 with respect to t p yields the relative concentration cr 19 c r v 0 m c x t p the transport process of sps in porous media is calculated using the pardiso solver of the comsol multiphysics software comsol co ltd then eq 2 is solved using the transport of diluted species interface and m b and cr are calculated using the global ordinary differential equations and differential algebraic equations 4 2 parameter sensitivity analysis if there is only a small difference between the bending shape of the initial deposition process o b a in fig 1 and the bending shape of the release redeposition process b c d in fig 1 then it can be assumed that β β 1 β 2 then η κ r κ d is defined to indicate the release effect on the deposition for harmonic changes in the concentration of sps on the surface of the column three parameters β η and λ in the attachment detachment model can affect the relative concentration cr in the outflow the injection concentration of sps is assumed to be fig 2 20 c c 0 sin 2 π t t where c 0 is the concentration amplitude and t is the period let c 0 2 mg ml t 120 s i e the injection time is 60 s and the injection velocity v 0 087 cm s fig 2 shows the sensitivity of parameters β η and λ to the penetration rate m b recovery rate of sps in the outflow where c out is the outflow concentration the calculation result shows that m b 82 6 when β 0 01 η 0 5 κ d 0 01 ml mg and λ 0 02 10 3 as the attenuation factor increases from β 0 to β 1 the penetration rate m b of sps increases and then remains steady thus the nonlinear deposition process β 0 can decrease the amount of sp deposition when β 1 the penetration rate can reach 98 7 indicating an obvious decrease in the deposition amount as the value η η κ r κ d η 0 1 increases the penetration rate m b increases almost linearly as a result m b 100 is obtained when η 1 fig 2 shows that as the injection concentration of sps decreases i e after c out c 0 1 the release effect increases with the increase in η e g η 0 2 0 5 0 9 indicating a more obvious tailing phenomenon the reaction rate constant λ indicates the interaction between sps and the porous medium matrix as the value λ increases the penetration rate m b decreases rapidly from m b 100 when there is no attachment or adsorption λ 0 to m b 0 when sps and the porous medium matrix are completely coupled λ 0 3 10 3 thus the value λ has an important influence on the calculation results and the range is λ 0 0 3 10 3 which is closely related to the physical and chemical properties of sps and the porous medium matrix 4 3 gaussian pulse injection of sps to test the applicability of the attachment detachment model the seepage velocity is assumed to decrease exponentially with time 21 u t u i e α t where u i is the initial seepage velocity and α is the attenuation parameter t 1 clearly a constant seepage velocity can be obtained when α 0 the injection concentration of sps on the surface of the column c 0 t f t is assumed to be a pulse periodic function fig 3 which can be described by the gaussian function 22 f t w 2 π e t t i n b 2 2 t i n t t i n 2 b 0 otherwise where t i n is the starting time of pulse n n is the cycle number b is the peak characteristic value of the gaussian function and w is the injection amount of sps for each pulse and thus w t i n t i n 2 b f t d t assume that v inj 30 ml of sps is injected over a period of t inj 2b 2 s for each pulse injection the initial seepage velocity in eq 21 is u i 0 15 cm s it is assumed that α d 0 4 cm β β 1 β 2 and α 0 001 s 1 when the velocity is attenuated fig 4 shows the variation in the relative concentration of sps in the flowing water with time at different positions x 5 10 20 and 30 cm from the injection surface where the injection period is t 60 s the attenuation factor β 0 01 the reaction rate constant λ 2 10 5 s 1 the transient equilibrium constant κ d 0 01 ml mg and κ r 0 005 ml mg the relative concentration of sps changes periodically at x 5 cm and the peak decreases as the pv increases indicating an increase in the interactions between the sps in flowing water and the porous medium matrix over time and consequently an increase in the deposition amount however as the distance from the injection surface increases the periodic change in the relative concentration of sps becomes less pronounced e g x 20 cm fig 4 c and even disappears e g x 30 cm fig 4 d due to the convection dispersion and adsorption effects there is a substantial amount of sps deposited on the porous media for instance at a constant velocity α 0 see the solid line in fig 4 the deposition amount is m a 16 6 m b 84 4 at x 0 5 cm and m a 27 5 m b 72 5 at x 0 30 cm thus the deposition amount at x 5 30 cm accounts for only 10 9 indicating that the deposition amount decreases rapidly with increasing transport distance fig 4 shows that there is a very low concentration of sps at x 5 cm when pv is larger than 1 5 as the distance from the injection surface increases to x 20 cm the relative concentration decreases to 0 at a pv of approximately 2 5 indicating an obvious retardation phenomenon in addition as the transport distance x increases the peak of the relative concentration decreases rapidly for instance c r 1 45 at x 5 cm and c r 0 58 at x 30 cm for the first peak when the attenuation parameter of the seepage velocity is α 0 001 s 1 the peak sp concentration c r is initially greater than the case without attenuation α 0 and then decreases as the cycle number increases in addition as the transport distance x increases the occurrence of the peak is delayed and the sp penetration rate m b decreases which can be attributed to the decrease in the seepage velocity during the later period the results show that for the proposed nonlinear model eqs 6 and 7 where κ d 0 08 ml mg κ r 0 04 ml mg and β 0 01 and its degenerated linear form β 0 the penetration rate is less than 100 after the cyclic deposition of sps a large difference in the pulse injection period will result in substantial differences in the concentration evolution process and the peak of sps in the outflow water as well as in the attachment amount of sps during the transport for instance the penetration rate at x 20 cm is m b 82 2 72 1 and 46 9 when t 6 60 and 120 s β 0 01 respectively in addition the shorter the time period e g t 6 s is the more rapid the increase in the penetration rate is and the higher the peak relative concentration c r is which is related to the reaction rate constant λ between the sps and the porous medium matrix i e nonequilibrium hydrodynamic process the result also shows that increasing the value β e g β 0 0 01 0 1 at t 60 s results in an increase in the penetration rate m b 63 7 72 1 74 4 thus it is possible that the use of linear models results in an overestimation of the adsorption capacity of porous media 5 experimental calibration of the transport parameters fig 5 shows the variation process of the static attachment concentration s with an increase or a decrease in the suspension concentration c and that the rate of increase in the attachment concentration of sps tends to decrease as the suspension concentration c increases observable adsorption occurs for small particle sizes such as d 50 2 μm whereas a straining effect occurs for large particle sizes such as d 50 50 μm as a result medium sized particles e g d 50 10 μm seem to show relatively smaller deposition amounts notably the release process of sps is relatively gentle at first and then becomes steeper and the final deposition amount differs significantly for sps with different particle sizes van genuchten and wierenga 1977 showed that the release process of 2 4 5 t a soluble compound was obvious at the very beginning and the final adsorption amount was very small which could be related to the particle size of the suspended substance soluble material or colloids the static deposition process curve was fitted using eq 6 and the parameter β 1 could be obtained the release process was fitted using eq 7 where the parameter β 2 was assumed to be equal for each release process i e scanning desorption isotherms and then the relationship between s and c c p for all release processes could be obtained origin 8 5 originlab corporation was used for the calculations the parameters β 1 and β 2 are shown in table 1 the coefficients of determination are r 2 0 99 and r 2 0 96 indicating good fitting fig 6 shows the experimental btcs of sps d 50 10 μm under pulse injection conditions and the calculated curves fitted using comsol multiphysics comsol co ltd the control parameters in the calculations are as follows the temporal discretization step is 3 s the spatial discretization step is 0 02 m the damping factor is 0 9 the iteration number is 4 and the relative tolerance is 0 0001 here there are six parameters β 1 β 2 κ d κ r α d and λ and β 1 and β 2 can be obtained from the static deposition tests generally the dispersivity increases with increasing particle size and slightly increases with increasing velocity ahfir et al 2009 chrysikopoulos and katzourakis 2015 it is not closely related to the injection concentration bai et al 2017 bennacer et al 2017 here the dispersivity α d is simply assumed to be α d 0 4 cm according the test results in this paper the remaining three parameters κ d κ r and λ can be uniquely fitted by the pulse injection experiments given in fig 6 the iteration is repeated until the required accuracy is reached when d 50 10 μm fig 6 the coefficient of determination is r 2 0 99 indicating good agreement between the results obtained from the nonlinear attachment detachment model and the experimental results the peak values of btcs generally lag e g pv 1 fig 6 which is related to the existence of adsorption hysteresis similar results were explained by altoe et al 2006 using a theoretical model considering the effect of the dispersive flux on the retention kinetics during the deposition process in particular the release of deposited sps is well illustrated in the latter part of the curves e g pv 2 which show that the penetration concentration of sps to be higher than 0 for a long time e g fig 6 d fig 6 shows that as the injection concentration increases the penetration rate of sps first decreases and then increases for instance the penetration rate at a darcy velocity of v 0 260 cm s is m b 65 8 58 3 70 0 and 76 6 at injection concentrations of c inj 0 5 1 3 and 4 mg ml respectively similar results can also be obtained at darcy velocities of v 0 087 and 0 173 cm s and the results are in line with previous findings bai et al 2017 chrysikopoulos et al 2017 thus there is a nonlinear relationship between the attachment concentration and suspension concentration indicating the existence of the maximum attachment concentration σ max at a low suspension concentration the dynamic attachment concentration σ on the matrix is not saturated and thus the matrix can still adsorb sps as a result the penetration rate m b decreases as the injection concentration increases when the suspension concentration is higher than a given value σ reaches a saturation level and the increment in the attachment concentration gradually approaches zero accordingly the porous medium matrix cannot adsorb more sps even at a high injection concentration and thus the penetration rate of sps increases the transport parameters β 1 β 2 κ d κ r α d and λ of sps in porous media can be affected by a wide variety of factors such as the seepage velocity injection concentration and particle size of the sps additionally the problem is more complex because these factors are interrelated and change constantly with the transport distance and time fig 7 shows the variations in κ d κ r and λ fitted in fig 6 as a function of the darcy velocity under different injection concentrations c inj 0 5 1 3 and 4 mg ml the results show that in the range of v 0 087 0 263 cm s the values of κ d and κ r remain almost unchanged with increasing seepage velocity which can be assumed to be constant in fact κ d and κ r are used to characterize the deposition of sps under static conditions because they are more related to the particle size of the suspended substance and the properties of the solution than to the seepage velocity thus the parameters κ d and κ r are taken to be the average of the fitted values table 1 for instance for d 50 10 μm κ d 0 69 ml mg and κ r 1 01 ml mg fig 7 shows that the parameter λ increases as the seepage velocity increases indicating an increase in the interaction between the sps and the porous medium matrix thus the seepage velocity evidently affects the transport process of sps 6 verification of the proposed model and discussion the experimental schemes are described in section 3 2 fig 8 shows the btcs of sps when the injection concentration is increased denoted by hollow dots or decreased denoted by solid dots fig 9 shows the btcs of sps when the seepage velocity is increased denoted by hollow dots or decreased denoted by solid dots figs 8 and 9 also give the simulated curves by the proposed nonlinear attachment detachment model and the adopted parameters can be seen in table 1 the transport processes of sps are calculated using the pardiso solver in comsol multiphysics comsol co ltd clearly there is good agreement between the simulated and experimental btcs with a coefficient of determination of r 2 0 91 for d 50 2 μm fig 8 a when the injection concentration is increased from c inj 0 1 mg ml to c inj 0 5 mg ml after pv 2 75 and then to c inj 2 mg ml after pv 4 61 the effluent concentration c out clearly increases this increase reflects the nonlinear deposition process of sps i e the relative decrease in the deposition amount in contrast the effluent concentration c out decreases when the injection concentration is decreased from c inj 2 mg ml to c inj 0 5 mg ml after pv 2 75 and then to c inj 0 1 mg ml after pv 4 61 certainly due to the decrease in the injection concentration the release effect of the already deposited sps prolongs the sp penetration process which produces a relatively high effluent concentration over a long period of time i e pv 4 61 similar results are also obtained when d 50 10 μm fig 8 b it is no more than that the effluent concentration c out is generally greater than that when d 50 2 μm fig 8 a and the required steady time is also shortened moreover with the increase in the injection concentration i e c inj 0 1 0 5 2 0 mg ml the rate of increase in the effluent concentration c out increases more obviously for d 50 10 μm than for d 50 2 μm fig 8 b this increase can be attributed to the weaker adsorption of large sized particles according to the static deposition tests see fig 5 c certainly with a further increase in particle size the straining effect of the porous medium pores on sps manifests which induces a decrease in the effluent concentration c out for example when the particle size increases from d 50 10 μm to d 50 50 μm c inj 2 mg ml v 0 260 cm s see the solid dots of fig 9 b and c the effluent concentration decreases from c out 0 94 mg ml to c out 0 50 mg ml fig 9 shows that increasing or decreasing the seepage velocity results in clear increases or decreases in effluent concentration c out respectively the influence of the seepage velocity mainly includes the two aspects of nonequilibrium adsorption and particle kinetic capture on the one hand the increase in the seepage velocity enhances the interaction between sps and the porous medium matrix i e increasing the reaction rate constant λ see fig 7 and correspondingly shortens the time to reach the adsorption equilibrium state which objectively accelerates the deposition of sps on the other hand the increase in the seepage velocity strengthens the hydrodynamic force acting on sps and actually enhances the movement of sps along the flowing water for small sized particles the sp matrix interaction plays a dominant role and is related to the aggregation capillary condensation and active energy of the suspended substances in contrast for large sized particles hydrodynamic forces play an important role except for the hysteresis caused by the collisions between sps and between sps and the matrix as a result the transport of sps exhibits an obvious nonlinear deposition process as shown in fig 9 when the particle size increases from d 50 2 μm to d 50 10 μm and then to d 50 50 μm at a given velocity the effluent concentration c out exhibits a trend of first increasing and then decreasing certainly there will be an increase in the effluent concentration c out when the seepage velocity increases e g v 0 087 0 260 cm s see the comparison of fig 9 b and c 7 conclusions a nonlinear attachment detachment model with adsorption hysteresis is proposed which uses an adsorption function and scanning desorption isotherms to model the deposition effect of sps the reaction rate constant related to hysteretic characteristics essentially reflects the nonequilibrium hydrodynamic process during the transport of sps static deposition tests and column experiments with pulse injection are used to calibrate the transport parameters column penetration experiments are performed under variable injection concentrations and seepage velocities the results show that there is good agreement between simulated and experimental btcs when the injection concentration is increased the effluent concentration clearly increases which actually reflects a nonlinear deposition process in contrast with a decrease in the injection concentration the release effect of the already deposited sps prolongs the penetration process which is also related to the hysteresis previously proposed linear attachment detachment models probably result in an overestimation of the adsorption capacity of porous media studies show that increasing the seepage velocity enhances the reaction rate constant between sps and the porous medium matrix and simultaneously strengthens the hydrodynamic force acting on sps which actually promotes the movement of sps along the flowing water for small particles the reaction rate constant is the dominant factor nevertheless for large particles the hydrodynamic force plays an important role except for the hysteretic effect caused by the collisions between sps and between sps and the solid matrix declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was financially supported by the beijing natural science foundation 8182046 and the national natural science foundation of china 51678043 51878035 the authors would like to thank the reviewers and editor for their constructive comments 
