index,text
4040,rain on grid rog modelling is an increasingly popular approach within the storm risk management in which the hydrological and hydrodynamic flood processes are modelled entirely within the 2d hydrodynamic model contrarily to what was done in the context of flood propagation in rivers at the present time no systematic benchmarking study of the software packages implementing this approach is available in the literature the need of benchmarking studies related to the rog approach is becoming ever more important for hec ras 2d hr2d the use of which has been rapidly increasing in the last few years as further testified by very recent papers explicitly focussed on this research issue however there is still a lack of studies that clearly show the suitability of this software package as a reliable fully integrated hydrologic hydrodynamic model therefore the novelty introduced by this paper is the benchmarking of hr2d for rog simulations analysing several situations representing most of the applications related to storm event hazard assessment specifically after the analysis of ideal cases which gave the opportunity to carefully assess the accuracy of the numerical schemes for rog simulations practical applications were considered to face some challenging issues related to the analysis of rainfall runoff in urbanized areas and actual basins including the numerical treatment of buildings and the computation of infiltration losses within hydrodynamic computations the hr2d results were compared to analytical solutions when available experimental data and numerical solutions of a numerical code developed by the authors the results shown in the paper highlight the potential but also the limitations of this software package providing evidence to scientists and technicians about those situations for which reliable results are expected but also indications on specific aspects that need improvements so as to increase the model accuracy keywords hecras rain on grid storm hazard assessment model benchmarking shallow water modelling 1 introduction understanding the effects of flood inundation in terms of area depth velocity and time is a key element for efficient flood risk management therefore the use of suitable mathematical models for flood inundation mapping differentiated according to characteristics of the flood event is a major step for the implementation of any flood management strategy it is well known that floods can arise from a variety of causes but the most common type is the so called fluvial flooding that occurs when following intense rainfall and or melting snow water levels in rivers rise and the rivers overtop their banks the general approach for the generation of fluvial flood hazards maps along large rivers is quite consolidated and it is commonly organized into two main steps requiring the use of two separate models consecutively in the first one attention is mainly focused on the computation of a discharge hydrograph related to single runoff events using consolidated hydrological rainfall runoff models then the calculated hydrograph is used as the upstream boundary condition of a two dimensional 2d hydrodynamic model however there is a growing awareness of different types of non fluvial flood events that show apparent increasing frequency and due to climate change are predicted to increase further they originate from heavy rainfall storm event hazard have different characteristics than fluvial floods since they occur apart from large rivers and are often characterized as flash or pluvial floods yin et al 2016 schanze 2018 pluvial flooding can be broadly defined as flooding that results from rainfall generated overland flow and ponding before the runoff enters any watercourse drainage system or sewer or cannot enter it because the network is full to capacity falconer et al 2009 this term is sometimes distinguished from flash flooding which may also be associated with heavy rainfall but usually arises from a watercourse rainfall non fluvial floods are modelled following the approach known as direct rainfall modelling or rain on grid rog in which the hydrological and hydrodynamic flood processes are not modelled in two different model systems but entirely with the 2d hydrodynamic model this approach is increasingly used to determine the rainfall runoff processes of watersheds with different sizes see for example cea and bladé 2015 fernández pato and garcía navarro 2016 fernández pato et al 2016 bout and jetten 2018 costabile et al 2019 ferraro et al 2020 ming et al 2020 and also on an urban scale in which due to the high relevance of the sewer system the studies often focus on the concept of dual drainage chang et al 2015 leandro et al 2016 jang et al 2018 li et al 2020a the aforementioned studies testify the increasing interest for this kind of approach and in the future the number of works dealing with this topic are expected to have the same diffusion of those related to fluvial flooding in previous years in particular specific attention to the benchmarking of software packages implementing this approach is likely to occur going through the significant amount of research carried out for fluvial flooding models in this latter context this important research activity was motivated by the strong need to provide evidence about the reliable predictions of the flood packages and a data set against which such numerical codes can be evaluated and differentiated in terms of performance and predictive capability specifically 2d software packages may have different features in terms of 1 the physical processes simulated by the model s mathematical formulation 2 the approximate numerical method used to solve the mathematical formulation 3 the configuration of the numerical grid upon which the numerical method is applied the first rigorous comparison of 2d hydraulic models was carried out by hunter et al 2008 comparing six models representing a wide spectrum of fundamental equations and numerical schemes to simulate surface flooding of a small urban catchment then a great effort was made within the environment agency defra department for environment food rural affairs uk which faced this issue in several reports in particular in a well known report néelz and pender 2010 10 benchmark test cases were presented against which 14 2d flood inundation modelling packages were tested and compared this study was updated in 2013 néelz and pender 2013 taking into account the further development of the already used software packages and the new ones that had become available neal et al 2012 used some of these test cases to benchmark three 2d models that can be broadly defined as simulating diffusive inertial and shallow water waves in order to understand how much physical complexity a flood inundation model needs for a given problem the model benchmarking carried out by néelz and pender 2013 has been used several times in the literature to check the performance of new models for flood mapping see for example leandro et al 2014 guidolin et al 2016 ayog et al 2021 unlike the fluvial flooding models at the present time no systematic benchmarking study of the software packages implementing the rog approach is available in the literature identifying a clear gap in the literature it should be recalled that rog simulations have specific and different features to the traditional 2d fluvial flood computations due to the very low value of surface runoff that may amplify the common problems related to the management of wet dry fronts instabilities due to roughness computations and inaccuracy related to numerical treatment of highly irregular topography see for example costabile et al 2013 cea and bladé 2015 therefore in our view there is the need of benchmarking studies related to rog modelling that along the lines of the research carried out by néelz and pender 2010 néelz and pender 2013 can provide 1 evidence about the accuracy and reliable predictions of the industrial flood packages and 2 a data set against which such software can be evaluated and differentiated in terms of performance and predictive capability this research issue gains much more importance when referred to the most used hydrodynamics models from both the scientific and technical points of view in this context the software hec ras 2d hereafter hr2d plays a leading role a scopus search highlighted that the number of papers per year having hec ras in the article title abstract or keywords has more than doubled in the last five years resulting in more than 200 documents in 2020 this significant increase is probably due to the launch of the version 5 0 in 2016 in which several new tools were introduced such as the module for two dimensional computations specifically the analysis of the related literature highlighted that hr2d was extensively used in flood mapping for estimating 1 flood magnitude van der meulen et al 2021 urban flood hazard yalcin 2019 rangari et al 2021 also using probabilistic approaches bhola et al 2020 and analysing the effects of bridges trueheart et al 2020 2 the influence of the topographic data on flood extent farooq et al 2019 stoleriu et al 2020 li et al 2020b yalcin 2020 ongdas et al 2020 muthusamy et al 2021 3 the performances of commercial and research software liu et al 2019 pinos and timbe 2019 shustikova et al 2019 sridharan et al 2020 and benchmarking of simplified models jamali et al 2019 afshari et al 2018 4 compound flooding saleh et al 2017 gori et al 2020 khanam et al 2021 5 potential or historical flooding due to dam dyke breaching albu et al 2020 urzică et al 2021 feroz islam et al 2019 pilotti et al 2020 and glacial lake outburst kougkoulos et al 2018 majeed et al 2021 besides these more traditional issues it is worthwhile to mention the popularity gained by hr2d in emergent fields of research such as ecohydraulics adeva bustos et al 2019 juárez et al 2019 papaioannou et al 2020 and the natural flood management keys et al 2018 pal et al 2020 ferguson and fenner 2020 tamagnone et al 2020 the widespread use of hr2d within the scientific community is expected to further increase in the near future considering also the new tools available in the just released version 6 0 that allow scholars and technicians to perform more reliable rog simulations in particular this last version was enriched with some options to simulate non uniform spatial rainfall and to compute infiltration losses in a 2d cell this research aims at providing a contribution within the scientific framework described so far in particular the paper is motivated by two considerations the increasing attention devoted to the analysis of non fluvial risks for which the rog is the reference approach and the substantial lack of benchmarking studies of widely used software packages such as hr2d in situations like these on the other hand the need for this line of research has already been highlighted in the very recent literature david and schmalz 2020 zeiger and hubbart 2021 however though facing a similar general purpose this work differs from the above cited papers since it is oriented to assess the accuracy and reliability of hr2d as an integrated hydrodynamic hydrologic model supporting storm risk management that therefore represents the focus and the novelty of this research to face this challenging issue an extensive benchmarking is presented analysing situations representative of most of the applications related to storm event hazard assessment specifically the paper is organized considering phenomena of increasing levels of trouble ranging from ideal cases to practical applications comparing the hr2d results to analytical solutions experimental data and results obtained by a numerical model specifically developed by the authors for problems like these the paper is organized as follows attention is firstly dedicated to the conceptualization of the work and particularly to the rationale used for the identification of the case studies and the description of the numerical benchmark section 2 the list of the test cases is presented in section 3 while section 4 is devoted to the analysis of the results finally the discussion of the results in the light of recent literature is provided in section 5 followed by the conclusions 2 conceptualization and methodological issues the conceptualization of this research involves essentially three aspects the first one revolves around the criteria used for the selection of specific test cases able to stress the performances of the hr2d model in challenging situations from both purely numerical and practical points of view the second one is represented by the need of testing the accuracy and the stability of the two numerical schemes implemented in the last released version of hr2d for solving fully dynamic wave equations finally the third aspect relates to the use of a numerical model the results from which are used for comparative analysis 2 1 rationale used for the identification of the case studies in the style of the benchmarking studies of 2d fluvial flooding models fewtrell et al 2011 neal et al 2012 néelz and pender 2013 a series of ideal and real world test cases are selected basically several idealized tests to check the accuracy and stability of the numerical algorithms implemented in hr2d were simulated this is a crucial issue from the authors point of view since as is well known in the literature the presence of very shallow depths over complex topography and wet dry interfaces may lead to several numerical problems when using fully dynamic wave equations in overland flow simulations these problems clearly are emphasized by the presence of a great number of computational dry cells becoming wet due to the rainfall input and subsequently dry out because of high bed slope so errors and instabilities come from steep bed slopes because more water than that actually contained in the wet cell may be computed as flowing in the dry cell and as a consequence the negative water depth may induce numerical instability or violation of the mass conservation leading to a gain of mass therefore specific treatments should be implemented in order to manage these situations see for example brufau et al 2004 liang and borthwick 2009 costabile et al 2013 further singularities may arise because of the bed friction term when the water depth becomes very small something which often occurs in overland flow simulations in these situations the bed friction term may dominate other terms of the momentum equation since it is inversely proportional to the 4 3 power of the water depth to the author s knowledge no studies exist that show performances of hr2d in those specific situations and therefore a profound analysis of situations like these is essential in a benchmarking study so the use of ideal tests in highly controlled and simplified environments will help in understanding the inherent properties of the numerical methods implemented in hr2d subsequently attention is devoted to situations closer to reality in this context the runoff simulation in urban areas is a major issue that gains further importance in a climate change context kaspersen et al 2017 padulano et al 2021 two important aspects are discussed the first one is related to the modelling approaches able to take into account the effects of buildings on the surface runoff as is well known one of the most used approaches to that purpose is to consider them as holes in the computational grids imposing solid wall conditions on the boundaries to the authors knowledge this option cannot be used within hr2d therefore the interest here is to test the suitability of this software package in the application of two other modelling strategies in the first one known as buildings resistance br method a large resistance parameter value is arbitrary assigned to cells that fall within the buildings footprints in the second scenario known as the buildings block bb method spatially distributed ground elevation data are raised to the heights of rooftops so that buildings appear as blocks in the topographic model used for flow simulation the second situation related to inundations of urban areas analyzed here is represented by the suitability of hr2d to deal with flow originating from different sources for example a rainfall input applied to the model grid and a point source flow at relatively high resolution such a situation allowed us to assess the capabilities of the model to handle complex topography and the related complex flow structures due to both sources of flows finally this work is oriented at providing indications about hr2d performance in very challenging situations such as the rainfall runoff modelling in natural basins for which several efforts have been made in the literature to get stable and accurate results the aim of this part of the research is not only the evaluation of the performances of hr2d using the rog that in any case would be a novelty in itself due the lack of studies on this the works by david and schmalz 2020 costabile et al 2020a zeiger and hubbart 2021 are exceptions the further purpose is to explore the potential of hr2d as an integrated hydrologic hydrodynamic model in which even the infiltration losses recently added in version 6 0 are considered in just one modelling tool in this regard the applications shown here represent the most challenging ones for the use of hr2d therefore the analyzes performed here is grouped in four main relevant situations 1 tests over impervious permeable planes using steady and uniform rainfall 2 tests over planes using unsteady or non uniform in space rainfall 3 tests in idealized or real world urban areas 4 rainfall runoff simulations in actual catchments considering net rainfall and gross rainfall so as to consider the effect of the infiltration losses inside the hr2d ultimately the analyzed tests are devoted to covering most of the applications related to storm event hazard assessment except those situations strictly related to urban drainage modelling in which the description of the interaction with the sewer system makes the application in hr2d quite complex all the case studies are presented in section 3 2 2 numerical solvers implemented in hr2d the hr2d model allows the user the choice of three equation sets namely 2d diffusion wave equations not considered in this work shallow water equations swe elm with a eulerian lagrangian approach to solving for advection or a new shallow water equation solver swe em that uses a eulerian approach for advection the governing equations are not reported here for the sake of brevity and the reader can refer to the user s hydraulic reference manual version 6 0 as reported in that manual the original solver swe elm is claimed to be more than adequate for most problems requiring the full momentum equations the last option swe em added only in version 6 0 is claimed to be more momentum conservative but may require smaller time steps and produce longer run times and therefore it is suggested only when the user is interested in very localized phenomena changes in water surfaces and velocities at and around hydraulic structures piers abutments and tight contractions and expansions the swe em uses an explicit solution scheme based on a strictly conservative form of the momentum equation according to the reference manual swe em solver produces less numerical diffusion than the original swe elm solver if a time step controlled by the courant number 1 0 is setup otherwise instabilities are expected to occur due to the explicit nature of the scheme both the numerical schemes will be used here in order to provide evidence about their accuracy and reliability 2 2 1 computational options and tolerance hr2d model allows the user to set the tolerance on both the 2d water surface elevations and the volume basically if the maximum error is greater than the set tolerance then the program will iterate to get a better answer the program will only iterate up to the maximum number of iterations set by the user therefore the maximum iteration allows the scheme to solve the equations with the minimum numerical error which has to be contained in the tolerance value for further details one may refer to the 2d modeling user s manual as for the simulations shown here in particular the tolerances thresholds were setup as small as possible 10 9 since the high degree of accuracy required in the tests case since a small tolerance was imposed the maximum number of iterations settable 40 was set according to the user s manual all the tests were run with a pure swe model no turbulent model was setup moreover the values of theta theta warmup were analyzed according to the 2d modeling user s manual this is the implicit weighting factor that is used to weight spatial derivatives between the current solution time line and the previously computed time line theta of 1 0 default uses only the currently solved time line for the spatial derivatives this provides for the most stable solution but possibly at the loss of some accuracy theta of 0 6 provides for the most accurate solution of the equations but tends to be less stable theta warmup is used during the model warmup and ramp up periods finally all the tests were performed using the adjust time step based on courant although the swe elm model can run with a courant number higher than 1 all the tests were run with a maximum value always less than the unity in order to correctly compare swe elm and swe em furthermore minimum courant number was set 1 100 of the maximum courant number the influence of all these parameters was checked in all the numerical tests highlighting negligible variations 2 3 unical benchmark model governing equations and numerical schemes different benchmarks for hr2d solutions were considered depending on features of the specific case study we used theoretical solutions related to the kinematic wave theory observed data and numerical solutions obtained from a code developed by the authors at the university of calabria italy hereafter unical that proved to be very reliable for simulations like these the rationale behind this choice is to provide evidence about the accuracy of hr2d in relation to a numerical model first order accurate in time and space developed for research purposes in other words the unical model is not used here to understand which model performs better but to have a reference numerical solution representative to what a reliable swe numerical model first order accurate in time and space can provide in terms of numerical simulations it should be observed that the reason of important discrepancies between model simulations and observed theoretical reference solutions can be found in the physics of the governing equations or in some numerical inaccuracy of the solvers in case of inaccurate solutions generated by hr2d and reliable simulations provided by the unical model the reason cannot be found in the physics of the governing equations but in some deficiencies of the numerical solvers therefore the use of unical model aims at certifying the presence of numerical errors in the solution of the numerical solvers implemented in hr2d and its solutions will be shown in particular in those cases for which hr2d predictions highlight important discrepancies in respect to the theoretical or experimental solutions the unical model is based on the 2 d swe that can be expressed in the following form 1 u t f x g y s where 2 u h h u h v f hu h u 2 g h 2 2 h u v g hv h u v h v 2 g h 2 2 s r f g h s 0 x s fx g h s 0 y s fy in which t s is time x m y m are the horizontal coordinates h m is the water depth u m s v m s are the depth averaged flow velocities in x and y directions g m s2 is the gravitational acceleration r m s is the rain intensity and f m s are the infiltration losses s0x m m s0y m m are the bed slopes in x and y directions sfx m m sfy m m are the friction slopes in x and y directions in equation 2 the source term s in the mass continuity equation is not zero both the rainfall and the infiltration losses are included therefore acting on the source term the swes have the ability to apply rain directly to a two dimensional grid implementing the rog approach the model is developed for unstructured grids based on irregular triangular elements to obtain the computational domain for the numerical integration of system 1 the model is based on finite volume methodology in particular the roe scheme 1981 first order accurate in time and space is used for the computation of the numerical fluxes the numerical integration of the shallow water equations in complex topographies requires further specific algorithms to the numerical treatment of the bottom slope of the friction slope and of the wet dry fronts for the sake of brevity only some key aspects of the model are recalled here a in order to ensure the stability of the model the time steps have been estimated according to the well known cfl condition b an upwind approach inspired by brufau et al 2004 is used to discretize the bottom variations c a semi implicit treatment of the friction source term is implemented costabile et al 2013 cea and bladé 2015 d a robust wet dry procedure is considered costabile et al 2013 this model was used for several different applications ranging from flood mapping in urban environments macchione et al 2019 costabile et al 2020b costabile et al 2021 to runoff simulations at basin scale costabile et al 2020a costabile and costanzo 2021 3 description of the numerical tests and available data 3 1 runoff over impervious or permeable planes using steady uniform rainfall three different tests characterized by geometries from low to high slopes and different values of rainfall input are performed in fig 1 an overall quick view of these tests is given the first one test 1 hereafter was proposed by gottardi and venutelli 1993 and then considered in other works see for example jaber and mothar 2003 for which the kinematic analytical solution given by stephenson and meadows 1986 can be used the watershed is represented by a plane having these characteristics low slope plane sl 0 0005 st 0 500 m long manning roughness coefficients nx ny 0 02 sm 1 3 a steady uniform rainfall rate r equal to 0 33 mm min was set for a duration d equal to 200 mins the second test test 2 hereafter was first introduced by singh 1996 and further used in several papers in the literature see for example tsai and yang 2005 singh et al 2015 in this case a steady and uniform rainfall intensity r equal to 300 mm h and duration d of 1600 s was set to simulate the overland flow over a plane with a length l 500 m and slopes sl 0 01 and st 0 the manning roughness coefficient was considered equal to 0 02 sm 1 3 also in this case the kinematic analytical solution can be computed the third test test 3 hereafter see fig 1 right panel is an experimental test carried out by lima 1982 who used a laboratory soil flume 1 m long 0 5 m wide having a slope equal to sl 0 01 st 0 the soil was a loam the bottom of the flume consisted of a metallic perforated plate to collect percolation water the rainfall simulator is able to generate a uniformly distributed rainfall pattern equal to r0 135 mm h for a duration of d 15 mins 3 2 runoff over impervious planes using unsteady or non uniform rainfall in this group of tests three differentiated situations were considered one of which is related to an unsteady rainfall and the remaining two are referred to non uniform rainfalls see fig 2 the first test of this category test 4 hereafter was proposed by tsai and yang 2005 the plane has the following characteristics length l 1000 m longitudinal slope sl 0 01 st 0 manning s coefficient equal to nx ny 0 02 sm 1 3 the unsteady rainfall duration is d 3 4500 s see fig 2a from d 1 1500 s to d 2 3000 s the rainfall rate is equal to r 2 300 mm h whereas it is equal to r 1 100 mm h outside this interval the last two tests considered here refer to steady and non uniform rainfalls in this context attention is firstly focused on the experimental tests carried out by iwagaki 1955 this test test 5 hereafter was used for validation purposes in several papers zhang and cundy 1989 feng and molz 1997 fiedler and ramirez 2000 west et al 2017 ding et al 2018 hu and song 2018 aureli et al 2020 the experiments consist in a rainfall runoff situation over a cascade of three planes fig 2b each plane section was 8 m long the slopes of which were equal to 0 02 0 015 and 0 01 in the downstream directions each section received a constant rainfall input of 389 230 and 288 cm h respectively three rainfall durations were considered in the experiments for which discharge and water depth hydrographs are available for the sake of brevity we considered only the durations d 10 s and d 30 s finally the last application test 6 hereafter considered for this category refers to a well known test in the literature see for example di giammarco et al 1996 kim et al 2012 xia et al 2017 hou et al 2018 shu et al 2020 and for which an analytical solution is available stephenson and meadows 1986 it is a v shaped catchment see fig 3 c having a single slope on both the plane sp 0 05 and the channel sc 0 02 the depth of the channel varies from 1 m at the upstream end to 20 m at the downstream end the intensity of the rainfall input r 0 is 10 8 mm h and duration d of 1 5 h the precipitation does not affect the channel interesting only the valley side the assigned values of the manning s coefficients are 0 05 s m 1 3 for the valley side and 0 15 s m1 3 for the channel 3 3 runoff over idealized and real world urban areas two tests were considered in this group one of which is represented by an idealized urban area whereas the other one is a real world situation specifically the first test hereafter identified as test 7 refers to the experiments performed by cea et al 2010 and considered for validation purposes by several authors in the literature see for example fernandez pato and garcia navarro 2016 xia et al 2017 su et al 2019 caviedes voullième et al 2020 the designed experimental urban catchments were made of three planes each of them with an approximate slope of 0 05 but once the experiment was set up the real topography was similar to what is shown in fig 3a eight different urban configurations were built in the laboratory the configurations considered in this paper are shown in fig 3b and 3c the horizontal dimensions of the building are 20 cm 30 cm and the vertical outer walls are 20 cm in height a steady and uniform rainfall equal to 300 mm h was set and three different durations 20 40 and 60 s were considered in the experiments even though only the shorter one is considered here following cea et al 2010 the manning coefficient can be assumed equal to 0 016 s m 1 3 the only variable measured was the discharge hydrograph generated at the outlet of the basin located in the valley in the middle of the domain fig 3a which was used to validate the numerical results the second test used for this category hereafter identified as test 8 belongs to case studies used in the benchmarking analysis carried out by néelz and pender 2013 it is used for assessing the latest generation of 2 d hydraulic modelling tools and widely used in the literature for benchmarking purposes for the most recent ones see for example courty et al 2017 hu et al 2018 savant et al 2019 caviedes voullième et al 2020 it corresponds to a synthetic event on a real topography located in the urban area of glasgow scotland uk the modelled area is approximately 400 960 m and a digital elevation model having a spatial resolution of 2 m is available see fig 3d the event was designed to determine the models capability to correctly simulate flooding due to two different sources of water since the test attempts to mimic a common urban flooding scenario where a rainfall event overwhelms the drainage systemsand consequently causes flooding due to a surcharging pipe orstormwaterdrain thus the flood is assumed to arise from a point time dependent inflow representing a sewer outflow fig 3e and a uniformly distributed rainfall fig 3f applied to the modelled area the source point location is shown in fig 3d together with the 9 observation locations considered for results comparisons roughness values were assumed to be variable throughout the domain since roads and pavements have the manning s coefficient equal to 0 02 s m 1 3 whereas it was assumed 0 05 s m 1 3 elsewhere all domain boundaries are closed and therefore no outflow hydrographs are available contrarily to the previous cases for which hr2d was used for the first time in the literature in this work this test had already been simulated by brunner 2018 despite that in the author s opinion it is important to discuss it again in the light of the purposes of this paper especially in relation to the results obtained by the first order accurate in time and space model user here unical 3 4 runoff over actual catchments in this group two possible situations of interest in the rainfall runoff simulations over actual catchments see fig 4 were considered the first one is oriented at using hr2d for predictive purposes in cases for which no observed data related to rainfall flooded areas and discharge are available this is a common situation that characterizes small basins that very often are ungauged catchments for which it is not possible to have data for model calibration and validation as a consequence blind simulations should be performed for instance using a design net hyetograph as input the authors feel that in situations like these it is important to assess the performance of a commercial software using a state of the art model developed for research purposes as the benchmark solution therefore the benchmark for this test will be thus represented by the solution provided by the unical model the selected basin namely ar shown in fig 4a is a part of the ardivestra catchment located in the lombardia region northern italy having an extent approximately equal to 43 km2 a mean altitude of 423 m above sea level a s l and length of the main river equal to 22 4 km a lidar bare ground data was available from which 1 m dem was extracted following a common approach for technical studies a chicago hyetograph was obtained by the available rainfall duration curve corresponding to a return period of 200 years in which the net rainfall was computed through the scn cn method the roughness coefficient is considered variable throughout the domain according to the available map of soil use the second test is focused on the reconstruction of an observed event on a small basin in this case hr2d will be used for the first time in the literature as an integrated hydrologic hydrodynamic model at the basin scale able to be initialized by gross rainfall and in which the computation of the infiltration losses is computed within the model itself specifically we considered the turbolo catchment located in the calabria region southern italy the area of the basin is equal to 29 1 km2 agricultural and wooded areas represent the dominant land use while urbanization is less than 2 of the total catchment area a variable roughness was assumed based on the information related to the map of the soil use furthermore a lithologic map is available for this basin buttafuoco et al 2012 according to which the parameters of the green ampt model were roughly estimated using the value proposed in rawls et al 1983 the observed event selected for evaluating the performance of hr2d occurred between the 27th and 28th january 2004 the rainfall data used here was recorded by the rain gauge of the fitterizzi station located at 185 m above the sea level whereas the observed discharge refers to a section located downstream at 75 m a s l fig 4b 4 results 4 1 impervious or permeable planes using steady uniform rainfall two benchmarks were used for these tests the first one is related to the analytical solution of the kinematic wave modelling useful to check the overall behaviour of the simulated discharges since attention here is focused on the full momentum solution provided by hr2d a second benchmark was also considered which refers to the simulation obtained by the unical model applied to an unstructured triangular grid having almost uniform resolution equal to 25 m2 the same resolution was used for hr2d for which the reference grid is made of square elements having sides equal to l0 5 m the minimum and maximum courant number for hr2d was set equal to 0 01 and 0 3 respectively these values are significantly lower than those recommended in the user s manual preliminary tests not shown here for the sake of brevity highlighted that the model did not crash using recommended values for example 1 2 for swe elm option however unphysical results and oscillations in the hydrodynamic variables may be generated confirming that hydrodynamic features of overland flow simulations that are more critical than the traditional flood propagation study 4 1 1 test 1 impervious plane very low slope fig 5 a shows the comparison between the simulated discharges obtained by the hr2d model using both the swe em and swe elm numerical resolution algorithms on the reference grid and the solutions provided by the two benchmarks the hr2d solutions are in a good agreement with the analytical one reproducing the expected shape of the wave the differences near the peak value can be explained easily considering the fully dynamic version of the momentum equation implemented in hr2d as a proof of this the simulated hydrograph is very similar to the unical solution in this part of the graph even though the peak value is not exactly the same of that simulated by the two benchmarks though the shape of the rising limb of the hydrograph is fairly well reproduced by hr2d it can be observed that they are slightly shifted on the left in respect to those obtained by the two benchmarks see the magenta box in fig 5a finally it is interesting to observe the solutions obtained by hr2d in the falling limb of the hydrograph the simulations are in good agreement with the two benchmarks but a strange behaviour is reproduced approximately around t 300 min giving an unrealistic shape of the wave not simulated by the benchmarks that are very close together see red box in fig 5a therefore it is likely that a numerical error occurred probably due to some difficulties in the treatment of drying fronts in order to check the effect of this inaccuracy as a function of the grid size three further simulations were performed halving progressively the side length of the mesh 0 5 l0 0 25 l0 0 125 l0 respectively the results obtained by the two solvers are very similar so only the simulations obtained using the swe elm numerical solver are shown see fig 5b as highlighted in the purple box of fig 5b see also the black arrows the artificial step like behaviour simulated by hr2d em progressively vanishes reducing its value and appearing later on the simulation only when using a very fine grid 0 125l0 the solution provided by hr2d seems to be not affected by numerical errors and very close to the solution given by the unical models shown in fig 5b 4 1 2 test 2 impervious plane steep slope fig 6 shows the comparison between the water depth hydrographs simulated by hr2d and the two benchmarks using the reference grid side length l0 5 m the two numerical solvers implemented in hr2d are not in agreement with each other and gave quite different results from the numerical and analytical benchmarks that in turn are practically superimposed fig 6a the unphysical behaviour observed in the previous test seems to be much more important than what was observed in test 1 providing a quite poor prediction of the recession limb of the hydrograph fig 6a in particular the sudden decrease of the water depth is a clear indication of the presence of numerical inaccuracies that generated poor predictions after the end of the rainfall input it is not very simple to detect which numerical scheme implemented in hr2d performs better the new numerical solver swe em seems to perform a little bit worse swe elm than the traditional scheme since some significant discrepancy from the benchmark solutions can be observed also during the rising stage of the hydrograph also in this case we analyzed the role played by the grid size on the generation of these numerical inaccuracies as expected the use of finer grids led to an improvement of the solution in particular the sudden decrease of the water levels is reduced and temporally shifted meaning that the generation of the errors happens later on in the simulation in respect to the reference grid fig 6b the two numerical schemes converged to the same solution as the grid size decreases providing a solution closer to those predicted by the benchmark fig 6b however despite the use of a finer grid hr2d performed worse than the unical model in order to better understand the reasons behind the unphysical solutions given by the numerical solvers implemented in hr2d in fig 7 the comparison between the water depth and velocity profiles simulated by unical model and hr2d using the original solver swe elm is shown the grid resolutions used to that purpose were finer than that used for the unical model corresponding to the mesh side equal to l0 2 l0 4 and l0 8 moreover three instants of times were considered t 5 min 25 min and 35 min corresponding to situations representative of the rising limb time to peak and recession limb of hydrograph during the rising stage the water depths simulated by hr2d show are characterized by significant oscillations generating predictions quite far from the unical solution that instead is oscillation free fig 7a reducing progressively the grid size the simulation provided by hr2d approaches to the unical profile even though some oscillations are still evident some oscillations can be observed also in the simulated velocities fig 7b that led to a generalized overestimation of the predictions performed using the unical model as expected the reduction of the grid size improved the solutions given by hr2d that tend to be similar to the benchmark this discrepancy in respect to the unical model might be explained by the inaccuracy of the numerical solver used by hr2d in dealing with an initially dry bed condition in presence of very low water depths as those characterizing overland flow simulations during the peak stage fig 7c d the simulation provided by hr2d seems to be more similar to that given by the unical model especially in terms of velocity profiles for which the benefits induced by grid refining are quite limited however oscillations still occurred in both the profiles finally the analysis of the profiles during the recession stage fig 7e f highlighted further important numerical inaccuracy in the solution provided by hr2d that led to unphysical solutions especially for the coarsest grid shown in fig 7 only the use of a very fine grid provided simulations that tended to be similar to that predicted by the unical model which conversely highlighted a convincing hydrodynamic behaviour the poor prediction in the falling stage might be explained by the inability of the numerical solver implemented in hr2d in simulating correctly wet dry fronts especially in the presence of a steep slope therefore this evenience may represent the reason of the unphysical behaviour observed in the water depth hydrograph shown in fig 6 4 1 3 test 3 permeable plane three simulations were carried out for this test using the well known green ampt method for the computation of the infiltration losses in the first one based on the elm solver the average values for loam according to rawls et al 1983 and reported in the reference manual were used therefore no calibration of the parameters of the green ampt model was performed in the second simulation we used the measured and estimated values of saturated soil water content and the hydraulic conductivity after lima 1989 and the same calibrated values for the capillary suction head and manning coefficient as in tügel et al 2020 selecting the elm solver as in the previous case finally the last simulation is based on the same set of parameters as in the second simulation but using the em solver since the calibration process was not performed in hr2d but refers to the calibrated values by tügel et al 2020 using their 2d swe model the hr2d solution should be compared ideally to the simulations shown in that paper in fig 8 the comparisons between the experimental data and simulated specific discharge are shown in the first simulation see blue line in fig 8 the surface runoff simulated by hr2d is strongly overestimated confirming what was already observed by tügel et al 2020 using their 2d swe model on the contrary the second simulation see red line in fig 8 provided a fairly good prediction of the phenomenon since the shape of the simulated hydrograph is very close to the observed one some overestimation can be observed in the early stages of the rising limb of the hydrograph according to other simulations performed in the literature lima 1989 tügel et al 2020 the prediction of hr2d is in good agreement with the experimental data including the recession limb of the superficial runoff similar considerations can be made for the third simulation in which the em solver provided a very similar solution to the elm one except a slightly faster arrival time of the front wave no oscillations or physical anomalies can be observed in this test giving a preliminary indication about the suitability of hr2d as an integrated hydrologic hydraulic model for storm risk management 4 2 impervious planes using unsteady or non uniform rainfall for the first two ideal cases two benchmarks provided by the analytical solution and the simulations obtained using the unical model were considered again whereas for the experimental case both the observed data and the unical simulation were used 4 2 1 test 4 unsteady flow over a plane fig 9 shows the comparison between the simulations performed by hr2d elm and hr2d em and the benchmarks considering the same reference computational grid as for the tests 1 and 2 the two benchmarks provided a very similar evolution of the water depths with the unical prediction being practically superimposed on the analytical solution in this case the predictions performed by both the solvers implemented in hr2d still suffer from numerical errors specifically the shape of the simulated hydrographs is close to the benchmarks only for the instant of time around the peak values the errors in both the rising and falling limbs of the water depth hydrographs already discussed for the test 2 seem to be amplified by the non uniform rainfall leading to a unphysical solution this consideration holds regardless of the numerical scheme used to compute the solution in this regard the simulation obtained using hr2d em is even worse than the original one hr2d elm this is in contrast to what was reported in the user s manual in which the swe em scheme is presented to be as more reliable than swe elm in order to evaluate potential positive effects induced by grid refinement further simulations were performed halving progressively the side length of the mesh for the sake of clarity only the simulations performed with both the numerical solvers related to 0 25l0 are shown in fig 9b though an improvement of the solutions induced by the grid refinement can be observed in both the rising and falling limbs of the hydrographs the results are still heavily affected by numerical inaccuracy leading for example to the unphysical sudden decrease of the water depths just before 6000 s this anomaly is probably smoothed using the reference grid l0 the solutions obtained using the two numerical schemes tend to be closer to each other in respect to the simulations carried out using the reference grid l0 suggesting that the source of the errors is not so much in the algorithm in itself elm vs em probably it could be found in the numerical errors generated by an inaccurate treatment of dry wet fronts which could have minor impacts on hr2d elm in respect to hr2d em due to the greater diffusion that tends to smooth out unphysical oscillations 4 2 2 test 5 non uniform rainfall over a cascade of three planes in order to distribute the three different rainfall inputs on the three successive planes three separate grids were created and connected to each other the connection was made by a sa 2d area connection option selecting a broad crested weir geometry which has the same height of the dem elevation between the connected areas and the weir width setup as small as possible 0 1 mm the same spatial resolution was used for the unical model fig 10 shows the comparison between the discharge and water depth hydrographs computed by hr2d elm and hr2d em and the two benchmarks represented by the experimental data and the solution of the unical model all the numerical simulations refer to grids having approximately 0 06 m2 of spatial resolution since the element side assumed for hr2d computations was set equal to l0 0 25 m focusing the attention on the overall phenomena observed for both the rain durations reasonable predictions in terms of water depth and discharge hydrographs were provided by hr2d however significant discrepancies not only from the experimental data but also from the unical model can be detected in particular hr2d showed some difficulties in capturing the shock wave observed for rain duration d 10 s especially when using hr2d em leading to an overestimation of the simulated discharges in the rising limb of the hydrographs fig 10a b moreover the recessive part of the hydrograph seems to be more impulsive than the observed one so that the temporal evolution of the water depths is far from the experimental values fig 10b therefore some important discrepancies in terms of velocities simulated by hr2d are likely to occur the hr2d predictions seem to be closer to the observed hydrographs when a less impulsive phenomenon is simulated fig 10 c d even though some significant underestimations can be detected especially in the water depth hydrograph it is important to observe that the limitations observed in the hr2d predictions are not present in the unical simulations which are in close agreement with the observed data for both the rain durations this may induce us to argue that the numerical errors provided by the hr2d solver highlighted in previous sections played an important role also in this case in order to evaluate the potential benefit due to the grid refinement l0 2 another simulation was performed using hr2d elm but halving the computational element side so that the spatial resolution is 4 times greater than before some improvements in the solution can be observed especially for rain duration d 10 s in which the sudden rise of the hydrographs is better reproduced limiting the effects of the numerical diffusion fig 10a b the shape of the recession limb of the hydrograph seems to be better reproduced as well for rain duration d 30 s the benefits in the solutions are quite limited and in particular no improvements can be observed in terms of water depth peak value fig 10 d therefore despite the use of a refined grid the overall solutions provided by hr2d is still worse than the unical ones considering all the simulations shown up to now hr2d em seems not to provide benefits in respect to the hr2d elm this comment holds regardless of the values assumed for the courant number and all the parameters reported in section 2 2 1 specifically several simulations not shown here for the sake of brevity were carried out further reducing the courant number and providing variations in both the tolerance and theta values because changing in the solution are expected however only negligible differences in the solutions were observed therefore these results seem not to confirm what was reported in the reference manual about the accuracy of the numerical solvers a possible explanation for this apparent discrepancy may be found in the already recalled specific nature of rog simulations that makes them more challenging than the traditional simulation of flood propagation for the sake of brevity only the results obtained using hr2d elm will be shown in the next sections 4 2 3 test 6 non uniform rainfall over idealized basin in order to simulate the vertical walls delimitating the channel two areas were connected through the sa 2d area connection option selecting a broad crested weir geometry which has the same height of the dem elevation at the end of the planes which was connected directly to the channel bottom as regards unical computations a uniform spatial resolution was set everywhere about 50 m2 except for a very limited area at the turn of the banks of the channel where a grid refinement was provided resolution approximately equal to 5 m2 to avoid excessive smoothing of the existing steep topographic gradient a square grid was used for the simulations performed in hr2d having element side l0 equal to 5 m fig 11 shows the comparison between the hydrographs simulated by hr2d and the two benchmarks the shape of the hydrograph simulated by hr2d is in good agreement with the benchmarks which are very close to each other even though a slight delay can be observed in the front arrival times and time to peak probably due to some inaccuracy in dealing with initially dry bed conditions some discrepancies between unical and hr2d can be observed in the recession part of the hydrograph specifically a drastic change of the discharge hydrograph derivative occurred after 120 mins see black circle in fig 11a that has no motivation from a hydrodynamic point of view this unphysical behaviour could be explained by some numerical inaccuracy in the treatment of wet dry front during the transition from overland plus channel flow to channel flow only on the contrary the unical solution is convincing due to the quite smooth shape of the simulated wave in order to evaluate the effect of the grid size on this kind of situation other simulations were carried out reducing progressively the grid size 0 8l0 0 6l0 0 4l0 in the channel only as shown in fig 11 the numerical errors progressively vanish leading to a smooth solution like that simulated by the unical model 4 3 simulation related to runoff over idealized and real world urban areas 4 3 1 test 7 experimental test the results obtained using hr2d were compared against the experimental data collected by cea et al 2010 two kinds of simulation were carried out for the considered buildings arrangements y20 and a12 see fig 3b and 3c following the br and bb approaches described in section 2 1 in the first one hr2d br the manning coefficients of the computational elements covering the building footprints were increased by one order of magnitude in respect to the value suggested by cea et al 2010 as representative of the experimental test in the second one hr2d bb the heights corresponding to the roof tops were assigned to the vertices of the computational mesh that fall within the building footprints while vertices outside them had original terrain heights as in the hr2d br simulation both the approaches are significantly influenced by the modelling choices the roughness value n0 for br and the mesh side of the computational mesh l0 for bb in the basic scenario it was assumed n0 0 1 s m1 3 and l0 0 04 m for the br and bb respectively finally in order to check the influence of the modelling assumptions for both the approaches other simulations were carried out specifically the value of n0 was increased by factors of 1 5 and 2 0 15 and 0 2 s m 1 3 and l0 was reduced by factors 2 and 4 element side 0 01 and 0 02 m for hr2d br and hr2d bb simulations respectively the value of l0 was set to 0 02 m for all the br simulations but obviously the buildings are not reproduced in the mesh the hr2d predictions were clearly influenced by the modelling choices and they reflected differently in the results according to the arrangements of the buildings specifically as regards the hr2d bb the choice made for the basic scenario led to a reasonably good agreement between simulated and observed hydrographs for y20 configuration fig 12 a for which the peak value is underestimated about 10 the prediction for the a12 arrangement is worse fig 12 c and the underestimation of the peak value is greater than the previous case about 30 the grid refinement improved the solution for the a12 case fig 12c especially near the peak stage whereas limited benefits were observed for the y20 case fig 12a for both the configurations all the simulations predicted a faster initiation of outflow in respect to what was observed experimentally but then the rising stage of the hydrographs is well reproduced however some inaccuracy can be detected also during the falling limb of the hydrographs similar comments can be made on the hr2d br simulations the value assumed for the basic scenario led to both a good solution for the y20 case and a significant overestimation for the a12 case almost 20 in terms of peak value the influence of the manning coefficient assumed to take into account the buildings did not have a great influence for the y20 case while it was much more important for the a12 configuration fig 12d it can be observed that the use of the manning coefficient ranging from 0 15 to 0 2 may provide reasonably good results for both the building configurations also for this group of simulations a faster initiation of outflow was reproduced the assessment of best method to use in situations like these goes beyond the purpose of the work however both the approaches can be effectively used in hr2d once the calibration of model parameters is carried out 4 3 2 test 8 rainfall and point source surface flow in urban areas the spatial grid resolution used for both the numerical models was 4 m2 for the sake of brevity only the solutions related to the points 1 2 3 and 6 are shown here as reported in néelz and pender 2013 and cea et al 2020 in particular water surface elevations and velocities are discussed for points 2 and 6 while only the water surface elevations are shown for stations 1 and 3 see fig 13 to make the comparison to the other software packages easier all the panels in fig 13 have the same vertical scale used for the y axis as in néelz and pender 2013 the results obtained by hr2d are free of oscillations consistent with results produced by other software discussed in néelz and pender 2013 and generally close to the unical ones as for the water surface levels hr2d reproduced the double peak observed in all the other models caused by the intense rainfall and the inflow discharge moreover it provided practically the same results obtained by unical model at points 1 3 and 2 see fig 13a b c whereas some discrepancies can be observed at point 6 fig 13e due to the hypothetical nature of the event we have no elements to understand which models provided the most accurate results however both the models reproduced substantially the same behaviour simulated by almost all finite volume codes solving the full swes shown in néelz and pender 2013 considering the expected differences due to the methods used for solving the equations treatment of wet dry fronts different approaches to process topography etc as for the computed water velocities by hr2d the differences in respect to the unical results are higher than those observed for the water surface elevation as regards point 2 fig 12d the differences mainly occurred during the recession stage after the two peaks since the peak values are almost the same the comparison at point 6 fig 12f showed higher differences during the first peak and the recession limb after the second peak however both the models provided values that fall in the middle of the range described by the models discussed in néelz and pender 2013 the overall solution provided by hr2d can be considered satisfying for this test considering the close agreement with both other software packages and the unical model 4 4 runoff over actual catchments 4 4 1 test 9 prediction of the discharge hydrograph starting from a design net hyetograph due to very long computational times needed to carry out this simulation the computational grid used for hr2d simulation is composed of square elements having sides equal to 10 m in order to ensure similar conditions in the simulation the same resolution was used for the unical model attention will be firstly focused on both the simulated discharges hydrographs at the basin outlet and to the analysis of flooded areas fig 14 a shows a reasonably good agreement between the hydrographs simulated by hr2d and unical even though some differences can be observed hr2d predicted a slightly slower wave than the unical one with the front wave and peak arrival times a little bit delayed the difference in terms of peak value is very low less than 5 beside the discharge hydrograph at the outlet one of most important pieces of information for flood hazard assessment is the flooded areas delimitation for rainfall runoff simulations at the basin scale since the rainfall input is applied to each computational cell it is necessary to define a water depth threshold for the identification of the flooded cells fig 14b shows the comparison between the flooded area extent computed by the two models considering four values of water depth thresholds 5 10 15 20 cm used to identify wet cells the results obtained by the two models are generally in good agreement the hr2d slightly overpredicts the flooded areas simulated by unical with a maximum discrepancy of 15 except for the first selected threshold value 0 05 m in which the total wet area is underestimated about 20 this behaviour could be explained looking at the features of the river network and flow patterns simulated by the two models shown in fig 15 in particular a quite disconnected river network is generated by hr2d in which the smaller horton orders are fragmented and look like a cloud of small areas not connected to each other this observation can be somewhat related to what was already highlighted by shustikova et al 2019 in a traditional flood propagation study about a certain amount of flooded areas hydraulically disconnected from the main inundated areas a possible explanation for this might be represented by the approach implemented in hr2d for the distribution of the water within a computational cell based also on the volume elevation curve drawn for each cell face in pre processing stage however more detailed analyzes are required on the specific features of this property that cannot be found room for in this work finally it could be of interest to assess the overlapping of the wetted areas for specific water depths this can be done using several indexes sampson et al 2015 here we used the so called critical success index csi defined as in equation 3 3 c s i a x a r a x a r in which ax and ar are the wet areas simulated by hr2d and that associated to the reference model unical respectively csi 0 means no match between model and the benchmark csi 1 implies a perfect match the csi values are substantially equal to 0 75 for all the water thresholds falling in the range 0 5 m 2 5 m highlighting a reasonably good agreement between the two models for higher water depths however the csi value is extremely low 0 15 when the wetted cells are defined using a very shallow water depth threshold 0 05 m confirming what was previously observed 4 4 2 test 10 reconstruction of an observed event computing infiltration losses within the hydrodynamic model this test was the most challenging one due to the specific features considered intentionally when this event was selected specifically a very complex event characterized by several closely spaced peak values was selected followed by a period in which no rain input was registered moreover several sources of uncertainty exist in the set up of the modelling inputs due to a lack of information the spatial distribution of the rainfall was not performed therefore the rainfall data recorded at fitterizzi station see fig 4 was considered as uniformly distributed over the basin another important source of uncertainty is in the choice of the parameter values of both the green ampt model and manning coefficients no calibration was carried out intentionally because the purpose here is to use hr2d in a blind mode as a modeller is forced to do for an ungauged basin or in the absence of previous calibration considering the available information lithological and land use maps mean values of the parameters were selected according the technical indications reported also in the hec ras user s manual finally the total duration of the simulated event approximately two days avoided the choice of a fine computational grid in order to reduce the overall computational times so significant inaccuracy in the geometric description of the channels network and the overall morphometric features of the basin are likely to occur this choice is also motivated by the absence of any parallelization of the numerical codes implemented in hr2d so a square computational grid element side 10 m was considered for the computations the comparison between the observed and simulated discharges are shown in fig 16 from a hydrologic point of view the overall solutions provided by hr2d are fairly good in particular the simulated hydrologic responses to the rainfall inputs b c and d highlighted in the green circles in fig 16 are very close to the observed ones even though some important discrepancies can be observed specifically looking at the catchment response to the rain input b the first peak is overestimated see number 1 in fig 16 whereas the second and third peaks might be considered comparable since only slight underestimations can be observed see numbers 2 and 3 in fig 16 the response to this part of the event is more impulsive than the observed one and for this reason all the simulated times to peak are lower especially in the case of the first peak a good agreement can be noted as well also after the rain input c see fig 16 for which the shape of the discharge hydrograph is very close to the observed one providing a slight overestimation of the peak and a comparable time to peak a little bit worse are the results obtained after the rain input d since the peak value is underestimated and the shape of the recession limb seems to be not reproduced particularly well finally some significant difference can be observed in the early stage of the simulation after the rain input a for which hr2d response is significant delayed therefore the differences between observed and simulated discharges were expected due to the lack of a model calibration procedure despite that the overall results can be considered encouraging and in reasonably good agreement with the observations 5 discussion this paper fits into the context of the research field related to the benchmarking of the software packages that in the last two decades have drawn significant attention within the fluvial flooding modelling however nothing has been done for non fluvial flood modelling in which the focus is not on the flood propagation starting from an upstream boundary condition discharge hydrograph but on the use of 2d hydrodynamic model as an integrated hydrologic hydrodynamic approach able to be initialized directly from a rain input as usually done in rog simulations these simulations are very challenging from a numerical point of view because the numerical schemes used for traditional flood propagation need specific treatment not only for appropriate discretization of the topography but also to deal with wet dry fronts and bed friction in order to avoid instabilities in the solution and unphysical results cea and bladé 2015 therefore the scheme must be accurate and robust to avoid instabilities in the solution due to the presence of highly unsteady wet dry fronts with water depths of a few millimetres over very rough complex and steep terrains at the same time the numerical discretization must ensure the conservation of water mass in order to compute properly the shape of the outlet hydrograph cea and bladé 2015 in this framework this paper represents one of the first studies related to the assessment of the accuracy of a software package for rog simulations with specific reference to the hr2d model due to its wide popularity even in the scientific community as far as the authors are aware this is the first time in which a systematic analysis of hr2d for rog simulation ranging from ideal tests to real event simulations has been presented in the literature but the need for research similar to this has already been recently underlined in the literature for example david and schmalz 2020 compared the performance of hr2d used as decoupled discharge hydrograph as boundary condition or integrated rog simulation model moreover zeiger and hubbart 2021 assessed the performance of hr2d for rog simulations in a mixed land use watershed using effective rainfall simulated by swat predictions those papers had different purposes from this study but are motivated by the need to understand the potential and limitations of this software package for these specific simulations the results of this study enrich and extend the analysis shown in the works cited above because we discuss the hr2d performances for rog simulation but from a different point of view explicitly focused on the evaluation of the accuracy of the numerical solvers in a wide range of challenging simulations finally for the first time in the literature hr2d was successfully used as an integrated hydrologic hydrodynamic software able to numerically reproduce an observed discharge hydrograph starting from the recorded rainfall and considering the infiltration losses within the same software package so this study is a strong indication about the fact that hr2d can be intended not only as a hydrodynamic model that needs to be coupled to hydrological models see among the most recent ones hankin et al 2019 ferguson and fenner 2020 but also as a stand alone approach able to simulate at least the basic hydrological process within a 2d hydrodynamic framework this is a key element for future research as observed by tamagnone et al 2020 according to whom the use of measured hyetographs or forecast in a hydraulic freeware and considering future upgrades in which further hydrological tools will be added open interesting opportunities for innovative hydrological hydraulic studies in this context this study might become a reference study and has the potential to pave the way for further analysis of the most widely used 2d hydrodynamic hydrologic models therefore the results of this work are expected to have several impacts in pluvial urban flood risk management schanze 2018 muthusamy et al 2019 in its broader sense however besides the accuracy features discussed in this work it should be underlined that a good hydraulic simulator cannot be fully evaluated without an extensive efficiency analysis as reported in the 2d modelling reference manual the hr2d computational module was developed from the ground up with parallel processing in mind the hec ras 2d computations will use as many cpu cores as there are available which is the default mode for running therefore an efficiency comparison with other numerical models for example running on gpu architecture may be performed but it is hard to show here because it requires a paper in itself representing a potential future development of this research 6 conclusions the rog approach is considered to be the most suitable numerical strategy for the implementation of an accurate storm risk management consequently several software packages and industrial codes are now available to perform studies like these therefore there is the need of benchmarking studies especially for the most popular software packages implementing this approach like hr2d the use of which has been rapidly increasing in the last few years motivated by these considerations this paper is one of the first researches specifically focused on the benchmarking of hr2d for rog simulations the experience gained in this benchmarking study can be summarized as reported below 1 the performance related to the runoff simulations over planar impervious surfaces using steady and uniform rainfall cannot be considered satisfying though the shape and peak value of the hydrographs are substantially reproduced unphysical results were observed in the solution due to some inaccuracy of the numerical schemes used to solve the governing equations specifically the most critical situation was detected in the simulation of the recession limb of the hydrograph in which important oscillations were observed probably induced by the inability of the numerical schemes to deal with wet dry fronts which in turn led to a meaningless solution from a hydraulic point of view this behaviour that seems to be much more important for higher slopes was not observed in the simulations performed using the unical model moreover it was highlighted that the hr2d solution approaches the unical solution only using computational cells of one order of magnitude as a further proof of the numerical inaccuracy in dealing with wet dry interfaces however these effects were not observed in the simulation related to the experimental permeable plane in which for the first time in the literature hr2d is used considering also the infiltration losses in particular the results are in good agreement with the experimental data when using calibrated parameters of the green ampt model according to what has been done in the literature 2 the use of unsteady rainfall over planar impervious surfaces exacerbated the numerical errors already discussed in the case of steady rainfall in this situation the refinement of the grid provided only limited improvements in the solution of the hr2d that showed important differences in respect to the analytical and numerical benchmarks 3 the simulations related to non uniform rainfall in the domain are challenging tests for hr2d for which no other works can be found in the literature the approach proposed here seems to provide encouraging results but further analyses are required in order to check the reliability of the solutions in the areas close to the discontinuity of the rainfall 4 contrarily to what was reported in the user s manual about the accuracy of the numerical solvers of the fully dynamic wave equations hr2d em does not provide benefits in respect to the hr2d elm at least for the rog simulations the reason for this apparent contradiction may be found in the specific nature of rog simulations that makes them more challenging than the traditional simulation of flood propagation 5 the simulations related to idealized and real world urbanized areas highlighted the good performances of hr2d specifically the two techniques used to take into account the effects of the buildings increase of roughness and topographical variation provided fairly good results even though the first approach is less influenced by the grid resolution contrarily to the second method moreover the real world test case allowed us to assess the reliability of hr2d even considering two contextual different sources of water 6 the simulations related to the runoff computation in actual basins starting from the net rainfall in order to avoid the computation of infiltration losses within hr2d highlighted a very good agreement with the predictions performed by the unical model in terms of discharge hydrograph at the outlet of the catchment no important discrepancies were observed in the water depth values throughout the basin except when considering very shallow water depths however hr2d confirmed the tendency to simulate a quite disconnected river network and inundation patterns as already observed in the literature 7 the simulation of a rainfall runoff event on the turbolo catchment carried out without any calibration of the parameters provided encouraging results since the observed discharge hydrographs are reproduced reasonably considering all the simplified assumptions and the several sources of uncertainty the analysis of this event is in itself a novelty in the literature because for the first time the performances of hr2d as an integrated hydrologic hydraulic model for discharge hydrograph computation and flood mapping are shown and discussed the generalization of the results presented in this work requires further analysis and applications however they may be useful to underline on one hand the need of further improvements in the numerical algorithms used probably in the treatment of the wet dry fronts and furthermore to consider the performances of hr2d as very promising for simulations of real events in which the rog approach is essential credit authorship contribution statement pierfranco costabile conceptualization methodology investigation writing original draft writing review editing formal analysis supervision carmelina costanzo methodology investigation software validation resources writing review editing domenico ferraro methodology investigation software validation formal analysis writing review editing pierfrancesco barca software validation formal analysis declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment the authors are grateful to dr daniel caviedes voullième for sharing data related to glasgow test case 
4040,rain on grid rog modelling is an increasingly popular approach within the storm risk management in which the hydrological and hydrodynamic flood processes are modelled entirely within the 2d hydrodynamic model contrarily to what was done in the context of flood propagation in rivers at the present time no systematic benchmarking study of the software packages implementing this approach is available in the literature the need of benchmarking studies related to the rog approach is becoming ever more important for hec ras 2d hr2d the use of which has been rapidly increasing in the last few years as further testified by very recent papers explicitly focussed on this research issue however there is still a lack of studies that clearly show the suitability of this software package as a reliable fully integrated hydrologic hydrodynamic model therefore the novelty introduced by this paper is the benchmarking of hr2d for rog simulations analysing several situations representing most of the applications related to storm event hazard assessment specifically after the analysis of ideal cases which gave the opportunity to carefully assess the accuracy of the numerical schemes for rog simulations practical applications were considered to face some challenging issues related to the analysis of rainfall runoff in urbanized areas and actual basins including the numerical treatment of buildings and the computation of infiltration losses within hydrodynamic computations the hr2d results were compared to analytical solutions when available experimental data and numerical solutions of a numerical code developed by the authors the results shown in the paper highlight the potential but also the limitations of this software package providing evidence to scientists and technicians about those situations for which reliable results are expected but also indications on specific aspects that need improvements so as to increase the model accuracy keywords hecras rain on grid storm hazard assessment model benchmarking shallow water modelling 1 introduction understanding the effects of flood inundation in terms of area depth velocity and time is a key element for efficient flood risk management therefore the use of suitable mathematical models for flood inundation mapping differentiated according to characteristics of the flood event is a major step for the implementation of any flood management strategy it is well known that floods can arise from a variety of causes but the most common type is the so called fluvial flooding that occurs when following intense rainfall and or melting snow water levels in rivers rise and the rivers overtop their banks the general approach for the generation of fluvial flood hazards maps along large rivers is quite consolidated and it is commonly organized into two main steps requiring the use of two separate models consecutively in the first one attention is mainly focused on the computation of a discharge hydrograph related to single runoff events using consolidated hydrological rainfall runoff models then the calculated hydrograph is used as the upstream boundary condition of a two dimensional 2d hydrodynamic model however there is a growing awareness of different types of non fluvial flood events that show apparent increasing frequency and due to climate change are predicted to increase further they originate from heavy rainfall storm event hazard have different characteristics than fluvial floods since they occur apart from large rivers and are often characterized as flash or pluvial floods yin et al 2016 schanze 2018 pluvial flooding can be broadly defined as flooding that results from rainfall generated overland flow and ponding before the runoff enters any watercourse drainage system or sewer or cannot enter it because the network is full to capacity falconer et al 2009 this term is sometimes distinguished from flash flooding which may also be associated with heavy rainfall but usually arises from a watercourse rainfall non fluvial floods are modelled following the approach known as direct rainfall modelling or rain on grid rog in which the hydrological and hydrodynamic flood processes are not modelled in two different model systems but entirely with the 2d hydrodynamic model this approach is increasingly used to determine the rainfall runoff processes of watersheds with different sizes see for example cea and bladé 2015 fernández pato and garcía navarro 2016 fernández pato et al 2016 bout and jetten 2018 costabile et al 2019 ferraro et al 2020 ming et al 2020 and also on an urban scale in which due to the high relevance of the sewer system the studies often focus on the concept of dual drainage chang et al 2015 leandro et al 2016 jang et al 2018 li et al 2020a the aforementioned studies testify the increasing interest for this kind of approach and in the future the number of works dealing with this topic are expected to have the same diffusion of those related to fluvial flooding in previous years in particular specific attention to the benchmarking of software packages implementing this approach is likely to occur going through the significant amount of research carried out for fluvial flooding models in this latter context this important research activity was motivated by the strong need to provide evidence about the reliable predictions of the flood packages and a data set against which such numerical codes can be evaluated and differentiated in terms of performance and predictive capability specifically 2d software packages may have different features in terms of 1 the physical processes simulated by the model s mathematical formulation 2 the approximate numerical method used to solve the mathematical formulation 3 the configuration of the numerical grid upon which the numerical method is applied the first rigorous comparison of 2d hydraulic models was carried out by hunter et al 2008 comparing six models representing a wide spectrum of fundamental equations and numerical schemes to simulate surface flooding of a small urban catchment then a great effort was made within the environment agency defra department for environment food rural affairs uk which faced this issue in several reports in particular in a well known report néelz and pender 2010 10 benchmark test cases were presented against which 14 2d flood inundation modelling packages were tested and compared this study was updated in 2013 néelz and pender 2013 taking into account the further development of the already used software packages and the new ones that had become available neal et al 2012 used some of these test cases to benchmark three 2d models that can be broadly defined as simulating diffusive inertial and shallow water waves in order to understand how much physical complexity a flood inundation model needs for a given problem the model benchmarking carried out by néelz and pender 2013 has been used several times in the literature to check the performance of new models for flood mapping see for example leandro et al 2014 guidolin et al 2016 ayog et al 2021 unlike the fluvial flooding models at the present time no systematic benchmarking study of the software packages implementing the rog approach is available in the literature identifying a clear gap in the literature it should be recalled that rog simulations have specific and different features to the traditional 2d fluvial flood computations due to the very low value of surface runoff that may amplify the common problems related to the management of wet dry fronts instabilities due to roughness computations and inaccuracy related to numerical treatment of highly irregular topography see for example costabile et al 2013 cea and bladé 2015 therefore in our view there is the need of benchmarking studies related to rog modelling that along the lines of the research carried out by néelz and pender 2010 néelz and pender 2013 can provide 1 evidence about the accuracy and reliable predictions of the industrial flood packages and 2 a data set against which such software can be evaluated and differentiated in terms of performance and predictive capability this research issue gains much more importance when referred to the most used hydrodynamics models from both the scientific and technical points of view in this context the software hec ras 2d hereafter hr2d plays a leading role a scopus search highlighted that the number of papers per year having hec ras in the article title abstract or keywords has more than doubled in the last five years resulting in more than 200 documents in 2020 this significant increase is probably due to the launch of the version 5 0 in 2016 in which several new tools were introduced such as the module for two dimensional computations specifically the analysis of the related literature highlighted that hr2d was extensively used in flood mapping for estimating 1 flood magnitude van der meulen et al 2021 urban flood hazard yalcin 2019 rangari et al 2021 also using probabilistic approaches bhola et al 2020 and analysing the effects of bridges trueheart et al 2020 2 the influence of the topographic data on flood extent farooq et al 2019 stoleriu et al 2020 li et al 2020b yalcin 2020 ongdas et al 2020 muthusamy et al 2021 3 the performances of commercial and research software liu et al 2019 pinos and timbe 2019 shustikova et al 2019 sridharan et al 2020 and benchmarking of simplified models jamali et al 2019 afshari et al 2018 4 compound flooding saleh et al 2017 gori et al 2020 khanam et al 2021 5 potential or historical flooding due to dam dyke breaching albu et al 2020 urzică et al 2021 feroz islam et al 2019 pilotti et al 2020 and glacial lake outburst kougkoulos et al 2018 majeed et al 2021 besides these more traditional issues it is worthwhile to mention the popularity gained by hr2d in emergent fields of research such as ecohydraulics adeva bustos et al 2019 juárez et al 2019 papaioannou et al 2020 and the natural flood management keys et al 2018 pal et al 2020 ferguson and fenner 2020 tamagnone et al 2020 the widespread use of hr2d within the scientific community is expected to further increase in the near future considering also the new tools available in the just released version 6 0 that allow scholars and technicians to perform more reliable rog simulations in particular this last version was enriched with some options to simulate non uniform spatial rainfall and to compute infiltration losses in a 2d cell this research aims at providing a contribution within the scientific framework described so far in particular the paper is motivated by two considerations the increasing attention devoted to the analysis of non fluvial risks for which the rog is the reference approach and the substantial lack of benchmarking studies of widely used software packages such as hr2d in situations like these on the other hand the need for this line of research has already been highlighted in the very recent literature david and schmalz 2020 zeiger and hubbart 2021 however though facing a similar general purpose this work differs from the above cited papers since it is oriented to assess the accuracy and reliability of hr2d as an integrated hydrodynamic hydrologic model supporting storm risk management that therefore represents the focus and the novelty of this research to face this challenging issue an extensive benchmarking is presented analysing situations representative of most of the applications related to storm event hazard assessment specifically the paper is organized considering phenomena of increasing levels of trouble ranging from ideal cases to practical applications comparing the hr2d results to analytical solutions experimental data and results obtained by a numerical model specifically developed by the authors for problems like these the paper is organized as follows attention is firstly dedicated to the conceptualization of the work and particularly to the rationale used for the identification of the case studies and the description of the numerical benchmark section 2 the list of the test cases is presented in section 3 while section 4 is devoted to the analysis of the results finally the discussion of the results in the light of recent literature is provided in section 5 followed by the conclusions 2 conceptualization and methodological issues the conceptualization of this research involves essentially three aspects the first one revolves around the criteria used for the selection of specific test cases able to stress the performances of the hr2d model in challenging situations from both purely numerical and practical points of view the second one is represented by the need of testing the accuracy and the stability of the two numerical schemes implemented in the last released version of hr2d for solving fully dynamic wave equations finally the third aspect relates to the use of a numerical model the results from which are used for comparative analysis 2 1 rationale used for the identification of the case studies in the style of the benchmarking studies of 2d fluvial flooding models fewtrell et al 2011 neal et al 2012 néelz and pender 2013 a series of ideal and real world test cases are selected basically several idealized tests to check the accuracy and stability of the numerical algorithms implemented in hr2d were simulated this is a crucial issue from the authors point of view since as is well known in the literature the presence of very shallow depths over complex topography and wet dry interfaces may lead to several numerical problems when using fully dynamic wave equations in overland flow simulations these problems clearly are emphasized by the presence of a great number of computational dry cells becoming wet due to the rainfall input and subsequently dry out because of high bed slope so errors and instabilities come from steep bed slopes because more water than that actually contained in the wet cell may be computed as flowing in the dry cell and as a consequence the negative water depth may induce numerical instability or violation of the mass conservation leading to a gain of mass therefore specific treatments should be implemented in order to manage these situations see for example brufau et al 2004 liang and borthwick 2009 costabile et al 2013 further singularities may arise because of the bed friction term when the water depth becomes very small something which often occurs in overland flow simulations in these situations the bed friction term may dominate other terms of the momentum equation since it is inversely proportional to the 4 3 power of the water depth to the author s knowledge no studies exist that show performances of hr2d in those specific situations and therefore a profound analysis of situations like these is essential in a benchmarking study so the use of ideal tests in highly controlled and simplified environments will help in understanding the inherent properties of the numerical methods implemented in hr2d subsequently attention is devoted to situations closer to reality in this context the runoff simulation in urban areas is a major issue that gains further importance in a climate change context kaspersen et al 2017 padulano et al 2021 two important aspects are discussed the first one is related to the modelling approaches able to take into account the effects of buildings on the surface runoff as is well known one of the most used approaches to that purpose is to consider them as holes in the computational grids imposing solid wall conditions on the boundaries to the authors knowledge this option cannot be used within hr2d therefore the interest here is to test the suitability of this software package in the application of two other modelling strategies in the first one known as buildings resistance br method a large resistance parameter value is arbitrary assigned to cells that fall within the buildings footprints in the second scenario known as the buildings block bb method spatially distributed ground elevation data are raised to the heights of rooftops so that buildings appear as blocks in the topographic model used for flow simulation the second situation related to inundations of urban areas analyzed here is represented by the suitability of hr2d to deal with flow originating from different sources for example a rainfall input applied to the model grid and a point source flow at relatively high resolution such a situation allowed us to assess the capabilities of the model to handle complex topography and the related complex flow structures due to both sources of flows finally this work is oriented at providing indications about hr2d performance in very challenging situations such as the rainfall runoff modelling in natural basins for which several efforts have been made in the literature to get stable and accurate results the aim of this part of the research is not only the evaluation of the performances of hr2d using the rog that in any case would be a novelty in itself due the lack of studies on this the works by david and schmalz 2020 costabile et al 2020a zeiger and hubbart 2021 are exceptions the further purpose is to explore the potential of hr2d as an integrated hydrologic hydrodynamic model in which even the infiltration losses recently added in version 6 0 are considered in just one modelling tool in this regard the applications shown here represent the most challenging ones for the use of hr2d therefore the analyzes performed here is grouped in four main relevant situations 1 tests over impervious permeable planes using steady and uniform rainfall 2 tests over planes using unsteady or non uniform in space rainfall 3 tests in idealized or real world urban areas 4 rainfall runoff simulations in actual catchments considering net rainfall and gross rainfall so as to consider the effect of the infiltration losses inside the hr2d ultimately the analyzed tests are devoted to covering most of the applications related to storm event hazard assessment except those situations strictly related to urban drainage modelling in which the description of the interaction with the sewer system makes the application in hr2d quite complex all the case studies are presented in section 3 2 2 numerical solvers implemented in hr2d the hr2d model allows the user the choice of three equation sets namely 2d diffusion wave equations not considered in this work shallow water equations swe elm with a eulerian lagrangian approach to solving for advection or a new shallow water equation solver swe em that uses a eulerian approach for advection the governing equations are not reported here for the sake of brevity and the reader can refer to the user s hydraulic reference manual version 6 0 as reported in that manual the original solver swe elm is claimed to be more than adequate for most problems requiring the full momentum equations the last option swe em added only in version 6 0 is claimed to be more momentum conservative but may require smaller time steps and produce longer run times and therefore it is suggested only when the user is interested in very localized phenomena changes in water surfaces and velocities at and around hydraulic structures piers abutments and tight contractions and expansions the swe em uses an explicit solution scheme based on a strictly conservative form of the momentum equation according to the reference manual swe em solver produces less numerical diffusion than the original swe elm solver if a time step controlled by the courant number 1 0 is setup otherwise instabilities are expected to occur due to the explicit nature of the scheme both the numerical schemes will be used here in order to provide evidence about their accuracy and reliability 2 2 1 computational options and tolerance hr2d model allows the user to set the tolerance on both the 2d water surface elevations and the volume basically if the maximum error is greater than the set tolerance then the program will iterate to get a better answer the program will only iterate up to the maximum number of iterations set by the user therefore the maximum iteration allows the scheme to solve the equations with the minimum numerical error which has to be contained in the tolerance value for further details one may refer to the 2d modeling user s manual as for the simulations shown here in particular the tolerances thresholds were setup as small as possible 10 9 since the high degree of accuracy required in the tests case since a small tolerance was imposed the maximum number of iterations settable 40 was set according to the user s manual all the tests were run with a pure swe model no turbulent model was setup moreover the values of theta theta warmup were analyzed according to the 2d modeling user s manual this is the implicit weighting factor that is used to weight spatial derivatives between the current solution time line and the previously computed time line theta of 1 0 default uses only the currently solved time line for the spatial derivatives this provides for the most stable solution but possibly at the loss of some accuracy theta of 0 6 provides for the most accurate solution of the equations but tends to be less stable theta warmup is used during the model warmup and ramp up periods finally all the tests were performed using the adjust time step based on courant although the swe elm model can run with a courant number higher than 1 all the tests were run with a maximum value always less than the unity in order to correctly compare swe elm and swe em furthermore minimum courant number was set 1 100 of the maximum courant number the influence of all these parameters was checked in all the numerical tests highlighting negligible variations 2 3 unical benchmark model governing equations and numerical schemes different benchmarks for hr2d solutions were considered depending on features of the specific case study we used theoretical solutions related to the kinematic wave theory observed data and numerical solutions obtained from a code developed by the authors at the university of calabria italy hereafter unical that proved to be very reliable for simulations like these the rationale behind this choice is to provide evidence about the accuracy of hr2d in relation to a numerical model first order accurate in time and space developed for research purposes in other words the unical model is not used here to understand which model performs better but to have a reference numerical solution representative to what a reliable swe numerical model first order accurate in time and space can provide in terms of numerical simulations it should be observed that the reason of important discrepancies between model simulations and observed theoretical reference solutions can be found in the physics of the governing equations or in some numerical inaccuracy of the solvers in case of inaccurate solutions generated by hr2d and reliable simulations provided by the unical model the reason cannot be found in the physics of the governing equations but in some deficiencies of the numerical solvers therefore the use of unical model aims at certifying the presence of numerical errors in the solution of the numerical solvers implemented in hr2d and its solutions will be shown in particular in those cases for which hr2d predictions highlight important discrepancies in respect to the theoretical or experimental solutions the unical model is based on the 2 d swe that can be expressed in the following form 1 u t f x g y s where 2 u h h u h v f hu h u 2 g h 2 2 h u v g hv h u v h v 2 g h 2 2 s r f g h s 0 x s fx g h s 0 y s fy in which t s is time x m y m are the horizontal coordinates h m is the water depth u m s v m s are the depth averaged flow velocities in x and y directions g m s2 is the gravitational acceleration r m s is the rain intensity and f m s are the infiltration losses s0x m m s0y m m are the bed slopes in x and y directions sfx m m sfy m m are the friction slopes in x and y directions in equation 2 the source term s in the mass continuity equation is not zero both the rainfall and the infiltration losses are included therefore acting on the source term the swes have the ability to apply rain directly to a two dimensional grid implementing the rog approach the model is developed for unstructured grids based on irregular triangular elements to obtain the computational domain for the numerical integration of system 1 the model is based on finite volume methodology in particular the roe scheme 1981 first order accurate in time and space is used for the computation of the numerical fluxes the numerical integration of the shallow water equations in complex topographies requires further specific algorithms to the numerical treatment of the bottom slope of the friction slope and of the wet dry fronts for the sake of brevity only some key aspects of the model are recalled here a in order to ensure the stability of the model the time steps have been estimated according to the well known cfl condition b an upwind approach inspired by brufau et al 2004 is used to discretize the bottom variations c a semi implicit treatment of the friction source term is implemented costabile et al 2013 cea and bladé 2015 d a robust wet dry procedure is considered costabile et al 2013 this model was used for several different applications ranging from flood mapping in urban environments macchione et al 2019 costabile et al 2020b costabile et al 2021 to runoff simulations at basin scale costabile et al 2020a costabile and costanzo 2021 3 description of the numerical tests and available data 3 1 runoff over impervious or permeable planes using steady uniform rainfall three different tests characterized by geometries from low to high slopes and different values of rainfall input are performed in fig 1 an overall quick view of these tests is given the first one test 1 hereafter was proposed by gottardi and venutelli 1993 and then considered in other works see for example jaber and mothar 2003 for which the kinematic analytical solution given by stephenson and meadows 1986 can be used the watershed is represented by a plane having these characteristics low slope plane sl 0 0005 st 0 500 m long manning roughness coefficients nx ny 0 02 sm 1 3 a steady uniform rainfall rate r equal to 0 33 mm min was set for a duration d equal to 200 mins the second test test 2 hereafter was first introduced by singh 1996 and further used in several papers in the literature see for example tsai and yang 2005 singh et al 2015 in this case a steady and uniform rainfall intensity r equal to 300 mm h and duration d of 1600 s was set to simulate the overland flow over a plane with a length l 500 m and slopes sl 0 01 and st 0 the manning roughness coefficient was considered equal to 0 02 sm 1 3 also in this case the kinematic analytical solution can be computed the third test test 3 hereafter see fig 1 right panel is an experimental test carried out by lima 1982 who used a laboratory soil flume 1 m long 0 5 m wide having a slope equal to sl 0 01 st 0 the soil was a loam the bottom of the flume consisted of a metallic perforated plate to collect percolation water the rainfall simulator is able to generate a uniformly distributed rainfall pattern equal to r0 135 mm h for a duration of d 15 mins 3 2 runoff over impervious planes using unsteady or non uniform rainfall in this group of tests three differentiated situations were considered one of which is related to an unsteady rainfall and the remaining two are referred to non uniform rainfalls see fig 2 the first test of this category test 4 hereafter was proposed by tsai and yang 2005 the plane has the following characteristics length l 1000 m longitudinal slope sl 0 01 st 0 manning s coefficient equal to nx ny 0 02 sm 1 3 the unsteady rainfall duration is d 3 4500 s see fig 2a from d 1 1500 s to d 2 3000 s the rainfall rate is equal to r 2 300 mm h whereas it is equal to r 1 100 mm h outside this interval the last two tests considered here refer to steady and non uniform rainfalls in this context attention is firstly focused on the experimental tests carried out by iwagaki 1955 this test test 5 hereafter was used for validation purposes in several papers zhang and cundy 1989 feng and molz 1997 fiedler and ramirez 2000 west et al 2017 ding et al 2018 hu and song 2018 aureli et al 2020 the experiments consist in a rainfall runoff situation over a cascade of three planes fig 2b each plane section was 8 m long the slopes of which were equal to 0 02 0 015 and 0 01 in the downstream directions each section received a constant rainfall input of 389 230 and 288 cm h respectively three rainfall durations were considered in the experiments for which discharge and water depth hydrographs are available for the sake of brevity we considered only the durations d 10 s and d 30 s finally the last application test 6 hereafter considered for this category refers to a well known test in the literature see for example di giammarco et al 1996 kim et al 2012 xia et al 2017 hou et al 2018 shu et al 2020 and for which an analytical solution is available stephenson and meadows 1986 it is a v shaped catchment see fig 3 c having a single slope on both the plane sp 0 05 and the channel sc 0 02 the depth of the channel varies from 1 m at the upstream end to 20 m at the downstream end the intensity of the rainfall input r 0 is 10 8 mm h and duration d of 1 5 h the precipitation does not affect the channel interesting only the valley side the assigned values of the manning s coefficients are 0 05 s m 1 3 for the valley side and 0 15 s m1 3 for the channel 3 3 runoff over idealized and real world urban areas two tests were considered in this group one of which is represented by an idealized urban area whereas the other one is a real world situation specifically the first test hereafter identified as test 7 refers to the experiments performed by cea et al 2010 and considered for validation purposes by several authors in the literature see for example fernandez pato and garcia navarro 2016 xia et al 2017 su et al 2019 caviedes voullième et al 2020 the designed experimental urban catchments were made of three planes each of them with an approximate slope of 0 05 but once the experiment was set up the real topography was similar to what is shown in fig 3a eight different urban configurations were built in the laboratory the configurations considered in this paper are shown in fig 3b and 3c the horizontal dimensions of the building are 20 cm 30 cm and the vertical outer walls are 20 cm in height a steady and uniform rainfall equal to 300 mm h was set and three different durations 20 40 and 60 s were considered in the experiments even though only the shorter one is considered here following cea et al 2010 the manning coefficient can be assumed equal to 0 016 s m 1 3 the only variable measured was the discharge hydrograph generated at the outlet of the basin located in the valley in the middle of the domain fig 3a which was used to validate the numerical results the second test used for this category hereafter identified as test 8 belongs to case studies used in the benchmarking analysis carried out by néelz and pender 2013 it is used for assessing the latest generation of 2 d hydraulic modelling tools and widely used in the literature for benchmarking purposes for the most recent ones see for example courty et al 2017 hu et al 2018 savant et al 2019 caviedes voullième et al 2020 it corresponds to a synthetic event on a real topography located in the urban area of glasgow scotland uk the modelled area is approximately 400 960 m and a digital elevation model having a spatial resolution of 2 m is available see fig 3d the event was designed to determine the models capability to correctly simulate flooding due to two different sources of water since the test attempts to mimic a common urban flooding scenario where a rainfall event overwhelms the drainage systemsand consequently causes flooding due to a surcharging pipe orstormwaterdrain thus the flood is assumed to arise from a point time dependent inflow representing a sewer outflow fig 3e and a uniformly distributed rainfall fig 3f applied to the modelled area the source point location is shown in fig 3d together with the 9 observation locations considered for results comparisons roughness values were assumed to be variable throughout the domain since roads and pavements have the manning s coefficient equal to 0 02 s m 1 3 whereas it was assumed 0 05 s m 1 3 elsewhere all domain boundaries are closed and therefore no outflow hydrographs are available contrarily to the previous cases for which hr2d was used for the first time in the literature in this work this test had already been simulated by brunner 2018 despite that in the author s opinion it is important to discuss it again in the light of the purposes of this paper especially in relation to the results obtained by the first order accurate in time and space model user here unical 3 4 runoff over actual catchments in this group two possible situations of interest in the rainfall runoff simulations over actual catchments see fig 4 were considered the first one is oriented at using hr2d for predictive purposes in cases for which no observed data related to rainfall flooded areas and discharge are available this is a common situation that characterizes small basins that very often are ungauged catchments for which it is not possible to have data for model calibration and validation as a consequence blind simulations should be performed for instance using a design net hyetograph as input the authors feel that in situations like these it is important to assess the performance of a commercial software using a state of the art model developed for research purposes as the benchmark solution therefore the benchmark for this test will be thus represented by the solution provided by the unical model the selected basin namely ar shown in fig 4a is a part of the ardivestra catchment located in the lombardia region northern italy having an extent approximately equal to 43 km2 a mean altitude of 423 m above sea level a s l and length of the main river equal to 22 4 km a lidar bare ground data was available from which 1 m dem was extracted following a common approach for technical studies a chicago hyetograph was obtained by the available rainfall duration curve corresponding to a return period of 200 years in which the net rainfall was computed through the scn cn method the roughness coefficient is considered variable throughout the domain according to the available map of soil use the second test is focused on the reconstruction of an observed event on a small basin in this case hr2d will be used for the first time in the literature as an integrated hydrologic hydrodynamic model at the basin scale able to be initialized by gross rainfall and in which the computation of the infiltration losses is computed within the model itself specifically we considered the turbolo catchment located in the calabria region southern italy the area of the basin is equal to 29 1 km2 agricultural and wooded areas represent the dominant land use while urbanization is less than 2 of the total catchment area a variable roughness was assumed based on the information related to the map of the soil use furthermore a lithologic map is available for this basin buttafuoco et al 2012 according to which the parameters of the green ampt model were roughly estimated using the value proposed in rawls et al 1983 the observed event selected for evaluating the performance of hr2d occurred between the 27th and 28th january 2004 the rainfall data used here was recorded by the rain gauge of the fitterizzi station located at 185 m above the sea level whereas the observed discharge refers to a section located downstream at 75 m a s l fig 4b 4 results 4 1 impervious or permeable planes using steady uniform rainfall two benchmarks were used for these tests the first one is related to the analytical solution of the kinematic wave modelling useful to check the overall behaviour of the simulated discharges since attention here is focused on the full momentum solution provided by hr2d a second benchmark was also considered which refers to the simulation obtained by the unical model applied to an unstructured triangular grid having almost uniform resolution equal to 25 m2 the same resolution was used for hr2d for which the reference grid is made of square elements having sides equal to l0 5 m the minimum and maximum courant number for hr2d was set equal to 0 01 and 0 3 respectively these values are significantly lower than those recommended in the user s manual preliminary tests not shown here for the sake of brevity highlighted that the model did not crash using recommended values for example 1 2 for swe elm option however unphysical results and oscillations in the hydrodynamic variables may be generated confirming that hydrodynamic features of overland flow simulations that are more critical than the traditional flood propagation study 4 1 1 test 1 impervious plane very low slope fig 5 a shows the comparison between the simulated discharges obtained by the hr2d model using both the swe em and swe elm numerical resolution algorithms on the reference grid and the solutions provided by the two benchmarks the hr2d solutions are in a good agreement with the analytical one reproducing the expected shape of the wave the differences near the peak value can be explained easily considering the fully dynamic version of the momentum equation implemented in hr2d as a proof of this the simulated hydrograph is very similar to the unical solution in this part of the graph even though the peak value is not exactly the same of that simulated by the two benchmarks though the shape of the rising limb of the hydrograph is fairly well reproduced by hr2d it can be observed that they are slightly shifted on the left in respect to those obtained by the two benchmarks see the magenta box in fig 5a finally it is interesting to observe the solutions obtained by hr2d in the falling limb of the hydrograph the simulations are in good agreement with the two benchmarks but a strange behaviour is reproduced approximately around t 300 min giving an unrealistic shape of the wave not simulated by the benchmarks that are very close together see red box in fig 5a therefore it is likely that a numerical error occurred probably due to some difficulties in the treatment of drying fronts in order to check the effect of this inaccuracy as a function of the grid size three further simulations were performed halving progressively the side length of the mesh 0 5 l0 0 25 l0 0 125 l0 respectively the results obtained by the two solvers are very similar so only the simulations obtained using the swe elm numerical solver are shown see fig 5b as highlighted in the purple box of fig 5b see also the black arrows the artificial step like behaviour simulated by hr2d em progressively vanishes reducing its value and appearing later on the simulation only when using a very fine grid 0 125l0 the solution provided by hr2d seems to be not affected by numerical errors and very close to the solution given by the unical models shown in fig 5b 4 1 2 test 2 impervious plane steep slope fig 6 shows the comparison between the water depth hydrographs simulated by hr2d and the two benchmarks using the reference grid side length l0 5 m the two numerical solvers implemented in hr2d are not in agreement with each other and gave quite different results from the numerical and analytical benchmarks that in turn are practically superimposed fig 6a the unphysical behaviour observed in the previous test seems to be much more important than what was observed in test 1 providing a quite poor prediction of the recession limb of the hydrograph fig 6a in particular the sudden decrease of the water depth is a clear indication of the presence of numerical inaccuracies that generated poor predictions after the end of the rainfall input it is not very simple to detect which numerical scheme implemented in hr2d performs better the new numerical solver swe em seems to perform a little bit worse swe elm than the traditional scheme since some significant discrepancy from the benchmark solutions can be observed also during the rising stage of the hydrograph also in this case we analyzed the role played by the grid size on the generation of these numerical inaccuracies as expected the use of finer grids led to an improvement of the solution in particular the sudden decrease of the water levels is reduced and temporally shifted meaning that the generation of the errors happens later on in the simulation in respect to the reference grid fig 6b the two numerical schemes converged to the same solution as the grid size decreases providing a solution closer to those predicted by the benchmark fig 6b however despite the use of a finer grid hr2d performed worse than the unical model in order to better understand the reasons behind the unphysical solutions given by the numerical solvers implemented in hr2d in fig 7 the comparison between the water depth and velocity profiles simulated by unical model and hr2d using the original solver swe elm is shown the grid resolutions used to that purpose were finer than that used for the unical model corresponding to the mesh side equal to l0 2 l0 4 and l0 8 moreover three instants of times were considered t 5 min 25 min and 35 min corresponding to situations representative of the rising limb time to peak and recession limb of hydrograph during the rising stage the water depths simulated by hr2d show are characterized by significant oscillations generating predictions quite far from the unical solution that instead is oscillation free fig 7a reducing progressively the grid size the simulation provided by hr2d approaches to the unical profile even though some oscillations are still evident some oscillations can be observed also in the simulated velocities fig 7b that led to a generalized overestimation of the predictions performed using the unical model as expected the reduction of the grid size improved the solutions given by hr2d that tend to be similar to the benchmark this discrepancy in respect to the unical model might be explained by the inaccuracy of the numerical solver used by hr2d in dealing with an initially dry bed condition in presence of very low water depths as those characterizing overland flow simulations during the peak stage fig 7c d the simulation provided by hr2d seems to be more similar to that given by the unical model especially in terms of velocity profiles for which the benefits induced by grid refining are quite limited however oscillations still occurred in both the profiles finally the analysis of the profiles during the recession stage fig 7e f highlighted further important numerical inaccuracy in the solution provided by hr2d that led to unphysical solutions especially for the coarsest grid shown in fig 7 only the use of a very fine grid provided simulations that tended to be similar to that predicted by the unical model which conversely highlighted a convincing hydrodynamic behaviour the poor prediction in the falling stage might be explained by the inability of the numerical solver implemented in hr2d in simulating correctly wet dry fronts especially in the presence of a steep slope therefore this evenience may represent the reason of the unphysical behaviour observed in the water depth hydrograph shown in fig 6 4 1 3 test 3 permeable plane three simulations were carried out for this test using the well known green ampt method for the computation of the infiltration losses in the first one based on the elm solver the average values for loam according to rawls et al 1983 and reported in the reference manual were used therefore no calibration of the parameters of the green ampt model was performed in the second simulation we used the measured and estimated values of saturated soil water content and the hydraulic conductivity after lima 1989 and the same calibrated values for the capillary suction head and manning coefficient as in tügel et al 2020 selecting the elm solver as in the previous case finally the last simulation is based on the same set of parameters as in the second simulation but using the em solver since the calibration process was not performed in hr2d but refers to the calibrated values by tügel et al 2020 using their 2d swe model the hr2d solution should be compared ideally to the simulations shown in that paper in fig 8 the comparisons between the experimental data and simulated specific discharge are shown in the first simulation see blue line in fig 8 the surface runoff simulated by hr2d is strongly overestimated confirming what was already observed by tügel et al 2020 using their 2d swe model on the contrary the second simulation see red line in fig 8 provided a fairly good prediction of the phenomenon since the shape of the simulated hydrograph is very close to the observed one some overestimation can be observed in the early stages of the rising limb of the hydrograph according to other simulations performed in the literature lima 1989 tügel et al 2020 the prediction of hr2d is in good agreement with the experimental data including the recession limb of the superficial runoff similar considerations can be made for the third simulation in which the em solver provided a very similar solution to the elm one except a slightly faster arrival time of the front wave no oscillations or physical anomalies can be observed in this test giving a preliminary indication about the suitability of hr2d as an integrated hydrologic hydraulic model for storm risk management 4 2 impervious planes using unsteady or non uniform rainfall for the first two ideal cases two benchmarks provided by the analytical solution and the simulations obtained using the unical model were considered again whereas for the experimental case both the observed data and the unical simulation were used 4 2 1 test 4 unsteady flow over a plane fig 9 shows the comparison between the simulations performed by hr2d elm and hr2d em and the benchmarks considering the same reference computational grid as for the tests 1 and 2 the two benchmarks provided a very similar evolution of the water depths with the unical prediction being practically superimposed on the analytical solution in this case the predictions performed by both the solvers implemented in hr2d still suffer from numerical errors specifically the shape of the simulated hydrographs is close to the benchmarks only for the instant of time around the peak values the errors in both the rising and falling limbs of the water depth hydrographs already discussed for the test 2 seem to be amplified by the non uniform rainfall leading to a unphysical solution this consideration holds regardless of the numerical scheme used to compute the solution in this regard the simulation obtained using hr2d em is even worse than the original one hr2d elm this is in contrast to what was reported in the user s manual in which the swe em scheme is presented to be as more reliable than swe elm in order to evaluate potential positive effects induced by grid refinement further simulations were performed halving progressively the side length of the mesh for the sake of clarity only the simulations performed with both the numerical solvers related to 0 25l0 are shown in fig 9b though an improvement of the solutions induced by the grid refinement can be observed in both the rising and falling limbs of the hydrographs the results are still heavily affected by numerical inaccuracy leading for example to the unphysical sudden decrease of the water depths just before 6000 s this anomaly is probably smoothed using the reference grid l0 the solutions obtained using the two numerical schemes tend to be closer to each other in respect to the simulations carried out using the reference grid l0 suggesting that the source of the errors is not so much in the algorithm in itself elm vs em probably it could be found in the numerical errors generated by an inaccurate treatment of dry wet fronts which could have minor impacts on hr2d elm in respect to hr2d em due to the greater diffusion that tends to smooth out unphysical oscillations 4 2 2 test 5 non uniform rainfall over a cascade of three planes in order to distribute the three different rainfall inputs on the three successive planes three separate grids were created and connected to each other the connection was made by a sa 2d area connection option selecting a broad crested weir geometry which has the same height of the dem elevation between the connected areas and the weir width setup as small as possible 0 1 mm the same spatial resolution was used for the unical model fig 10 shows the comparison between the discharge and water depth hydrographs computed by hr2d elm and hr2d em and the two benchmarks represented by the experimental data and the solution of the unical model all the numerical simulations refer to grids having approximately 0 06 m2 of spatial resolution since the element side assumed for hr2d computations was set equal to l0 0 25 m focusing the attention on the overall phenomena observed for both the rain durations reasonable predictions in terms of water depth and discharge hydrographs were provided by hr2d however significant discrepancies not only from the experimental data but also from the unical model can be detected in particular hr2d showed some difficulties in capturing the shock wave observed for rain duration d 10 s especially when using hr2d em leading to an overestimation of the simulated discharges in the rising limb of the hydrographs fig 10a b moreover the recessive part of the hydrograph seems to be more impulsive than the observed one so that the temporal evolution of the water depths is far from the experimental values fig 10b therefore some important discrepancies in terms of velocities simulated by hr2d are likely to occur the hr2d predictions seem to be closer to the observed hydrographs when a less impulsive phenomenon is simulated fig 10 c d even though some significant underestimations can be detected especially in the water depth hydrograph it is important to observe that the limitations observed in the hr2d predictions are not present in the unical simulations which are in close agreement with the observed data for both the rain durations this may induce us to argue that the numerical errors provided by the hr2d solver highlighted in previous sections played an important role also in this case in order to evaluate the potential benefit due to the grid refinement l0 2 another simulation was performed using hr2d elm but halving the computational element side so that the spatial resolution is 4 times greater than before some improvements in the solution can be observed especially for rain duration d 10 s in which the sudden rise of the hydrographs is better reproduced limiting the effects of the numerical diffusion fig 10a b the shape of the recession limb of the hydrograph seems to be better reproduced as well for rain duration d 30 s the benefits in the solutions are quite limited and in particular no improvements can be observed in terms of water depth peak value fig 10 d therefore despite the use of a refined grid the overall solutions provided by hr2d is still worse than the unical ones considering all the simulations shown up to now hr2d em seems not to provide benefits in respect to the hr2d elm this comment holds regardless of the values assumed for the courant number and all the parameters reported in section 2 2 1 specifically several simulations not shown here for the sake of brevity were carried out further reducing the courant number and providing variations in both the tolerance and theta values because changing in the solution are expected however only negligible differences in the solutions were observed therefore these results seem not to confirm what was reported in the reference manual about the accuracy of the numerical solvers a possible explanation for this apparent discrepancy may be found in the already recalled specific nature of rog simulations that makes them more challenging than the traditional simulation of flood propagation for the sake of brevity only the results obtained using hr2d elm will be shown in the next sections 4 2 3 test 6 non uniform rainfall over idealized basin in order to simulate the vertical walls delimitating the channel two areas were connected through the sa 2d area connection option selecting a broad crested weir geometry which has the same height of the dem elevation at the end of the planes which was connected directly to the channel bottom as regards unical computations a uniform spatial resolution was set everywhere about 50 m2 except for a very limited area at the turn of the banks of the channel where a grid refinement was provided resolution approximately equal to 5 m2 to avoid excessive smoothing of the existing steep topographic gradient a square grid was used for the simulations performed in hr2d having element side l0 equal to 5 m fig 11 shows the comparison between the hydrographs simulated by hr2d and the two benchmarks the shape of the hydrograph simulated by hr2d is in good agreement with the benchmarks which are very close to each other even though a slight delay can be observed in the front arrival times and time to peak probably due to some inaccuracy in dealing with initially dry bed conditions some discrepancies between unical and hr2d can be observed in the recession part of the hydrograph specifically a drastic change of the discharge hydrograph derivative occurred after 120 mins see black circle in fig 11a that has no motivation from a hydrodynamic point of view this unphysical behaviour could be explained by some numerical inaccuracy in the treatment of wet dry front during the transition from overland plus channel flow to channel flow only on the contrary the unical solution is convincing due to the quite smooth shape of the simulated wave in order to evaluate the effect of the grid size on this kind of situation other simulations were carried out reducing progressively the grid size 0 8l0 0 6l0 0 4l0 in the channel only as shown in fig 11 the numerical errors progressively vanish leading to a smooth solution like that simulated by the unical model 4 3 simulation related to runoff over idealized and real world urban areas 4 3 1 test 7 experimental test the results obtained using hr2d were compared against the experimental data collected by cea et al 2010 two kinds of simulation were carried out for the considered buildings arrangements y20 and a12 see fig 3b and 3c following the br and bb approaches described in section 2 1 in the first one hr2d br the manning coefficients of the computational elements covering the building footprints were increased by one order of magnitude in respect to the value suggested by cea et al 2010 as representative of the experimental test in the second one hr2d bb the heights corresponding to the roof tops were assigned to the vertices of the computational mesh that fall within the building footprints while vertices outside them had original terrain heights as in the hr2d br simulation both the approaches are significantly influenced by the modelling choices the roughness value n0 for br and the mesh side of the computational mesh l0 for bb in the basic scenario it was assumed n0 0 1 s m1 3 and l0 0 04 m for the br and bb respectively finally in order to check the influence of the modelling assumptions for both the approaches other simulations were carried out specifically the value of n0 was increased by factors of 1 5 and 2 0 15 and 0 2 s m 1 3 and l0 was reduced by factors 2 and 4 element side 0 01 and 0 02 m for hr2d br and hr2d bb simulations respectively the value of l0 was set to 0 02 m for all the br simulations but obviously the buildings are not reproduced in the mesh the hr2d predictions were clearly influenced by the modelling choices and they reflected differently in the results according to the arrangements of the buildings specifically as regards the hr2d bb the choice made for the basic scenario led to a reasonably good agreement between simulated and observed hydrographs for y20 configuration fig 12 a for which the peak value is underestimated about 10 the prediction for the a12 arrangement is worse fig 12 c and the underestimation of the peak value is greater than the previous case about 30 the grid refinement improved the solution for the a12 case fig 12c especially near the peak stage whereas limited benefits were observed for the y20 case fig 12a for both the configurations all the simulations predicted a faster initiation of outflow in respect to what was observed experimentally but then the rising stage of the hydrographs is well reproduced however some inaccuracy can be detected also during the falling limb of the hydrographs similar comments can be made on the hr2d br simulations the value assumed for the basic scenario led to both a good solution for the y20 case and a significant overestimation for the a12 case almost 20 in terms of peak value the influence of the manning coefficient assumed to take into account the buildings did not have a great influence for the y20 case while it was much more important for the a12 configuration fig 12d it can be observed that the use of the manning coefficient ranging from 0 15 to 0 2 may provide reasonably good results for both the building configurations also for this group of simulations a faster initiation of outflow was reproduced the assessment of best method to use in situations like these goes beyond the purpose of the work however both the approaches can be effectively used in hr2d once the calibration of model parameters is carried out 4 3 2 test 8 rainfall and point source surface flow in urban areas the spatial grid resolution used for both the numerical models was 4 m2 for the sake of brevity only the solutions related to the points 1 2 3 and 6 are shown here as reported in néelz and pender 2013 and cea et al 2020 in particular water surface elevations and velocities are discussed for points 2 and 6 while only the water surface elevations are shown for stations 1 and 3 see fig 13 to make the comparison to the other software packages easier all the panels in fig 13 have the same vertical scale used for the y axis as in néelz and pender 2013 the results obtained by hr2d are free of oscillations consistent with results produced by other software discussed in néelz and pender 2013 and generally close to the unical ones as for the water surface levels hr2d reproduced the double peak observed in all the other models caused by the intense rainfall and the inflow discharge moreover it provided practically the same results obtained by unical model at points 1 3 and 2 see fig 13a b c whereas some discrepancies can be observed at point 6 fig 13e due to the hypothetical nature of the event we have no elements to understand which models provided the most accurate results however both the models reproduced substantially the same behaviour simulated by almost all finite volume codes solving the full swes shown in néelz and pender 2013 considering the expected differences due to the methods used for solving the equations treatment of wet dry fronts different approaches to process topography etc as for the computed water velocities by hr2d the differences in respect to the unical results are higher than those observed for the water surface elevation as regards point 2 fig 12d the differences mainly occurred during the recession stage after the two peaks since the peak values are almost the same the comparison at point 6 fig 12f showed higher differences during the first peak and the recession limb after the second peak however both the models provided values that fall in the middle of the range described by the models discussed in néelz and pender 2013 the overall solution provided by hr2d can be considered satisfying for this test considering the close agreement with both other software packages and the unical model 4 4 runoff over actual catchments 4 4 1 test 9 prediction of the discharge hydrograph starting from a design net hyetograph due to very long computational times needed to carry out this simulation the computational grid used for hr2d simulation is composed of square elements having sides equal to 10 m in order to ensure similar conditions in the simulation the same resolution was used for the unical model attention will be firstly focused on both the simulated discharges hydrographs at the basin outlet and to the analysis of flooded areas fig 14 a shows a reasonably good agreement between the hydrographs simulated by hr2d and unical even though some differences can be observed hr2d predicted a slightly slower wave than the unical one with the front wave and peak arrival times a little bit delayed the difference in terms of peak value is very low less than 5 beside the discharge hydrograph at the outlet one of most important pieces of information for flood hazard assessment is the flooded areas delimitation for rainfall runoff simulations at the basin scale since the rainfall input is applied to each computational cell it is necessary to define a water depth threshold for the identification of the flooded cells fig 14b shows the comparison between the flooded area extent computed by the two models considering four values of water depth thresholds 5 10 15 20 cm used to identify wet cells the results obtained by the two models are generally in good agreement the hr2d slightly overpredicts the flooded areas simulated by unical with a maximum discrepancy of 15 except for the first selected threshold value 0 05 m in which the total wet area is underestimated about 20 this behaviour could be explained looking at the features of the river network and flow patterns simulated by the two models shown in fig 15 in particular a quite disconnected river network is generated by hr2d in which the smaller horton orders are fragmented and look like a cloud of small areas not connected to each other this observation can be somewhat related to what was already highlighted by shustikova et al 2019 in a traditional flood propagation study about a certain amount of flooded areas hydraulically disconnected from the main inundated areas a possible explanation for this might be represented by the approach implemented in hr2d for the distribution of the water within a computational cell based also on the volume elevation curve drawn for each cell face in pre processing stage however more detailed analyzes are required on the specific features of this property that cannot be found room for in this work finally it could be of interest to assess the overlapping of the wetted areas for specific water depths this can be done using several indexes sampson et al 2015 here we used the so called critical success index csi defined as in equation 3 3 c s i a x a r a x a r in which ax and ar are the wet areas simulated by hr2d and that associated to the reference model unical respectively csi 0 means no match between model and the benchmark csi 1 implies a perfect match the csi values are substantially equal to 0 75 for all the water thresholds falling in the range 0 5 m 2 5 m highlighting a reasonably good agreement between the two models for higher water depths however the csi value is extremely low 0 15 when the wetted cells are defined using a very shallow water depth threshold 0 05 m confirming what was previously observed 4 4 2 test 10 reconstruction of an observed event computing infiltration losses within the hydrodynamic model this test was the most challenging one due to the specific features considered intentionally when this event was selected specifically a very complex event characterized by several closely spaced peak values was selected followed by a period in which no rain input was registered moreover several sources of uncertainty exist in the set up of the modelling inputs due to a lack of information the spatial distribution of the rainfall was not performed therefore the rainfall data recorded at fitterizzi station see fig 4 was considered as uniformly distributed over the basin another important source of uncertainty is in the choice of the parameter values of both the green ampt model and manning coefficients no calibration was carried out intentionally because the purpose here is to use hr2d in a blind mode as a modeller is forced to do for an ungauged basin or in the absence of previous calibration considering the available information lithological and land use maps mean values of the parameters were selected according the technical indications reported also in the hec ras user s manual finally the total duration of the simulated event approximately two days avoided the choice of a fine computational grid in order to reduce the overall computational times so significant inaccuracy in the geometric description of the channels network and the overall morphometric features of the basin are likely to occur this choice is also motivated by the absence of any parallelization of the numerical codes implemented in hr2d so a square computational grid element side 10 m was considered for the computations the comparison between the observed and simulated discharges are shown in fig 16 from a hydrologic point of view the overall solutions provided by hr2d are fairly good in particular the simulated hydrologic responses to the rainfall inputs b c and d highlighted in the green circles in fig 16 are very close to the observed ones even though some important discrepancies can be observed specifically looking at the catchment response to the rain input b the first peak is overestimated see number 1 in fig 16 whereas the second and third peaks might be considered comparable since only slight underestimations can be observed see numbers 2 and 3 in fig 16 the response to this part of the event is more impulsive than the observed one and for this reason all the simulated times to peak are lower especially in the case of the first peak a good agreement can be noted as well also after the rain input c see fig 16 for which the shape of the discharge hydrograph is very close to the observed one providing a slight overestimation of the peak and a comparable time to peak a little bit worse are the results obtained after the rain input d since the peak value is underestimated and the shape of the recession limb seems to be not reproduced particularly well finally some significant difference can be observed in the early stage of the simulation after the rain input a for which hr2d response is significant delayed therefore the differences between observed and simulated discharges were expected due to the lack of a model calibration procedure despite that the overall results can be considered encouraging and in reasonably good agreement with the observations 5 discussion this paper fits into the context of the research field related to the benchmarking of the software packages that in the last two decades have drawn significant attention within the fluvial flooding modelling however nothing has been done for non fluvial flood modelling in which the focus is not on the flood propagation starting from an upstream boundary condition discharge hydrograph but on the use of 2d hydrodynamic model as an integrated hydrologic hydrodynamic approach able to be initialized directly from a rain input as usually done in rog simulations these simulations are very challenging from a numerical point of view because the numerical schemes used for traditional flood propagation need specific treatment not only for appropriate discretization of the topography but also to deal with wet dry fronts and bed friction in order to avoid instabilities in the solution and unphysical results cea and bladé 2015 therefore the scheme must be accurate and robust to avoid instabilities in the solution due to the presence of highly unsteady wet dry fronts with water depths of a few millimetres over very rough complex and steep terrains at the same time the numerical discretization must ensure the conservation of water mass in order to compute properly the shape of the outlet hydrograph cea and bladé 2015 in this framework this paper represents one of the first studies related to the assessment of the accuracy of a software package for rog simulations with specific reference to the hr2d model due to its wide popularity even in the scientific community as far as the authors are aware this is the first time in which a systematic analysis of hr2d for rog simulation ranging from ideal tests to real event simulations has been presented in the literature but the need for research similar to this has already been recently underlined in the literature for example david and schmalz 2020 compared the performance of hr2d used as decoupled discharge hydrograph as boundary condition or integrated rog simulation model moreover zeiger and hubbart 2021 assessed the performance of hr2d for rog simulations in a mixed land use watershed using effective rainfall simulated by swat predictions those papers had different purposes from this study but are motivated by the need to understand the potential and limitations of this software package for these specific simulations the results of this study enrich and extend the analysis shown in the works cited above because we discuss the hr2d performances for rog simulation but from a different point of view explicitly focused on the evaluation of the accuracy of the numerical solvers in a wide range of challenging simulations finally for the first time in the literature hr2d was successfully used as an integrated hydrologic hydrodynamic software able to numerically reproduce an observed discharge hydrograph starting from the recorded rainfall and considering the infiltration losses within the same software package so this study is a strong indication about the fact that hr2d can be intended not only as a hydrodynamic model that needs to be coupled to hydrological models see among the most recent ones hankin et al 2019 ferguson and fenner 2020 but also as a stand alone approach able to simulate at least the basic hydrological process within a 2d hydrodynamic framework this is a key element for future research as observed by tamagnone et al 2020 according to whom the use of measured hyetographs or forecast in a hydraulic freeware and considering future upgrades in which further hydrological tools will be added open interesting opportunities for innovative hydrological hydraulic studies in this context this study might become a reference study and has the potential to pave the way for further analysis of the most widely used 2d hydrodynamic hydrologic models therefore the results of this work are expected to have several impacts in pluvial urban flood risk management schanze 2018 muthusamy et al 2019 in its broader sense however besides the accuracy features discussed in this work it should be underlined that a good hydraulic simulator cannot be fully evaluated without an extensive efficiency analysis as reported in the 2d modelling reference manual the hr2d computational module was developed from the ground up with parallel processing in mind the hec ras 2d computations will use as many cpu cores as there are available which is the default mode for running therefore an efficiency comparison with other numerical models for example running on gpu architecture may be performed but it is hard to show here because it requires a paper in itself representing a potential future development of this research 6 conclusions the rog approach is considered to be the most suitable numerical strategy for the implementation of an accurate storm risk management consequently several software packages and industrial codes are now available to perform studies like these therefore there is the need of benchmarking studies especially for the most popular software packages implementing this approach like hr2d the use of which has been rapidly increasing in the last few years motivated by these considerations this paper is one of the first researches specifically focused on the benchmarking of hr2d for rog simulations the experience gained in this benchmarking study can be summarized as reported below 1 the performance related to the runoff simulations over planar impervious surfaces using steady and uniform rainfall cannot be considered satisfying though the shape and peak value of the hydrographs are substantially reproduced unphysical results were observed in the solution due to some inaccuracy of the numerical schemes used to solve the governing equations specifically the most critical situation was detected in the simulation of the recession limb of the hydrograph in which important oscillations were observed probably induced by the inability of the numerical schemes to deal with wet dry fronts which in turn led to a meaningless solution from a hydraulic point of view this behaviour that seems to be much more important for higher slopes was not observed in the simulations performed using the unical model moreover it was highlighted that the hr2d solution approaches the unical solution only using computational cells of one order of magnitude as a further proof of the numerical inaccuracy in dealing with wet dry interfaces however these effects were not observed in the simulation related to the experimental permeable plane in which for the first time in the literature hr2d is used considering also the infiltration losses in particular the results are in good agreement with the experimental data when using calibrated parameters of the green ampt model according to what has been done in the literature 2 the use of unsteady rainfall over planar impervious surfaces exacerbated the numerical errors already discussed in the case of steady rainfall in this situation the refinement of the grid provided only limited improvements in the solution of the hr2d that showed important differences in respect to the analytical and numerical benchmarks 3 the simulations related to non uniform rainfall in the domain are challenging tests for hr2d for which no other works can be found in the literature the approach proposed here seems to provide encouraging results but further analyses are required in order to check the reliability of the solutions in the areas close to the discontinuity of the rainfall 4 contrarily to what was reported in the user s manual about the accuracy of the numerical solvers of the fully dynamic wave equations hr2d em does not provide benefits in respect to the hr2d elm at least for the rog simulations the reason for this apparent contradiction may be found in the specific nature of rog simulations that makes them more challenging than the traditional simulation of flood propagation 5 the simulations related to idealized and real world urbanized areas highlighted the good performances of hr2d specifically the two techniques used to take into account the effects of the buildings increase of roughness and topographical variation provided fairly good results even though the first approach is less influenced by the grid resolution contrarily to the second method moreover the real world test case allowed us to assess the reliability of hr2d even considering two contextual different sources of water 6 the simulations related to the runoff computation in actual basins starting from the net rainfall in order to avoid the computation of infiltration losses within hr2d highlighted a very good agreement with the predictions performed by the unical model in terms of discharge hydrograph at the outlet of the catchment no important discrepancies were observed in the water depth values throughout the basin except when considering very shallow water depths however hr2d confirmed the tendency to simulate a quite disconnected river network and inundation patterns as already observed in the literature 7 the simulation of a rainfall runoff event on the turbolo catchment carried out without any calibration of the parameters provided encouraging results since the observed discharge hydrographs are reproduced reasonably considering all the simplified assumptions and the several sources of uncertainty the analysis of this event is in itself a novelty in the literature because for the first time the performances of hr2d as an integrated hydrologic hydraulic model for discharge hydrograph computation and flood mapping are shown and discussed the generalization of the results presented in this work requires further analysis and applications however they may be useful to underline on one hand the need of further improvements in the numerical algorithms used probably in the treatment of the wet dry fronts and furthermore to consider the performances of hr2d as very promising for simulations of real events in which the rog approach is essential credit authorship contribution statement pierfranco costabile conceptualization methodology investigation writing original draft writing review editing formal analysis supervision carmelina costanzo methodology investigation software validation resources writing review editing domenico ferraro methodology investigation software validation formal analysis writing review editing pierfrancesco barca software validation formal analysis declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment the authors are grateful to dr daniel caviedes voullième for sharing data related to glasgow test case 
4041,the primary objective of this study is to investigate the kinetic fractionation of evaporation of small water bodies the experiments were performed in outdoor conditions using two evaporation pans and a small fishpond the work is motivated in part by the high sensitivity of lake evaporation derived from isotopic mass balance to the strength of the kinetic effect results show that the kinetic factor ε k for the oxygen isotopes is inversely related to the water to air temperature gradient indicating the important role of convective turbulence in kinetic fractionation of evaporation although the measured ε k displays a weak correlation with the slope of the local evaporation line lel by replacing the default ε k value of 14 2 for 18o commonly adopted for lake studies it greatly improves the performance of a theoretical lel model the ε k data in this study and reported by other authors do not support the hypothesis that ε k decreases with increasing lake size the overall mean ε k is 9 7 for 18o and 8 5 for 2h based on nine outdoor experimental results keywords kinetic fractionation oxygen and hydrogen isotopes local evaporation line small water bodies 1 introduction small lakes and ponds area 1 km2 are widely distributed in the terrestrial environment verpoorter et al 2014 messager et al 2016 they comprise over 99 of the 300 million water bodies in the world and occupy about half of the total water area on land downing et al 2006 these small water bodies are highly dynamic over time berg et al 2016 finger higgens et al 2019 maberly et al 2020 and are vulnerable to natural and anthropogenic perturbations habets et al 2018 they serve important society and ecosystem functions such as modulation of river discharge fowler et al 2015 supply of household water consumption alvarez et al 2008 carvajal et al 2014 yao et al 2018 and amphibian habitats scheffer et al 2006 wang et al 2018 accurate quantification of their evaporative water loss to the atmosphere is an important step towards a better prediction of how this water resource may be affected by environmental changes unlike land evaporation lake evaporation occurs without water limitation and can be calculated with the priestley taylor model of potential evaporation priestley and taylor 1972 for large lakes this model performs quite well stewart and rouse 1976 guo et al 2015 assouline et al 2016 xiao et al 2020 for small lakes with short fetch the model suffers from low biases because the sensible heat advected from the adjacent land provides additional energy to fuel the evaporation a field experiment at a small subarctic lake shows that the bias can be as large as 40 on the daily time scale bello and smith 1990 owing to the advection effect the monin obukhov similarity does not hold in the atmospheric surface layer over small lakes and the gradient diffusion technique is not recommended for measuring lake evaporation assouline et al 2016 another measurement technique is eddy covariance but a successful eddy covariance application also requires that the fetch is sufficiently large so that the eddy covariance flux footprint falls within the boundary of the targeted water surface for a small water body this fetch requirement is easily violated if the eddy covariance sensor is too high above the surface xiao et al 2018 zhao et al 2019 a very low observation height is necessary to reduce the flux footprint and to avoid the interference by water vapor evaporated outside of the water body but because eddies that dominate water vapor transport are small at a low measurement height kaimal and finnigan 1994 high frequency loss is a large source of the flux measurement error moore 1986 alternatively lake evaporation can be determined with isotopic mass conservation zuber 1983 gat et al 1994 jasechko et al 2014 in this application the evaporation rate is obtained by combining the measurement of isotopic compositions of inflow outflow and lake water at the start and end of an observational period with the isotopic composition of evaporation δ e calculated with the craig gordon cg model one of the most critical parameters for the cg model calculation is the kinetic fractionation factor ε k or the isotope relative enrichment due to molecular diffusion xiao et al 2017 showed that at lake taihu the lake evaporation estimate is 70 higher if they used the ε k value of about 7 2 from an ocean evaporation parameterization os than if they used the ε k value of 14 2 for 18o based on a default lake parameterization lk they found that the annual lake evaporation estimated with the os parameterization agrees well with the water vapor flux measured with an in situ eddy covariance instrument and that the cg calculated δ e produces a local evaporation line slope in agreement with the observed value the os and lk ε k parameterizations invoke different assumptions about the role of turbulence in water vapor diffusion in the atmospheric surface layer above the lake if the diffusion pathway is fully turbulent no kinetic effect exists and ε k is zero at the other limit if the diffusion is fully molecular ε k will have the highest value of 28 4 for 18o which is the ratio expressed in delta notation of the molecular diffusivity of the lighter h2 16o molecule to that of the heavier h2 18o molecule in air the lk parameterization assumes that turbulence reduces the kinetic effect of lake evaporation by half from the molecular limit gonfiantini 1986 gibson et al 2016 arnoux et al 2017 in the os parameterization the kinetic effect is weakened further presumably because of stronger atmospheric turbulence over the open ocean than over inland waters merlivat and jouzel 1979 benetti et al 2014 in addition to xiao et al 2017 the field experiment performed at an ephemeral lake lake gara diba initial size 160 m2 fontes and gonfiantini 1967 also supports use of a low ε k value by optimizing a unified cg model against the lake isotopic data obtained by fontes and gonfiantini 1967 gonfiantini et al 2018 found an ε k value of 8 52 for 18o however these two studies are not free of drawbacks in the case of gonfiantini et al 2018 the vapor isotopic composition a critical input variable of the cg model was not measured at lake gara diba but was given a somewhat arbitrary guess value in the case of xiao et al 2017 δ e was determined with the gradient diffusion technique which requires that the diffusion of the h2 18o and h2 16o molecules is in perfect compliance with the monin obukhov similarity furthermore for large lakes such as lake taihu area 2400 km2 levels of wind and turbulence are high due to large open fetch conditions it is possible that the kinetic factor is higher for small lakes due to weaker winds in a recent study gonfiantini et al 2020 have shown that in high wind conditions the isotopic behavior of evaporating waters may deviate significantly from the cg model prediction possibly due to different kinetics of breaking the hydrogen bonds of liquid water at the water air interface the current study is motivated by the question of what ε k value is most appropriate for evaporation of small water bodies its objectives are 1 to measure the ε k of evaporation of small water bodies for the oxygen isotopes 2 to investigate the relationship between ε k and the slope of the local evaporation line lel and 3 to test the hypothesis that the strength of the kinetic effect decreases with increasing lake size the outdoor experimental determination of ε k was carried out using a fishpond and two evaporation pans as proxies for small lakes the present experiment was designed to overcome the limitations of past studies the δ e was determined from the first principle mass conservation and therefore assumptions implicit in the gradient diffusion method of xiao et al 2017 were avoided the vapor isotopic composition was measured directly at high temporal resolutions that matched those of other driving variables of the cg model because these water bodies are small surface area from 0 13 m2 to 6900 m2 their influence on the overlaying air was negligible at large lakes surface evaporation and the overlaying air are interactive feng et al 2016 evaporation will modify the humidity and the vapor isotopic composition as the air moves across the lake the humidity and vapor isotopic composition changes in turn will modify surface evaporation and its isotopic composition such interactions are a source of uncertainty in cg model calculations 2 materials and methods 2 1 experimental site and instruments the goal of the field experiment was to determine ε k by inverting the isotopic mass balance equation isotope and micrometeorological data were collected for a fishpond and two evaporation pans the fishpond located in anhui province china 118 25 e and 31 97 n had an area of 6900 m2 and average depth of 2 1 m a total of six trials were conducted with a duration of 10 to 50 days table 2 during the trials a water sample was collected once a day at the 20 cm depth micrometeorological variables measured at half hourly intervals included the four components of the net radiation model cnr4 kipp zonen b v delft the netherlands the profile of water temperature at depths of 20 50 and 80 cm temperature probes model 109 l campbell scientific inc logan utah usa air temperature and humidity model hmp155a vaisala inc helsinki finland at a height of 2 m above the surface wind speed and wind direction model 05103 r m young inc traverse city michigan usa at a height of 3 m and eddy fluxes of water vapor sensible heat and momentum sonic anemometer thermometer model csat3a campbell scientific inc open path co2 h2o infrared gas analyzer model ec150 campbell scientific inc at a height of 2 m rainfall was observed at a weather station belonging to the quanjiao meteorological bureau about 12 km from the observation site rainfall samples were collected at the site for individual precipitation events for isotopic analysis the water surface temperature was inverted from the outgoing and incoming longwave radiation using the stefan boltzmann law with an emissivity of 0 97 to maintain a sufficient water level local famers pumped 412 and 634 m3 water from a canal into the fishpond during fishpond trials f1 and f2 respectively a sample was collected from the pumped water for isotopic analysis two evaporation pans wmo type e601 with 61 8 cm diameter and type ϕ20 with 20 cm diameter were installed next to the fishpond they were partially buried in the soil to help reduce temperature fluctuations their bottom interiors were painted black to promote absorption of solar radiation and convective mixing of the water column the water surface temperature was measured with an infrared thermometer model si 111 campbell scientific inc water temperature was also measured at 2 cm below the surface model 109 l campbell scientific inc three experimental trials each lasting 13 to 20 days were made with the big pan and six trials each lasting 4 to 10 days were made with the small pan the initial water mass was about 100 kg and the final mass was about 90 kg in the big pan trials the initial and the final mass in the small pan trials were about 3 kg and 2 kg respectively a small sample 5 ml was collected each day for isotopic analysis the evaporation rate was determined daily by measurement of the water level and corrected for the removal of water samples the pans were covered during rain events for the big pan the water surface was 26 73 cm to 31 99 cm below the top edge for the small pan the distance ranged from 1 53 cm to 4 95 cm the craig gordon model calculation requires measurement of the isotopic composition of water vapor this measurement was made in situ with a water vapor isotope analyzer model 911 0004 los gatos research mountain view ca usa located at a distance of 100 m from the fishpond the analyzer inlet was positioned at a height of 9 m above the water surface the analyzer sampling frequency was 1 hz and the data were averaged to 60 min intervals calibration of the vapor isotope measurement was made with a vapor source supplied with working liquid water standards model 908 0003 9002 los gatos research traceable to the vsmow scale the liquid water standards had delta values in the range of 8 7 to 3 0 for δ 18o and 59 4 to 26 2 for δ 2h the calibration was performed at five humidity levels that were adjusted dynamically to bracket the ambient humidity xiao et al 2017 isotopic analysis of liquid water samples including rainwater irrigation water fishpond water and evaporation pan water was made with a liquid water isotope analyzer model dlt 100 los gatos research in the key laboratory of ecosystem network observation and modeling chinese academy of sciences the analyzer was calibrated against 3 working standards traceable to the vsmow scale δ 2h δ 18o 79 6 11 04 49 2 7 81 9 9 2 99 all liquid water samples were sealed and placed in a refrigerator at 4 c before analysis all isotope values are expressed as delta scale δ r sample r vsmow 1 1000 where r is the 2h 1h or 18o 16o ratio and r vsmow are 0 00015576 for 2h 1h and 0 0020052 for 18o 16o the analytical uncertainty of the liquid water isotope measurement is 0 3 for δ 2h and 0 1 for δ 18o and the uncertainty of the vapor isotope measurement after calibration is 2 for δ 2h and 0 2 for δ 18o 2 2 isotope mass balance analysis we used the mass balance equations to obtain the isotopic composition of evaporation δ e and the mean evaporation rate e t for each experimental trial described above the complete expression of mass balance of a water body is 1 i p o s e d v where i is inflow water p is precipitation o is outflow water s is the amount of water sample removed for isotopic analysis e is evaporation water loss and dv is the change of water amount during the experimental period the isotopic mass balance equation is 2 i δ i p δ p o δ o s δ s e δ e d v δ l where δ is isotopic composition of 2h or 18o in delta notation and subscripts i p o s e and l denote inflow precipitation outflow sampled water evaporated water and liquid water in the fishpond or the evaporation pans as defined in table 1 for the evaporation pans inflow and outflow were zero and precipitation input was also zero for the fishpond s was negligible outflow was zero because no drainage occurred during the experimental trials and i was the water input via pumping during f1 and f2 and zero for other trials all the terms in eqs 2 and 3 except e and δ e were measured experimentally the total amount of evaporation e was determined from eq 1 and was converted to evaporation rate e t in units of g m 2 s 1 the isotopic composition of evaporation δ e was determined from eq 2 2 3 experimental determination of the kinetic factor the mass balance approach we combined the δ e obtained from the isotopic mass balance with the craig gordon model craig and gordon 1965 to quantify the kinetic factor for 18o according to the model the hourly isotopic composition of evaporation is given by 3 δ e α e q 1 δ l h δ v ε e q 1 h ε k 1 h 0 001 1 h ε k where h is relative humidity in fraction in reference to the saturated vapor pressure at the water surface δ v is isotopic composition of water vapor δ l is isotopic composition of liquid water in the evaporation pans or the fishpond α eq 1 is the equilibrium fractionation factor ε eq 103 1 1 α eq is the equilibrium factor in delta notation and ε k is isotopic kinetic fractionation factor the prime symbol indicates that the calculated isotopic composition of evaporation is an hourly value to distinguish it from the whole trial mean δ e from eq 2 in eq 3 h and t s were means of two 30 min measurements α eq and ε eq were determined as a function of the water surface temperature δ l was linearly interpolated to hourly intervals from the daily isotope measurement of the liquid sample but ε k is an unknown parameter to be determined by an optimization method described below supplementary figure s1 eq 3 helps to clarify the definition of the kinetic factor used in the present study it is a property intrinsic to atmospheric flow and is not related to the status of atmospheric humidity the total kinetic effect is given by 1 h ε k the bulk aerodynamic method was used to determine a weighting factor for the fishpond trials this method expressed the hourly evaporation rate as 4 e t ρ a c e u q s q a where ρ a is air density c e is the transfer coefficients for moisture u is wind speed and q s and q a are the specific humidity at the surface and at the reference height respectively so the parameter group ρ a u q s q a was used as evaporation flux weighted factor the craig gordon model calculation was upscaled to give the δ e of the whole experimental trial as 5 δ e δ e ρ a u q s q a ρ a u q s q a eq 5 makes the assumption that c e is invariant with time the evaporation flux weighting factor ρ a u q s q a was calculated on an hourly scale this weighting factor is essentially a bulk parameterization for open water evaporation whereby the rate of evaporation is proportional to wind speed and to the vapor concentration difference between the water surface and a reference height in the surface layer the kinetic factor ε k was determined using a numerical optimization method with eqs 3 5 the optimization aimed to achieve a perfect match between δ e calculated from these equations and the δ e determined from the isotopic mass conservation eq 2 the method yielded a solution of ε k the bulk relationship was also used to obtain the evaporation flux weighted factor for the pan experiments supplementary figure s2 however we found that the transfer coefficient showed day to day variations to account for these variations we included a daily correction coefficient c i so the weighting becomes c i ρ a u q s q a the coefficient c i is given by 6 c i e i ρ a u q s q a where e i is the actual daily evaporation amount observed on day i the ε k value was also found through the optimization method with eqs 3 5 except that the weighting factor was calculated with a correction coefficient c i 2 4 experimental determination of the kinetic factor the unified cg model approach the kinetic factor was also determined with the unified cg model of gonfiantini et al 2018 this model combines the cg model with the isotopic mass balance equation into an integral form and predicts δ l as a function of the residual liquid water fraction in this model water temperature humidity vapor isotopic composition and initial δ l are known variables the kinetic effect appears in this model as a tunable turbulence parameter n the n value was determined for each pan experiment by optimizing the model predicted δ l against the observed δ l the goal of the optimization was to minimize the sum of squared errors of δ l all the input variables were flux weighted mean values as described above the relationship between n and r i r or the ratio of the diffusion resistance of the heavier h2 18o molecule r i to that of the lighter h2 16o molecule r is given by 7 r i r d d i n where d and d i denote the molecular diffusivity of major and minor water isotopic species in air respectively the n value ranges between 0 under fully turbulent conditions and 1 if the diffusion is completely molecular the kinetic factor ε k was obtained from the optimized n from the following equation gonfiantini 1986 8 ε k n d d i 1 10 3 the diffusivity ratio d i d is set to the value of 0 9723 for 18o and 0 9755 for 2h merlivat 1978 hellmann and harvey 2020 giving an ε k of 28 4 for 18o and 25 0 for 2h at n 1 in principle the mass balance and the unified cg methods can used to constrain the kinetic factor for 2h to our best knowledge no published studies have used 2h data alone to determine the kinetic factor in outdoor conditions there may be two reasons for this first the 2h fractionation of water evaporation in natural conditions is dominated by the equilibrium effect at 20 c the equilibrium fractionation factor ε eq for 18o is 9 4 which is comparable in magnitude to the kinetic factor but ε eq for 2h 74 3 is an order of magnitude larger the δ 2h of evaporation is not sensitive to the kinetic effect xiao et al 2017 the lack of sensitivity makes it difficult to obtain an accurate estimate of the kinetic factor from the measured δ 2h of evaporation second measurement errors for 2h are generally larger than for 18o in the present study the uncertainty of the liquid water delta is 0 3 for 2h which is three times that for 18o 0 1 the uncertainty of the vapor delta is 10 times larger for 2h 2 than for 18o 0 2 in the following we only report the result on the turbulent parameter n using the 18o data although the 2h data was not used for the determination of n it was included in the evaluation of the relationship between the lel slope and kinetic fractionation section 4 3 3 results table 2 summarizes the mean environmental conditions for all the experimental trials the experiments were conducted in warm seasons with the water temperature ranging from 14 7 c to 40 7 c the wind speed during these times ranged from 1 21 m s 1 to 2 86 m s 1 the δ v varied in the range of 126 9 to 78 9 for 2h and 20 6 to 11 2 for 18o which are typical of the warm season values in eastern china wen et al 2008 xiao et al 2017 the initial δ l of the pan experiments was on average 41 7 for 2h and 6 2 for 18o which is lower than that of the fishpond water average 19 3 for 2h and 1 5 for 18o the relative humidity referenced to the water surface temperature varied in a range of 0 37 to 0 62 figure 1 provides an example of hourly time series of the driving variables panels a b and d of the craig gordon model and time series of the model calculated hourly δ 18o values of evaporating vapor δ e for experiment s2 the δ e result shown here is given with the optimized ε k of 6 01 for 18o the δ 18o value of the pan water δ l was continuously enriched over time as a result δ e increased progressively from the initial value of 20 1 to 13 1 at the end of the experiment the relative humidity h showed strong diurnal variations which mirrored the variations in the water surface temperature t s resulting in lower δ e at night than during the day the daytime observations were weighted much more heavily than the nighttime values panel e with the optimized ε k the flux weighted mean isotopic composition of evaporation was 17 0 matching exactly the δ e obtained from the isotopic mass balance calculation figure 2 is an example showing the application of the unified cg model to experiment s1 the optimization yielded the best estimate of 0 25 for n according to eq 8 the best estimate of ε k for this experiment is 7 10 figure 3 compares ε k value obtained with isotopic mass balance that from the unified cg model in general the ε k value from isotopic mass balance agrees very well with the ε k value from the unified cg model if the unified cg used flux weighted mean values for its input variables black squares linear correlation r 0 99 confidence level p 0 001 in the following unless stated otherwise we will restrict our analysis to the isotopic mass balance data the results of all the experimental trials are summarized in table 3 here the 18o δ e value was obtained from optimizing the craig gordon model calculation against the δ e from the isotopic mass balance and the turbulence parameter n was obtained from eq 8 the δ e shows a large range of variation with the lowest value 31 8 observed in experiment trial b3 with the big evaporation pan and highest value 7 3 during f4 with the fishpond the experimental trial s6 with the small pan experienced similar environmental conditions as trial b3 as they took place at about the same time table 2 but the δ e of s6 was much higher 13 1 a significant and negative correlation was found between δ e 18o and ε k linear correlation r 0 69 p 0 01 confirming that a stronger kinetic effect will cause more depletion of 18o in the evaporated water the correlation between δ e and other variables shown in table 2 was not significant a multivariate stepwise regression reveals that ε k ε eq δ l and δ v could explain 99 of the δ e variations shown in table 2 and that flux weighted relative humidity was excluded by the stepwise procedure the kinetic factor ε k varied in a broad range from 2 40 experimental trial s4 to 22 10 experimental trial b3 indicating a varying role of turbulence in the kinetic fractionation among these experiments the kinetic factor showed a strong negative correlation with the water to air temperature difference t s t a r 0 67 p 0 01 fig 4 additionally ε k was negatively correlated with water surface temperature t s r 0 67 p 0 01 and the mean evaporation rate e t r 0 76 p 0 01 however t s and e t were both positively correlated with t s t a r 0 68 for t s and r 0 75 for e t p 0 01 the most logical explanation for these correlations is that t s t a exerted direct control on ε k and the correlation of ε k with t s or e t arose from their covariations with t s t a the mean kinetic factor measured in this study was 7 0 3 1 with the small evaporation pan 14 3 6 8 with the big evaporation pan and 10 2 4 9 with the fishpond if we excluded b3 section 3 1 the mean value for the big evaporation pan 10 4 was in better agreement with that obtained with the small evaporation pan these values agreed better with the os value of 8 1 calculated for the mean wind conditions during this study than with the default lake value of 14 2 fig 5 the mean ε k values from the pan experiments was 9 44 5 54 mean one standard deviation according to the imb calculation and 9 34 6 60 according to the unified cg model a two tailed student t test shows that there was no significant difference between the results p 0 97 t 0 04 the rmse of two sets of ε k values was 1 27 4 discussion 4 1 uncertainty analysis we performed monte carlo simulations to quantify uncertainties in the calculated ε k uncertainties in input variables are provided in supplementary table s1 errors in these variables were assumed to follow normal distributions and to be independent of each other a total of 10 000 ensemble members were used for each evaporation experiment with each member producing an ε k value the uncertainty in ε k was calculated as ½ of the difference between the 75th and the 25th percentile value of the ensemble these ε k uncertainties are smaller than the physical range of variations shown in table 3 and fig 4 in the case of the mass balance approach uncertainties in both the δ e mass balance measurement and the cg calculation contributed to the uncertainty in the determination of ε k as shown in fig 6 for experiment s1 in this figure the solid sloped line represents the δ e as a function of ε k calculated with the cg model using the measured input parameters and the solid horizontal line represents the δ e value of 18 0 from the isotopic mass balance table 3 the intercept of these two lines gives the actual ε k 7 73 table 3 for experiment s1 assuming no uncertainty in either the mass balance or the cg model calculation however both the δ e measurement and cg model calculation carried uncertainties shown as the range between the paired dashed lines in fig 6 the overall uncertainty in ε k was 0 3 according to the monte carlo analysis similar ε k uncertainty estimates were obtained for the mass balance approach applied to the other pan experiments the ε k estimates for the fishpond experiments using the isotopic mass balance method had an uncertainty of about 1 5 this larger uncertainty stemmed primarily from the uncertainty in the δ e determination uncertainty of about 1 6 which is larger than the δ e uncertainty of 0 27 for the pan experiment s1 shown in fig 6 because the mass balance calculation involved more input variables than for the pan experiments and because these additional variables were more uncertain than the other variables supplementary table s1 in contrast the ε k uncertainty from the unified cg model was 5 to 10 times smaller than the uncertainty for the pan experiments from the isotopic mass balance method indicating robustness of the unified cg model there are two reasons for this first the unified cg model was constrained by the isotopic composition of the liquid water δ l which is more accurate than δ e table s1 second multiple δ l measurements were used in the optimization procedure fig 2 and s3 further reducing the uncertainty in the ε k estimation 4 2 comparison of pan experimental data numerous outdoor pan experiments have been reported in the literature the majority of these experiments aim to quantify the rate of liquid water evaporation some have been used to determine the isotopic composition of evaporation by adopting the traditional values of ε k 14 2 for 18o and 12 5 for 2h e g crawford et al 2019 devi et al 2015 skrzypek et al 2015 according to the survey by gonfiantini et al 2018 two pan experiments have been conducted in the past to investigate kinetic isotopic fractionation of evaporation in natural conditions the first one was carried out by craig et al 1963 on the roof of a laboratory building in la jolla california for a duration of 16 days the second one was carried out in an open field by skrzypek et al 2015 in western australia for a duration of 12 16 days recently gonfiantini et al 2018 used the unified cg model to constrain the turbulent parameter n with the data from these experiments because the isotopic ratio of water vapor was not measured fontes and gonfiantini 1967 gonfiantini et al 2018 approximated vapor delta with the value in equilibrium with local precipitation this approximation is somewhat arbitrary because precipitation events were rare however its impact on δ e is rather limited due to the low air humidity in addition algebraic mean values were used for other input variables of the model the resulting n is 0 5 ε k 14 2 for 18o for craig s experiment and 0 4 ε k 11 36 for 18o for skrzypek s experiment in their original study skrzypek et al 2015 used the traditional value of 14 2 for ε k the current study was inspired by the work of these authors the iris instrument brought two improvements to the pan experimental method first the vapor isotopic composition was directly measured so the equilibrium approximation was no longer needed second instead of simple algebraic averaging flux weighted mean values for input variables h ε eq and δ v were used in the unified cg model calculation in order to account for the fact that environmental conditions during times of higher evaporation exert a stronger influence on the cumulative fractionation of the evaporating water with these improvements the ε k from the unified cg model was in excellent agreement with that obtained from isotopic mass balance with a small root mean square error rmse of 1 27 solid symbols fig 3 if simple algebraic means of the forcing variables were used for the unified cg calculation the rmse became larger at 2 55 open symbols fig 3 the unified cg model was also sensitive to how the vapor delta was obtained the amount weighted isotopic composition of precipitation during the 2017 experimental season may to november was 3 38 18o if the vapor delta value in equilibrium with the local precipitation was used instead of the observed value the ε k could deviate significantly from that obtained with the isotopic mass balance method giving a large overall rmse of 4 23 grey symbols fig 3 our experimental study seems to be the first to provide direct evidence for the role of turbulence in kinetic fractionation in outdoor conditions fig 4 since t s t a drives convective turbulence in the atmospheric surface layer fig 4 confirms that atmospheric turbulence weakens the kinetic fractionation of water evaporation we found that ε k was weakly correlated with humidity h r 0 34 p 0 23 and friction velocity u r 0 32 p 0 26 the latter of which is a measure of mechanic turbulence a stepwise linear regression using t s t a h and u as predictors reveals that ε k was only independently related to t s t a suggesting that convective turbulence played a more dominant role than mechanic turbulence in controlling the kinetic effect during our experimental trials the extremely high ε k of 22 1 from experiment b3 occurred at a very low water to air temperature gradient 0 25 c fig 4 the corresponding turbulence parameter n is 0 78 indicating that the level of turbulence during this experiment was almost negligible this n value is higher than those reported for the outdoor pan evaporation experiments carried out by craig et al 1963 n 0 50 and skrzypek et al 2015 n 0 40 and even higher than most of the evaporation experiments conducted in controlled conditions for example cappa et al 2003 reported that n ranges from 0 36 to 0 44 using small evaporation dishes housed in a dynamic chamber using a similar flow through evaporation chamber setup kim and lee 2011 reported n values of 0 55 to 0 75 of the 29 laboratory and natural experiments analyzed by gonfiantini et al 2018 only six have n 0 78 and all the exceptions involve a setup where water vaporizes into quiescent air or involving a special gas it appears that conditions during experiment b3 were anomalous for these reasons the high ε k value from experiment b3 has been excluded from the mean value in fig 5 and table 4 4 3 relationship between the lel slope and kinetic fractionation a well known consequence of kinetic fractionation is the deviation of the local evaporation line lel from the global mean meteorite water line gmwl the lel is formed in a scatter plot between the hydrogen and oxygen isotope compositions of the evaporating water compared to the gmwl slope of 8 the lel has a smaller slope value because the lel preserves the cumulative influence of water evaporation it is often used to help infer local hydrological conditions during the evaporation season gibson et al 2008 approximated the local precipitation isotope value with the intercept of the observed lel and the gmwl gibson et al 2005 used the deviation of the lel from the gmwl in their model to determine the watershed evaporation to inflow ratio skrzypek et al 2015 estimated the water vapor isotope delta using the isotope composition of rainfall and the slope of lel wassenaar et al 2011 used the lel slope to determine relative humidity which is a parameter required for computing the evaporation to inflow ratio the analysis of an isotope dataset collected at a peatland stream network suggests that the lel slope is indicative of potential evaporation sprenger et al 2017 these applications generally use the default lake kinetic factor of 14 2 for 18o the observed lel slope is given in table 3 here the lel slope was the slope of linear regression of the δ 2h value against the δ 18o value of the pan water the kinetic factor itself was poorly correlated with the slope r 0 05 the correlation between 1 h ε k and the slope was also weak r 0 02 we deployed two predictive models to further examine the relationship of the lel slope to kinetic fractionation the first model model 1 is given by 9 s l e l ε e q 1 h ε k 2 ε e q 1 h ε k 18 where subscript 2 and 18 denote 2h and 18o respectively gat 2010 brooks et al 2014 this model assumes that the evaporating water and the atmospheric vapor are in isotopic equilibrium and consequently only equilibrium fractionation and kinetic fractionation control the lel slope the second model model 2 takes a more general form gibson et al 2008 10 s l e l h δ v δ l 0 1 10 3 δ l 0 1 h ε k α e q 1 ε e q 10 3 h 1 h ε k α e q 1 ε e q 2 h δ v δ l 0 1 10 3 δ l 0 1 h ε k α e q 1 ε e q 10 3 h 1 h ε k α e q 1 ε e q 18 this model applies to situations where the evaporating water comes from local precipitation and no isotopic equilibrium is assumed here the δ p in the original model was replaced by the isotopic composition of the liquid water at the start of the pan experiment δ l 0 the model calculations were repeated three times using three sets of kinetic factors and were compared with the observed lel slope fig 7 the first set solid symbols fig 7 used the 18o ε k determined by isotopic mass balance imb table 3 and the 2h ε k obtained with eq 8 and the imb n value in table 3 the second set open symbols fig 7 used the lake default ε k of 14 2 for 18o and 12 5 for 2h the third set grey symbols fig 7 deployed the imb ε k for 18o and the lake default value for 2h the fishpond experiments were excluded from this analysis because the range of the observed liquid water isotopic composition was too small during each experimental period 0 7 for 18o and the resulting lel slope was too uncertain both models were sensitive to how the kinetic factors were specified using the measured ε k values the modeled lel slope was 5 52 0 56 mean 1 standard deviation according to model 1 and 4 75 0 98 according to model 2 using the default lake ε k values the modeled slope was reduced to 4 71 0 45 according to model 1 and 3 89 0 58 according to model 2 the sensitivity arose mostly from changes in the kinetic factor for 18o by changing the 2h kinetic factor to the default lake value but keeping the measured value for 18o the modeled slope only changed slightly to 5 72 0 75 and 5 09 1 26 according to model 1 and model 2 respectively using the default lake ε k values xiao et al 2017 found that the δ e calculated by the craig gordon model falls on a lel with a slope of about 3 2 for lake taihu which is lower than the observed slope of 6 33 by switching to the lower os kinetic factors their calculated δ e falls on the observed lel the lel slope predicted by model 2 broadly agreed with the observed value mean bias 0 15 rmse 1 04 but the slope predicted by model 1 was biased high and was more scattered mean bias 0 59 rmse 1 25 gibson et al 2008 found that model 2 can reproduce the observed lel slope for lakes in the world the superior performance of model 2 over model 1 implies that although the kinetic effect plays an important role in determining the lel slope other factors such as the isotopic compositions of water vapor and local water input can also influence the slope value 4 4 dependence of kinetic factor on lake size table 4 provides a summary of the kinetic factors for 18o obtained in natural conditions they include three values from this study four values found in the published literature and two additional values we determined with local hydrological data reported by other authors a range of methods were used to obtain these values including isotopic mass balance small pan big pan fishpond the unified craig gordon model evap pan g evap pan s and lake gara gradient diffusion lake taihu and simplified isotopic mass balance for terminal lakes lake waid and lake burdur appendix a here the ε k value for lake taihu was obtained by tuning it so the craig gordon model prediction matches the δ e determined with the gradient diffusion method and was slightly higher than that given by xiao et al 2017 using the wind parameterization of merlivat and jouzel 1979 the survey results are separated into two size classes according to this survey there is no significant relationship between ε k and lake size the mean ε k 18o value 9 64 2 80 for the small class is not significantly different from the mean value 10 10 2 60 for the large class p 0 85 t 0 20 two tailed student t test the overall mean ε k is 9 74 2 60 for 18o based on the 9 values in table 4 the corresponding turbulent parameter n is 0 34 combining this n value with eq 8 yields a mean kinetic factor of 8 5 for 2h the insignificant difference in ε k between the two size classes is based on a small data sample more field research is needed to further evaluate this relationship there are however reasons to believe that the insensitivity of ε k to lake size may hold broadly for globe lakes this is because wind speed and the thermal gradient in the surface layer air have opposite relationships with lake size the longer fetch at a larger lake allows wind speed to build up which will reduce ε k according to the os parameterization of merlivat and jouzel 1979 in a modeling study of heat diffusion between the lake and the atmosphere hondzo and stefan 1993 parameterized wind speed as a proportion to lake area increasing by about 50 from a size of 0 01 km2 to a size of 100 km2 on the other hand the water air temperature difference t s t a should decrease with increasing lake size which will result in an increase in ε k according to fig 4 and may cancel out part or all of the decrease in ε k due to the wind effect large lakes are generally deeper than small lakes cael et al 2017 and do not warm up as fast in the evaporation season they also tend to have lower dissolved organic carbon concentrations hanson et al 2007 allowing sunlight to penetrate deeper in the water and leading to lower surface temperature than small lakes the inverse relationship between t s t a and lake size is supported by the meta analysis of thermal conditions of global lakes showing that the occurrence frequency of unstable stratification in the surface layer air woolway et al 2017 and the diel air temperature range woolway et al 2016 are negatively correlated with lake size oswald and rouse 2004 provided a numerical example on the opposing effects of lake size on wind speed and on the temperature gradient they showed that skeeter lake a small lake area 0 05 km2 in northwest territories canada displayed a larger t s t a 4 5 c but lower wind speed 2 8 m s 1 than sleepy dragon lake a large lake area 5 5 km2 in the same region t s t a of 2 5 c wind speed of 4 2 m s 1 during an ice free season 5 conclusions the kinetic factor ε k for 18o varied in the range of 2 40 to 22 10 during our experiments the mean value was 9 70 with all the data included and 8 75 with the b3 outlier excluded we showed that ε k decreased linearly with increasing lake surface to air temperature gradient the novelty of this finding interpreted together with the classic parameterization of ε k as a function of wind speed merlivat and jouzel 1979 is that the role of turbulence in kinetic fractionation manifests in both mechanic turbulence as measured by wind speed and convective turbulence as measured by the temperature gradient although the measured ε k showed poor correlation with the slope of the lel local evaporation line it greatly improved the performance of the lel model of gibson et al 2008 supporting the robustness of our isotopic mass balance method and indicating that in addition to the kinetic effect the isotopic compositions of water vapor and local water input can also influence the lel slope the ε k data reported here and those found in the literature do not support the hypothesis that ε k decreases with increasing lake size the lack of sensitivity to lake size may be a result of opposing effects of lake size on wind speed and on the lake to air temperature gradient the overall mean ε k was 9 7 for 18o and 8 5 for 2h based on ten outdoor experimental results covering a size range from 0 13 m2 to 2400 km2 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national key r d program of china grant 2019yfa0607202 to wx and the national natural science foundation of china grants 41975143 41475141 41830860 and 42021004 to wx and mz appendix a kinetic fractionation of terminal lakes terminal lakes are lakes that do not have surface outflows in the special case where groundwater contribution and seepage are negligible the water input inflow plus precipitation is balanced by evaporation loss and the isotopic value of the input water is balanced by that of evaporation under these conditions poulin et al 2019 have derived an expression for the lake water isotopic value from isotopic mass balance manipulating their eq 7 we obtain an equation for the kinetic factor as a 1 ε k α e q 1 δ l h δ v ε e q 1 h δ i 1 h 10 3 δ i 1 eq a 1 was used to estimate the 18o kinetic factor for lake waid zimmermann 1979 zuber 1983 and lake burdur dincer 1968 zuber 1983 the input variables are summarized as follows lake waid germany δ l 2 19 δ i 7 91 δ v 17 4 t w 11 1 c water temperature t a 10 55 c air temperature h 0 69 in reference to water temperature lake burdur turkey δ i 8 9 δ l 0 3 table 4 of dincer 1968 t l 12 9 c h 0 59 δ v 19 0 on the assumption that it is in equilibrium with δ i δ p at temperature of 12 9 c appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126974 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
4041,the primary objective of this study is to investigate the kinetic fractionation of evaporation of small water bodies the experiments were performed in outdoor conditions using two evaporation pans and a small fishpond the work is motivated in part by the high sensitivity of lake evaporation derived from isotopic mass balance to the strength of the kinetic effect results show that the kinetic factor ε k for the oxygen isotopes is inversely related to the water to air temperature gradient indicating the important role of convective turbulence in kinetic fractionation of evaporation although the measured ε k displays a weak correlation with the slope of the local evaporation line lel by replacing the default ε k value of 14 2 for 18o commonly adopted for lake studies it greatly improves the performance of a theoretical lel model the ε k data in this study and reported by other authors do not support the hypothesis that ε k decreases with increasing lake size the overall mean ε k is 9 7 for 18o and 8 5 for 2h based on nine outdoor experimental results keywords kinetic fractionation oxygen and hydrogen isotopes local evaporation line small water bodies 1 introduction small lakes and ponds area 1 km2 are widely distributed in the terrestrial environment verpoorter et al 2014 messager et al 2016 they comprise over 99 of the 300 million water bodies in the world and occupy about half of the total water area on land downing et al 2006 these small water bodies are highly dynamic over time berg et al 2016 finger higgens et al 2019 maberly et al 2020 and are vulnerable to natural and anthropogenic perturbations habets et al 2018 they serve important society and ecosystem functions such as modulation of river discharge fowler et al 2015 supply of household water consumption alvarez et al 2008 carvajal et al 2014 yao et al 2018 and amphibian habitats scheffer et al 2006 wang et al 2018 accurate quantification of their evaporative water loss to the atmosphere is an important step towards a better prediction of how this water resource may be affected by environmental changes unlike land evaporation lake evaporation occurs without water limitation and can be calculated with the priestley taylor model of potential evaporation priestley and taylor 1972 for large lakes this model performs quite well stewart and rouse 1976 guo et al 2015 assouline et al 2016 xiao et al 2020 for small lakes with short fetch the model suffers from low biases because the sensible heat advected from the adjacent land provides additional energy to fuel the evaporation a field experiment at a small subarctic lake shows that the bias can be as large as 40 on the daily time scale bello and smith 1990 owing to the advection effect the monin obukhov similarity does not hold in the atmospheric surface layer over small lakes and the gradient diffusion technique is not recommended for measuring lake evaporation assouline et al 2016 another measurement technique is eddy covariance but a successful eddy covariance application also requires that the fetch is sufficiently large so that the eddy covariance flux footprint falls within the boundary of the targeted water surface for a small water body this fetch requirement is easily violated if the eddy covariance sensor is too high above the surface xiao et al 2018 zhao et al 2019 a very low observation height is necessary to reduce the flux footprint and to avoid the interference by water vapor evaporated outside of the water body but because eddies that dominate water vapor transport are small at a low measurement height kaimal and finnigan 1994 high frequency loss is a large source of the flux measurement error moore 1986 alternatively lake evaporation can be determined with isotopic mass conservation zuber 1983 gat et al 1994 jasechko et al 2014 in this application the evaporation rate is obtained by combining the measurement of isotopic compositions of inflow outflow and lake water at the start and end of an observational period with the isotopic composition of evaporation δ e calculated with the craig gordon cg model one of the most critical parameters for the cg model calculation is the kinetic fractionation factor ε k or the isotope relative enrichment due to molecular diffusion xiao et al 2017 showed that at lake taihu the lake evaporation estimate is 70 higher if they used the ε k value of about 7 2 from an ocean evaporation parameterization os than if they used the ε k value of 14 2 for 18o based on a default lake parameterization lk they found that the annual lake evaporation estimated with the os parameterization agrees well with the water vapor flux measured with an in situ eddy covariance instrument and that the cg calculated δ e produces a local evaporation line slope in agreement with the observed value the os and lk ε k parameterizations invoke different assumptions about the role of turbulence in water vapor diffusion in the atmospheric surface layer above the lake if the diffusion pathway is fully turbulent no kinetic effect exists and ε k is zero at the other limit if the diffusion is fully molecular ε k will have the highest value of 28 4 for 18o which is the ratio expressed in delta notation of the molecular diffusivity of the lighter h2 16o molecule to that of the heavier h2 18o molecule in air the lk parameterization assumes that turbulence reduces the kinetic effect of lake evaporation by half from the molecular limit gonfiantini 1986 gibson et al 2016 arnoux et al 2017 in the os parameterization the kinetic effect is weakened further presumably because of stronger atmospheric turbulence over the open ocean than over inland waters merlivat and jouzel 1979 benetti et al 2014 in addition to xiao et al 2017 the field experiment performed at an ephemeral lake lake gara diba initial size 160 m2 fontes and gonfiantini 1967 also supports use of a low ε k value by optimizing a unified cg model against the lake isotopic data obtained by fontes and gonfiantini 1967 gonfiantini et al 2018 found an ε k value of 8 52 for 18o however these two studies are not free of drawbacks in the case of gonfiantini et al 2018 the vapor isotopic composition a critical input variable of the cg model was not measured at lake gara diba but was given a somewhat arbitrary guess value in the case of xiao et al 2017 δ e was determined with the gradient diffusion technique which requires that the diffusion of the h2 18o and h2 16o molecules is in perfect compliance with the monin obukhov similarity furthermore for large lakes such as lake taihu area 2400 km2 levels of wind and turbulence are high due to large open fetch conditions it is possible that the kinetic factor is higher for small lakes due to weaker winds in a recent study gonfiantini et al 2020 have shown that in high wind conditions the isotopic behavior of evaporating waters may deviate significantly from the cg model prediction possibly due to different kinetics of breaking the hydrogen bonds of liquid water at the water air interface the current study is motivated by the question of what ε k value is most appropriate for evaporation of small water bodies its objectives are 1 to measure the ε k of evaporation of small water bodies for the oxygen isotopes 2 to investigate the relationship between ε k and the slope of the local evaporation line lel and 3 to test the hypothesis that the strength of the kinetic effect decreases with increasing lake size the outdoor experimental determination of ε k was carried out using a fishpond and two evaporation pans as proxies for small lakes the present experiment was designed to overcome the limitations of past studies the δ e was determined from the first principle mass conservation and therefore assumptions implicit in the gradient diffusion method of xiao et al 2017 were avoided the vapor isotopic composition was measured directly at high temporal resolutions that matched those of other driving variables of the cg model because these water bodies are small surface area from 0 13 m2 to 6900 m2 their influence on the overlaying air was negligible at large lakes surface evaporation and the overlaying air are interactive feng et al 2016 evaporation will modify the humidity and the vapor isotopic composition as the air moves across the lake the humidity and vapor isotopic composition changes in turn will modify surface evaporation and its isotopic composition such interactions are a source of uncertainty in cg model calculations 2 materials and methods 2 1 experimental site and instruments the goal of the field experiment was to determine ε k by inverting the isotopic mass balance equation isotope and micrometeorological data were collected for a fishpond and two evaporation pans the fishpond located in anhui province china 118 25 e and 31 97 n had an area of 6900 m2 and average depth of 2 1 m a total of six trials were conducted with a duration of 10 to 50 days table 2 during the trials a water sample was collected once a day at the 20 cm depth micrometeorological variables measured at half hourly intervals included the four components of the net radiation model cnr4 kipp zonen b v delft the netherlands the profile of water temperature at depths of 20 50 and 80 cm temperature probes model 109 l campbell scientific inc logan utah usa air temperature and humidity model hmp155a vaisala inc helsinki finland at a height of 2 m above the surface wind speed and wind direction model 05103 r m young inc traverse city michigan usa at a height of 3 m and eddy fluxes of water vapor sensible heat and momentum sonic anemometer thermometer model csat3a campbell scientific inc open path co2 h2o infrared gas analyzer model ec150 campbell scientific inc at a height of 2 m rainfall was observed at a weather station belonging to the quanjiao meteorological bureau about 12 km from the observation site rainfall samples were collected at the site for individual precipitation events for isotopic analysis the water surface temperature was inverted from the outgoing and incoming longwave radiation using the stefan boltzmann law with an emissivity of 0 97 to maintain a sufficient water level local famers pumped 412 and 634 m3 water from a canal into the fishpond during fishpond trials f1 and f2 respectively a sample was collected from the pumped water for isotopic analysis two evaporation pans wmo type e601 with 61 8 cm diameter and type ϕ20 with 20 cm diameter were installed next to the fishpond they were partially buried in the soil to help reduce temperature fluctuations their bottom interiors were painted black to promote absorption of solar radiation and convective mixing of the water column the water surface temperature was measured with an infrared thermometer model si 111 campbell scientific inc water temperature was also measured at 2 cm below the surface model 109 l campbell scientific inc three experimental trials each lasting 13 to 20 days were made with the big pan and six trials each lasting 4 to 10 days were made with the small pan the initial water mass was about 100 kg and the final mass was about 90 kg in the big pan trials the initial and the final mass in the small pan trials were about 3 kg and 2 kg respectively a small sample 5 ml was collected each day for isotopic analysis the evaporation rate was determined daily by measurement of the water level and corrected for the removal of water samples the pans were covered during rain events for the big pan the water surface was 26 73 cm to 31 99 cm below the top edge for the small pan the distance ranged from 1 53 cm to 4 95 cm the craig gordon model calculation requires measurement of the isotopic composition of water vapor this measurement was made in situ with a water vapor isotope analyzer model 911 0004 los gatos research mountain view ca usa located at a distance of 100 m from the fishpond the analyzer inlet was positioned at a height of 9 m above the water surface the analyzer sampling frequency was 1 hz and the data were averaged to 60 min intervals calibration of the vapor isotope measurement was made with a vapor source supplied with working liquid water standards model 908 0003 9002 los gatos research traceable to the vsmow scale the liquid water standards had delta values in the range of 8 7 to 3 0 for δ 18o and 59 4 to 26 2 for δ 2h the calibration was performed at five humidity levels that were adjusted dynamically to bracket the ambient humidity xiao et al 2017 isotopic analysis of liquid water samples including rainwater irrigation water fishpond water and evaporation pan water was made with a liquid water isotope analyzer model dlt 100 los gatos research in the key laboratory of ecosystem network observation and modeling chinese academy of sciences the analyzer was calibrated against 3 working standards traceable to the vsmow scale δ 2h δ 18o 79 6 11 04 49 2 7 81 9 9 2 99 all liquid water samples were sealed and placed in a refrigerator at 4 c before analysis all isotope values are expressed as delta scale δ r sample r vsmow 1 1000 where r is the 2h 1h or 18o 16o ratio and r vsmow are 0 00015576 for 2h 1h and 0 0020052 for 18o 16o the analytical uncertainty of the liquid water isotope measurement is 0 3 for δ 2h and 0 1 for δ 18o and the uncertainty of the vapor isotope measurement after calibration is 2 for δ 2h and 0 2 for δ 18o 2 2 isotope mass balance analysis we used the mass balance equations to obtain the isotopic composition of evaporation δ e and the mean evaporation rate e t for each experimental trial described above the complete expression of mass balance of a water body is 1 i p o s e d v where i is inflow water p is precipitation o is outflow water s is the amount of water sample removed for isotopic analysis e is evaporation water loss and dv is the change of water amount during the experimental period the isotopic mass balance equation is 2 i δ i p δ p o δ o s δ s e δ e d v δ l where δ is isotopic composition of 2h or 18o in delta notation and subscripts i p o s e and l denote inflow precipitation outflow sampled water evaporated water and liquid water in the fishpond or the evaporation pans as defined in table 1 for the evaporation pans inflow and outflow were zero and precipitation input was also zero for the fishpond s was negligible outflow was zero because no drainage occurred during the experimental trials and i was the water input via pumping during f1 and f2 and zero for other trials all the terms in eqs 2 and 3 except e and δ e were measured experimentally the total amount of evaporation e was determined from eq 1 and was converted to evaporation rate e t in units of g m 2 s 1 the isotopic composition of evaporation δ e was determined from eq 2 2 3 experimental determination of the kinetic factor the mass balance approach we combined the δ e obtained from the isotopic mass balance with the craig gordon model craig and gordon 1965 to quantify the kinetic factor for 18o according to the model the hourly isotopic composition of evaporation is given by 3 δ e α e q 1 δ l h δ v ε e q 1 h ε k 1 h 0 001 1 h ε k where h is relative humidity in fraction in reference to the saturated vapor pressure at the water surface δ v is isotopic composition of water vapor δ l is isotopic composition of liquid water in the evaporation pans or the fishpond α eq 1 is the equilibrium fractionation factor ε eq 103 1 1 α eq is the equilibrium factor in delta notation and ε k is isotopic kinetic fractionation factor the prime symbol indicates that the calculated isotopic composition of evaporation is an hourly value to distinguish it from the whole trial mean δ e from eq 2 in eq 3 h and t s were means of two 30 min measurements α eq and ε eq were determined as a function of the water surface temperature δ l was linearly interpolated to hourly intervals from the daily isotope measurement of the liquid sample but ε k is an unknown parameter to be determined by an optimization method described below supplementary figure s1 eq 3 helps to clarify the definition of the kinetic factor used in the present study it is a property intrinsic to atmospheric flow and is not related to the status of atmospheric humidity the total kinetic effect is given by 1 h ε k the bulk aerodynamic method was used to determine a weighting factor for the fishpond trials this method expressed the hourly evaporation rate as 4 e t ρ a c e u q s q a where ρ a is air density c e is the transfer coefficients for moisture u is wind speed and q s and q a are the specific humidity at the surface and at the reference height respectively so the parameter group ρ a u q s q a was used as evaporation flux weighted factor the craig gordon model calculation was upscaled to give the δ e of the whole experimental trial as 5 δ e δ e ρ a u q s q a ρ a u q s q a eq 5 makes the assumption that c e is invariant with time the evaporation flux weighting factor ρ a u q s q a was calculated on an hourly scale this weighting factor is essentially a bulk parameterization for open water evaporation whereby the rate of evaporation is proportional to wind speed and to the vapor concentration difference between the water surface and a reference height in the surface layer the kinetic factor ε k was determined using a numerical optimization method with eqs 3 5 the optimization aimed to achieve a perfect match between δ e calculated from these equations and the δ e determined from the isotopic mass conservation eq 2 the method yielded a solution of ε k the bulk relationship was also used to obtain the evaporation flux weighted factor for the pan experiments supplementary figure s2 however we found that the transfer coefficient showed day to day variations to account for these variations we included a daily correction coefficient c i so the weighting becomes c i ρ a u q s q a the coefficient c i is given by 6 c i e i ρ a u q s q a where e i is the actual daily evaporation amount observed on day i the ε k value was also found through the optimization method with eqs 3 5 except that the weighting factor was calculated with a correction coefficient c i 2 4 experimental determination of the kinetic factor the unified cg model approach the kinetic factor was also determined with the unified cg model of gonfiantini et al 2018 this model combines the cg model with the isotopic mass balance equation into an integral form and predicts δ l as a function of the residual liquid water fraction in this model water temperature humidity vapor isotopic composition and initial δ l are known variables the kinetic effect appears in this model as a tunable turbulence parameter n the n value was determined for each pan experiment by optimizing the model predicted δ l against the observed δ l the goal of the optimization was to minimize the sum of squared errors of δ l all the input variables were flux weighted mean values as described above the relationship between n and r i r or the ratio of the diffusion resistance of the heavier h2 18o molecule r i to that of the lighter h2 16o molecule r is given by 7 r i r d d i n where d and d i denote the molecular diffusivity of major and minor water isotopic species in air respectively the n value ranges between 0 under fully turbulent conditions and 1 if the diffusion is completely molecular the kinetic factor ε k was obtained from the optimized n from the following equation gonfiantini 1986 8 ε k n d d i 1 10 3 the diffusivity ratio d i d is set to the value of 0 9723 for 18o and 0 9755 for 2h merlivat 1978 hellmann and harvey 2020 giving an ε k of 28 4 for 18o and 25 0 for 2h at n 1 in principle the mass balance and the unified cg methods can used to constrain the kinetic factor for 2h to our best knowledge no published studies have used 2h data alone to determine the kinetic factor in outdoor conditions there may be two reasons for this first the 2h fractionation of water evaporation in natural conditions is dominated by the equilibrium effect at 20 c the equilibrium fractionation factor ε eq for 18o is 9 4 which is comparable in magnitude to the kinetic factor but ε eq for 2h 74 3 is an order of magnitude larger the δ 2h of evaporation is not sensitive to the kinetic effect xiao et al 2017 the lack of sensitivity makes it difficult to obtain an accurate estimate of the kinetic factor from the measured δ 2h of evaporation second measurement errors for 2h are generally larger than for 18o in the present study the uncertainty of the liquid water delta is 0 3 for 2h which is three times that for 18o 0 1 the uncertainty of the vapor delta is 10 times larger for 2h 2 than for 18o 0 2 in the following we only report the result on the turbulent parameter n using the 18o data although the 2h data was not used for the determination of n it was included in the evaluation of the relationship between the lel slope and kinetic fractionation section 4 3 3 results table 2 summarizes the mean environmental conditions for all the experimental trials the experiments were conducted in warm seasons with the water temperature ranging from 14 7 c to 40 7 c the wind speed during these times ranged from 1 21 m s 1 to 2 86 m s 1 the δ v varied in the range of 126 9 to 78 9 for 2h and 20 6 to 11 2 for 18o which are typical of the warm season values in eastern china wen et al 2008 xiao et al 2017 the initial δ l of the pan experiments was on average 41 7 for 2h and 6 2 for 18o which is lower than that of the fishpond water average 19 3 for 2h and 1 5 for 18o the relative humidity referenced to the water surface temperature varied in a range of 0 37 to 0 62 figure 1 provides an example of hourly time series of the driving variables panels a b and d of the craig gordon model and time series of the model calculated hourly δ 18o values of evaporating vapor δ e for experiment s2 the δ e result shown here is given with the optimized ε k of 6 01 for 18o the δ 18o value of the pan water δ l was continuously enriched over time as a result δ e increased progressively from the initial value of 20 1 to 13 1 at the end of the experiment the relative humidity h showed strong diurnal variations which mirrored the variations in the water surface temperature t s resulting in lower δ e at night than during the day the daytime observations were weighted much more heavily than the nighttime values panel e with the optimized ε k the flux weighted mean isotopic composition of evaporation was 17 0 matching exactly the δ e obtained from the isotopic mass balance calculation figure 2 is an example showing the application of the unified cg model to experiment s1 the optimization yielded the best estimate of 0 25 for n according to eq 8 the best estimate of ε k for this experiment is 7 10 figure 3 compares ε k value obtained with isotopic mass balance that from the unified cg model in general the ε k value from isotopic mass balance agrees very well with the ε k value from the unified cg model if the unified cg used flux weighted mean values for its input variables black squares linear correlation r 0 99 confidence level p 0 001 in the following unless stated otherwise we will restrict our analysis to the isotopic mass balance data the results of all the experimental trials are summarized in table 3 here the 18o δ e value was obtained from optimizing the craig gordon model calculation against the δ e from the isotopic mass balance and the turbulence parameter n was obtained from eq 8 the δ e shows a large range of variation with the lowest value 31 8 observed in experiment trial b3 with the big evaporation pan and highest value 7 3 during f4 with the fishpond the experimental trial s6 with the small pan experienced similar environmental conditions as trial b3 as they took place at about the same time table 2 but the δ e of s6 was much higher 13 1 a significant and negative correlation was found between δ e 18o and ε k linear correlation r 0 69 p 0 01 confirming that a stronger kinetic effect will cause more depletion of 18o in the evaporated water the correlation between δ e and other variables shown in table 2 was not significant a multivariate stepwise regression reveals that ε k ε eq δ l and δ v could explain 99 of the δ e variations shown in table 2 and that flux weighted relative humidity was excluded by the stepwise procedure the kinetic factor ε k varied in a broad range from 2 40 experimental trial s4 to 22 10 experimental trial b3 indicating a varying role of turbulence in the kinetic fractionation among these experiments the kinetic factor showed a strong negative correlation with the water to air temperature difference t s t a r 0 67 p 0 01 fig 4 additionally ε k was negatively correlated with water surface temperature t s r 0 67 p 0 01 and the mean evaporation rate e t r 0 76 p 0 01 however t s and e t were both positively correlated with t s t a r 0 68 for t s and r 0 75 for e t p 0 01 the most logical explanation for these correlations is that t s t a exerted direct control on ε k and the correlation of ε k with t s or e t arose from their covariations with t s t a the mean kinetic factor measured in this study was 7 0 3 1 with the small evaporation pan 14 3 6 8 with the big evaporation pan and 10 2 4 9 with the fishpond if we excluded b3 section 3 1 the mean value for the big evaporation pan 10 4 was in better agreement with that obtained with the small evaporation pan these values agreed better with the os value of 8 1 calculated for the mean wind conditions during this study than with the default lake value of 14 2 fig 5 the mean ε k values from the pan experiments was 9 44 5 54 mean one standard deviation according to the imb calculation and 9 34 6 60 according to the unified cg model a two tailed student t test shows that there was no significant difference between the results p 0 97 t 0 04 the rmse of two sets of ε k values was 1 27 4 discussion 4 1 uncertainty analysis we performed monte carlo simulations to quantify uncertainties in the calculated ε k uncertainties in input variables are provided in supplementary table s1 errors in these variables were assumed to follow normal distributions and to be independent of each other a total of 10 000 ensemble members were used for each evaporation experiment with each member producing an ε k value the uncertainty in ε k was calculated as ½ of the difference between the 75th and the 25th percentile value of the ensemble these ε k uncertainties are smaller than the physical range of variations shown in table 3 and fig 4 in the case of the mass balance approach uncertainties in both the δ e mass balance measurement and the cg calculation contributed to the uncertainty in the determination of ε k as shown in fig 6 for experiment s1 in this figure the solid sloped line represents the δ e as a function of ε k calculated with the cg model using the measured input parameters and the solid horizontal line represents the δ e value of 18 0 from the isotopic mass balance table 3 the intercept of these two lines gives the actual ε k 7 73 table 3 for experiment s1 assuming no uncertainty in either the mass balance or the cg model calculation however both the δ e measurement and cg model calculation carried uncertainties shown as the range between the paired dashed lines in fig 6 the overall uncertainty in ε k was 0 3 according to the monte carlo analysis similar ε k uncertainty estimates were obtained for the mass balance approach applied to the other pan experiments the ε k estimates for the fishpond experiments using the isotopic mass balance method had an uncertainty of about 1 5 this larger uncertainty stemmed primarily from the uncertainty in the δ e determination uncertainty of about 1 6 which is larger than the δ e uncertainty of 0 27 for the pan experiment s1 shown in fig 6 because the mass balance calculation involved more input variables than for the pan experiments and because these additional variables were more uncertain than the other variables supplementary table s1 in contrast the ε k uncertainty from the unified cg model was 5 to 10 times smaller than the uncertainty for the pan experiments from the isotopic mass balance method indicating robustness of the unified cg model there are two reasons for this first the unified cg model was constrained by the isotopic composition of the liquid water δ l which is more accurate than δ e table s1 second multiple δ l measurements were used in the optimization procedure fig 2 and s3 further reducing the uncertainty in the ε k estimation 4 2 comparison of pan experimental data numerous outdoor pan experiments have been reported in the literature the majority of these experiments aim to quantify the rate of liquid water evaporation some have been used to determine the isotopic composition of evaporation by adopting the traditional values of ε k 14 2 for 18o and 12 5 for 2h e g crawford et al 2019 devi et al 2015 skrzypek et al 2015 according to the survey by gonfiantini et al 2018 two pan experiments have been conducted in the past to investigate kinetic isotopic fractionation of evaporation in natural conditions the first one was carried out by craig et al 1963 on the roof of a laboratory building in la jolla california for a duration of 16 days the second one was carried out in an open field by skrzypek et al 2015 in western australia for a duration of 12 16 days recently gonfiantini et al 2018 used the unified cg model to constrain the turbulent parameter n with the data from these experiments because the isotopic ratio of water vapor was not measured fontes and gonfiantini 1967 gonfiantini et al 2018 approximated vapor delta with the value in equilibrium with local precipitation this approximation is somewhat arbitrary because precipitation events were rare however its impact on δ e is rather limited due to the low air humidity in addition algebraic mean values were used for other input variables of the model the resulting n is 0 5 ε k 14 2 for 18o for craig s experiment and 0 4 ε k 11 36 for 18o for skrzypek s experiment in their original study skrzypek et al 2015 used the traditional value of 14 2 for ε k the current study was inspired by the work of these authors the iris instrument brought two improvements to the pan experimental method first the vapor isotopic composition was directly measured so the equilibrium approximation was no longer needed second instead of simple algebraic averaging flux weighted mean values for input variables h ε eq and δ v were used in the unified cg model calculation in order to account for the fact that environmental conditions during times of higher evaporation exert a stronger influence on the cumulative fractionation of the evaporating water with these improvements the ε k from the unified cg model was in excellent agreement with that obtained from isotopic mass balance with a small root mean square error rmse of 1 27 solid symbols fig 3 if simple algebraic means of the forcing variables were used for the unified cg calculation the rmse became larger at 2 55 open symbols fig 3 the unified cg model was also sensitive to how the vapor delta was obtained the amount weighted isotopic composition of precipitation during the 2017 experimental season may to november was 3 38 18o if the vapor delta value in equilibrium with the local precipitation was used instead of the observed value the ε k could deviate significantly from that obtained with the isotopic mass balance method giving a large overall rmse of 4 23 grey symbols fig 3 our experimental study seems to be the first to provide direct evidence for the role of turbulence in kinetic fractionation in outdoor conditions fig 4 since t s t a drives convective turbulence in the atmospheric surface layer fig 4 confirms that atmospheric turbulence weakens the kinetic fractionation of water evaporation we found that ε k was weakly correlated with humidity h r 0 34 p 0 23 and friction velocity u r 0 32 p 0 26 the latter of which is a measure of mechanic turbulence a stepwise linear regression using t s t a h and u as predictors reveals that ε k was only independently related to t s t a suggesting that convective turbulence played a more dominant role than mechanic turbulence in controlling the kinetic effect during our experimental trials the extremely high ε k of 22 1 from experiment b3 occurred at a very low water to air temperature gradient 0 25 c fig 4 the corresponding turbulence parameter n is 0 78 indicating that the level of turbulence during this experiment was almost negligible this n value is higher than those reported for the outdoor pan evaporation experiments carried out by craig et al 1963 n 0 50 and skrzypek et al 2015 n 0 40 and even higher than most of the evaporation experiments conducted in controlled conditions for example cappa et al 2003 reported that n ranges from 0 36 to 0 44 using small evaporation dishes housed in a dynamic chamber using a similar flow through evaporation chamber setup kim and lee 2011 reported n values of 0 55 to 0 75 of the 29 laboratory and natural experiments analyzed by gonfiantini et al 2018 only six have n 0 78 and all the exceptions involve a setup where water vaporizes into quiescent air or involving a special gas it appears that conditions during experiment b3 were anomalous for these reasons the high ε k value from experiment b3 has been excluded from the mean value in fig 5 and table 4 4 3 relationship between the lel slope and kinetic fractionation a well known consequence of kinetic fractionation is the deviation of the local evaporation line lel from the global mean meteorite water line gmwl the lel is formed in a scatter plot between the hydrogen and oxygen isotope compositions of the evaporating water compared to the gmwl slope of 8 the lel has a smaller slope value because the lel preserves the cumulative influence of water evaporation it is often used to help infer local hydrological conditions during the evaporation season gibson et al 2008 approximated the local precipitation isotope value with the intercept of the observed lel and the gmwl gibson et al 2005 used the deviation of the lel from the gmwl in their model to determine the watershed evaporation to inflow ratio skrzypek et al 2015 estimated the water vapor isotope delta using the isotope composition of rainfall and the slope of lel wassenaar et al 2011 used the lel slope to determine relative humidity which is a parameter required for computing the evaporation to inflow ratio the analysis of an isotope dataset collected at a peatland stream network suggests that the lel slope is indicative of potential evaporation sprenger et al 2017 these applications generally use the default lake kinetic factor of 14 2 for 18o the observed lel slope is given in table 3 here the lel slope was the slope of linear regression of the δ 2h value against the δ 18o value of the pan water the kinetic factor itself was poorly correlated with the slope r 0 05 the correlation between 1 h ε k and the slope was also weak r 0 02 we deployed two predictive models to further examine the relationship of the lel slope to kinetic fractionation the first model model 1 is given by 9 s l e l ε e q 1 h ε k 2 ε e q 1 h ε k 18 where subscript 2 and 18 denote 2h and 18o respectively gat 2010 brooks et al 2014 this model assumes that the evaporating water and the atmospheric vapor are in isotopic equilibrium and consequently only equilibrium fractionation and kinetic fractionation control the lel slope the second model model 2 takes a more general form gibson et al 2008 10 s l e l h δ v δ l 0 1 10 3 δ l 0 1 h ε k α e q 1 ε e q 10 3 h 1 h ε k α e q 1 ε e q 2 h δ v δ l 0 1 10 3 δ l 0 1 h ε k α e q 1 ε e q 10 3 h 1 h ε k α e q 1 ε e q 18 this model applies to situations where the evaporating water comes from local precipitation and no isotopic equilibrium is assumed here the δ p in the original model was replaced by the isotopic composition of the liquid water at the start of the pan experiment δ l 0 the model calculations were repeated three times using three sets of kinetic factors and were compared with the observed lel slope fig 7 the first set solid symbols fig 7 used the 18o ε k determined by isotopic mass balance imb table 3 and the 2h ε k obtained with eq 8 and the imb n value in table 3 the second set open symbols fig 7 used the lake default ε k of 14 2 for 18o and 12 5 for 2h the third set grey symbols fig 7 deployed the imb ε k for 18o and the lake default value for 2h the fishpond experiments were excluded from this analysis because the range of the observed liquid water isotopic composition was too small during each experimental period 0 7 for 18o and the resulting lel slope was too uncertain both models were sensitive to how the kinetic factors were specified using the measured ε k values the modeled lel slope was 5 52 0 56 mean 1 standard deviation according to model 1 and 4 75 0 98 according to model 2 using the default lake ε k values the modeled slope was reduced to 4 71 0 45 according to model 1 and 3 89 0 58 according to model 2 the sensitivity arose mostly from changes in the kinetic factor for 18o by changing the 2h kinetic factor to the default lake value but keeping the measured value for 18o the modeled slope only changed slightly to 5 72 0 75 and 5 09 1 26 according to model 1 and model 2 respectively using the default lake ε k values xiao et al 2017 found that the δ e calculated by the craig gordon model falls on a lel with a slope of about 3 2 for lake taihu which is lower than the observed slope of 6 33 by switching to the lower os kinetic factors their calculated δ e falls on the observed lel the lel slope predicted by model 2 broadly agreed with the observed value mean bias 0 15 rmse 1 04 but the slope predicted by model 1 was biased high and was more scattered mean bias 0 59 rmse 1 25 gibson et al 2008 found that model 2 can reproduce the observed lel slope for lakes in the world the superior performance of model 2 over model 1 implies that although the kinetic effect plays an important role in determining the lel slope other factors such as the isotopic compositions of water vapor and local water input can also influence the slope value 4 4 dependence of kinetic factor on lake size table 4 provides a summary of the kinetic factors for 18o obtained in natural conditions they include three values from this study four values found in the published literature and two additional values we determined with local hydrological data reported by other authors a range of methods were used to obtain these values including isotopic mass balance small pan big pan fishpond the unified craig gordon model evap pan g evap pan s and lake gara gradient diffusion lake taihu and simplified isotopic mass balance for terminal lakes lake waid and lake burdur appendix a here the ε k value for lake taihu was obtained by tuning it so the craig gordon model prediction matches the δ e determined with the gradient diffusion method and was slightly higher than that given by xiao et al 2017 using the wind parameterization of merlivat and jouzel 1979 the survey results are separated into two size classes according to this survey there is no significant relationship between ε k and lake size the mean ε k 18o value 9 64 2 80 for the small class is not significantly different from the mean value 10 10 2 60 for the large class p 0 85 t 0 20 two tailed student t test the overall mean ε k is 9 74 2 60 for 18o based on the 9 values in table 4 the corresponding turbulent parameter n is 0 34 combining this n value with eq 8 yields a mean kinetic factor of 8 5 for 2h the insignificant difference in ε k between the two size classes is based on a small data sample more field research is needed to further evaluate this relationship there are however reasons to believe that the insensitivity of ε k to lake size may hold broadly for globe lakes this is because wind speed and the thermal gradient in the surface layer air have opposite relationships with lake size the longer fetch at a larger lake allows wind speed to build up which will reduce ε k according to the os parameterization of merlivat and jouzel 1979 in a modeling study of heat diffusion between the lake and the atmosphere hondzo and stefan 1993 parameterized wind speed as a proportion to lake area increasing by about 50 from a size of 0 01 km2 to a size of 100 km2 on the other hand the water air temperature difference t s t a should decrease with increasing lake size which will result in an increase in ε k according to fig 4 and may cancel out part or all of the decrease in ε k due to the wind effect large lakes are generally deeper than small lakes cael et al 2017 and do not warm up as fast in the evaporation season they also tend to have lower dissolved organic carbon concentrations hanson et al 2007 allowing sunlight to penetrate deeper in the water and leading to lower surface temperature than small lakes the inverse relationship between t s t a and lake size is supported by the meta analysis of thermal conditions of global lakes showing that the occurrence frequency of unstable stratification in the surface layer air woolway et al 2017 and the diel air temperature range woolway et al 2016 are negatively correlated with lake size oswald and rouse 2004 provided a numerical example on the opposing effects of lake size on wind speed and on the temperature gradient they showed that skeeter lake a small lake area 0 05 km2 in northwest territories canada displayed a larger t s t a 4 5 c but lower wind speed 2 8 m s 1 than sleepy dragon lake a large lake area 5 5 km2 in the same region t s t a of 2 5 c wind speed of 4 2 m s 1 during an ice free season 5 conclusions the kinetic factor ε k for 18o varied in the range of 2 40 to 22 10 during our experiments the mean value was 9 70 with all the data included and 8 75 with the b3 outlier excluded we showed that ε k decreased linearly with increasing lake surface to air temperature gradient the novelty of this finding interpreted together with the classic parameterization of ε k as a function of wind speed merlivat and jouzel 1979 is that the role of turbulence in kinetic fractionation manifests in both mechanic turbulence as measured by wind speed and convective turbulence as measured by the temperature gradient although the measured ε k showed poor correlation with the slope of the lel local evaporation line it greatly improved the performance of the lel model of gibson et al 2008 supporting the robustness of our isotopic mass balance method and indicating that in addition to the kinetic effect the isotopic compositions of water vapor and local water input can also influence the lel slope the ε k data reported here and those found in the literature do not support the hypothesis that ε k decreases with increasing lake size the lack of sensitivity to lake size may be a result of opposing effects of lake size on wind speed and on the lake to air temperature gradient the overall mean ε k was 9 7 for 18o and 8 5 for 2h based on ten outdoor experimental results covering a size range from 0 13 m2 to 2400 km2 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national key r d program of china grant 2019yfa0607202 to wx and the national natural science foundation of china grants 41975143 41475141 41830860 and 42021004 to wx and mz appendix a kinetic fractionation of terminal lakes terminal lakes are lakes that do not have surface outflows in the special case where groundwater contribution and seepage are negligible the water input inflow plus precipitation is balanced by evaporation loss and the isotopic value of the input water is balanced by that of evaporation under these conditions poulin et al 2019 have derived an expression for the lake water isotopic value from isotopic mass balance manipulating their eq 7 we obtain an equation for the kinetic factor as a 1 ε k α e q 1 δ l h δ v ε e q 1 h δ i 1 h 10 3 δ i 1 eq a 1 was used to estimate the 18o kinetic factor for lake waid zimmermann 1979 zuber 1983 and lake burdur dincer 1968 zuber 1983 the input variables are summarized as follows lake waid germany δ l 2 19 δ i 7 91 δ v 17 4 t w 11 1 c water temperature t a 10 55 c air temperature h 0 69 in reference to water temperature lake burdur turkey δ i 8 9 δ l 0 3 table 4 of dincer 1968 t l 12 9 c h 0 59 δ v 19 0 on the assumption that it is in equilibrium with δ i δ p at temperature of 12 9 c appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126974 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
4042,how to improve the performance of runoff predictions in ungauged basins pub is challenging recently the long short term memory lstm based models have excellent performance and receive many attentions in this paper to improve the performance for 1 day ahead runoff pub and provide good performance for multi day ahead runoff pub we propose four sequence to sequence s2s models to deal with pub furthermore we introduce two modules named attribute weighting module and multi head attention module for improving the performance to show the power of these s2s models and the advantages of those two modules we test our four s2s models and also three benchmark models including a pub lstm model and two process driven models by using k fold validation on 531 basins of the catchment attributes and meteorology for large sample studies camels dataset for 1 day ahead runoff pub the median and the mean of nash sutcliffe efficiency for the 531 basins provided by our best model achieve 0 78 and 0 70 respectively while those provided by the pub lstm model the best one among those three benchmark models are 0 69 and 0 54 respectively besides our s2s models have promising results for multi day ahead runoff pub for 7 th day ahead runoff pub the median and the mean of nash sutcliffe efficiency for the 531 basins provided by our best model are 0 68 and 0 57 respectively furthermore the results also show that the two modules are beneficial for improving the performance keywords rainfall runoff modeling lstm sequence to sequence models ungauged basins 1 introduction models for runoff predictions can be generally divided into three sorts process driven models fidal and kjeldsen 2020 huo et al 2020 jadidoleslam et al 2019 mathevet et al 2020 data driven models kratzert et al 2019b tikhamarine et al 2020 zuo et al 2020 yin et al 2020 and hybrid models okkan et al 2021 they have different characteristics and the lstm based models show their promising performance recently kratzert et al 2018 investigated the potential of lstm for runoff predictions on 241 basins of the camels dataset with meteorological time series observations and showed that their lstm based models can achieve good performance ni et al 2020 developed two lstm based hybrid models and showed that lstm was applicable for time series prediction and their two hybrid models were better kao et al 2020 proposed a feed forward neural network based encoder decoder model and a lstm based one to predict multi step ahead flood these two models show good multi step ahead forecasts and the lstm based one can provide more reliable and accurate flood forecasts xiang et al 2020 proposed a lstm sequence to sequence rainfall runoff model tested the performance on five stations in two watersheds and showed that its performance is better than all other machine learning benchmark models kao et al 2021 proposed a hybrid of the stacked autoencoder with a recurrent neural network which can provide accurate and timely information to support emergency management in areas impacted by flood hazards gao et al 2020 applied three models including lstm gated recurrent unit gru and artificial neural network to simulate runoff in the yutan station control catchment and showed that lstm and gru have better performance furthermore they also mentioned that gru was preferred because of its simple structure barzegar et al 2021 proposed boundary corrected maximal overlap discrete wavelet transform preprocessing method coupled with convolutional neural network lstm deep learning and machine learning models for multi step lake water level forecasting khosravi et al 2020 developed a flood susceptibility map for iran by using a deep learning convolutional neural networks algorithm which is one of the most powerful algorithms in big data sets salloom et al 2021 handled water demand forecasting by using a deep neural network architecture based on the gated recurrent unit and the k means which can achieve promising performance with low cost of complexity in practice we often need to deal with the cases of runoff predictions in ungauged basins pub which is still a challenge and very important task to study sivapalan et al 2003 presented a summary of the science and implementation plan of pub with a call to the hydrological community to participate actively in the realization of several goals montanari et al 2013 mentioned that researches on pub received a lot of attentions and thus developed well bloschl et al 2019 pointed out that pub is still one of twenty three unsolved problems in hydrology in recent years more and more attentions are focusing on pub atieh et al 2015 desai and ouarda 2021 du et al 2020 grimaldi et al 2020 jafarzadegan and moradkhani 2020 milukow et al 2019 rezende de souza et al 2021 swain and patra 2017 tegegne and kim 2018 teutschbein et al 2018 zhang et al 2015 grimaldi et al 2020 applied a continuous model specifically designed for ungauged basins and tested its performance in certain conditions rezende de souza et al 2021 demonstrated the adequate applicability of regionalization in ungauged watersheds and promoted sustainable flood risk management by providing an alternative for maximum streamflow estimates tegegne and kim 2018 presented a new regionalization methodology named catchment runoff response similarity to reduce the uncertainty of runoff predictions in ungauged catchments and addressed the problem of key attributes identification jafarzadegan and moradkhani 2020 applied a generic regionalization framework for the regionalization of stage discharge rating curves in the arkansas white red region gauch et al 2021 showed that tree based models and lstm based models have similarly accurate predictions on small datasets while lstms are better on big datasets prieto et al 2019 handled the pub problem by exploiting advances in flow index selection and regionalization in bayesian inference and further developed novel model performance tests in ungauged catchments kratzert et al 2019a trained several lstm based models and then tested them on the camels dataset using k fold validation and the results showed the power of lstm based models compared with several benchmark models in this paper we focus on pub and have the following considerations first we proposed a lstm based sequence to sequence model with multi state vector named lstm msv s2s in yin et al 2021 which achieves excellent performance in camels dataset in that paper we trained each model for each basin and used five meteorological forcings including precipitation shortwave downward radiation vapour pressure daily maximum temperature and daily minimum temperature as inputs for pub besides those five meteorological forcings we use static catchment attributes we want to focus on more important attributes and thus propose an attribute weighting module second soft attention mechanisms can pay more attentions to more important areas of a whole input sequence rather than a fixed element or area recently soft attention mechanisms have shown promising performance in many tasks such as sarcasm detection jain et al 2020 human trajectory prediction fernando et al 2018 and visual question answering liu et al 2019 since a soft attention mechanism is beneficial for achieving better results we apply it to pub based on the above considerations we propose a novel attribute weighting multi head attention seq2seq model based on lstm lstm awma s2s for pub along with two models named lstm based attribute weighting seq2seq lstm aw s2s and lstm based multi ahead attention seq2seq lstm ma s2s based on the above two considerations respectively we summarize the contributions of this paper as follows first four s2s models are proposed for pub second we compare our s2s models with three benchmarks on 531 basins in camels dataset and our s2s models outperform the benchmarks for 1 day ahead runoff pub significantly and also can provide good performance for multi day ahead runoff pub third two added modules including an aw module and a ma module are beneficial for improving the performance we organize this paper as follows section 2 discusses our four s2s models we introduce the camels dataset in section 3 section 4 provides results and discussions we conclude this paper in section 5 2 methods we introduce our lstm msv s2s yin et al 2021 first and then propose the lstm awma s2s these models are related to the lstm network since the lstm network has been clearly described in detail in many papers e g kratzert et al 2018 we do not introduce it here 2 1 lstm msv s2s model here the structure of the lstm msv s2s model is illustrated in fig 1 this model has two encoders m context vectors and a decoder the first encoder contains n m lstm cells with both meteorological forcings and static catchment attributes as inputs the second encoder contains n lstm cells with runoff observations as inputs the m context vectors contain information from these encoders the decoder with m lstm cells outputs m step aheadrunoff predicted values the lstm msv s2s assigns the attributes the same weights usually different attributes affect the results differently since they are not the same important this kind of importance or weights can be learned by adding an attribute weighting module furthermore by using m context vectors the lstm msv s2s follows the case in practice the meteorological forcing data after the jth day do not influence the jth day runoff however it pays attention to a fixed element as mentioned soft attention mechanisms can pay more attentions to a specific area or important areas of the input sequence rather than a fixed element hence we add a multi head attention module consisting of many soft attentions which not only can follow the causality as the lstm msv s2s does but also can pay more attentions to a specific area rather than a fixed element 2 2 lstm aw s2s lstm ma s2s and lstm awma s2s model the architectures of lstm aw s2s lstm ma s2s and lstm awma s2s are shown in fig 2 fig 3 and fig 4 respectively compared with the lstm msv s2s the lstm aw s2s adds an attribute weighting aw module providing attributes different weights by learning from the training set the aw module i e the attribute weighting part in fig 2 or fig 4 consists of n m vectors corresponding to n m lstm cells inputs of n m days the elements of each vector are the weights obtained by the softmax operation corresponding to the input the attributes for one lstm cell compared with the lstm msv s2s the lstm ma s2s adds a multi ahead attention ma module the ma module follows the case in practice that the meteorological forcing data after the jth day do not influence the jth day runoff and focuses on the area or the time series not after the jth day for predicting the jth day runoff the ma module contains 8 parallel soft attention layers heads the outputs of these 8 heads are concatenated and then a linear transformation is operated on it note that for showing how the proposed lstm awma s2s works more clearly fig 4 illustrates the ith day ahead runoff pub and the pseudocode is presented in algorithm 1 accordingly actually the lstm ma s2s and the lstm awma s2s are proposed for m day ahead runoff pub that is the outputs of their decoders can predict m day ahead runoff values furthermore besides the ma module the structure of the lstm ma s2s model differs from that of the lstm msv s2s by a encoding the runoff observations into the decoder directly rather than using another encoder and b using a feedback mechanism the orange line in fig 3 this feedback element contains the information from the past time and the information through the ma module compared with the lstm ma s2s the lstm awma s2s adds an aw module that is these two models are the same expect for the aw module here since the lstm msv s2s was proposed in our previous study yin et al 2021 we point out the difference between that study and this paper as follows first this paper handles pub problem while that previous study handled runoff predictions in each individual basin that is the two papers deal with different problems second in this paper although the lstm msv s2s was introduced to handle pub problem we propose three novel s2s models i e lstm aw s2s lstm ma s2s and lstm awma s2s by using two modules i e aw module and ma module and a feedback mechanism in our opinion these two modules and the feedback mechanism are proposed in handling such a problem for the first time third the experiments between that study and this paper are totally different in this paper the training and testing process are done by using k fold validation for pub see section 3 2 in that previous study we trained and tested one lstm msv s2s model for one basin fourth the previous study focused on the lstm msv s2s and the results showed its advantages on runoff predictions for in basin cases in this paper we focus on the three proposed s2s models i e lstm aw s2s lstm ma s2s and lstm awma s2s and want to show their power in pub and also the effects of those two modules i e aw module and ma module and the feedback mechanism see section 4 algorithm 1 pseudocode of lstm awma s2s input x x 1 x n m y y 1 y n output y hyper parameters m 7 default predicting days n 15 default known days h 8 default number of heads parameters except lstm w y b y w c w s w o b o w q 1 w k 1 w v 1 w q h w k h w v h 1 initialize y 2 h 1 h n m s hidden s cell lstm x 1 x n m 0 0 3 s 1 s n t w y y 1 y n t b y 4 for i 1 to m do 5 z 1 z n i 1 s hidden s cell lstm s 1 s n s n 1 s n i 1 s hidden s cell 6 for j 1 to h do parallel loop 7 q n i 1 w q j z n i 1 8 k n i w k j h 1 h n i 9 v n i w v j h 1 h n i 10 attn value n i j softmax q n i 1 k n i t d k v n i d k means dimension of k n i 11 v n i w c concat attn value n i 1 attn value n i h 12 s n i w s concat v n i z n i 1 13 y n i w o s n i b o 14 end for 15 y append y n i 16 end for 17 return y 2 3 benchmarks evaluation measures we employ three benchmarks the pub lstm kratzert et al 2019a a lumped conceptual model named sacramento soil moisture accounting model sac sma calibrated in gauged basins newman et al 2015 and a distributed process based model named the u s national water model nwm salas et al 2018 to be fair we did not run any of these benchmarks and the results are obtained by other research groups that is these existing model runs are used so as not to favor our proposed models the results from these three benchmarks can be found in kratzert et al 2019a for evaluation of the models we apply a popular performance metric the nash sutcliffe efficiency nse along with four statistics of the nses including the median the mean the number of basins with nse 0 and the cumulative distribution functions cdf the nse is defined as 1 nse 1 i 1 n y i y i 2 i 1 n y i y 2 where y i is the observed value at time i y i is the prediction y refers to the average of n observations 3 dataset and experimental setup 3 1 camels dateset the dataset used here is the camels dataset addor et al 2017 newman et al 2015 having 671 basins in the united states this dataset has many differently complex catchments and thus different models can be evaluated generally and statistically the camels dataset contains meteorological forcings static catchment attributes and observed runoff values on each basin at the daily timescale from october 1 1980 to december 31 2014 the meteorological data used in this paper are calculated from the national land data assimilation system nldas data xia et al 2012 these data can be available freely at https ral ucar edu solutions products camels newman et al 2014 the static catchment attributes are about soils climate vegetation topography geology and so on they are introduced in detail in addor et al 2017 2018 and we list the meteorological forcings and static catchment attributes in table 1 for convenience in this study we choose 531 of 671 basins from the camels dataset which are the same basins that were used by newman et al 2017 and kratzert et al 2019a furthermore we use the 5 daily meteorological forcings from nldas and the same 27 static catchment attributes used by kratzert et al 2019a for a fair comparison 3 2 experimental setup and model settings the lstm msv s2s and the lstm aw s2s have two encoders and one decoder where the inputs of one encoder contain 5 meteorological forcings and 27 catchment characteristics and those of the other encoder are runoff observations the decoder outputs 7 day ahead runoff predicted values the lstm ma s2s and the lstm awma s2s have one encoder and one decoder where the inputs of the encoder contain 5 meteorological forcings and 27 catchment characteristics the decoder outputs 7 day ahead runoff predicted values in this paper we use the same meteorological forcings and catchment characteristics as those were used in kratzert et al 2019a we use the data from 1981 to 1995 water years to train the models and test them using the data from 1996 to 2010 water years the training and testing process are done by using k fold validation as follows first the 531 basins are randomly split into 12 groups with approximately equal size second all basins from 11 groups are used to train the model third we test the model on the rest single group without training this procedure is repeated 12 times to guarantee that all basins are tested for pub we test the following four s2s models including the lstm msv s2s in yin et al 2021 the lstm aw s2s the lstm ma s2s and the lstm awma s2s the purposes are threefold first we want to show the power of s2s models for pub compared with the benchmark models the proposed s2s models not only can improve the 1 day ahead pub significantly but also can provide good performance for multi day ahead pub second the aw module is beneficial for improving the performance because it can learn the appropriate weights of attributes from the training dataset third the ma module is also beneficial for pub because it focuses on the area or the time series rather than a fixed point the parameters of the above proposed models are set as follows for the encoder having 21 lstm units each lstm unit has one input vector with 32 dimensions the hidden state length of this encoder is set as 256 for the encoder having 15 lstm units each lstm unit has one input vector with 1 dimension i e runoff observed values the hidden state length of this encoder is set as 128 we apply z score normalization method to normalize all inputs the hidden state length of the decoder sequence is set as 256 the dropout rate and the batchsize are set as 0 3 and 2048 respectively here the loss function is the average nse over all training basins proposed by kratzert et al 2019b and also used in kratzert et al 2019a for a lstm unit the cell state and the hidden state are related to the long memory and the short memory respectively these two states vectors have the same length the hidden state length is the dimension of hidden state which is an important hyper parameter of a lstm unit the dimension of input vector and that of the hidden state determine the shapes of those learnable parameters once the length or the dimension of the hidden state and that of the input vector are given the shapes of learnable parameters are determined the hidden state length and other hyper parameters can be determined by using the hyper parameter optimization or named hyper parameter search although the hyper parameter search is beneficial for obtaining a better model that can achieve better performance in this paper we do not apply it for our model but use almost the same hyper parameters as kratzert et al 2019a for a more fair comparison the model proposed by kratzert et al 2019a is an important benchmark model in this paper which performs best among the benchmark models 4 results and discussion we evaluate the performance of seven models i e four s2s models and three benchmarks by four statistics of the nses including the median the mean the number of basins with nse 0 and the cdf the results of first three statistics are shown in table 2 the cdfs are shown in fig 5 and fig 6 4 1 the power of s2s models the median and the mean of nses show that our four s2s models outperform those three benchmark models significantly for 1 day ahead runoff pub in general the nse cdfs in fig 5 of the 7 models for 1 day ahead runoff pub on 531 basins also indicate that our four s2s models can improve the performance for 1 day ahead runoff pub significantly in general in other words the s2s models show their power when they are applied for 1 day ahead runoff pub compared with those three benchmark models including two process driven models and a data driven model in fig 6 we compare the nse cdfs of lstm awma s2s for 7 day ahead pub with the nse cdfs of three benchmark models for 1 day ahead pub the results in fig 6 show that our lstm awma s2s has better performance for 4 day ahead pub than pub lstm for 1 day ahead pub and has comparable performance for 5 6 7 th day ahead pub to pub lstm for 1 day ahead pub the median and the mean of nses in table 2 also indicate a similar advantage of our proposed lstm awma s2s the median and the mean of nses of our lstm awma s2s for 4 day ahead pub are larger than those of three benchmarks for 1 day ahead pub our lstm awma s2s has larger median and mean of nses for 5 6 7 th day ahead pub compared with two process based benchmarks and has comparable median and mean of nses for 5 6 7 th day ahead pub compared with pub lstm besides the three benchmark models kratzert et al 2019b kratzert et al 2019a proposed a global lstm with static features which uses both meteorological forcings and static catchment characteristics as inputs trained on all catchments simultaneously without k fold validation this global lstm model is an upper bound of the pub lstm model the median and the mean of nses provided by the global lstm model are 0 74 and 0 68 respectively we can see that the lstm aw s2s the lstm ma s2s and the lstm awsa s2soutperform the global lstm model it further indicates the power of our proposed s2s models besides 1 day ahead runoff pub our s2s models give promising results for multi day ahead runoff pub for a further comparison we would like to see how many basins that the s2s models can beat the benchmark models for 1 day ahead runoff pub that is we compare the nse of s2s models with that of the benchmarks on all basins the results are shown in table 3 the lstm awma s2s has a higher nse than the sac sma model in 417 of 531 79 basins the nwm model in 467 of 531 88 basins and the pub lstm model in 409 of 531 77 basins respectively the above results show the power of our proposed s2s models for pub here we summarize them briefly as follows first for 1 day ahead pub our s2s models outperform the benchmarks and improve the performance significantly as shown by the median and the mean of nses in table 2 and the nse cdfs in fig 5 second the comparisons in table 2 and fig 6 between our model for 7 day ahead pub and the benchmarks for 1 day ahead pub indicate that the performance of our lstm awma s2s for 7 day ahead pub is better or at least comparable with benchmark models for 1 day ahead pub third compared with a global lstm trained in basin without k fold validation i e an upper bound of the pub lstm our three s2s models trained out of sample for pub have better performance fourth the comparisons between nses of s2s models with those of the benchmarks on all basins are provided to further show the power of our s2s models for pub based on the above comparisons and results we have the following three points first the proposed s2s models have more power compared with the benchmark models for 1 day ahead runoff pub besides they can provide promising multi day ahead runoff predictions second the proposed s2s models have higher nses than those two process driven models in most basins note that the process driven models are calibrated in basin while our s2s models are trained out of sample for pub that is the proposed s2s models can find a better representation of rainfall runoff processing for pub on most basins by using a big dataset and thus can achieve higher nses however they still can be improved since a they are worse than the process driven models in some basins and b the sac sma model has the least number of basins with nse 0 although the models are calibrated in basin moreover data driven approaches bartoletti et al 2018 ahmadi et al 2019 xiang and demir 2020 and process driven approaches samadi et al 2019 song et al 2019 tasdighi et al 2018 zhou et al 2019 have their own advantages and characteristics and we believe that a combination or a fusion has potential to achieve better results if the fusion model has both the advantage of a data driven model and that of a process driven model it is also our future work third compared with the pub lstm model there are 23 basins that we have lower nses for 1 day ahead runoff pub in yin et al 2020 we showed that encoding the runoff observations is beneficial for improving the performance when the lstm based model is trained in basin for pub encoding the runoff observations seems not as good as in basin cases although our s2s models are better than the pub lstm on most basins in our opinion for pub encoding the runoff observations may cause the overfitting problem on some basins thus how to encode or use the runoff observations better is worthwhile to study 4 2 effect of attribute weighting module the results in table 2 show that the aw module is beneficial for improving the performance the median and the mean of nses provided by the lstm aw s2s which is added the aw module are higher than those provided by the lstm msv s2s for 7 day ahead pub compared with the lstm ma s2s the lstm awma s2s which is added the aw module has a similar case their cdfs in fig 5 also show the effect of aw module furthermore we compare the model having aw module with the model without aw module on all basins specifically we compare the lstm aw s2s with the lstm msv s2s and also compare the lstm awma s2s with the lstm ma s2s respectively the results are presented in table 4 which shows that adding the aw module can improve the performance on a majority of basins here we show the weights of those 32 attributes as inputs to 21 lstm units in fig 7 and have the following points first the 5 meteorological forcings have larger weights than those 27 catchment characteristics for the last 8 lstm units that is for the days close to the runoff prediction day the aw module gives the 5 meteorological forcings larger weights second among these 5 meteorological forcings the average daily precipitation has the largest weight third the weights of static catchment characteristics are more scattered than those of the meteorological forcings in other words the weights of meteorological forcings and those of static catchment characteristics have different patterns specifically we discuss the above three points and their reasons as follows usually the meteorological forcings vary frequently over time while the static catchment characteristics are usually fixed values or vary very slowly when we train and use a lstm based data driven model to predict the runoff values for an individual basin the model can mimic the highly nonlinear function or relationship well between the variation inputs and variation outputs by using meteorological forcings and runoff observations for such a case runoff predictions for an individual basin the static catchment characteristics usually have little effect on the runoff predictions and thus do not contribute to a lstm based data driven model however when we train and use a lstm based data driven model to predict the runoff values for many basins also called regional runoff predictions e g pub the case is different and the static catchment characteristics become important for such a case adding the static catchment characteristics to the inputs can improve the performance significantly as shown in kratzert et al 2019b the lstm based data driven model can learn to group similar basins together into the high dimensional space by using the static catchment characteristics so that hydrologically similar basins use similar parts of the lstm cell states therefore for regional rainfall runoff process the static catchment characteristics and the meteorological forcings have different effects on runoff predictions that is the static catchment characteristics are useful for a data driven model to group similar basins together while the meteorological forcings are used to learn the highly nonlinear function or relationship between the variation inputs and variation outputs the above analysis shows that both the static catchment characteristics and the meteorological forcings are very important for pub a lstm based data driven model cannot achieve excellent performance without either of these two sorts as mentioned those 5 meteorological forcings have larger weights than those 27 catchment characteristics for the days close to the runoff prediction day this is because the meteorological forcings of those days are more closely related to the runoff values of runoff prediction days compared with those static attributes that is for a lstm based data driven model the variations of the meteorological forcings among those days affect the runoff values of runoff prediction days much more directly and thus the meteorological forcings should be assigned larger weights as shown in fig 7 among the 5 meteorological forcings the average daily precipitation has the largest weight this is reasonable since the average daily precipitation is usually a very and usually the most important factor in the rainfall runoff process here in camels dataset besides the rainfall the snow influence is also considered by the average daily precipitation with temperatures below 0 and thus the average daily precipitation is a main and very important factor causing runoff and peak discharge as shown in fig 7 the weights of static catchment characteristics are more scattered than those of the meteorological forcings as mentioned since the static catchment characteristics are used to group similar basins together so that hydrologically similar basins can use similar parts of the lstm cell states their weights show a different pattern from the meteorological forcings that is different from the meteorological forcings having larger weights for the days close to the runoff prediction day the weights of static catchment characteristics are more scattered and do not focus on a part of time series from the above analysis and the results we can see that the proposed aw module provides appropriate weights learned from the training set and thus this module can improve the performance 4 3 effect of multi head attention module in table 2 compared with the lstm msv s2s the lstm ma s2s which is added the ma module has a larger median of nses and also a larger mean of nses for 7 day ahead pub compared with the lstm aw s2s model the lstm awma s2s model which is added the ma module has a similar case their cdfs in fig 5 also show the effect of ma module thus the ma module is useful and beneficial for improving the performance generally we also compare the model having ma module with the model without ma module on all basins specifically we compare the lstm ma s2s with the lstm msv s2s and compare the lstm awma s2s with the lstm aw s2s respectively the results are presented in table 5 which shows that adding the aw module can improve the performance on a majority of basins compared with the structure of lstm msv s2s besides ma module the lstm ma s2s encodes runoff observations into the decoder directly rather than using another encoder and then uses a feedback mechanism containing the information from the past time and also that through the ma module here we compare the proposed lstm ma s2s model with the following model see fig 8 which adds the ma module to the lstm msv s2s directly we compare the lstm ma s2s with the model in fig 8 on all basins and show the comparisons in table 6 we can see that the lstm ma s2s model has better performance on a majority of basins due to encoding the runoff observations into the decoder directly and the feedback mechanism in our opinion encoding the runoff observations by using an encoder means that the information of runoff observations is compressed information loss more heavily than encoding the runoff observations into the decoder directly furthermore the lstm ma s2s model uses more information by the feedback mechanism with the elements through the ma module 4 4 influence of decoder length as shown in table 2 and fig 6 the performance of ith day ahead runoff predictions is better than that of i 1 th day ahead runoff predictions in general for example for lstm awma s2s the nse median of 2nd day ahead runoff predictions i e 0 73 is larger than that of 3rd day ahead runoff predictions i e 0 71 this is because when we predict the 3rd day ahead runoff our model uses the predicted values of both 1 day ahead runoff and 2nd day ahead runoff the accumulation of prediction errors causes the decreasing of performance thus the m of m day ahead usually cannot be very large furthermore the value of m is related to the number of lstm units in the encoder in this paper since the number of lstm units in the encoder is 15 which is not large we provide 7 day ahead runoff predictions we want to show that our model can provide multi day ahead runoff predictions with a small number of lstm units in the encoder a smaller number of lstm units in the encoder means a shorter training time and less computation cost here we change the decoder length i e the value of m to 15 a larger one compared with 7 which is the same as the encoder length the mean of nses for 15 day ahead runoff predictions are shown in fig 9 based on the results we have the following points first as similar as the case of m 7 the performance of ith day ahead runoff predictions decreases with the increasing of i generally in the case of m 15 this is also caused by the accumulation of prediction errors second comparing the performance of ith day ahead runoff predictions with that of i 1 th day ahead runoff predictions the performance between 1 day ahead and 2nd day ahead has the largest difference when the 2nd day ahead runoff values are predicted the model uses the predicted values of 1 day ahead runoff for 1 day ahead runoff predictions the model does not use any runoff predicted values this indicates that the prediction errors affect the performance significantly when the runoff predicted values are firstly used by the model third the mean of nses provided by 13 14 15 th day ahead runoff predictions decreases to the value close to but smaller than 0 5 it shows that for the encoder having the length of 15 the decoder had better not have a length the value of m larger than 15 based on the above experiment and discussion we can see that the m cannot be very large the model like an autoregressive decoding one uses predicted runoff values and thus the accumulation of prediction errors can cause the decreasing of performance although our lstm awma s2s achieves best performance on camels dataset for pub its performance still has limitation due to e g accumulation of prediction errors the model can be improved by a better architecture which is our future work 5 conclusions in this paper we proposed three novel s2s models i e lstm aw s2s lstm ma s2s and lstm awma s2s and also introduced one our previous s2s model i e lstm msv s2s to deal with pub for the three new s2s models we proposed two modules i e the aw module and the ma module and a feedback mechanism the aw module gives the attributes different weights learning from the training set the ma module gives attentions or larger weights on more important parts compared with the lstm msv s2s without these two modules our proposed three models can focus on attributes and areas by giving weights on them and the results showed that these two modules were beneficial for improving the performance by the feedback mechanism the model can use more information from the past time and more information through the ma module compared with three benchmark models including two process driven models and one data driven model our s2s models showed their power by testing on 531 basins from camels dataset for 1 day ahead pub the median and the mean of nses provided by our lstm awma s2s achieves 0 78 and 0 70 respectively while those provided by the pub lstm are 0 69 and 0 54 respectively that is the median and the mean of nses are improved by 0 09 and 0 16 respectively we also compared the nse of our models with that of the benchmarks on all basins and we conclude that the performance can be improved significantly for 1 day ahead runoff pub furthermore our s2s models can deal with multi day ahead pub and the results are also good note that the nse mean 0 57 and the nse median 0 68 of 7th day ahead pub provided by our lstm awma s2s model have similar performance to 1 day ahead pub of the pub lstm model which further shows its power the main findings can be concluded briefly as follows first the proposed s2s models have excellent performance for pub and they can further give good multi day ahead runoff predicted values second the proposed s2s models can find a better representation of rainfall runoff processing for pub on most basins by using a big dataset and thus can achieve higher nses third encoding the runoff observations is beneficial for improving the performance when a lstm based model is trained in basin for pub encoding the runoff observations seems not as good as the in basin cases and how to encode or use the runoff observations better is worthwhile to study fourth the proposed aw module can provide appropriate weights learning from the training set and thus it can improve the performance fifth adding the ma module can improve the performance on a majority of basins sixth more information can be used by the feedback mechanism which is beneficial for the performance in the future we will consider a combination of a process driven model and a data driven model we hope a combination model has both the advantage of a process driven model and that of a data driven model and thus the performance for pub can be further improved besides how to encode or use the runoff observations better is also our future work credit authorship contribution statement hanlin yin conceptualization methodology software writing original draft zilong guo methodology data curation software xiuwei zhang writing review editing jiaojiao chen software yanning zhang supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research is supported in part by the national natural science foundation of china 61801395 61971356 and the national natural science foundation of shaanxi province 2020gm 137 the authors would like to thank the editors and anonymous reviewers for their insightful and constructive comments 
4042,how to improve the performance of runoff predictions in ungauged basins pub is challenging recently the long short term memory lstm based models have excellent performance and receive many attentions in this paper to improve the performance for 1 day ahead runoff pub and provide good performance for multi day ahead runoff pub we propose four sequence to sequence s2s models to deal with pub furthermore we introduce two modules named attribute weighting module and multi head attention module for improving the performance to show the power of these s2s models and the advantages of those two modules we test our four s2s models and also three benchmark models including a pub lstm model and two process driven models by using k fold validation on 531 basins of the catchment attributes and meteorology for large sample studies camels dataset for 1 day ahead runoff pub the median and the mean of nash sutcliffe efficiency for the 531 basins provided by our best model achieve 0 78 and 0 70 respectively while those provided by the pub lstm model the best one among those three benchmark models are 0 69 and 0 54 respectively besides our s2s models have promising results for multi day ahead runoff pub for 7 th day ahead runoff pub the median and the mean of nash sutcliffe efficiency for the 531 basins provided by our best model are 0 68 and 0 57 respectively furthermore the results also show that the two modules are beneficial for improving the performance keywords rainfall runoff modeling lstm sequence to sequence models ungauged basins 1 introduction models for runoff predictions can be generally divided into three sorts process driven models fidal and kjeldsen 2020 huo et al 2020 jadidoleslam et al 2019 mathevet et al 2020 data driven models kratzert et al 2019b tikhamarine et al 2020 zuo et al 2020 yin et al 2020 and hybrid models okkan et al 2021 they have different characteristics and the lstm based models show their promising performance recently kratzert et al 2018 investigated the potential of lstm for runoff predictions on 241 basins of the camels dataset with meteorological time series observations and showed that their lstm based models can achieve good performance ni et al 2020 developed two lstm based hybrid models and showed that lstm was applicable for time series prediction and their two hybrid models were better kao et al 2020 proposed a feed forward neural network based encoder decoder model and a lstm based one to predict multi step ahead flood these two models show good multi step ahead forecasts and the lstm based one can provide more reliable and accurate flood forecasts xiang et al 2020 proposed a lstm sequence to sequence rainfall runoff model tested the performance on five stations in two watersheds and showed that its performance is better than all other machine learning benchmark models kao et al 2021 proposed a hybrid of the stacked autoencoder with a recurrent neural network which can provide accurate and timely information to support emergency management in areas impacted by flood hazards gao et al 2020 applied three models including lstm gated recurrent unit gru and artificial neural network to simulate runoff in the yutan station control catchment and showed that lstm and gru have better performance furthermore they also mentioned that gru was preferred because of its simple structure barzegar et al 2021 proposed boundary corrected maximal overlap discrete wavelet transform preprocessing method coupled with convolutional neural network lstm deep learning and machine learning models for multi step lake water level forecasting khosravi et al 2020 developed a flood susceptibility map for iran by using a deep learning convolutional neural networks algorithm which is one of the most powerful algorithms in big data sets salloom et al 2021 handled water demand forecasting by using a deep neural network architecture based on the gated recurrent unit and the k means which can achieve promising performance with low cost of complexity in practice we often need to deal with the cases of runoff predictions in ungauged basins pub which is still a challenge and very important task to study sivapalan et al 2003 presented a summary of the science and implementation plan of pub with a call to the hydrological community to participate actively in the realization of several goals montanari et al 2013 mentioned that researches on pub received a lot of attentions and thus developed well bloschl et al 2019 pointed out that pub is still one of twenty three unsolved problems in hydrology in recent years more and more attentions are focusing on pub atieh et al 2015 desai and ouarda 2021 du et al 2020 grimaldi et al 2020 jafarzadegan and moradkhani 2020 milukow et al 2019 rezende de souza et al 2021 swain and patra 2017 tegegne and kim 2018 teutschbein et al 2018 zhang et al 2015 grimaldi et al 2020 applied a continuous model specifically designed for ungauged basins and tested its performance in certain conditions rezende de souza et al 2021 demonstrated the adequate applicability of regionalization in ungauged watersheds and promoted sustainable flood risk management by providing an alternative for maximum streamflow estimates tegegne and kim 2018 presented a new regionalization methodology named catchment runoff response similarity to reduce the uncertainty of runoff predictions in ungauged catchments and addressed the problem of key attributes identification jafarzadegan and moradkhani 2020 applied a generic regionalization framework for the regionalization of stage discharge rating curves in the arkansas white red region gauch et al 2021 showed that tree based models and lstm based models have similarly accurate predictions on small datasets while lstms are better on big datasets prieto et al 2019 handled the pub problem by exploiting advances in flow index selection and regionalization in bayesian inference and further developed novel model performance tests in ungauged catchments kratzert et al 2019a trained several lstm based models and then tested them on the camels dataset using k fold validation and the results showed the power of lstm based models compared with several benchmark models in this paper we focus on pub and have the following considerations first we proposed a lstm based sequence to sequence model with multi state vector named lstm msv s2s in yin et al 2021 which achieves excellent performance in camels dataset in that paper we trained each model for each basin and used five meteorological forcings including precipitation shortwave downward radiation vapour pressure daily maximum temperature and daily minimum temperature as inputs for pub besides those five meteorological forcings we use static catchment attributes we want to focus on more important attributes and thus propose an attribute weighting module second soft attention mechanisms can pay more attentions to more important areas of a whole input sequence rather than a fixed element or area recently soft attention mechanisms have shown promising performance in many tasks such as sarcasm detection jain et al 2020 human trajectory prediction fernando et al 2018 and visual question answering liu et al 2019 since a soft attention mechanism is beneficial for achieving better results we apply it to pub based on the above considerations we propose a novel attribute weighting multi head attention seq2seq model based on lstm lstm awma s2s for pub along with two models named lstm based attribute weighting seq2seq lstm aw s2s and lstm based multi ahead attention seq2seq lstm ma s2s based on the above two considerations respectively we summarize the contributions of this paper as follows first four s2s models are proposed for pub second we compare our s2s models with three benchmarks on 531 basins in camels dataset and our s2s models outperform the benchmarks for 1 day ahead runoff pub significantly and also can provide good performance for multi day ahead runoff pub third two added modules including an aw module and a ma module are beneficial for improving the performance we organize this paper as follows section 2 discusses our four s2s models we introduce the camels dataset in section 3 section 4 provides results and discussions we conclude this paper in section 5 2 methods we introduce our lstm msv s2s yin et al 2021 first and then propose the lstm awma s2s these models are related to the lstm network since the lstm network has been clearly described in detail in many papers e g kratzert et al 2018 we do not introduce it here 2 1 lstm msv s2s model here the structure of the lstm msv s2s model is illustrated in fig 1 this model has two encoders m context vectors and a decoder the first encoder contains n m lstm cells with both meteorological forcings and static catchment attributes as inputs the second encoder contains n lstm cells with runoff observations as inputs the m context vectors contain information from these encoders the decoder with m lstm cells outputs m step aheadrunoff predicted values the lstm msv s2s assigns the attributes the same weights usually different attributes affect the results differently since they are not the same important this kind of importance or weights can be learned by adding an attribute weighting module furthermore by using m context vectors the lstm msv s2s follows the case in practice the meteorological forcing data after the jth day do not influence the jth day runoff however it pays attention to a fixed element as mentioned soft attention mechanisms can pay more attentions to a specific area or important areas of the input sequence rather than a fixed element hence we add a multi head attention module consisting of many soft attentions which not only can follow the causality as the lstm msv s2s does but also can pay more attentions to a specific area rather than a fixed element 2 2 lstm aw s2s lstm ma s2s and lstm awma s2s model the architectures of lstm aw s2s lstm ma s2s and lstm awma s2s are shown in fig 2 fig 3 and fig 4 respectively compared with the lstm msv s2s the lstm aw s2s adds an attribute weighting aw module providing attributes different weights by learning from the training set the aw module i e the attribute weighting part in fig 2 or fig 4 consists of n m vectors corresponding to n m lstm cells inputs of n m days the elements of each vector are the weights obtained by the softmax operation corresponding to the input the attributes for one lstm cell compared with the lstm msv s2s the lstm ma s2s adds a multi ahead attention ma module the ma module follows the case in practice that the meteorological forcing data after the jth day do not influence the jth day runoff and focuses on the area or the time series not after the jth day for predicting the jth day runoff the ma module contains 8 parallel soft attention layers heads the outputs of these 8 heads are concatenated and then a linear transformation is operated on it note that for showing how the proposed lstm awma s2s works more clearly fig 4 illustrates the ith day ahead runoff pub and the pseudocode is presented in algorithm 1 accordingly actually the lstm ma s2s and the lstm awma s2s are proposed for m day ahead runoff pub that is the outputs of their decoders can predict m day ahead runoff values furthermore besides the ma module the structure of the lstm ma s2s model differs from that of the lstm msv s2s by a encoding the runoff observations into the decoder directly rather than using another encoder and b using a feedback mechanism the orange line in fig 3 this feedback element contains the information from the past time and the information through the ma module compared with the lstm ma s2s the lstm awma s2s adds an aw module that is these two models are the same expect for the aw module here since the lstm msv s2s was proposed in our previous study yin et al 2021 we point out the difference between that study and this paper as follows first this paper handles pub problem while that previous study handled runoff predictions in each individual basin that is the two papers deal with different problems second in this paper although the lstm msv s2s was introduced to handle pub problem we propose three novel s2s models i e lstm aw s2s lstm ma s2s and lstm awma s2s by using two modules i e aw module and ma module and a feedback mechanism in our opinion these two modules and the feedback mechanism are proposed in handling such a problem for the first time third the experiments between that study and this paper are totally different in this paper the training and testing process are done by using k fold validation for pub see section 3 2 in that previous study we trained and tested one lstm msv s2s model for one basin fourth the previous study focused on the lstm msv s2s and the results showed its advantages on runoff predictions for in basin cases in this paper we focus on the three proposed s2s models i e lstm aw s2s lstm ma s2s and lstm awma s2s and want to show their power in pub and also the effects of those two modules i e aw module and ma module and the feedback mechanism see section 4 algorithm 1 pseudocode of lstm awma s2s input x x 1 x n m y y 1 y n output y hyper parameters m 7 default predicting days n 15 default known days h 8 default number of heads parameters except lstm w y b y w c w s w o b o w q 1 w k 1 w v 1 w q h w k h w v h 1 initialize y 2 h 1 h n m s hidden s cell lstm x 1 x n m 0 0 3 s 1 s n t w y y 1 y n t b y 4 for i 1 to m do 5 z 1 z n i 1 s hidden s cell lstm s 1 s n s n 1 s n i 1 s hidden s cell 6 for j 1 to h do parallel loop 7 q n i 1 w q j z n i 1 8 k n i w k j h 1 h n i 9 v n i w v j h 1 h n i 10 attn value n i j softmax q n i 1 k n i t d k v n i d k means dimension of k n i 11 v n i w c concat attn value n i 1 attn value n i h 12 s n i w s concat v n i z n i 1 13 y n i w o s n i b o 14 end for 15 y append y n i 16 end for 17 return y 2 3 benchmarks evaluation measures we employ three benchmarks the pub lstm kratzert et al 2019a a lumped conceptual model named sacramento soil moisture accounting model sac sma calibrated in gauged basins newman et al 2015 and a distributed process based model named the u s national water model nwm salas et al 2018 to be fair we did not run any of these benchmarks and the results are obtained by other research groups that is these existing model runs are used so as not to favor our proposed models the results from these three benchmarks can be found in kratzert et al 2019a for evaluation of the models we apply a popular performance metric the nash sutcliffe efficiency nse along with four statistics of the nses including the median the mean the number of basins with nse 0 and the cumulative distribution functions cdf the nse is defined as 1 nse 1 i 1 n y i y i 2 i 1 n y i y 2 where y i is the observed value at time i y i is the prediction y refers to the average of n observations 3 dataset and experimental setup 3 1 camels dateset the dataset used here is the camels dataset addor et al 2017 newman et al 2015 having 671 basins in the united states this dataset has many differently complex catchments and thus different models can be evaluated generally and statistically the camels dataset contains meteorological forcings static catchment attributes and observed runoff values on each basin at the daily timescale from october 1 1980 to december 31 2014 the meteorological data used in this paper are calculated from the national land data assimilation system nldas data xia et al 2012 these data can be available freely at https ral ucar edu solutions products camels newman et al 2014 the static catchment attributes are about soils climate vegetation topography geology and so on they are introduced in detail in addor et al 2017 2018 and we list the meteorological forcings and static catchment attributes in table 1 for convenience in this study we choose 531 of 671 basins from the camels dataset which are the same basins that were used by newman et al 2017 and kratzert et al 2019a furthermore we use the 5 daily meteorological forcings from nldas and the same 27 static catchment attributes used by kratzert et al 2019a for a fair comparison 3 2 experimental setup and model settings the lstm msv s2s and the lstm aw s2s have two encoders and one decoder where the inputs of one encoder contain 5 meteorological forcings and 27 catchment characteristics and those of the other encoder are runoff observations the decoder outputs 7 day ahead runoff predicted values the lstm ma s2s and the lstm awma s2s have one encoder and one decoder where the inputs of the encoder contain 5 meteorological forcings and 27 catchment characteristics the decoder outputs 7 day ahead runoff predicted values in this paper we use the same meteorological forcings and catchment characteristics as those were used in kratzert et al 2019a we use the data from 1981 to 1995 water years to train the models and test them using the data from 1996 to 2010 water years the training and testing process are done by using k fold validation as follows first the 531 basins are randomly split into 12 groups with approximately equal size second all basins from 11 groups are used to train the model third we test the model on the rest single group without training this procedure is repeated 12 times to guarantee that all basins are tested for pub we test the following four s2s models including the lstm msv s2s in yin et al 2021 the lstm aw s2s the lstm ma s2s and the lstm awma s2s the purposes are threefold first we want to show the power of s2s models for pub compared with the benchmark models the proposed s2s models not only can improve the 1 day ahead pub significantly but also can provide good performance for multi day ahead pub second the aw module is beneficial for improving the performance because it can learn the appropriate weights of attributes from the training dataset third the ma module is also beneficial for pub because it focuses on the area or the time series rather than a fixed point the parameters of the above proposed models are set as follows for the encoder having 21 lstm units each lstm unit has one input vector with 32 dimensions the hidden state length of this encoder is set as 256 for the encoder having 15 lstm units each lstm unit has one input vector with 1 dimension i e runoff observed values the hidden state length of this encoder is set as 128 we apply z score normalization method to normalize all inputs the hidden state length of the decoder sequence is set as 256 the dropout rate and the batchsize are set as 0 3 and 2048 respectively here the loss function is the average nse over all training basins proposed by kratzert et al 2019b and also used in kratzert et al 2019a for a lstm unit the cell state and the hidden state are related to the long memory and the short memory respectively these two states vectors have the same length the hidden state length is the dimension of hidden state which is an important hyper parameter of a lstm unit the dimension of input vector and that of the hidden state determine the shapes of those learnable parameters once the length or the dimension of the hidden state and that of the input vector are given the shapes of learnable parameters are determined the hidden state length and other hyper parameters can be determined by using the hyper parameter optimization or named hyper parameter search although the hyper parameter search is beneficial for obtaining a better model that can achieve better performance in this paper we do not apply it for our model but use almost the same hyper parameters as kratzert et al 2019a for a more fair comparison the model proposed by kratzert et al 2019a is an important benchmark model in this paper which performs best among the benchmark models 4 results and discussion we evaluate the performance of seven models i e four s2s models and three benchmarks by four statistics of the nses including the median the mean the number of basins with nse 0 and the cdf the results of first three statistics are shown in table 2 the cdfs are shown in fig 5 and fig 6 4 1 the power of s2s models the median and the mean of nses show that our four s2s models outperform those three benchmark models significantly for 1 day ahead runoff pub in general the nse cdfs in fig 5 of the 7 models for 1 day ahead runoff pub on 531 basins also indicate that our four s2s models can improve the performance for 1 day ahead runoff pub significantly in general in other words the s2s models show their power when they are applied for 1 day ahead runoff pub compared with those three benchmark models including two process driven models and a data driven model in fig 6 we compare the nse cdfs of lstm awma s2s for 7 day ahead pub with the nse cdfs of three benchmark models for 1 day ahead pub the results in fig 6 show that our lstm awma s2s has better performance for 4 day ahead pub than pub lstm for 1 day ahead pub and has comparable performance for 5 6 7 th day ahead pub to pub lstm for 1 day ahead pub the median and the mean of nses in table 2 also indicate a similar advantage of our proposed lstm awma s2s the median and the mean of nses of our lstm awma s2s for 4 day ahead pub are larger than those of three benchmarks for 1 day ahead pub our lstm awma s2s has larger median and mean of nses for 5 6 7 th day ahead pub compared with two process based benchmarks and has comparable median and mean of nses for 5 6 7 th day ahead pub compared with pub lstm besides the three benchmark models kratzert et al 2019b kratzert et al 2019a proposed a global lstm with static features which uses both meteorological forcings and static catchment characteristics as inputs trained on all catchments simultaneously without k fold validation this global lstm model is an upper bound of the pub lstm model the median and the mean of nses provided by the global lstm model are 0 74 and 0 68 respectively we can see that the lstm aw s2s the lstm ma s2s and the lstm awsa s2soutperform the global lstm model it further indicates the power of our proposed s2s models besides 1 day ahead runoff pub our s2s models give promising results for multi day ahead runoff pub for a further comparison we would like to see how many basins that the s2s models can beat the benchmark models for 1 day ahead runoff pub that is we compare the nse of s2s models with that of the benchmarks on all basins the results are shown in table 3 the lstm awma s2s has a higher nse than the sac sma model in 417 of 531 79 basins the nwm model in 467 of 531 88 basins and the pub lstm model in 409 of 531 77 basins respectively the above results show the power of our proposed s2s models for pub here we summarize them briefly as follows first for 1 day ahead pub our s2s models outperform the benchmarks and improve the performance significantly as shown by the median and the mean of nses in table 2 and the nse cdfs in fig 5 second the comparisons in table 2 and fig 6 between our model for 7 day ahead pub and the benchmarks for 1 day ahead pub indicate that the performance of our lstm awma s2s for 7 day ahead pub is better or at least comparable with benchmark models for 1 day ahead pub third compared with a global lstm trained in basin without k fold validation i e an upper bound of the pub lstm our three s2s models trained out of sample for pub have better performance fourth the comparisons between nses of s2s models with those of the benchmarks on all basins are provided to further show the power of our s2s models for pub based on the above comparisons and results we have the following three points first the proposed s2s models have more power compared with the benchmark models for 1 day ahead runoff pub besides they can provide promising multi day ahead runoff predictions second the proposed s2s models have higher nses than those two process driven models in most basins note that the process driven models are calibrated in basin while our s2s models are trained out of sample for pub that is the proposed s2s models can find a better representation of rainfall runoff processing for pub on most basins by using a big dataset and thus can achieve higher nses however they still can be improved since a they are worse than the process driven models in some basins and b the sac sma model has the least number of basins with nse 0 although the models are calibrated in basin moreover data driven approaches bartoletti et al 2018 ahmadi et al 2019 xiang and demir 2020 and process driven approaches samadi et al 2019 song et al 2019 tasdighi et al 2018 zhou et al 2019 have their own advantages and characteristics and we believe that a combination or a fusion has potential to achieve better results if the fusion model has both the advantage of a data driven model and that of a process driven model it is also our future work third compared with the pub lstm model there are 23 basins that we have lower nses for 1 day ahead runoff pub in yin et al 2020 we showed that encoding the runoff observations is beneficial for improving the performance when the lstm based model is trained in basin for pub encoding the runoff observations seems not as good as in basin cases although our s2s models are better than the pub lstm on most basins in our opinion for pub encoding the runoff observations may cause the overfitting problem on some basins thus how to encode or use the runoff observations better is worthwhile to study 4 2 effect of attribute weighting module the results in table 2 show that the aw module is beneficial for improving the performance the median and the mean of nses provided by the lstm aw s2s which is added the aw module are higher than those provided by the lstm msv s2s for 7 day ahead pub compared with the lstm ma s2s the lstm awma s2s which is added the aw module has a similar case their cdfs in fig 5 also show the effect of aw module furthermore we compare the model having aw module with the model without aw module on all basins specifically we compare the lstm aw s2s with the lstm msv s2s and also compare the lstm awma s2s with the lstm ma s2s respectively the results are presented in table 4 which shows that adding the aw module can improve the performance on a majority of basins here we show the weights of those 32 attributes as inputs to 21 lstm units in fig 7 and have the following points first the 5 meteorological forcings have larger weights than those 27 catchment characteristics for the last 8 lstm units that is for the days close to the runoff prediction day the aw module gives the 5 meteorological forcings larger weights second among these 5 meteorological forcings the average daily precipitation has the largest weight third the weights of static catchment characteristics are more scattered than those of the meteorological forcings in other words the weights of meteorological forcings and those of static catchment characteristics have different patterns specifically we discuss the above three points and their reasons as follows usually the meteorological forcings vary frequently over time while the static catchment characteristics are usually fixed values or vary very slowly when we train and use a lstm based data driven model to predict the runoff values for an individual basin the model can mimic the highly nonlinear function or relationship well between the variation inputs and variation outputs by using meteorological forcings and runoff observations for such a case runoff predictions for an individual basin the static catchment characteristics usually have little effect on the runoff predictions and thus do not contribute to a lstm based data driven model however when we train and use a lstm based data driven model to predict the runoff values for many basins also called regional runoff predictions e g pub the case is different and the static catchment characteristics become important for such a case adding the static catchment characteristics to the inputs can improve the performance significantly as shown in kratzert et al 2019b the lstm based data driven model can learn to group similar basins together into the high dimensional space by using the static catchment characteristics so that hydrologically similar basins use similar parts of the lstm cell states therefore for regional rainfall runoff process the static catchment characteristics and the meteorological forcings have different effects on runoff predictions that is the static catchment characteristics are useful for a data driven model to group similar basins together while the meteorological forcings are used to learn the highly nonlinear function or relationship between the variation inputs and variation outputs the above analysis shows that both the static catchment characteristics and the meteorological forcings are very important for pub a lstm based data driven model cannot achieve excellent performance without either of these two sorts as mentioned those 5 meteorological forcings have larger weights than those 27 catchment characteristics for the days close to the runoff prediction day this is because the meteorological forcings of those days are more closely related to the runoff values of runoff prediction days compared with those static attributes that is for a lstm based data driven model the variations of the meteorological forcings among those days affect the runoff values of runoff prediction days much more directly and thus the meteorological forcings should be assigned larger weights as shown in fig 7 among the 5 meteorological forcings the average daily precipitation has the largest weight this is reasonable since the average daily precipitation is usually a very and usually the most important factor in the rainfall runoff process here in camels dataset besides the rainfall the snow influence is also considered by the average daily precipitation with temperatures below 0 and thus the average daily precipitation is a main and very important factor causing runoff and peak discharge as shown in fig 7 the weights of static catchment characteristics are more scattered than those of the meteorological forcings as mentioned since the static catchment characteristics are used to group similar basins together so that hydrologically similar basins can use similar parts of the lstm cell states their weights show a different pattern from the meteorological forcings that is different from the meteorological forcings having larger weights for the days close to the runoff prediction day the weights of static catchment characteristics are more scattered and do not focus on a part of time series from the above analysis and the results we can see that the proposed aw module provides appropriate weights learned from the training set and thus this module can improve the performance 4 3 effect of multi head attention module in table 2 compared with the lstm msv s2s the lstm ma s2s which is added the ma module has a larger median of nses and also a larger mean of nses for 7 day ahead pub compared with the lstm aw s2s model the lstm awma s2s model which is added the ma module has a similar case their cdfs in fig 5 also show the effect of ma module thus the ma module is useful and beneficial for improving the performance generally we also compare the model having ma module with the model without ma module on all basins specifically we compare the lstm ma s2s with the lstm msv s2s and compare the lstm awma s2s with the lstm aw s2s respectively the results are presented in table 5 which shows that adding the aw module can improve the performance on a majority of basins compared with the structure of lstm msv s2s besides ma module the lstm ma s2s encodes runoff observations into the decoder directly rather than using another encoder and then uses a feedback mechanism containing the information from the past time and also that through the ma module here we compare the proposed lstm ma s2s model with the following model see fig 8 which adds the ma module to the lstm msv s2s directly we compare the lstm ma s2s with the model in fig 8 on all basins and show the comparisons in table 6 we can see that the lstm ma s2s model has better performance on a majority of basins due to encoding the runoff observations into the decoder directly and the feedback mechanism in our opinion encoding the runoff observations by using an encoder means that the information of runoff observations is compressed information loss more heavily than encoding the runoff observations into the decoder directly furthermore the lstm ma s2s model uses more information by the feedback mechanism with the elements through the ma module 4 4 influence of decoder length as shown in table 2 and fig 6 the performance of ith day ahead runoff predictions is better than that of i 1 th day ahead runoff predictions in general for example for lstm awma s2s the nse median of 2nd day ahead runoff predictions i e 0 73 is larger than that of 3rd day ahead runoff predictions i e 0 71 this is because when we predict the 3rd day ahead runoff our model uses the predicted values of both 1 day ahead runoff and 2nd day ahead runoff the accumulation of prediction errors causes the decreasing of performance thus the m of m day ahead usually cannot be very large furthermore the value of m is related to the number of lstm units in the encoder in this paper since the number of lstm units in the encoder is 15 which is not large we provide 7 day ahead runoff predictions we want to show that our model can provide multi day ahead runoff predictions with a small number of lstm units in the encoder a smaller number of lstm units in the encoder means a shorter training time and less computation cost here we change the decoder length i e the value of m to 15 a larger one compared with 7 which is the same as the encoder length the mean of nses for 15 day ahead runoff predictions are shown in fig 9 based on the results we have the following points first as similar as the case of m 7 the performance of ith day ahead runoff predictions decreases with the increasing of i generally in the case of m 15 this is also caused by the accumulation of prediction errors second comparing the performance of ith day ahead runoff predictions with that of i 1 th day ahead runoff predictions the performance between 1 day ahead and 2nd day ahead has the largest difference when the 2nd day ahead runoff values are predicted the model uses the predicted values of 1 day ahead runoff for 1 day ahead runoff predictions the model does not use any runoff predicted values this indicates that the prediction errors affect the performance significantly when the runoff predicted values are firstly used by the model third the mean of nses provided by 13 14 15 th day ahead runoff predictions decreases to the value close to but smaller than 0 5 it shows that for the encoder having the length of 15 the decoder had better not have a length the value of m larger than 15 based on the above experiment and discussion we can see that the m cannot be very large the model like an autoregressive decoding one uses predicted runoff values and thus the accumulation of prediction errors can cause the decreasing of performance although our lstm awma s2s achieves best performance on camels dataset for pub its performance still has limitation due to e g accumulation of prediction errors the model can be improved by a better architecture which is our future work 5 conclusions in this paper we proposed three novel s2s models i e lstm aw s2s lstm ma s2s and lstm awma s2s and also introduced one our previous s2s model i e lstm msv s2s to deal with pub for the three new s2s models we proposed two modules i e the aw module and the ma module and a feedback mechanism the aw module gives the attributes different weights learning from the training set the ma module gives attentions or larger weights on more important parts compared with the lstm msv s2s without these two modules our proposed three models can focus on attributes and areas by giving weights on them and the results showed that these two modules were beneficial for improving the performance by the feedback mechanism the model can use more information from the past time and more information through the ma module compared with three benchmark models including two process driven models and one data driven model our s2s models showed their power by testing on 531 basins from camels dataset for 1 day ahead pub the median and the mean of nses provided by our lstm awma s2s achieves 0 78 and 0 70 respectively while those provided by the pub lstm are 0 69 and 0 54 respectively that is the median and the mean of nses are improved by 0 09 and 0 16 respectively we also compared the nse of our models with that of the benchmarks on all basins and we conclude that the performance can be improved significantly for 1 day ahead runoff pub furthermore our s2s models can deal with multi day ahead pub and the results are also good note that the nse mean 0 57 and the nse median 0 68 of 7th day ahead pub provided by our lstm awma s2s model have similar performance to 1 day ahead pub of the pub lstm model which further shows its power the main findings can be concluded briefly as follows first the proposed s2s models have excellent performance for pub and they can further give good multi day ahead runoff predicted values second the proposed s2s models can find a better representation of rainfall runoff processing for pub on most basins by using a big dataset and thus can achieve higher nses third encoding the runoff observations is beneficial for improving the performance when a lstm based model is trained in basin for pub encoding the runoff observations seems not as good as the in basin cases and how to encode or use the runoff observations better is worthwhile to study fourth the proposed aw module can provide appropriate weights learning from the training set and thus it can improve the performance fifth adding the ma module can improve the performance on a majority of basins sixth more information can be used by the feedback mechanism which is beneficial for the performance in the future we will consider a combination of a process driven model and a data driven model we hope a combination model has both the advantage of a process driven model and that of a data driven model and thus the performance for pub can be further improved besides how to encode or use the runoff observations better is also our future work credit authorship contribution statement hanlin yin conceptualization methodology software writing original draft zilong guo methodology data curation software xiuwei zhang writing review editing jiaojiao chen software yanning zhang supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research is supported in part by the national natural science foundation of china 61801395 61971356 and the national natural science foundation of shaanxi province 2020gm 137 the authors would like to thank the editors and anonymous reviewers for their insightful and constructive comments 
4043,depth damage relationships of residential typologies have an important bearing on the reliability of flood risk assessments yet the information for creating adequate functions is frequently missing in places where they are needed the most developing countries where floods inflict severe losses to overcome the lack of site specific functions modelers usually adopt functions from foreign typologies extrapolate from limited flood damage data and conduct expert elicitation surveys the latter although not exempt from challenges are a helpful resource in situations in which there are sufficient experts available the classical model is a structured expert judgment technique which is one of the most used because it minimizes the number of subjective elements in the ranking of experts experience and its results can be compared with similar studies this paper presents depth damage and fragility functions developed with the classical model conducted with experts with extensive knowledge in the flood damage mechanism of typologies in northeast argentina a region under a severe flood hazard the depth damage functions were partially validated with damage data and exhibited good agreement also they are consistent with the fragility functions hence these functions can be helpful for probabilistic flood risk assessments provided that the underlying assumptions are deemed acceptable 1 introduction the quantification of flood damage potential affords insights of the effects that may result from the overlap of climatic and socioeconomic systems this information is essential for designing effective structural and non structural mitigation mechanisms in damage reduction and public policy the conventional approach to estimate flood building damages is with depth damage functions however having adequate depth damage functions to describe the building typologies vulnerability is a constant challenge that stands in the way of flood risk modelers admittedly modelers who assess flood risk in countries with a long tradition of risk modeling as the united states us have at their disposal a large assortment of functions in contrast modelers in other countries must usually have recourse to repositories of functions derived for other situations for example hazus cran r project org package hazus the corps of engineers usace 2015 open global repositories e g huizinga et al 2017 pregnolato and galasso 2015 bombelli 2019 proprietary repositories penning rowsell et al 2013 and meta inventories e g gerl et al 2016 however adopting a depth damage function of certain origin typology to describe a slightly different target typology could lead to incorrect damage estimates due to disagreements between typologies and flood situations i e differences in river regimes and topography consequently the transferability of depth damage functions hinges on the goodness of the correspondence between both situations cammerer et al 2013 the methodologies to develop depth damage functions range roughly from those based on causally simulating the damage mechanism to heuristic ones they include engineering model simulations which conduct detailed load path analyses e g mazzorana et al 2014 based on machine learning amadio et al 2019 wagenaar et al 2017 fitting analytical functions on empirical damage or loss data at the individual typology level grigg and helweg 1975 davis and skaggs 1992 usace 2000 2003 lehman and nafari 2016 or at the regional level pistrika et al 2014 and expert elicitation gec 1996 1997 reese and ramsay 2010 usually the available time and resources as well as accuracy desired will dictate which methodology is adequate fragility functions unlike depth damage functions allow propagating uncertainties in loss estimates and afford insights of potential flood damages nevertheless these have not been commonly used in flood damage modeling there are recent efforts however which recognize the potential usefulness of fragility functions and have developed them with methodologies that lay in the same spectrum described above simulation of load paths nadal et al 2010 jalayer et al 2016 based on reliability methods nofal et al 2020 damage data regression on individual typology level thapa et al 2020 and regional level mcgrath et al 2019 this study inspects the vulnerability of dwellings in the region northwards of resistencia capital of the province of chaco in argentina the province of chaco is one of the most affected by floods in the country several mitigation mechanisms structural and non structural have been implemented in recent decades with varying degrees of success von lany et al 2014 penning rowsell 1996 nevertheless no specific depth damage functions have been developed at the individual typology level which could be helpful for conducting flood damage assessments this region bears many similarities with sites worldwide that have vulnerable dwellings located in the floodplain of a large river another similarity is the paucity of damage data to construct functions and the absence of adequate autochthonous depth damage functions consequently the functions derived herein could be of use in those cases specifically for latin america situations several flood damage studies have been conducted which either developed empirical functions or adopted depth damage functions among the former in brazil machado et al 2005 nascimento 2007 fadel et al 2018 and in mexico baró et al 2011 in ecuador functions were regressed on damage data pinos et al 2017 a study in uruguay established 0 80 m a threshold of complete damage piperno and sierra 2013 studies which adopted functions developed for other countries include a study for paraguay iadb 2018 in which hazus functions were used independently of flood duration in argentina depth damage functions have been developed though not fragility functions although to our knowledge without accounting for uncertainty and damage to contents these are discussed below this paper introduces damage functions developed with the classical model cooke 1991 of structured expert judgment sej on residential typologies in the following section an overview of the flood hazard and the residential building inventory in the study area are presented next a list of depth damage functions developed in previous studies in the study area is introduced the structured expert judgment analysis is then described along with the assumptions of the study it follows a description and discussion of the depth damage functions derived in this study finally a summary of recommendations and limitations of the technique and of the functions is presented 2 background the study area is a flood prone region in the eastern part of the province of chaco the region has several settlements flanked by three important rivers paraná the most influential with an average annual of 18 900 m3 s at corrientes paraguay 3 800 m3 s at pilcomayo and bermejo 320 m3 s at paraguay river fig 1 changes in the rivers regimes have taken place due to changes in the characteristics of the upstream basins and construction of control works since the early 1970s paoli and malinow 2010 lopardo and seoane 2000 floods occurred in the last five decades in chaco have exerted substantial economic losses and population displacement but fortunately few fatalities see table 1 for references on direct damages for indirect damages see e g caputo et al 1985 celis 2006 de mari 2001 the region has suffered floods since long page 1889 the most impactful being those of 1905 and 1966 1977 1983 1992 and 1998 depettris et al 2000 fig 2 the infrastructure characteristics and flood risk situation are similar in the neighboring provinces corrientes formosa and misiones 2 1 characteristics of the building inventory in the study area the study area comprises populated centers near resistencia and include semi urban towns margarita belen colonia benitez las palmas la leonesa general vedia and rural towns puerto bermejo isla del cerrito puerto eva peron the majority of dwellings are single family and were built by federal housing developments fondo nacional de la vivienda especially after 1984 and federal loan programs procrear since 2012 mingo et al 2018 fig 4 a previous study found that the inventory was composed of precarious houses 80 to 85 mid low quality and 15 20 and no high quality dwellings mc 1979 in this study the building inventory was surveyed with aerial imagery google street view census 2010 data and in person reconnaissance in one town colonia benitez table 2 as per the survey the most frequent dwelling type is a single story unreinforced masonry with brick and block walls ufb4 ucb sheet metal roof wooden openings without basement the second most common type especially in towns near resistencia are confined masonry dwellings of one and two stories cml square footage was not surveyed but available information of similar dwellings in resistencia affords an approximation in the greater resistencia metropolitan area the average built area is 120 m2 fig 3 rohrman et al 1998 when classified by building quality the built areas are 3 of precarious dwellings up to 40 m2 9 medium low between 40 and 60 m2 18 medium high between 60 m2 and 90 m2 and the 70 of higher quality dwellings 100 m2 for the province precarious 30 m2 medium low 60 m2 and medium high 90 m2 mc 1979 another study found that in santa fe province whose building inventory is similar to that in the study area the average area of precarious and mid quality dwellings was 25 m2 and 64 2 m2 respectively halcrow 1994 the predominant foundation types for one story dwellings are piles and grade beam when soil resistance is low concrete slab is used for two story reinforced concrete isolated footing and deep piles foundations for taller buildings 3 stories a small number of houses from the late 19th and early 20th centuries can still be found these dwellings have strip footing brick or concrete as foundation types 2 2 previous flood risk studies in the region three flood studies of the nea region that used depth damage functions to predict damage were identified in the evaluation study for the dam and hydroelectric power station yacyreta areal depth damage functions were developed fitting data from the floods of 1966 and 1977 mc 1979 another study regressed empirical data of the 1977 and 1983 floods aisiks 1984 the last study halcrow 1994 adapted empirical and expert supplied functions of buildings in the united kingdom penning rowsell and chatterton 1977 the functions developed in these studies however are too coarse outdated and geared towards a deterministic approach and as such they are not valid for quantifying flood damages within a probabilistic simulation there exists also damage data available from a survey conducted on the 1998 resistencia flood by rohrmann et al 1998 that could be used for developing an empirical relationship however this data collected on a single building typology represents a limited range of water depths up to 1 m and so a significant extrapolation beyond the region of data must be made moreover the choice of extrapolation procedure is critical hence the empirical data cannot be used as the sole resource to build a damage function although it can be used as data for validation as is done below 3 derivation of depth damage and fragility functions in view of the situation described above an expert elicitation methodology was applied in this study to develop a new set of depth damage relationships for the most common typologies of the region expert opinion elicitation is an alternative for supplying data to address technical problems for which the variables of interest cannot be measured or when the methodology for measuring them is expensive or impractical surveys consist of two key parts selection of relevant experts and conduction of a questionnaire with the target quantities and combination of the expert estimates to get an estimate of the target variables of interest in the flood risk modeling community the use of expert opinion to build depth damage relationships is established of which the us army corps of engineers is a pioneer e g usace 2006 2015 3 1 use of classical model to build depth damage and fragility functions several approaches have been created to aggregate expert opinion clemen and winkler 1999 o hagan et al 2006 each with strengths and weaknesses arising from underlying assumptions bedford and cooke 2001 morgan 2014 the method developed by cooke 1991 known as the classical model of structured expert judgment was applied in this study to combine expert estimates the reason for selecting it lies in that it is a performance based weighting technique which minimizes the use of subjective elements for determining the weights to combine the experts opinions moreover there is considerable experience about the model as it has been used in many applications it was tested extensively and was found to outperform other methods colson and cooke 2018 finally its formal structure is a consistent and transparent framework that facilitates that its results can be unambiguously compared with other future damage studies the classical model has been successfully used for developing seismic damage functions jaiswal et al 2014 but to our knowledge not for flood depth damage functions at least not the type of functions typologies and granularity proposed herein the technique has a strong foundation in information theory aspinall 2008 unlike other approaches the classical model requires that besides the target variables the experts also judge the value of several calibration variables whose correct value is known only by the survey facilitators the latter are considered samples of random distributions and serve to compute two scores that weight each expert s estimates in terms of accuracy and dispersion with respect to the correct values the statistical accuracy score ci of expert i measures the probability of falsely rejecting the hypothesis that expert i is statistically accurate based on the calibration variables it ranges from 0 no chance of false rejection worst possible score to 1 statistical accuracy hypothesis is certainly true best score the informativeness score of expert i ii measures the spread of the information provided with respect to a background measure based on the assessments of all experts and the true value ii 0 indicates that expert i adds no information to the background measure the normalized performance metric wi ascribed to each expert factors his her estimates within the pool of experts and is computed as 1 w i c i i i δ c i α where δ ci α is 1 or 0 depending whether the ci of an expert is above the threshold level α and i w i 1 in this study it is adopted that the threshold δ c i α 0 meaning that no expert is left outside of the combination scheme the classical model does not judge both scores equally in fact the accuracy score ci governs the weight value because it was devised as a faster function i e it attributes the differences between experts performances to a much wider range of orders of magnitude than the ii which is confined within a smaller range of variation a more detailed account of the computation of these scores for the study using the tool excalibur cooke and solomatine 1992 freely available at www lighttwist net wp excalibur and anduryl leontaris and morales nápoles 2018 will be provided in a companion paper a limitation of the classical model is that it assumes that a set of weights built on experts ability to answer calibration questions is a reliable indicator to score the performance on the unknown target variables wittmann et al 2015 another shortcoming is intrinsic in the informativeness score i which depends on the values of the calibration variables and the responses from the other experts these aspects accentuate the importance of designing adequate calibration questions and communicating clearly with experts to encourage them to identify the need of adjusting components of the questionnaire 3 2 setting up of the expert survey for the elicitation survey a group was formed of ten experts who have wide experience on all the aspects of flood damage mechanism and who led national and international projects in research flood management construction pathology studies and emergency management table 3 before the workshop the experts were provided with a document containing detailed information of the survey protocol and about the building typologies studied damage definitions flood duration and cost analyses they were also encouraged to provide feedback on any aspects that they felt were unclear or missing and to provide recommendations for improvement the questionnaire had twelve calibration questions whose values were known only to the authors on aspects related to the flood damage mechanisms in the typologies of the study there were also 32 target questions covering three themes 1 structural and 2 content damage ratios as a function of water depth and 3 damage uncertainty specifically quantiles of the structural damage ratios 5 50 and 95 for increasing water depths 0 5 1 0 2 0 and 3 0 m on typologies 1 and 2 described below 8 variable values quantiles of contents damage ratios 5 50 and 95 for increasing water depths 0 5 1 0 2 0 and 3 0 m independently of typology 4 variable values probability values of five damage states for water depths 0 5 1 0 2 0 and 3 0 m independent of typologies 20 variable values in the next section the definitions and simplifying assumptions of the study are discussed this information was also provided to the experts before the workshop and subjected to their inputs 3 3 definitions and simplifying assumptions damage is defined as the ratio of replacement cost plus labor and the building value although frequently labor for repairs may be supplied by homeowners themselves the total value represents the market value of dwellings immediately before the flood event foundations represent 5 6 of the total house value damage to electrical or plumbing installations was not considered explicitly but as a proxy of the overall damage actions on the buildings foundations from scour chemical action and soil volume changes were considered negligible 3 3 1 flood duration flood duration is a chief driver of building damage but not always accounted for in depth damage functions flood duration was considered in this study with the intention of developing functions that represent the most frequent and less severe floods in consultation with the experts the flood duration was set to two weeks this duration roughly corresponds to discharges of the paraná river of up to 20 year return period paoli and malinow 2010 considering floods above the critical discharge variously estimated as a 25 000 34 000 m3 s mc 1979 b 25 000 m3 s aisiks 1984 with a flow series of 1904 1905 1965 1966 1976 1977 and 1982 1983 and c 32 000 m3 s halcrow 1994 with a series from 1904 to 1993 in view of the assumption of a two week flood duration the functions developed herein will underestimate damage if used with longer duration floods 3 3 2 characteristics of building typologies the typologies adopted are the most frequent dwelling types in the area of study fig 4 typology 1 unreinforced brick concrete block and typology 2 confined masonry which correspond to ufb4 ucb and cml respectively in the pager taxonomy jaiswal et al 2010 a built area of 86 m2 was adopted for both typologies based on common dimensions of local houses and based on the areas listed earlier 4 results in this section the depth damage and fragility functions derived are presented in addition by way of a broad validation they are compared with data from 1998 resistencia flood and contrasted with other functions in the literature 4 1 depth damage functions for structure and contents the outcome of the survey consists in 3 quantile estimates for each water depth and each typology table 4 the anonymized raw data is available upon request a mathematical expression was fitted to the damage ratio quantiles from table 4 to build simple depth damage functions the model adopted to describe the relationship between damage ratios d h at each water depth h is 2 d h a 1 e b h where a and b are fitting parameters note that water depth h is measured from the grade level finished floor elevation ffe is located at 0 2 m above the grade level the resulting functions are displayed in fig 5 and the model parameters in table 5 upon inspection typology 1 i e ufb4 ucb is more vulnerable than typology 2 cml as expected this difference reflects variances in construction quality typology 1 represents lower quality of building components material and probably of workmanship moreover typology 2 also exhibits less damage variability than typology 1 to characterize the resulting damage variabilities a cumulative distribution function was fitted to the 5 50 and 95 quantiles of table 3 for this the beta cumulative distribution function cdf f x α β is adopted eq 2 johnson and kotz 1970 37 as it customarily used for this same purpose in seismic damage functions atc 1985 the beta distribution is well suited to represent damage variability around a mean value as it is constrained between 0 and 1 and is flexible to accommodate the variability of low and high water depths 3 f x α β 1 b α β 0 x t α 1 1 t β 1 d t 0 x 1 where x is the damage ratio t is an auxiliary variable and b is the beta function the parameters values of eq 2 are shown in table 6 it should be noted however that the analytical quantiles of the fitted beta cdfs differ slightly from the values of the damage bounds at the stages that is from the values of eq 1 evaluated at each stage due to accuracy in the fitting process however if the approximations are deemed acceptable by a modeler the functions may provide a useful means to simulate the damage uncertainty for flood damage simulations as regards to contents a single damage function was derived for lack of information to differentiate between typical contents of both typologies in this study contents include kitchen appliances laundry room appliances living and bedroom furniture and electronics content damage is defined in a simplified way recognizing that the variety and value of contents across the building stock in the study area may not be large thus the damage is defined as the ratio between the number of damaged items which obviously were not removed from the house over the total number of items the resulting damage function taken as a proxy of the monetary value of the contents is shown in fig 6 and table 7 4 2 flood fragility functions the definitions of damage states vary considerably in the literature in this study the damage states thresholds were adopted from hazus fema 1999 and slightly modified to adequately represent the flood damage mode exerted by the slow flood increase of the paraná river on local typologies light damage 0 40 moderate damage 41 70 extensive damage 71 90 partial to total collapse 91 100 the experts found the damage states adopted acceptable the combined values from the experts is shown in table 8 the damage probabilities by damage state were approximated with a lognormal cdf with distributional parameters μ and σ a customary choice in seismic fragility functions porter et al 2007 the functions and parameter values are shown in fig 7 and table 9 respectively an assessment of the uncertainty of each fragility function was not conducted although there are techniques for accomplishing this e g mosleh and apostolakis 1986 5 validation of depth damage and fragility functions the functions derived with the classical model should not be considered to be automatically validated a feature which is essential for risk assessments and in a catastrophe model in this study however the functions are compared with damage data and other functions in the literature to judge their overall level of dependability empirical data from the resistencia flood of 1998 mentioned above was used to validate the depth damage functions up to one meter of water the data is well suited to the comparison because it was measured on a similar inventory especially typology 2 and the average flood duration is two weeks 14 3 days with a variability of 3 to 30 days an inspection of fig 8 shows a good correspondence between the trend of the functions and the data especially for typology 2 there is also a good correspondence between the variability of the data and that of the experts estimated damage variability at 0 5 m fig 9 bottom for typology 2 again these good agreements can be interpreted to provide some degree of support to the reliability of the derived depth damage functions especially up to one meter of water a further comparison has been carried out on the functions with an empirical function from mc 1979 for a flood duration of 0 4 weeks at around 0 80 m table 10 there is a reasonable agreement between the function in that study 35 40 with the mean damage functions of this study 25 35 in the mid low and mid high typologies which coincide approximately with typology 1 and 2 respectively the trend and values of the functions derived herein are also relatively similar to other functions of similar typologies in the literature usace 2015 huizinga 2017 büchele et al 2006 herath 2003 dutta et al 2003 and lie somewhere in the middle region fig 9 although not much more than this can be implied from this comparison for content damage functions there is no available damage data that can be used to validate them but they are contrasted with comparable functions in the literature even as an indirect way of comparison at least the contents damage function from this study lies somewhere in the middle region of other content damage functions in the literature fig 9 comparatively fragility functions are more challenging to validate with functions in the literature because of differing definitions of damage states but an indirect validation has been carried out an equivalent damage function was obtained convolving the fragility functions with the midpoint damage value of the damage states ranges taken at 0 0 20 0 55 0 80 and 0 95 a comparison between the equivalent function and the damage functions derived with the classical model shows that for the midpoints chosen the equivalent damage function spans both typologies fig 10 around 0 5 m fragility functions are closer to typology 2 stronger while for depth of 2 m or more they are closer to typology 1 from this comparison it can be observed that aside from the discrepancies the fragility functions lie within the uncertainty bounds of the depth damage functions shown in fig 5 this indicates that both the experts were consistent in evaluating building damage from two unrelated standpoints in the survey and that the fragility functions have some degree of reliability for representing the flood damage uncertainty of both typologies 6 discussion flood risk assessments are at the core of effective damage reduction projects and policies depth damage functions are essential pieces in these assessments across risk analysis techniques but the resources to develop them are sometimes missing in places where floods exert devastating effects not infrequently the lack of damage functions or of empirical damage data leads to a paralysis that delays projects or to the adoption of inadequate functions which may introduce invalidating biases and uncertainties in situations like these expert opinion damage data may be a viable alternative to break the modeling gridlock the literature on expert supplied flood damage functions is substantial but to our knowledge no use has been made yet of the classical model for this purpose this is one of the most popular structured expert judgment methodologies and has several advantages over other techniques transparent derivation of expert weights solid theoretical foundation small number of subjective elements for ranking experts estimates and its results can be compared directly with similar studies this paper implements this approach for the first time to our knowledge to survey and combine expert opinion damage data to build depth damage functions structure and contents and fragility functions as described above leading experts with knowledge and experience in the region provided estimates of the values of calibration and target variables in a questionnaire and their estimates were combined according to the classical model in addition this paper characterizes the structure and distribution of the most frequent residential typologies of the building inventory the resulting expert opinion based damage functions and uncertainty conform well with the few empirical damage data available moreover they are also acceptably similar to many other functions representing similar typologies and river regimes built with different methodologies fragility functions the other contribution from this paper are also consistent with the damage functions consequently these functions might be useful for flood damage assessment studies provided that the assumptions characteristics of building typologies definitions of damage flood type and duration river characteristics and flood return periods are met for these reasons it is proposed here that the use of the classical model to develop flood damage functions is encouraging and represents a viable approach when modelers face the constraints listed in the introduction limitations of the classical model and of the functions presented herein are similar to those that are inherent to all expert opinion survey methods however the classical model requires less subjective inputs and puts more control in the hands of the elicitors during the process of building expert weights this enabled us to design the survey in a way that reduced ambiguities for experts and to ensure that they properly understood the characteristics of the variables that they were estimating future studies should address the derivation of depth damage functions for similar typologies and conditions in other regions of the world for other typologies found in the area of study and for other building uses e g commercial industrial education and health also it is necessary to compare the performance of the classical model against other expert opinion methods for building flood damage functions in addition it is necessary to advance in the validation of these and other functions with adequate empirical damage data finally the analysis during flood policy formation studies of cost and time reductions versus variation in outcomes reliability that arise from using these expert opinion based functions appears useful and promising credit authorship contribution statement gonzalo l pita conceptualization methodology software supervision project administration writing review editing bárbara s albornoz methodology investigation software resources project administration juan i zaracho methodology investigation software data curation project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we are thankful to the experts who generously provided their insights and feedback we would like to acknowledge the help of bruno natalini in organizing and conducting the workshop the support and collaboration of hugo rohrmann is gratefully acknowledged this study was conducted with partial support from the universidad nacional del nordeste and conicet appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126982 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4043,depth damage relationships of residential typologies have an important bearing on the reliability of flood risk assessments yet the information for creating adequate functions is frequently missing in places where they are needed the most developing countries where floods inflict severe losses to overcome the lack of site specific functions modelers usually adopt functions from foreign typologies extrapolate from limited flood damage data and conduct expert elicitation surveys the latter although not exempt from challenges are a helpful resource in situations in which there are sufficient experts available the classical model is a structured expert judgment technique which is one of the most used because it minimizes the number of subjective elements in the ranking of experts experience and its results can be compared with similar studies this paper presents depth damage and fragility functions developed with the classical model conducted with experts with extensive knowledge in the flood damage mechanism of typologies in northeast argentina a region under a severe flood hazard the depth damage functions were partially validated with damage data and exhibited good agreement also they are consistent with the fragility functions hence these functions can be helpful for probabilistic flood risk assessments provided that the underlying assumptions are deemed acceptable 1 introduction the quantification of flood damage potential affords insights of the effects that may result from the overlap of climatic and socioeconomic systems this information is essential for designing effective structural and non structural mitigation mechanisms in damage reduction and public policy the conventional approach to estimate flood building damages is with depth damage functions however having adequate depth damage functions to describe the building typologies vulnerability is a constant challenge that stands in the way of flood risk modelers admittedly modelers who assess flood risk in countries with a long tradition of risk modeling as the united states us have at their disposal a large assortment of functions in contrast modelers in other countries must usually have recourse to repositories of functions derived for other situations for example hazus cran r project org package hazus the corps of engineers usace 2015 open global repositories e g huizinga et al 2017 pregnolato and galasso 2015 bombelli 2019 proprietary repositories penning rowsell et al 2013 and meta inventories e g gerl et al 2016 however adopting a depth damage function of certain origin typology to describe a slightly different target typology could lead to incorrect damage estimates due to disagreements between typologies and flood situations i e differences in river regimes and topography consequently the transferability of depth damage functions hinges on the goodness of the correspondence between both situations cammerer et al 2013 the methodologies to develop depth damage functions range roughly from those based on causally simulating the damage mechanism to heuristic ones they include engineering model simulations which conduct detailed load path analyses e g mazzorana et al 2014 based on machine learning amadio et al 2019 wagenaar et al 2017 fitting analytical functions on empirical damage or loss data at the individual typology level grigg and helweg 1975 davis and skaggs 1992 usace 2000 2003 lehman and nafari 2016 or at the regional level pistrika et al 2014 and expert elicitation gec 1996 1997 reese and ramsay 2010 usually the available time and resources as well as accuracy desired will dictate which methodology is adequate fragility functions unlike depth damage functions allow propagating uncertainties in loss estimates and afford insights of potential flood damages nevertheless these have not been commonly used in flood damage modeling there are recent efforts however which recognize the potential usefulness of fragility functions and have developed them with methodologies that lay in the same spectrum described above simulation of load paths nadal et al 2010 jalayer et al 2016 based on reliability methods nofal et al 2020 damage data regression on individual typology level thapa et al 2020 and regional level mcgrath et al 2019 this study inspects the vulnerability of dwellings in the region northwards of resistencia capital of the province of chaco in argentina the province of chaco is one of the most affected by floods in the country several mitigation mechanisms structural and non structural have been implemented in recent decades with varying degrees of success von lany et al 2014 penning rowsell 1996 nevertheless no specific depth damage functions have been developed at the individual typology level which could be helpful for conducting flood damage assessments this region bears many similarities with sites worldwide that have vulnerable dwellings located in the floodplain of a large river another similarity is the paucity of damage data to construct functions and the absence of adequate autochthonous depth damage functions consequently the functions derived herein could be of use in those cases specifically for latin america situations several flood damage studies have been conducted which either developed empirical functions or adopted depth damage functions among the former in brazil machado et al 2005 nascimento 2007 fadel et al 2018 and in mexico baró et al 2011 in ecuador functions were regressed on damage data pinos et al 2017 a study in uruguay established 0 80 m a threshold of complete damage piperno and sierra 2013 studies which adopted functions developed for other countries include a study for paraguay iadb 2018 in which hazus functions were used independently of flood duration in argentina depth damage functions have been developed though not fragility functions although to our knowledge without accounting for uncertainty and damage to contents these are discussed below this paper introduces damage functions developed with the classical model cooke 1991 of structured expert judgment sej on residential typologies in the following section an overview of the flood hazard and the residential building inventory in the study area are presented next a list of depth damage functions developed in previous studies in the study area is introduced the structured expert judgment analysis is then described along with the assumptions of the study it follows a description and discussion of the depth damage functions derived in this study finally a summary of recommendations and limitations of the technique and of the functions is presented 2 background the study area is a flood prone region in the eastern part of the province of chaco the region has several settlements flanked by three important rivers paraná the most influential with an average annual of 18 900 m3 s at corrientes paraguay 3 800 m3 s at pilcomayo and bermejo 320 m3 s at paraguay river fig 1 changes in the rivers regimes have taken place due to changes in the characteristics of the upstream basins and construction of control works since the early 1970s paoli and malinow 2010 lopardo and seoane 2000 floods occurred in the last five decades in chaco have exerted substantial economic losses and population displacement but fortunately few fatalities see table 1 for references on direct damages for indirect damages see e g caputo et al 1985 celis 2006 de mari 2001 the region has suffered floods since long page 1889 the most impactful being those of 1905 and 1966 1977 1983 1992 and 1998 depettris et al 2000 fig 2 the infrastructure characteristics and flood risk situation are similar in the neighboring provinces corrientes formosa and misiones 2 1 characteristics of the building inventory in the study area the study area comprises populated centers near resistencia and include semi urban towns margarita belen colonia benitez las palmas la leonesa general vedia and rural towns puerto bermejo isla del cerrito puerto eva peron the majority of dwellings are single family and were built by federal housing developments fondo nacional de la vivienda especially after 1984 and federal loan programs procrear since 2012 mingo et al 2018 fig 4 a previous study found that the inventory was composed of precarious houses 80 to 85 mid low quality and 15 20 and no high quality dwellings mc 1979 in this study the building inventory was surveyed with aerial imagery google street view census 2010 data and in person reconnaissance in one town colonia benitez table 2 as per the survey the most frequent dwelling type is a single story unreinforced masonry with brick and block walls ufb4 ucb sheet metal roof wooden openings without basement the second most common type especially in towns near resistencia are confined masonry dwellings of one and two stories cml square footage was not surveyed but available information of similar dwellings in resistencia affords an approximation in the greater resistencia metropolitan area the average built area is 120 m2 fig 3 rohrman et al 1998 when classified by building quality the built areas are 3 of precarious dwellings up to 40 m2 9 medium low between 40 and 60 m2 18 medium high between 60 m2 and 90 m2 and the 70 of higher quality dwellings 100 m2 for the province precarious 30 m2 medium low 60 m2 and medium high 90 m2 mc 1979 another study found that in santa fe province whose building inventory is similar to that in the study area the average area of precarious and mid quality dwellings was 25 m2 and 64 2 m2 respectively halcrow 1994 the predominant foundation types for one story dwellings are piles and grade beam when soil resistance is low concrete slab is used for two story reinforced concrete isolated footing and deep piles foundations for taller buildings 3 stories a small number of houses from the late 19th and early 20th centuries can still be found these dwellings have strip footing brick or concrete as foundation types 2 2 previous flood risk studies in the region three flood studies of the nea region that used depth damage functions to predict damage were identified in the evaluation study for the dam and hydroelectric power station yacyreta areal depth damage functions were developed fitting data from the floods of 1966 and 1977 mc 1979 another study regressed empirical data of the 1977 and 1983 floods aisiks 1984 the last study halcrow 1994 adapted empirical and expert supplied functions of buildings in the united kingdom penning rowsell and chatterton 1977 the functions developed in these studies however are too coarse outdated and geared towards a deterministic approach and as such they are not valid for quantifying flood damages within a probabilistic simulation there exists also damage data available from a survey conducted on the 1998 resistencia flood by rohrmann et al 1998 that could be used for developing an empirical relationship however this data collected on a single building typology represents a limited range of water depths up to 1 m and so a significant extrapolation beyond the region of data must be made moreover the choice of extrapolation procedure is critical hence the empirical data cannot be used as the sole resource to build a damage function although it can be used as data for validation as is done below 3 derivation of depth damage and fragility functions in view of the situation described above an expert elicitation methodology was applied in this study to develop a new set of depth damage relationships for the most common typologies of the region expert opinion elicitation is an alternative for supplying data to address technical problems for which the variables of interest cannot be measured or when the methodology for measuring them is expensive or impractical surveys consist of two key parts selection of relevant experts and conduction of a questionnaire with the target quantities and combination of the expert estimates to get an estimate of the target variables of interest in the flood risk modeling community the use of expert opinion to build depth damage relationships is established of which the us army corps of engineers is a pioneer e g usace 2006 2015 3 1 use of classical model to build depth damage and fragility functions several approaches have been created to aggregate expert opinion clemen and winkler 1999 o hagan et al 2006 each with strengths and weaknesses arising from underlying assumptions bedford and cooke 2001 morgan 2014 the method developed by cooke 1991 known as the classical model of structured expert judgment was applied in this study to combine expert estimates the reason for selecting it lies in that it is a performance based weighting technique which minimizes the use of subjective elements for determining the weights to combine the experts opinions moreover there is considerable experience about the model as it has been used in many applications it was tested extensively and was found to outperform other methods colson and cooke 2018 finally its formal structure is a consistent and transparent framework that facilitates that its results can be unambiguously compared with other future damage studies the classical model has been successfully used for developing seismic damage functions jaiswal et al 2014 but to our knowledge not for flood depth damage functions at least not the type of functions typologies and granularity proposed herein the technique has a strong foundation in information theory aspinall 2008 unlike other approaches the classical model requires that besides the target variables the experts also judge the value of several calibration variables whose correct value is known only by the survey facilitators the latter are considered samples of random distributions and serve to compute two scores that weight each expert s estimates in terms of accuracy and dispersion with respect to the correct values the statistical accuracy score ci of expert i measures the probability of falsely rejecting the hypothesis that expert i is statistically accurate based on the calibration variables it ranges from 0 no chance of false rejection worst possible score to 1 statistical accuracy hypothesis is certainly true best score the informativeness score of expert i ii measures the spread of the information provided with respect to a background measure based on the assessments of all experts and the true value ii 0 indicates that expert i adds no information to the background measure the normalized performance metric wi ascribed to each expert factors his her estimates within the pool of experts and is computed as 1 w i c i i i δ c i α where δ ci α is 1 or 0 depending whether the ci of an expert is above the threshold level α and i w i 1 in this study it is adopted that the threshold δ c i α 0 meaning that no expert is left outside of the combination scheme the classical model does not judge both scores equally in fact the accuracy score ci governs the weight value because it was devised as a faster function i e it attributes the differences between experts performances to a much wider range of orders of magnitude than the ii which is confined within a smaller range of variation a more detailed account of the computation of these scores for the study using the tool excalibur cooke and solomatine 1992 freely available at www lighttwist net wp excalibur and anduryl leontaris and morales nápoles 2018 will be provided in a companion paper a limitation of the classical model is that it assumes that a set of weights built on experts ability to answer calibration questions is a reliable indicator to score the performance on the unknown target variables wittmann et al 2015 another shortcoming is intrinsic in the informativeness score i which depends on the values of the calibration variables and the responses from the other experts these aspects accentuate the importance of designing adequate calibration questions and communicating clearly with experts to encourage them to identify the need of adjusting components of the questionnaire 3 2 setting up of the expert survey for the elicitation survey a group was formed of ten experts who have wide experience on all the aspects of flood damage mechanism and who led national and international projects in research flood management construction pathology studies and emergency management table 3 before the workshop the experts were provided with a document containing detailed information of the survey protocol and about the building typologies studied damage definitions flood duration and cost analyses they were also encouraged to provide feedback on any aspects that they felt were unclear or missing and to provide recommendations for improvement the questionnaire had twelve calibration questions whose values were known only to the authors on aspects related to the flood damage mechanisms in the typologies of the study there were also 32 target questions covering three themes 1 structural and 2 content damage ratios as a function of water depth and 3 damage uncertainty specifically quantiles of the structural damage ratios 5 50 and 95 for increasing water depths 0 5 1 0 2 0 and 3 0 m on typologies 1 and 2 described below 8 variable values quantiles of contents damage ratios 5 50 and 95 for increasing water depths 0 5 1 0 2 0 and 3 0 m independently of typology 4 variable values probability values of five damage states for water depths 0 5 1 0 2 0 and 3 0 m independent of typologies 20 variable values in the next section the definitions and simplifying assumptions of the study are discussed this information was also provided to the experts before the workshop and subjected to their inputs 3 3 definitions and simplifying assumptions damage is defined as the ratio of replacement cost plus labor and the building value although frequently labor for repairs may be supplied by homeowners themselves the total value represents the market value of dwellings immediately before the flood event foundations represent 5 6 of the total house value damage to electrical or plumbing installations was not considered explicitly but as a proxy of the overall damage actions on the buildings foundations from scour chemical action and soil volume changes were considered negligible 3 3 1 flood duration flood duration is a chief driver of building damage but not always accounted for in depth damage functions flood duration was considered in this study with the intention of developing functions that represent the most frequent and less severe floods in consultation with the experts the flood duration was set to two weeks this duration roughly corresponds to discharges of the paraná river of up to 20 year return period paoli and malinow 2010 considering floods above the critical discharge variously estimated as a 25 000 34 000 m3 s mc 1979 b 25 000 m3 s aisiks 1984 with a flow series of 1904 1905 1965 1966 1976 1977 and 1982 1983 and c 32 000 m3 s halcrow 1994 with a series from 1904 to 1993 in view of the assumption of a two week flood duration the functions developed herein will underestimate damage if used with longer duration floods 3 3 2 characteristics of building typologies the typologies adopted are the most frequent dwelling types in the area of study fig 4 typology 1 unreinforced brick concrete block and typology 2 confined masonry which correspond to ufb4 ucb and cml respectively in the pager taxonomy jaiswal et al 2010 a built area of 86 m2 was adopted for both typologies based on common dimensions of local houses and based on the areas listed earlier 4 results in this section the depth damage and fragility functions derived are presented in addition by way of a broad validation they are compared with data from 1998 resistencia flood and contrasted with other functions in the literature 4 1 depth damage functions for structure and contents the outcome of the survey consists in 3 quantile estimates for each water depth and each typology table 4 the anonymized raw data is available upon request a mathematical expression was fitted to the damage ratio quantiles from table 4 to build simple depth damage functions the model adopted to describe the relationship between damage ratios d h at each water depth h is 2 d h a 1 e b h where a and b are fitting parameters note that water depth h is measured from the grade level finished floor elevation ffe is located at 0 2 m above the grade level the resulting functions are displayed in fig 5 and the model parameters in table 5 upon inspection typology 1 i e ufb4 ucb is more vulnerable than typology 2 cml as expected this difference reflects variances in construction quality typology 1 represents lower quality of building components material and probably of workmanship moreover typology 2 also exhibits less damage variability than typology 1 to characterize the resulting damage variabilities a cumulative distribution function was fitted to the 5 50 and 95 quantiles of table 3 for this the beta cumulative distribution function cdf f x α β is adopted eq 2 johnson and kotz 1970 37 as it customarily used for this same purpose in seismic damage functions atc 1985 the beta distribution is well suited to represent damage variability around a mean value as it is constrained between 0 and 1 and is flexible to accommodate the variability of low and high water depths 3 f x α β 1 b α β 0 x t α 1 1 t β 1 d t 0 x 1 where x is the damage ratio t is an auxiliary variable and b is the beta function the parameters values of eq 2 are shown in table 6 it should be noted however that the analytical quantiles of the fitted beta cdfs differ slightly from the values of the damage bounds at the stages that is from the values of eq 1 evaluated at each stage due to accuracy in the fitting process however if the approximations are deemed acceptable by a modeler the functions may provide a useful means to simulate the damage uncertainty for flood damage simulations as regards to contents a single damage function was derived for lack of information to differentiate between typical contents of both typologies in this study contents include kitchen appliances laundry room appliances living and bedroom furniture and electronics content damage is defined in a simplified way recognizing that the variety and value of contents across the building stock in the study area may not be large thus the damage is defined as the ratio between the number of damaged items which obviously were not removed from the house over the total number of items the resulting damage function taken as a proxy of the monetary value of the contents is shown in fig 6 and table 7 4 2 flood fragility functions the definitions of damage states vary considerably in the literature in this study the damage states thresholds were adopted from hazus fema 1999 and slightly modified to adequately represent the flood damage mode exerted by the slow flood increase of the paraná river on local typologies light damage 0 40 moderate damage 41 70 extensive damage 71 90 partial to total collapse 91 100 the experts found the damage states adopted acceptable the combined values from the experts is shown in table 8 the damage probabilities by damage state were approximated with a lognormal cdf with distributional parameters μ and σ a customary choice in seismic fragility functions porter et al 2007 the functions and parameter values are shown in fig 7 and table 9 respectively an assessment of the uncertainty of each fragility function was not conducted although there are techniques for accomplishing this e g mosleh and apostolakis 1986 5 validation of depth damage and fragility functions the functions derived with the classical model should not be considered to be automatically validated a feature which is essential for risk assessments and in a catastrophe model in this study however the functions are compared with damage data and other functions in the literature to judge their overall level of dependability empirical data from the resistencia flood of 1998 mentioned above was used to validate the depth damage functions up to one meter of water the data is well suited to the comparison because it was measured on a similar inventory especially typology 2 and the average flood duration is two weeks 14 3 days with a variability of 3 to 30 days an inspection of fig 8 shows a good correspondence between the trend of the functions and the data especially for typology 2 there is also a good correspondence between the variability of the data and that of the experts estimated damage variability at 0 5 m fig 9 bottom for typology 2 again these good agreements can be interpreted to provide some degree of support to the reliability of the derived depth damage functions especially up to one meter of water a further comparison has been carried out on the functions with an empirical function from mc 1979 for a flood duration of 0 4 weeks at around 0 80 m table 10 there is a reasonable agreement between the function in that study 35 40 with the mean damage functions of this study 25 35 in the mid low and mid high typologies which coincide approximately with typology 1 and 2 respectively the trend and values of the functions derived herein are also relatively similar to other functions of similar typologies in the literature usace 2015 huizinga 2017 büchele et al 2006 herath 2003 dutta et al 2003 and lie somewhere in the middle region fig 9 although not much more than this can be implied from this comparison for content damage functions there is no available damage data that can be used to validate them but they are contrasted with comparable functions in the literature even as an indirect way of comparison at least the contents damage function from this study lies somewhere in the middle region of other content damage functions in the literature fig 9 comparatively fragility functions are more challenging to validate with functions in the literature because of differing definitions of damage states but an indirect validation has been carried out an equivalent damage function was obtained convolving the fragility functions with the midpoint damage value of the damage states ranges taken at 0 0 20 0 55 0 80 and 0 95 a comparison between the equivalent function and the damage functions derived with the classical model shows that for the midpoints chosen the equivalent damage function spans both typologies fig 10 around 0 5 m fragility functions are closer to typology 2 stronger while for depth of 2 m or more they are closer to typology 1 from this comparison it can be observed that aside from the discrepancies the fragility functions lie within the uncertainty bounds of the depth damage functions shown in fig 5 this indicates that both the experts were consistent in evaluating building damage from two unrelated standpoints in the survey and that the fragility functions have some degree of reliability for representing the flood damage uncertainty of both typologies 6 discussion flood risk assessments are at the core of effective damage reduction projects and policies depth damage functions are essential pieces in these assessments across risk analysis techniques but the resources to develop them are sometimes missing in places where floods exert devastating effects not infrequently the lack of damage functions or of empirical damage data leads to a paralysis that delays projects or to the adoption of inadequate functions which may introduce invalidating biases and uncertainties in situations like these expert opinion damage data may be a viable alternative to break the modeling gridlock the literature on expert supplied flood damage functions is substantial but to our knowledge no use has been made yet of the classical model for this purpose this is one of the most popular structured expert judgment methodologies and has several advantages over other techniques transparent derivation of expert weights solid theoretical foundation small number of subjective elements for ranking experts estimates and its results can be compared directly with similar studies this paper implements this approach for the first time to our knowledge to survey and combine expert opinion damage data to build depth damage functions structure and contents and fragility functions as described above leading experts with knowledge and experience in the region provided estimates of the values of calibration and target variables in a questionnaire and their estimates were combined according to the classical model in addition this paper characterizes the structure and distribution of the most frequent residential typologies of the building inventory the resulting expert opinion based damage functions and uncertainty conform well with the few empirical damage data available moreover they are also acceptably similar to many other functions representing similar typologies and river regimes built with different methodologies fragility functions the other contribution from this paper are also consistent with the damage functions consequently these functions might be useful for flood damage assessment studies provided that the assumptions characteristics of building typologies definitions of damage flood type and duration river characteristics and flood return periods are met for these reasons it is proposed here that the use of the classical model to develop flood damage functions is encouraging and represents a viable approach when modelers face the constraints listed in the introduction limitations of the classical model and of the functions presented herein are similar to those that are inherent to all expert opinion survey methods however the classical model requires less subjective inputs and puts more control in the hands of the elicitors during the process of building expert weights this enabled us to design the survey in a way that reduced ambiguities for experts and to ensure that they properly understood the characteristics of the variables that they were estimating future studies should address the derivation of depth damage functions for similar typologies and conditions in other regions of the world for other typologies found in the area of study and for other building uses e g commercial industrial education and health also it is necessary to compare the performance of the classical model against other expert opinion methods for building flood damage functions in addition it is necessary to advance in the validation of these and other functions with adequate empirical damage data finally the analysis during flood policy formation studies of cost and time reductions versus variation in outcomes reliability that arise from using these expert opinion based functions appears useful and promising credit authorship contribution statement gonzalo l pita conceptualization methodology software supervision project administration writing review editing bárbara s albornoz methodology investigation software resources project administration juan i zaracho methodology investigation software data curation project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we are thankful to the experts who generously provided their insights and feedback we would like to acknowledge the help of bruno natalini in organizing and conducting the workshop the support and collaboration of hugo rohrmann is gratefully acknowledged this study was conducted with partial support from the universidad nacional del nordeste and conicet appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126982 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4044,spatial and temporal droughts during rainy seasons are important climatic aspects to consider in water resources management the dry spell index a time independent index that considers the characteristic of dry days dry spell seasonal length and evaporation rate in drought severity estimation is supporting the analyses of the spatiotemporal variations of drought severity in the rainy season of the indonesian maritime continent imc between 1998 and 2018 the rainy season was determined using a modified anomalous accumulation the results showed that an increase in dry spells produced a consistently increasing temporal drought during the rainy season across the imc meanwhile spatial variation suggested that although there is an increase in the rainy season total accumulated precipitation and duration a large area within the monsoon regime also experiences increased drought severity indicating more frequent extreme precipitation regional drought severity was classified as normal with a tendency of an increasing area under dry categories overall the rainy season drought has increased in the imc from 1998 to 2018 elevating the threats of reduced agricultural production keywords drought dry spell index rainy season indonesian maritime continent 1 introduction droughts are unpredictable recurring natural phenomena caused by a deficiency in precipitation which results in long term decreases in water storage compared to other natural disasters droughts are creeping phenomena that progress slowly and for which it is more difficult to determine start and end dates droughts also cover wider areas than most other disasters mishra and singh 2010 ostad ali askari et al 2020 tsakiris 2017 vicente serrano and lópez moreno 2005 therefore droughts may occur anytime and anywhere in addition no single drought definition is universally acceptable tsakiris et al 2013 making it difficult to quantify and monitor drought progression and severity as a result the droughts have caused the loss of both lives and property around the world drought has caused enormous financial losses around the world with an estimated annual loss of between 137 million and 8 billion us dollars dai 2011 guo et al 2017 tsakiris 2017 several indices have been used globally to estimate drought severity these indices are generated from either a single variable or a combination of drought related variables hao and singh 2015 precipitation is the main parameter controlling drought development and the primary input used in drought indices therefore most indices require accumulated precipitation over a particular period however accumulated precipitation based indices fail to detect drought generation over shorter time scales huang et al 2015 thus they are not appropriate to evaluate changes in global precipitation patterns such as increases in extreme precipitation and poorer precipitation distribution across time and space due to global warming occurrences of both extreme precipitation events trenberth 2011 ye and fetzer 2019 and days without precipitation zhou et al 2019 are increasing unfortunately when accumulated precipitation is used as a metric drought development is usually masked by an increase in accumulated precipitation due to these extreme events therefore the increasing length of dry spells which denote a period of consecutive days without precipitation or with precipitation below a threshold is not captured poor precipitation distribution over time and space resulting from high precipitation variability increases dry spell frequency and durations even during the rainy season as global precipitation patterns change dry spell studies become increasingly important to establish a sound understanding of drought through temporal trends and spatial variation in dry spell occurrence li et al 2017 previous dry spell studies primarily identified maximum duration and frequency kebede et al 2017 mupangwa et al 2011 ngetich et al 2014 raymond et al 2016 these studies typically focus on the dry season during which dry spells are common however dry spells during the rainy season can also be important in the development of drought conditions dry spells during the rainy season impact water availability as well as crop growth and production in some parts of the world for example byakatonda et al 2018 found some locations in botswana are experiencing increasing trends in dry spell frequency during the rainy season rendering these areas unsuitable for rainfed farming some stations in the upper baro akobo basin ethiopia showed increasing trends in the maximum duration and frequency of dry spells during the rainy season although the trends were not statistically significant indicating the need for better water management planning to minimize future climate risks kebede et al 2017 hence dry spells have become an important indicator to understand the dryness of the rainy season particularly in regions where rainy season precipitation is the primary source of water focussing only on the extreme dry spell duration would neglect dry spells with shorter duration as most dry spells are very short in duration li et al 2017 and even these short rainy season dry spells can have destructive impacts on agriculture and water resources engelbrecht et al 2006 thus it is important to consider all dry spells when assessing rainy season drought conditions a dry spell index dsi ferijal et al 2021 was created to quantify the severity of dryness in the presence of substantial precipitation variability it takes into account the characteristics of dry days dry spells and seasonal length hence the index is more flexible in the period of analysis and able to handle small changes in precipitation distribution however the index does not include the air temperature in the estimation drought development is exacerbated by increased air temperatures which change the driving force from precipitation deficiency to atmospheric demand leading to higher evaporation losses dai and zhao 2017 trenberth et al 2014 easterling et al 2007 found that the increase in drought frequency in the us during the period 1950 2006 was mainly driven by increasing air temperatures amrit et al 2018 found a significant relationship between the variation in annual temperature and drought intensity meanwhile in the pearl river basin southern china the variation in temperature contributed more significantly than precipitation to increased drought severity and duration wu and chen 2019 a combination of increased temperature and decreased precipitation has caused drought to be more prevalent in the loess plateau northern china sun and ma 2015 in the more extreme case severe water scarcity impacted 9 65 million residents and 39 94 million hectares of crops in the yunan province of china due to high temperatures and low precipitation ali et al 2020 thus it is important to integrate temperature into drought indices dabanli 2019 showed a strong relationship between temperature differences and hydro meteorological variables such as dry spells which allows the integration of the temperature function in the dsi the objective and novelty of this study is therefore to evaluate spatial and temporal variations in rainy season drought severity caused by the variation of dry spells during the rainy season using the dsi because of its strong correlation with dry spells another innovation of this research is to use the evaporation rate for defining the weight of consecutive dry days in the dsi calculation this approach is applied to the indonesian maritime continent imc as a study area the imc is one of the rainiest areas on earth and highly influenced by local and global air circulation resulting in high spatiotemporal variation in rainy season precipitation 2 study area indonesia is an archipelago that has more than 17 000 large and small islands it geographically covers a region of 6 n 11 s and 95 141 e and has an area of approximately 2 million km2 fig 1 it consists of the five big islands java sumatera kalimantan sulawesi and irian jaya and is characterized by complex topography java is the most populous island and plays a very important role in agricultural and industrial activities the complex interaction between land and sea in the imc caused this area to be depicted as a miniature of the earth in which land and sea coexist side by side yamanaka 2016 because the imc is sandwiched between two continents asia and australia and two oceans the pacific and indian the precipitation is strongly affected by the movement of the inter tropical convergence zone itcz when the itcz is in its southernmost position the northwest monsoon bring moisture from the south china sea and the pacific ocean causing wet periods in this region which peak in january and february conversely when the itcz is in its northernmost position the southeast monsoon brings dry winds from australia causing relatively dry periods in this area especially in july and august however most of the imc receives rain throughout the year in addition indonesia is also located between the indo and pacific warm pools and hence receives a lot of water vapor originating from the surrounding oceans thus indonesia is one of the highest rainfall areas in the world the imc also experiences high variability in precipitation with three types of precipitation characteristics occurring monsoon anti monsoon and semi annual aldrian and dwi susanto 2003 supari et al 2018 the monsoon and anti monsoon regimes have one precipitation peak which occurs during dec feb and jun jul respectively while the semi annual regime has two precipitation peaks in one year which occur in oct nov and mar may the imc has relatively constant air temperatures both in space and time daily air average temperature ranges from 23 c in the mountainous region to 31 c near the coast the average annual temperature amplitude is small with humidity generally greater than 90 this tropical climate region gets enough sunshine all year round making it very suitable for agriculture activities however future projected climate change and global circulation will intensify the modulation of precipitation anomalies potentially impacting the agriculture production in this region naylor et al 2007 3 data and methodology 3 1 data this study used daily precipitation sourced from the tropical rainfall measuring mission trmm multi satellite precipitation analysis tmpa 3b42 v7 https mirador gsfc nasa gov for the time period 1998 2018 this trmm product has been widely used for precipitation analysis because of its accuracy sahoo et al 2015 gleams data https www gleam eu was used to extract daily actual evaporation data from 1998 to 2014 both data have 0 25 spatial resolution and were extracted for the imc region only the analysis of precipitation data was performed on the inland area only by making use of the gleams data as a mask 3 2 methodology 3 2 1 definition of rainy season the onset and cessation of the rainy season were determined using the anomalous accumulation method applied for each climatological year the climatological year starts from the driest period in the current year and ends before the next driest period we selected july august as the driest period for monsoon and semi annual regimes and november december as the driest period for the anti monsoon regime to accommodate the temporal variation between these driest periods we allow the climatological year to overlap for those months thus the climatological year is defined as the period from 1 june to 30 august of the following year for monsoon and semi annual regimes and from 1 november to 31 december of the following year for the anti monsoon regime therefore there will be two overlapping periods the first period in the beginning and the second at the end of the climatological year the anomalous accumulation method uses the accumulation of the daily precipitation anomaly to determine the onset and cessation of the rainy season the rainy season is the period with the most intense precipitation characterized by an increase in anomalous accumulation the onset of the rainy season is marked by the day after which the anomalous accumulation increases the increase continues to a maximum point called the cessation i e the moment when the anomalous accumulation decreases to deal with a strong variation in precipitation over the study area we applied a modified anomalous accumulation method to determine the rainy season this method involves the following steps fig 2 1 calculating daily precipitation accumulation using the formula 1 a t n 0 t r n r where a t is the precipitation accumulation anomaly until time t r n is the precipitation on day n and r is the average daily precipitation 2 smoothing the anomaly accumulation curve by taking a 30 day running average of anomalous accumulation this smoothed curve helps to define multiple periods of intense precipitation characterized by a continuous increase in 30 day running average of anomalous accumulation using a method proposed by dunning et al 2016 two or more periods of intense precipitation are merged if they form a continuous increase in the 30 day running average of anomalous accumulation and the gap between the end of the first period and the start of the next period is less than 5 days 3 the starting and ending dates of each period of intense precipitation were defined by determining the minimum and maximum daily precipitation accumulation respectively corresponding to the start and end of the period of intense precipitation 4 the rainy season period was selected based on the start and end dates that form a longest continuous increasing in anomalous accumulation to prevent the same rainy season for two consecutive climatological years no onset is allowed within the second overlapping period for the semi annual regime the onset of the rainy season should occur before february this approach allows the onset of the rainy season to occur at any time during the defined climatological year the onset date will vary highly from year to year depending on the precipitation characteristic of the year likewise for regions with high precipitation the rainy season tends to have a longer duration 3 2 2 dry spell index the dry spell index was used to estimate dryness severity during the rainy season this method is time independent and therefore can accommodate strong variation in the onset and cessation of the rainy season the dsi is calculated as 2 dsi 1 rsl i 1 ndd w i where ndd is the number of dry days rsl is the rainy season length and wi is the weight assigned for each day within a given dry spell instead of using sequential numbers for the weight in this study the weights were obtained from the relationship between the dry spell and the evaporation rate this is based on the assumption that increasing dryness severity is equivalent to the water lost due to evaporation evaporation rates for each dry day in all dry spells during the rainy season were extracted for 50 randomly selected points over the land area of the imc for every dry spell of at least 3 dry days the weight of the dry day was calculated as 3 w i e i e 1 where wi is weight on ith day ei and e1 are the average daily evaporation rates for the ith and 1st day in the dry spell respectively hence the weight of the first dry day w1 within any dry spell will always equal 1 the number of dry spells greater than 10 days long was very small 0 15 hence the relationship between dry spell and evaporation rate was generated from the first 10 dry days only the dsi values were calculated and tested for normal distribution using the shapiro wilk and anderson darling tests once the normality was confirmed the dsi values were then classified into drought severity classes the threshold of each drought severity class was determined based on its probability according to the spi classification table 1 3 2 3 trend analysis the average total precipitation over the rainy season and average dry spell index for all precipitation regimes were plotted for the period 1998 2018 mann kendall mk trend tests were used to detect the possibility of trends in the time series mk is a non parametric trend test that is distribution free and has been widely used to detect monotonic trends in many hydro climatological time series the mk test was applied on the original time series with the assumption that the data is serially independent because it was derived from onset data of rainy seasons which are independent from each other the test assesses the null hypothesis h0 that no trend exists in the time series the h0 will be rejected if the absolute standardized test statistic zs is greater than the critical value zcrit at significance level α 2 for the normal distribution we selected 90 for α and the standardized test statistic was calculated as 4 z s s 1 var s i f s 0 0 i f s 0 s 1 var s i f s 0 where s is the statistic of the test defined as 5 s i 1 n 1 j i 1 n s i g n x j x i where x j and x i are sequential data in time series the statistic s has a mean equal to zero and a variance 6 var s n n 1 2 n 5 j 1 m t j t j 1 2 t j 5 18 where tj is the number of tied observations n is the number of data and m is the number of tied data values the sign of the zs value indicates the direction of change positive or negative 4 results 4 1 rainy season onset length and total precipitation the mean onset of the rainy season over the imc showed a clear spatial difference between the western and eastern regions fig 3 the pattern of onset propagation is generally in agreement with the existing description the onset propagation usually starts in the northern part of the region and moves southward before turning easter over java toward the eastern part of the region this movement causes an august onset in northern sumatera and a september to early october onset in central and southern sumatera in most of western borneo the onset of the rainy season is in mid september to early january while in central and southern sulawesi the onset is in mid october to early january for northern sulawesi and the rest of the eastern imc the rainy season starts between the end of may and the end of july interestingly a small part of western java and the central lesser sunda islands have a july onset which is out of the pattern however most of java and the lesser sunda islands have a rainy season beginning somewhere in august to november only a small portion of the easternmost lesser sunda islands timor island has an onset period that extends to early january the rainy season lengths vary from 48 to 182 days fig 4 the locations that have rainy seasons up to 6 months long were found in central kalimantan while only a few locations have rainy seasons less than 2 months long such as in middle and eastern java southern sulawesi and central irian jaya rainy seasons in the monsoon and anti monsoon regimes generally last from 70 to 90 days while the semi annual regime has longer rainy seasons which are up to 160 days long kalimantan and northern sumatera have stable precipitation throughout the year as syakur et al 2013 mandapaka et al 2017 hence most of this area does not have a distinct wet or dry season in comparison the southern hemisphere is characterized by a more pronounced wet and dry season in which the precipitation events mostly occur during the rainy season a significant increasing trend in the length of the rainy season was found in northern and southern sumatera java and some parts of the lesser sunda islands fig 4 this trend was also found in the eastern region of the imc distributed over sulawesi and irian jaya significant decreasing trends were found mostly in the central parts of three main islands sumatera kalimantan and irian jaya therefore although most of the southern regions have a shorter rainy season than the northern ones there is a tendency for the duration of the southern rainy season including southern sumatra java bali and the lesser sunda islands to become longer this increasing trend is not typically found in the northern region interestingly significant decreasing trends were found in some parts of sumatra kalimantan and irian jaya the precipitation accumulation during the rainy season is positively correlated with the duration of the rainy season in the areas where rainy season duration is long the total rainy season precipitation is significantly higher than other areas in the imc and vice versa high accumulated precipitation during the rainy season occurred mainly in central kalimantan and northern sumatera these areas have many annual wet days which consistently produce a high total annual precipitation mandapaka et al 2017 meanwhile low precipitation was detected in the central zone of the imc including sulawesi northern maluku and timor fig 5 significant increasing and decreasing trends in rainy season precipitation were found across the region however increasing trends dominate over all the main islands of the imc region while decreasing trends were mostly found in central sumatera and northern kalimantan the temporal variability of the average rainy season total precipitation over the whole region has not changed for the period 1998 2018 fig 6 a regional temporal variation showed that the total precipitation was very low in 2015 and relatively high in 2010 and 2012 total precipitation during the rainy season is between 1800 and 2000 mm which is approximately 65 72 of total annual precipitation the monsoon and semi annual rainy season precipitation showed increasing slopes fig 6b d while the anti monsoon precipitation had a decreasing slope fig 6c but none of those slopes were significant the rainy season precipitation in the semi annual regime which is mostly found in the northern hemisphere was relatively constant with an average total precipitation of 2200 mm year this mean rainy season precipitation is 12 to 18 higher than the precipitation in the monsoon and anti monsoon regimes for both monsoon and anti monsoon regimes strong temporal variation was observed 4 2 evaporation rates dry spells during the rainy season over the imc were dominated by very short spells approximately 93 of total dry days were 1 to 3 day dry spells a short dry spell potentially evaporates less water than a longer dry spell the rate of daily evaporation increases with the increase in dry spell duration fig 7 however the increase is not completely linear for the first four days the evaporation rate was approximately 3 6 mm day but then increased to 4 mm day from the 5th day forward the mean and standard deviation ranged from 3 5 to 4 3 mm day and from 0 71 to 0 89 respectively the variability of the average daily evaporation was strongly affected by the condition of the preceding wet days which affected the available water for evaporation the wetter the preceding conditions the greater the availability of water and the higher the evaporation rate the variability increased when all dry spell durations were used in the analysis the ratio of the evaporation rate of the first ten dry days to the evaporation rate of the first dry day could be best explained by the equation y 0 99x0 08 with a coefficient of determination of 0 83 4 3 dry spell index dsi the mean dsi ranged from 0 18 to 0 66 with lower dsi values corresponding to lower potential drought severity the spatial distribution of dsi showed an opposite pattern to the rainy season total precipitation high dsi values were randomly scattered throughout the imc mainly in southern sumatera western java sulawesi east timor and north maluku while low dsi values were concentrated in southern kalimantan and central sumatera fig 8 however the spatial variation of low dsi was not comparable to the spatial variation of high precipitation areas high precipitation areas distributed over central and northern kalimantan and northern sumatera fig 5 had a weak spatial relationship to the low dsi area which was concentrated in southern kalimantan the distribution of high dsi areas on the other hand was strongly correlated with the distribution of low precipitation areas significant increasing and decreasing trends in dsi were found over the imc region significant increasing trends were mostly found in the southern part of the imc region which is mostly the monsoon area with the exception of northern sumatera high dsi areas tended to have increasing trends and vice versa temporal variation showed a dsi increase of approximately 2 for the period 1998 2018 at the imc scale fig 9 a the increases were also observed in all precipitation regimes particularly in the monsoon 2 5 fig 9b and anti monsoon 2 2 fig 9c regimes across the whole imc several years show a high dsi i e 2002 2004 and 2015 fig 9a meanwhile the lowest dsi occurred in 1999 the dsi in the anti monsoon area exhibited a similar peak trough pattern to the overall imc but with stronger variation in both peaks and troughs this pattern seems to be the source of temporal variation at the regional scale the combination of strong annual variation and recurring 12 year cycles found in the anti monsoon regime is a strong indication of the influence of larger atmospheric circulation this recurring pattern was also found in the temporal variation of the total rainy season precipitation fig 5 4 4 impact of enso modulation the enso significantly impacts the climate over the imc region yamanaka 2016 tangang et al 2017 supari et al 2018 the modulation of enso should therefore be captured by drought indices the oceanic nino index oni which is used to measure enso is the 3 month running average of the extended reconstructed sea surface temperature ersst the ersst v 5 anomaly for the niño 3 4 region 5 n 5 s 120 170 w which is available from the noaa enso web page https origin cpc ncep noaa gov products analysis monitoring ensostuff oni v5 php was used the response of total precipitation and dsi to enso variations were compared using the correlation between total precipitation and dsi versus the oni this was done by taking the square of the correlation between the total precipitation and dsi versus the oni for all years the results indicated that oni is more correlated to the dsi than total precipitation fig 10 the correlation between oni versus total precipitation and oni versus dsi increased during the rainy season for all precipitation regimes mid june dec for monsoon and semi annual and mid may july for anti monsoon this indicated that dsi responded to drought variations induced by enso modulation both changes in precipitation or dry days much better than total precipitation did 4 5 spatial distribution of dry spell based drought severity the calculated dsi values ranged from 0 02 to 0 92 with a mean of 0 37 and a standard deviation of 0 11 the total number of estimated dsi values was nearly 91 000 this is a very large sample size which is not appropriate for any normality test as insignificant deviations from normality may significantly impact the test results garson 2012 therefore instead of using all of the data the normality test was performed on a subset of the data which was generated by randomly selecting 10 from the total population of dsi the shapiro wilk and anderson darling tests were selected to prove the normality of this subset the processes of subset generation and normality test were repeated 100 times the normal distribution assumption was not rejected by the shapiro wilk and anderson darling tests in 71 and 88 of all cases respectively indicating that the total population of dsi is normally distributed the drought severity of each pixel was determined by taking the standardized value of the dsi and classifying according to the classes of table 1 the area of each drought severity class was calculated for each year the spatial drought severity based mean dsi showed that most of the region is classified into mild wet and mild drought classes although the mild drought class was slightly more dominant the overall drought severity of the region could be considered normal mild drought is dominant across java the lesser sunda islands sulawesi and maluku while mild wet is mostly found in northern sumatera and southern kalimantan fig 11 moderate to severe drought was found in some locations including western java the eastern side of southern sumatra timor and northern maluku no area was classified as extremely wet while extreme drought conditions were found in southern sulawesi temporal variation in severity classes was evaluated for the very wet dry and medium wet dry categories the very wet dry category is the summation of extremely and severely wet dry classes while the medium wet dry category is the summation of mild and moderately wet dry classes the result indicated that the area experiencing dry conditions very medium dry classes increased and the area experiencing wet conditions very medium wet classes decreased fig 12 the results imply that all the areas in the mild to extreme dry category consistently increased meanwhile all areas in the wet category decreased except for the severely wet class overall the highest increasing and decreasing rates were 5 1 and 16 2 respectively which corresponded to the extreme dry and the mild wet classes 5 discussion the increasing existence of extreme precipitation events globally casts doubt on the usefulness of accumulated precipitation as the sole metric in the determination of drought periods therefore in this study a dry spell index that includes both evaporation and dry spell occurrences was used to estimate drought conditions during the rainy season though not included in previous studies of drought during the rainy season information on the evaporation rate enhanced the estimation of drought severity overall this approach can be applied in drought studies to take into account the climatological variation due to climate change such as an increase in the amount of daily precipitation the number of dry days and the evaporation rate satellite based data for both precipitation and actual evaporation which captures the diversity of precipitation regimes over the indonesian maritime continent was used in this analysis the onsets of the rainy season confirm striking differences in precipitation characteristics within the imc region as described by aldrian and dwi susanto 2003 the precipitation data showed that within the imc the rainy season onset generally occurred between august and november in the west september and january in the central region or april and june in the east region however this result is not consistent with that of moron et al 2010 particularly for the western part of java the inconsistency is likely due to differences in the onset determination used moron et al 2010 set the onset to occur only within the period of august and february this formulation overlooked the rainy seasons where the onset may occur before august nevertheless their findings also suggested that a small part of western java has a distinctive onset date the spatial pattern of rainy season onset found in this study also mostly agrees with the global rainy season patterns described by bombardi et al 2019 the rainy season length within the semi annual regime was generally longer than other regimes however strong tendencies toward longer rainy season duration were found in this regime and most of the southern hemisphere region the tendencies were spatially correlated with the increase in total precipitation meanwhile the tendency toward decreasing rainy season duration was observed in the middle of three main islands sumatera kalimantan and irian jaya land cover on these islands is primarily forest particularly in the middle part of the islands where the most significant decreasing trends exist these shortened trends in the rainy season duration could be an indication of the impact of deforestation deforestation potentially terminates the rainy season earlier by slowing the rate of evapotranspiration bombardi et al 2020 the average total rainy season precipitation over the imc did not change during the 1998 2018 period however although they were not significant increasing and decreasing trends were found within the precipitation regimes monsoon and semi annual regimes showed a tendency towards wetter conditions with an insignificant increase in rainy season precipitation the anti monsoon regime showed a contrary trend these results are very much in line with murray tortarolo et al 2017 who found no significant changes in rainy season precipitation at the global scale but increasing or decreasing trends at the regional scale both the annual and total rainy season precipitation trends were similar to those found by supari et al 2017 however contrary trends were observed in the monsoon and anti monsoon regions which stem from the differences in the source and duration of precipitation data positive and negative trends are strongly influenced by the value of the last data of the time series for example supari et al 2017 used ground based precipitation data ending in 2012 and precipitation in the monsoon regime trended downward beginning in 2010 fig 6b likewise the positive trend in annual precipitation in the anti monsoon region was caused by the upward trend in the 2008 2012 period fig 6c in the semi annual regime where the difference between the rainy season and the dry season is not very clear both the annual and rainy season precipitation have the same trend directions the impact of regional oscillation particularly enso is also evident in the total precipitation at the regional scale and three precipitation regimes within the imc the total precipitation dropped significantly during the very strong el nino year 2015 2016 these findings were consistent with supari et al 2018 who showed that decreasing total seasonal precipitation is due to el nino however accumulated precipitation does not explain the impact of enso variation on long term rainy season drought moreover changes in accumulated precipitation were not consistent with the modulation of enso in which accumulated precipitation may still increase or not significantly decrease during a strong el nino due to the increases in extreme precipitation this was also shown by supari et al 2017 who found that enso significantly impacts extreme events more than the intensity or duration of precipitation therefore variation in enso has a stronger correlation with the dsi than with total precipitation the correlation increased significantly during the rainy season indicating that the dsi was able to detect small changes in precipitation distribution during the rainy season the temporal variation of the dsi showed consistently positive changes at both regional and precipitation regime scales the change indicates the uniform progression of an increase in dryness severity due to dry spells across the imc region as shown by both the significant increases in temporal trends and the strong spatial tendencies toward expanding areas of all drying categories including extreme and severe drought areas this study also found that the most significant increase in the rainy season total precipitation occurred in the monsoon regime leading to the strong impression of getting wetter the increases could be attributed to the tendency toward longer rainy season duration however the dsi revealed that nearly 75 of the area with an increasing dryness is part of the monsoon area this indicates that the monsoon regime precipitation changed toward more frequent extreme precipitation and dry spell events increased extreme precipitation contributes to the increase in total precipitation which masks the drought progression by the dry spells hence the impression based on accumulated precipitation may cause a false interpretation of ongoing drought development this finding is in accordance with the increasing dry spell frequency found in monsoon regimes supari et al 2017 this research provides an alternative characterization of the rainy season drought by combining the dry spell and evaporation rate this is important as the warmer air temperatures of the future will cause more water to evaporate which also potentially elevates the drought severity dai and zhao 2017 the proposed method is not only able to capture variation in dryness severity at the fine spatial resolution but is also time independent hence it can be applied at any time scale the flexibility of this approach makes application over various durations possible which is a crucial feature for many climate change studies the findings of this study serve as a trigger for researchers and decision makers to provide further attention to increased drought during the rainy season this is especially the case given the projected significantly increasing trend in the number of dry days in this region polade et al 2014 with an increasing need for drought monitoring it is also important to have a globally applicable method the dsi can capture the dryness severity in the imc hence future research is needed to calibrate the dryness severity resulting from the dsi although in this study the dsi only used one formula for predicting dry day evaporation rates we recommend the use of more than one formula in future studies the formula can be developed based on the characteristics of soil land cover or other parameters affected by evaporation thus integrating multiple factors into a single drought index 6 conclusion overall dry spell analysis showed that the tendency toward rainy season drought has increased both temporally and spatially in the imc over the period 1998 to 2018 the increase in drought severity occurred across the region with a tendency for wet areas to become dry areas the significant increasing trends in drought severity caused by the presence of dry spells were mostly found in the monsoon regime area however the same pattern was also observed in total precipitation indicating the change in precipitation frequency and intensity toward more extreme conditions when accumulated precipitation is used for indexing these extreme conditions would mask drought development the dry spell index used in this study was able to capture the response in the variation in rainy season precipitation and enso increasing dryness severity may have important consequences for agricultural activities and water resources management increasing dry spell frequency or duration may harm crop development during the growing period which will eventually impact total crop production increasing rainy season dryness was generally found in java which is a very important area for agriculture thus these results are important to the imc hence water resources and agricultural management need to take the increasing rainy season drought into account to ensure that loss in crop productivity is minimized credit authorship contribution statement teuku ferijal conceptualization methodology data curation investigation formal analysis writing original draft okke batelaan methodology supervision writing review editing margaret shanafield methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
4044,spatial and temporal droughts during rainy seasons are important climatic aspects to consider in water resources management the dry spell index a time independent index that considers the characteristic of dry days dry spell seasonal length and evaporation rate in drought severity estimation is supporting the analyses of the spatiotemporal variations of drought severity in the rainy season of the indonesian maritime continent imc between 1998 and 2018 the rainy season was determined using a modified anomalous accumulation the results showed that an increase in dry spells produced a consistently increasing temporal drought during the rainy season across the imc meanwhile spatial variation suggested that although there is an increase in the rainy season total accumulated precipitation and duration a large area within the monsoon regime also experiences increased drought severity indicating more frequent extreme precipitation regional drought severity was classified as normal with a tendency of an increasing area under dry categories overall the rainy season drought has increased in the imc from 1998 to 2018 elevating the threats of reduced agricultural production keywords drought dry spell index rainy season indonesian maritime continent 1 introduction droughts are unpredictable recurring natural phenomena caused by a deficiency in precipitation which results in long term decreases in water storage compared to other natural disasters droughts are creeping phenomena that progress slowly and for which it is more difficult to determine start and end dates droughts also cover wider areas than most other disasters mishra and singh 2010 ostad ali askari et al 2020 tsakiris 2017 vicente serrano and lópez moreno 2005 therefore droughts may occur anytime and anywhere in addition no single drought definition is universally acceptable tsakiris et al 2013 making it difficult to quantify and monitor drought progression and severity as a result the droughts have caused the loss of both lives and property around the world drought has caused enormous financial losses around the world with an estimated annual loss of between 137 million and 8 billion us dollars dai 2011 guo et al 2017 tsakiris 2017 several indices have been used globally to estimate drought severity these indices are generated from either a single variable or a combination of drought related variables hao and singh 2015 precipitation is the main parameter controlling drought development and the primary input used in drought indices therefore most indices require accumulated precipitation over a particular period however accumulated precipitation based indices fail to detect drought generation over shorter time scales huang et al 2015 thus they are not appropriate to evaluate changes in global precipitation patterns such as increases in extreme precipitation and poorer precipitation distribution across time and space due to global warming occurrences of both extreme precipitation events trenberth 2011 ye and fetzer 2019 and days without precipitation zhou et al 2019 are increasing unfortunately when accumulated precipitation is used as a metric drought development is usually masked by an increase in accumulated precipitation due to these extreme events therefore the increasing length of dry spells which denote a period of consecutive days without precipitation or with precipitation below a threshold is not captured poor precipitation distribution over time and space resulting from high precipitation variability increases dry spell frequency and durations even during the rainy season as global precipitation patterns change dry spell studies become increasingly important to establish a sound understanding of drought through temporal trends and spatial variation in dry spell occurrence li et al 2017 previous dry spell studies primarily identified maximum duration and frequency kebede et al 2017 mupangwa et al 2011 ngetich et al 2014 raymond et al 2016 these studies typically focus on the dry season during which dry spells are common however dry spells during the rainy season can also be important in the development of drought conditions dry spells during the rainy season impact water availability as well as crop growth and production in some parts of the world for example byakatonda et al 2018 found some locations in botswana are experiencing increasing trends in dry spell frequency during the rainy season rendering these areas unsuitable for rainfed farming some stations in the upper baro akobo basin ethiopia showed increasing trends in the maximum duration and frequency of dry spells during the rainy season although the trends were not statistically significant indicating the need for better water management planning to minimize future climate risks kebede et al 2017 hence dry spells have become an important indicator to understand the dryness of the rainy season particularly in regions where rainy season precipitation is the primary source of water focussing only on the extreme dry spell duration would neglect dry spells with shorter duration as most dry spells are very short in duration li et al 2017 and even these short rainy season dry spells can have destructive impacts on agriculture and water resources engelbrecht et al 2006 thus it is important to consider all dry spells when assessing rainy season drought conditions a dry spell index dsi ferijal et al 2021 was created to quantify the severity of dryness in the presence of substantial precipitation variability it takes into account the characteristics of dry days dry spells and seasonal length hence the index is more flexible in the period of analysis and able to handle small changes in precipitation distribution however the index does not include the air temperature in the estimation drought development is exacerbated by increased air temperatures which change the driving force from precipitation deficiency to atmospheric demand leading to higher evaporation losses dai and zhao 2017 trenberth et al 2014 easterling et al 2007 found that the increase in drought frequency in the us during the period 1950 2006 was mainly driven by increasing air temperatures amrit et al 2018 found a significant relationship between the variation in annual temperature and drought intensity meanwhile in the pearl river basin southern china the variation in temperature contributed more significantly than precipitation to increased drought severity and duration wu and chen 2019 a combination of increased temperature and decreased precipitation has caused drought to be more prevalent in the loess plateau northern china sun and ma 2015 in the more extreme case severe water scarcity impacted 9 65 million residents and 39 94 million hectares of crops in the yunan province of china due to high temperatures and low precipitation ali et al 2020 thus it is important to integrate temperature into drought indices dabanli 2019 showed a strong relationship between temperature differences and hydro meteorological variables such as dry spells which allows the integration of the temperature function in the dsi the objective and novelty of this study is therefore to evaluate spatial and temporal variations in rainy season drought severity caused by the variation of dry spells during the rainy season using the dsi because of its strong correlation with dry spells another innovation of this research is to use the evaporation rate for defining the weight of consecutive dry days in the dsi calculation this approach is applied to the indonesian maritime continent imc as a study area the imc is one of the rainiest areas on earth and highly influenced by local and global air circulation resulting in high spatiotemporal variation in rainy season precipitation 2 study area indonesia is an archipelago that has more than 17 000 large and small islands it geographically covers a region of 6 n 11 s and 95 141 e and has an area of approximately 2 million km2 fig 1 it consists of the five big islands java sumatera kalimantan sulawesi and irian jaya and is characterized by complex topography java is the most populous island and plays a very important role in agricultural and industrial activities the complex interaction between land and sea in the imc caused this area to be depicted as a miniature of the earth in which land and sea coexist side by side yamanaka 2016 because the imc is sandwiched between two continents asia and australia and two oceans the pacific and indian the precipitation is strongly affected by the movement of the inter tropical convergence zone itcz when the itcz is in its southernmost position the northwest monsoon bring moisture from the south china sea and the pacific ocean causing wet periods in this region which peak in january and february conversely when the itcz is in its northernmost position the southeast monsoon brings dry winds from australia causing relatively dry periods in this area especially in july and august however most of the imc receives rain throughout the year in addition indonesia is also located between the indo and pacific warm pools and hence receives a lot of water vapor originating from the surrounding oceans thus indonesia is one of the highest rainfall areas in the world the imc also experiences high variability in precipitation with three types of precipitation characteristics occurring monsoon anti monsoon and semi annual aldrian and dwi susanto 2003 supari et al 2018 the monsoon and anti monsoon regimes have one precipitation peak which occurs during dec feb and jun jul respectively while the semi annual regime has two precipitation peaks in one year which occur in oct nov and mar may the imc has relatively constant air temperatures both in space and time daily air average temperature ranges from 23 c in the mountainous region to 31 c near the coast the average annual temperature amplitude is small with humidity generally greater than 90 this tropical climate region gets enough sunshine all year round making it very suitable for agriculture activities however future projected climate change and global circulation will intensify the modulation of precipitation anomalies potentially impacting the agriculture production in this region naylor et al 2007 3 data and methodology 3 1 data this study used daily precipitation sourced from the tropical rainfall measuring mission trmm multi satellite precipitation analysis tmpa 3b42 v7 https mirador gsfc nasa gov for the time period 1998 2018 this trmm product has been widely used for precipitation analysis because of its accuracy sahoo et al 2015 gleams data https www gleam eu was used to extract daily actual evaporation data from 1998 to 2014 both data have 0 25 spatial resolution and were extracted for the imc region only the analysis of precipitation data was performed on the inland area only by making use of the gleams data as a mask 3 2 methodology 3 2 1 definition of rainy season the onset and cessation of the rainy season were determined using the anomalous accumulation method applied for each climatological year the climatological year starts from the driest period in the current year and ends before the next driest period we selected july august as the driest period for monsoon and semi annual regimes and november december as the driest period for the anti monsoon regime to accommodate the temporal variation between these driest periods we allow the climatological year to overlap for those months thus the climatological year is defined as the period from 1 june to 30 august of the following year for monsoon and semi annual regimes and from 1 november to 31 december of the following year for the anti monsoon regime therefore there will be two overlapping periods the first period in the beginning and the second at the end of the climatological year the anomalous accumulation method uses the accumulation of the daily precipitation anomaly to determine the onset and cessation of the rainy season the rainy season is the period with the most intense precipitation characterized by an increase in anomalous accumulation the onset of the rainy season is marked by the day after which the anomalous accumulation increases the increase continues to a maximum point called the cessation i e the moment when the anomalous accumulation decreases to deal with a strong variation in precipitation over the study area we applied a modified anomalous accumulation method to determine the rainy season this method involves the following steps fig 2 1 calculating daily precipitation accumulation using the formula 1 a t n 0 t r n r where a t is the precipitation accumulation anomaly until time t r n is the precipitation on day n and r is the average daily precipitation 2 smoothing the anomaly accumulation curve by taking a 30 day running average of anomalous accumulation this smoothed curve helps to define multiple periods of intense precipitation characterized by a continuous increase in 30 day running average of anomalous accumulation using a method proposed by dunning et al 2016 two or more periods of intense precipitation are merged if they form a continuous increase in the 30 day running average of anomalous accumulation and the gap between the end of the first period and the start of the next period is less than 5 days 3 the starting and ending dates of each period of intense precipitation were defined by determining the minimum and maximum daily precipitation accumulation respectively corresponding to the start and end of the period of intense precipitation 4 the rainy season period was selected based on the start and end dates that form a longest continuous increasing in anomalous accumulation to prevent the same rainy season for two consecutive climatological years no onset is allowed within the second overlapping period for the semi annual regime the onset of the rainy season should occur before february this approach allows the onset of the rainy season to occur at any time during the defined climatological year the onset date will vary highly from year to year depending on the precipitation characteristic of the year likewise for regions with high precipitation the rainy season tends to have a longer duration 3 2 2 dry spell index the dry spell index was used to estimate dryness severity during the rainy season this method is time independent and therefore can accommodate strong variation in the onset and cessation of the rainy season the dsi is calculated as 2 dsi 1 rsl i 1 ndd w i where ndd is the number of dry days rsl is the rainy season length and wi is the weight assigned for each day within a given dry spell instead of using sequential numbers for the weight in this study the weights were obtained from the relationship between the dry spell and the evaporation rate this is based on the assumption that increasing dryness severity is equivalent to the water lost due to evaporation evaporation rates for each dry day in all dry spells during the rainy season were extracted for 50 randomly selected points over the land area of the imc for every dry spell of at least 3 dry days the weight of the dry day was calculated as 3 w i e i e 1 where wi is weight on ith day ei and e1 are the average daily evaporation rates for the ith and 1st day in the dry spell respectively hence the weight of the first dry day w1 within any dry spell will always equal 1 the number of dry spells greater than 10 days long was very small 0 15 hence the relationship between dry spell and evaporation rate was generated from the first 10 dry days only the dsi values were calculated and tested for normal distribution using the shapiro wilk and anderson darling tests once the normality was confirmed the dsi values were then classified into drought severity classes the threshold of each drought severity class was determined based on its probability according to the spi classification table 1 3 2 3 trend analysis the average total precipitation over the rainy season and average dry spell index for all precipitation regimes were plotted for the period 1998 2018 mann kendall mk trend tests were used to detect the possibility of trends in the time series mk is a non parametric trend test that is distribution free and has been widely used to detect monotonic trends in many hydro climatological time series the mk test was applied on the original time series with the assumption that the data is serially independent because it was derived from onset data of rainy seasons which are independent from each other the test assesses the null hypothesis h0 that no trend exists in the time series the h0 will be rejected if the absolute standardized test statistic zs is greater than the critical value zcrit at significance level α 2 for the normal distribution we selected 90 for α and the standardized test statistic was calculated as 4 z s s 1 var s i f s 0 0 i f s 0 s 1 var s i f s 0 where s is the statistic of the test defined as 5 s i 1 n 1 j i 1 n s i g n x j x i where x j and x i are sequential data in time series the statistic s has a mean equal to zero and a variance 6 var s n n 1 2 n 5 j 1 m t j t j 1 2 t j 5 18 where tj is the number of tied observations n is the number of data and m is the number of tied data values the sign of the zs value indicates the direction of change positive or negative 4 results 4 1 rainy season onset length and total precipitation the mean onset of the rainy season over the imc showed a clear spatial difference between the western and eastern regions fig 3 the pattern of onset propagation is generally in agreement with the existing description the onset propagation usually starts in the northern part of the region and moves southward before turning easter over java toward the eastern part of the region this movement causes an august onset in northern sumatera and a september to early october onset in central and southern sumatera in most of western borneo the onset of the rainy season is in mid september to early january while in central and southern sulawesi the onset is in mid october to early january for northern sulawesi and the rest of the eastern imc the rainy season starts between the end of may and the end of july interestingly a small part of western java and the central lesser sunda islands have a july onset which is out of the pattern however most of java and the lesser sunda islands have a rainy season beginning somewhere in august to november only a small portion of the easternmost lesser sunda islands timor island has an onset period that extends to early january the rainy season lengths vary from 48 to 182 days fig 4 the locations that have rainy seasons up to 6 months long were found in central kalimantan while only a few locations have rainy seasons less than 2 months long such as in middle and eastern java southern sulawesi and central irian jaya rainy seasons in the monsoon and anti monsoon regimes generally last from 70 to 90 days while the semi annual regime has longer rainy seasons which are up to 160 days long kalimantan and northern sumatera have stable precipitation throughout the year as syakur et al 2013 mandapaka et al 2017 hence most of this area does not have a distinct wet or dry season in comparison the southern hemisphere is characterized by a more pronounced wet and dry season in which the precipitation events mostly occur during the rainy season a significant increasing trend in the length of the rainy season was found in northern and southern sumatera java and some parts of the lesser sunda islands fig 4 this trend was also found in the eastern region of the imc distributed over sulawesi and irian jaya significant decreasing trends were found mostly in the central parts of three main islands sumatera kalimantan and irian jaya therefore although most of the southern regions have a shorter rainy season than the northern ones there is a tendency for the duration of the southern rainy season including southern sumatra java bali and the lesser sunda islands to become longer this increasing trend is not typically found in the northern region interestingly significant decreasing trends were found in some parts of sumatra kalimantan and irian jaya the precipitation accumulation during the rainy season is positively correlated with the duration of the rainy season in the areas where rainy season duration is long the total rainy season precipitation is significantly higher than other areas in the imc and vice versa high accumulated precipitation during the rainy season occurred mainly in central kalimantan and northern sumatera these areas have many annual wet days which consistently produce a high total annual precipitation mandapaka et al 2017 meanwhile low precipitation was detected in the central zone of the imc including sulawesi northern maluku and timor fig 5 significant increasing and decreasing trends in rainy season precipitation were found across the region however increasing trends dominate over all the main islands of the imc region while decreasing trends were mostly found in central sumatera and northern kalimantan the temporal variability of the average rainy season total precipitation over the whole region has not changed for the period 1998 2018 fig 6 a regional temporal variation showed that the total precipitation was very low in 2015 and relatively high in 2010 and 2012 total precipitation during the rainy season is between 1800 and 2000 mm which is approximately 65 72 of total annual precipitation the monsoon and semi annual rainy season precipitation showed increasing slopes fig 6b d while the anti monsoon precipitation had a decreasing slope fig 6c but none of those slopes were significant the rainy season precipitation in the semi annual regime which is mostly found in the northern hemisphere was relatively constant with an average total precipitation of 2200 mm year this mean rainy season precipitation is 12 to 18 higher than the precipitation in the monsoon and anti monsoon regimes for both monsoon and anti monsoon regimes strong temporal variation was observed 4 2 evaporation rates dry spells during the rainy season over the imc were dominated by very short spells approximately 93 of total dry days were 1 to 3 day dry spells a short dry spell potentially evaporates less water than a longer dry spell the rate of daily evaporation increases with the increase in dry spell duration fig 7 however the increase is not completely linear for the first four days the evaporation rate was approximately 3 6 mm day but then increased to 4 mm day from the 5th day forward the mean and standard deviation ranged from 3 5 to 4 3 mm day and from 0 71 to 0 89 respectively the variability of the average daily evaporation was strongly affected by the condition of the preceding wet days which affected the available water for evaporation the wetter the preceding conditions the greater the availability of water and the higher the evaporation rate the variability increased when all dry spell durations were used in the analysis the ratio of the evaporation rate of the first ten dry days to the evaporation rate of the first dry day could be best explained by the equation y 0 99x0 08 with a coefficient of determination of 0 83 4 3 dry spell index dsi the mean dsi ranged from 0 18 to 0 66 with lower dsi values corresponding to lower potential drought severity the spatial distribution of dsi showed an opposite pattern to the rainy season total precipitation high dsi values were randomly scattered throughout the imc mainly in southern sumatera western java sulawesi east timor and north maluku while low dsi values were concentrated in southern kalimantan and central sumatera fig 8 however the spatial variation of low dsi was not comparable to the spatial variation of high precipitation areas high precipitation areas distributed over central and northern kalimantan and northern sumatera fig 5 had a weak spatial relationship to the low dsi area which was concentrated in southern kalimantan the distribution of high dsi areas on the other hand was strongly correlated with the distribution of low precipitation areas significant increasing and decreasing trends in dsi were found over the imc region significant increasing trends were mostly found in the southern part of the imc region which is mostly the monsoon area with the exception of northern sumatera high dsi areas tended to have increasing trends and vice versa temporal variation showed a dsi increase of approximately 2 for the period 1998 2018 at the imc scale fig 9 a the increases were also observed in all precipitation regimes particularly in the monsoon 2 5 fig 9b and anti monsoon 2 2 fig 9c regimes across the whole imc several years show a high dsi i e 2002 2004 and 2015 fig 9a meanwhile the lowest dsi occurred in 1999 the dsi in the anti monsoon area exhibited a similar peak trough pattern to the overall imc but with stronger variation in both peaks and troughs this pattern seems to be the source of temporal variation at the regional scale the combination of strong annual variation and recurring 12 year cycles found in the anti monsoon regime is a strong indication of the influence of larger atmospheric circulation this recurring pattern was also found in the temporal variation of the total rainy season precipitation fig 5 4 4 impact of enso modulation the enso significantly impacts the climate over the imc region yamanaka 2016 tangang et al 2017 supari et al 2018 the modulation of enso should therefore be captured by drought indices the oceanic nino index oni which is used to measure enso is the 3 month running average of the extended reconstructed sea surface temperature ersst the ersst v 5 anomaly for the niño 3 4 region 5 n 5 s 120 170 w which is available from the noaa enso web page https origin cpc ncep noaa gov products analysis monitoring ensostuff oni v5 php was used the response of total precipitation and dsi to enso variations were compared using the correlation between total precipitation and dsi versus the oni this was done by taking the square of the correlation between the total precipitation and dsi versus the oni for all years the results indicated that oni is more correlated to the dsi than total precipitation fig 10 the correlation between oni versus total precipitation and oni versus dsi increased during the rainy season for all precipitation regimes mid june dec for monsoon and semi annual and mid may july for anti monsoon this indicated that dsi responded to drought variations induced by enso modulation both changes in precipitation or dry days much better than total precipitation did 4 5 spatial distribution of dry spell based drought severity the calculated dsi values ranged from 0 02 to 0 92 with a mean of 0 37 and a standard deviation of 0 11 the total number of estimated dsi values was nearly 91 000 this is a very large sample size which is not appropriate for any normality test as insignificant deviations from normality may significantly impact the test results garson 2012 therefore instead of using all of the data the normality test was performed on a subset of the data which was generated by randomly selecting 10 from the total population of dsi the shapiro wilk and anderson darling tests were selected to prove the normality of this subset the processes of subset generation and normality test were repeated 100 times the normal distribution assumption was not rejected by the shapiro wilk and anderson darling tests in 71 and 88 of all cases respectively indicating that the total population of dsi is normally distributed the drought severity of each pixel was determined by taking the standardized value of the dsi and classifying according to the classes of table 1 the area of each drought severity class was calculated for each year the spatial drought severity based mean dsi showed that most of the region is classified into mild wet and mild drought classes although the mild drought class was slightly more dominant the overall drought severity of the region could be considered normal mild drought is dominant across java the lesser sunda islands sulawesi and maluku while mild wet is mostly found in northern sumatera and southern kalimantan fig 11 moderate to severe drought was found in some locations including western java the eastern side of southern sumatra timor and northern maluku no area was classified as extremely wet while extreme drought conditions were found in southern sulawesi temporal variation in severity classes was evaluated for the very wet dry and medium wet dry categories the very wet dry category is the summation of extremely and severely wet dry classes while the medium wet dry category is the summation of mild and moderately wet dry classes the result indicated that the area experiencing dry conditions very medium dry classes increased and the area experiencing wet conditions very medium wet classes decreased fig 12 the results imply that all the areas in the mild to extreme dry category consistently increased meanwhile all areas in the wet category decreased except for the severely wet class overall the highest increasing and decreasing rates were 5 1 and 16 2 respectively which corresponded to the extreme dry and the mild wet classes 5 discussion the increasing existence of extreme precipitation events globally casts doubt on the usefulness of accumulated precipitation as the sole metric in the determination of drought periods therefore in this study a dry spell index that includes both evaporation and dry spell occurrences was used to estimate drought conditions during the rainy season though not included in previous studies of drought during the rainy season information on the evaporation rate enhanced the estimation of drought severity overall this approach can be applied in drought studies to take into account the climatological variation due to climate change such as an increase in the amount of daily precipitation the number of dry days and the evaporation rate satellite based data for both precipitation and actual evaporation which captures the diversity of precipitation regimes over the indonesian maritime continent was used in this analysis the onsets of the rainy season confirm striking differences in precipitation characteristics within the imc region as described by aldrian and dwi susanto 2003 the precipitation data showed that within the imc the rainy season onset generally occurred between august and november in the west september and january in the central region or april and june in the east region however this result is not consistent with that of moron et al 2010 particularly for the western part of java the inconsistency is likely due to differences in the onset determination used moron et al 2010 set the onset to occur only within the period of august and february this formulation overlooked the rainy seasons where the onset may occur before august nevertheless their findings also suggested that a small part of western java has a distinctive onset date the spatial pattern of rainy season onset found in this study also mostly agrees with the global rainy season patterns described by bombardi et al 2019 the rainy season length within the semi annual regime was generally longer than other regimes however strong tendencies toward longer rainy season duration were found in this regime and most of the southern hemisphere region the tendencies were spatially correlated with the increase in total precipitation meanwhile the tendency toward decreasing rainy season duration was observed in the middle of three main islands sumatera kalimantan and irian jaya land cover on these islands is primarily forest particularly in the middle part of the islands where the most significant decreasing trends exist these shortened trends in the rainy season duration could be an indication of the impact of deforestation deforestation potentially terminates the rainy season earlier by slowing the rate of evapotranspiration bombardi et al 2020 the average total rainy season precipitation over the imc did not change during the 1998 2018 period however although they were not significant increasing and decreasing trends were found within the precipitation regimes monsoon and semi annual regimes showed a tendency towards wetter conditions with an insignificant increase in rainy season precipitation the anti monsoon regime showed a contrary trend these results are very much in line with murray tortarolo et al 2017 who found no significant changes in rainy season precipitation at the global scale but increasing or decreasing trends at the regional scale both the annual and total rainy season precipitation trends were similar to those found by supari et al 2017 however contrary trends were observed in the monsoon and anti monsoon regions which stem from the differences in the source and duration of precipitation data positive and negative trends are strongly influenced by the value of the last data of the time series for example supari et al 2017 used ground based precipitation data ending in 2012 and precipitation in the monsoon regime trended downward beginning in 2010 fig 6b likewise the positive trend in annual precipitation in the anti monsoon region was caused by the upward trend in the 2008 2012 period fig 6c in the semi annual regime where the difference between the rainy season and the dry season is not very clear both the annual and rainy season precipitation have the same trend directions the impact of regional oscillation particularly enso is also evident in the total precipitation at the regional scale and three precipitation regimes within the imc the total precipitation dropped significantly during the very strong el nino year 2015 2016 these findings were consistent with supari et al 2018 who showed that decreasing total seasonal precipitation is due to el nino however accumulated precipitation does not explain the impact of enso variation on long term rainy season drought moreover changes in accumulated precipitation were not consistent with the modulation of enso in which accumulated precipitation may still increase or not significantly decrease during a strong el nino due to the increases in extreme precipitation this was also shown by supari et al 2017 who found that enso significantly impacts extreme events more than the intensity or duration of precipitation therefore variation in enso has a stronger correlation with the dsi than with total precipitation the correlation increased significantly during the rainy season indicating that the dsi was able to detect small changes in precipitation distribution during the rainy season the temporal variation of the dsi showed consistently positive changes at both regional and precipitation regime scales the change indicates the uniform progression of an increase in dryness severity due to dry spells across the imc region as shown by both the significant increases in temporal trends and the strong spatial tendencies toward expanding areas of all drying categories including extreme and severe drought areas this study also found that the most significant increase in the rainy season total precipitation occurred in the monsoon regime leading to the strong impression of getting wetter the increases could be attributed to the tendency toward longer rainy season duration however the dsi revealed that nearly 75 of the area with an increasing dryness is part of the monsoon area this indicates that the monsoon regime precipitation changed toward more frequent extreme precipitation and dry spell events increased extreme precipitation contributes to the increase in total precipitation which masks the drought progression by the dry spells hence the impression based on accumulated precipitation may cause a false interpretation of ongoing drought development this finding is in accordance with the increasing dry spell frequency found in monsoon regimes supari et al 2017 this research provides an alternative characterization of the rainy season drought by combining the dry spell and evaporation rate this is important as the warmer air temperatures of the future will cause more water to evaporate which also potentially elevates the drought severity dai and zhao 2017 the proposed method is not only able to capture variation in dryness severity at the fine spatial resolution but is also time independent hence it can be applied at any time scale the flexibility of this approach makes application over various durations possible which is a crucial feature for many climate change studies the findings of this study serve as a trigger for researchers and decision makers to provide further attention to increased drought during the rainy season this is especially the case given the projected significantly increasing trend in the number of dry days in this region polade et al 2014 with an increasing need for drought monitoring it is also important to have a globally applicable method the dsi can capture the dryness severity in the imc hence future research is needed to calibrate the dryness severity resulting from the dsi although in this study the dsi only used one formula for predicting dry day evaporation rates we recommend the use of more than one formula in future studies the formula can be developed based on the characteristics of soil land cover or other parameters affected by evaporation thus integrating multiple factors into a single drought index 6 conclusion overall dry spell analysis showed that the tendency toward rainy season drought has increased both temporally and spatially in the imc over the period 1998 to 2018 the increase in drought severity occurred across the region with a tendency for wet areas to become dry areas the significant increasing trends in drought severity caused by the presence of dry spells were mostly found in the monsoon regime area however the same pattern was also observed in total precipitation indicating the change in precipitation frequency and intensity toward more extreme conditions when accumulated precipitation is used for indexing these extreme conditions would mask drought development the dry spell index used in this study was able to capture the response in the variation in rainy season precipitation and enso increasing dryness severity may have important consequences for agricultural activities and water resources management increasing dry spell frequency or duration may harm crop development during the growing period which will eventually impact total crop production increasing rainy season dryness was generally found in java which is a very important area for agriculture thus these results are important to the imc hence water resources and agricultural management need to take the increasing rainy season drought into account to ensure that loss in crop productivity is minimized credit authorship contribution statement teuku ferijal conceptualization methodology data curation investigation formal analysis writing original draft okke batelaan methodology supervision writing review editing margaret shanafield methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
