index,text
7080,various types of regionalization approaches have been proposed in the last several decades for predictions in ungauged basins the most commonly used methods are based on the proximity of catchment centroids and physiographic and or climatic conditions of the catchments however the proximity of the catchment centroids and catchment physical attributes do not necessarily translate into similarities in hydrologic behavior it is also difficult to identify the key attributes that favor hydrologic similarity therefore in this study we proposed a new method called catchment runoff response similarity crrs in the view of reducing the hydrologic process predictive uncertainty and to solve the problem of the key attributes identification that favor hydrologic similarity the crrs has a two step approach 1 the commonly used regionalization approach is used to temporarily transpose the calibrated model parameter from gauged to ungauged catchments and 2 the runoff response of each smaller delineated subbasin of the gauged and ungauged basins are obtained based on the parameter value computed in the first step the similar subbasins of the gauged and ungauged basins are then identified based on their runoff response similarity the final parameter value in the ungauged subbasins are determined based on the notion that similar subbasins with runoff responses to similar input rainfall could have similar model structure settings the applicability of the proposed approach was verified for the geum river basin grb of south korea and the lake tana basin ltb of ethiopia leave one out evaluations of the proposed parameter transfer approach at various test gauging stations showed that the crrs approach outperformed the other widely used methods the crrs in the grb and ltb reached 91 and 77 during the calibration and 86 and 67 during the validation period respectively of the at site calibrated model performance on average over the test stations the overall worth of the crrs over the second best commonly used regionalization approach were also found to be 10 and 14 during the calibration and 7 and 4 during the validation period in the grb and ltb respectively in general it can be concluded from the overall result that the runoff predictive uncertainty in the ungauged catchments of the two study basins was significantly reduced by the crrs approach therefore the proposed approach can be used as an alternative method for runoff prediction in the ungauged basins worldwide keywords parameter transfer ungauged catchment catchment runoff response similarity geum river basin lake tana basin 1 introduction despite continuous research efforts and investments to accumulate hydrological data over the last century there are still some areas of the world with sparse hydrometric gauging stations in other words the density of hydrometric gauging stations is highly variable across the world in many hydrological analysis studies managing the ungauged catchments has therefore become a major obstacle that requires attention various versions of regionalization a process of transferring hydrological information from gauged to ungauged catchments have been developed in the past several decades the most common approaches for regionalization include arithmetic mean am jin et al 2009 merz and blöschl 2004 oudin et al 2008 physical similarity ps oudin et al 2008 samaniego et al 2010 samuel et al 2011 spatial proximity sp li et al 2009 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 and regression rg cheng et al 2006 götzinger and bárdossy 2007 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 young 2006 in the am approach each model parameter for the ungauged catchment is simply computed as a mean of the corresponding parameter of the gauged catchments therefore the parameter values are identical for all ungauged catchments the ps approach uses catchment attributes to group the similar catchments this approach identifies a donor catchment that is most similar to an ungauged site with respect to its catchment attributes and then transfers a complete parameter set from the donor to the corresponding ungauged catchment for hydrological modelling the success of this approach depends on the choices of attributes for the similarity of catchments the topography land use and soil type have been widely used as geomorphological attributes bastola et al 2008 heuvelmans et al 2006 merz and blöschl 2004 wagener et al 2007 whereas long term characteristics of precipitation and potential evapotranspiration have been applied as meteorological attributes bastola et al 2008 wagener et al 2007 the sp approach estimates the model parameters at ungauged catchments using an interpolation technique such as kriging merz and blöschl 2004 parajka et al 2005 this approach assumes that the nearby catchments are located in a homogeneous region the rg approach uses catchment attributes and hydrological model parameters as independent and dependent variables respectively cheng et al 2006 götzinger and bárdossy 2007 merz and blöschl 2004 parajka et al 2005 young 2006 the main concern of the rg approach is that the significance of dependent variables may vary from one catchment to the other to compensate for model structure errors mcintyre et al 2005 possibly resulting in a weak or null relationship between the independent and dependent variables moreover the structural form of the rg equations in the case of multiple ungauged catchments may vary from one catchment to the next even if those catchments share the same independent variables of the gauged catchments the other key issue with the rg approach is the interaction between the model parameters during the calibration mcintyre et al 2005 oudin et al 2008 this could produce complex response surfaces that are not well defined by either independent or correlated normal distributions mcintyre et al 2005 sorooshian and gupta 1995 moreover the response surface becomes more complex if applied to a model with several parameters mcintyre et al 2005 such as the case considered in this study various studies have compared the performance of different regionalization techniques in different basins arsenault and brissette 2014 bao et al 2012 jin et al 2009 kay et al 2006 li and zhang 2017 mcintyre et al 2005 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 patil and stieglitz 2012 samuel et al 2011 singh et al 2014 swain and patra 2017 young 2006 zhang and chiew 2009 zhang et al 2014 most previous studies have reported the robustness of the ps and sp approaches arsenault and brissette 2014 bao et al 2012 kay et al 2006 li and zhang 2017 mcintyre et al 2005 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 samuel et al 2011 swain and patra 2017 zhang and chiew 2009 zhang et al 2014 more importantly oudin et al 2008 compared the ps rg and sp regionalization approaches for runoff predictions in ungauged catchments using 913 gauged catchments in france they found that sp slightly outperformed ps in the areas characterized by a dense stream gauge network while the ps and sp predictive performances become similar when the stream gauging station network density decreases to 60 gauges per 100 000 km2 parajka et al 2013 reported that the effects of the parameter transfer approaches on model performance varies between studies based on a review of 34 past studies mentioning a tendency towards a lower performance of rg than other methods commonly used in those studies in their study ps and sp were found to be best in humid catchments while ps and rg perform slightly better in arid catchments this study also reviewed 15 past studies see table 1 and drew the same conclusion as oudin et al 2008 and parajka et al 2013 in terms of the robust performance of ps and sp over rg therefore in this study we adopted the ps and sp approaches to model the ungauged catchments of two different basins in terms of climate condition and stream gauging station network density in the ps approach a majority of the past studies used the similarity of the input attributes of the rainfall runoff model such as meteorological data e g rainfall temperature relative humidity solar radiation and wind speed and spatial data e g soil use land use and topography one would expect that these catchment attributes provide valuable information for modelling the ungauged catchments young 2006 but are not considered in the sp approach the ps approach assumes that the similarity in the input attribute be fully transferred to the output i e the runoff however the relation between the input and output variables in the hydrological process can be inherently different between gauged and ungauged basins furthermore it is difficult to consider all the necessary inputs in the regionalization procedure of the gauged and ungauged catchments due to this fact it has been reported that different researchers used different attributes for the regionalization of catchments it seems that an initial hypothetical judgment is required to identify the key catchment attributes influencing the runoff response razavi and coulibaly 2012 however it is difficult to select the key physiographic and or climatic conditions that best represent the hydrologic similarity moreover the proximity among catchment centroids used in sp are not necessarily translated into the hydrologic similarity kokkonen et al 2003 post and jakeman 1996 the above problems in ps and sp motivated the work in this paper to find a better attribute that can best represent the hydrological similarity as the runoff is the integrated output that expresses all of the interactions related to the hydrological phenomenon within a basin it would be ideal if the hydrological similarity could be determined by this attribute therefore in this study we propose a catchment runoff response similarity crrs approach that is based on the following steps 1 a conventional parameter transfer methods is used to transpose the model parameter from the gauged to ungauged catchments 2 the runoff response of each gauged and ungauged catchment are computed based on the defined parameter sets 3 the hydrological similarity between subbasins of the gauged and ungauged catchments are updated as per the similarity of their runoff response and 4 the model parameters in the ungauged catchments are re determined based on the updated similarity of the gauged and ungauged catchments 2 study area description two hydro geographically different basins one from the subtropical zone the geum river basin grb and the other from the tropical zone the lake tana basin ltb were used for this study the hydro climatic conditions in the grb are dominated by the asian monsoon with most of the annual precipitation and runoff taking place during the wet season july to september the development of water resources projects in the grb has disrupted the natural hydrologic processes therefore there are many sites where the natural discharge data is not readily available for prediction using the hydrological models in the ltb lake tana a natural lake covers an area of 3000 3600 km2 the climate of the ltb varies from humid to semiarid the summer monsoon is the driver for hydro climatic variability in the ltb with most of the precipitation occurring in the wet season june september and most of the annual flow occurring from july to october the grb see fig 1 a is the third largest river basin in south korea that lies in a natural drainage basin of 9859 km2 it geographically extends between 126 41 128 25 e and 35 35 37 05 n the grb is the home of two large multipurpose dams yongdam and daecheong that have been built along the main river the total length of the main stream of the geum river is 395 9 km with an average slope of 16 74 the area is used for forestry 61 mixed forest 20 and other 19 purposes the elevation ranges between 80 and 820 m above the mean sea level the grb has a temperate climate with rainfall heavier in summer than winter with a mean annual temperature of 11 5 c the average annual rainfall in the basin is 1343 mm the observed daily weather data with a record length of more than 30 years were collected from 14 weather gauging stations namely boeun buan buyeo cheonan cheongju chungju chupungryung geochang geumsan gunsan imsil jeonju mungyeong and seosan the collected weather data from these weather stations were used to setup the soil and water assessment tool swat model the streamflow data from eight stations yongdam daecheong hoendeok seokhwa nonsan guryong cheongju and bugil and the weather data from 14 stations were retrieved from one of the government databases called water resources management information system the ltb is a part of the blue nile river basin located in a natural drainage basin with a size of 15 114 km2 it geographically extends between latitudes 10 95 n and 12 78 n and longitudes 36 89 e and 38 25 e the elevation ranges from between 914 and 4096 m above the mean sea level gilgelabay ribb gummera and megech in order from largest to smallest land area are the major gauged watersheds of the study area see fig 1 b the only surface outflow from the basin is the blue nile comprised of 7 of the blue nile flow at the border between ethiopia and sudan shahin 1985 the rainfall distribution in the basin has a monomodal pattern one peak value is observed during the rainy season based on the observations at 13 rainfall stations in the basin from 1995 to 2014 the mean annual rainfall ranges from 955 mm in enfranz to 2365 mm in enjibara similarly the mean annual minimum and maximum temperature varies from 8 8 c in merawi to 28 c in enfranz based on the land use classification 51 37 of the watershed area was covered by agriculture 21 94 was agropastoral 20 41 was covered by lake tana 0 39 was agrosilvicultural 0 13 was covered by wetland 5 47 was pastoral 0 15 was silvicultural 0 03 was silvipastoral and 0 11 was urban based on the soil classification halpic luvisol covering 20 68 of the watershed area is considered the dominant soil in the study area the observed daily weather data recorded over 32 years 1983 2014 at 13 weather gauge stations were used as the input for the selected model the observed weather data from 13 weather gauge stations were retrieved from the ethiopian national metrological agency and the ministry of water irrigation and energy of ethiopia provided the spatial input data digital elevation model dem land use and soil data and observed streamflow data it is apparent from the information of the two study basins that one single streamflow gauging station on average covers approximately 1232 and 3023 km2 in the grb and ltb respectively the spatial coverage of the streamflow gauging station in the grb is almost about three times denser than the coverage in the ltb moreover the meteorological stations are very sparse in the ltb compared to the grb the average weather stations in the grb and ltb represent 704 and 1163 km2 respectively the two catchments are used to test the applicability of the crrs approach in different basins in terms of the climate condition and stream gauging station network density the former and the latter are above and below respectively the cut off density 60 gauges per 100 000 km2 used by oudin et al 2008 for comparing the performance of the sp and ps 3 methodology 3 1 hydrologic model a semi distributed model the swat arnold et al 1998 has been applied to eight gauged watersheds of the grb i e bugil guryong nonsan cheongju yongdam daecheong hoedeok and seokhwa and to five gauged watersheds of the ltb i e gilgelabay gummera koga megech and ribb more recently tegegne et al 2017a b reported the applicability of the swat model in the two study basins as a physically based semi distributed hydrological model in the swat model a basin is divided into multiple subbasins that are then further subdivided into units with distinct soil and land use characteristics called hydrological response units hrus the surface runoff is estimated separately for each subbasin and routed to quantify the total surface runoff of the basin abbaspour et al 2007 the water balance equation in the swat model neitsch et al 2011 is based on 1 sw t sw 0 i 1 t r day q surf e a w seep q gw i where swt is the final water content mm swo is the initial soil water content on day i mm t is the time days rday is the amount of precipitation on day i mm qsurf is the amount of surface runoff on day i mm ea is the amount of evapotranspiration on day i mm wseep is the amount of water entering the vadose zone from the soil profile on day i and qgw is the amount of groundwater flow on day i mm for this study the modified soil conservation service runoff curve number scs cn is used to compute the surface runoff volume the potential evapotranspiration was estimated based on the penman monteith method monteith 1965 and the variable storage coefficient method is used to determine the flow through the channel 3 2 parameter sensitivity analysis over parameterization is a well known and commonly occurring problem in distributed hydrological models beven 1989 van griensven et al 2006 sensitivity analysis methods designed to reduce the number of parameters that require fitting with input output data are thus common spear and hornberger 1980 van griensven et al 2006 moreover tegegne et al 2017a b reported that the streamflow generation using the swat model in both study basins was influenced by a particular subset of the original parameters suggesting the need to implement sensitivity analysis of parameters during calibration in general sensitivity analysis is useful in calibration of hydrological models and also for their transposition to different watersheds e g cibin et al 2010 in this study the model parameter sensitivity analysis used to identify the parameters that affect streamflow generation using swat was done with the global sensitivity analysis techniques therefore the global sensitivity analysis is performed before the calibration of the swat model to identify the most sensitive parameters it is based on the average change in the objective function for each parameter while all other parameters are changing the parameter sensitivity is quantified based on the t stat and p value statistical characteristics a larger absolute value of t stat and smaller p value indicates a more sensitive parameter for the sensitivity analysis the 13 important swat model parameters see table 2 that affect streamflow predictions were identified through a detailed literature review arabi et al 2007 neitsch et al 2011 cibin et al 2010 tegegne et al 2017a b 3 3 parameter calibration and uncertainty analysis the sequential uncertainty fitting sufi2 abbaspour et al 2004 one of the methods integrated in swat calibration and uncertainty programs swat cups is used for calibration and uncertainty analysis the uncertainties of parameters in sufi 2 account for all sources of uncertainty including model structure model input e g rainfall and temperature measured data for model calibration and validation e g discharge by propagating these uncertainties in the parameters abbaspour et al 2004 sufi 2 uses a latin hypercube sampling procedure to sample from the parameter intervals and the initial parameter ranges are updated at each iteration until a narrower parameter uncertainty range is obtained abbaspour et al 2004 the sufi2 calibration and uncertainty analysis result is evaluated based on the closeness of the percentage of observations covered by the 95 prediction uncertainty 95ppu p factor to 100 and the relative width of a 95 probability band r factor to zero a p factor of 100 and an r factor of zero represent a simulation that exactly corresponds to the observed data in fact most of the observations can be covered by the 95 interval leading to a high p factor at a large parameter range high r factor therefore the two indicators have to be used to evaluate the model uncertainty results abbaspour 2013 suggested that a p factor value of greater than 70 corresponds to an r factor of 1 in general the main steps of sufi 2 can be summarized as follows 1 define the objective function and physically meaningful parameter range 2 hypercube parameter sampling is performed within the defined parameter range that leads to a number of parameter combinations equal to the number of simulation iterations 3 the 95ppu is computed and evaluated as per the two performance metrics p factor and r factor and 4 as per the evaluation criteria the parameter ranges are updated and are always centered around the best estimates the p factor and r factor can be computed using the following equation 2 p factor t 1 t z t t 100 z t 1 if q t o q t 2 5 s q t 97 5 s 0 otherwise 3 r factor 1 t t 1 t q t 97 5 s q t 2 5 s σ obs where q t 97 5 s and q t 2 5 s represent the upper calculated at the 97 5 levels of cumulative distribution and lower calculated at the 2 5 levels of cumulative distribution simulated boundaries at time t respectively t is the number of time steps in the observed data s indicates the simulated values o indicates the observed values t is the simulation time step σ obs is the standard deviation of the observed data q t o is the observed data at time step t and z t has a value of 1 when the observed discharge is within the 95ppu interval the objective function applied to the simulation in the sufi 2 is the well known nash sutcliffe efficiency nse method nash and sutcliffe 1970 4 nse 1 i 1 n o i p i 2 i 1 n o i o 2 where p i is the simulated value o i is the measured value and o is the average measured value 3 4 common parameter transfer approaches 3 4 1 arithmetic mean approach the am is mainly used for first phase parameter transfer of the crrs approach that is discussed in detail in section 3 5 in the am approach each model parameter for the ungauged catchment is simply computed as the mean of the corresponding parameters of the gauged catchments and this is based on the assumption that the hydrologic prediction in the am approach will be within the uncertainty resulting from calculating the metric of similarity in this study a little better am method i e the weighted average wam approach is used in this modified am approach each model parameter for the ungauged catchment is simply computed as a weighted mean of the corresponding parameter of the gauged catchments that might be useful for uncertain modelling results for example the performance of the swat model in reproducing the runoff might be good in one gauge catchment and poor in the other therefore the weighted mean of the calibrated parameters might be a good approach in such conditions of uncertain performance results of the hydrologic model the weighted mean value of the calibrated model parameters of the gauged catchments are then assumed identical for all ungauged subbasins of the study basin the weight of each calibrated model parameter in each gauged catchment is determined based on their performance in reproducing the observed runoff at the corresponding gauged catchments the reliability of each calibrated parameter is determined based on the model performance during the calibration and validation period as measured by the nse the weight r i for the ith calibrated parameter is determined by the multiplication of two factors 1 the calibrated parameter performance to reproduce the runoff during the calibration period and 2 the calibrated parameter ability in reproducing the runoff in the validation period the model reliability ranges from zero unreliable to one reliable the weight is given by 5 r i nse c i m nse v i n where r i indicates the weight of the ith calibrated parameter in terms of reliability nse c i indicates the reliability of the i th calibrated parameter through the nse during the calibration period nse v i indicates the reliability of the ith calibrated parameter through the nse during the validation period and m and n are the parameters to provide a weight based on the importance for the reliability during the calibration and validation periods respectively note that i represents the number of gauged catchments that are considered for multi model averaging the number of gauge catchments in our study are eight and five for the cases of the grb and ltb respectively the main idea of weighting the swat model parameters θ i of each gauged catchment is to give more weight to the best performed calibrated parameter sets this will likely improve the uncertainty of the runoff prediction over the simple arithmetic mean approach the weighted model parameters θ w at the ungauged subbasin can be computed as 6 θ w i 1 n r i θ i i 1 n r i 3 4 2 physical similarity approach the physical similarity approach is based on the assumption that catchment physiographic characteristics predetermine the hydrological behavior the catchment attributes used to define the similarity are related to the topography land cover and soil features derived from the available data such as land use soil use and dem these catchment attributes are considered the main drivers of the hydrological process in the literature merz and blöschl 2004 in addition the selection of the appropriate catchment attributes depends on the physical meaning of the selected model parameters objective of the regionalization procedure and knowledge regarding the key hydrological processes occurring within the catchment sellami et al 2014 for instance the curve number parameter cn2 in the swat model depends on the soil and land use characteristics of the catchment thus the concept of the hrus similarity in which the land use soil use and land slope are unique is introduced to facilitate the parameter transfer from gauged to ungauged catchments 3 4 3 spatial proximity approach the spatial proximity approach is based on the spatial distance between catchment centroids that are interpolated as function of the geographic location the spatial interpolation technique used in this study is kriging samuel et al 2011 that is known to be better than the inverse distance weighting method the basic tool of kriging is the semivariogram that captures the spatial dependence between samples by plotting the semivariance against the separation distance 3 5 the catchment runoff response similarity approach in this study we propose a new parameter transfer approach based on the two step approach of parameter transfer see fig 2 at the first step the existing parameter transfer methods e g am ps and sp can be used to temporarily transpose the calibrated model parameter from the gauged to ungauged subbasins the modified am wam approach is used for this study as the number of gauged watersheds are too limited in the two case study basins it is difficult to subgroup the already grouped similar subbasins based on the ps and or sp approaches due to a limited number of donor subbasins this is because the number of similar groups will be too high compared to the number of donor catchments if we further subgroup the identified similar groups based on the ps and or sp approaches at the first approach in which some similar groups may not have a similarity with the donor catchments however the ps and sp approaches can be used as a first parameter transfer approach for the study basins with too many donor subbasins the second step of the proposed parameter transfer approach is based on the notion of hydrologic similarity the subbasins that have similar runoff responses and rainfall characteristics are considered hydrologically similar once the hydrologically similar subbasins are identified the final parameter values of each of the ungauged subbasins can be easily transposed from the gauged to ungauged subbasins the calibration of swat involves the selection of a parameter set that reproduces the historically observed runoff signatures at each gauged catchment as closely as possible it is essential to note that the runoff response associated with the calibrated parameters is the integrated output of the model and expresses all of the interactions related to the hydrological phenomenon within a basin the regionalization of the calibrated swat model parameter values from the gauged to the ungauged basins can consequently be related to the runoff signatures with the aim of reducing the hydrologic predictive uncertainty in the ungauged basin as runoff is the integral output for the estimated parameter the detailed systematic procedures of crrs are summarized in six steps as follows see also fig 2 step 1 the hydrologic models for the gauged and ungauged basins are set up by inputting the spatial data i e land use soil use and slope and meteorological data e g rainfall temperature relative humidity wind speed and solar radiation into the model step 2 the gauged and ungauged basins are subdivided into smaller subbasins using a geographical information system gis that keeps track of the flow direction in a dem land use soil type and slope of all the subdivided subbasins are then classified and overlaid to form the hydrologic response units hrus the dominant land use soil and slope of each subbasin are used to define the hrus in each subbasin step 3 model parameters are calibrated for each subbasin of the gauged watersheds step 4 the first phase parameter transfer from gauged to ungauged subbasins is based on the commonly used parameter transfer approaches the ps sp or am parameter transfer approaches can be used during this phase in the case of the ps approach the similarity of hrus with similarity in land use soil type and slope is used to group similar subbasins into n hydrologically similar groups in the sp approach on the other hand the gauged and ungauged subbasins are grouped into n hydrologically similar subbasins based on the assumption that proximate subbasins will likely have a similar runoff regime during the first phase the model parameters and model output i e runoff response are temporarily supposed to be known by transposing the calibrated model parameters from the gauged into the ungauged subbasins using the commonly used parameter transfer approaches here we temporarily assign a calibrated parameter value for each similar subbasin as per the parameter transfer approach used in the first phase this is because catchments with a similar response may actually have very different parameters for the rainfall runoff transformation we therefore assign similar parameter values for all similar subbasins as per the regionalization approach used in the first phase of the proposed approach since our aim is to further identify the similar subbasins based on their runoff response similarity it is important to note that the procedure of the commonly used parameter transfer approaches am ps and sp can be applied in those basins with a sufficient number of gauged streamflow stations during the first phase of the parameter transfer method step 5 the hydrologic model is used to predict the runoff in all subbasins of the gauged and ungauged basins since the system in all ungauged subbasins is known arbitrarily through the first phase parameter transfer the runoff output of swat for each subbasin is obtained and normalized by the corresponding subbasin area the normalized runoff runoff response of the subbasins is considered the main attribute for identifying hydrologically similar regions step 6 in the second phase of the parameter transfer approach the model parameters are transposed from the gauged to the ungauged subbasins by means of crrs this is the ultimate goal of the proposed parameter transfer approach the self organizing map clustering technique the details were presented by kohonen 1990 is used here to identify hydrologically similar subbasins using the runoff response and rainfall of each subbasin this parameter transfer approach is a promising approach that can yield more precise interpretation of the term hydrologic similarity widely used in previous studies finally the hydrologic model for the ungauged basins are updated with the final parameter values to obtain the runoff and other important water balance components from the ungauged basins the performance of the proposed parameter transfer approach should be assessed by comparing the predicted and observed response characteristics for gauged test catchments as the number of gauged catchments for the ltb and grb are limited to five and eight respectively a leave one out evaluation technique is carried out to successively validate the proposed approach therefore the performance of the parameter transfer scheme is successfully cross validated by assuming each gauged one gauged catchment at once catchment is ungauged the runoff output of the model with the regionalized and optimal calibrated parameters at each test catchment is compared and assessed to finalize the validation of the proposed approach 4 results and discussion 4 1 parameter sensitivity result the global sensitivity analysis on the swat model parameters were conducted for eight gauged stations yongdam daecheong hoedeok seokhwa nonsan guryong cheongju and bugil in the grb and for five gauged stations gilgelabay gummera koga megech and ribb in the ltb in the grb the observed flow record period used to run the swat were 2001 2016 for the yongdam nonsan guryong cheongju and bugil catchments 1981 2000 for the daecheong catchment 1998 2016 for the hoedeok and seokhwa catchments the observed flow prior to the operation of the yongdam dam reservoir is used to run the swat at the daecheong catchment in each of the gauged catchments of the grb the last four years are used for model validation in the ltb a large amount of data is missing with respect to hydrometeorological observations prior to 1998 for the gilgelabay gummera megech and koga catchments and prior to 1995 for the ribb catchment therefore only recent flow data from the gilgelabay gummera megech and koga catchments 1998 2012 and ribb catchment 1995 2009 were used to evaluate the simulation capabilities of the model in each of the cases of the ltb the last three years are used for model validation parameter sensitivity analysis in parameter regionalization is important for simplifying the structure of a complex hydrological model such as swat by minimizing the number of parameters involved in the modeling framework this provides a better identified model structure and facilitates the transposition of dominant parameters to different watersheds the implementation of parameter sensitivity analysis in parameter regionalization thus supports our primary hypothesis that the identification of the dominant parameters describing the key hydrological process of the system can reduce the model prediction uncertainty in the gauged and ungauged catchments from the sensitivity analysis results six flow parameters i e cn2 alpha bnk alpha bf ch k2 ch n2 and sftmp and six flow parameters i e cn2 ch k2 ch n2 gw delay alpha bnk and esco are found to be the most sensitive parameters for the grb and ltb respectively with the overall average p values 0 01 see fig 3 and absolute t stat values 7 the default values of the non sensitive parameters in both study basins were used for the simulation of the streamflow fig 3 illustrates the small to null p value variation for the selected most sensitive parameters across all watersheds of the two case study basins for example there is no p value variation across any of the watersheds for the parameters cn2 alpha bnk alpha bf ch n2 and ch k2 in the grb and for the parameters cn2 ch k2 and ch n2 in the ltb see fig 3 moreover most of the identified sensitive parameters are the same for all watersheds of each case study basin but they differ in their ranking it is vital that the identified dominant parameters that are assumed to describe the hydrologic process of the real system are consistent across all gauged watersheds so that the transposition of these parameters from the gauged to ungauged catchments can reduce the uncertainty of hydrologic prediction in the ungauged catchments for simplicity fig 4 presents an example of the parameter sampling distributions for the most sensitive and insensitive parameters in the megech ribb seokhwa and yongdam watersheds the parameter density distribution sunflower plots display the density of sampling points see fig 4 dark and light sunflowers represent high and medium density areas of parameter sampling respectively and each marker symbol represents one model run for low density sampling points in fig 4 the dotty plot for the most sensitive parameters i e alpha bnk and cn2 shows that the parameter samples are relatively very dense around the maximum with narrow ranges the analysis based on the parameter density distributions in all watersheds revealed that the high density parameter sampling of the most sensitive parameters seemed to vary over narrower ranges toward unimodal posterior distributions while the high density region of the non sensitive parameters varied over wider ranges toward flat posterior distributions in other words the unimodal peaked posterior distributions are associated with easily identifiable parameters while flat distributions indicate non identifiability of parameters from the variation in parameter sampling of the values of the nse as measured by p and t stat values it was evident that the four most sensitive parameters in all watersheds of both study basins were cn2 ch k2 ch n2 and alpha bnk among these four parameters the most sensitive in most of the watersheds was cn2 gilgelabay gummera koga megech ribb bugil cheongju hoedeok nonsan and seokhwa alpha bnk was most sensitive in the guryong and yongdam watersheds and the ch k2 was in the daecheong watershed the sensitivity of the daily streamflow simulations to the cn2 parameter in most of the watersheds is expected since this parameter is the primary influence on the amount of runoff generated from a hydrologic response unit cibin et al 2010 the result is consistent with the conclusion of gassman et al 2007 that cn2 was an important parameter affecting hydrologic simulations in all of the model applications it is noteworthy that only a few sampling points in the watersheds of the ltb see fig 4 as an example for the megech and ribb watersheds have nse values significantly greater than zero whereas many sampling points in the grb had nse values significantly greater than zero the problem of parameter sampling in the ltb might be related to the quality of measured rainfall data and measured discharge data poor spatial coverage of rainfall data within the ltb could be another cause 4 2 parameter calibration and uncertainty result in the ltb the calibrated swat model poorly performed in the smaller watersheds koga and megech but performed relatively better in the larger watersheds see table 3 conversely the swat model in the grb achieves more than 60 and 50 of the observed flow characteristics on average over all gauging stations during the calibration and validation periods respectively in terms of the nse indicator in summary the values of the nse obtained for all watersheds in the grb using the sufi 2 calibration strategy vary between 0 51 at bugil and 0 74 at yongdam for the calibration and 0 23 at cheongju and 0 80 at daecheong for the validation period on the other hand the performance of swat in the watersheds of the ltb in terms of the nse fall between 0 22 at koga and 0 76 at gummera for the calibration and 0 14 at koga and 0 76 at gummera for the validation period the performance results of swat in the watersheds of the grb and ltb from the validation period show a similar pattern to those from the calibration period except for the poor validation performance in the cheongju watershed from the grb moriasi et al 2007 suggested that model simulation can be judged as satisfactory if nse is greater than 0 5 the results in the watersheds of the two case study basins agree reasonably well with this value except the koga and megech watersheds of the ltb during both the calibration and validation period and the cheongju watershed of the grb during the validation period it is important to present the hydrologic model prediction results with an envelope of good solutions expressed by the 95ppu produced by certain parameter ranges in addition to the model performance by reproducing the observed hydrograph figs 5 and 6 present the 95 prediction uncertainty comprising of all uncertainties in the model observed streamflow and best simulated streamflow plot for the four more representative gauged catchments in both the grb and ltb respectively the p and r factors were used to evaluate the sufi 2 in quantifying the uncertainty in the grb p factors of 0 78 0 78 0 77 0 86 0 93 0 68 0 73 and 0 80 and r factors of 0 42 0 38 0 47 0 46 0 43 0 45 0 27 and 0 37 were quantified for the yongdam hoedeok seokhwa daecheong bugil cheongju guryong and nonsan catchments respectively while in the ltb p factors of 0 64 0 85 0 74 0 44 and 0 13 and r factors of 1 1 0 78 0 59 0 70 and 0 17 were found for the gilgelabay gummera megech ribb and koga catchments respectively the p and r factors for all gauged catchments in the grb and for the gilgelabay gummera and megech watersheds in the ltb are acceptable however the p factor for the ribb and koga watersheds in the ltb are not within acceptable limits indicating that the parameter uncertainties were not within the desired ranges for the ribb and koga watersheds the mean values of the estimated p factors and r factors in the watersheds of the grb were found to be 79 and 0 4 respectively conversely the mean values of the estimated p factors and r factors in the watersheds of the ltb were found to be 56 and 0 67 respectively the uncertainty analysis shows that the sufi 2 captured the observations much better in the watersheds of the grb than in those of the ltb note that the p factor in the koga watershed combined with the poor performance values for the nse revealed that there is high uncertainty of simulated flow due to errors in input data and other sources of uncertainty such as upstream dam construction for town water supply diversion of streams for irrigation and other unknown activities specific to the koga watershed the model uncertainty range of the ltb was observed to be higher than that of the grb see figs 5 and 6 the high uncertainty in the ltb might be due to the sparse spatial distribution of the meteorological stations and the quality of the hydrometric data it is therefore suggested that more accurate areal rainfall estimation and more precipitation stations should be established for more accurate hydrological modeling in the ltb in both study basins the low flows were well bracketed by the 95ppu while the peak flows were relatively less captured within the 95ppu however the relative thickness of the 95ppu as measured by the r factor for the peak flow were relatively less compared to the relative width in the low flows this result shows that the swat model prediction of the low flows is highly uncertain compared to its predictive uncertainty of the high flow 4 3 evaluation of the catchment runoff response similarity approach the total of 13 representative gauging sites 8 from korea and 5 from ethiopia were selected to test the applicability of the crrs approach with a jack knife cross validation approach and the performances of the crrs approach at each test site were compared with the wam ps and sp approaches see fig 9 and table 4 the wam parameter transfer approach shows the poorest results in all test sites compared to the other approaches and even the am provided poor results compared with the wam results this shows that the poorly modelled watershed yields highly uncertain model parameter values in the am approach during the calibration period the wam approach resulted an nse value between 0 35 at both bugil and hoedeok and 0 56 at the yongdam stations in the grb and 0 08 at koga and 0 43 at the gilgelabay stations in the ltb conversely the overall performance of the sp approach in terms of the nse varies between 0 35 in the guryong and 0 61 in the yongdam catchments in the grb and varies between 0 15 in the megech and 0 42 in the gummera catchments of the ltb see table 4 for the case of the physical similarity approach the ltb was delineated into 109 smaller subbasins using gis 47 subbasins are found in the five gauged watersheds while the rest are ungauged conversely the grb was delineated into 73 smaller subbasins 52 subbasins are found in the eight gauged watersheds by overlaying the soil use land use and slope of the basin using gis the 109 smaller units in the ltb and 73 smaller units in the grb were grouped into six and nine physically similar homogeneous groups respectively see fig 7 a and b based on the similarity of land use soil use and slope the performance of the ps approach in terms of the nse varies between 0 42 in the bugil and 0 63 in the yongdam catchments in the grb and varies between 0 09 in the megech and 0 63 in the gummera catchments in the ltb see table 4 in the crrs approach the two step approach was used to estimate the parameter values at the ungauged subbasins in the first step the weighted mean values of the calibrated parameters from the gauged subbasins were used to generate the runoff in the entire study basin the ltb was subdivided into 109 smaller subbasins that are known to be hrus and these smaller subbasins were clustered into six hydrologically similar regions based on the rainfall and runoff response of each smaller units see fig 8 a conversely the grb was subdivided into 73 smaller hrus and clustered into nine hydrologically similar groups see fig 8 b based on the similarity of the rainfall and runoff response of the smaller subbasins the performance of the crrs approach in terms of the nse varies between 0 49 in both bugil and guryong and 0 69 in the yongdam catchments of the grb and varies between 0 12 in the koga and 0 69 in the gummera catchments of the ltb the evaluation result shows that the proposed parameter transfer crrs approach outperforms the other three commonly used parameter transfer approaches see table 4 table 4 presents the performance of all proposed parameter transfer schemes overall the wam method perform poorly conversely the crrs ps and sp methods provided better estimates of the runoff from the ungauged catchments of the two study basins the crrs method performed best in the ten test catchments and essentially performed equally with the other parameter transfer approaches in the remaining three test catchments during the calibration period therefore the crrs approach of parameter transfer proved to be good for the prediction of the runoff in the ungauged catchments with performance improvements of up to 26 and 34 during the calibration and validation periods respectively compared with the second best parameter transfer method see table 4 consequently the conclusion of this study is that the crrs one of the best approaches to estimate the runoff in worldwide ungauged basins the predictive capacity of the parameter transfer schemes for estimating the swat model parameters must be evaluated with the predictive performance of the swat model when run with the estimated regionalized and calibrated parameters the predictive performance of both the calibrated and regionalized models over both the two study basins during the calibration and validation periods are summarized in table 4 and fig 9 some key findings are summarized below the newly proposed parameter transfer approach crrs reaches 91 and 86 during the calibration and validation periods respectively of the at site calibrated model performance on average over eight test stations in the grb conversely it reaches 77 and 67 during the calibration and validation periods respectively of the at site calibrated model performance on average over five test stations in the ltb during the calibration period in the grb the maximum achievement ratio of the crrs crrs optimal at site 96 occurs in the bugil station and the minimum achievement ratio 84 occurs in the guryong station in the case of the ltb the maximum achievement ratio of crrs 92 occurs at the ribb station and the minimum achievement ratio 54 occurs at koga stations during the validation period in the grb the crrs is greater by 9 compared with the at site calibrated model performance at the seokhwa station and the minimum achievement ratio 69 of the crrs occurs at the cheongju station in the case of the ltb during the validation period the maximum achievement ratio 92 of the crrs occurs at the gilgelabay station and the minimum 41 occurs at the ribb station when we compare the achievement ratios of the crrs with the other three parameter transfer approaches wam ps and sp the crrs is 10 during the calibration and 7 during the validation period greater than the second best parameter transfer approach ps on average over all eight test stations in the grb in the case of the ltb the crrs is 14 during the calibration and 4 during the validation period greater than the second best parameter transfer scheme ps on average over five test stations overall the crrs approach outperformed all other parameter transfer approaches in the two study basins followed by the ps approach the ps approach performed better than the crrs approach in the cheongju and guryong stations during the calibration period and in the bugil and guryong stations during the validation period for the case of the grb the ps approach also performed better than the crrs approach in the koga station during both the calibration and validation periods for the case of the ltb for the rest of the test stations the crrs performance was better fig 9 shows that the performance variation range across the test station in the case of the ltb is high compared to the performance range in the grb this demonstrates that the swat model in the ltb yields highly uncertain results it is important to know that the accuracy of the hydrological model simulation mostly depends on the weather data accuracy however the weather gauging stations in the ltb are scarce and unevenly distributed leading to the high uncertainties in the hydrologic simulation results see fig 9 it is essential to discuss the most important findings from the results of crrs application in the two hydro geographically different basins as well as to propose future directions for how to improve the hydrological prediction accuracy the performance results of the regionalized parameters of swat in the watersheds of the grb and ltb exhibit patterns similar to the performance of the at site calibrated parameters in both the calibration and validation period as might be expected the evolution of the hydrologic modeling uncertainty with the watershed management and input data conditions resulted in much higher total model uncertainty being observed in the poorly managed ltb than in the fairly well managed grb watersheds the regionalized parameter performance results in general have high uncertainty in the ltb such that the crrs and other parameter transfer approaches for the megech and koga watersheds were found to perform poorly see table 4 the hydrologic simulation results of the at site calibrated swat in the two watersheds are also unreliable the poor performance in the megech and koga watersheds may be attributed to the inability of the swat model to reproduce streamflows in mountainous areas that lack robust data sets due to spatially insufficient observations that is in which only a single weather station exists for each watershed i e merawi for koga and gonder for megech the other main feature distinguishing the megech and koga watersheds from the other watersheds in the ltb is the size of their smallest watersheds the swat model performed poorly in the smaller watersheds koga and megech but performed relatively better in the larger watersheds in the ltb more importantly there are activities in these two watersheds that can be considered substantial sources of uncertainty such as the construction of infrastructure upstream of the watershed the abstraction of flow for small scale irrigation and other unknown activities in general the main sources of predictive uncertainty in the koga and megech watersheds might be associated with the inability of the swat modeling framework to capture the processes occurring in the watersheds the mismatch between the real processes occurring in the watershed and the process included in the model e g the existence of artificial open reservoirs water diversions upstream water supply and irrigation abstraction and observational errors in the meteorological variables input to the modeling framework the high predictive uncertainty in the data scarce region ltb is expected since poor spatial coverage and uneven distribution of rainfall stations leads to high hydrologic prediction uncertainty it is also important to note that there are poor watershed management practices in the ltb e g deforestation and overgrazing that can increase soil erosion as the parameters of swat do not account for the effect of soil erosion on runoff the relatively high predictive uncertainty in the ltb could be associated with soil erosion which affects the structure infiltration capacity and other soil properties the most important question to be addressed by future work in the study basin is therefore how to reduce the hydrologic modeling predictive uncertainty in the ungauged and gauged basins it is evident that the quality of data and its spatial distribution form the backbone for understanding and predicting hydrologic processes in any type of watershed to this end different observation technologies and strategies have been emerging in recent decades advances in weather observation by means of radar and satellite technologies have become more widely available due to an increase of areal coverage e g krajewski et al 2010 in addition zeng et al 2018 reported that an increase in the number of rain gauges resulted in reduced hydrologic modeling uncertainty results faridzad et al 2018 also suggested using remotely sensed precipitation data for data scarce regions to improve hydrological modeling results the usage of such data could improve hydrological process modeling results in the gauged and ungauged basins especially in the ltb as the precipitation gauge stations are scarce and unevenly distributed another source of uncertainty that warrants more research is the choice of the objective function for the model calibration as this choice can have considerable impacts on the results in this study we used the nse as it is one of the most popular normalized measures of model performance it is however oversensitive to peak flows due to its use of squared residuals it might thus be possible to reduce the model predictive uncertainty by using an optimization approach that allows for a balanced representation of the hydrograph based on weighting different parameterizations for the dry and peak flow periods moreover the existence of artificial open reservoirs water diversions upstream water supply and irrigation abstraction were not explicitly included in the hydrologic modeling framework but their inclusion might reduce the hydrologic predictive uncertainty it is essential to recognize how a crrs parameter transfer approach resolves the main problems in more traditional parameter transfer approaches one of these main problems that is addressed by crrs is the difficulty in identifying the key attributes that favor hydrologic similarity as the runoff is the integrated output that expresses all of the interactions related to the hydrological phenomenon within a basin it would be ideal if the hydrological similarity could be determined by this attribute as revealed by the results of this study the other key advantage of the crrs approach over more traditional parameter transfer approaches is the reduction of hydrologic prediction uncertainty in the ungauged catchments by the two step parameter transfer approach in general the novelty of the crrs approach lies in the proposal to use runoff response as an attribute for identifying hydrologically similar catchments 4 4 water resource potential water resources are often quantified in terms of blue water flow water yield plus deep aquifer recharge green water storage soil moisture and green water flow actual evapotranspiration abbaspour et al 2015 using the calibrated and regionalized model the long term average internal blue water resources green water storage and green water flow are mapped for the grb 1981 2016 and ltb 1995 2012 fig 10 the results show a wide range of spatial variation of internal blue water resources in both study basins fig 10 the temporal variation of internal blue water resources is computed with the coefficient of variation cv for the simulation period the cv for the blue water flow green water storage and green water flow respectively varies between 26 and 62 4 and 54 and 5 and 25 in the grb and 11 and 47 4 and 14 and 5 and 38 in the ltb areas with larger green water storage might have higher potential for development of rainfed agriculture abbaspour et al 2015 moreover the water resources potential of the ltb and grb were quantified by estimating the total runoff from the gauged and ungauged catchments the total surface water inflow into lake tana and total surface flow from the grb were estimated using the crrs approach the mean annual surface inflow into lake tana was found to be 6 93 bm3 for the analysis period of 1995 2012 the surface inflow from the ungauged catchment represents 44 45 of the total inflow into lake tana whereas the four major gauged catchments gilegelabay gummera megech and ribb contribute 55 55 of the total mean annual surface inflow into lake tana conversely the mean annual surface flow of the grb was found to be 6 43 bm3 for the analysis period of 1981 2016 the surface flow from the ungauged catchment of the grb represents 20 68 of the total surface flow of the grb 5 summery and conclusion this study presents a proposal of a new regionalization methodology crrs to reduce the runoff predictive uncertainty in the ungauged catchments as well as addressing the problem of the key attributes identification the crrs has two steps 1 the commonly used regionalization approach is applied to temporarily transpose the calibrated model parameter from gauged to ungauged catchments and 2 the runoff response of each smaller delineated subbasin of the gauged and ungauged basins are obtained based on the parameter value computed in the first step the similar subbasins of the gauged and ungauged basins are then identified based on their runoff response similarity the final parameter values in the ungauged subbasins are determined based on the similarity of runoff response of the subbasins the crrs was evaluated based on the performance of three widely used regionalization approaches i e ps sp and wam and the performance of the at site calibrated model in the grb of korea and the ltb of ethiopia the evaluation results with a leave one out cross validation approach at various test stations show the robustness of the crrs approach the crrs overall achievement ratio of the at site calibrated model performance reaches 91 in the grb 77 in the ltb during the calibration 86 in the grb and 67 in the ltb during the validation period as expected the crrs approach was the most successful while the wam approach was the least successful the performances of the ps and sp fell between those of crrs and wam approaches as shown in the overall analyses in the two study basins therefore the parameter transfer method crrs proposed in this study could be useful for other worldwide ungauged basins moreover the ps and sp approaches provided almost equal performances in the two different basins with climate conditions and stream gauging network densities contrary to the conclusion by oudin et al 2008 the ps slightly outperformed the sp approach in almost all test catchments of the grb categorized in a region with a dense stream gauge station and one gauge station covering 1232 km2 conversely the ps outperformed the sp in the two larger and well managed watersheds gilgelabay and gummera while the sp slightly outperformed the ps in the smaller watersheds koga and megech of the ltb it is important to note that the conclusions of most previous studies are based on analyses in large scale regions with areas greater than 100 000 km2 but the conclusions of this study are based on the analysis in small to medium scale watersheds with areas in the range 9000 15 000 km2 it should be recognized that the gauged and ungauged catchments in a small scale region could be spatially similar as per the regionalization analysis in the larger scale region it is expected that the sp could outperform the ps in large scale regions with diverse topographical climate soil use and land cover data this study therefore revealed that the performance of the various types of regionalization techniques could vary depending on the basin scale considered in the analysis moreover the ps outperformed the sp approach in the catchments with a relatively reliable model calibration result indicating the robustness of the ps approach for well managed watersheds in small to medium scale watersheds the mean annual total inflow into lake tana using the crrs regionalized model was found to be 6 93 bm3 for the period of 1995 2012 conversely the mean annual flow of the grb was found to be 6 43 bm3 based on the analysis period of 1981 2016 this research addressed a number of hydrological issues including the 1 identification of the most important flow parameters 2 hydrologic model uncertainty and 3 robust methodology for the estimation of surface runoff from the ungauged catchments conflict of interest the authors declare that there is no conflict of interest with respect to the publication of this paper acknowledgement this work was supported by the korea ministry of environment climate change correspondence program under project number 2014001310007 
7080,various types of regionalization approaches have been proposed in the last several decades for predictions in ungauged basins the most commonly used methods are based on the proximity of catchment centroids and physiographic and or climatic conditions of the catchments however the proximity of the catchment centroids and catchment physical attributes do not necessarily translate into similarities in hydrologic behavior it is also difficult to identify the key attributes that favor hydrologic similarity therefore in this study we proposed a new method called catchment runoff response similarity crrs in the view of reducing the hydrologic process predictive uncertainty and to solve the problem of the key attributes identification that favor hydrologic similarity the crrs has a two step approach 1 the commonly used regionalization approach is used to temporarily transpose the calibrated model parameter from gauged to ungauged catchments and 2 the runoff response of each smaller delineated subbasin of the gauged and ungauged basins are obtained based on the parameter value computed in the first step the similar subbasins of the gauged and ungauged basins are then identified based on their runoff response similarity the final parameter value in the ungauged subbasins are determined based on the notion that similar subbasins with runoff responses to similar input rainfall could have similar model structure settings the applicability of the proposed approach was verified for the geum river basin grb of south korea and the lake tana basin ltb of ethiopia leave one out evaluations of the proposed parameter transfer approach at various test gauging stations showed that the crrs approach outperformed the other widely used methods the crrs in the grb and ltb reached 91 and 77 during the calibration and 86 and 67 during the validation period respectively of the at site calibrated model performance on average over the test stations the overall worth of the crrs over the second best commonly used regionalization approach were also found to be 10 and 14 during the calibration and 7 and 4 during the validation period in the grb and ltb respectively in general it can be concluded from the overall result that the runoff predictive uncertainty in the ungauged catchments of the two study basins was significantly reduced by the crrs approach therefore the proposed approach can be used as an alternative method for runoff prediction in the ungauged basins worldwide keywords parameter transfer ungauged catchment catchment runoff response similarity geum river basin lake tana basin 1 introduction despite continuous research efforts and investments to accumulate hydrological data over the last century there are still some areas of the world with sparse hydrometric gauging stations in other words the density of hydrometric gauging stations is highly variable across the world in many hydrological analysis studies managing the ungauged catchments has therefore become a major obstacle that requires attention various versions of regionalization a process of transferring hydrological information from gauged to ungauged catchments have been developed in the past several decades the most common approaches for regionalization include arithmetic mean am jin et al 2009 merz and blöschl 2004 oudin et al 2008 physical similarity ps oudin et al 2008 samaniego et al 2010 samuel et al 2011 spatial proximity sp li et al 2009 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 and regression rg cheng et al 2006 götzinger and bárdossy 2007 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 young 2006 in the am approach each model parameter for the ungauged catchment is simply computed as a mean of the corresponding parameter of the gauged catchments therefore the parameter values are identical for all ungauged catchments the ps approach uses catchment attributes to group the similar catchments this approach identifies a donor catchment that is most similar to an ungauged site with respect to its catchment attributes and then transfers a complete parameter set from the donor to the corresponding ungauged catchment for hydrological modelling the success of this approach depends on the choices of attributes for the similarity of catchments the topography land use and soil type have been widely used as geomorphological attributes bastola et al 2008 heuvelmans et al 2006 merz and blöschl 2004 wagener et al 2007 whereas long term characteristics of precipitation and potential evapotranspiration have been applied as meteorological attributes bastola et al 2008 wagener et al 2007 the sp approach estimates the model parameters at ungauged catchments using an interpolation technique such as kriging merz and blöschl 2004 parajka et al 2005 this approach assumes that the nearby catchments are located in a homogeneous region the rg approach uses catchment attributes and hydrological model parameters as independent and dependent variables respectively cheng et al 2006 götzinger and bárdossy 2007 merz and blöschl 2004 parajka et al 2005 young 2006 the main concern of the rg approach is that the significance of dependent variables may vary from one catchment to the other to compensate for model structure errors mcintyre et al 2005 possibly resulting in a weak or null relationship between the independent and dependent variables moreover the structural form of the rg equations in the case of multiple ungauged catchments may vary from one catchment to the next even if those catchments share the same independent variables of the gauged catchments the other key issue with the rg approach is the interaction between the model parameters during the calibration mcintyre et al 2005 oudin et al 2008 this could produce complex response surfaces that are not well defined by either independent or correlated normal distributions mcintyre et al 2005 sorooshian and gupta 1995 moreover the response surface becomes more complex if applied to a model with several parameters mcintyre et al 2005 such as the case considered in this study various studies have compared the performance of different regionalization techniques in different basins arsenault and brissette 2014 bao et al 2012 jin et al 2009 kay et al 2006 li and zhang 2017 mcintyre et al 2005 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 patil and stieglitz 2012 samuel et al 2011 singh et al 2014 swain and patra 2017 young 2006 zhang and chiew 2009 zhang et al 2014 most previous studies have reported the robustness of the ps and sp approaches arsenault and brissette 2014 bao et al 2012 kay et al 2006 li and zhang 2017 mcintyre et al 2005 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 samuel et al 2011 swain and patra 2017 zhang and chiew 2009 zhang et al 2014 more importantly oudin et al 2008 compared the ps rg and sp regionalization approaches for runoff predictions in ungauged catchments using 913 gauged catchments in france they found that sp slightly outperformed ps in the areas characterized by a dense stream gauge network while the ps and sp predictive performances become similar when the stream gauging station network density decreases to 60 gauges per 100 000 km2 parajka et al 2013 reported that the effects of the parameter transfer approaches on model performance varies between studies based on a review of 34 past studies mentioning a tendency towards a lower performance of rg than other methods commonly used in those studies in their study ps and sp were found to be best in humid catchments while ps and rg perform slightly better in arid catchments this study also reviewed 15 past studies see table 1 and drew the same conclusion as oudin et al 2008 and parajka et al 2013 in terms of the robust performance of ps and sp over rg therefore in this study we adopted the ps and sp approaches to model the ungauged catchments of two different basins in terms of climate condition and stream gauging station network density in the ps approach a majority of the past studies used the similarity of the input attributes of the rainfall runoff model such as meteorological data e g rainfall temperature relative humidity solar radiation and wind speed and spatial data e g soil use land use and topography one would expect that these catchment attributes provide valuable information for modelling the ungauged catchments young 2006 but are not considered in the sp approach the ps approach assumes that the similarity in the input attribute be fully transferred to the output i e the runoff however the relation between the input and output variables in the hydrological process can be inherently different between gauged and ungauged basins furthermore it is difficult to consider all the necessary inputs in the regionalization procedure of the gauged and ungauged catchments due to this fact it has been reported that different researchers used different attributes for the regionalization of catchments it seems that an initial hypothetical judgment is required to identify the key catchment attributes influencing the runoff response razavi and coulibaly 2012 however it is difficult to select the key physiographic and or climatic conditions that best represent the hydrologic similarity moreover the proximity among catchment centroids used in sp are not necessarily translated into the hydrologic similarity kokkonen et al 2003 post and jakeman 1996 the above problems in ps and sp motivated the work in this paper to find a better attribute that can best represent the hydrological similarity as the runoff is the integrated output that expresses all of the interactions related to the hydrological phenomenon within a basin it would be ideal if the hydrological similarity could be determined by this attribute therefore in this study we propose a catchment runoff response similarity crrs approach that is based on the following steps 1 a conventional parameter transfer methods is used to transpose the model parameter from the gauged to ungauged catchments 2 the runoff response of each gauged and ungauged catchment are computed based on the defined parameter sets 3 the hydrological similarity between subbasins of the gauged and ungauged catchments are updated as per the similarity of their runoff response and 4 the model parameters in the ungauged catchments are re determined based on the updated similarity of the gauged and ungauged catchments 2 study area description two hydro geographically different basins one from the subtropical zone the geum river basin grb and the other from the tropical zone the lake tana basin ltb were used for this study the hydro climatic conditions in the grb are dominated by the asian monsoon with most of the annual precipitation and runoff taking place during the wet season july to september the development of water resources projects in the grb has disrupted the natural hydrologic processes therefore there are many sites where the natural discharge data is not readily available for prediction using the hydrological models in the ltb lake tana a natural lake covers an area of 3000 3600 km2 the climate of the ltb varies from humid to semiarid the summer monsoon is the driver for hydro climatic variability in the ltb with most of the precipitation occurring in the wet season june september and most of the annual flow occurring from july to october the grb see fig 1 a is the third largest river basin in south korea that lies in a natural drainage basin of 9859 km2 it geographically extends between 126 41 128 25 e and 35 35 37 05 n the grb is the home of two large multipurpose dams yongdam and daecheong that have been built along the main river the total length of the main stream of the geum river is 395 9 km with an average slope of 16 74 the area is used for forestry 61 mixed forest 20 and other 19 purposes the elevation ranges between 80 and 820 m above the mean sea level the grb has a temperate climate with rainfall heavier in summer than winter with a mean annual temperature of 11 5 c the average annual rainfall in the basin is 1343 mm the observed daily weather data with a record length of more than 30 years were collected from 14 weather gauging stations namely boeun buan buyeo cheonan cheongju chungju chupungryung geochang geumsan gunsan imsil jeonju mungyeong and seosan the collected weather data from these weather stations were used to setup the soil and water assessment tool swat model the streamflow data from eight stations yongdam daecheong hoendeok seokhwa nonsan guryong cheongju and bugil and the weather data from 14 stations were retrieved from one of the government databases called water resources management information system the ltb is a part of the blue nile river basin located in a natural drainage basin with a size of 15 114 km2 it geographically extends between latitudes 10 95 n and 12 78 n and longitudes 36 89 e and 38 25 e the elevation ranges from between 914 and 4096 m above the mean sea level gilgelabay ribb gummera and megech in order from largest to smallest land area are the major gauged watersheds of the study area see fig 1 b the only surface outflow from the basin is the blue nile comprised of 7 of the blue nile flow at the border between ethiopia and sudan shahin 1985 the rainfall distribution in the basin has a monomodal pattern one peak value is observed during the rainy season based on the observations at 13 rainfall stations in the basin from 1995 to 2014 the mean annual rainfall ranges from 955 mm in enfranz to 2365 mm in enjibara similarly the mean annual minimum and maximum temperature varies from 8 8 c in merawi to 28 c in enfranz based on the land use classification 51 37 of the watershed area was covered by agriculture 21 94 was agropastoral 20 41 was covered by lake tana 0 39 was agrosilvicultural 0 13 was covered by wetland 5 47 was pastoral 0 15 was silvicultural 0 03 was silvipastoral and 0 11 was urban based on the soil classification halpic luvisol covering 20 68 of the watershed area is considered the dominant soil in the study area the observed daily weather data recorded over 32 years 1983 2014 at 13 weather gauge stations were used as the input for the selected model the observed weather data from 13 weather gauge stations were retrieved from the ethiopian national metrological agency and the ministry of water irrigation and energy of ethiopia provided the spatial input data digital elevation model dem land use and soil data and observed streamflow data it is apparent from the information of the two study basins that one single streamflow gauging station on average covers approximately 1232 and 3023 km2 in the grb and ltb respectively the spatial coverage of the streamflow gauging station in the grb is almost about three times denser than the coverage in the ltb moreover the meteorological stations are very sparse in the ltb compared to the grb the average weather stations in the grb and ltb represent 704 and 1163 km2 respectively the two catchments are used to test the applicability of the crrs approach in different basins in terms of the climate condition and stream gauging station network density the former and the latter are above and below respectively the cut off density 60 gauges per 100 000 km2 used by oudin et al 2008 for comparing the performance of the sp and ps 3 methodology 3 1 hydrologic model a semi distributed model the swat arnold et al 1998 has been applied to eight gauged watersheds of the grb i e bugil guryong nonsan cheongju yongdam daecheong hoedeok and seokhwa and to five gauged watersheds of the ltb i e gilgelabay gummera koga megech and ribb more recently tegegne et al 2017a b reported the applicability of the swat model in the two study basins as a physically based semi distributed hydrological model in the swat model a basin is divided into multiple subbasins that are then further subdivided into units with distinct soil and land use characteristics called hydrological response units hrus the surface runoff is estimated separately for each subbasin and routed to quantify the total surface runoff of the basin abbaspour et al 2007 the water balance equation in the swat model neitsch et al 2011 is based on 1 sw t sw 0 i 1 t r day q surf e a w seep q gw i where swt is the final water content mm swo is the initial soil water content on day i mm t is the time days rday is the amount of precipitation on day i mm qsurf is the amount of surface runoff on day i mm ea is the amount of evapotranspiration on day i mm wseep is the amount of water entering the vadose zone from the soil profile on day i and qgw is the amount of groundwater flow on day i mm for this study the modified soil conservation service runoff curve number scs cn is used to compute the surface runoff volume the potential evapotranspiration was estimated based on the penman monteith method monteith 1965 and the variable storage coefficient method is used to determine the flow through the channel 3 2 parameter sensitivity analysis over parameterization is a well known and commonly occurring problem in distributed hydrological models beven 1989 van griensven et al 2006 sensitivity analysis methods designed to reduce the number of parameters that require fitting with input output data are thus common spear and hornberger 1980 van griensven et al 2006 moreover tegegne et al 2017a b reported that the streamflow generation using the swat model in both study basins was influenced by a particular subset of the original parameters suggesting the need to implement sensitivity analysis of parameters during calibration in general sensitivity analysis is useful in calibration of hydrological models and also for their transposition to different watersheds e g cibin et al 2010 in this study the model parameter sensitivity analysis used to identify the parameters that affect streamflow generation using swat was done with the global sensitivity analysis techniques therefore the global sensitivity analysis is performed before the calibration of the swat model to identify the most sensitive parameters it is based on the average change in the objective function for each parameter while all other parameters are changing the parameter sensitivity is quantified based on the t stat and p value statistical characteristics a larger absolute value of t stat and smaller p value indicates a more sensitive parameter for the sensitivity analysis the 13 important swat model parameters see table 2 that affect streamflow predictions were identified through a detailed literature review arabi et al 2007 neitsch et al 2011 cibin et al 2010 tegegne et al 2017a b 3 3 parameter calibration and uncertainty analysis the sequential uncertainty fitting sufi2 abbaspour et al 2004 one of the methods integrated in swat calibration and uncertainty programs swat cups is used for calibration and uncertainty analysis the uncertainties of parameters in sufi 2 account for all sources of uncertainty including model structure model input e g rainfall and temperature measured data for model calibration and validation e g discharge by propagating these uncertainties in the parameters abbaspour et al 2004 sufi 2 uses a latin hypercube sampling procedure to sample from the parameter intervals and the initial parameter ranges are updated at each iteration until a narrower parameter uncertainty range is obtained abbaspour et al 2004 the sufi2 calibration and uncertainty analysis result is evaluated based on the closeness of the percentage of observations covered by the 95 prediction uncertainty 95ppu p factor to 100 and the relative width of a 95 probability band r factor to zero a p factor of 100 and an r factor of zero represent a simulation that exactly corresponds to the observed data in fact most of the observations can be covered by the 95 interval leading to a high p factor at a large parameter range high r factor therefore the two indicators have to be used to evaluate the model uncertainty results abbaspour 2013 suggested that a p factor value of greater than 70 corresponds to an r factor of 1 in general the main steps of sufi 2 can be summarized as follows 1 define the objective function and physically meaningful parameter range 2 hypercube parameter sampling is performed within the defined parameter range that leads to a number of parameter combinations equal to the number of simulation iterations 3 the 95ppu is computed and evaluated as per the two performance metrics p factor and r factor and 4 as per the evaluation criteria the parameter ranges are updated and are always centered around the best estimates the p factor and r factor can be computed using the following equation 2 p factor t 1 t z t t 100 z t 1 if q t o q t 2 5 s q t 97 5 s 0 otherwise 3 r factor 1 t t 1 t q t 97 5 s q t 2 5 s σ obs where q t 97 5 s and q t 2 5 s represent the upper calculated at the 97 5 levels of cumulative distribution and lower calculated at the 2 5 levels of cumulative distribution simulated boundaries at time t respectively t is the number of time steps in the observed data s indicates the simulated values o indicates the observed values t is the simulation time step σ obs is the standard deviation of the observed data q t o is the observed data at time step t and z t has a value of 1 when the observed discharge is within the 95ppu interval the objective function applied to the simulation in the sufi 2 is the well known nash sutcliffe efficiency nse method nash and sutcliffe 1970 4 nse 1 i 1 n o i p i 2 i 1 n o i o 2 where p i is the simulated value o i is the measured value and o is the average measured value 3 4 common parameter transfer approaches 3 4 1 arithmetic mean approach the am is mainly used for first phase parameter transfer of the crrs approach that is discussed in detail in section 3 5 in the am approach each model parameter for the ungauged catchment is simply computed as the mean of the corresponding parameters of the gauged catchments and this is based on the assumption that the hydrologic prediction in the am approach will be within the uncertainty resulting from calculating the metric of similarity in this study a little better am method i e the weighted average wam approach is used in this modified am approach each model parameter for the ungauged catchment is simply computed as a weighted mean of the corresponding parameter of the gauged catchments that might be useful for uncertain modelling results for example the performance of the swat model in reproducing the runoff might be good in one gauge catchment and poor in the other therefore the weighted mean of the calibrated parameters might be a good approach in such conditions of uncertain performance results of the hydrologic model the weighted mean value of the calibrated model parameters of the gauged catchments are then assumed identical for all ungauged subbasins of the study basin the weight of each calibrated model parameter in each gauged catchment is determined based on their performance in reproducing the observed runoff at the corresponding gauged catchments the reliability of each calibrated parameter is determined based on the model performance during the calibration and validation period as measured by the nse the weight r i for the ith calibrated parameter is determined by the multiplication of two factors 1 the calibrated parameter performance to reproduce the runoff during the calibration period and 2 the calibrated parameter ability in reproducing the runoff in the validation period the model reliability ranges from zero unreliable to one reliable the weight is given by 5 r i nse c i m nse v i n where r i indicates the weight of the ith calibrated parameter in terms of reliability nse c i indicates the reliability of the i th calibrated parameter through the nse during the calibration period nse v i indicates the reliability of the ith calibrated parameter through the nse during the validation period and m and n are the parameters to provide a weight based on the importance for the reliability during the calibration and validation periods respectively note that i represents the number of gauged catchments that are considered for multi model averaging the number of gauge catchments in our study are eight and five for the cases of the grb and ltb respectively the main idea of weighting the swat model parameters θ i of each gauged catchment is to give more weight to the best performed calibrated parameter sets this will likely improve the uncertainty of the runoff prediction over the simple arithmetic mean approach the weighted model parameters θ w at the ungauged subbasin can be computed as 6 θ w i 1 n r i θ i i 1 n r i 3 4 2 physical similarity approach the physical similarity approach is based on the assumption that catchment physiographic characteristics predetermine the hydrological behavior the catchment attributes used to define the similarity are related to the topography land cover and soil features derived from the available data such as land use soil use and dem these catchment attributes are considered the main drivers of the hydrological process in the literature merz and blöschl 2004 in addition the selection of the appropriate catchment attributes depends on the physical meaning of the selected model parameters objective of the regionalization procedure and knowledge regarding the key hydrological processes occurring within the catchment sellami et al 2014 for instance the curve number parameter cn2 in the swat model depends on the soil and land use characteristics of the catchment thus the concept of the hrus similarity in which the land use soil use and land slope are unique is introduced to facilitate the parameter transfer from gauged to ungauged catchments 3 4 3 spatial proximity approach the spatial proximity approach is based on the spatial distance between catchment centroids that are interpolated as function of the geographic location the spatial interpolation technique used in this study is kriging samuel et al 2011 that is known to be better than the inverse distance weighting method the basic tool of kriging is the semivariogram that captures the spatial dependence between samples by plotting the semivariance against the separation distance 3 5 the catchment runoff response similarity approach in this study we propose a new parameter transfer approach based on the two step approach of parameter transfer see fig 2 at the first step the existing parameter transfer methods e g am ps and sp can be used to temporarily transpose the calibrated model parameter from the gauged to ungauged subbasins the modified am wam approach is used for this study as the number of gauged watersheds are too limited in the two case study basins it is difficult to subgroup the already grouped similar subbasins based on the ps and or sp approaches due to a limited number of donor subbasins this is because the number of similar groups will be too high compared to the number of donor catchments if we further subgroup the identified similar groups based on the ps and or sp approaches at the first approach in which some similar groups may not have a similarity with the donor catchments however the ps and sp approaches can be used as a first parameter transfer approach for the study basins with too many donor subbasins the second step of the proposed parameter transfer approach is based on the notion of hydrologic similarity the subbasins that have similar runoff responses and rainfall characteristics are considered hydrologically similar once the hydrologically similar subbasins are identified the final parameter values of each of the ungauged subbasins can be easily transposed from the gauged to ungauged subbasins the calibration of swat involves the selection of a parameter set that reproduces the historically observed runoff signatures at each gauged catchment as closely as possible it is essential to note that the runoff response associated with the calibrated parameters is the integrated output of the model and expresses all of the interactions related to the hydrological phenomenon within a basin the regionalization of the calibrated swat model parameter values from the gauged to the ungauged basins can consequently be related to the runoff signatures with the aim of reducing the hydrologic predictive uncertainty in the ungauged basin as runoff is the integral output for the estimated parameter the detailed systematic procedures of crrs are summarized in six steps as follows see also fig 2 step 1 the hydrologic models for the gauged and ungauged basins are set up by inputting the spatial data i e land use soil use and slope and meteorological data e g rainfall temperature relative humidity wind speed and solar radiation into the model step 2 the gauged and ungauged basins are subdivided into smaller subbasins using a geographical information system gis that keeps track of the flow direction in a dem land use soil type and slope of all the subdivided subbasins are then classified and overlaid to form the hydrologic response units hrus the dominant land use soil and slope of each subbasin are used to define the hrus in each subbasin step 3 model parameters are calibrated for each subbasin of the gauged watersheds step 4 the first phase parameter transfer from gauged to ungauged subbasins is based on the commonly used parameter transfer approaches the ps sp or am parameter transfer approaches can be used during this phase in the case of the ps approach the similarity of hrus with similarity in land use soil type and slope is used to group similar subbasins into n hydrologically similar groups in the sp approach on the other hand the gauged and ungauged subbasins are grouped into n hydrologically similar subbasins based on the assumption that proximate subbasins will likely have a similar runoff regime during the first phase the model parameters and model output i e runoff response are temporarily supposed to be known by transposing the calibrated model parameters from the gauged into the ungauged subbasins using the commonly used parameter transfer approaches here we temporarily assign a calibrated parameter value for each similar subbasin as per the parameter transfer approach used in the first phase this is because catchments with a similar response may actually have very different parameters for the rainfall runoff transformation we therefore assign similar parameter values for all similar subbasins as per the regionalization approach used in the first phase of the proposed approach since our aim is to further identify the similar subbasins based on their runoff response similarity it is important to note that the procedure of the commonly used parameter transfer approaches am ps and sp can be applied in those basins with a sufficient number of gauged streamflow stations during the first phase of the parameter transfer method step 5 the hydrologic model is used to predict the runoff in all subbasins of the gauged and ungauged basins since the system in all ungauged subbasins is known arbitrarily through the first phase parameter transfer the runoff output of swat for each subbasin is obtained and normalized by the corresponding subbasin area the normalized runoff runoff response of the subbasins is considered the main attribute for identifying hydrologically similar regions step 6 in the second phase of the parameter transfer approach the model parameters are transposed from the gauged to the ungauged subbasins by means of crrs this is the ultimate goal of the proposed parameter transfer approach the self organizing map clustering technique the details were presented by kohonen 1990 is used here to identify hydrologically similar subbasins using the runoff response and rainfall of each subbasin this parameter transfer approach is a promising approach that can yield more precise interpretation of the term hydrologic similarity widely used in previous studies finally the hydrologic model for the ungauged basins are updated with the final parameter values to obtain the runoff and other important water balance components from the ungauged basins the performance of the proposed parameter transfer approach should be assessed by comparing the predicted and observed response characteristics for gauged test catchments as the number of gauged catchments for the ltb and grb are limited to five and eight respectively a leave one out evaluation technique is carried out to successively validate the proposed approach therefore the performance of the parameter transfer scheme is successfully cross validated by assuming each gauged one gauged catchment at once catchment is ungauged the runoff output of the model with the regionalized and optimal calibrated parameters at each test catchment is compared and assessed to finalize the validation of the proposed approach 4 results and discussion 4 1 parameter sensitivity result the global sensitivity analysis on the swat model parameters were conducted for eight gauged stations yongdam daecheong hoedeok seokhwa nonsan guryong cheongju and bugil in the grb and for five gauged stations gilgelabay gummera koga megech and ribb in the ltb in the grb the observed flow record period used to run the swat were 2001 2016 for the yongdam nonsan guryong cheongju and bugil catchments 1981 2000 for the daecheong catchment 1998 2016 for the hoedeok and seokhwa catchments the observed flow prior to the operation of the yongdam dam reservoir is used to run the swat at the daecheong catchment in each of the gauged catchments of the grb the last four years are used for model validation in the ltb a large amount of data is missing with respect to hydrometeorological observations prior to 1998 for the gilgelabay gummera megech and koga catchments and prior to 1995 for the ribb catchment therefore only recent flow data from the gilgelabay gummera megech and koga catchments 1998 2012 and ribb catchment 1995 2009 were used to evaluate the simulation capabilities of the model in each of the cases of the ltb the last three years are used for model validation parameter sensitivity analysis in parameter regionalization is important for simplifying the structure of a complex hydrological model such as swat by minimizing the number of parameters involved in the modeling framework this provides a better identified model structure and facilitates the transposition of dominant parameters to different watersheds the implementation of parameter sensitivity analysis in parameter regionalization thus supports our primary hypothesis that the identification of the dominant parameters describing the key hydrological process of the system can reduce the model prediction uncertainty in the gauged and ungauged catchments from the sensitivity analysis results six flow parameters i e cn2 alpha bnk alpha bf ch k2 ch n2 and sftmp and six flow parameters i e cn2 ch k2 ch n2 gw delay alpha bnk and esco are found to be the most sensitive parameters for the grb and ltb respectively with the overall average p values 0 01 see fig 3 and absolute t stat values 7 the default values of the non sensitive parameters in both study basins were used for the simulation of the streamflow fig 3 illustrates the small to null p value variation for the selected most sensitive parameters across all watersheds of the two case study basins for example there is no p value variation across any of the watersheds for the parameters cn2 alpha bnk alpha bf ch n2 and ch k2 in the grb and for the parameters cn2 ch k2 and ch n2 in the ltb see fig 3 moreover most of the identified sensitive parameters are the same for all watersheds of each case study basin but they differ in their ranking it is vital that the identified dominant parameters that are assumed to describe the hydrologic process of the real system are consistent across all gauged watersheds so that the transposition of these parameters from the gauged to ungauged catchments can reduce the uncertainty of hydrologic prediction in the ungauged catchments for simplicity fig 4 presents an example of the parameter sampling distributions for the most sensitive and insensitive parameters in the megech ribb seokhwa and yongdam watersheds the parameter density distribution sunflower plots display the density of sampling points see fig 4 dark and light sunflowers represent high and medium density areas of parameter sampling respectively and each marker symbol represents one model run for low density sampling points in fig 4 the dotty plot for the most sensitive parameters i e alpha bnk and cn2 shows that the parameter samples are relatively very dense around the maximum with narrow ranges the analysis based on the parameter density distributions in all watersheds revealed that the high density parameter sampling of the most sensitive parameters seemed to vary over narrower ranges toward unimodal posterior distributions while the high density region of the non sensitive parameters varied over wider ranges toward flat posterior distributions in other words the unimodal peaked posterior distributions are associated with easily identifiable parameters while flat distributions indicate non identifiability of parameters from the variation in parameter sampling of the values of the nse as measured by p and t stat values it was evident that the four most sensitive parameters in all watersheds of both study basins were cn2 ch k2 ch n2 and alpha bnk among these four parameters the most sensitive in most of the watersheds was cn2 gilgelabay gummera koga megech ribb bugil cheongju hoedeok nonsan and seokhwa alpha bnk was most sensitive in the guryong and yongdam watersheds and the ch k2 was in the daecheong watershed the sensitivity of the daily streamflow simulations to the cn2 parameter in most of the watersheds is expected since this parameter is the primary influence on the amount of runoff generated from a hydrologic response unit cibin et al 2010 the result is consistent with the conclusion of gassman et al 2007 that cn2 was an important parameter affecting hydrologic simulations in all of the model applications it is noteworthy that only a few sampling points in the watersheds of the ltb see fig 4 as an example for the megech and ribb watersheds have nse values significantly greater than zero whereas many sampling points in the grb had nse values significantly greater than zero the problem of parameter sampling in the ltb might be related to the quality of measured rainfall data and measured discharge data poor spatial coverage of rainfall data within the ltb could be another cause 4 2 parameter calibration and uncertainty result in the ltb the calibrated swat model poorly performed in the smaller watersheds koga and megech but performed relatively better in the larger watersheds see table 3 conversely the swat model in the grb achieves more than 60 and 50 of the observed flow characteristics on average over all gauging stations during the calibration and validation periods respectively in terms of the nse indicator in summary the values of the nse obtained for all watersheds in the grb using the sufi 2 calibration strategy vary between 0 51 at bugil and 0 74 at yongdam for the calibration and 0 23 at cheongju and 0 80 at daecheong for the validation period on the other hand the performance of swat in the watersheds of the ltb in terms of the nse fall between 0 22 at koga and 0 76 at gummera for the calibration and 0 14 at koga and 0 76 at gummera for the validation period the performance results of swat in the watersheds of the grb and ltb from the validation period show a similar pattern to those from the calibration period except for the poor validation performance in the cheongju watershed from the grb moriasi et al 2007 suggested that model simulation can be judged as satisfactory if nse is greater than 0 5 the results in the watersheds of the two case study basins agree reasonably well with this value except the koga and megech watersheds of the ltb during both the calibration and validation period and the cheongju watershed of the grb during the validation period it is important to present the hydrologic model prediction results with an envelope of good solutions expressed by the 95ppu produced by certain parameter ranges in addition to the model performance by reproducing the observed hydrograph figs 5 and 6 present the 95 prediction uncertainty comprising of all uncertainties in the model observed streamflow and best simulated streamflow plot for the four more representative gauged catchments in both the grb and ltb respectively the p and r factors were used to evaluate the sufi 2 in quantifying the uncertainty in the grb p factors of 0 78 0 78 0 77 0 86 0 93 0 68 0 73 and 0 80 and r factors of 0 42 0 38 0 47 0 46 0 43 0 45 0 27 and 0 37 were quantified for the yongdam hoedeok seokhwa daecheong bugil cheongju guryong and nonsan catchments respectively while in the ltb p factors of 0 64 0 85 0 74 0 44 and 0 13 and r factors of 1 1 0 78 0 59 0 70 and 0 17 were found for the gilgelabay gummera megech ribb and koga catchments respectively the p and r factors for all gauged catchments in the grb and for the gilgelabay gummera and megech watersheds in the ltb are acceptable however the p factor for the ribb and koga watersheds in the ltb are not within acceptable limits indicating that the parameter uncertainties were not within the desired ranges for the ribb and koga watersheds the mean values of the estimated p factors and r factors in the watersheds of the grb were found to be 79 and 0 4 respectively conversely the mean values of the estimated p factors and r factors in the watersheds of the ltb were found to be 56 and 0 67 respectively the uncertainty analysis shows that the sufi 2 captured the observations much better in the watersheds of the grb than in those of the ltb note that the p factor in the koga watershed combined with the poor performance values for the nse revealed that there is high uncertainty of simulated flow due to errors in input data and other sources of uncertainty such as upstream dam construction for town water supply diversion of streams for irrigation and other unknown activities specific to the koga watershed the model uncertainty range of the ltb was observed to be higher than that of the grb see figs 5 and 6 the high uncertainty in the ltb might be due to the sparse spatial distribution of the meteorological stations and the quality of the hydrometric data it is therefore suggested that more accurate areal rainfall estimation and more precipitation stations should be established for more accurate hydrological modeling in the ltb in both study basins the low flows were well bracketed by the 95ppu while the peak flows were relatively less captured within the 95ppu however the relative thickness of the 95ppu as measured by the r factor for the peak flow were relatively less compared to the relative width in the low flows this result shows that the swat model prediction of the low flows is highly uncertain compared to its predictive uncertainty of the high flow 4 3 evaluation of the catchment runoff response similarity approach the total of 13 representative gauging sites 8 from korea and 5 from ethiopia were selected to test the applicability of the crrs approach with a jack knife cross validation approach and the performances of the crrs approach at each test site were compared with the wam ps and sp approaches see fig 9 and table 4 the wam parameter transfer approach shows the poorest results in all test sites compared to the other approaches and even the am provided poor results compared with the wam results this shows that the poorly modelled watershed yields highly uncertain model parameter values in the am approach during the calibration period the wam approach resulted an nse value between 0 35 at both bugil and hoedeok and 0 56 at the yongdam stations in the grb and 0 08 at koga and 0 43 at the gilgelabay stations in the ltb conversely the overall performance of the sp approach in terms of the nse varies between 0 35 in the guryong and 0 61 in the yongdam catchments in the grb and varies between 0 15 in the megech and 0 42 in the gummera catchments of the ltb see table 4 for the case of the physical similarity approach the ltb was delineated into 109 smaller subbasins using gis 47 subbasins are found in the five gauged watersheds while the rest are ungauged conversely the grb was delineated into 73 smaller subbasins 52 subbasins are found in the eight gauged watersheds by overlaying the soil use land use and slope of the basin using gis the 109 smaller units in the ltb and 73 smaller units in the grb were grouped into six and nine physically similar homogeneous groups respectively see fig 7 a and b based on the similarity of land use soil use and slope the performance of the ps approach in terms of the nse varies between 0 42 in the bugil and 0 63 in the yongdam catchments in the grb and varies between 0 09 in the megech and 0 63 in the gummera catchments in the ltb see table 4 in the crrs approach the two step approach was used to estimate the parameter values at the ungauged subbasins in the first step the weighted mean values of the calibrated parameters from the gauged subbasins were used to generate the runoff in the entire study basin the ltb was subdivided into 109 smaller subbasins that are known to be hrus and these smaller subbasins were clustered into six hydrologically similar regions based on the rainfall and runoff response of each smaller units see fig 8 a conversely the grb was subdivided into 73 smaller hrus and clustered into nine hydrologically similar groups see fig 8 b based on the similarity of the rainfall and runoff response of the smaller subbasins the performance of the crrs approach in terms of the nse varies between 0 49 in both bugil and guryong and 0 69 in the yongdam catchments of the grb and varies between 0 12 in the koga and 0 69 in the gummera catchments of the ltb the evaluation result shows that the proposed parameter transfer crrs approach outperforms the other three commonly used parameter transfer approaches see table 4 table 4 presents the performance of all proposed parameter transfer schemes overall the wam method perform poorly conversely the crrs ps and sp methods provided better estimates of the runoff from the ungauged catchments of the two study basins the crrs method performed best in the ten test catchments and essentially performed equally with the other parameter transfer approaches in the remaining three test catchments during the calibration period therefore the crrs approach of parameter transfer proved to be good for the prediction of the runoff in the ungauged catchments with performance improvements of up to 26 and 34 during the calibration and validation periods respectively compared with the second best parameter transfer method see table 4 consequently the conclusion of this study is that the crrs one of the best approaches to estimate the runoff in worldwide ungauged basins the predictive capacity of the parameter transfer schemes for estimating the swat model parameters must be evaluated with the predictive performance of the swat model when run with the estimated regionalized and calibrated parameters the predictive performance of both the calibrated and regionalized models over both the two study basins during the calibration and validation periods are summarized in table 4 and fig 9 some key findings are summarized below the newly proposed parameter transfer approach crrs reaches 91 and 86 during the calibration and validation periods respectively of the at site calibrated model performance on average over eight test stations in the grb conversely it reaches 77 and 67 during the calibration and validation periods respectively of the at site calibrated model performance on average over five test stations in the ltb during the calibration period in the grb the maximum achievement ratio of the crrs crrs optimal at site 96 occurs in the bugil station and the minimum achievement ratio 84 occurs in the guryong station in the case of the ltb the maximum achievement ratio of crrs 92 occurs at the ribb station and the minimum achievement ratio 54 occurs at koga stations during the validation period in the grb the crrs is greater by 9 compared with the at site calibrated model performance at the seokhwa station and the minimum achievement ratio 69 of the crrs occurs at the cheongju station in the case of the ltb during the validation period the maximum achievement ratio 92 of the crrs occurs at the gilgelabay station and the minimum 41 occurs at the ribb station when we compare the achievement ratios of the crrs with the other three parameter transfer approaches wam ps and sp the crrs is 10 during the calibration and 7 during the validation period greater than the second best parameter transfer approach ps on average over all eight test stations in the grb in the case of the ltb the crrs is 14 during the calibration and 4 during the validation period greater than the second best parameter transfer scheme ps on average over five test stations overall the crrs approach outperformed all other parameter transfer approaches in the two study basins followed by the ps approach the ps approach performed better than the crrs approach in the cheongju and guryong stations during the calibration period and in the bugil and guryong stations during the validation period for the case of the grb the ps approach also performed better than the crrs approach in the koga station during both the calibration and validation periods for the case of the ltb for the rest of the test stations the crrs performance was better fig 9 shows that the performance variation range across the test station in the case of the ltb is high compared to the performance range in the grb this demonstrates that the swat model in the ltb yields highly uncertain results it is important to know that the accuracy of the hydrological model simulation mostly depends on the weather data accuracy however the weather gauging stations in the ltb are scarce and unevenly distributed leading to the high uncertainties in the hydrologic simulation results see fig 9 it is essential to discuss the most important findings from the results of crrs application in the two hydro geographically different basins as well as to propose future directions for how to improve the hydrological prediction accuracy the performance results of the regionalized parameters of swat in the watersheds of the grb and ltb exhibit patterns similar to the performance of the at site calibrated parameters in both the calibration and validation period as might be expected the evolution of the hydrologic modeling uncertainty with the watershed management and input data conditions resulted in much higher total model uncertainty being observed in the poorly managed ltb than in the fairly well managed grb watersheds the regionalized parameter performance results in general have high uncertainty in the ltb such that the crrs and other parameter transfer approaches for the megech and koga watersheds were found to perform poorly see table 4 the hydrologic simulation results of the at site calibrated swat in the two watersheds are also unreliable the poor performance in the megech and koga watersheds may be attributed to the inability of the swat model to reproduce streamflows in mountainous areas that lack robust data sets due to spatially insufficient observations that is in which only a single weather station exists for each watershed i e merawi for koga and gonder for megech the other main feature distinguishing the megech and koga watersheds from the other watersheds in the ltb is the size of their smallest watersheds the swat model performed poorly in the smaller watersheds koga and megech but performed relatively better in the larger watersheds in the ltb more importantly there are activities in these two watersheds that can be considered substantial sources of uncertainty such as the construction of infrastructure upstream of the watershed the abstraction of flow for small scale irrigation and other unknown activities in general the main sources of predictive uncertainty in the koga and megech watersheds might be associated with the inability of the swat modeling framework to capture the processes occurring in the watersheds the mismatch between the real processes occurring in the watershed and the process included in the model e g the existence of artificial open reservoirs water diversions upstream water supply and irrigation abstraction and observational errors in the meteorological variables input to the modeling framework the high predictive uncertainty in the data scarce region ltb is expected since poor spatial coverage and uneven distribution of rainfall stations leads to high hydrologic prediction uncertainty it is also important to note that there are poor watershed management practices in the ltb e g deforestation and overgrazing that can increase soil erosion as the parameters of swat do not account for the effect of soil erosion on runoff the relatively high predictive uncertainty in the ltb could be associated with soil erosion which affects the structure infiltration capacity and other soil properties the most important question to be addressed by future work in the study basin is therefore how to reduce the hydrologic modeling predictive uncertainty in the ungauged and gauged basins it is evident that the quality of data and its spatial distribution form the backbone for understanding and predicting hydrologic processes in any type of watershed to this end different observation technologies and strategies have been emerging in recent decades advances in weather observation by means of radar and satellite technologies have become more widely available due to an increase of areal coverage e g krajewski et al 2010 in addition zeng et al 2018 reported that an increase in the number of rain gauges resulted in reduced hydrologic modeling uncertainty results faridzad et al 2018 also suggested using remotely sensed precipitation data for data scarce regions to improve hydrological modeling results the usage of such data could improve hydrological process modeling results in the gauged and ungauged basins especially in the ltb as the precipitation gauge stations are scarce and unevenly distributed another source of uncertainty that warrants more research is the choice of the objective function for the model calibration as this choice can have considerable impacts on the results in this study we used the nse as it is one of the most popular normalized measures of model performance it is however oversensitive to peak flows due to its use of squared residuals it might thus be possible to reduce the model predictive uncertainty by using an optimization approach that allows for a balanced representation of the hydrograph based on weighting different parameterizations for the dry and peak flow periods moreover the existence of artificial open reservoirs water diversions upstream water supply and irrigation abstraction were not explicitly included in the hydrologic modeling framework but their inclusion might reduce the hydrologic predictive uncertainty it is essential to recognize how a crrs parameter transfer approach resolves the main problems in more traditional parameter transfer approaches one of these main problems that is addressed by crrs is the difficulty in identifying the key attributes that favor hydrologic similarity as the runoff is the integrated output that expresses all of the interactions related to the hydrological phenomenon within a basin it would be ideal if the hydrological similarity could be determined by this attribute as revealed by the results of this study the other key advantage of the crrs approach over more traditional parameter transfer approaches is the reduction of hydrologic prediction uncertainty in the ungauged catchments by the two step parameter transfer approach in general the novelty of the crrs approach lies in the proposal to use runoff response as an attribute for identifying hydrologically similar catchments 4 4 water resource potential water resources are often quantified in terms of blue water flow water yield plus deep aquifer recharge green water storage soil moisture and green water flow actual evapotranspiration abbaspour et al 2015 using the calibrated and regionalized model the long term average internal blue water resources green water storage and green water flow are mapped for the grb 1981 2016 and ltb 1995 2012 fig 10 the results show a wide range of spatial variation of internal blue water resources in both study basins fig 10 the temporal variation of internal blue water resources is computed with the coefficient of variation cv for the simulation period the cv for the blue water flow green water storage and green water flow respectively varies between 26 and 62 4 and 54 and 5 and 25 in the grb and 11 and 47 4 and 14 and 5 and 38 in the ltb areas with larger green water storage might have higher potential for development of rainfed agriculture abbaspour et al 2015 moreover the water resources potential of the ltb and grb were quantified by estimating the total runoff from the gauged and ungauged catchments the total surface water inflow into lake tana and total surface flow from the grb were estimated using the crrs approach the mean annual surface inflow into lake tana was found to be 6 93 bm3 for the analysis period of 1995 2012 the surface inflow from the ungauged catchment represents 44 45 of the total inflow into lake tana whereas the four major gauged catchments gilegelabay gummera megech and ribb contribute 55 55 of the total mean annual surface inflow into lake tana conversely the mean annual surface flow of the grb was found to be 6 43 bm3 for the analysis period of 1981 2016 the surface flow from the ungauged catchment of the grb represents 20 68 of the total surface flow of the grb 5 summery and conclusion this study presents a proposal of a new regionalization methodology crrs to reduce the runoff predictive uncertainty in the ungauged catchments as well as addressing the problem of the key attributes identification the crrs has two steps 1 the commonly used regionalization approach is applied to temporarily transpose the calibrated model parameter from gauged to ungauged catchments and 2 the runoff response of each smaller delineated subbasin of the gauged and ungauged basins are obtained based on the parameter value computed in the first step the similar subbasins of the gauged and ungauged basins are then identified based on their runoff response similarity the final parameter values in the ungauged subbasins are determined based on the similarity of runoff response of the subbasins the crrs was evaluated based on the performance of three widely used regionalization approaches i e ps sp and wam and the performance of the at site calibrated model in the grb of korea and the ltb of ethiopia the evaluation results with a leave one out cross validation approach at various test stations show the robustness of the crrs approach the crrs overall achievement ratio of the at site calibrated model performance reaches 91 in the grb 77 in the ltb during the calibration 86 in the grb and 67 in the ltb during the validation period as expected the crrs approach was the most successful while the wam approach was the least successful the performances of the ps and sp fell between those of crrs and wam approaches as shown in the overall analyses in the two study basins therefore the parameter transfer method crrs proposed in this study could be useful for other worldwide ungauged basins moreover the ps and sp approaches provided almost equal performances in the two different basins with climate conditions and stream gauging network densities contrary to the conclusion by oudin et al 2008 the ps slightly outperformed the sp approach in almost all test catchments of the grb categorized in a region with a dense stream gauge station and one gauge station covering 1232 km2 conversely the ps outperformed the sp in the two larger and well managed watersheds gilgelabay and gummera while the sp slightly outperformed the ps in the smaller watersheds koga and megech of the ltb it is important to note that the conclusions of most previous studies are based on analyses in large scale regions with areas greater than 100 000 km2 but the conclusions of this study are based on the analysis in small to medium scale watersheds with areas in the range 9000 15 000 km2 it should be recognized that the gauged and ungauged catchments in a small scale region could be spatially similar as per the regionalization analysis in the larger scale region it is expected that the sp could outperform the ps in large scale regions with diverse topographical climate soil use and land cover data this study therefore revealed that the performance of the various types of regionalization techniques could vary depending on the basin scale considered in the analysis moreover the ps outperformed the sp approach in the catchments with a relatively reliable model calibration result indicating the robustness of the ps approach for well managed watersheds in small to medium scale watersheds the mean annual total inflow into lake tana using the crrs regionalized model was found to be 6 93 bm3 for the period of 1995 2012 conversely the mean annual flow of the grb was found to be 6 43 bm3 based on the analysis period of 1981 2016 this research addressed a number of hydrological issues including the 1 identification of the most important flow parameters 2 hydrologic model uncertainty and 3 robust methodology for the estimation of surface runoff from the ungauged catchments conflict of interest the authors declare that there is no conflict of interest with respect to the publication of this paper acknowledgement this work was supported by the korea ministry of environment climate change correspondence program under project number 2014001310007 
7081,a double sided stochastic chance constrained linear fractional programming dsclfp model is developed for managing irrigation water under uncertainty the model is developed by incorporating double sided stochastic chance constrained programming dsccp into a linear fractional programming lfp optimization framework it can address ratio optimization problems with double sided randomness i e both left hand and right hand sides more importantly it also improves upon the existing stochastic chance constrained programming for handing random uncertainties in the left hand and right hand sides of constraints simultaneously a non equivalent but sufficient linearization form of the dsclfp is provided and proved which will greatly reduce the computational burden then the model is applied to a case study in yingke irrigation district yid in the middle reaches of the heihe river basin northwest china four confidence levels e g αi 0 85 0 90 0 95 and 0 99 are provided to examine and compare the results the objective function values are slightly decreased from 5 284 yuan m3 to 5 276 yuan m3 when αi level is raised from 0 85 to 0 99 the results from the dsclfp can identify desired irrigation water allocation plans under the objective function of maximizing water productivity under different confidence levels therefore the results can provide tradeoffs among water productivity confidence level and constraint violation risk level moreover comparisons with double sided stochastic chance constrained linear programming dsclp model and deterministic model are introduced to highlight advantages and feasibility of the developed model therefore these results can provide decision support for managers in arid areas keywords irrigation management linear fractional programming chance constrained programming double sided randomness water productivity 1 introduction under the pressures of the increasing water demands and the shortages of water supply sustainable water management is becoming an issue of great significance for water managers throughout the world especially in arid areas dominated by irrigated agriculture elliott et al 2014 kang et al 2017 there is a concern that the water productivity need to be addressed in irrigation water management problems due to water scarcity in other words this is a conflicting objective to maximize the system benefits with minimum irrigation water use generally water productivity is defined as a ratio representing the unit of outputs e g crop yield economic benefits per unit of irrigation water barker et al 2003 such a ratio optimization problem can be quantitatively solved by linear fractional programming lfp method which is effectively used to account for conflicting objectives and reflect system efficiency lara and stancu minasian 1999 gómez et al 2006 zhu and huang 2011 stancu minasian 2012 zhang and guo 2018 compared with traditional methods the lfp is superior to them to compare multiple objective directly through the original magnitudes guo et al 2014 particularly it s adopted in the management problems that need to compare two magnitudes e g output input moreover another concern is the inherent uncertainty in practical applications for example spatial and temporal changes in surface runoff and groundwater fluctuations of market prices effected by various stochastic factors li et al 2010 which are closely related to input parameters and hardly quantified accurately additionally the interrelationships among these uncertain factors and economic implications may cause challenges in planning irrigation water management due to system complexities tan et al 2011 li et al 2012 therefore it is imperative to develop novel method to deal with these concerns and generate irrigation water allocation plans for supporting sustainable irrigation water management previously three main types of inexact mathematical programming methods were proposed including interval parameter linear programming ilp fuzzy mathematical programming fmp and stochastic mathematical programming smp to address uncertainties among them smp method is exclusively for handling random variables expressed as known probability density functions pdfs in the model s input information gu et al 2013 guo et al 2014 zhang et al 2017 this means that when uncertain parameters can be described results can be presented as comparisons under different reliability levels as a major type of smp chance constrained programming ccp initially developed by charnes and cooper 1959 allows violation of system constraints indicating that not all of the constraints must be rigorously satisfied thus the random constraints can be hold at least a certain probability α where α 0 1 is defined as confidence level given by the decision makers this will normally increase the system benefits to a certain extent at a compromise of environmental capacity in irrigation water management problems generally due to the nonlinear forms in solving ccp problems it s commonly employed in the case of the independent right hand side randomness in constraints huang 1998 zhu and huang 2011 nemirovski 2012 for example huang 1998 proposed an inexact ccp method for water quality management where stochastic uncertainties exist in the right hand side of constraints zhu and huang 2011 developed a stochastic linear fractional programming for solid waste management where the right hand side coefficients are random for all α values moreover the ccp methods incorporated with the randomness in the left hand side of the constraints have also been developed for example cao et al 2011 developed an interval left hand side ccp method for regional air quality management sun et al 2013 developed an inexact joint probabilistic left hand side ccp model for solid waste management zhang et al 2017 proposed an interval multistage joint probabilistic ccp model with left hand side randomness for crop area planning however in practice random uncertainties may exist in both left hand side and right hand side of the constraints which will thereby lead to the above mentioned ccp methods not account for such a difficulty therefore based on the assumption of both left hand and right hand sides of randomness have gaussian distributions and α 0 5 α is the satisfaction degree of constraints roubens and teghem 1991 huang 1998 a double sided stochastic chance constrained programming dsccp method is useful for solving above difficulties liu 2009 although the algorithm of the dsccp can be directly proved by mathematical proof its nonlinear forms will inevitably intensify challenges in practical applicability furthermore the dsccp method can hardly account for ratio optimization problems and few scholars handled double sided random stochastic issues with lfp models nevertheless few applications of the dsccp method to irrigation water management are conducted therefore the objective of this study is to develop a novel method to address ratio optimization problems in the case of double sided random stochastic uncertainties in the constraints it is an attempt to develop such a double sided stochastic chance constrained linear fractional programming dsclfp model by incorporating the dsccp into a lfp framework for supporting irrigation water management under uncertainty it can improve upon the existing stochastic chance constrained programing by dealing with double sided randomness moreover to reduce computational burden and improve computational efficiency a non equivalent but sufficient linearization form of dsclfp model will be provided and proved for comparisons to demonstrate its applicability the developed model will be applied to a case study to manage irrigation water to different crops in the yingke irrigation district yid in the middle reaches of the heihe river basin northwest china several scenarios associated with confidence levels will be analyzed for examining and comparing the variations of results 2 methodology 2 1 linear fractional programming lfp in a linear fractional programming lfp problem it is generally considered as a functional relationship expressed as a ratio between two variables in the numerator and denominator charnes and cooper 1962 the numerator represents the change in total cost and other variables while the denominator represents the volume changes that may lead to the change of the related cost coefficients therefore lfp can deal with bi objectives problems and reflect system efficiency it can be formulated as follows 1a max f cx α dx β subject to 1b ax b 1c x 0 where a is a real m n matrix x and b are column vectors with n and m components respectively c and d are row vectors with n components α and β are constant terms the lfp model can address deterministic ratio optimization problems but it is not able to deal with complexities when uncertainties exist in the constraints of optimization model zhu and huang 2011 2 2 double sided stochastic chance constrained programming dsccp in a linear programming model when both left hand aij and right hand side bj parameters in the constraints are to be independently normally distributed random variables µ is expected value and σ is standard variation and the constraints are hold at a certain level of probability α then the double sided stochastic chance constrained programming dsccp method can be adopted as follows 2a max f j 1 n c j x j subject to 2b pr j 1 n a ij x j b i α i i 1 2 m 2c a ij ω n μ a i j σ a i j 2 2d b i ξ n μ b i σ b i 2 2e x j 0 j 1 2 n where f is the objective function xj is decision variable bi and cj are input parameters αi α i 0 1 refers to a given level of probability for constraint i representing the satisfaction degree level of constraints m is the number of constraints according to liu 2009 constraint 2b can be transformed into a nonlinear form and the set of feasible constraints is convex see theorem 1 theorem 1 eq 2b is equivalent to eq 3a that is if aij and bi are assumed to be independently normally distributed random variables then eq 2b can be hold if and only if 3a j 1 n μ a i j x j φ 1 α i j 1 n σ a i j 2 x j 2 σ b i 2 μ b i i 1 2 m where φ is the standardized normal distribution function proof since aij and bj are independently random variables following normal distributions let s introduce the variable y i j 1 n a ij x j b i i 1 2 m it also follows normal distribution its expected value and variance are presented as follows 3b μ y i j 1 n μ a i j x j μ b i 3c σ y i 2 j 1 n σ a i j 2 x j 2 σ b i 2 then the expression j 1 n a ij x j b i j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 must be standardized normally distributed accordingly the associated inequality j 1 n a ij x j b i i 1 2 m is equivalent to 3d j 1 n a ij x j b i j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 thus the chance constraint 2b can be converted into 3e pr z j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 α i i 1 2 m where z is defined as the standardized normally distributed random variable therefore the chance constraint 3e can be satisfied if and only if 3f φ 1 α i j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 i 1 2 m finally we have the deterministic equivalent of chance constraint 3a the theorem 1 is proved because eq 3a is presented as nonlinear form it will intensify computational burden when solving problems as an alternative solution method an approximated linearization form of eq 3a is proposed see theorem 2 theorem 2 eq 4a is a sufficient condition for eq 3a where α i 0 5 and x j 0 4a j 1 n μ a i j x j φ 1 α i j 1 n σ a i j x j σ b i μ b i i 1 2 m proof based on the following inequality 4b j 1 n t 2 j 1 n t t r t 0 when j 1 n σ a i j x j σ b i r and j 1 n σ a i j x j σ b i 0 we have 4c j 1 n σ a i j 2 x j 2 σ b i 2 j 1 n σ a i j x j σ b i moreover when α i 0 5 we have 4d φ 1 α i 0 thus from inequalities 4c and 4d we have 4e j 1 n μ a i j x j φ 1 α i j 1 n σ a i j 2 x j 2 σ b i 2 j 1 n μ a i j x j φ 1 α i j 1 n σ a i j x j σ b i i 1 2 m understandably if inequality 4a holds sufficient condition then from inequality 4e we have 3a therefore according to theorems 1 and 2 when α i 0 5 and x j 0 eq 2b can be transformed into a non equivalent but sufficient linearization form in 5a 5a j 1 n μ a i j x j φ 1 α i j 1 n σ a i j x j σ b i μ b i i 1 2 m 2 3 double sided stochastic chance constrained linear fractional programming dsclfp in this study a dsclfp model is developed in response to ratio optimization problems with double sided randomness in the constraints it incorporates dsccp model into lfp optimization framework the developed dsclfp model is written as follows 6a max f cx α dx β subject to 6b j 1 n μ a i j x j φ 1 α i j 1 n σ a i j 2 x j 2 σ b i 2 μ b i i 1 2 m 6c a ij ω n μ a i j σ a i j 2 6d b i ξ n μ b i σ b i 2 6e x j 0 j 1 2 n alternatively by using inequality 5a substituting constraint 6b we have a linearization form of dsclfp model 7a max f cx α dx β subject to 7b j 1 n μ a i j x j φ 1 α i j 1 n σ a i j x j σ b i μ b i i 1 2 m 7c a ij ω n μ a i j σ a i j 2 7d b i ξ n μ b i σ b i 2 7e x j 0 j 1 2 n 2 4 solution method the framework of the developed dsclfp model is graphically presented in fig 1 the detailed solution method can be further summarized as follows step 1 formulate the dsclfp model step 2 acquire the model input parameters including deterministic values and independently normally distributed random variables probabilistic distributions step 3 convert stochastic chance constraints into deterministic ones through the dsccp method by giving a certain confidence level αi for each constraint i step 4 reformulate the deterministic dsclfp model step 5 solve the deterministic model and obtain solutions step 6 repeat steps 3 5 under different confidence levels and obtain final decision solutions 3 case study 3 1 study area the yingke irrigation district yid is one of the three major irrigation areas in the middle reaches of the heihe river basin it s located in zhangye city gansu province northwest china 100 17 100 34 e 38 50 38 58 n fig 2 it s a highly developed agricultural zone with a typical inland arid climate where 68 of the overall area 13147 ha are arable lands that particularly need to be irrigated the mean annual temperature is 7 0 c the annual sunshine hours are over 3000 h and the frost free period is around 140 days the mean annual precipitation is merely 125 mm and annual et is about 1200 mm however over 80 of the precipitation is concentrated between july and september in the yid the main types of crops are maize e g field maize and seed maize spring wheat and economic crops because of their overwhelmingly larger proportion of the total planting area jiang et al 2015 meanwhile economic crops mainly refers to vegetables in the study area the growth period of spring wheat is from april to july and the growth period of maize is from april to september soil texture is dominated by sandy loam and loam agricultural water consumptions including surface water and groundwater and surface water is mostly used for agricultural irrigation i e accounting for more than 90 moreover traditional irrigation patterns such as flood and furrow methods are commonly adopted which is a cost effective way but with a lower irrigation water efficiency groundwater pumping can compensate insufficient part of surface water due to seasonal variations and untimely events agricultural irrigation water is physically transported to field crops through a multi layered canal system from water sources including one main canal and eleven sub canals among them all the main canal nearly 97 of secondary canals and 60 of tertiary canals have been lined jiang et al 2016 therefore in the yid the irrigation water use coefficients of surface water and groundwater are 0 52 0 60 respectively 3 2 problem statement a manager is responsible for allocating limited irrigation water resources to four types of crops due to irrigation water shortages and little precipitation in arid areas there is a growing competition among different water users crops moreover crop water production function cwpf is selected as the basis of irrigation planning because it can describe mathematical relationships between crop production i e crop yield or dry biomass and water use i e evapotranspiration cwpfs for different crops are generally expressed as polynomial function and linear cwpfs are selected because their simple form can facilitate the further promotion of the study model table 1 presents the linear cwpfs for the study crops these cwpfs are obtained by fitting the experimental data of crop yields and actual evapotranspiration table 2 presents the basic input data of the study area and crops including crop planting area crop price and cost of per unit of irrigation surface water and groundwater effective precipitation and maximum evapotranspiration these related parameters are acquired from government reports and statistical data in fact there are some uncertain factors in agricultural systems for example surface water and groundwater availabilities and the rates of surface water and groundwater loss during conveyance usually show randomness in response to these existing problems rational assumptions and simplifications of input parameters are needed to analyze the management system and tackle uncertainties thus it is assumed that there are sufficient historical records for determining the random distributions namely normal distributions see figs 3 and 4 specifically the surface water and groundwater availabilities are n 10195 1200 2 104 m3 and n 4300 1000 2 104 m3 the rates of surface water and groundwater loss during conveyance are n 0 25 0 0167 2 and n 0 15 0 0167 2 therefore an optimization model integrating linear cwpfs is developed for effective managing irrigation water to allocate them to different crops under uncertainty 3 3 application of the dsclfp model in this study the difficulties of optimizing irrigation water allocation include 1 how to deal with double sided random uncertainties in the system 2 how to address system efficiency i e water productivity 3 how to allocate irrigation water to different crops to achieve maximum system efficiency and 4 how to identify optimal irrigation water allocation solutions under given confidence levels therefore a double sided stochastic chance constrained linear fractional programming dsclfp model is developed under uncertainty the objective is to obtain maximum system benefits per unit of the allocated irrigation water meanwhile a series of constraints should be provided by involving all the relationships between the decision variables and system conditions the dsclfp model is formulated as follows objective function 8a max f net system benefits total irrigation water amount j 1 4 a j n b j c p j a j s w j g w j p e b j s c j j 1 4 a j c s j s w j η s c g j g w j η g j 1 4 a j s w j η s g w j η g net system benefits represent the total system benefits minus costs of crop productions irrigated surface water and groundwater use total irrigation water amount represents the irrigated surface water and groundwater use through irrigation water allocation solutions there is an assumption that the amount of irrigation water demands during the whole growth period is the sum of irrigation water and effective precipitation due to higher management level tong and guo 2013 where f is objective function yuan m3 its physical meaning is to maximize economic water productivity in irrigation water management problems j denotes the crop types j 1 for field maize j 2 for seed maize j 3 for spring wheat j 4 for economic crops aj is planting area of crop j ha nbj is crop price of crop j yuan kg cpj is the cost of crop production for crop j including all the costs such as seed fertilizer pesticides machinery harvesting and other costs yuan kg aj and bj are the empirical coefficients of the linear cwpfs for crop j swj and gwj are the decision variables denoting the amount of irrigated surface water and groundwater for crop j m3 ha pe is the effective precipitation of the study area m3 ha scj is subsidies for food crops per unit of area yuan ha csj and cgj are the cost of surface water and groundwater use per unit of irrigation water yuan m3 η s and η g are the comprehensive irrigation water use coefficients of surface water and groundwater constraints 1 surface water availability constraints 8b pr j 1 4 1 λ s a j s w j q s η s β s α i i 2 groundwater availability constraints 8c pr j 1 4 1 λ g a j g w j q g η g β g α i i constraints 8b and 8c are stochastic chance constraints indicating that such constraints can be satisfied at a certain confidence level αi and the admissible risk of constraint violating 1 α i λ s and λ g are the rates of surface water and groundwater loss during water conveyance that are presented as random variables following normal distributions respectively q s and q g are the surface water and groundwater availabilities which are also expressed as random variables following normal distributions 104 m3 β s and β g are the proportion of surface water and groundwater used for irrigation in this study β s 0 9 and β g 0 9 in the above constraints 3 irrigation water demand constraints 8d e t min j s w j g w j p e e t max j j where e t min j and e t max j denote the minimum and maximum evapotranspiration for each crop j indicating the fluctuation of actual irrigation water requirements for crops thus constraint 8d means that each crop should be irrigated within a certain range between maximum and minimum evapotranspiration 4 non negative constraints 8e s w j 0 g w j 0 j therefore by solving the model based on the solution algorithms see section 2 4 we have solutions under different confidence levels f opt s w j o p t and g w j o p t 4 results and discussion 4 1 results analysis four confidence levels αi 0 85 0 90 0 95 and 0 99 are introduced to investigate the satisfaction degree level of constraints and compare the results of the dsclfp model accordingly the risk levels of violating the constraints are presented as 1 α i which can be interpreted as significance level or probability of constraints violation table 3 presents optimal solutions resulting from the dsclfp model under four confidence levels the results show that the available groundwater is firstly utilized for irrigation because the allocated groundwater is greater than that of the allocated surface water for example when αi 0 99 optimal irrigation water allocation for four crops are 1063 58 m3 ha surface water and 1551 02 m3 ha groundwater for field maize 828 75 m3 ha and 1802 95 m3 ha for seed maize 0 and 1725 40 m3 ha for spring wheat and 357 78 m3 ha and 1002 22 m3 ha for economic crops this can be explained by groundwater has a higher irrigation water use coefficient and a lower rate of water loss during water conveyance in contrast with surface water i e η g η s and λ g λ s in terms of different confidence levels when αi is increased from 0 85 to 0 99 the overall trend of allocated surface water is raised but allocated groundwater is decreased for field maize seed maize and economic crops spring wheat is an exception due to unchanged results meanwhile the sum of allocated surface water and groundwater is exactly equal to the difference between their minimum crop water requirements and effective precipitation obviously it is evident that those crops will be water deficient which can be attributed to the efficiency oriented objective function for achieving the maximum system benefits with the minimum irrigation amount fig 5 presents the objection function values of the dsclfp model under different confidence levels the results show that a high αi level bring a lower ratio objective for example the objectives are decreased from 5 284 yuan m3 to 5 276 yuan m3 when αi level is raised from 0 85 to 0 99 the variation trend of this ratio objective is in fact consistent with the findings of previous similar research of a stochastic linear fractional programming approach zhu and huang 2011 in their paper when p i is increased then the ratio objective would be increased accordingly this is because the p i level means the probability that the chance constraints can be violated which is contrary to the confidence level mentioned in this paper the αi level means the satisfaction degree level of the constraints i e α i 1 p i and the ratio objective represents the water productivity moreover a higher αi level corresponds to a lower constraint violation risk level therefore the results can support in depth of the interrelationship among the objective value αi level and constraint violation risk level in fact an increased αi level can lead to an increased strictness for the system conditions and then a narrower decision space however it is notable that an increased αi level makes the system more reliable thus an acceptable and suitable level should be decided based on attitudes of managers and stakeholders associated with conservative or positive choices the above analysis indicates that the dsclfp model can effectively address random information in its framework it can also generate a range of optimal solutions under different confidence levels however it is worth mentioning that the dsclfp model has computational burden due to nonlinear forms of constraints which will limit the scope of application of this method it is thus desirable to develop a computationally tractable solution algorithm to improve computational efficiency and promote practical applications 4 2 comparison with linearization form of the dsclfp in response to this concern a non equivalent but sufficient linearization form of the dsclfp is proposed and proved through theorems 1 and 2 table 4 presents the results obtained from the linearization form of the dsclfp model under different confidence levels compared with table 3 the results of the two models are almost the same this also verifies the feasibility of the linearization form of the dsclfp model therefore the linearization form of the dsclfp model can be regarded as a reasonable one and can enhance its practical implementations for future promotion for address random uncertainties in terms of errors occurred by the linearization of the dsclfp model which theoretically occurred in the process of the linearization from nonlinear forms into non equivalent linear one eq 4b when the nonlinear left hand side random coefficients are replaced by linear forms the left hand side coefficients in the constraints become greater which may lead to an increased strictness for the constraints and thus narrow down the feasible decision space to some extent however it has an advantage of a highly efficient computational process to greatly reduce computational time sun et al 2013 zhang et al 2017 therefore it should be an innovative and effective method to address the dsclfp model 4 3 comparison with double sided stochastic chance constrained linear programming dsclp when the managers put more emphases on economic returns under the objective function of maximizing system benefits the dsclfp model can be transformed into a linear one i e double sided stochastic chance constrained linear programming dsclp with the same input parameters of deterministic and random information results of the dsclp model can be obtained under given confidence levels table 5 shows optimal solutions of the dsclp model under different αi levels obviously more surface water is utilized for irrigation in this case because its lower cost of irrigation water use in contrast with groundwater this results can be explained by the objective function of the benefit oriented dsclp model with αi level increases the variation trends of allocated surface water is decreased for field maize and seed maize and stays unchanged for spring wheat and economic crops this is contrary to the trend of efficiency oriented dsclfp model especially when αi level is increased from 0 85 to 0 99 water productivity resulting from the dsclp model will be increased from 2 808 yuan m3 to 2 848 yuan m3 which is considerably lower than that from the dsclfp model such a significant difference between the dsclfp and dsclp can be further demonstrated in the following analysis of the system benefits and total irrigation water use fig 6 presents the system benefits resulting from two models under a range of αi levels apparently the dsclp model brings approximately 20 higher system benefits than the dsclfp model for example the system benefits from the dsclp model are 29643 09 104 yuan when αi 0 85 29624 31 104 yuan when αi 0 90 29596 51 104 yuan when αi 0 95 and 29545 15 104 yuan when αi 0 99 a higher confidence level leads to a lower system benefits due to an increasing strictness of constraints which will lower the system failure risk and increase reliability level accordingly achieving these system benefits is inevitably at the expense of large amounts of irrigation water resources fig 7 presents the total irrigation water use obtained from two models under different confidence levels the total irrigation water use of the dsclp model is much greater than that of the optimal ratio model comparison between the two models shows that the dsclp model makes full use of irrigation water resources but the dsclfp model illustrates the water saving potential of the yid therefore the dsclfp model is clearly exemplified by the current results to utilize irrigation water in an efficient manner 4 4 comparison with deterministic model without consideration of random information and uncertainties in the model the dsclfp model can be directly simplified into a deterministic linear fractional programming lfp model thus only singe solution can be generated by solving this model see table 6 moreover this solution can be regarded as a special case in the solutions resulting from the dsclfp model in such a case the flexibility of the solution is reduced on the one hand there are many uncertain factors in the irrigation water resources planning problems the traditional lfp model has some limitations in solving practical problems the obtained results through the newly developed model can provide managers with more reliable and reasonable decision making recommendations in addition the lfp model can only provide a set of results while the dsclfp model can generate more results based on the system conditions and managers attitudes this will undoubtedly provide managers with more reference information when making decision plans for example under a lower confidence level the system can achieve greater water productivity but at the same time it must withstand higher constraint violation risks on the contrary a lower water productivity will be achieved with a reduced risk level in summary the dsclfp model not only has an enhanced applicability than the lfp model but it can also be used to better handle trade offs between economics environment and system reliability and to provides more effective choices for managers 5 conclusions a double sided stochastic chance constrained linear fractional programming dsclfp model has been developed for supporting irrigation water management problems under uncertainty it can address ratio optimization problems i e water productivity associated with double sided stochastic constraint violation where double sided stochastic chance constrained programming dsccp is incorporated into a linear fractional programming lfp framework it thus improves upon the existing stochastic chance constrained programming by addressing double sided randomness simultaneously meanwhile a non equivalent but sufficient linearization form of the dsclfp model is presented to reduce computational burden therefore the dsclfp model has the following advantages in 1 reflecting the ratio objective of water productivity 2 providing solutions under different confidence levels and 3 supporting in depth analysis of interrelationships among water productivity confidence level and constraint violation risk as well as reliability level a case study is provided for demonstrating the applicability of the developed dsclfp model which is used to allocate limited irrigation water resources to different crops in yid northwest china optimal solutions are useful for supporting managers to decide desirable choices under different system conditions moreover comparison with linearization form of the dsclfp model shows the effectiveness of the innovative method comparisons with double sided stochastic chance constrained linear programming dsclp model and deterministic model can clearly highlight and reflect advantages and feasibility of the developed model therefore some meaningful findings are summarized into following three aspects to prove worthiness of proposed study first the results indicate that a high αi level bring a lower water productivity which will correspond to managers preferences regarding the tradeoff between the water productivity and system constraint violation risk accordingly the results under different confidence levels refer to different irrigation water management solutions and risk violation levels based on these results managers can adjust their policies in response to uncertain information second to pursue a higher water productivity will certainly improve irrigation water use efficiency but water deficits undoubtedly occur in crop growth due to less allocated irrigation water as well from a positive perspective the water saving potential of the yid is enormous the saved water can be transferred to other purposes for achieving higher ecological values and economic benefits third the linearization process of model can greatly enhance practical applicability for address random uncertainties although this study is the attempt for supporting irrigation water management problems the algorithms and results suggest that it can be extended to other resources and environmental management problems moreover this study is based on the assumption of independently normally random variables which may have limitations when encountering more unidentified probability distributions thus the dsclfp model still has space for future improvements it can be potentially enhanced by incorporating techniques of monte carlo stochastic simulation uncertainty analysis fuzzy theory and dynamic programming into its framework for tackling more complex applications acknowledgements this research was supported by national natural science foundation of china 91425302 and national key research and development programs of thirteen five plan 2016yfc0400207 we gratefully acknowledge financial funding from the china scholarship council which supported the first author as a visiting ph d student at purdue university in the usa the authors are grateful to the editors and the anonymous reviewers for their insightful and constructive comments and suggestions for improving the paper 
7081,a double sided stochastic chance constrained linear fractional programming dsclfp model is developed for managing irrigation water under uncertainty the model is developed by incorporating double sided stochastic chance constrained programming dsccp into a linear fractional programming lfp optimization framework it can address ratio optimization problems with double sided randomness i e both left hand and right hand sides more importantly it also improves upon the existing stochastic chance constrained programming for handing random uncertainties in the left hand and right hand sides of constraints simultaneously a non equivalent but sufficient linearization form of the dsclfp is provided and proved which will greatly reduce the computational burden then the model is applied to a case study in yingke irrigation district yid in the middle reaches of the heihe river basin northwest china four confidence levels e g αi 0 85 0 90 0 95 and 0 99 are provided to examine and compare the results the objective function values are slightly decreased from 5 284 yuan m3 to 5 276 yuan m3 when αi level is raised from 0 85 to 0 99 the results from the dsclfp can identify desired irrigation water allocation plans under the objective function of maximizing water productivity under different confidence levels therefore the results can provide tradeoffs among water productivity confidence level and constraint violation risk level moreover comparisons with double sided stochastic chance constrained linear programming dsclp model and deterministic model are introduced to highlight advantages and feasibility of the developed model therefore these results can provide decision support for managers in arid areas keywords irrigation management linear fractional programming chance constrained programming double sided randomness water productivity 1 introduction under the pressures of the increasing water demands and the shortages of water supply sustainable water management is becoming an issue of great significance for water managers throughout the world especially in arid areas dominated by irrigated agriculture elliott et al 2014 kang et al 2017 there is a concern that the water productivity need to be addressed in irrigation water management problems due to water scarcity in other words this is a conflicting objective to maximize the system benefits with minimum irrigation water use generally water productivity is defined as a ratio representing the unit of outputs e g crop yield economic benefits per unit of irrigation water barker et al 2003 such a ratio optimization problem can be quantitatively solved by linear fractional programming lfp method which is effectively used to account for conflicting objectives and reflect system efficiency lara and stancu minasian 1999 gómez et al 2006 zhu and huang 2011 stancu minasian 2012 zhang and guo 2018 compared with traditional methods the lfp is superior to them to compare multiple objective directly through the original magnitudes guo et al 2014 particularly it s adopted in the management problems that need to compare two magnitudes e g output input moreover another concern is the inherent uncertainty in practical applications for example spatial and temporal changes in surface runoff and groundwater fluctuations of market prices effected by various stochastic factors li et al 2010 which are closely related to input parameters and hardly quantified accurately additionally the interrelationships among these uncertain factors and economic implications may cause challenges in planning irrigation water management due to system complexities tan et al 2011 li et al 2012 therefore it is imperative to develop novel method to deal with these concerns and generate irrigation water allocation plans for supporting sustainable irrigation water management previously three main types of inexact mathematical programming methods were proposed including interval parameter linear programming ilp fuzzy mathematical programming fmp and stochastic mathematical programming smp to address uncertainties among them smp method is exclusively for handling random variables expressed as known probability density functions pdfs in the model s input information gu et al 2013 guo et al 2014 zhang et al 2017 this means that when uncertain parameters can be described results can be presented as comparisons under different reliability levels as a major type of smp chance constrained programming ccp initially developed by charnes and cooper 1959 allows violation of system constraints indicating that not all of the constraints must be rigorously satisfied thus the random constraints can be hold at least a certain probability α where α 0 1 is defined as confidence level given by the decision makers this will normally increase the system benefits to a certain extent at a compromise of environmental capacity in irrigation water management problems generally due to the nonlinear forms in solving ccp problems it s commonly employed in the case of the independent right hand side randomness in constraints huang 1998 zhu and huang 2011 nemirovski 2012 for example huang 1998 proposed an inexact ccp method for water quality management where stochastic uncertainties exist in the right hand side of constraints zhu and huang 2011 developed a stochastic linear fractional programming for solid waste management where the right hand side coefficients are random for all α values moreover the ccp methods incorporated with the randomness in the left hand side of the constraints have also been developed for example cao et al 2011 developed an interval left hand side ccp method for regional air quality management sun et al 2013 developed an inexact joint probabilistic left hand side ccp model for solid waste management zhang et al 2017 proposed an interval multistage joint probabilistic ccp model with left hand side randomness for crop area planning however in practice random uncertainties may exist in both left hand side and right hand side of the constraints which will thereby lead to the above mentioned ccp methods not account for such a difficulty therefore based on the assumption of both left hand and right hand sides of randomness have gaussian distributions and α 0 5 α is the satisfaction degree of constraints roubens and teghem 1991 huang 1998 a double sided stochastic chance constrained programming dsccp method is useful for solving above difficulties liu 2009 although the algorithm of the dsccp can be directly proved by mathematical proof its nonlinear forms will inevitably intensify challenges in practical applicability furthermore the dsccp method can hardly account for ratio optimization problems and few scholars handled double sided random stochastic issues with lfp models nevertheless few applications of the dsccp method to irrigation water management are conducted therefore the objective of this study is to develop a novel method to address ratio optimization problems in the case of double sided random stochastic uncertainties in the constraints it is an attempt to develop such a double sided stochastic chance constrained linear fractional programming dsclfp model by incorporating the dsccp into a lfp framework for supporting irrigation water management under uncertainty it can improve upon the existing stochastic chance constrained programing by dealing with double sided randomness moreover to reduce computational burden and improve computational efficiency a non equivalent but sufficient linearization form of dsclfp model will be provided and proved for comparisons to demonstrate its applicability the developed model will be applied to a case study to manage irrigation water to different crops in the yingke irrigation district yid in the middle reaches of the heihe river basin northwest china several scenarios associated with confidence levels will be analyzed for examining and comparing the variations of results 2 methodology 2 1 linear fractional programming lfp in a linear fractional programming lfp problem it is generally considered as a functional relationship expressed as a ratio between two variables in the numerator and denominator charnes and cooper 1962 the numerator represents the change in total cost and other variables while the denominator represents the volume changes that may lead to the change of the related cost coefficients therefore lfp can deal with bi objectives problems and reflect system efficiency it can be formulated as follows 1a max f cx α dx β subject to 1b ax b 1c x 0 where a is a real m n matrix x and b are column vectors with n and m components respectively c and d are row vectors with n components α and β are constant terms the lfp model can address deterministic ratio optimization problems but it is not able to deal with complexities when uncertainties exist in the constraints of optimization model zhu and huang 2011 2 2 double sided stochastic chance constrained programming dsccp in a linear programming model when both left hand aij and right hand side bj parameters in the constraints are to be independently normally distributed random variables µ is expected value and σ is standard variation and the constraints are hold at a certain level of probability α then the double sided stochastic chance constrained programming dsccp method can be adopted as follows 2a max f j 1 n c j x j subject to 2b pr j 1 n a ij x j b i α i i 1 2 m 2c a ij ω n μ a i j σ a i j 2 2d b i ξ n μ b i σ b i 2 2e x j 0 j 1 2 n where f is the objective function xj is decision variable bi and cj are input parameters αi α i 0 1 refers to a given level of probability for constraint i representing the satisfaction degree level of constraints m is the number of constraints according to liu 2009 constraint 2b can be transformed into a nonlinear form and the set of feasible constraints is convex see theorem 1 theorem 1 eq 2b is equivalent to eq 3a that is if aij and bi are assumed to be independently normally distributed random variables then eq 2b can be hold if and only if 3a j 1 n μ a i j x j φ 1 α i j 1 n σ a i j 2 x j 2 σ b i 2 μ b i i 1 2 m where φ is the standardized normal distribution function proof since aij and bj are independently random variables following normal distributions let s introduce the variable y i j 1 n a ij x j b i i 1 2 m it also follows normal distribution its expected value and variance are presented as follows 3b μ y i j 1 n μ a i j x j μ b i 3c σ y i 2 j 1 n σ a i j 2 x j 2 σ b i 2 then the expression j 1 n a ij x j b i j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 must be standardized normally distributed accordingly the associated inequality j 1 n a ij x j b i i 1 2 m is equivalent to 3d j 1 n a ij x j b i j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 thus the chance constraint 2b can be converted into 3e pr z j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 α i i 1 2 m where z is defined as the standardized normally distributed random variable therefore the chance constraint 3e can be satisfied if and only if 3f φ 1 α i j 1 n μ a i j x j μ b i j 1 n σ a i j 2 x j 2 σ b i 2 i 1 2 m finally we have the deterministic equivalent of chance constraint 3a the theorem 1 is proved because eq 3a is presented as nonlinear form it will intensify computational burden when solving problems as an alternative solution method an approximated linearization form of eq 3a is proposed see theorem 2 theorem 2 eq 4a is a sufficient condition for eq 3a where α i 0 5 and x j 0 4a j 1 n μ a i j x j φ 1 α i j 1 n σ a i j x j σ b i μ b i i 1 2 m proof based on the following inequality 4b j 1 n t 2 j 1 n t t r t 0 when j 1 n σ a i j x j σ b i r and j 1 n σ a i j x j σ b i 0 we have 4c j 1 n σ a i j 2 x j 2 σ b i 2 j 1 n σ a i j x j σ b i moreover when α i 0 5 we have 4d φ 1 α i 0 thus from inequalities 4c and 4d we have 4e j 1 n μ a i j x j φ 1 α i j 1 n σ a i j 2 x j 2 σ b i 2 j 1 n μ a i j x j φ 1 α i j 1 n σ a i j x j σ b i i 1 2 m understandably if inequality 4a holds sufficient condition then from inequality 4e we have 3a therefore according to theorems 1 and 2 when α i 0 5 and x j 0 eq 2b can be transformed into a non equivalent but sufficient linearization form in 5a 5a j 1 n μ a i j x j φ 1 α i j 1 n σ a i j x j σ b i μ b i i 1 2 m 2 3 double sided stochastic chance constrained linear fractional programming dsclfp in this study a dsclfp model is developed in response to ratio optimization problems with double sided randomness in the constraints it incorporates dsccp model into lfp optimization framework the developed dsclfp model is written as follows 6a max f cx α dx β subject to 6b j 1 n μ a i j x j φ 1 α i j 1 n σ a i j 2 x j 2 σ b i 2 μ b i i 1 2 m 6c a ij ω n μ a i j σ a i j 2 6d b i ξ n μ b i σ b i 2 6e x j 0 j 1 2 n alternatively by using inequality 5a substituting constraint 6b we have a linearization form of dsclfp model 7a max f cx α dx β subject to 7b j 1 n μ a i j x j φ 1 α i j 1 n σ a i j x j σ b i μ b i i 1 2 m 7c a ij ω n μ a i j σ a i j 2 7d b i ξ n μ b i σ b i 2 7e x j 0 j 1 2 n 2 4 solution method the framework of the developed dsclfp model is graphically presented in fig 1 the detailed solution method can be further summarized as follows step 1 formulate the dsclfp model step 2 acquire the model input parameters including deterministic values and independently normally distributed random variables probabilistic distributions step 3 convert stochastic chance constraints into deterministic ones through the dsccp method by giving a certain confidence level αi for each constraint i step 4 reformulate the deterministic dsclfp model step 5 solve the deterministic model and obtain solutions step 6 repeat steps 3 5 under different confidence levels and obtain final decision solutions 3 case study 3 1 study area the yingke irrigation district yid is one of the three major irrigation areas in the middle reaches of the heihe river basin it s located in zhangye city gansu province northwest china 100 17 100 34 e 38 50 38 58 n fig 2 it s a highly developed agricultural zone with a typical inland arid climate where 68 of the overall area 13147 ha are arable lands that particularly need to be irrigated the mean annual temperature is 7 0 c the annual sunshine hours are over 3000 h and the frost free period is around 140 days the mean annual precipitation is merely 125 mm and annual et is about 1200 mm however over 80 of the precipitation is concentrated between july and september in the yid the main types of crops are maize e g field maize and seed maize spring wheat and economic crops because of their overwhelmingly larger proportion of the total planting area jiang et al 2015 meanwhile economic crops mainly refers to vegetables in the study area the growth period of spring wheat is from april to july and the growth period of maize is from april to september soil texture is dominated by sandy loam and loam agricultural water consumptions including surface water and groundwater and surface water is mostly used for agricultural irrigation i e accounting for more than 90 moreover traditional irrigation patterns such as flood and furrow methods are commonly adopted which is a cost effective way but with a lower irrigation water efficiency groundwater pumping can compensate insufficient part of surface water due to seasonal variations and untimely events agricultural irrigation water is physically transported to field crops through a multi layered canal system from water sources including one main canal and eleven sub canals among them all the main canal nearly 97 of secondary canals and 60 of tertiary canals have been lined jiang et al 2016 therefore in the yid the irrigation water use coefficients of surface water and groundwater are 0 52 0 60 respectively 3 2 problem statement a manager is responsible for allocating limited irrigation water resources to four types of crops due to irrigation water shortages and little precipitation in arid areas there is a growing competition among different water users crops moreover crop water production function cwpf is selected as the basis of irrigation planning because it can describe mathematical relationships between crop production i e crop yield or dry biomass and water use i e evapotranspiration cwpfs for different crops are generally expressed as polynomial function and linear cwpfs are selected because their simple form can facilitate the further promotion of the study model table 1 presents the linear cwpfs for the study crops these cwpfs are obtained by fitting the experimental data of crop yields and actual evapotranspiration table 2 presents the basic input data of the study area and crops including crop planting area crop price and cost of per unit of irrigation surface water and groundwater effective precipitation and maximum evapotranspiration these related parameters are acquired from government reports and statistical data in fact there are some uncertain factors in agricultural systems for example surface water and groundwater availabilities and the rates of surface water and groundwater loss during conveyance usually show randomness in response to these existing problems rational assumptions and simplifications of input parameters are needed to analyze the management system and tackle uncertainties thus it is assumed that there are sufficient historical records for determining the random distributions namely normal distributions see figs 3 and 4 specifically the surface water and groundwater availabilities are n 10195 1200 2 104 m3 and n 4300 1000 2 104 m3 the rates of surface water and groundwater loss during conveyance are n 0 25 0 0167 2 and n 0 15 0 0167 2 therefore an optimization model integrating linear cwpfs is developed for effective managing irrigation water to allocate them to different crops under uncertainty 3 3 application of the dsclfp model in this study the difficulties of optimizing irrigation water allocation include 1 how to deal with double sided random uncertainties in the system 2 how to address system efficiency i e water productivity 3 how to allocate irrigation water to different crops to achieve maximum system efficiency and 4 how to identify optimal irrigation water allocation solutions under given confidence levels therefore a double sided stochastic chance constrained linear fractional programming dsclfp model is developed under uncertainty the objective is to obtain maximum system benefits per unit of the allocated irrigation water meanwhile a series of constraints should be provided by involving all the relationships between the decision variables and system conditions the dsclfp model is formulated as follows objective function 8a max f net system benefits total irrigation water amount j 1 4 a j n b j c p j a j s w j g w j p e b j s c j j 1 4 a j c s j s w j η s c g j g w j η g j 1 4 a j s w j η s g w j η g net system benefits represent the total system benefits minus costs of crop productions irrigated surface water and groundwater use total irrigation water amount represents the irrigated surface water and groundwater use through irrigation water allocation solutions there is an assumption that the amount of irrigation water demands during the whole growth period is the sum of irrigation water and effective precipitation due to higher management level tong and guo 2013 where f is objective function yuan m3 its physical meaning is to maximize economic water productivity in irrigation water management problems j denotes the crop types j 1 for field maize j 2 for seed maize j 3 for spring wheat j 4 for economic crops aj is planting area of crop j ha nbj is crop price of crop j yuan kg cpj is the cost of crop production for crop j including all the costs such as seed fertilizer pesticides machinery harvesting and other costs yuan kg aj and bj are the empirical coefficients of the linear cwpfs for crop j swj and gwj are the decision variables denoting the amount of irrigated surface water and groundwater for crop j m3 ha pe is the effective precipitation of the study area m3 ha scj is subsidies for food crops per unit of area yuan ha csj and cgj are the cost of surface water and groundwater use per unit of irrigation water yuan m3 η s and η g are the comprehensive irrigation water use coefficients of surface water and groundwater constraints 1 surface water availability constraints 8b pr j 1 4 1 λ s a j s w j q s η s β s α i i 2 groundwater availability constraints 8c pr j 1 4 1 λ g a j g w j q g η g β g α i i constraints 8b and 8c are stochastic chance constraints indicating that such constraints can be satisfied at a certain confidence level αi and the admissible risk of constraint violating 1 α i λ s and λ g are the rates of surface water and groundwater loss during water conveyance that are presented as random variables following normal distributions respectively q s and q g are the surface water and groundwater availabilities which are also expressed as random variables following normal distributions 104 m3 β s and β g are the proportion of surface water and groundwater used for irrigation in this study β s 0 9 and β g 0 9 in the above constraints 3 irrigation water demand constraints 8d e t min j s w j g w j p e e t max j j where e t min j and e t max j denote the minimum and maximum evapotranspiration for each crop j indicating the fluctuation of actual irrigation water requirements for crops thus constraint 8d means that each crop should be irrigated within a certain range between maximum and minimum evapotranspiration 4 non negative constraints 8e s w j 0 g w j 0 j therefore by solving the model based on the solution algorithms see section 2 4 we have solutions under different confidence levels f opt s w j o p t and g w j o p t 4 results and discussion 4 1 results analysis four confidence levels αi 0 85 0 90 0 95 and 0 99 are introduced to investigate the satisfaction degree level of constraints and compare the results of the dsclfp model accordingly the risk levels of violating the constraints are presented as 1 α i which can be interpreted as significance level or probability of constraints violation table 3 presents optimal solutions resulting from the dsclfp model under four confidence levels the results show that the available groundwater is firstly utilized for irrigation because the allocated groundwater is greater than that of the allocated surface water for example when αi 0 99 optimal irrigation water allocation for four crops are 1063 58 m3 ha surface water and 1551 02 m3 ha groundwater for field maize 828 75 m3 ha and 1802 95 m3 ha for seed maize 0 and 1725 40 m3 ha for spring wheat and 357 78 m3 ha and 1002 22 m3 ha for economic crops this can be explained by groundwater has a higher irrigation water use coefficient and a lower rate of water loss during water conveyance in contrast with surface water i e η g η s and λ g λ s in terms of different confidence levels when αi is increased from 0 85 to 0 99 the overall trend of allocated surface water is raised but allocated groundwater is decreased for field maize seed maize and economic crops spring wheat is an exception due to unchanged results meanwhile the sum of allocated surface water and groundwater is exactly equal to the difference between their minimum crop water requirements and effective precipitation obviously it is evident that those crops will be water deficient which can be attributed to the efficiency oriented objective function for achieving the maximum system benefits with the minimum irrigation amount fig 5 presents the objection function values of the dsclfp model under different confidence levels the results show that a high αi level bring a lower ratio objective for example the objectives are decreased from 5 284 yuan m3 to 5 276 yuan m3 when αi level is raised from 0 85 to 0 99 the variation trend of this ratio objective is in fact consistent with the findings of previous similar research of a stochastic linear fractional programming approach zhu and huang 2011 in their paper when p i is increased then the ratio objective would be increased accordingly this is because the p i level means the probability that the chance constraints can be violated which is contrary to the confidence level mentioned in this paper the αi level means the satisfaction degree level of the constraints i e α i 1 p i and the ratio objective represents the water productivity moreover a higher αi level corresponds to a lower constraint violation risk level therefore the results can support in depth of the interrelationship among the objective value αi level and constraint violation risk level in fact an increased αi level can lead to an increased strictness for the system conditions and then a narrower decision space however it is notable that an increased αi level makes the system more reliable thus an acceptable and suitable level should be decided based on attitudes of managers and stakeholders associated with conservative or positive choices the above analysis indicates that the dsclfp model can effectively address random information in its framework it can also generate a range of optimal solutions under different confidence levels however it is worth mentioning that the dsclfp model has computational burden due to nonlinear forms of constraints which will limit the scope of application of this method it is thus desirable to develop a computationally tractable solution algorithm to improve computational efficiency and promote practical applications 4 2 comparison with linearization form of the dsclfp in response to this concern a non equivalent but sufficient linearization form of the dsclfp is proposed and proved through theorems 1 and 2 table 4 presents the results obtained from the linearization form of the dsclfp model under different confidence levels compared with table 3 the results of the two models are almost the same this also verifies the feasibility of the linearization form of the dsclfp model therefore the linearization form of the dsclfp model can be regarded as a reasonable one and can enhance its practical implementations for future promotion for address random uncertainties in terms of errors occurred by the linearization of the dsclfp model which theoretically occurred in the process of the linearization from nonlinear forms into non equivalent linear one eq 4b when the nonlinear left hand side random coefficients are replaced by linear forms the left hand side coefficients in the constraints become greater which may lead to an increased strictness for the constraints and thus narrow down the feasible decision space to some extent however it has an advantage of a highly efficient computational process to greatly reduce computational time sun et al 2013 zhang et al 2017 therefore it should be an innovative and effective method to address the dsclfp model 4 3 comparison with double sided stochastic chance constrained linear programming dsclp when the managers put more emphases on economic returns under the objective function of maximizing system benefits the dsclfp model can be transformed into a linear one i e double sided stochastic chance constrained linear programming dsclp with the same input parameters of deterministic and random information results of the dsclp model can be obtained under given confidence levels table 5 shows optimal solutions of the dsclp model under different αi levels obviously more surface water is utilized for irrigation in this case because its lower cost of irrigation water use in contrast with groundwater this results can be explained by the objective function of the benefit oriented dsclp model with αi level increases the variation trends of allocated surface water is decreased for field maize and seed maize and stays unchanged for spring wheat and economic crops this is contrary to the trend of efficiency oriented dsclfp model especially when αi level is increased from 0 85 to 0 99 water productivity resulting from the dsclp model will be increased from 2 808 yuan m3 to 2 848 yuan m3 which is considerably lower than that from the dsclfp model such a significant difference between the dsclfp and dsclp can be further demonstrated in the following analysis of the system benefits and total irrigation water use fig 6 presents the system benefits resulting from two models under a range of αi levels apparently the dsclp model brings approximately 20 higher system benefits than the dsclfp model for example the system benefits from the dsclp model are 29643 09 104 yuan when αi 0 85 29624 31 104 yuan when αi 0 90 29596 51 104 yuan when αi 0 95 and 29545 15 104 yuan when αi 0 99 a higher confidence level leads to a lower system benefits due to an increasing strictness of constraints which will lower the system failure risk and increase reliability level accordingly achieving these system benefits is inevitably at the expense of large amounts of irrigation water resources fig 7 presents the total irrigation water use obtained from two models under different confidence levels the total irrigation water use of the dsclp model is much greater than that of the optimal ratio model comparison between the two models shows that the dsclp model makes full use of irrigation water resources but the dsclfp model illustrates the water saving potential of the yid therefore the dsclfp model is clearly exemplified by the current results to utilize irrigation water in an efficient manner 4 4 comparison with deterministic model without consideration of random information and uncertainties in the model the dsclfp model can be directly simplified into a deterministic linear fractional programming lfp model thus only singe solution can be generated by solving this model see table 6 moreover this solution can be regarded as a special case in the solutions resulting from the dsclfp model in such a case the flexibility of the solution is reduced on the one hand there are many uncertain factors in the irrigation water resources planning problems the traditional lfp model has some limitations in solving practical problems the obtained results through the newly developed model can provide managers with more reliable and reasonable decision making recommendations in addition the lfp model can only provide a set of results while the dsclfp model can generate more results based on the system conditions and managers attitudes this will undoubtedly provide managers with more reference information when making decision plans for example under a lower confidence level the system can achieve greater water productivity but at the same time it must withstand higher constraint violation risks on the contrary a lower water productivity will be achieved with a reduced risk level in summary the dsclfp model not only has an enhanced applicability than the lfp model but it can also be used to better handle trade offs between economics environment and system reliability and to provides more effective choices for managers 5 conclusions a double sided stochastic chance constrained linear fractional programming dsclfp model has been developed for supporting irrigation water management problems under uncertainty it can address ratio optimization problems i e water productivity associated with double sided stochastic constraint violation where double sided stochastic chance constrained programming dsccp is incorporated into a linear fractional programming lfp framework it thus improves upon the existing stochastic chance constrained programming by addressing double sided randomness simultaneously meanwhile a non equivalent but sufficient linearization form of the dsclfp model is presented to reduce computational burden therefore the dsclfp model has the following advantages in 1 reflecting the ratio objective of water productivity 2 providing solutions under different confidence levels and 3 supporting in depth analysis of interrelationships among water productivity confidence level and constraint violation risk as well as reliability level a case study is provided for demonstrating the applicability of the developed dsclfp model which is used to allocate limited irrigation water resources to different crops in yid northwest china optimal solutions are useful for supporting managers to decide desirable choices under different system conditions moreover comparison with linearization form of the dsclfp model shows the effectiveness of the innovative method comparisons with double sided stochastic chance constrained linear programming dsclp model and deterministic model can clearly highlight and reflect advantages and feasibility of the developed model therefore some meaningful findings are summarized into following three aspects to prove worthiness of proposed study first the results indicate that a high αi level bring a lower water productivity which will correspond to managers preferences regarding the tradeoff between the water productivity and system constraint violation risk accordingly the results under different confidence levels refer to different irrigation water management solutions and risk violation levels based on these results managers can adjust their policies in response to uncertain information second to pursue a higher water productivity will certainly improve irrigation water use efficiency but water deficits undoubtedly occur in crop growth due to less allocated irrigation water as well from a positive perspective the water saving potential of the yid is enormous the saved water can be transferred to other purposes for achieving higher ecological values and economic benefits third the linearization process of model can greatly enhance practical applicability for address random uncertainties although this study is the attempt for supporting irrigation water management problems the algorithms and results suggest that it can be extended to other resources and environmental management problems moreover this study is based on the assumption of independently normally random variables which may have limitations when encountering more unidentified probability distributions thus the dsclfp model still has space for future improvements it can be potentially enhanced by incorporating techniques of monte carlo stochastic simulation uncertainty analysis fuzzy theory and dynamic programming into its framework for tackling more complex applications acknowledgements this research was supported by national natural science foundation of china 91425302 and national key research and development programs of thirteen five plan 2016yfc0400207 we gratefully acknowledge financial funding from the china scholarship council which supported the first author as a visiting ph d student at purdue university in the usa the authors are grateful to the editors and the anonymous reviewers for their insightful and constructive comments and suggestions for improving the paper 
7082,a probabilistic approach is presented to assess the performance validity of the empirical curve number cn and physically based green and ampt g a rainfall runoff methods in the swat model specifically the effects of modeling uncertainties on characterization of the hydrologic budgets and streamflow regimes at various spatial scales and upstream land use conditions are investigated a bayesian total uncertainty assessment framework which explicitly accounts for uncertainties from model parameters inputs structure and measurement data was employed to explore uncertainties in streamflow simulation using swat with different rainfall runoff methods in a mixed land use watershed while the models were trained for streamflow estimation only at the watershed outlet the performances of the models were compared at different stream locations within the watershed at the watershed outlet the cn method had a slightly better but not significant performance in terms of streamflow error statistics similar results were obtained for the predominantly forested and agricultural tributaries however in tributaries with higher percentage of developed land g a outperformed the cn method in simulating streamflow based on various performance metrics in general the 95 prediction intervals from the models with g a method covered a higher percentage of observed streamflow especially during the high flow events however they were approximately 20 45 wider than the corresponding 95 prediction intervals from the cn methods using 95 prediction interval for estimated flow duration curves results indicated that the models with cn methods underestimated high flow events especially in tributaries with highly developed land use however the cn methods generated higher water yields to streams than the g a method the results of this study have important implications for the selection and application of appropriate rainfall runoff methods within complex distributed hydrologic models particularly when simulating hydrologic responses in mixed land use watersheds in the present study while cn and g a methods in the swat model performed similarly at the outlet of a mixed land use watershed g a captured the internal processes more realistically the subsequent effects on the representation of internal hydrological processes and budgets are discussed keywords rainfall runoff model green and ampt curve number distributed hydrologic modeling bayesian uncertainty analysis swat 1 introduction watershed models are increasingly used to assess hydrologic responses of watersheds to changes in land use climate variability and change and other alterations of system characteristics faced with myriad hydrologic models hydrologists ought to select an appropriate model and demonstrate its performance validity for the desired assessments the performance of watershed models is often evaluated based on a deterministic approach i e calibrate validate predict where calibration is conducted to obtain a parameter set that provides the best fit between model responses and observations at the watershed outlet seibert 1999 santhi et al 2008 niraula et al 2015 such assessments can be inadequate and in many cases misleading for selecting an appropriate distributed hydrologic model particularly when the model is used to simulate interior hydrologic processes or to assess responses at various locations within the watershed beven 2001 ahmadi et al 2014 probabilistic approaches can address the equifinality and nonuniqueness issues in parameter estimation moradkhani et al 2005 input uncertainty kavetski et al 2003 and measurement errors harmel and smith 2007 when assessing competing model structures ajami et al 2007 literature is replete with studies in which a model calibrated at the watershed outlet is used to predict streamflows at interior locations within the watershed under varying upstream land use conditions ahearn et al 2005 baker and miller 2013 yan et al 2013 similarly studies continue to use the deterministic approach to explore the hydrologic effects of land use change zhou et al 2013 sunde et al 2016 zuo et al 2016 climate change xu et al 2013 meaurio et al 2017 or implementation of management practices taylor et al 2016 jang et al 2017 motallebi et al 2017 interestingly calibrated model responses at the watershed outlet are also used to compare the performance of competing models seibert 1999 santhi et al 2008 niraula et al 2015 the validity of these studies remains unclear mainly because a model could produce responses at the watershed outlet that adequately match observations i e right answer while representing the internal processes and responses incorrectly i e wrong reasons beven 2006 two common methods for rainfall runoff modeling are the curve number method cn usda nrcs 2004 and the green and ampt method g a green and ampt 1911 the cn is an empirical method that provides estimates of runoff under varying land use and soil types using total volume of rainfall conversely the g a is a physically based method that uses rainfall intensity and duration along with soil physical characteristics such as hydraulic conductivity to simulate infiltration a major limitation of the cn method is that it only uses the total volume of rainfall and does not account for rainfall intensity and duration hence the applicability of the method is limited to simulations at daily to annual time steps and cannot be extended to resolve processes at sub daily time steps such limitations can result in erroneous simulations of runoff processes in areas with inherently quick hydrologic responses to rainfall events such as small catchments areas with relatively low soil permeability and developed areas with large impervious surfaces miller et al 2014 yet many studies continue to use the cn method to quantify runoff in mixed land use watersheds with considerable areas of developed land zhou et al 2013 yan et al 2013 similarly several studies have used the cn method calibrated in a dominantly agricultural or forested watershed to predict changes in runoff or streamflow under projections of urban growth du et al 2012 zhou et al 2013 niraula et al 2015 wagner et al 2016 the soil and water assessment tool swat arnold et al 1998 2012 is a semi distributed watershed model which includes both the cn and g a methods to simulate rainfall runoff processes the large majority of studies conducted with swat have used the cn method for hydrologic and water quality assessments gassman et al 2014 bauwe et al 2016 a few recent studies have compared the performance of the cn or g a methods the results from these studies are often inconsistent and in some cases contradictory some studies concluded better performance of the cn method wilcox et al 1990 kannan et al 2007 bauwe et al 2016 cheng et al 2016 while other studies demonstrated better performance of the g a king et al 1999 ficklin and zhang 2013 yang et al 2016 however the generalizability of the conclusions from these studies remains limited because they neglected three important considerations first comparison of models based on a single calibrated parameter set is subject to biases in model selection and modelers expertise second a model calibrated for responses at the outlet of the watershed may not produce reliable simulations of interior locations with different geospatial characteristics such as land use third modeling uncertainties must be incorporated in comparison and selection of models modeling uncertainty includes the uncertainty in model parameters algorithms inputs and measurement data beven and binley 1992 vrugt et al 2003 ajami et al 2007 harmel et al 2014 yen et al 2014 not accounting for any of these sources of uncertainty when comparing the performance of models can mask real differences in model performance the overall goal of this study is to probabilistically investigate the performance validity of the cn and g a methods within swat for simulating hydrologic responses under varying land use conditions the specific objectives are to i evaluate the uncertainties from different sources parameters input data and model structure under the cn and g a methods when simulating streamflow ii compare the streamflow prediction uncertainty for swat with different rainfall runoff methods and iii quantify the total hydrologic regime and components of streamflow simulated using cn and g a methods at locations with various dominant upstream land use while a number of previous studies have compared the performance of cn and g a methods applying a total uncertainty estimation framework and accounting for upstream land use variations to assess the performance of the methods is novel considering that different climate inputs daily vs subdaily are used for cn vs g a the study reveals the importance of accounting for input data uncertainty when comparing the performance of the methods in simulating hydrologic responses also using full flow statistics via predictive flow duration curve uncertainty for assessing the performance of the methods sheds light on the benefits and deficiencies of each method this study provides useful insight into the benefits and limitations of different runoff simulation methods in the widely applied swat model 2 materials and methods three separate swat models were developed the models were identical except for the rainfall runoff mechanism and the precipitation time step accommodating the mechanism the analysis period was 2002 2012 of which 2002 2008 was used for training 2000 2001 was used for model warmup and 2009 2012 was used for testing the models the uncertainty assessment framework developed was used with the likelihood function set to consider the errors only at the outlet of the watershed at each model realization the error statistics including likelihood sum of squared errors sse and nash sutcliff coefficient of efficiency ns as well as time series of simulated streamflow were stored for the outlet of the watershed and five other stream locations usgs gauges inside the watershed the stream locations inside the watershed were selected such that they included a variety of sizes and dominant land use types agriculture developed forest of upstream subwatersheds by comparing model performance at these locations inside the watershed we assessed how models with cn and g a mechanisms perform at subwatersheds with different dominant land use types while training the model at the watershed outlet 2 1 study watershed the haw watershed in central north carolina within the piedmont region fig 1 drains 3280 km2 1270 miles2 the land use within the watershed is 43 forest 20 urban suburban and 27 agriculture of which more than 90 is pasture national land cover database nlcd2011 usgs tnm 2016 average annual precipitation is 1060 mm mm with summer precipitation being the highest and autumn the driest from 2002 to 2012 the driest year was 2002 with 780 mm precipitation and 2003 had the highest precipitation 1815 mm national oceanic and atmospheric administration noaa 2016 2 2 hydrologic model swat is a continuous time distributed parameter process based watershed model which has been used extensively for hydrologic and water quality assessments under varying climatic land use and management conditions in small watersheds to large river basins gassman et al 2007 arnold et al 2012 card staff 2016 the model has the capability to run on daily or smaller time steps in swat the watershed is split into smaller subwatersheds which are further discretized into hydrologic response units hrus hrus are the smallest spatial units in swat and are defined as areas within each subwatershed with unique combinations of land use soil and slope class swat does not have a routing component between hrus the runoff from hrus within each subwatershed is aggregated and then routed through the stream network climate inputs drive hydrologic responses and provide moisture and energy inputs in swat hydrologic processes simulated in the model include canopy storage surface runoff infiltration evapotranspiration lateral flow tile drainage redistribution of water within the soil profile return flow and recharge arnold et al 2012 surface runoff is simulated using either the modified g a mein and larson 1973 with subdaily rainfall or cn method with daily rainfall the rainfall runoff methods examined in this study are infiltration excess methods saturation excess was not an important consideration in this study watershed however the probabilistic framework for assessment of rainfall runoff methods developed and illustrated in this study could be extended to other versions of the swat model that do incorporate saturation excess processes e g easton et al 2008 the green and ampt and cn methods are available runoff estimation mechanisms i e model structures in swat in the cn method surface runoff is estimated with daily rainfall depth r day and retention parameter s 1 q surf r day 0 2 s 2 r day 0 8 s where q surf is the depth of the surface runoff all parameters are values for the day in millimeter mm the retention parameter for cn in swat is often estimated based on antecedent soil moisture 2 s s max 1 sw s w exp w 1 w 2 s w where sw is the soil water content of the entire profile excluding the amount of water mm held in profile at wilting point w 1 and w 2 are shape coefficients explained in swat documentation neitsch et al 2011 and s max denotes the maximum value of retention parameter mm calculated as 3 s max 25 4 1000 cn 10 where cn is the curve number for soil moisture condition i explained in swat documentation neitsch et al 2011 this approach tends to overestimate the runoff in shallow soils kannan et al 2007 hence another option can be used to compute the retention parameter at a given time step t based on plant evapotranspiration neitsch et al 2011 4 s t s t 1 e 0 exp c n c o e f s t 1 s max r day q surf where s t 1 is the retention parameter from the previous time step i e day e 0 is the potential evapotranspiration for the day and cncoef is the weighting coefficient determined by calibration at the beginning of the simulation first day the retention is defined as s 0 9 s max calculating the cn based on plant evapotranspiration instead of soil moisture makes its value more dependent on climate instead of soil storage neitsch et al 2011 the cn method based on soil moisture and evapotranspiration will be referred to as cn i and cn ii respectively hereafter the modified g a method is the alternative model structure in swat for runoff estimation that incorporates rainfall duration and intensity to compute the infiltration rate on subdaily time steps 5 f inf t k e ψ wf δ θ v f inf t where f inf t is the infiltration rate at time t mm per hour and f inf t is the cumulative infiltration at time t mm k e denotes the effective hydraulic conductivity mm per hour ψ wf denotes the wetting front potential mm and δ θ v represents the change in volumetric moisture content across the wetting front mm mm equations for f inf t k e ψ wf and δ θ v are explained in swat documentation neitsch et al 2011 2 3 model inputs terrain soils land use climate and hydrography the elevation data for building the swat model was the 1 3 arc second 10 m resolution digital elevation model dem of the haw watershed obtained from united states geological survey the national map usgs tnm 2016 the soil survey geographic ssurgo database from united states department of agriculture natural resources conservation services usda nrcs 2016 was used to represent soil characteristics and variability in the watershed the ssurgo soil data were not available for a small area in the north eastern part of the haw watershed 3 of total watershed area the state soil geographic statsgo usda nrcs 2016 data were used to cover the area with missing ssurgo information the components within each map unit were aggregated using a weighted average scheme in which the weights were the percentage of each component within the map unit the national land cover database nlcd for year 2006 was obtained from the usgs tnm and used as land use for building the model the resolution of the ssurgo statsgo and nlcd data was 1 arc second 30 m stream flowlines subwatershed boundaries and other hydrography information were obtained from usgs national hydrography dataset usgs nhd 2016 the stream flowlines were used for more accurate stream delineation in swat by superimposing the nhd flowlines on the dem in the process of watershed delineation the hydrographic segmentation and subwatershed boundary delineation was improved especially in locations where the dem does not provide enough accuracy winchell et al 2007 the haw watershed contains three major lakes whose operations altered the natural streamflow regime to some extent these lakes were included in the models and their operations were modeled by including their average monthly outflows observed climate for three meteorological stations fig 1 were obtained from the national climatic data center ncdc quality controlled local climatological data qclcd noaa 2016 database daily and hourly precipitation minimum and maximum temperature were collected for the period of 2000 to 2012 wind speed solar radiation and relative humidity were simulated by swat 2 4 measurements stream discharge daily stream discharge data from usgs national water information system usgs nwis 2016 were obtained for six stations with daily measurements for the analysis period 2002 2012 fig 1 the locations of gauges table 1 were carefully selected to enable adequate characterization of the predictive skill of different model structures under varying land use conditions particularly developed i e urban versus undeveloped areas 2 5 the swat model setup the dem was used along with the nhd flowlines to delineate the watershed and streams the watershed was divided into 23 subwatersheds the hru definition was done using the land use and soil data with 10 threshold for delineation since the topographic variability was small a single class slope was assumed within each subwatershed using these settings 122 hrus were defined for the watershed in highly urbanized watersheds facilities such as wastewater treatment plants can alter the natural streamflow regime hence their effects must be incorporated into the model in haw watershed there were 10 large facilities with average daily effluent larger than 0 1 mgd discharging into the streams these facilities were included in the models through adding point sources in swat at stream locations where they discharged their effluents their effluents were discharged into streams at related stream locations as average monthly flows another factor that can alter the natural streamflow regime in urban areas is the stormwater discharge into streams through pipes or conduits the urban stormwater collection systems and control measures were not included in the models as it was beyond the scope of this study this study was concentrated on aggregate responses of the developed areas at the subwatershed level in other words the model performance was evaluated probabilistically for stream locations that incorporate the aggregate effects of urban areas including point sources and urban stormwater runoff considering that we tried to define the subwatersheds such that each urban area falls within a subwatershed so that addition of stormwater in a diffuse manner or through a conduit or pipe has a minimal effect on the results two separate swat models were developed using arcswat 2012 usda ars 2014 the models were completely identical except for the runoff estimation method and precipitation time step one of the models was developed with daily precipitation and cn method using the soil moisture cn i and plant evapotranspiration cn ii and the other model was developed using the hourly precipitation and g a method for runoff simulation therefore three model setups were prepared for the analyses 2 6 probabilistic model assessment framework a probabilistic approach was used to assess the predictive skill and performance validity of competing model structures under varying land use conditions the bayesian based approach explicitly accounts for uncertainties from model parameterization climate input data i e precipitation model structure cn i cn ii or g a and measurement data i e daily streamflow the framework was developed in matlab the mathworks inc a markov chain monte carlo mcmc sampling scheme the dream method was used to sample the parameter space and derive the posterior distributions a statistically correct likelihood function which explicitly accounts for streamflow error heteroscedasticity and autocorrelation was employed to ensure the reliability of the search algorithm input data uncertainty was incorporated by using precipitation multipliers drawn from a gaussian distribution with an uncertain mean and standard deviation for each meteorological station inferences on posterior distributions of precipitation multipliers were obtained simultaneously along with swat model parameters finally bayesian model averaging bma was used to evaluate model structural uncertainty and to assess the predictive skill of the competing model structures similar frameworks have been developed in other studies e g ajami et al 2007 kavetski et al 2003 in which they used other mcmc algorithms such as shuffled complex evolution metropolis scem however employing the dream algorithm for conducting the mcmc within this total uncertainty estimation framework is novel more importantly application of such framework for probabilistic appraisal of different rainfall runoff methods within distributed hydrologic models has not been conducted to the best of our knowledge 2 6 1 model parameter uncertainty in a hydrologic model m streamflow is simulated q as a function of climatic inputs i e precipitation r and a vector of model parameters θ 6 q m r θ the simulated streamflow is subject to a variety of errors stemming from measured climate inputs model parameters and insufficiency of the model conceptualization model structural error the streamflow error residual then becomes 7 e r θ m q m r θ where q is the observed streamflow and e r θ m denotes the streamflow error residuals due to errors from observed precipitation model parameters and model structure applying the bayes theorem the parameter set θ is assigned posterior probability distribution p θ q which is proportional to the product of the parameter prior probability distribution p θ and a likelihood function l θ q the likelihood function assuming normally and independently distributed model residuals e with mean zero and variable standard deviation at each observation time step σ t can be expressed as vrugt 2016 8 l θ q σ t 1 n 1 2 π σ t 2 e x p 1 2 σ t 2 q t q t θ 2 where n is the number of time steps using a variable standard deviation at each observation time step σ t allows accounting for error heteroscedasticity which often exists in streamflow simulations however in most cases it is infeasible to determine σ at each time step due to lack of repeated streamflow measurements different approaches have been proposed to circumvent this issue some studies have used different transformations including natural log or box cox to stabilize σ and reduce heteroscedasticity sorooshian and dracup 1980 others have proposed alternative forms for the likelihood function schoups and vrugt 2010 in this study we applied a natural log transformation on measured and observed streamflow to reduce error heteroscedasticity often it is easier to maximize the logarithm of the likelihood function due to numerical stability and algebraic simplicity ajami et al 2007 vrugt 2016 hence the natural log of the likelihood function was adopted for optimization the streamflow error residuals are usually not independently distributed and in most cases temporal autocorrelation exists in the residuals specifically when errors are estimated at daily or smaller time steps a common approach to reduce the autocorrelation in model residuals is applying an auto regressive scheme on the error residuals sorooshian and dracup 1980 9 e t ρ e t 1 ν t where ρ is the lag serial correlation coefficient for the error residuals and ν t is a vector of random components ν t n 0 σ ν in this study we used a first order autoregressive transformation ar 1 applying the natural log and ar 1 ρ 1 the log likelihood function becomes vrugt 2016 10 l θ q σ ρ n 2 ln 2 π 1 2 ln σ ν 2 1 ρ 2 1 2 σ ν 2 1 ρ 2 e 1 2 t 2 n e t ρ e t 1 2 parameters ρ and σ are determined along with model parameters at each model realization during the mcmc sampling algorithm the parameters for the uncertainty analysis were selected based on experience and sensitivity analysis performed previously arabi et al 2007 arnold et al 2012 tasdighi et al 2017 table 2 lists the parameters selected for uncertainty analysis along with their ranges in this study uniform noninformative prior distributions were assumed for parameters within predefined ranges the same assumption has been used in many other hydrological modeling studies since prior knowledge of the model parameters is often not available and is case specific ajami et al 2007 the ranges for parameters were selected based on the swat user manual and experience from previous study tasdighi et al 2017 arnold et al 2012 2 6 2 model input uncertainty while uncertainty from model parametrization has been examined in many hydrologic modeling studies there are only a few cases where input uncertainty is explicitly accounted for kavetski et al 2003 ajami et al 2007 the majority of these studies incorporate input uncertainty by applying latent variables which are basically multipliers for precipitation events drawn randomly from a predefined distribution along with model parameters kavetski et al 2003 leta et al 2015 this approach can lead to dimensionality problems as the number of precipitation events increase in this study a method proposed by ajami et al 2007 is implemented to account for precipitation uncertainty using this method instead of iterating on each single multiplier the iteration is performed on the mean and standard deviation of a random gaussian distribution from which the multipliers are randomly drawn at each time step 11 r t ϕ t r t ϕ t n μ ϕ σ ϕ 2 where r t and r t are the corrected and observed precipitation depths respectively ϕ t is the random multiplier drawn from a normal distribution with a random mean μ ϕ μ ϕ 0 9 1 1 and variance σ ϕ 2 σ ϕ 2 1 e 5 1 e 3 ajami et al 2007 incorporating precipitation multipliers using this approach reduces the dimensionality issue 2 6 3 model structural uncertainty evaluation of model structural uncertainty has been investigated in hydrologic modeling raftery et al 2005 duan et al 2007 yen et al 2014 different methods have been proposed to account for model structural uncertainty hoeting et al 1999 georgakakos et al 2004 one such approach is the bayesian model averaging bma hoeting et al 1999 the bma is a probabilistic algorithm for combining competing models based on their predictive skills ajami et al 2007 madadgar and moradkhani 2014 in this study the three rainfall runoff model structures in swat m 1 c n i m 2 c n i i m 3 g a were used to explore the effects of model structural uncertainty under the bma theory the posterior distribution of the bma prediction q bma is 12 p q bma m 1 m 2 m 3 q i 1 3 p m i q p i q i m i q where p m i q is the posterior probability of the model m i this term can be assumed as a probabilistic weight w i for model m i in the bma prediction q bma the constraint for bma weights is i 1 3 w i 1 higher values of w i can be interpreted as higher predictive skill for a given model structure the model weights can be determined using different optimization techniques the expectation maximization em algorithm dempster et al 1977 is one such technique to estimate model weights used in several studies yen et al 2014 ajami et al 2007 in this study the em method was used to determine the model weights the brier scores were also employed to compare the performance of the three models while incorporating parameter and input data uncertainties the brier score bs is a measure of the accuracy of the prediction and has been frequently used in the probabilistic forecast analysis georgakakos et al 2004 bs is defined as 13 bs 1 n t 1 n f t o t 2 where n is the number of time steps in the record f t is estimated by the fraction of model simulations larger than the predefined streamflow threshold and o t is a binary value equal to 1 if the observation at time step t is larger than the predefined threshold and equal to zero in all other cases in this form eq 13 the lower the value of the bs the better the prediction skill of the model 2 6 4 the dream algorithm for mcmc analyses several bayesian algorithms are available which have been widely used for uncertainty assessment in hydrologic modeling including the generalized likelihood uncertainty estimation glue beven and binley 1992 the shuffled complex evolution metropolis scem ua vrugt et al 2003 and the differential evolution adaptive metropolis dream vrugt et al 2009 dream is a multi chain mcmc method that randomly samples the parameter space and automatically tunes the scale and orientation of the sampling distribution to move toward the target distribution by maximizing the value of the likelihood function the method has been used extensively for parameter estimation of complex environmental models vrugt 2016 the convergence of the algorithm can be monitored using the procedure proposed by gelman and rubin 1992 in this procedure a scale reduction score r is monitored to check whether each parameter has reached a stationary distribution gelman and rubin 1992 the common convergence criterion of r 1 2 was used in this study as well dream is specifically beneficial in the optimization of complex high dimensional problems in this study dream was employed to sample the parameter space and derive the posterior distributions 2 7 the strategy for assessment of model performances several criteria were used to assess the performance of the models including error statistics likelihood sse and ns determined based on simulated and observed hydrographs width of the band of uncertainty spread inclusion rate coverage determined based on the streamflow observations and 95 confidence interval of simulation ensembles flow duration curves along with bands of uncertainty brier scores and bma weights the value of utilizing multiple performance indicators is commonly recommended because it produces a more comprehensive evaluation of model performance legates and mccabe 1999 harmel et al 2010 for comparing the performance of the models in terms of error statistics and bma weights a two sample t test and kolmogorov smirnov were employed to test the significance of the difference between mean and distribution of the error statistics under each model respectively finally the water budget in the watershed was analyzed using the results obtained from different models at various locations 3 results and discussion 3 1 evaluation of model performances the purpose of this step of analyses was to monitor the variation of streamflow error statistics at different stream locations in the watershed during the training of the model at the watershed outlet using the bayesian total uncertainty analysis framework fig 2 illustrates the variation of error statistics at different stream locations it is important to note that the training of the models was performed only at the watershed outlet outlet 23 using the values of likelihood eq 10 as the objective function the performances of the three models were identical in terms of the likelihood function at the watershed outlet outlet 23 however cn i and cn ii models had a slightly although statistically significant better performance in terms of sse and ns t test p 0 01 the two sample kolmogorov smirnov test revealed that the distributions of error statistics e g ns under different models were different at 0 01 significance level at all locations at outlets 13 and 19 with mainly agricultural and forested land use cn models performed slightly better t test p 0 01 than the g a model in terms of sse and ns while cn i and cn ii had very close performance at different locations cn ii had a relatively better performance t test p 0 01 compared to cn i and g a in the highly forested subwatershed outlet 19 showing lower values of sse on average 8 and 11 lower than cni and g a respectively and higher values of ns on average 21 and 29 higher than cni and g a respectively this was foreseeable as with cn ii the curve number is determined based on plant evapotranspiration instead of soil moisture similar results were reported for better performance of the cn method over the g a in other agricultural watersheds kannan et al 2007 cheng et al 2016 in contrast comparing the performance of the cn and g a methods in an intensive agricultural watershed ficklin and zhang 2013 concluded that the g a model is more likely to generate better daily simulations it should be noted that these studies used a deterministic approach and none compared the performance of the cn and g a with regard to upstream land use variations in highly developed subwatersheds outlets 9 and 12 g a had a substantially and significantly t test p 0 01 better performance than the cn methods with all error statistics fig 2 this is an important result as it demonstrates that while trained at the outlet of the watershed the g a model had a much better performance in urbanized subwatersheds inside the watershed the better performance of the g a compared to cn methods in urban areas is investigated and discussed more in section 3 5 outlet 7 had an erratic behavior in terms of likelihood which can indicate fundamental deficiency of the models in simulating streamflow for that subwatershed 3 2 model parameter uncertainty the posterior cumulative distribution functions cdf of parameters for the three models are illustrated in fig 3 the posterior distributions were generated using 10 000 parameter sets sampled after the convergence of the mcmc algorithm it can be observed that using different rainfall runoff methods different posterior distributions were inferred for parameters in general most posterior parameter distributions showed some level of skewness which indicates deficiency in identifiability ajami et al 2007 while for most of the parameters the rainfall runoff methods determined the degree of the skewness for some parameters ch nii gw revap gwqmn and rchrg dp the skewness changed from positive to negative using different methods the cn i and cn ii resulted in similar posterior distributions for most parameters however for ch ki sol awc and sol k different distributions were inferred which conforms to intuition as cn i uses the soil water content for determining the curve number in runoff estimation parameter distributions that show great deviation from normality indicate some sort of deficiency in the combination of model structure input and training data an important observation in fig 3 was the lower values of surlag parameter sampled for the g a method surlag controls the surface runoff storage through the fraction of the total available water that will be allowed to enter the reach smaller values of surlag result in higher storage of water and delay in release of water to the reach looking at the posterior distribution of this parameter it can be observed that compared to cn methods smaller surlag values have been sampled for the g a method which can indicate simulation of a flashier hydrograph and higher peak flows by g a this was further investigated in section 3 5 these findings have important implications with regard to parameterization of swat when using different rainfall runoff mechanisms the majority of studies that have compared the performance of the rainfall runoff mechanisms within swat have used a deterministic approach for setting the model parameters using the cn or g a methods e g king et al 1999 ficklin and zhang 2013 the results obtained here suggest that this approach may mask the differences between the methods and result in misleading inferences regarding the performance of the models under the cn or g a methods 3 3 model input uncertainty precipitation multipliers were drawn from normal distributions with random mean and standard deviation sampled during each model run within the bayesian total uncertainty analysis framework fig 4 shows the cdf of the values of the mean μ ϕ sampled for input error models under different rainfall runoff mechanisms for the three climate stations since the posterior distributions of standard deviation σ ϕ for input error models were close to uniform they were excluded from the figure in general the mean of input error model under the g a method showed a distribution closer to normal with mean around one in contrast the cn methods produced posterior distribution skewed toward the higher bound especially at stations wban93783 and wban 93785 skewness toward the higher bound indicates the sampling algorithm s attempt to increase the magnitude of the precipitation events by using multipliers larger than one this can be explained by the structural deficiency of cn methods in simulating the peak streamflows which caused higher values of precipitation multipliers to be drawn to augment the runoff volume to capture the high flow events under these circumstances it can be hypothesized that the cn methods will lead to systematic overestimation of streamflow compared to g a assessed subsequently 3 4 model structural uncertainty bayesian model averaging was used at each model realization to combine the three rainfall runoff models bma weights were determined using em optimization method fig 5 shows the boxplots of bma weights at different subwatershed outlets mean of the weights and the weight for the optimized solution max likelihood are also marked on the boxplots the two sample kolmogorov smirnov test revealed that the distribution of bma weights for models were different at 0 01 significance level model performances in the agricultural and forested subwatersheds were relatively close in terms of bma weights it is evident that in the highly urbanized subwatersheds g a substantially and significantly based on the t test p 0 01 outperformed the cn methods however at the outlet of the watershed the cn methods showed a slightly but not significant better performance these results are in accordance with findings in section 3 1 where g a had a better performance in the subwatersheds with dominant urban land in terms of various error statistics in addition to bma brier scores were also employed to assess the skill of the models in streamflow simulation in original form eq 13 bs varies between 0 and 1 the lower the value of the bs the better the prediction skill of the model for illustration we used b s 1 b s to compare the performance of the models in fig 6 in this figure higher values of b s indicate better performance of the model at the outlet of the watershed the cn models showed a slightly better performance compared to the g a model specifically at low flow events with the agricultural and forested watershed the performances of the models were very close in terms of bs however at the highly urbanized subwatersheds the g a mechanism clearly outperformed the cn methods during low flow as well as high flow events resulting in higher values of b s these findings are also congruent with results from the bma and error statistics 3 5 streamflow prediction uncertainty hydrographs with bands of uncertainty have been used frequently for visual assessment of streamflow prediction uncertainty e g harmel et al 2010 while visual inspection of these graphs can provide useful information about the quality of simulation in cases where a relatively long record of streamflow is to be inspected this method can result in graphs that are difficult to read also hydrographs may not be very effective when comparing the predictive performance of several models specifically when bands of uncertainty are involved in this situation one has to either use a smaller time period or select some specific events for illustration of the hydrograph or use other measures for visualizing streamflow we therefore resorted to flow duration curves fdc to compare the performance of the models graphs of fdc along with bands of uncertainty provide an easily readable informative measure which can be used to assess the quality of streamflow prediction vogel and fennessey 1994 more importantly such graphs are much easier for comparing the predictive performance of the competing models it should be noted that fdcs can also be misleading since the serial structure and autocorrelation of the sequence of the streamflow record is removed in them vogel and fennessey 1994 bearing that in mind while we used fdcs to compare the predictive performance of the models the coverage percent of observations lying inside the 95 confidence interval of simulation ensembles and spread average width of the 95 confidence interval uncertainty band were determined based on hydrographs instead of fdcs since the performances of the models were similar in the smaller agricultural and forested subwatersheds outlets 7 13 and 19 they were excluded from further analysis the g a method resulted in wider bands of uncertainty wider spread and higher coverage rates compared to the cn methods table 3 during both training 2002 2008 and testing 2009 2012 periods except for outlet 23 during testing where cn ii resulted in higher spread at the outlet of the watershed outlet 23 the difference between the methods is small in terms of coverage and spread however at stations 9 and 12 urban dominant subwatersheds g a generated higher coverage rates compared to the cn models fig 7 shows the flow duration curves for the observed streamflow and 95 confidence interval bounds for the simulated streamflows for the three models at the three stream locations during the training period comparing the performance of the models at the outlet of the watershed the cn method produced narrower bands of uncertainty than the g a method however the g a model showed a slightly better performance in capturing the higher streamflow values in highly developed subwatersheds 9 and 12 the cn methods were unable to capture the high flow events also for medium low flow events the observations lay on the upper bound of the uncertainty band in contrast for the g a model the high flow events were mostly captured and the observations were near the center of the uncertainty band the better performance of the g a method in more developed areas was attributed to its better capacity in capturing the flashier behavior of the hydrographs due to quicker hydrologic responses in these areas the g a method was used with hourly precipitation data taking into account the effects of rainfall intensity since the hydrologic responses of urban areas areas with higher impervious surfaces and lower permeability tend to be flashier this consideration may significantly improve the model performance in particular the g a method outperformed the cn approaches in high intensity rainfall events this results in better performance of the g a in capturing the peak flows compared to the cn method which often caused high errors for the cn method in more developed subwatersheds similar results were obtained for the testing period fig 8 slightly narrower bands of uncertainty were determined during the testing period specifically at the watershed outlet outlet 23 table 4 presents the summary of different error statistics during training and testing periods minimum median and maximum values for various error statistics during the training and testing are provided in this table the better performance of the g a method compared to the cn in more developed subwatersheds can be observed in table 4 as well the assumptions of the likelihood function used were assessed using different diagnostics fig 9 homoscedasticity normality and autocorrelation of streamflow residuals at watershed outlet outlet 23 where model training is performed were assessed and illustrated in fig 9 the figure reveals that the ar 1 and log transformation were successful in fulfilling the assumptions of the likelihood function in terms of normality independence and homoscedasticity of residuals it can be observed that the g a method resulted in narrower normal distribution around zero for residuals 3 6 assessment of hydrologic budget and streamflow components the mean annual total water budget and components of streamflow for the three subwatersheds were quantified to gain insight into the differences among the hydrologic processes generating the outcomes fig 10 shows the cumulative bar plots for the overall water budget a c and more detailed components of streamflow e f the g a method generated lower water yield total amount of water contributing to streamflow and higher evapotranspiration et compared to the cn at all locations in all models et is the major component of water loss between 60 and 75 while about 10 15 and 20 25 of water turns into water yield for the g a and cn methods respectively the g a method predicted lower surface runoff sq and groundwater flow gwq contributing to streamflow compared to the cn method at all locations however it simulated higher lateral flow latq contribution to streamflow with cn i and cn ii about 35 of the water yield was derived from the lateral flow while in the g a method lateral flow contributed up to 75 of the streamflow other studies have shown higher baseflow contribution from the g a method compared to the cn bauwe et al 2016 kannan et al 2007 considering all components of subsurface flow the g a model infiltrated more precipitation more water in soil profile resulted in higher et for the g a model as well based on the results from multiple model performance criteria the g a performed better and hence was the more suitable method in the study watershed 4 conclusions swat has been used extensively in the literature for hydrologic simulations while the model has the capability to employ either cn or g a method for runoff estimation almost all studies have employed the cn method this may be partly due to lack of a rigorous comparison study to justify merits of using one method over the other along with simplicity of the cn method this study attempted to address this shortcoming regarding the extreme popularity of the swat model the findings of this study can shed light on selecting the rainfall runoff method within swat that can potentially lead to more realistic streamflow simulations in mixed land use watersheds in this study a bayesian total uncertainty assessment framework was implemented to compare the performance of the three runoff generation mechanisms within swat under different upstream land use conditions using the uncertainty assessment framework at the watershed outlet model performances was assessed at several stream locations inside the watershed at the watershed outlet and subwatersheds with dominant agricultural or forest land use the models with cn methods performed slightly better however at the two subwatersheds with highly developed land use models with g a method had a much better performance in simulating the streamflow the better performance of the g a method in more developed areas was attributed to its better capacity in capturing the flashier behavior of the hydrographs due to quicker hydrologic responses in these areas the g a method had a much better performance in simulating the peak flows in the more developed subwatersheds overall the streamflow prediction intervals from models with g a method covered more observations however they were slightly wider indicating higher uncertainty for streamflow prediction the cn models were unable to capture the high flow events specifically in developed subwatersheds posterior distribution of mean for gaussian distributions from which precipitation multipliers were randomly drawn were closer to normal using the hourly precipitation data and g a method while using daily precipitation with cn methods resulted in substantial negative skewness the deficiency of models with cn methods in simulating the peak streamflows caused higher values of precipitation multipliers to be sampled to augment the runoff volume the cn method simulated higher water yield volumes specifically at the urban dominated subwatersheds while g a method simulated higher et values the higher water yield volumes predicted by cn method in the highly urbanized subwatersheds can be explained by cn attempt to simulate the high flow events during the model training which results in overall overestimation of water yield the g a model resulted in lower surface runoff at all locations compared to the cn models however it simulated higher infiltration and subsurface flows the results of this study have important implications for determining which rainfall runoff method performs better in simulating the hydrologic regime the evaluation is specifically relevant for applying a distributed hydrologic model such as swat in a mixed land use watershed where model training will be performed only at the watershed outlet but the model is to be used for simulating hydrologic responses at different locations inside the watershed in summary the results suggest that in the haw watershed while trained at watershed outlet the swat model with g a method can potentially perform better in areas inside the watershed with higher percentage of developed land the swat models with cn methods proved to have similar or slightly better performance in areas with agriculture or forest dominant land use however care should be taken in applying such inferences as further studies in other watersheds with different physiographic characteristics are needed to generalize such findings it should also be noted that in highly urbanized areas the discharge of stormwater runoff through drainage pipes or conduits can disturb the natural streamflow regime in such watersheds including the discharge from conduits or pipes at the actual stream locations should improve the streamflow simulation acknowledgements this publication was made possible by usepa grant rd835570 its contents are solely the responsibility of the grantee and do not necessarily represent the official views of the usepa further usepa does not endorse the purchase of any commercial products or services mentioned in the publication the authors would like to thank the associate editor and reviewers for their insightful comments usda is an equal opportunity employer and provider 
7082,a probabilistic approach is presented to assess the performance validity of the empirical curve number cn and physically based green and ampt g a rainfall runoff methods in the swat model specifically the effects of modeling uncertainties on characterization of the hydrologic budgets and streamflow regimes at various spatial scales and upstream land use conditions are investigated a bayesian total uncertainty assessment framework which explicitly accounts for uncertainties from model parameters inputs structure and measurement data was employed to explore uncertainties in streamflow simulation using swat with different rainfall runoff methods in a mixed land use watershed while the models were trained for streamflow estimation only at the watershed outlet the performances of the models were compared at different stream locations within the watershed at the watershed outlet the cn method had a slightly better but not significant performance in terms of streamflow error statistics similar results were obtained for the predominantly forested and agricultural tributaries however in tributaries with higher percentage of developed land g a outperformed the cn method in simulating streamflow based on various performance metrics in general the 95 prediction intervals from the models with g a method covered a higher percentage of observed streamflow especially during the high flow events however they were approximately 20 45 wider than the corresponding 95 prediction intervals from the cn methods using 95 prediction interval for estimated flow duration curves results indicated that the models with cn methods underestimated high flow events especially in tributaries with highly developed land use however the cn methods generated higher water yields to streams than the g a method the results of this study have important implications for the selection and application of appropriate rainfall runoff methods within complex distributed hydrologic models particularly when simulating hydrologic responses in mixed land use watersheds in the present study while cn and g a methods in the swat model performed similarly at the outlet of a mixed land use watershed g a captured the internal processes more realistically the subsequent effects on the representation of internal hydrological processes and budgets are discussed keywords rainfall runoff model green and ampt curve number distributed hydrologic modeling bayesian uncertainty analysis swat 1 introduction watershed models are increasingly used to assess hydrologic responses of watersheds to changes in land use climate variability and change and other alterations of system characteristics faced with myriad hydrologic models hydrologists ought to select an appropriate model and demonstrate its performance validity for the desired assessments the performance of watershed models is often evaluated based on a deterministic approach i e calibrate validate predict where calibration is conducted to obtain a parameter set that provides the best fit between model responses and observations at the watershed outlet seibert 1999 santhi et al 2008 niraula et al 2015 such assessments can be inadequate and in many cases misleading for selecting an appropriate distributed hydrologic model particularly when the model is used to simulate interior hydrologic processes or to assess responses at various locations within the watershed beven 2001 ahmadi et al 2014 probabilistic approaches can address the equifinality and nonuniqueness issues in parameter estimation moradkhani et al 2005 input uncertainty kavetski et al 2003 and measurement errors harmel and smith 2007 when assessing competing model structures ajami et al 2007 literature is replete with studies in which a model calibrated at the watershed outlet is used to predict streamflows at interior locations within the watershed under varying upstream land use conditions ahearn et al 2005 baker and miller 2013 yan et al 2013 similarly studies continue to use the deterministic approach to explore the hydrologic effects of land use change zhou et al 2013 sunde et al 2016 zuo et al 2016 climate change xu et al 2013 meaurio et al 2017 or implementation of management practices taylor et al 2016 jang et al 2017 motallebi et al 2017 interestingly calibrated model responses at the watershed outlet are also used to compare the performance of competing models seibert 1999 santhi et al 2008 niraula et al 2015 the validity of these studies remains unclear mainly because a model could produce responses at the watershed outlet that adequately match observations i e right answer while representing the internal processes and responses incorrectly i e wrong reasons beven 2006 two common methods for rainfall runoff modeling are the curve number method cn usda nrcs 2004 and the green and ampt method g a green and ampt 1911 the cn is an empirical method that provides estimates of runoff under varying land use and soil types using total volume of rainfall conversely the g a is a physically based method that uses rainfall intensity and duration along with soil physical characteristics such as hydraulic conductivity to simulate infiltration a major limitation of the cn method is that it only uses the total volume of rainfall and does not account for rainfall intensity and duration hence the applicability of the method is limited to simulations at daily to annual time steps and cannot be extended to resolve processes at sub daily time steps such limitations can result in erroneous simulations of runoff processes in areas with inherently quick hydrologic responses to rainfall events such as small catchments areas with relatively low soil permeability and developed areas with large impervious surfaces miller et al 2014 yet many studies continue to use the cn method to quantify runoff in mixed land use watersheds with considerable areas of developed land zhou et al 2013 yan et al 2013 similarly several studies have used the cn method calibrated in a dominantly agricultural or forested watershed to predict changes in runoff or streamflow under projections of urban growth du et al 2012 zhou et al 2013 niraula et al 2015 wagner et al 2016 the soil and water assessment tool swat arnold et al 1998 2012 is a semi distributed watershed model which includes both the cn and g a methods to simulate rainfall runoff processes the large majority of studies conducted with swat have used the cn method for hydrologic and water quality assessments gassman et al 2014 bauwe et al 2016 a few recent studies have compared the performance of the cn or g a methods the results from these studies are often inconsistent and in some cases contradictory some studies concluded better performance of the cn method wilcox et al 1990 kannan et al 2007 bauwe et al 2016 cheng et al 2016 while other studies demonstrated better performance of the g a king et al 1999 ficklin and zhang 2013 yang et al 2016 however the generalizability of the conclusions from these studies remains limited because they neglected three important considerations first comparison of models based on a single calibrated parameter set is subject to biases in model selection and modelers expertise second a model calibrated for responses at the outlet of the watershed may not produce reliable simulations of interior locations with different geospatial characteristics such as land use third modeling uncertainties must be incorporated in comparison and selection of models modeling uncertainty includes the uncertainty in model parameters algorithms inputs and measurement data beven and binley 1992 vrugt et al 2003 ajami et al 2007 harmel et al 2014 yen et al 2014 not accounting for any of these sources of uncertainty when comparing the performance of models can mask real differences in model performance the overall goal of this study is to probabilistically investigate the performance validity of the cn and g a methods within swat for simulating hydrologic responses under varying land use conditions the specific objectives are to i evaluate the uncertainties from different sources parameters input data and model structure under the cn and g a methods when simulating streamflow ii compare the streamflow prediction uncertainty for swat with different rainfall runoff methods and iii quantify the total hydrologic regime and components of streamflow simulated using cn and g a methods at locations with various dominant upstream land use while a number of previous studies have compared the performance of cn and g a methods applying a total uncertainty estimation framework and accounting for upstream land use variations to assess the performance of the methods is novel considering that different climate inputs daily vs subdaily are used for cn vs g a the study reveals the importance of accounting for input data uncertainty when comparing the performance of the methods in simulating hydrologic responses also using full flow statistics via predictive flow duration curve uncertainty for assessing the performance of the methods sheds light on the benefits and deficiencies of each method this study provides useful insight into the benefits and limitations of different runoff simulation methods in the widely applied swat model 2 materials and methods three separate swat models were developed the models were identical except for the rainfall runoff mechanism and the precipitation time step accommodating the mechanism the analysis period was 2002 2012 of which 2002 2008 was used for training 2000 2001 was used for model warmup and 2009 2012 was used for testing the models the uncertainty assessment framework developed was used with the likelihood function set to consider the errors only at the outlet of the watershed at each model realization the error statistics including likelihood sum of squared errors sse and nash sutcliff coefficient of efficiency ns as well as time series of simulated streamflow were stored for the outlet of the watershed and five other stream locations usgs gauges inside the watershed the stream locations inside the watershed were selected such that they included a variety of sizes and dominant land use types agriculture developed forest of upstream subwatersheds by comparing model performance at these locations inside the watershed we assessed how models with cn and g a mechanisms perform at subwatersheds with different dominant land use types while training the model at the watershed outlet 2 1 study watershed the haw watershed in central north carolina within the piedmont region fig 1 drains 3280 km2 1270 miles2 the land use within the watershed is 43 forest 20 urban suburban and 27 agriculture of which more than 90 is pasture national land cover database nlcd2011 usgs tnm 2016 average annual precipitation is 1060 mm mm with summer precipitation being the highest and autumn the driest from 2002 to 2012 the driest year was 2002 with 780 mm precipitation and 2003 had the highest precipitation 1815 mm national oceanic and atmospheric administration noaa 2016 2 2 hydrologic model swat is a continuous time distributed parameter process based watershed model which has been used extensively for hydrologic and water quality assessments under varying climatic land use and management conditions in small watersheds to large river basins gassman et al 2007 arnold et al 2012 card staff 2016 the model has the capability to run on daily or smaller time steps in swat the watershed is split into smaller subwatersheds which are further discretized into hydrologic response units hrus hrus are the smallest spatial units in swat and are defined as areas within each subwatershed with unique combinations of land use soil and slope class swat does not have a routing component between hrus the runoff from hrus within each subwatershed is aggregated and then routed through the stream network climate inputs drive hydrologic responses and provide moisture and energy inputs in swat hydrologic processes simulated in the model include canopy storage surface runoff infiltration evapotranspiration lateral flow tile drainage redistribution of water within the soil profile return flow and recharge arnold et al 2012 surface runoff is simulated using either the modified g a mein and larson 1973 with subdaily rainfall or cn method with daily rainfall the rainfall runoff methods examined in this study are infiltration excess methods saturation excess was not an important consideration in this study watershed however the probabilistic framework for assessment of rainfall runoff methods developed and illustrated in this study could be extended to other versions of the swat model that do incorporate saturation excess processes e g easton et al 2008 the green and ampt and cn methods are available runoff estimation mechanisms i e model structures in swat in the cn method surface runoff is estimated with daily rainfall depth r day and retention parameter s 1 q surf r day 0 2 s 2 r day 0 8 s where q surf is the depth of the surface runoff all parameters are values for the day in millimeter mm the retention parameter for cn in swat is often estimated based on antecedent soil moisture 2 s s max 1 sw s w exp w 1 w 2 s w where sw is the soil water content of the entire profile excluding the amount of water mm held in profile at wilting point w 1 and w 2 are shape coefficients explained in swat documentation neitsch et al 2011 and s max denotes the maximum value of retention parameter mm calculated as 3 s max 25 4 1000 cn 10 where cn is the curve number for soil moisture condition i explained in swat documentation neitsch et al 2011 this approach tends to overestimate the runoff in shallow soils kannan et al 2007 hence another option can be used to compute the retention parameter at a given time step t based on plant evapotranspiration neitsch et al 2011 4 s t s t 1 e 0 exp c n c o e f s t 1 s max r day q surf where s t 1 is the retention parameter from the previous time step i e day e 0 is the potential evapotranspiration for the day and cncoef is the weighting coefficient determined by calibration at the beginning of the simulation first day the retention is defined as s 0 9 s max calculating the cn based on plant evapotranspiration instead of soil moisture makes its value more dependent on climate instead of soil storage neitsch et al 2011 the cn method based on soil moisture and evapotranspiration will be referred to as cn i and cn ii respectively hereafter the modified g a method is the alternative model structure in swat for runoff estimation that incorporates rainfall duration and intensity to compute the infiltration rate on subdaily time steps 5 f inf t k e ψ wf δ θ v f inf t where f inf t is the infiltration rate at time t mm per hour and f inf t is the cumulative infiltration at time t mm k e denotes the effective hydraulic conductivity mm per hour ψ wf denotes the wetting front potential mm and δ θ v represents the change in volumetric moisture content across the wetting front mm mm equations for f inf t k e ψ wf and δ θ v are explained in swat documentation neitsch et al 2011 2 3 model inputs terrain soils land use climate and hydrography the elevation data for building the swat model was the 1 3 arc second 10 m resolution digital elevation model dem of the haw watershed obtained from united states geological survey the national map usgs tnm 2016 the soil survey geographic ssurgo database from united states department of agriculture natural resources conservation services usda nrcs 2016 was used to represent soil characteristics and variability in the watershed the ssurgo soil data were not available for a small area in the north eastern part of the haw watershed 3 of total watershed area the state soil geographic statsgo usda nrcs 2016 data were used to cover the area with missing ssurgo information the components within each map unit were aggregated using a weighted average scheme in which the weights were the percentage of each component within the map unit the national land cover database nlcd for year 2006 was obtained from the usgs tnm and used as land use for building the model the resolution of the ssurgo statsgo and nlcd data was 1 arc second 30 m stream flowlines subwatershed boundaries and other hydrography information were obtained from usgs national hydrography dataset usgs nhd 2016 the stream flowlines were used for more accurate stream delineation in swat by superimposing the nhd flowlines on the dem in the process of watershed delineation the hydrographic segmentation and subwatershed boundary delineation was improved especially in locations where the dem does not provide enough accuracy winchell et al 2007 the haw watershed contains three major lakes whose operations altered the natural streamflow regime to some extent these lakes were included in the models and their operations were modeled by including their average monthly outflows observed climate for three meteorological stations fig 1 were obtained from the national climatic data center ncdc quality controlled local climatological data qclcd noaa 2016 database daily and hourly precipitation minimum and maximum temperature were collected for the period of 2000 to 2012 wind speed solar radiation and relative humidity were simulated by swat 2 4 measurements stream discharge daily stream discharge data from usgs national water information system usgs nwis 2016 were obtained for six stations with daily measurements for the analysis period 2002 2012 fig 1 the locations of gauges table 1 were carefully selected to enable adequate characterization of the predictive skill of different model structures under varying land use conditions particularly developed i e urban versus undeveloped areas 2 5 the swat model setup the dem was used along with the nhd flowlines to delineate the watershed and streams the watershed was divided into 23 subwatersheds the hru definition was done using the land use and soil data with 10 threshold for delineation since the topographic variability was small a single class slope was assumed within each subwatershed using these settings 122 hrus were defined for the watershed in highly urbanized watersheds facilities such as wastewater treatment plants can alter the natural streamflow regime hence their effects must be incorporated into the model in haw watershed there were 10 large facilities with average daily effluent larger than 0 1 mgd discharging into the streams these facilities were included in the models through adding point sources in swat at stream locations where they discharged their effluents their effluents were discharged into streams at related stream locations as average monthly flows another factor that can alter the natural streamflow regime in urban areas is the stormwater discharge into streams through pipes or conduits the urban stormwater collection systems and control measures were not included in the models as it was beyond the scope of this study this study was concentrated on aggregate responses of the developed areas at the subwatershed level in other words the model performance was evaluated probabilistically for stream locations that incorporate the aggregate effects of urban areas including point sources and urban stormwater runoff considering that we tried to define the subwatersheds such that each urban area falls within a subwatershed so that addition of stormwater in a diffuse manner or through a conduit or pipe has a minimal effect on the results two separate swat models were developed using arcswat 2012 usda ars 2014 the models were completely identical except for the runoff estimation method and precipitation time step one of the models was developed with daily precipitation and cn method using the soil moisture cn i and plant evapotranspiration cn ii and the other model was developed using the hourly precipitation and g a method for runoff simulation therefore three model setups were prepared for the analyses 2 6 probabilistic model assessment framework a probabilistic approach was used to assess the predictive skill and performance validity of competing model structures under varying land use conditions the bayesian based approach explicitly accounts for uncertainties from model parameterization climate input data i e precipitation model structure cn i cn ii or g a and measurement data i e daily streamflow the framework was developed in matlab the mathworks inc a markov chain monte carlo mcmc sampling scheme the dream method was used to sample the parameter space and derive the posterior distributions a statistically correct likelihood function which explicitly accounts for streamflow error heteroscedasticity and autocorrelation was employed to ensure the reliability of the search algorithm input data uncertainty was incorporated by using precipitation multipliers drawn from a gaussian distribution with an uncertain mean and standard deviation for each meteorological station inferences on posterior distributions of precipitation multipliers were obtained simultaneously along with swat model parameters finally bayesian model averaging bma was used to evaluate model structural uncertainty and to assess the predictive skill of the competing model structures similar frameworks have been developed in other studies e g ajami et al 2007 kavetski et al 2003 in which they used other mcmc algorithms such as shuffled complex evolution metropolis scem however employing the dream algorithm for conducting the mcmc within this total uncertainty estimation framework is novel more importantly application of such framework for probabilistic appraisal of different rainfall runoff methods within distributed hydrologic models has not been conducted to the best of our knowledge 2 6 1 model parameter uncertainty in a hydrologic model m streamflow is simulated q as a function of climatic inputs i e precipitation r and a vector of model parameters θ 6 q m r θ the simulated streamflow is subject to a variety of errors stemming from measured climate inputs model parameters and insufficiency of the model conceptualization model structural error the streamflow error residual then becomes 7 e r θ m q m r θ where q is the observed streamflow and e r θ m denotes the streamflow error residuals due to errors from observed precipitation model parameters and model structure applying the bayes theorem the parameter set θ is assigned posterior probability distribution p θ q which is proportional to the product of the parameter prior probability distribution p θ and a likelihood function l θ q the likelihood function assuming normally and independently distributed model residuals e with mean zero and variable standard deviation at each observation time step σ t can be expressed as vrugt 2016 8 l θ q σ t 1 n 1 2 π σ t 2 e x p 1 2 σ t 2 q t q t θ 2 where n is the number of time steps using a variable standard deviation at each observation time step σ t allows accounting for error heteroscedasticity which often exists in streamflow simulations however in most cases it is infeasible to determine σ at each time step due to lack of repeated streamflow measurements different approaches have been proposed to circumvent this issue some studies have used different transformations including natural log or box cox to stabilize σ and reduce heteroscedasticity sorooshian and dracup 1980 others have proposed alternative forms for the likelihood function schoups and vrugt 2010 in this study we applied a natural log transformation on measured and observed streamflow to reduce error heteroscedasticity often it is easier to maximize the logarithm of the likelihood function due to numerical stability and algebraic simplicity ajami et al 2007 vrugt 2016 hence the natural log of the likelihood function was adopted for optimization the streamflow error residuals are usually not independently distributed and in most cases temporal autocorrelation exists in the residuals specifically when errors are estimated at daily or smaller time steps a common approach to reduce the autocorrelation in model residuals is applying an auto regressive scheme on the error residuals sorooshian and dracup 1980 9 e t ρ e t 1 ν t where ρ is the lag serial correlation coefficient for the error residuals and ν t is a vector of random components ν t n 0 σ ν in this study we used a first order autoregressive transformation ar 1 applying the natural log and ar 1 ρ 1 the log likelihood function becomes vrugt 2016 10 l θ q σ ρ n 2 ln 2 π 1 2 ln σ ν 2 1 ρ 2 1 2 σ ν 2 1 ρ 2 e 1 2 t 2 n e t ρ e t 1 2 parameters ρ and σ are determined along with model parameters at each model realization during the mcmc sampling algorithm the parameters for the uncertainty analysis were selected based on experience and sensitivity analysis performed previously arabi et al 2007 arnold et al 2012 tasdighi et al 2017 table 2 lists the parameters selected for uncertainty analysis along with their ranges in this study uniform noninformative prior distributions were assumed for parameters within predefined ranges the same assumption has been used in many other hydrological modeling studies since prior knowledge of the model parameters is often not available and is case specific ajami et al 2007 the ranges for parameters were selected based on the swat user manual and experience from previous study tasdighi et al 2017 arnold et al 2012 2 6 2 model input uncertainty while uncertainty from model parametrization has been examined in many hydrologic modeling studies there are only a few cases where input uncertainty is explicitly accounted for kavetski et al 2003 ajami et al 2007 the majority of these studies incorporate input uncertainty by applying latent variables which are basically multipliers for precipitation events drawn randomly from a predefined distribution along with model parameters kavetski et al 2003 leta et al 2015 this approach can lead to dimensionality problems as the number of precipitation events increase in this study a method proposed by ajami et al 2007 is implemented to account for precipitation uncertainty using this method instead of iterating on each single multiplier the iteration is performed on the mean and standard deviation of a random gaussian distribution from which the multipliers are randomly drawn at each time step 11 r t ϕ t r t ϕ t n μ ϕ σ ϕ 2 where r t and r t are the corrected and observed precipitation depths respectively ϕ t is the random multiplier drawn from a normal distribution with a random mean μ ϕ μ ϕ 0 9 1 1 and variance σ ϕ 2 σ ϕ 2 1 e 5 1 e 3 ajami et al 2007 incorporating precipitation multipliers using this approach reduces the dimensionality issue 2 6 3 model structural uncertainty evaluation of model structural uncertainty has been investigated in hydrologic modeling raftery et al 2005 duan et al 2007 yen et al 2014 different methods have been proposed to account for model structural uncertainty hoeting et al 1999 georgakakos et al 2004 one such approach is the bayesian model averaging bma hoeting et al 1999 the bma is a probabilistic algorithm for combining competing models based on their predictive skills ajami et al 2007 madadgar and moradkhani 2014 in this study the three rainfall runoff model structures in swat m 1 c n i m 2 c n i i m 3 g a were used to explore the effects of model structural uncertainty under the bma theory the posterior distribution of the bma prediction q bma is 12 p q bma m 1 m 2 m 3 q i 1 3 p m i q p i q i m i q where p m i q is the posterior probability of the model m i this term can be assumed as a probabilistic weight w i for model m i in the bma prediction q bma the constraint for bma weights is i 1 3 w i 1 higher values of w i can be interpreted as higher predictive skill for a given model structure the model weights can be determined using different optimization techniques the expectation maximization em algorithm dempster et al 1977 is one such technique to estimate model weights used in several studies yen et al 2014 ajami et al 2007 in this study the em method was used to determine the model weights the brier scores were also employed to compare the performance of the three models while incorporating parameter and input data uncertainties the brier score bs is a measure of the accuracy of the prediction and has been frequently used in the probabilistic forecast analysis georgakakos et al 2004 bs is defined as 13 bs 1 n t 1 n f t o t 2 where n is the number of time steps in the record f t is estimated by the fraction of model simulations larger than the predefined streamflow threshold and o t is a binary value equal to 1 if the observation at time step t is larger than the predefined threshold and equal to zero in all other cases in this form eq 13 the lower the value of the bs the better the prediction skill of the model 2 6 4 the dream algorithm for mcmc analyses several bayesian algorithms are available which have been widely used for uncertainty assessment in hydrologic modeling including the generalized likelihood uncertainty estimation glue beven and binley 1992 the shuffled complex evolution metropolis scem ua vrugt et al 2003 and the differential evolution adaptive metropolis dream vrugt et al 2009 dream is a multi chain mcmc method that randomly samples the parameter space and automatically tunes the scale and orientation of the sampling distribution to move toward the target distribution by maximizing the value of the likelihood function the method has been used extensively for parameter estimation of complex environmental models vrugt 2016 the convergence of the algorithm can be monitored using the procedure proposed by gelman and rubin 1992 in this procedure a scale reduction score r is monitored to check whether each parameter has reached a stationary distribution gelman and rubin 1992 the common convergence criterion of r 1 2 was used in this study as well dream is specifically beneficial in the optimization of complex high dimensional problems in this study dream was employed to sample the parameter space and derive the posterior distributions 2 7 the strategy for assessment of model performances several criteria were used to assess the performance of the models including error statistics likelihood sse and ns determined based on simulated and observed hydrographs width of the band of uncertainty spread inclusion rate coverage determined based on the streamflow observations and 95 confidence interval of simulation ensembles flow duration curves along with bands of uncertainty brier scores and bma weights the value of utilizing multiple performance indicators is commonly recommended because it produces a more comprehensive evaluation of model performance legates and mccabe 1999 harmel et al 2010 for comparing the performance of the models in terms of error statistics and bma weights a two sample t test and kolmogorov smirnov were employed to test the significance of the difference between mean and distribution of the error statistics under each model respectively finally the water budget in the watershed was analyzed using the results obtained from different models at various locations 3 results and discussion 3 1 evaluation of model performances the purpose of this step of analyses was to monitor the variation of streamflow error statistics at different stream locations in the watershed during the training of the model at the watershed outlet using the bayesian total uncertainty analysis framework fig 2 illustrates the variation of error statistics at different stream locations it is important to note that the training of the models was performed only at the watershed outlet outlet 23 using the values of likelihood eq 10 as the objective function the performances of the three models were identical in terms of the likelihood function at the watershed outlet outlet 23 however cn i and cn ii models had a slightly although statistically significant better performance in terms of sse and ns t test p 0 01 the two sample kolmogorov smirnov test revealed that the distributions of error statistics e g ns under different models were different at 0 01 significance level at all locations at outlets 13 and 19 with mainly agricultural and forested land use cn models performed slightly better t test p 0 01 than the g a model in terms of sse and ns while cn i and cn ii had very close performance at different locations cn ii had a relatively better performance t test p 0 01 compared to cn i and g a in the highly forested subwatershed outlet 19 showing lower values of sse on average 8 and 11 lower than cni and g a respectively and higher values of ns on average 21 and 29 higher than cni and g a respectively this was foreseeable as with cn ii the curve number is determined based on plant evapotranspiration instead of soil moisture similar results were reported for better performance of the cn method over the g a in other agricultural watersheds kannan et al 2007 cheng et al 2016 in contrast comparing the performance of the cn and g a methods in an intensive agricultural watershed ficklin and zhang 2013 concluded that the g a model is more likely to generate better daily simulations it should be noted that these studies used a deterministic approach and none compared the performance of the cn and g a with regard to upstream land use variations in highly developed subwatersheds outlets 9 and 12 g a had a substantially and significantly t test p 0 01 better performance than the cn methods with all error statistics fig 2 this is an important result as it demonstrates that while trained at the outlet of the watershed the g a model had a much better performance in urbanized subwatersheds inside the watershed the better performance of the g a compared to cn methods in urban areas is investigated and discussed more in section 3 5 outlet 7 had an erratic behavior in terms of likelihood which can indicate fundamental deficiency of the models in simulating streamflow for that subwatershed 3 2 model parameter uncertainty the posterior cumulative distribution functions cdf of parameters for the three models are illustrated in fig 3 the posterior distributions were generated using 10 000 parameter sets sampled after the convergence of the mcmc algorithm it can be observed that using different rainfall runoff methods different posterior distributions were inferred for parameters in general most posterior parameter distributions showed some level of skewness which indicates deficiency in identifiability ajami et al 2007 while for most of the parameters the rainfall runoff methods determined the degree of the skewness for some parameters ch nii gw revap gwqmn and rchrg dp the skewness changed from positive to negative using different methods the cn i and cn ii resulted in similar posterior distributions for most parameters however for ch ki sol awc and sol k different distributions were inferred which conforms to intuition as cn i uses the soil water content for determining the curve number in runoff estimation parameter distributions that show great deviation from normality indicate some sort of deficiency in the combination of model structure input and training data an important observation in fig 3 was the lower values of surlag parameter sampled for the g a method surlag controls the surface runoff storage through the fraction of the total available water that will be allowed to enter the reach smaller values of surlag result in higher storage of water and delay in release of water to the reach looking at the posterior distribution of this parameter it can be observed that compared to cn methods smaller surlag values have been sampled for the g a method which can indicate simulation of a flashier hydrograph and higher peak flows by g a this was further investigated in section 3 5 these findings have important implications with regard to parameterization of swat when using different rainfall runoff mechanisms the majority of studies that have compared the performance of the rainfall runoff mechanisms within swat have used a deterministic approach for setting the model parameters using the cn or g a methods e g king et al 1999 ficklin and zhang 2013 the results obtained here suggest that this approach may mask the differences between the methods and result in misleading inferences regarding the performance of the models under the cn or g a methods 3 3 model input uncertainty precipitation multipliers were drawn from normal distributions with random mean and standard deviation sampled during each model run within the bayesian total uncertainty analysis framework fig 4 shows the cdf of the values of the mean μ ϕ sampled for input error models under different rainfall runoff mechanisms for the three climate stations since the posterior distributions of standard deviation σ ϕ for input error models were close to uniform they were excluded from the figure in general the mean of input error model under the g a method showed a distribution closer to normal with mean around one in contrast the cn methods produced posterior distribution skewed toward the higher bound especially at stations wban93783 and wban 93785 skewness toward the higher bound indicates the sampling algorithm s attempt to increase the magnitude of the precipitation events by using multipliers larger than one this can be explained by the structural deficiency of cn methods in simulating the peak streamflows which caused higher values of precipitation multipliers to be drawn to augment the runoff volume to capture the high flow events under these circumstances it can be hypothesized that the cn methods will lead to systematic overestimation of streamflow compared to g a assessed subsequently 3 4 model structural uncertainty bayesian model averaging was used at each model realization to combine the three rainfall runoff models bma weights were determined using em optimization method fig 5 shows the boxplots of bma weights at different subwatershed outlets mean of the weights and the weight for the optimized solution max likelihood are also marked on the boxplots the two sample kolmogorov smirnov test revealed that the distribution of bma weights for models were different at 0 01 significance level model performances in the agricultural and forested subwatersheds were relatively close in terms of bma weights it is evident that in the highly urbanized subwatersheds g a substantially and significantly based on the t test p 0 01 outperformed the cn methods however at the outlet of the watershed the cn methods showed a slightly but not significant better performance these results are in accordance with findings in section 3 1 where g a had a better performance in the subwatersheds with dominant urban land in terms of various error statistics in addition to bma brier scores were also employed to assess the skill of the models in streamflow simulation in original form eq 13 bs varies between 0 and 1 the lower the value of the bs the better the prediction skill of the model for illustration we used b s 1 b s to compare the performance of the models in fig 6 in this figure higher values of b s indicate better performance of the model at the outlet of the watershed the cn models showed a slightly better performance compared to the g a model specifically at low flow events with the agricultural and forested watershed the performances of the models were very close in terms of bs however at the highly urbanized subwatersheds the g a mechanism clearly outperformed the cn methods during low flow as well as high flow events resulting in higher values of b s these findings are also congruent with results from the bma and error statistics 3 5 streamflow prediction uncertainty hydrographs with bands of uncertainty have been used frequently for visual assessment of streamflow prediction uncertainty e g harmel et al 2010 while visual inspection of these graphs can provide useful information about the quality of simulation in cases where a relatively long record of streamflow is to be inspected this method can result in graphs that are difficult to read also hydrographs may not be very effective when comparing the predictive performance of several models specifically when bands of uncertainty are involved in this situation one has to either use a smaller time period or select some specific events for illustration of the hydrograph or use other measures for visualizing streamflow we therefore resorted to flow duration curves fdc to compare the performance of the models graphs of fdc along with bands of uncertainty provide an easily readable informative measure which can be used to assess the quality of streamflow prediction vogel and fennessey 1994 more importantly such graphs are much easier for comparing the predictive performance of the competing models it should be noted that fdcs can also be misleading since the serial structure and autocorrelation of the sequence of the streamflow record is removed in them vogel and fennessey 1994 bearing that in mind while we used fdcs to compare the predictive performance of the models the coverage percent of observations lying inside the 95 confidence interval of simulation ensembles and spread average width of the 95 confidence interval uncertainty band were determined based on hydrographs instead of fdcs since the performances of the models were similar in the smaller agricultural and forested subwatersheds outlets 7 13 and 19 they were excluded from further analysis the g a method resulted in wider bands of uncertainty wider spread and higher coverage rates compared to the cn methods table 3 during both training 2002 2008 and testing 2009 2012 periods except for outlet 23 during testing where cn ii resulted in higher spread at the outlet of the watershed outlet 23 the difference between the methods is small in terms of coverage and spread however at stations 9 and 12 urban dominant subwatersheds g a generated higher coverage rates compared to the cn models fig 7 shows the flow duration curves for the observed streamflow and 95 confidence interval bounds for the simulated streamflows for the three models at the three stream locations during the training period comparing the performance of the models at the outlet of the watershed the cn method produced narrower bands of uncertainty than the g a method however the g a model showed a slightly better performance in capturing the higher streamflow values in highly developed subwatersheds 9 and 12 the cn methods were unable to capture the high flow events also for medium low flow events the observations lay on the upper bound of the uncertainty band in contrast for the g a model the high flow events were mostly captured and the observations were near the center of the uncertainty band the better performance of the g a method in more developed areas was attributed to its better capacity in capturing the flashier behavior of the hydrographs due to quicker hydrologic responses in these areas the g a method was used with hourly precipitation data taking into account the effects of rainfall intensity since the hydrologic responses of urban areas areas with higher impervious surfaces and lower permeability tend to be flashier this consideration may significantly improve the model performance in particular the g a method outperformed the cn approaches in high intensity rainfall events this results in better performance of the g a in capturing the peak flows compared to the cn method which often caused high errors for the cn method in more developed subwatersheds similar results were obtained for the testing period fig 8 slightly narrower bands of uncertainty were determined during the testing period specifically at the watershed outlet outlet 23 table 4 presents the summary of different error statistics during training and testing periods minimum median and maximum values for various error statistics during the training and testing are provided in this table the better performance of the g a method compared to the cn in more developed subwatersheds can be observed in table 4 as well the assumptions of the likelihood function used were assessed using different diagnostics fig 9 homoscedasticity normality and autocorrelation of streamflow residuals at watershed outlet outlet 23 where model training is performed were assessed and illustrated in fig 9 the figure reveals that the ar 1 and log transformation were successful in fulfilling the assumptions of the likelihood function in terms of normality independence and homoscedasticity of residuals it can be observed that the g a method resulted in narrower normal distribution around zero for residuals 3 6 assessment of hydrologic budget and streamflow components the mean annual total water budget and components of streamflow for the three subwatersheds were quantified to gain insight into the differences among the hydrologic processes generating the outcomes fig 10 shows the cumulative bar plots for the overall water budget a c and more detailed components of streamflow e f the g a method generated lower water yield total amount of water contributing to streamflow and higher evapotranspiration et compared to the cn at all locations in all models et is the major component of water loss between 60 and 75 while about 10 15 and 20 25 of water turns into water yield for the g a and cn methods respectively the g a method predicted lower surface runoff sq and groundwater flow gwq contributing to streamflow compared to the cn method at all locations however it simulated higher lateral flow latq contribution to streamflow with cn i and cn ii about 35 of the water yield was derived from the lateral flow while in the g a method lateral flow contributed up to 75 of the streamflow other studies have shown higher baseflow contribution from the g a method compared to the cn bauwe et al 2016 kannan et al 2007 considering all components of subsurface flow the g a model infiltrated more precipitation more water in soil profile resulted in higher et for the g a model as well based on the results from multiple model performance criteria the g a performed better and hence was the more suitable method in the study watershed 4 conclusions swat has been used extensively in the literature for hydrologic simulations while the model has the capability to employ either cn or g a method for runoff estimation almost all studies have employed the cn method this may be partly due to lack of a rigorous comparison study to justify merits of using one method over the other along with simplicity of the cn method this study attempted to address this shortcoming regarding the extreme popularity of the swat model the findings of this study can shed light on selecting the rainfall runoff method within swat that can potentially lead to more realistic streamflow simulations in mixed land use watersheds in this study a bayesian total uncertainty assessment framework was implemented to compare the performance of the three runoff generation mechanisms within swat under different upstream land use conditions using the uncertainty assessment framework at the watershed outlet model performances was assessed at several stream locations inside the watershed at the watershed outlet and subwatersheds with dominant agricultural or forest land use the models with cn methods performed slightly better however at the two subwatersheds with highly developed land use models with g a method had a much better performance in simulating the streamflow the better performance of the g a method in more developed areas was attributed to its better capacity in capturing the flashier behavior of the hydrographs due to quicker hydrologic responses in these areas the g a method had a much better performance in simulating the peak flows in the more developed subwatersheds overall the streamflow prediction intervals from models with g a method covered more observations however they were slightly wider indicating higher uncertainty for streamflow prediction the cn models were unable to capture the high flow events specifically in developed subwatersheds posterior distribution of mean for gaussian distributions from which precipitation multipliers were randomly drawn were closer to normal using the hourly precipitation data and g a method while using daily precipitation with cn methods resulted in substantial negative skewness the deficiency of models with cn methods in simulating the peak streamflows caused higher values of precipitation multipliers to be sampled to augment the runoff volume the cn method simulated higher water yield volumes specifically at the urban dominated subwatersheds while g a method simulated higher et values the higher water yield volumes predicted by cn method in the highly urbanized subwatersheds can be explained by cn attempt to simulate the high flow events during the model training which results in overall overestimation of water yield the g a model resulted in lower surface runoff at all locations compared to the cn models however it simulated higher infiltration and subsurface flows the results of this study have important implications for determining which rainfall runoff method performs better in simulating the hydrologic regime the evaluation is specifically relevant for applying a distributed hydrologic model such as swat in a mixed land use watershed where model training will be performed only at the watershed outlet but the model is to be used for simulating hydrologic responses at different locations inside the watershed in summary the results suggest that in the haw watershed while trained at watershed outlet the swat model with g a method can potentially perform better in areas inside the watershed with higher percentage of developed land the swat models with cn methods proved to have similar or slightly better performance in areas with agriculture or forest dominant land use however care should be taken in applying such inferences as further studies in other watersheds with different physiographic characteristics are needed to generalize such findings it should also be noted that in highly urbanized areas the discharge of stormwater runoff through drainage pipes or conduits can disturb the natural streamflow regime in such watersheds including the discharge from conduits or pipes at the actual stream locations should improve the streamflow simulation acknowledgements this publication was made possible by usepa grant rd835570 its contents are solely the responsibility of the grantee and do not necessarily represent the official views of the usepa further usepa does not endorse the purchase of any commercial products or services mentioned in the publication the authors would like to thank the associate editor and reviewers for their insightful comments usda is an equal opportunity employer and provider 
7083,in predicting how droughts and hydrological cycles might change in a changing climate change of pan evaporation epan is one crucial element to be understood the derived partial differential pd form of the penpan equation is a prevailing attribution approach worldwide however small biases exist and the application of pd method is limited within the derivation of partial differential form of the equation which impede the attribution analysis in hydrology here we designed a series of numerical experiments by detrending each climatic variable i e an experimental detrending ed approach to attribute changes of epan over china we compared the attribution results using these two methods and further analyzed the plausible advantages of ed approach the comparison shows that both ed approach and pd method perform well in attributing changes of epan and to the input meteorological variables in china over 1960 2017 the first advantage of ed approach is that it can help make robust adjustment for the pd method in attribution analysis another advantage lies in its ability to attribute to the observed meteorological variables in china when the pd method fails to quantify the contribution of relative humidity and air temperature in net radiation in epan attribution analysis we highlight that the ed approach is recommended in attribution analysis for hydrologic research together with the adjusted pd method both methods can assist a better understanding and prediction of water energy cycles change in a changing climate keywords pan evaporation attribution the experimental detrending ed approach the partial differential pd method 1 introduction the long term change of atmospheric evaporative demand measured using pan evaporation epan is of special concern for understanding how droughts and more generally hydrologic cycle might change in a changing climate brutsaert and parlange 1998 roderick et al 2007 zhang et al 2017 observed decline in epan during the past half century known as the evaporation paradox brutsaert and parlange 1998 peterson 1995 promoted much research interest in attributing changes of epan worldwide see comprehensive reviews by roderick et al 2009a b mcvicar et al 2012 and more recently by wang et al 2017 in attributing changes of epan the correlation regression analysis nourani and fard 2012 vicente serrano et al 2014 has been used for its simplicity in investigating the relationship between the epan and meteorological forcings li et al 2014 however the significant correlation among input meteorological variables would result in considerable biases in attributing changes of epan using the correlation regression approaches whilst effective the correlation methods are not physically based and thus do not reveal causality roderick et al 2007 developed a partial differential hereafter denoted as pd form of the penpan model to attribute changes of epan with respect to meteorological variables the pd method has a simple and physically transparent form and hence has been widely used to quantify the changes of epan potential evaporation and etc donohue et al 2010 hobbins et al 2012 hobbins 2016 li et al 2013 liu and sun 2016 2017 roderick et al 2007 wang et al 2015 wang et al 2017 this pd method has been applied to some hydrological equations e g the penman type potential evaporation equation liu and mcvicar 2012 roderick et al 2007 and the simple budyko curve roderick and farquhar 2011 however small biases exist in the attributing results when using the pd method roderick et al 2007 hobbins et al 2012 li et al 2013 liu and sun 2017 and the application of pd method is limited with clear derivation of partial differential forms of the equations for more complicated models in hydrology and other fields for which one could not derive the partial differential forms a new approach becomes a helpful alternative this approach i e the experimental detrending ed approach was developed based on the detrending approach hamlet and lettenmaier 2007 mao et al 2015 has successfully attributed changes of the palmer droughts standard index pdsi to the meteorological variables including precipitation air temperature wind speed sunshine duration and relative humidity zhang et al 2016 which was beyond the ability of pd method in attribution analysis this indicates that the ed approach can be more widely applied in hydrology research in circumstances where both pd method and ed approach can be used in attribution analysis e g attributing changes of epan how would ed approach perform in comparison with the widely used pd method hence in this study we aim to design an experiment based detrending approach to attribute changes of epan over china using the most recent meteorological observations and to compare this ed approach with widely applied traditional pd method moreover we are motivated to 1 explore the possible advantages of ed approach and 2 reduce the biases of attribution results when using the traditional pd method in attributing changes of epan we present detailed description about both pd method and ed approach along with related data and other method description in section 2 and the comparison results in section 3 followed by discussion in section 4 and conclusions in section 5 2 data and method 2 1 data we collected the most recent daily meteorological data set and the radiation data set provided by the china meteorological data sharing service system http data cma cn containing 838 stations maximum distributed across china the four major meteorological variables air temperature ta wind speed at 2 m above ground level u2 sunshine duration sd and relative humidity rh cover the period of 1960 2017 the pan the diameter is 20 cm hereafter d20 evaporation records are mostly available for the period of 1960 2001 and records in some of the pans are available for 2002 2017 the radiation data set contains 130 sites and the incoming solar radiation is covering the period of 1960 2014 further temporal and spatial consistency control on data was applied based on the information like the length of the time series and spatial distribution of available meteorological data we chose 416 stations with monthly mean meteorological variables with more than 20 days per month from january 1960 to december 2017 entire time out of all 838 meteorological stations see fig 1 for the following comparison for the spatial inhomogeneity problems we selected grid boxes of 2 2 longitude by latitude with at least one selected meteorological station within or very much nearby as mask to avoid the possible interpolation influence cai et al 2010 2 2 the penpan model rotstayn et al 2006 coupled the aerodynamic component developed by thom et al 1981 with the radiative component of linacre 1994 and developed a penpan model based on the mass and energy balance of the pan evaporation the penpan model eq 1 can obtain well agreement with measured epan and has been well tested around the world li et al 2013 liu and sun 2016 roderick et al 2007 1 e pan e p r e p a δ δ a γ r n λ a γ δ a γ f q u 2 e s e a where epan is the pan evaporation rate in kg m2 s equivalent to mm s and δ in pa k is the slope of the curve created by plotting saturation vapor pressure against air temperature measured at 2 m above the ground γ pa k is the psychrometric constant rn in w m2 is the net available energy see the detailed calculation in section s1 in the supporting information and λ is the latent heat of vaporization in j kg es and ea are the saturate and actual vapor pressure pa respectively the parameter a 4 2 for chinese d20 pan is the ratio of effective surface area for heat and water vapor transfer the commonly used wind function f q u 2 1 39 10 8 1 1 35 u 2 in kg m2 s pa is derived and parameterized by thom et al 1981 however a large bias exists in the estimated epan when comparing with observed monthly d20 epan fig 2 a with root mean square error rmse of 38 83 mm month one possible explanation is that the wind function which is empirically derived for class a epan estimation is not suitable for d20 epan estimation as other parameters or constants are physically based rotstayn et al 2006 in the penpan model we used meteorological variables ta sd u2 and rh and the corresponding observed d20 epan in the wind function parameterization following thom s equation the calibrated wind function is as 2 f q u 2 3 977 10 8 1 0 505 u 2 improvement has been made with r2 improving to 0 92 and rmse decreasing to 26 03 mm month fig 2b hence the newly adjusted epan reasonably represents the d20 epan after using this calibrated wind function and can thus provide a more accurate basis for attributing changes of epan 2 3 the partial differential method roderick et al 2007 developed the pd approach to attribute changes of epan in australia soon afterwards it has been widely applied around the world hobbins et al 2012 li et al 2013 liu and sun 2016 prasch and sonnewald 2012 wang et al 2015 to explain the causes of the declining pan evaporation or potential evaporation changes of epan can be separated to the changes in the radiative component ep r and the aerodynamic component ep a i e 3 d e p a n p d dt d e p r dt d e p a dt to further attribute the changes of epan to the four key driving variables rn ea u2 and ta are used here the detailed decomposition of the first order ep r and ep a expressions are 4 d e p r dt e p r r n d r n dt e p r δ d δ d t a d t a dt 5 d e p a dt e p a u 2 d u 2 dt e p a e a d e a dt e p a t a d t a dt the effect of d t a d t on d e p a d t can be approximated as the sum of d δ d t a d t a d t and d e s d t a d t a d t in that changes in δ and es can be attributed solely to the changes to ta the contribution of ta in epan is from both ep r and ep a given by 6 e pan t a d t a dt e p r δ d δ d t a d t a dt e p a δ d δ d t a d t a dt e p a e s d e s d t a d t a dt in the above equations the linear trends e g d t a d t in eqs 4 6 are derived from the meteorological observations and the sensitivity expressions e g e p a n p d t a in eq 6 are estimated based on the monthly mean of related the meteorological variables besides the model parameters e g a γ and λ can be obtained from previous research li et al 2013 roderick et al 2007 with the derivation above the attribution results i e d e p a n p d d t are the sum of contributions of four meteorological variables and can be expressed as 7 d e p a n p d dt e p r r n d r n dt e pan t a d t a dt e p a u 2 d u 2 dt e p a e a d e a dt the attribution result d e p a n p d d t is then evaluated against the linear trend of observed epan i e d e pan d t at each station 2 4 the experimental detrending approach research on climate change is mainly focused on the trend of meteorological variables and thus their changes in a changing climate the detrending approach helps eliminate the long term trends in original meteorological variables so as to separate the roles of climate trend and its variability for a given variable hamlet and lettenmaier 2007 lan et al 2013 zhang et al 2016 improved this detrending approach and designed a series of numerical experiments to remove the trends of other independent variables and to retain only a single independent trend which still preserves the internal relation among the inputs and offers a reasonable separation of attribution results they have successfully attributed the trend of pdsi to the input variables which is beyond the ability of pd method hence this method called the experimental detrending ed approach here can be adopted as an alternative to attribute changes of epan first we need to generate the newly detrended data sets we calculated the monthly time series of rn based on sd rh and ta and ea based on rh and ta for each station please see detailed description in supporting information and used rn ta ea and u2 as inputs in the following process so that the attribution results are comparable with those using the pd method the linear trends of ta rn u2 and ea i e d t a d t drn d t d u 2 d t and d e a d t were calculated over 1960 2017 for each given station the pivotal year ipivot 1960 was chosen as the starting years upon which the linear trend was removed from the monthly time series in each station in detail the detrended dataset of ta was as 8 t a det r e n d i j t a observed i j k i i pivot where ta detrend i j is the detrended dataset of ta in year i 1960 1961 2017 and month j 1 2 12 and ta observed i j is historical observed monthly mean ta in the same time k is the linear trend of annual ta at each station since u2 rn and ea are generally bounded by 0 the detrending process of these three variables were based on eqs 9 and 10 9 f det r e n d i j f observed i j k i i pivot 10 f det r e n d i j f observed i j f det r e n d i f observed i where fdetrend i is the detrended annual mean time series of u2 rn and ea respectively in year i and fobserved i is historical forcings during the same time fdetrend i j is the detrended monthly forcing in year i and month j and fobserved i j is the corresponding historical variable after the trend in each station was removed from monthly data the original monthly datasets ta observed i j and fobserved i j were scaled to recreate the detrended monthly datasets while retaining the time series elements of the monthly variations within the year the inter and intra annual variability of the historical climate records are thus preserved since the detrended datasets are constructed through perturbing the historical time series with the linear trends then we form the annual time series of epan based on the newly generated detrended data sets step one we calculated the epan using the detrended monthly meteorological forcings i e ta detrend i j for ta and fdetrend i j for u2 rn and ea to form the base scenario of epan and denoted this epan as ebasecase for each station then the linear trend of ebasecase denoted as debasecase dt represents the trend of epan without the effect of climate change step two we released the trend of one climatic factor at a time e g for releasing the trend of ta we used ta observed i j for ta and fdetrend i j for u2 rn and ea to calculate epan denoted as edetrend ta the trend of edetrend ta represents the rate of change of epan with the warming effect only we released the trend of ta u2 rn and ea respectively and then the corresponding trend of epan denoted as dedetrend f dt and the subscript f is the meteorological forcing of ta u2 rn and ea respectively represents the rate of change of epan with the effect of increasing decreasing in ta u2 rn and ea in climate change scenarios respectively step three we got the difference between dedetrend f dt and debasecase dt using eq 11 then this difference can be seen as the contribution of that forcing cf for epan in each station the sum of the contribution of these four meteorological forcings eq 12 in each station is the attributed trend of epan based on ed approach denoted as d e p a n e d d t 11 c f d e detrend f d t d e basecase d t 12 d e p a n e d dt c t a c u 2 c rn c e a finally the attribution results d e p a n e d d t were then evaluated against the linear trend of observed epan d e pan d t in each station 2 5 the adjustment for the pd method the ebasecase plays an important role as control run in ed approach and represents the condition of epan that free from the impact of climate change the trend of ebasecase contains the contribution of some possible factors that are relevant but of minor importance except the effect of four major meteorological forcings rn u2 ta and ea it can lead to some bias when this part of influence on epan has not been well considered here we adopt the ebasecase from ed approach and make a simple adjustment for the pd method eq 13 in attributing changes of the epan 13 d e pan p d adj d t d e pan p d d t d e basecase d t where d e pan p d d t and d e pan p d adj d t are the attributed trends of epan using the traditional pd and the adjusted pd methods the d e basecase d t is the trend of base case of epan which can be seen as the rate change of epan due to all other possible factors except the contributions from 4 input meteorological variables in addition rmse is used to evaluate the performance of attributing changes of epan based on pd method and ed approach against its observed trend and n is the total amout of years involving in this evaluation 14 rmse i 1 n x i y i 2 n 3 results 3 1 attributing changes of e pan how does this ed approach perform in attributing change of epan when compared with the widely used pd method here we take the calculated epan and make comparison of the attributed trends of epan ep r and ep a y axis in fig 3 using these two attribution methods against the corresponding observed trends x axis in fig 3 for 416 sites over 1960 2017 overall both methods are robust in attributing changes of epan ep r and ep a with dots all very close to 1 1 line fig 3 showing that the ed approach performs well in attributing change of epan as well as that based on the pd method their averages of attributing results for 416 sites are close to the observed linear trends of epan depan dt of ep a dep r dt and of ep r dep a dt with slopes very approaching to 1 0 and r2 higher than 0 95 besides their rmse are very similar based on these two attribution methods to be specific the rmse is less than 0 43 mm yr2 when attributing change of epan over the period of 1960 2017 which accounts for a bias of approximately 25 when using these two methods the biases in ep a are relatively smaller with rmse of 0 30 mm yr2 based on ed approach against 0 27 mm yr2 when using pd method moreover the ed approach yields a small improvement in attributing change of ep r with rmse of only 0 14 mm yr2 which accounts for a bias of less than 20 when compared with that based on the pd method above all the ed approach performs well in attributing change of epan when compared with the widely used pd method 3 2 attributing to meteorological variables moreover the attribution of epan to the four meteorological variables are compared and presented in fig 4 the contribution of rn u2 ta and ea based on the pd method fig 4a1 d1 and the ed approach fig 4a2 d2 are spatially identical consistent with the conclusions on attribution of epan in section 3 1 while small differences exist in the attribution results between these two methods fig 4a3 4d3 discrepancy of around 0 0 1 mm yr2 is detected for the contribution of ta with maximum deficit of 0 94 mm yr2 in the northern part of china fig 4b3 less discrepancies are detected in the contribution of u2 and ea with averaged differences of approximately 0 1 mm yr2 and also in the contribution of rn with averaged difference of approximately 0 1 mm yr2 over the period of 1960 2017 hence the ed approach can be used in attributing change of epan to the input meteorological variables and their results are very similar to those based on the pd method 4 discussion as mentioned above one can conclude that the first advantage of ed approach is its wider application in attribution analysis in hydrology with complicated models involved e g attributing changes of pdsi zhang et al 2016 when the usage of pd method is limited within the derivation of partial differential form of the equation which impede the attribution analysis in hydrology to explore other possible advantages of this ed approach we conduct the following analysis 4 1 advantage better identification and quantification the change of epan has been attributed to rn ta ea and u2 in the above comparison however the ea is not obtained from observations estimated based on ta and rh please see details in section s1 in the supporting information in china though observed and more commonly used elsewhere around the world meanwhile the observation of rn is rather limited and is often obtained using observations of sd ta and rh please see details in section s1 in the supporting information instead therefore it can lead to some biases in the total contribution of some variables when attributing change of epan in each station besides it would offer more information when attributing to the observed meteorological variables hence we try to attribute change of epan to the observed meteorological variables i e sd rh u2 and ta for these 416 sites in china while using the traditional pd method in the attribution process it is difficult to decompose the contribution of rn into the contribution of sd rh and ta in that the extraterrestrial radiation eq 4 in supporting information is estimated and varied for each day of the year hence we use rn u2 ta and rh as inputs and re attribute change of epan to these four meteorological variables first and make comparison of their attribution results using the ed approach same procedure as section 2 4 but use rh instead of ea and the pd method to present the second advantage of ed approach the results are shown in fig 5 a overall both methods can well attribute changes of epan to the input variables of rn u2 ta and rh and the ed approach performs slightly better than the pd method with r2 a little bit higher 0 94 versus 0 93 and rmse relatively smaller 0 64 mm yr2 versus 0 69 mm yr2 for 416 sites over 1960 2017 fig 5a the discrepancies of the contribution of some variables are relatively small with largest difference of 0 13 mm yr2 in rh and difference of 0 09 mm yr2 in ta between ed approach and pd methods table 1 moreover one can concludefrom above comparisons sections 3 1 and 4 1 that the ability of these two methods would weaken a little bit with more complicated algorithm involved and the ed approach performs not worse than the pd method furthermore we use sd u2 ta and rh as input meteorological variables as they are all obtained from observations in china and conduct the attribution analysis based on the ed approach denoted as ed2 then we make comparison of this attribution results against those using rn u2 ta and rh as input meteorological variables denoted as ed and the results are shown in fig 5b the ed approach still performs well when using different input variables in attributing change of epan over 1960 2017 in china table 1 and fig 5b the rmse is 0 638 mm yr2 which is very similar to those when attributing to rn u2 ta and rh based on ed approach rmse 0 639 mm yr2 meanwhile the contribution of rh in ep r has been well detected with averaged contribution of 0 05 mm yr2 for these 416 sites although it is relatively small comparing with other variables it hits the maximum at 0 39 mm yr2 over the period of 1960 2017 meanwhile the contribution of ta in ep r would be more accurate in that the proportion of the contribution of ta in rn please see details in section s1 in the supporting information has been well quantified when using the ed2 approach while the proportions of the contribution of rh and ta are failed to identify and have been overlooked when using the pd method table 1 in attributing changes of epan therefore it can lead to some biases in the total contribution of rh and ta when attributing change of epan to the observed meteorological variables using the pd method 4 2 advantage robust adjustment for the pd method based on the calculation process another advantage of ed approach is the existence of the ebasecase which indicates the base state of epan and is directly related to the effect of all other possible factors except the four input meteorological variables the ebasecase works as the control run for the attribution analysis when using the ed approach then debasecase dt could be related to the bias of the attribution analysis for the pd method theoretically using ebasecase ebasecase r and ebasecase a respectively we adopt eq 13 to make adjustment for the pd method in attributing changes of epan ep r and ep a their attribution results using the pd and adjusted pd methods depan attribtued dt dep r attribtued dt and dep a attribtued dt in y axis against the observed linear trend of epan depan dt of ep r dep r dt and of ep a dep a dt for 416 sites over 1960 2017 are shown in fig 6 clear improvements have been made when using the adjusted pd method with r2 all higher than 0 99 in three components their rmse are much smaller reducing from the original 0 41 mm yr2 to 0 10 mm yr2 for epan from 0 16 mm yr2 to 0 04 mm yr2 for ep r and from 0 27 mm yr2 to 0 09 mm yr2 for ep a for 416 sites hence the adjusted pd method turns out to be effective and can help to improve the attribution results of epan moreover we can gain a better understanding of the rate of change of epan the effect of four input meteorological variables rn ea u2 and ta accounts for 91 of the total rate of change of epan while the rest 9 due to other possible factors though minor but relevant is unidentifiable using the traditional pd method but can be well identified and remedied by the adjusted pd method in attributing changes of epan an accurate estimation and usage of ebasecase is crucial for the ed approach and the pd method adjustment hence the third advantage of ed approach is that it can make robust adjustment for pd method and can help gain an in depth analysis of changes of epan and further provide a better way in understanding and prediction of water energy change in a changing climate 5 conclusion an accurate attribution analysis of epan is crucial and necessary to understand the evaporative demand and its changes in a changing climate the prevailing attribution approach partial differential pd method is usually applied to simple equations with a small bias in the attribution results hence we designed a series of numerical experiments by detrending each climatic variable i e an experimental detrending ed approach to provide another attribution approach and to make up that disadvantage of the pd method so as to better attribute change of epan first clear improvement can be made when using the newly calibrated wind function f q u 2 3 977 10 8 1 0 505 u 2 in the penpan model in chinese d20 epan estimation then the comparison of attribution results show that both ed approach and pd method perform well in attributing change of epan when using rn ea u2 and ta as input meteorological variables the first advantage of ed approach is its wider application in hydrology with complicated models involved he second advantage lies in its ability to attribute changes of epan to sd u2 ta and rh which are meteorological observations in china the ed approach can well identify and quantify the contribution of rh and ta in rn which have been overlooked when using the pd method the third advantage is the ebasecase in ed approach which works as control run can make robust adjustment for the traditional pd method the adjusted pd method turns out to be effective and provides a better understanding of the change of epan the contribution of four meteorological variables takes up 91 of the total rate of change of epan and can be well identified by the pd method leaving the rest 9 due to other possible factors unidentifiable but can be well identified and remedied by the adjusted pd method hence the ed approach is recommended for its superiority in cases when pd method is capable in attribution analysis as well as in cases with complicated hydrological models involved when the usage of pd method is limited within the derivation of partial differential form of the equation e g attributing of pdsi besides the ed approach can make robust adjustment for the pd method therefore both the ed approach and the adjusted pd method are recommended in attribution analysis in hydrology and hydrometeorology to gain a better understanding and prediction of water energy changes in a changing climate acknowledgements this research was supported by the national key research and development program of china 2016yfc0401401 and 2016yfa0602402 the key programs of the chinese academy of sciences zdrw zs 2017 3 1 the cas pioneer hundred talents program fubao sun an open research fund of state key laboratory of desert and oasis ecology in xinjiang institute of ecology and geography chinese academy of sciences cas the authors gratefully acknowledge the china meteorological data sharing service system administration http data cma cn for the data served here we also wish to thank the editor tim r mcvicar and associate editor sergio m vicente serrano and three anonymous reviewers for their invaluable comments and constructive suggestions to improve this manuscript appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 07 021 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
7083,in predicting how droughts and hydrological cycles might change in a changing climate change of pan evaporation epan is one crucial element to be understood the derived partial differential pd form of the penpan equation is a prevailing attribution approach worldwide however small biases exist and the application of pd method is limited within the derivation of partial differential form of the equation which impede the attribution analysis in hydrology here we designed a series of numerical experiments by detrending each climatic variable i e an experimental detrending ed approach to attribute changes of epan over china we compared the attribution results using these two methods and further analyzed the plausible advantages of ed approach the comparison shows that both ed approach and pd method perform well in attributing changes of epan and to the input meteorological variables in china over 1960 2017 the first advantage of ed approach is that it can help make robust adjustment for the pd method in attribution analysis another advantage lies in its ability to attribute to the observed meteorological variables in china when the pd method fails to quantify the contribution of relative humidity and air temperature in net radiation in epan attribution analysis we highlight that the ed approach is recommended in attribution analysis for hydrologic research together with the adjusted pd method both methods can assist a better understanding and prediction of water energy cycles change in a changing climate keywords pan evaporation attribution the experimental detrending ed approach the partial differential pd method 1 introduction the long term change of atmospheric evaporative demand measured using pan evaporation epan is of special concern for understanding how droughts and more generally hydrologic cycle might change in a changing climate brutsaert and parlange 1998 roderick et al 2007 zhang et al 2017 observed decline in epan during the past half century known as the evaporation paradox brutsaert and parlange 1998 peterson 1995 promoted much research interest in attributing changes of epan worldwide see comprehensive reviews by roderick et al 2009a b mcvicar et al 2012 and more recently by wang et al 2017 in attributing changes of epan the correlation regression analysis nourani and fard 2012 vicente serrano et al 2014 has been used for its simplicity in investigating the relationship between the epan and meteorological forcings li et al 2014 however the significant correlation among input meteorological variables would result in considerable biases in attributing changes of epan using the correlation regression approaches whilst effective the correlation methods are not physically based and thus do not reveal causality roderick et al 2007 developed a partial differential hereafter denoted as pd form of the penpan model to attribute changes of epan with respect to meteorological variables the pd method has a simple and physically transparent form and hence has been widely used to quantify the changes of epan potential evaporation and etc donohue et al 2010 hobbins et al 2012 hobbins 2016 li et al 2013 liu and sun 2016 2017 roderick et al 2007 wang et al 2015 wang et al 2017 this pd method has been applied to some hydrological equations e g the penman type potential evaporation equation liu and mcvicar 2012 roderick et al 2007 and the simple budyko curve roderick and farquhar 2011 however small biases exist in the attributing results when using the pd method roderick et al 2007 hobbins et al 2012 li et al 2013 liu and sun 2017 and the application of pd method is limited with clear derivation of partial differential forms of the equations for more complicated models in hydrology and other fields for which one could not derive the partial differential forms a new approach becomes a helpful alternative this approach i e the experimental detrending ed approach was developed based on the detrending approach hamlet and lettenmaier 2007 mao et al 2015 has successfully attributed changes of the palmer droughts standard index pdsi to the meteorological variables including precipitation air temperature wind speed sunshine duration and relative humidity zhang et al 2016 which was beyond the ability of pd method in attribution analysis this indicates that the ed approach can be more widely applied in hydrology research in circumstances where both pd method and ed approach can be used in attribution analysis e g attributing changes of epan how would ed approach perform in comparison with the widely used pd method hence in this study we aim to design an experiment based detrending approach to attribute changes of epan over china using the most recent meteorological observations and to compare this ed approach with widely applied traditional pd method moreover we are motivated to 1 explore the possible advantages of ed approach and 2 reduce the biases of attribution results when using the traditional pd method in attributing changes of epan we present detailed description about both pd method and ed approach along with related data and other method description in section 2 and the comparison results in section 3 followed by discussion in section 4 and conclusions in section 5 2 data and method 2 1 data we collected the most recent daily meteorological data set and the radiation data set provided by the china meteorological data sharing service system http data cma cn containing 838 stations maximum distributed across china the four major meteorological variables air temperature ta wind speed at 2 m above ground level u2 sunshine duration sd and relative humidity rh cover the period of 1960 2017 the pan the diameter is 20 cm hereafter d20 evaporation records are mostly available for the period of 1960 2001 and records in some of the pans are available for 2002 2017 the radiation data set contains 130 sites and the incoming solar radiation is covering the period of 1960 2014 further temporal and spatial consistency control on data was applied based on the information like the length of the time series and spatial distribution of available meteorological data we chose 416 stations with monthly mean meteorological variables with more than 20 days per month from january 1960 to december 2017 entire time out of all 838 meteorological stations see fig 1 for the following comparison for the spatial inhomogeneity problems we selected grid boxes of 2 2 longitude by latitude with at least one selected meteorological station within or very much nearby as mask to avoid the possible interpolation influence cai et al 2010 2 2 the penpan model rotstayn et al 2006 coupled the aerodynamic component developed by thom et al 1981 with the radiative component of linacre 1994 and developed a penpan model based on the mass and energy balance of the pan evaporation the penpan model eq 1 can obtain well agreement with measured epan and has been well tested around the world li et al 2013 liu and sun 2016 roderick et al 2007 1 e pan e p r e p a δ δ a γ r n λ a γ δ a γ f q u 2 e s e a where epan is the pan evaporation rate in kg m2 s equivalent to mm s and δ in pa k is the slope of the curve created by plotting saturation vapor pressure against air temperature measured at 2 m above the ground γ pa k is the psychrometric constant rn in w m2 is the net available energy see the detailed calculation in section s1 in the supporting information and λ is the latent heat of vaporization in j kg es and ea are the saturate and actual vapor pressure pa respectively the parameter a 4 2 for chinese d20 pan is the ratio of effective surface area for heat and water vapor transfer the commonly used wind function f q u 2 1 39 10 8 1 1 35 u 2 in kg m2 s pa is derived and parameterized by thom et al 1981 however a large bias exists in the estimated epan when comparing with observed monthly d20 epan fig 2 a with root mean square error rmse of 38 83 mm month one possible explanation is that the wind function which is empirically derived for class a epan estimation is not suitable for d20 epan estimation as other parameters or constants are physically based rotstayn et al 2006 in the penpan model we used meteorological variables ta sd u2 and rh and the corresponding observed d20 epan in the wind function parameterization following thom s equation the calibrated wind function is as 2 f q u 2 3 977 10 8 1 0 505 u 2 improvement has been made with r2 improving to 0 92 and rmse decreasing to 26 03 mm month fig 2b hence the newly adjusted epan reasonably represents the d20 epan after using this calibrated wind function and can thus provide a more accurate basis for attributing changes of epan 2 3 the partial differential method roderick et al 2007 developed the pd approach to attribute changes of epan in australia soon afterwards it has been widely applied around the world hobbins et al 2012 li et al 2013 liu and sun 2016 prasch and sonnewald 2012 wang et al 2015 to explain the causes of the declining pan evaporation or potential evaporation changes of epan can be separated to the changes in the radiative component ep r and the aerodynamic component ep a i e 3 d e p a n p d dt d e p r dt d e p a dt to further attribute the changes of epan to the four key driving variables rn ea u2 and ta are used here the detailed decomposition of the first order ep r and ep a expressions are 4 d e p r dt e p r r n d r n dt e p r δ d δ d t a d t a dt 5 d e p a dt e p a u 2 d u 2 dt e p a e a d e a dt e p a t a d t a dt the effect of d t a d t on d e p a d t can be approximated as the sum of d δ d t a d t a d t and d e s d t a d t a d t in that changes in δ and es can be attributed solely to the changes to ta the contribution of ta in epan is from both ep r and ep a given by 6 e pan t a d t a dt e p r δ d δ d t a d t a dt e p a δ d δ d t a d t a dt e p a e s d e s d t a d t a dt in the above equations the linear trends e g d t a d t in eqs 4 6 are derived from the meteorological observations and the sensitivity expressions e g e p a n p d t a in eq 6 are estimated based on the monthly mean of related the meteorological variables besides the model parameters e g a γ and λ can be obtained from previous research li et al 2013 roderick et al 2007 with the derivation above the attribution results i e d e p a n p d d t are the sum of contributions of four meteorological variables and can be expressed as 7 d e p a n p d dt e p r r n d r n dt e pan t a d t a dt e p a u 2 d u 2 dt e p a e a d e a dt the attribution result d e p a n p d d t is then evaluated against the linear trend of observed epan i e d e pan d t at each station 2 4 the experimental detrending approach research on climate change is mainly focused on the trend of meteorological variables and thus their changes in a changing climate the detrending approach helps eliminate the long term trends in original meteorological variables so as to separate the roles of climate trend and its variability for a given variable hamlet and lettenmaier 2007 lan et al 2013 zhang et al 2016 improved this detrending approach and designed a series of numerical experiments to remove the trends of other independent variables and to retain only a single independent trend which still preserves the internal relation among the inputs and offers a reasonable separation of attribution results they have successfully attributed the trend of pdsi to the input variables which is beyond the ability of pd method hence this method called the experimental detrending ed approach here can be adopted as an alternative to attribute changes of epan first we need to generate the newly detrended data sets we calculated the monthly time series of rn based on sd rh and ta and ea based on rh and ta for each station please see detailed description in supporting information and used rn ta ea and u2 as inputs in the following process so that the attribution results are comparable with those using the pd method the linear trends of ta rn u2 and ea i e d t a d t drn d t d u 2 d t and d e a d t were calculated over 1960 2017 for each given station the pivotal year ipivot 1960 was chosen as the starting years upon which the linear trend was removed from the monthly time series in each station in detail the detrended dataset of ta was as 8 t a det r e n d i j t a observed i j k i i pivot where ta detrend i j is the detrended dataset of ta in year i 1960 1961 2017 and month j 1 2 12 and ta observed i j is historical observed monthly mean ta in the same time k is the linear trend of annual ta at each station since u2 rn and ea are generally bounded by 0 the detrending process of these three variables were based on eqs 9 and 10 9 f det r e n d i j f observed i j k i i pivot 10 f det r e n d i j f observed i j f det r e n d i f observed i where fdetrend i is the detrended annual mean time series of u2 rn and ea respectively in year i and fobserved i is historical forcings during the same time fdetrend i j is the detrended monthly forcing in year i and month j and fobserved i j is the corresponding historical variable after the trend in each station was removed from monthly data the original monthly datasets ta observed i j and fobserved i j were scaled to recreate the detrended monthly datasets while retaining the time series elements of the monthly variations within the year the inter and intra annual variability of the historical climate records are thus preserved since the detrended datasets are constructed through perturbing the historical time series with the linear trends then we form the annual time series of epan based on the newly generated detrended data sets step one we calculated the epan using the detrended monthly meteorological forcings i e ta detrend i j for ta and fdetrend i j for u2 rn and ea to form the base scenario of epan and denoted this epan as ebasecase for each station then the linear trend of ebasecase denoted as debasecase dt represents the trend of epan without the effect of climate change step two we released the trend of one climatic factor at a time e g for releasing the trend of ta we used ta observed i j for ta and fdetrend i j for u2 rn and ea to calculate epan denoted as edetrend ta the trend of edetrend ta represents the rate of change of epan with the warming effect only we released the trend of ta u2 rn and ea respectively and then the corresponding trend of epan denoted as dedetrend f dt and the subscript f is the meteorological forcing of ta u2 rn and ea respectively represents the rate of change of epan with the effect of increasing decreasing in ta u2 rn and ea in climate change scenarios respectively step three we got the difference between dedetrend f dt and debasecase dt using eq 11 then this difference can be seen as the contribution of that forcing cf for epan in each station the sum of the contribution of these four meteorological forcings eq 12 in each station is the attributed trend of epan based on ed approach denoted as d e p a n e d d t 11 c f d e detrend f d t d e basecase d t 12 d e p a n e d dt c t a c u 2 c rn c e a finally the attribution results d e p a n e d d t were then evaluated against the linear trend of observed epan d e pan d t in each station 2 5 the adjustment for the pd method the ebasecase plays an important role as control run in ed approach and represents the condition of epan that free from the impact of climate change the trend of ebasecase contains the contribution of some possible factors that are relevant but of minor importance except the effect of four major meteorological forcings rn u2 ta and ea it can lead to some bias when this part of influence on epan has not been well considered here we adopt the ebasecase from ed approach and make a simple adjustment for the pd method eq 13 in attributing changes of the epan 13 d e pan p d adj d t d e pan p d d t d e basecase d t where d e pan p d d t and d e pan p d adj d t are the attributed trends of epan using the traditional pd and the adjusted pd methods the d e basecase d t is the trend of base case of epan which can be seen as the rate change of epan due to all other possible factors except the contributions from 4 input meteorological variables in addition rmse is used to evaluate the performance of attributing changes of epan based on pd method and ed approach against its observed trend and n is the total amout of years involving in this evaluation 14 rmse i 1 n x i y i 2 n 3 results 3 1 attributing changes of e pan how does this ed approach perform in attributing change of epan when compared with the widely used pd method here we take the calculated epan and make comparison of the attributed trends of epan ep r and ep a y axis in fig 3 using these two attribution methods against the corresponding observed trends x axis in fig 3 for 416 sites over 1960 2017 overall both methods are robust in attributing changes of epan ep r and ep a with dots all very close to 1 1 line fig 3 showing that the ed approach performs well in attributing change of epan as well as that based on the pd method their averages of attributing results for 416 sites are close to the observed linear trends of epan depan dt of ep a dep r dt and of ep r dep a dt with slopes very approaching to 1 0 and r2 higher than 0 95 besides their rmse are very similar based on these two attribution methods to be specific the rmse is less than 0 43 mm yr2 when attributing change of epan over the period of 1960 2017 which accounts for a bias of approximately 25 when using these two methods the biases in ep a are relatively smaller with rmse of 0 30 mm yr2 based on ed approach against 0 27 mm yr2 when using pd method moreover the ed approach yields a small improvement in attributing change of ep r with rmse of only 0 14 mm yr2 which accounts for a bias of less than 20 when compared with that based on the pd method above all the ed approach performs well in attributing change of epan when compared with the widely used pd method 3 2 attributing to meteorological variables moreover the attribution of epan to the four meteorological variables are compared and presented in fig 4 the contribution of rn u2 ta and ea based on the pd method fig 4a1 d1 and the ed approach fig 4a2 d2 are spatially identical consistent with the conclusions on attribution of epan in section 3 1 while small differences exist in the attribution results between these two methods fig 4a3 4d3 discrepancy of around 0 0 1 mm yr2 is detected for the contribution of ta with maximum deficit of 0 94 mm yr2 in the northern part of china fig 4b3 less discrepancies are detected in the contribution of u2 and ea with averaged differences of approximately 0 1 mm yr2 and also in the contribution of rn with averaged difference of approximately 0 1 mm yr2 over the period of 1960 2017 hence the ed approach can be used in attributing change of epan to the input meteorological variables and their results are very similar to those based on the pd method 4 discussion as mentioned above one can conclude that the first advantage of ed approach is its wider application in attribution analysis in hydrology with complicated models involved e g attributing changes of pdsi zhang et al 2016 when the usage of pd method is limited within the derivation of partial differential form of the equation which impede the attribution analysis in hydrology to explore other possible advantages of this ed approach we conduct the following analysis 4 1 advantage better identification and quantification the change of epan has been attributed to rn ta ea and u2 in the above comparison however the ea is not obtained from observations estimated based on ta and rh please see details in section s1 in the supporting information in china though observed and more commonly used elsewhere around the world meanwhile the observation of rn is rather limited and is often obtained using observations of sd ta and rh please see details in section s1 in the supporting information instead therefore it can lead to some biases in the total contribution of some variables when attributing change of epan in each station besides it would offer more information when attributing to the observed meteorological variables hence we try to attribute change of epan to the observed meteorological variables i e sd rh u2 and ta for these 416 sites in china while using the traditional pd method in the attribution process it is difficult to decompose the contribution of rn into the contribution of sd rh and ta in that the extraterrestrial radiation eq 4 in supporting information is estimated and varied for each day of the year hence we use rn u2 ta and rh as inputs and re attribute change of epan to these four meteorological variables first and make comparison of their attribution results using the ed approach same procedure as section 2 4 but use rh instead of ea and the pd method to present the second advantage of ed approach the results are shown in fig 5 a overall both methods can well attribute changes of epan to the input variables of rn u2 ta and rh and the ed approach performs slightly better than the pd method with r2 a little bit higher 0 94 versus 0 93 and rmse relatively smaller 0 64 mm yr2 versus 0 69 mm yr2 for 416 sites over 1960 2017 fig 5a the discrepancies of the contribution of some variables are relatively small with largest difference of 0 13 mm yr2 in rh and difference of 0 09 mm yr2 in ta between ed approach and pd methods table 1 moreover one can concludefrom above comparisons sections 3 1 and 4 1 that the ability of these two methods would weaken a little bit with more complicated algorithm involved and the ed approach performs not worse than the pd method furthermore we use sd u2 ta and rh as input meteorological variables as they are all obtained from observations in china and conduct the attribution analysis based on the ed approach denoted as ed2 then we make comparison of this attribution results against those using rn u2 ta and rh as input meteorological variables denoted as ed and the results are shown in fig 5b the ed approach still performs well when using different input variables in attributing change of epan over 1960 2017 in china table 1 and fig 5b the rmse is 0 638 mm yr2 which is very similar to those when attributing to rn u2 ta and rh based on ed approach rmse 0 639 mm yr2 meanwhile the contribution of rh in ep r has been well detected with averaged contribution of 0 05 mm yr2 for these 416 sites although it is relatively small comparing with other variables it hits the maximum at 0 39 mm yr2 over the period of 1960 2017 meanwhile the contribution of ta in ep r would be more accurate in that the proportion of the contribution of ta in rn please see details in section s1 in the supporting information has been well quantified when using the ed2 approach while the proportions of the contribution of rh and ta are failed to identify and have been overlooked when using the pd method table 1 in attributing changes of epan therefore it can lead to some biases in the total contribution of rh and ta when attributing change of epan to the observed meteorological variables using the pd method 4 2 advantage robust adjustment for the pd method based on the calculation process another advantage of ed approach is the existence of the ebasecase which indicates the base state of epan and is directly related to the effect of all other possible factors except the four input meteorological variables the ebasecase works as the control run for the attribution analysis when using the ed approach then debasecase dt could be related to the bias of the attribution analysis for the pd method theoretically using ebasecase ebasecase r and ebasecase a respectively we adopt eq 13 to make adjustment for the pd method in attributing changes of epan ep r and ep a their attribution results using the pd and adjusted pd methods depan attribtued dt dep r attribtued dt and dep a attribtued dt in y axis against the observed linear trend of epan depan dt of ep r dep r dt and of ep a dep a dt for 416 sites over 1960 2017 are shown in fig 6 clear improvements have been made when using the adjusted pd method with r2 all higher than 0 99 in three components their rmse are much smaller reducing from the original 0 41 mm yr2 to 0 10 mm yr2 for epan from 0 16 mm yr2 to 0 04 mm yr2 for ep r and from 0 27 mm yr2 to 0 09 mm yr2 for ep a for 416 sites hence the adjusted pd method turns out to be effective and can help to improve the attribution results of epan moreover we can gain a better understanding of the rate of change of epan the effect of four input meteorological variables rn ea u2 and ta accounts for 91 of the total rate of change of epan while the rest 9 due to other possible factors though minor but relevant is unidentifiable using the traditional pd method but can be well identified and remedied by the adjusted pd method in attributing changes of epan an accurate estimation and usage of ebasecase is crucial for the ed approach and the pd method adjustment hence the third advantage of ed approach is that it can make robust adjustment for pd method and can help gain an in depth analysis of changes of epan and further provide a better way in understanding and prediction of water energy change in a changing climate 5 conclusion an accurate attribution analysis of epan is crucial and necessary to understand the evaporative demand and its changes in a changing climate the prevailing attribution approach partial differential pd method is usually applied to simple equations with a small bias in the attribution results hence we designed a series of numerical experiments by detrending each climatic variable i e an experimental detrending ed approach to provide another attribution approach and to make up that disadvantage of the pd method so as to better attribute change of epan first clear improvement can be made when using the newly calibrated wind function f q u 2 3 977 10 8 1 0 505 u 2 in the penpan model in chinese d20 epan estimation then the comparison of attribution results show that both ed approach and pd method perform well in attributing change of epan when using rn ea u2 and ta as input meteorological variables the first advantage of ed approach is its wider application in hydrology with complicated models involved he second advantage lies in its ability to attribute changes of epan to sd u2 ta and rh which are meteorological observations in china the ed approach can well identify and quantify the contribution of rh and ta in rn which have been overlooked when using the pd method the third advantage is the ebasecase in ed approach which works as control run can make robust adjustment for the traditional pd method the adjusted pd method turns out to be effective and provides a better understanding of the change of epan the contribution of four meteorological variables takes up 91 of the total rate of change of epan and can be well identified by the pd method leaving the rest 9 due to other possible factors unidentifiable but can be well identified and remedied by the adjusted pd method hence the ed approach is recommended for its superiority in cases when pd method is capable in attribution analysis as well as in cases with complicated hydrological models involved when the usage of pd method is limited within the derivation of partial differential form of the equation e g attributing of pdsi besides the ed approach can make robust adjustment for the pd method therefore both the ed approach and the adjusted pd method are recommended in attribution analysis in hydrology and hydrometeorology to gain a better understanding and prediction of water energy changes in a changing climate acknowledgements this research was supported by the national key research and development program of china 2016yfc0401401 and 2016yfa0602402 the key programs of the chinese academy of sciences zdrw zs 2017 3 1 the cas pioneer hundred talents program fubao sun an open research fund of state key laboratory of desert and oasis ecology in xinjiang institute of ecology and geography chinese academy of sciences cas the authors gratefully acknowledge the china meteorological data sharing service system administration http data cma cn for the data served here we also wish to thank the editor tim r mcvicar and associate editor sergio m vicente serrano and three anonymous reviewers for their invaluable comments and constructive suggestions to improve this manuscript appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 07 021 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
7084,water quality networks usually do not include observations on a continuous timescale over a long period statistical models that use streamflow and mechanistic models that use meteorological information and land use are commonly employed to develop continuous streamflow and nutrient records given the availability of long meteorological records mechanistic models have the potential to develop continuous water quality records but such predictions suffer from systematic biases on both streamflow and water quality constituents this study proposes a multivariate bias correction technique based on canonical correlation analysis cca a dimension reduction technique based on multivariate multiple regression that reduces the bias in both streamflow and loadings simultaneously by preserving the cross correlation we compare the performance of cca with linear regression lr in removing the systematic bias from the swat model forced with precipitation and temperature for three selected watersheds from the southeastern us first we compare the performance of cca with lr in removing the bias in swat model outputs in predicting the observed streamflow and total nitrogen tn loadings from the water quality network wqn dataset we also evaluate the potential of cca in removing the bias in swat model predictions at daily and monthly time scales by considering the loadest model predicted loadings as the predictand for cca and lr evaluation of cca with the observed dataset and at daily and streamflow time scales shows that the proposed multivariate technique not only reduces the bias in the cross correlation between streamflow and loadings but also improves the joint probability of estimating observed streamflow and loadings potential implications of the proposed bias correction technique cca in water quality forecasting and management are also discussed keywords multivariate bias correction mechanistic models water quality modeling 1 introduction water quality measurements available over a continuous period are usually limited to watersheds that have implemented monitoring programs for tracking water quality impairments under the us clean water act of 1972 public law 92 500 cost and labor requirements limit these daily continuous observations to shorter time periods i e 1 2 years from the start time of impairment quilbé et al 2006 rao et al 2013 however studies focusing on the regional and long term variability of nutrient loadings to climate have been limited to smaller sample lengths and sparse sampling for interpreting and calibrating water quality models smith et al 1997 data sources having multi decadal observations such as the u s geological survey national stream water quality monitoring network wqn which includes 679 stations across the united states over the period 1962 1995 have scattered and non continuous water quality records alexander et al 1998 frequency of wqn sampling was determined by the type of water quality constituent for instance total nitrogen sampling typically ranged from 4 to 12 times per year budgetary constraints caused the sampling frequency to vary over the period with the majority of sites starting at monthly sampling and then dropping to bimonthly and eventually quarterly sampling starting in 1982 alexander et al 1998 load prediction models used for water quality management require long term measurements on the monthly and seasonal scale for model development hence efforts have focused on filling the data gaps in observations using both statistical and mechanistic models water quality modeling and predictions have been carried out using statistical based models aulenbach 2013 moyer et al 2012 oh and sankarasubramanian 2012 park and engel 2015 and studies have also used physically based mechanistic models for predicting water quality constituents amatya et al 2013 jha et al 2007 2010 shrestha et al 2008 statistical based models for estimating nutrient loadings like the loadest cohn 2005 cohn et al 1989 1992 and wrtds hirsch et al 2010 model use streamflow time and a seasonality component to predict nutrient loadings and develop continuous records over longer time periods the main challenge with this approach is that predictions are restricted to basins with gauged stations and to periods with observed streamflow thus making them not suited for predicting water quality in ungauged basins on the other hand mechanistic models such as the soil water assessment tool swat model douglas mankin et al 2010 use soil and land use information along with long term observed meteorological records to predict streamflow nutrient loadings and concentrations further impacts from changes in land use change anthropogenic forcings and management practices can be investigated using the mechanistic model douglas mankin et al 2010 one of the mechanistic models the swat model has been used widely in studies for streamflow prediction and forecasting ahl et al 2008 alansi et al 2009 and to understand the impacts of land use changes on streamflow and pollutant loadings marhaento et al 2017 serpa et al 2017 tong et al 2009 wang et al 2014 complex mechanistic models like swat are abstractions of actual physical processes that are difficult to represent hence such models can exhibit bias in predicting the observed variables even though these models reasonably capture the variability of observed streamflow and loadings if calibrated well model bias can be introduced from imperfect representations of complex natural processes as seen in gcm modeling of atmospheric physics or from using improper parameter conditions maraun 2016 the swat model has sub representations of actual physical processes that are difficult to represent specifically the nitrogen cycle which involves the formation and degradation of several nitrogen species given the complexity of such processes model bias can be introduced from model deficiencies in formula representation and or failure to adequately calibrate parameters in this study we will define bias as the systematic deviation between model and observed moments mean variance and cross correlation improving model calibration can greatly reduce model bias and is the most preferred from of bias correction but not the easiest ehret et al 2012 using time independent variables such as sparse or non continuous wqn records for calibrating models makes it difficult to identify if sources of bias result from model deficiencies or incorrect calibration thus the type of bias correction considered for this study is a post processing technique to reduce the deviation between the model and observed moments mean variances and cross correlation model predictions with systematic deviations from the observed streamflow and loadings should be corrected prior to application santhi et al 2001 under these situations for model applications univariate bias correction techniques using regressions are commonly employed for removing bias in streamflow stewart and reagan cirincione 1991 and loadings leisenring and moradkhani 2012 windolf et al 2011 studies examining the long term or future impacts of climate on streamflow and water quality also use forcings from general circulation models whose outputs need to be bias corrected precipitation and temperature before forcing them in the swat model in this context univariate and multi variate bias correction procedures have been applied for bias correction in climate forcings das bhowmik et al 2017 fang et al 2015 mazrooei et al 2015 wood et al 2004 on the other hand bias correction techniques for improving water quality predictions from mechanistic models like the swat model is very limited windolf et al 2011 the hydrological community using precipitation and temperatures from gcms have largely used bias correction as a pre process step to remove deviations prior to forcing the variables in prediction models prediction models using observed precipitation and temperature may use bias correction as a post process application to remove bias caused by model deficiencies maraun 2016 a common post processing technique for bias correction is to apply bias removing coefficients to model outputs in the form of a regression equation with a multiplicative coefficient representing the slope and an additive coefficient being an intercept based on regression stewart and reagan cirincione 1991 a thorough search for the cause of model bias should be done prior to using a post processing bias correction technique mechanistic models use internal variables that describe actual physical processes and identifying the parameters that introduce bias to predictions can be very helpful in understanding the modeling process incorrect use of bias correction types may result in the covering up of model deficiencies rather than actually reducing bias reichert and mieleitner 2009 in this study applying post process bias correction techniques to mechanistic model predictions is appropriate since identifying the cause of bias when using sparse non continuous variables is difficult most bias correction procedures are univariate with the regression relationship being developed separately between observed and model output for one variable at a time linear post processing has shown to be useful in reducing bias in the mean and variance of model predictions however reducing bias present in other moments may require further processes vannitsem 2011 das bhowmik 2016 showed that univariate bias correction techniques such as quantile mapping and linear regression do not preserve the cross correlation between the bias corrected variables to address this das bhowmik et al 2017 suggested multivariate bias correction based on asynchronous canonical correlation analysis acca for bias correcting both monthly precipitation and monthly temperature from gcms the term asynchronous indicates the gcms projections under climate change do not have time correspondence with the observed climatic variables another multivariate downscaling technique that is quite popular is the multivariate adaptive constructed analogues maca approach which provides spatially disaggregated time series of precipitation and temperature inside gcm simulations abatzoglou and brown 2012 hidalgo et al 2008 in the context of water quality predictions mechanistic models that predict both streamflow and nutrient loadings are strongly correlated and inherently exhibit bias with the observed attributes one could consider univariate bias correction procedures such as simple regression or quantile mapping for removing the bias in the estimation of loadings since streamflow and loadings are strongly dependent on each other it is important to perform bias correction that better preserves the cross correlation between the two variables thereby improving the joint likelihood of estimating observed streamflow and loadings in other words any efforts to bias correct them separately will result in underestimation of the cross correlation between streamflow and loadings this study provides a multivariate bias correction technique using canonical correlation analysis cca that simultaneously reduces the bias in streamflow and nutrient loadings while reducing the bias in estimating the cross correlation between the two variables the key differences of the proposed approach from the acca das bhowmik et al 2017 is that here cca is applied synchronously and as a post processing step keeping time correspondence between the swat model predictions and the observed variables is paramount since our interest is in improving monthly streamflow and water quality predictions this paper compares two bias correction techniques univariate regression and multivariate cca on their ability to reduce the bias in estimating the observed mean standard deviation of streamflow and loadings and also reduce the bias in the estimation of cross correlation between streamflow and loadings we also discuss how the reduced bias in the estimation of moments translate to improving the joint probability of estimating observed streamflow and loadings model values of predicted streamflow and total nitrogen loadings come from the calibrated swat model for three watersheds chosen across the southeastern u s the univariate and multivariate bias correction techniques are first evaluated at the daily time scale by comparing with the observed moments of streamflow and loadings from the wqn dataset further we also compare the two bias correction techniques at monthly time scale using the aggregated total nitrogen tn loadings estimated from the loadest model the ability of both bias correction techniques in preserving the joint probability of observed streamflow and loadings is also presented along with potential application of the multivariate techniques in streamflow and water quality forecasting the paper is organized as follows first a description of the data sources and swat model construction is presented which is followed by a discussion of two bias correction techniques next we evaluate the performance of two bias correction techniques by applying it for the wqn data and at daily and monthly time scales finally we summarize the findings along with potential applications of multivariate bias correction techniques for water quality forecasting 2 data sources this study considers three watersheds chosen from region 3 of the southern eastern united states seus fig 1 oh and sankarasubramanian 2012 considered 18 watersheds from the seus for seasonal nutrient forecasting using climate information these three watersheds were selected from the 18 watersheds based on the length of nutrient and streamflow observations this study was limited to just three basins across the southeast in varying basin size given the calibration and computation time of the swat model table 1 shows a summary of the total number of daily observations for nitrogen loadings for all three watersheds with each having less than 200 days extended over about 20 years further these watersheds are part of the usgs hydro climatic data network hcdn and the national stream water quality monitoring networks wqn alexander et al 1998 whose streamflow and water quality observations are minimally impacted by anthropogenic influences the hcdn is a subset of usgs streamgages that have been identified as watersheds where anthropogenic activities such as pumping and having artificial storage are minimal absent so that climate signal can be studied in streamflow slack et al 1993 vogel and sankarasubramanian 2005 the wqn is a combination of two networks the national stream quality accounting network nasqan with observations scattered from 1962 to 1995 and the hydrologic benchmark network hbn with observations scattered from 1973 to 1995 the framework proposed in this study can be applicable to all constituents but we limit our analyses of bias correction to only streamflow and total nitrogen loadings observed nitrogen loadings is calculated by multiplying the observed total nitrogen concentration from the wqn by the average streamflow on that day from usgs stream gages 2 1 performance measures the performance statistic used to quantify model performance is nash sutcliffe efficiency nse nash sutcliffe efficiency measures the squared deviations of the model value x i to the observed value x i with respect to the squared deviations of the observed values to the mean of the observations x as shown in eq 1 krause et al 2005 here the values could be for either streamflow or loadings nse describes how much of the observed variance is captured by the model values and ranges from negative infinity to one a nse value of 1 indicates that the model is perfect and capturing all of the observed variance while a nse value that tends towards less than and close to zero is considered a poor model santhi et al 2001 1 nse 1 i 1 n x i x i 2 i 1 n x i x 2 percent bias pbias is a term used in this paper to quantify the bias between the observed q o i and model values q m i eq 2 shows an example for calculating pbias of modeled streamflow from the swat model 2 pbias i 1 n q o i q m i i 1 n q o i 100 these two metrics were chosen based on their wide use in the swat modeling community and availability of satisfactory performance ratings for both streamflow and nutrient load moriasi et al 2007 2 2 total nitrogen loadings observed streamflow and total nitrogen concentration from the wqn records were used to calibrate the usgs s constituent load estimator loadest cohn 2005 cohn et al 1989 1992 to apply the proposed cca bias correction procedure at the daily time scale daily nitrogen loadings were estimated for the period 1951 2010 using the loadest model shown in eq 3 this model version was chosen from the 10 other predetermined models within the loadest program by using akaike information criterion aic akaike 1974 the selected loadest model is 3 ln l i α 1 α 2 ln q i α 3 sin 2 π d t i m e α 4 cos 2 π d t i m e ε i where l i is the observed daily total nitrogen loadings on day i q i is the observed daily streamflow on day i dtime is the centered decimal time α 1 α 4 are model estimated coefficients and ε i denotes the estimated model residual on day i 2 3 swat model estimates the watershed models were built in arcgis version 10 1 using arcswat version 2012 arnold and fohrer 2005 gassman et al 2007 delineation of the watersheds was done using the watershed delineator internal to arcswat using digital elevation data from the national elevation dataset ned using 1 3 arc second resolution usgs 2009 land cover information was obtained from the 2011 national land cover database and soil type information from the swat us soils database homer et al 2015 gridded 1 8th degree observed daily precipitation and temperature was used for the period 1949 2010 livneh et al 2013 total nitrogen loadings were calculated by summing outputs for organic nitrogen ammonia nitrite and nitrate and multiplying by the streamflow at the stream gage location the swat model was calibrated to maximize the nash sutcliffe efficiency nse in predicting observed monthly streamflow over the 60 year period 2 years were removed as a startup period by changing the following parameters initial scs runoff curve number for moisture condition ii cn2 available water capacity of first soil layer sol awc soil evaporation compensation factor epco and plant uptake compensation factor esco nse was chosen as the objective metric for calibration based on the suggested procedure for swat model calibration presented in santhi et al 2001 a summary of the hydrologic calibration performance in predicting monthly streamflow for the three watersheds is shown in table 2 all of the nse values are above 0 5 and all pearson s correlation squared ρ2 are above 0 6 nitrogen loadings from the swat model were calibrated using daily wqn observed loadings over the short time scale 200 days considering the simulation period 20 000 days is much longer than the observed time scale low performance in calibration was expected the following nitrogen related parameters were manipulated to improve the nse of loadings benthic p source rate coefficient rs3 organic n settling rate coefficient rs4 nitrogen uptake distribution n updis other parameters related to the nitrogen cycle where initially considered for manipulation but calibration runs showed that the nse of loadings was not sensitive to changes in the excluded variables furthermore if the parameters listed did not result in a noticeable difference 0 1 in nse performance after 30 iterations manual calibration was halted a summary of performance metrics for loadings calibration is shown in table 2 3 methodology univariate and multivariate bias correction methods 3 1 motivation daily streamflow is available over the entire modeling period hence performance evaluation with observed streamflow is quite possible however over the entire prediction period loadings performance values for nse were much lower compared to hydrologic calibration nse values as shown in table 2 pearson s correlation squared values turned out to be only slightly lower 0 2 in value for loadings calibration when compared to hydrologic calibration also shown in table 2 nse and ρ2 both approach a value of 1 for perfect model prediction but as the deviation between model and observed values increases the two values nse and ρ2 begin to vary in value krause et al 2005 considering that loadings calibration for the tar and escambia have moderate values for ρ2 0 4 but have poorer values for nse 0 2 suggests that there is considerable bias in model estimates this is also indicated by high values of percent bias pbias shown in table 2 based on this bias correction is needed to reduce the amount of bias present between the observed and swat model values since observed loadings are limited which restricts the period for bias correction daily loadings from loadest are considered when bias correcting the swat model over the entire simulation period the loadest model is able to capture more than 80 of the variability in observed loadings from the wqn data using eq 3 the nash sutcliffe efficiency nse for the loadest model in predicting the observed loadings is 0 91 for tar river 0 93 for ogeechee river and 0 81 for escambia river this study proposes a multivariate regression technique known as canonical correlation analysis cca that reduces the bias in streamflow and loadings prediction the performance of cca is first compared with a simple linear regression in reducing the bias as well as in preserving the cross correlation between observed streamflow and loadings from the wqn data then cca is used in reducing the bias in predicting daily streamflow and daily loadings over the entire period considering observed streamflow and loadest loadings estimates lastly bias is removed using cca from monthly streamflow and monthly loadings predictions considering observed monthly streamflow and monthly loadest estimates for the considered 60 year period 1951 2010 3 2 simple linear regression cca based bias corrected values of streamflow and loadings are compared with a simple linear regression lr approach for the wqn data using the same training and validation data used for developing cca approach eq 4 shows the form of the linear adjustment with β 0 denoting a constant β 1 denoting the slope of the observed to model fit and ε t the random error term these linear adjustment parameters are fit by minimizing the sum of squared residuals ε t between the model estimates and y obs linear regressions are done separately for streamflow and loadings 4 y obs t β 0 β 1 y swat t ε t the residuals of the fitted values must be approximately normal to satisfy the assumptions that a linear model is appropriate normality was checked by using the probability plot correlation coefficient ppcc vogel 1986 which calculates the correlation of the normality plot for the residuals the ppcc values for regressions on streamflow and loadings respectively for each watershed are tar river 0 90 0 93 ogeechee river 0 99 0 98 and escambia river 0 86 0 95 the high ppcc values indicate that the residuals are approximately normal 3 3 multivariate bias correction canonical correlation analysis cca is a regression based technique where multiple predictors swat model streamflow and loadings and multiple predictands observed streamflow and loadings are rotated in such a way to maximize the correlation between two linear combinations of the variables cca has been employed for bias correction of precipitation and temperature from gcm outputs das bhowmik et al 2017 it s been used in attributing the key sources in forecasting using gcms barnett and preisendorfer 1987 and also for identifying high correlated model fields for predicting precipitating anomalies tippett et al 2003 anytime you have multiple model values that are related like precipitation and temperature or streamflow and nutrient load and they have significant cross correlation it makes sense to bias correct them simultaneously however significant cross correlation is not a requirement for using cca it will simultaneously reduce individual bias amount the variates in this study we will be using cca as a multivariate regression to reduce the bias from swat model outputs cca rotates centered multivariate arrays of observations denoted y of streamflow and loadings from wqn data and the corresponding modeled values form swat denoted x and maximizes the correlation between the rotated x and y matrices both observed y and model predicted values x are first transformed into the log space to avoid negative values of discharge and loadings after bias correction the matrices will be of size n x p with n being the number of observations or estimations and p being the number of variables in this case p 2 canonical coefficients a b of size p x p are used to rotate the centered matrices x and y into orthogonal space shown in 5 and 6 matrix u corresponds to the variable x in rotated space and matrix v corresponds to the variable y in rotated space the canonical correlations r of size p x 1 relate the columns between rotated variables u and v for example r2 is the correlation between u2 and v2 the canonical correlations can then be used to relate the rotated model matrix u to the rotated observed matrix v as shown in 7 a process similarly done in das bhowmik et al 2017 with v representing the rotated model matrix related to the observed matrix afterwards v is rotated back to log space from orthogonal space using the b matrix shown in 8 the observed mean is added back in log space and then transformed back to normal space 5 u x μ x a 6 v y μ y b 7 v u r 8 x v i n v b cca is evaluated in a split sample validation approach by using a y matrix of observed monthly streamflow and monthly loadest estimates with an x matrix of swat monthly streamflow and loadings for a given month january february etc covering the entire period the first half of the data month 1 month 30 is used as training data set and the second half month 31 month 60 is used as a validation data set for example the training data set for the january cca model would include jan 1951 jan1980 and the validation data set would include jan 1981 jan 2010 the training data set denoted by subscript t is transformed into log space and centered using μt it is then rotated into orthogonal space into ut and vt matrices using canonical coefficients at bt canonical correlations rt relate ut and vt of the training data set the validation data set xv denoted by subscript v is log transformed centered and then rotated using its own means μv and canonical coefficients av bv shown in 9 then vv is produced for the validation set using uv and rt as shown in 10 using bt from the training data set vv can be rotated back to log space to x v using 11 finally the mean from the training data set μt is added back in log space to the validation set in 12 and transformed into normal space this process is repeated for each month of the year and is outlined in fig 2 9 u v x v μ x v a v 10 v v u v r t 11 x v v v i n v b t 12 x v x v μ x t the second canonical correlation r2 is much lower 0 3 than the first canonical correlation 0 8 across all three watersheds thus we decided to retain only the first rotated components of x and y for further analysis in this case the model and observed matrices are composed of streamflow and loadings with streamflow being the main driver of loadings the primary reason for the second canonical correlation being so low is because the first component explains most of the variance leaving little unexplained variance outside the first component the first component comes mainly from variance explained in streamflow for a more in depth explanation of canonical correlation analysis please see wilks 1995 3 4 comparison of bias correction techniques over different time scales this section first presents a general description of cca for application to the observed wqn period following that we discuss setting up of monthly and daily bias prediction models and provide how both models are evaluated under split sample validation at monthly and daily time scales the performance of the two techniques cca and simple regression described in section 3 2 is compared by their ability in preserving the cross correlation as well as in estimating the joint probability of the observed streamflow and observed loadest loadings 3 4 1 wqn data to begin with application of cca is first compared with simple regression for the observed wqn data i e 200 days to illustrate its utility in preserving the observed cross correlation from the wqn data since the wqn data consists of non consecutive days and has such a short sample length model validation was not performed for wqn data the performance of the simple regression and cca approach was evaluated in reducing the bias in the observed cross correlation between loadings and streamflow of the wqn data since the data length is short we did not perform any cross validation under wqn data we next compare the cca and simple regression for bias correcting daily and monthly predictions of streamflow and loadings from the swat model 3 4 2 bias correction of monthly swat predictions for bias correcting at monthly time scale a separate cca model for each calendar month was developed using the observed monthly streamflow and loadest estimated monthly loadings as y for bias correction for the 60 year period monthly loadings from the loadest model was obtained by aggregating the daily loadings estimated from daily streamflow for the 60 year period 1951 2010 separate bias correction models for each month is advantageous because calibration is done only using months that are experiencing the similar inter annual variability which should improve bias correction for example the cca model for january would have 60 monthly values one for each year over the entire period given we have 60 year length for each month we can also evaluate the monthly bias correction model under split sample validation with 30 years for model fitting and 30 years for validation this type of validation structure allows for application to a forecasting mode historical observations and simulations can train the bias correction model without knowledge of the future for use with forecasting simulations 3 4 3 bias correction of daily swat predictions given the data length is quite long with 60 years of daily predictions from the swat model a 30 day moving window is considered for bias correcting daily streamflow and loadings for training fig 3 for example to bias correct streamflow and loadings for jan 1 1990 denoted as the target day the training data set would include streamflow and loadings from december 17th to 31st 1989 and january 2nd to 16th 1990 cca techniques are trained over the 30 day moving window with the left out day being added in the validation dataset in this case the observed matrix y consists of daily streamflow and daily loadest estimates and the model matrix x consisting of daily swat streamflow and loadings the moving window approach dynamically changes the training data set to the previous and subsequent 15 days resulting in a 30 day training period for every day in the 60 year period the first and last 15 days of the period are thrown out for comparison canonical coefficients at bt and correlations rt are retained from the 30 day training data set after matrices xt and yt are centering and rotated to make ut and vt canonical correlations are used with rotated matrix from the validation data set uv over the last 30 years which includes model values from the 30 day window plus the target day resulting in a 31 day validation period to relate to the vv matrix and canonical coefficient bt is used to rotate to xv in a fashion shown in 11 lastly the mean from the training data set is added back to the validation data set the bias corrected value for streamflow and loadings only on the target day is kept and the process is repeated for each day over the entire period this process is outlined in fig 3 in this case we are using past and present information to bias correct respective to the day being corrected this structure would be appropriate for correcting long periods of historical simulations 3 5 comparing cross correlations fisher s z transformation test is used to determine whether the model bias corrected cross correlation between the loadings and nutrients is statistically equal to the observed cross correlation given that correlations do not follow normality for small sample sizes or population with high correlation fisher 1992 suggested a transformation of correlation shown in eq 14 that results in a normal distribution for hypothesis testing on correlation fisher 1992 the z transformation has a standard error shown in eq 15 with a sample length of n fisher 1992 since the z transformation follows a normal distribution we can use the standard normal z table to establish significance given two cross correlations we first find the difference in their respective z transformations and divide it by the standard error of the difference to create a standard normal z score z using eq 16 the variance of the difference in z transformations is the summation of reciprocals of the sample sizes n 3 in this study the sample lengths of the observed and models are equal so the variance just becomes 2 n 3 fisher 1992 taking the square root of the variance gives the standard error of the difference in z transformations and 16 becomes 17 a standard normal z score can be looked up using an alpha level of say 5 and compared to the z if z z α 2 then the difference between the two cross correlations are not significant 14 z 1 2 ln 1 ρ 1 ρ 15 σ z 1 n 3 16 z z obs z mod e l σ z obs z mod e l 17 z z obs z mod e l n 3 2 3 6 comparing joint likelihoods in addition to preserving cross correlation the performance of bias correction techniques was also evaluated for their ability in predicting the joint likelihood of streamflow and loadings using observed moments streamflow and water quality constituents have both been known to follow log normal distributions bowers et al 2012 van buren et al 1997 hence we assume the joint likelihood of streamflow and loadings follow a bivariate lognormal distribution denoted as mulitlog observed means of streamflow and loadings μ obs and the observed covariance matrix cov obs were used to estimate joint probabilities of observed streamflow and loadings in eq 18 likewise the joint probabilities of cca bias corrected values and lr bias corrected values were estimated using the observed moments based on eqs 19 and 20 respectively the joint probability using equation 18 is expected to be higher than the bias corrected streamflow and loadings given in eqs 19 and 20 18 q obs l obs multilog μ obs cov obs 19 q cca l cca multilog μ obs cov obs 20 q lr l lr multilog μ obs cov obs the estimated joint probabilities from the above three equations were compared based on box plots 4 results performance of bias correction techniques over different time scales 4 1 wqn data linear bias correction using the regression model was compared with cca bias correction by correcting daily swat model values only for days corresponding with wqn observations the nash sutcliffe efficiency nse of the bias corrected streamflow for both cca and linear regression is shown in fig 4 nse values for the raw swat model predictions are shown in the parentheses linear bias correction fig 4b shows better performance in improving the nse of swat discharge in predicting the observed discharge compared to the cca approach in two basins fig 4a cca bias correction shows a reduction in nse from the nse of the swat model in tar and escambia river basins while ogeechee river is showing a slight improvement going from 0 56 nse to 0 64 overall the absolute differences in nse between the raw swat values and cca bias corrected values for discharge are less than 0 1 bias correction of swat loadings using cca fig 5 a shows more improvement in nse values from raw swat loadings for both tar and escambia river in comparison to the performance of lr fig 5b in the case of ogeechee river cca bias corrected loadings performance nse 0 53 is slightly lower than the lr corrected values nse 0 68 fig 5 from the three watersheds ogeechee river was the best calibrated watershed in terms of loadings nse 0 66 and the worst calibrated watershed in terms of streamflow nse 0 56 yet after cca bias correction for ogeechee river basin performs the best for streamflow nse 0 64 and the worst in loadings nse 0 53 effectively cca being a multivariate multiple regression bias corrects both streamflow and loadings by trading off the explained variance in bias corrected streamflow and loadings cross correlation is better preserved under cca approach in comparison to using the lr approach correlation between the bias corrected streamflow and loadings using cca are all within 0 01 of the observed cross correlation for each watershed as shown in fig 6 using a fisher z transformation test at an alpha level of 5 reveals that the cross correlations of the cca corrected values are not significantly different than the observed specifically all the z values are below 1 96 with tar ogeechee and escambia river having scores of 0 97 1 03 and 0 36 respectively cross correlation of the raw swat model values from the ogeechee river watershed was initially ρ cross 0 93 which is not significantly different than the observed correlation being ρ cross 0 95 using a fisher z transformation however fig 6 shows that the cca correction method is still able to improve the cross correlation resulting in ρ cross 0 94 cross correlations of bias corrected values using lr did not improve from the raw model values as shown in fig 6 tar and ogeechee river both have high cross correlations 0 90 while escambia the largest watershed has a lower value of ρ cross 0 88 preserving the cross correlation during bias correction is important specifically for management periods 5 10 years where streamflow is understood to change over time in addition to better preserving the observed cross correlation cca also does a better job in predicting the joint likelihood of bias corrected streamflow and loadings given the observed moments each observation over the wqn period has an associated probability using the bivariate log normal distribution similarly the probability of cca and lr bias corrected values also have an associated probability for each day over the period the differences in observed probabilities to the probabilities from the raw swat model cca and lr for each day are shown as boxplots in fig 7 for all basins the mean of the cca boxplot shows to be centered very close to zero while lr and the raw swat model are shifted below zero suggesting that cca better preserves in predicting the joint likelihood of streamflow and loadings for the tar river and escambia river basins the difference in the observed standard deviation to the standard deviation of cca is 3 9 10 8 and 9 2 10 8 for lr indicating that cca captures the observed variability of the wqn data for the tar river basin cca is the preferred method over lr for predicting the mean and standard deviation of the observed joint likelihood for escambia river as well as shown in fig 7 estimates from the swat model where able to capture the mean and standard deviation relatively well before bias correction thus both cca and lr are not able to improve prediction of the joint likelihood beyond the model estimates 4 2 performance of bias correction techniques over daily and monthly time scales given the advantages in preserving the observed cross correlation and joint likelihood when using the cca approach for the observed wqn data lr was not compared for bias correcting daily and monthly values bias correction for the daily time scale for discharge and loadings using the moving window cca approach for the selected three watersheds was compared to the original raw swat model performance in fig 8 improvement from the raw swat performance with cca bias corrected nse values being larger than 0 6 fig 8a cca bias corrected performance shows an even larger increase in nse values for loadings shown in fig 8b with all the raw swat performance nse values being lower than 0 3 and bias corrected nse being all above 0 6 bias corrected streamflow performance for escambia river is nse 0 79 which is an improvement from the raw swat performance of nse 0 67 tar river basin nse 0 12 and ogeechee river basin nse 0 25 also improved the nse on the bias corrected streamflow shown in fig 8a considerable performance improvement is seen for bias corrected loadings with a nse value of 0 83 coming from a raw swat nse value of 0 29 in escambia river raw swat model performance in predicting loadest loadings at daily time scale was nse 0 23 but after cca nse improved to 0 84 ogeechee river did not exhibit any increase in performance for daily bias corrected loadings for cca in fact nse dropped by a value of 0 06 recall that for the daily timescale we are using daily loadest estimates for loadings in the y matrix of cca given that observed streamflow is a predictor in determining the loadest loadings estimates shown in 3 the observed cross correlation can be expected to be very high table 3 observed cross correlation between daily streamflow and daily loadest loadings are 0 99 which is close to 1 the upper limit of correlation for tar and escambia river cca is shown to perfectly preserve the observed cross correlation table 3 under extreme values of correlation which demonstrates the robust utility of cca since the entire daily bias corrected data set is too long to show in one window a hand picked 30 day window containing a high flow event in early march of 1998 is shown for examining advantages of cca fig 9 the nse performance over the full period is shown in the top left hand corners of the figure for reference fig 9 bias corrected loadings in fig 9 left from cca green line follow more closely with the loadest loadings blue line better than the raw swat model estimates red line likewise the bias corrected streamflow fig 9 right from the cca approach green follows more closely with the observed streamflow black line cca bias corrected values for both streamflow and loadings in fig 9 shows that are shifted away from the raw swat values red lines towards observed loadest values this 30 day window shows that the swat model over estimates the observed high flow event and underestimates the loadest loadings estimate for this case cca is able to reduce the overestimation in streamflow and underestimation in loadings considering the entire 60 year period cca is able to explain more observed variance than the raw swat model estimates shown by the nse terms in the upper left hand corner these two arguments illustrate the ability of cca to shift the magnitude and variability of model values towards observations since this cca bias correction technique for daily values uses local data points it is most suited for bias correcting predictions for continuous historical periods monthly bias correction using cca was conducted for every month of the year but discussion is summarized for only two months january and july with one from the winter season and another from the summer season for the tar river basin left column of fig 10 shows bias correction for loadings and the right column shows bias correction for streamflow in january top and in july bottom the red lines show the original raw swat simulations while the green lines show the cca bias corrected values in the loading plots fig 10 left monthly loadest values are shown as empty circles and in the streamflow plots fig 10 right the monthly observed means are shown as filled in black dots bias corrected loadings for both january and july show improvement from the raw swat performance which is reflected in the overall nse values with increases from 0 02 to 0 60 in the january and from 8 2 to 0 84 in july loadings from cca bias correction shifts from the raw swat values and towards the loadest values seen most prominently in january for the years 1994 and 1995 and for almost every year in july shown in fig 10 left streamflow also shows the same shift for cca bias corrected values moving away from swat values to observed monthly streamflow black dots for almost every january from the years 1981 2010 thus cca provides a better and robust methodology for bias correcting both streamflow and loadings from the swat model at daily and monthly time scales 5 discussion and concluding remarks modeling water quality constituents in mechanistic models is generally more difficult than streamflow modeling given the complex interactions between different constituents for instance total nitrogen concentration is the sum of organic ammonium nitrite and nitrate species all which have equations estimating their respective concentrations on a daily time scale thus the matrix of parameters determining total nitrogen estimates is very large and adjusting every possible parameter is time consuming and unwieldy further availability of limited and discontinuous records makes it hard to validate the predictions on the other hand calibrating and validating the swat model for streamflow is relatively easy and often results in nse values greater than 0 6 mainly due to the long observation period from usgs streamgages dating back before 1950 in addition capturing the observed variability in streamflow estimates comes mainly from the explained variability in precipitation inputs irrespective of the long record of streamflow it is always required to remove the systematic bias in the estimation of streamflow by the swat model using commonly available bias correction techniques koch and smillie 1986 given the vast literature on bias correcting the streamflow we suggest here a multivariate bias correction technique that removes bias in the estimation of observed moments of streamflow and loadings including the observed cross correlation between streamflow and loadings common bias correction techniques used in hydrological studies are univariate given that they aim to remove bias from streamflow alone these univariate techniques are commonly using simple linear regressions or quantile regressions that relate the probability of exceedence between the observed and model predicted values in studies where more than one variables are of interest in prediction multivariate techniques are more appropriate multivariate bias correction of precipitation and temperature by way of acca or macca has shown to be effective for using climate change projections the purpose of this paper was to propose a multivariate technique specifically cca for bias correcting streamflow and loadings simultaneously for improving water quality predictions this study has shown that the multivariate bias correction cca has potential in reducing individual variables biases from the swat model and also improves the bias in estimating the cross correlation between streamflow and loadings even with limited samples available from the wqn data observed variability is also better explained in terms of nse for bias corrected values in comparison to raw model estimates this partly stems from the reduced pbias for the bias corrected predictions to summarize cca bias correction is preferable to simple linear regression because the multivariate technique can preserve the observed cross correlation while univariate bias correction has limited ability in preserving the cross correlation the joint likelihood of estimating observed streamflow and loadings is also higher under cca compared to univariate technique using the moving window cca bias correction technique is also useful for extending daily records over long periods cca has also shown potential in reducing bias in moments including cross correlation at monthly time scale water quality models e g loadest that provide estimations of loadings also can offer estimations of concentrations to fill in sparse observations on the concentration side for this study we were mainly interested in bias correcting loadings and did not evaluate the performance of bias correction techniques in estimating tn concentration however plotting bias corrected loadings versus bias corrected streamflow for the observed wqn period can show how well the concentration was estimated fig 11 compares the performance of cca and lr in bias correcting swat model predicted loadings and streamflow for the selected three river basins from fig 11 we clearly see that the streamflow and loadings bias corrected by cca follow closely with the observed loadings and streamflow indicating better prediction of observed concentration a noticeable shift from the raw swat predictions could also be observed for both the cca and lr approach thus fig 11 shows that cca based bias correction improves the prediction of both streamflow and loadings resulting in overall improved estimates of predicted tn concentration this study recognizes that there is an inherent issue with calibrating and validating a water quality model given the infrequent and sparse observation data sets apart from using statistical models like loadest and wrtds for extending the data record this study uses a mechanistic model to develop continuous water quality records and also suggests a multivariate bias correction procedure that preserves the cross correlation structure between streamflow and loadings by considering the loadest estimations as the truth we evaluated the performance of the bias correction procedures at daily and monthly time scales for the three selected watersheds using loadest estimates as a surrogate in the observed matrix y have potential downfalls as the loadest estimates have errors associated with hence any application of bias correction techniques with loadest model as the truth should consider the performance of the loadest model oh and sankarasubramanian 2012 consider the r2 of loadest model and the tn forecasting model for potential application towards seasonal forecasting the primary advantage of using mechanistic model like swat with the proposed bias correction technique is in exploiting the long meteorological records to develop streamflow and loadings estimates for watersheds subjected to limited anthropogenic influence further bias correcting mechanistic model outputs could also provide streamflow and loadings under potential climate and land use changes improved bias correction techniques such as cca are especially useful for water quality modelers that provide improve joint probability of estimating observed streamflow and loadings our analyses over daily and monthly time scales has shown cca flexibility in preserving the cross correlation structure between streamflow and loadings bias correction on daily swat estimates is useful for monitoring downstream loadings from wastewater treatment plants that discharge loadings of effluents with different concentrations i e primary secondary and tertiary on a daily timescale the proposed bias correction framework can also be adapted for use in nutrient nitrogen or phosphorus loadings forecasting that could be used in management practices e g nutrient reduction plans to plan on the monthly timescale using climate forecasts the mechanistic or physical based models can be very useful for nutrient reduction plans by forecasting monthly to seasonal water quality incorporating monthly bias corrected streamflow and loadings is important for reservoir managers so that potential eutrophic conditions could be forecasted using climate forecasts forcing forecasted precipitation and temperature from climate models with the swat model one could obtain yield monthly forecasted loadings and streamflow for locations of interest bias correction can be done using hindcasted periods of streamflow and loadings as the training data set and used the retained coefficients and correlations to develop real time 1 3 month ahead streamflow and loadings forecasts i e 1 3 months ahead thus the demonstration of the multivariate bias correction approach based on cca can be useful in improving streamflow and water quality predictions at daily monthly and decadal time scales which have relevant applications from water quality management perspective acknowledgments we would like to thank the national science foundation for supporting this project under the carrer grant climate informed uncertainty analyses for integrated water resources sustainability no 0954405 
7084,water quality networks usually do not include observations on a continuous timescale over a long period statistical models that use streamflow and mechanistic models that use meteorological information and land use are commonly employed to develop continuous streamflow and nutrient records given the availability of long meteorological records mechanistic models have the potential to develop continuous water quality records but such predictions suffer from systematic biases on both streamflow and water quality constituents this study proposes a multivariate bias correction technique based on canonical correlation analysis cca a dimension reduction technique based on multivariate multiple regression that reduces the bias in both streamflow and loadings simultaneously by preserving the cross correlation we compare the performance of cca with linear regression lr in removing the systematic bias from the swat model forced with precipitation and temperature for three selected watersheds from the southeastern us first we compare the performance of cca with lr in removing the bias in swat model outputs in predicting the observed streamflow and total nitrogen tn loadings from the water quality network wqn dataset we also evaluate the potential of cca in removing the bias in swat model predictions at daily and monthly time scales by considering the loadest model predicted loadings as the predictand for cca and lr evaluation of cca with the observed dataset and at daily and streamflow time scales shows that the proposed multivariate technique not only reduces the bias in the cross correlation between streamflow and loadings but also improves the joint probability of estimating observed streamflow and loadings potential implications of the proposed bias correction technique cca in water quality forecasting and management are also discussed keywords multivariate bias correction mechanistic models water quality modeling 1 introduction water quality measurements available over a continuous period are usually limited to watersheds that have implemented monitoring programs for tracking water quality impairments under the us clean water act of 1972 public law 92 500 cost and labor requirements limit these daily continuous observations to shorter time periods i e 1 2 years from the start time of impairment quilbé et al 2006 rao et al 2013 however studies focusing on the regional and long term variability of nutrient loadings to climate have been limited to smaller sample lengths and sparse sampling for interpreting and calibrating water quality models smith et al 1997 data sources having multi decadal observations such as the u s geological survey national stream water quality monitoring network wqn which includes 679 stations across the united states over the period 1962 1995 have scattered and non continuous water quality records alexander et al 1998 frequency of wqn sampling was determined by the type of water quality constituent for instance total nitrogen sampling typically ranged from 4 to 12 times per year budgetary constraints caused the sampling frequency to vary over the period with the majority of sites starting at monthly sampling and then dropping to bimonthly and eventually quarterly sampling starting in 1982 alexander et al 1998 load prediction models used for water quality management require long term measurements on the monthly and seasonal scale for model development hence efforts have focused on filling the data gaps in observations using both statistical and mechanistic models water quality modeling and predictions have been carried out using statistical based models aulenbach 2013 moyer et al 2012 oh and sankarasubramanian 2012 park and engel 2015 and studies have also used physically based mechanistic models for predicting water quality constituents amatya et al 2013 jha et al 2007 2010 shrestha et al 2008 statistical based models for estimating nutrient loadings like the loadest cohn 2005 cohn et al 1989 1992 and wrtds hirsch et al 2010 model use streamflow time and a seasonality component to predict nutrient loadings and develop continuous records over longer time periods the main challenge with this approach is that predictions are restricted to basins with gauged stations and to periods with observed streamflow thus making them not suited for predicting water quality in ungauged basins on the other hand mechanistic models such as the soil water assessment tool swat model douglas mankin et al 2010 use soil and land use information along with long term observed meteorological records to predict streamflow nutrient loadings and concentrations further impacts from changes in land use change anthropogenic forcings and management practices can be investigated using the mechanistic model douglas mankin et al 2010 one of the mechanistic models the swat model has been used widely in studies for streamflow prediction and forecasting ahl et al 2008 alansi et al 2009 and to understand the impacts of land use changes on streamflow and pollutant loadings marhaento et al 2017 serpa et al 2017 tong et al 2009 wang et al 2014 complex mechanistic models like swat are abstractions of actual physical processes that are difficult to represent hence such models can exhibit bias in predicting the observed variables even though these models reasonably capture the variability of observed streamflow and loadings if calibrated well model bias can be introduced from imperfect representations of complex natural processes as seen in gcm modeling of atmospheric physics or from using improper parameter conditions maraun 2016 the swat model has sub representations of actual physical processes that are difficult to represent specifically the nitrogen cycle which involves the formation and degradation of several nitrogen species given the complexity of such processes model bias can be introduced from model deficiencies in formula representation and or failure to adequately calibrate parameters in this study we will define bias as the systematic deviation between model and observed moments mean variance and cross correlation improving model calibration can greatly reduce model bias and is the most preferred from of bias correction but not the easiest ehret et al 2012 using time independent variables such as sparse or non continuous wqn records for calibrating models makes it difficult to identify if sources of bias result from model deficiencies or incorrect calibration thus the type of bias correction considered for this study is a post processing technique to reduce the deviation between the model and observed moments mean variances and cross correlation model predictions with systematic deviations from the observed streamflow and loadings should be corrected prior to application santhi et al 2001 under these situations for model applications univariate bias correction techniques using regressions are commonly employed for removing bias in streamflow stewart and reagan cirincione 1991 and loadings leisenring and moradkhani 2012 windolf et al 2011 studies examining the long term or future impacts of climate on streamflow and water quality also use forcings from general circulation models whose outputs need to be bias corrected precipitation and temperature before forcing them in the swat model in this context univariate and multi variate bias correction procedures have been applied for bias correction in climate forcings das bhowmik et al 2017 fang et al 2015 mazrooei et al 2015 wood et al 2004 on the other hand bias correction techniques for improving water quality predictions from mechanistic models like the swat model is very limited windolf et al 2011 the hydrological community using precipitation and temperatures from gcms have largely used bias correction as a pre process step to remove deviations prior to forcing the variables in prediction models prediction models using observed precipitation and temperature may use bias correction as a post process application to remove bias caused by model deficiencies maraun 2016 a common post processing technique for bias correction is to apply bias removing coefficients to model outputs in the form of a regression equation with a multiplicative coefficient representing the slope and an additive coefficient being an intercept based on regression stewart and reagan cirincione 1991 a thorough search for the cause of model bias should be done prior to using a post processing bias correction technique mechanistic models use internal variables that describe actual physical processes and identifying the parameters that introduce bias to predictions can be very helpful in understanding the modeling process incorrect use of bias correction types may result in the covering up of model deficiencies rather than actually reducing bias reichert and mieleitner 2009 in this study applying post process bias correction techniques to mechanistic model predictions is appropriate since identifying the cause of bias when using sparse non continuous variables is difficult most bias correction procedures are univariate with the regression relationship being developed separately between observed and model output for one variable at a time linear post processing has shown to be useful in reducing bias in the mean and variance of model predictions however reducing bias present in other moments may require further processes vannitsem 2011 das bhowmik 2016 showed that univariate bias correction techniques such as quantile mapping and linear regression do not preserve the cross correlation between the bias corrected variables to address this das bhowmik et al 2017 suggested multivariate bias correction based on asynchronous canonical correlation analysis acca for bias correcting both monthly precipitation and monthly temperature from gcms the term asynchronous indicates the gcms projections under climate change do not have time correspondence with the observed climatic variables another multivariate downscaling technique that is quite popular is the multivariate adaptive constructed analogues maca approach which provides spatially disaggregated time series of precipitation and temperature inside gcm simulations abatzoglou and brown 2012 hidalgo et al 2008 in the context of water quality predictions mechanistic models that predict both streamflow and nutrient loadings are strongly correlated and inherently exhibit bias with the observed attributes one could consider univariate bias correction procedures such as simple regression or quantile mapping for removing the bias in the estimation of loadings since streamflow and loadings are strongly dependent on each other it is important to perform bias correction that better preserves the cross correlation between the two variables thereby improving the joint likelihood of estimating observed streamflow and loadings in other words any efforts to bias correct them separately will result in underestimation of the cross correlation between streamflow and loadings this study provides a multivariate bias correction technique using canonical correlation analysis cca that simultaneously reduces the bias in streamflow and nutrient loadings while reducing the bias in estimating the cross correlation between the two variables the key differences of the proposed approach from the acca das bhowmik et al 2017 is that here cca is applied synchronously and as a post processing step keeping time correspondence between the swat model predictions and the observed variables is paramount since our interest is in improving monthly streamflow and water quality predictions this paper compares two bias correction techniques univariate regression and multivariate cca on their ability to reduce the bias in estimating the observed mean standard deviation of streamflow and loadings and also reduce the bias in the estimation of cross correlation between streamflow and loadings we also discuss how the reduced bias in the estimation of moments translate to improving the joint probability of estimating observed streamflow and loadings model values of predicted streamflow and total nitrogen loadings come from the calibrated swat model for three watersheds chosen across the southeastern u s the univariate and multivariate bias correction techniques are first evaluated at the daily time scale by comparing with the observed moments of streamflow and loadings from the wqn dataset further we also compare the two bias correction techniques at monthly time scale using the aggregated total nitrogen tn loadings estimated from the loadest model the ability of both bias correction techniques in preserving the joint probability of observed streamflow and loadings is also presented along with potential application of the multivariate techniques in streamflow and water quality forecasting the paper is organized as follows first a description of the data sources and swat model construction is presented which is followed by a discussion of two bias correction techniques next we evaluate the performance of two bias correction techniques by applying it for the wqn data and at daily and monthly time scales finally we summarize the findings along with potential applications of multivariate bias correction techniques for water quality forecasting 2 data sources this study considers three watersheds chosen from region 3 of the southern eastern united states seus fig 1 oh and sankarasubramanian 2012 considered 18 watersheds from the seus for seasonal nutrient forecasting using climate information these three watersheds were selected from the 18 watersheds based on the length of nutrient and streamflow observations this study was limited to just three basins across the southeast in varying basin size given the calibration and computation time of the swat model table 1 shows a summary of the total number of daily observations for nitrogen loadings for all three watersheds with each having less than 200 days extended over about 20 years further these watersheds are part of the usgs hydro climatic data network hcdn and the national stream water quality monitoring networks wqn alexander et al 1998 whose streamflow and water quality observations are minimally impacted by anthropogenic influences the hcdn is a subset of usgs streamgages that have been identified as watersheds where anthropogenic activities such as pumping and having artificial storage are minimal absent so that climate signal can be studied in streamflow slack et al 1993 vogel and sankarasubramanian 2005 the wqn is a combination of two networks the national stream quality accounting network nasqan with observations scattered from 1962 to 1995 and the hydrologic benchmark network hbn with observations scattered from 1973 to 1995 the framework proposed in this study can be applicable to all constituents but we limit our analyses of bias correction to only streamflow and total nitrogen loadings observed nitrogen loadings is calculated by multiplying the observed total nitrogen concentration from the wqn by the average streamflow on that day from usgs stream gages 2 1 performance measures the performance statistic used to quantify model performance is nash sutcliffe efficiency nse nash sutcliffe efficiency measures the squared deviations of the model value x i to the observed value x i with respect to the squared deviations of the observed values to the mean of the observations x as shown in eq 1 krause et al 2005 here the values could be for either streamflow or loadings nse describes how much of the observed variance is captured by the model values and ranges from negative infinity to one a nse value of 1 indicates that the model is perfect and capturing all of the observed variance while a nse value that tends towards less than and close to zero is considered a poor model santhi et al 2001 1 nse 1 i 1 n x i x i 2 i 1 n x i x 2 percent bias pbias is a term used in this paper to quantify the bias between the observed q o i and model values q m i eq 2 shows an example for calculating pbias of modeled streamflow from the swat model 2 pbias i 1 n q o i q m i i 1 n q o i 100 these two metrics were chosen based on their wide use in the swat modeling community and availability of satisfactory performance ratings for both streamflow and nutrient load moriasi et al 2007 2 2 total nitrogen loadings observed streamflow and total nitrogen concentration from the wqn records were used to calibrate the usgs s constituent load estimator loadest cohn 2005 cohn et al 1989 1992 to apply the proposed cca bias correction procedure at the daily time scale daily nitrogen loadings were estimated for the period 1951 2010 using the loadest model shown in eq 3 this model version was chosen from the 10 other predetermined models within the loadest program by using akaike information criterion aic akaike 1974 the selected loadest model is 3 ln l i α 1 α 2 ln q i α 3 sin 2 π d t i m e α 4 cos 2 π d t i m e ε i where l i is the observed daily total nitrogen loadings on day i q i is the observed daily streamflow on day i dtime is the centered decimal time α 1 α 4 are model estimated coefficients and ε i denotes the estimated model residual on day i 2 3 swat model estimates the watershed models were built in arcgis version 10 1 using arcswat version 2012 arnold and fohrer 2005 gassman et al 2007 delineation of the watersheds was done using the watershed delineator internal to arcswat using digital elevation data from the national elevation dataset ned using 1 3 arc second resolution usgs 2009 land cover information was obtained from the 2011 national land cover database and soil type information from the swat us soils database homer et al 2015 gridded 1 8th degree observed daily precipitation and temperature was used for the period 1949 2010 livneh et al 2013 total nitrogen loadings were calculated by summing outputs for organic nitrogen ammonia nitrite and nitrate and multiplying by the streamflow at the stream gage location the swat model was calibrated to maximize the nash sutcliffe efficiency nse in predicting observed monthly streamflow over the 60 year period 2 years were removed as a startup period by changing the following parameters initial scs runoff curve number for moisture condition ii cn2 available water capacity of first soil layer sol awc soil evaporation compensation factor epco and plant uptake compensation factor esco nse was chosen as the objective metric for calibration based on the suggested procedure for swat model calibration presented in santhi et al 2001 a summary of the hydrologic calibration performance in predicting monthly streamflow for the three watersheds is shown in table 2 all of the nse values are above 0 5 and all pearson s correlation squared ρ2 are above 0 6 nitrogen loadings from the swat model were calibrated using daily wqn observed loadings over the short time scale 200 days considering the simulation period 20 000 days is much longer than the observed time scale low performance in calibration was expected the following nitrogen related parameters were manipulated to improve the nse of loadings benthic p source rate coefficient rs3 organic n settling rate coefficient rs4 nitrogen uptake distribution n updis other parameters related to the nitrogen cycle where initially considered for manipulation but calibration runs showed that the nse of loadings was not sensitive to changes in the excluded variables furthermore if the parameters listed did not result in a noticeable difference 0 1 in nse performance after 30 iterations manual calibration was halted a summary of performance metrics for loadings calibration is shown in table 2 3 methodology univariate and multivariate bias correction methods 3 1 motivation daily streamflow is available over the entire modeling period hence performance evaluation with observed streamflow is quite possible however over the entire prediction period loadings performance values for nse were much lower compared to hydrologic calibration nse values as shown in table 2 pearson s correlation squared values turned out to be only slightly lower 0 2 in value for loadings calibration when compared to hydrologic calibration also shown in table 2 nse and ρ2 both approach a value of 1 for perfect model prediction but as the deviation between model and observed values increases the two values nse and ρ2 begin to vary in value krause et al 2005 considering that loadings calibration for the tar and escambia have moderate values for ρ2 0 4 but have poorer values for nse 0 2 suggests that there is considerable bias in model estimates this is also indicated by high values of percent bias pbias shown in table 2 based on this bias correction is needed to reduce the amount of bias present between the observed and swat model values since observed loadings are limited which restricts the period for bias correction daily loadings from loadest are considered when bias correcting the swat model over the entire simulation period the loadest model is able to capture more than 80 of the variability in observed loadings from the wqn data using eq 3 the nash sutcliffe efficiency nse for the loadest model in predicting the observed loadings is 0 91 for tar river 0 93 for ogeechee river and 0 81 for escambia river this study proposes a multivariate regression technique known as canonical correlation analysis cca that reduces the bias in streamflow and loadings prediction the performance of cca is first compared with a simple linear regression in reducing the bias as well as in preserving the cross correlation between observed streamflow and loadings from the wqn data then cca is used in reducing the bias in predicting daily streamflow and daily loadings over the entire period considering observed streamflow and loadest loadings estimates lastly bias is removed using cca from monthly streamflow and monthly loadings predictions considering observed monthly streamflow and monthly loadest estimates for the considered 60 year period 1951 2010 3 2 simple linear regression cca based bias corrected values of streamflow and loadings are compared with a simple linear regression lr approach for the wqn data using the same training and validation data used for developing cca approach eq 4 shows the form of the linear adjustment with β 0 denoting a constant β 1 denoting the slope of the observed to model fit and ε t the random error term these linear adjustment parameters are fit by minimizing the sum of squared residuals ε t between the model estimates and y obs linear regressions are done separately for streamflow and loadings 4 y obs t β 0 β 1 y swat t ε t the residuals of the fitted values must be approximately normal to satisfy the assumptions that a linear model is appropriate normality was checked by using the probability plot correlation coefficient ppcc vogel 1986 which calculates the correlation of the normality plot for the residuals the ppcc values for regressions on streamflow and loadings respectively for each watershed are tar river 0 90 0 93 ogeechee river 0 99 0 98 and escambia river 0 86 0 95 the high ppcc values indicate that the residuals are approximately normal 3 3 multivariate bias correction canonical correlation analysis cca is a regression based technique where multiple predictors swat model streamflow and loadings and multiple predictands observed streamflow and loadings are rotated in such a way to maximize the correlation between two linear combinations of the variables cca has been employed for bias correction of precipitation and temperature from gcm outputs das bhowmik et al 2017 it s been used in attributing the key sources in forecasting using gcms barnett and preisendorfer 1987 and also for identifying high correlated model fields for predicting precipitating anomalies tippett et al 2003 anytime you have multiple model values that are related like precipitation and temperature or streamflow and nutrient load and they have significant cross correlation it makes sense to bias correct them simultaneously however significant cross correlation is not a requirement for using cca it will simultaneously reduce individual bias amount the variates in this study we will be using cca as a multivariate regression to reduce the bias from swat model outputs cca rotates centered multivariate arrays of observations denoted y of streamflow and loadings from wqn data and the corresponding modeled values form swat denoted x and maximizes the correlation between the rotated x and y matrices both observed y and model predicted values x are first transformed into the log space to avoid negative values of discharge and loadings after bias correction the matrices will be of size n x p with n being the number of observations or estimations and p being the number of variables in this case p 2 canonical coefficients a b of size p x p are used to rotate the centered matrices x and y into orthogonal space shown in 5 and 6 matrix u corresponds to the variable x in rotated space and matrix v corresponds to the variable y in rotated space the canonical correlations r of size p x 1 relate the columns between rotated variables u and v for example r2 is the correlation between u2 and v2 the canonical correlations can then be used to relate the rotated model matrix u to the rotated observed matrix v as shown in 7 a process similarly done in das bhowmik et al 2017 with v representing the rotated model matrix related to the observed matrix afterwards v is rotated back to log space from orthogonal space using the b matrix shown in 8 the observed mean is added back in log space and then transformed back to normal space 5 u x μ x a 6 v y μ y b 7 v u r 8 x v i n v b cca is evaluated in a split sample validation approach by using a y matrix of observed monthly streamflow and monthly loadest estimates with an x matrix of swat monthly streamflow and loadings for a given month january february etc covering the entire period the first half of the data month 1 month 30 is used as training data set and the second half month 31 month 60 is used as a validation data set for example the training data set for the january cca model would include jan 1951 jan1980 and the validation data set would include jan 1981 jan 2010 the training data set denoted by subscript t is transformed into log space and centered using μt it is then rotated into orthogonal space into ut and vt matrices using canonical coefficients at bt canonical correlations rt relate ut and vt of the training data set the validation data set xv denoted by subscript v is log transformed centered and then rotated using its own means μv and canonical coefficients av bv shown in 9 then vv is produced for the validation set using uv and rt as shown in 10 using bt from the training data set vv can be rotated back to log space to x v using 11 finally the mean from the training data set μt is added back in log space to the validation set in 12 and transformed into normal space this process is repeated for each month of the year and is outlined in fig 2 9 u v x v μ x v a v 10 v v u v r t 11 x v v v i n v b t 12 x v x v μ x t the second canonical correlation r2 is much lower 0 3 than the first canonical correlation 0 8 across all three watersheds thus we decided to retain only the first rotated components of x and y for further analysis in this case the model and observed matrices are composed of streamflow and loadings with streamflow being the main driver of loadings the primary reason for the second canonical correlation being so low is because the first component explains most of the variance leaving little unexplained variance outside the first component the first component comes mainly from variance explained in streamflow for a more in depth explanation of canonical correlation analysis please see wilks 1995 3 4 comparison of bias correction techniques over different time scales this section first presents a general description of cca for application to the observed wqn period following that we discuss setting up of monthly and daily bias prediction models and provide how both models are evaluated under split sample validation at monthly and daily time scales the performance of the two techniques cca and simple regression described in section 3 2 is compared by their ability in preserving the cross correlation as well as in estimating the joint probability of the observed streamflow and observed loadest loadings 3 4 1 wqn data to begin with application of cca is first compared with simple regression for the observed wqn data i e 200 days to illustrate its utility in preserving the observed cross correlation from the wqn data since the wqn data consists of non consecutive days and has such a short sample length model validation was not performed for wqn data the performance of the simple regression and cca approach was evaluated in reducing the bias in the observed cross correlation between loadings and streamflow of the wqn data since the data length is short we did not perform any cross validation under wqn data we next compare the cca and simple regression for bias correcting daily and monthly predictions of streamflow and loadings from the swat model 3 4 2 bias correction of monthly swat predictions for bias correcting at monthly time scale a separate cca model for each calendar month was developed using the observed monthly streamflow and loadest estimated monthly loadings as y for bias correction for the 60 year period monthly loadings from the loadest model was obtained by aggregating the daily loadings estimated from daily streamflow for the 60 year period 1951 2010 separate bias correction models for each month is advantageous because calibration is done only using months that are experiencing the similar inter annual variability which should improve bias correction for example the cca model for january would have 60 monthly values one for each year over the entire period given we have 60 year length for each month we can also evaluate the monthly bias correction model under split sample validation with 30 years for model fitting and 30 years for validation this type of validation structure allows for application to a forecasting mode historical observations and simulations can train the bias correction model without knowledge of the future for use with forecasting simulations 3 4 3 bias correction of daily swat predictions given the data length is quite long with 60 years of daily predictions from the swat model a 30 day moving window is considered for bias correcting daily streamflow and loadings for training fig 3 for example to bias correct streamflow and loadings for jan 1 1990 denoted as the target day the training data set would include streamflow and loadings from december 17th to 31st 1989 and january 2nd to 16th 1990 cca techniques are trained over the 30 day moving window with the left out day being added in the validation dataset in this case the observed matrix y consists of daily streamflow and daily loadest estimates and the model matrix x consisting of daily swat streamflow and loadings the moving window approach dynamically changes the training data set to the previous and subsequent 15 days resulting in a 30 day training period for every day in the 60 year period the first and last 15 days of the period are thrown out for comparison canonical coefficients at bt and correlations rt are retained from the 30 day training data set after matrices xt and yt are centering and rotated to make ut and vt canonical correlations are used with rotated matrix from the validation data set uv over the last 30 years which includes model values from the 30 day window plus the target day resulting in a 31 day validation period to relate to the vv matrix and canonical coefficient bt is used to rotate to xv in a fashion shown in 11 lastly the mean from the training data set is added back to the validation data set the bias corrected value for streamflow and loadings only on the target day is kept and the process is repeated for each day over the entire period this process is outlined in fig 3 in this case we are using past and present information to bias correct respective to the day being corrected this structure would be appropriate for correcting long periods of historical simulations 3 5 comparing cross correlations fisher s z transformation test is used to determine whether the model bias corrected cross correlation between the loadings and nutrients is statistically equal to the observed cross correlation given that correlations do not follow normality for small sample sizes or population with high correlation fisher 1992 suggested a transformation of correlation shown in eq 14 that results in a normal distribution for hypothesis testing on correlation fisher 1992 the z transformation has a standard error shown in eq 15 with a sample length of n fisher 1992 since the z transformation follows a normal distribution we can use the standard normal z table to establish significance given two cross correlations we first find the difference in their respective z transformations and divide it by the standard error of the difference to create a standard normal z score z using eq 16 the variance of the difference in z transformations is the summation of reciprocals of the sample sizes n 3 in this study the sample lengths of the observed and models are equal so the variance just becomes 2 n 3 fisher 1992 taking the square root of the variance gives the standard error of the difference in z transformations and 16 becomes 17 a standard normal z score can be looked up using an alpha level of say 5 and compared to the z if z z α 2 then the difference between the two cross correlations are not significant 14 z 1 2 ln 1 ρ 1 ρ 15 σ z 1 n 3 16 z z obs z mod e l σ z obs z mod e l 17 z z obs z mod e l n 3 2 3 6 comparing joint likelihoods in addition to preserving cross correlation the performance of bias correction techniques was also evaluated for their ability in predicting the joint likelihood of streamflow and loadings using observed moments streamflow and water quality constituents have both been known to follow log normal distributions bowers et al 2012 van buren et al 1997 hence we assume the joint likelihood of streamflow and loadings follow a bivariate lognormal distribution denoted as mulitlog observed means of streamflow and loadings μ obs and the observed covariance matrix cov obs were used to estimate joint probabilities of observed streamflow and loadings in eq 18 likewise the joint probabilities of cca bias corrected values and lr bias corrected values were estimated using the observed moments based on eqs 19 and 20 respectively the joint probability using equation 18 is expected to be higher than the bias corrected streamflow and loadings given in eqs 19 and 20 18 q obs l obs multilog μ obs cov obs 19 q cca l cca multilog μ obs cov obs 20 q lr l lr multilog μ obs cov obs the estimated joint probabilities from the above three equations were compared based on box plots 4 results performance of bias correction techniques over different time scales 4 1 wqn data linear bias correction using the regression model was compared with cca bias correction by correcting daily swat model values only for days corresponding with wqn observations the nash sutcliffe efficiency nse of the bias corrected streamflow for both cca and linear regression is shown in fig 4 nse values for the raw swat model predictions are shown in the parentheses linear bias correction fig 4b shows better performance in improving the nse of swat discharge in predicting the observed discharge compared to the cca approach in two basins fig 4a cca bias correction shows a reduction in nse from the nse of the swat model in tar and escambia river basins while ogeechee river is showing a slight improvement going from 0 56 nse to 0 64 overall the absolute differences in nse between the raw swat values and cca bias corrected values for discharge are less than 0 1 bias correction of swat loadings using cca fig 5 a shows more improvement in nse values from raw swat loadings for both tar and escambia river in comparison to the performance of lr fig 5b in the case of ogeechee river cca bias corrected loadings performance nse 0 53 is slightly lower than the lr corrected values nse 0 68 fig 5 from the three watersheds ogeechee river was the best calibrated watershed in terms of loadings nse 0 66 and the worst calibrated watershed in terms of streamflow nse 0 56 yet after cca bias correction for ogeechee river basin performs the best for streamflow nse 0 64 and the worst in loadings nse 0 53 effectively cca being a multivariate multiple regression bias corrects both streamflow and loadings by trading off the explained variance in bias corrected streamflow and loadings cross correlation is better preserved under cca approach in comparison to using the lr approach correlation between the bias corrected streamflow and loadings using cca are all within 0 01 of the observed cross correlation for each watershed as shown in fig 6 using a fisher z transformation test at an alpha level of 5 reveals that the cross correlations of the cca corrected values are not significantly different than the observed specifically all the z values are below 1 96 with tar ogeechee and escambia river having scores of 0 97 1 03 and 0 36 respectively cross correlation of the raw swat model values from the ogeechee river watershed was initially ρ cross 0 93 which is not significantly different than the observed correlation being ρ cross 0 95 using a fisher z transformation however fig 6 shows that the cca correction method is still able to improve the cross correlation resulting in ρ cross 0 94 cross correlations of bias corrected values using lr did not improve from the raw model values as shown in fig 6 tar and ogeechee river both have high cross correlations 0 90 while escambia the largest watershed has a lower value of ρ cross 0 88 preserving the cross correlation during bias correction is important specifically for management periods 5 10 years where streamflow is understood to change over time in addition to better preserving the observed cross correlation cca also does a better job in predicting the joint likelihood of bias corrected streamflow and loadings given the observed moments each observation over the wqn period has an associated probability using the bivariate log normal distribution similarly the probability of cca and lr bias corrected values also have an associated probability for each day over the period the differences in observed probabilities to the probabilities from the raw swat model cca and lr for each day are shown as boxplots in fig 7 for all basins the mean of the cca boxplot shows to be centered very close to zero while lr and the raw swat model are shifted below zero suggesting that cca better preserves in predicting the joint likelihood of streamflow and loadings for the tar river and escambia river basins the difference in the observed standard deviation to the standard deviation of cca is 3 9 10 8 and 9 2 10 8 for lr indicating that cca captures the observed variability of the wqn data for the tar river basin cca is the preferred method over lr for predicting the mean and standard deviation of the observed joint likelihood for escambia river as well as shown in fig 7 estimates from the swat model where able to capture the mean and standard deviation relatively well before bias correction thus both cca and lr are not able to improve prediction of the joint likelihood beyond the model estimates 4 2 performance of bias correction techniques over daily and monthly time scales given the advantages in preserving the observed cross correlation and joint likelihood when using the cca approach for the observed wqn data lr was not compared for bias correcting daily and monthly values bias correction for the daily time scale for discharge and loadings using the moving window cca approach for the selected three watersheds was compared to the original raw swat model performance in fig 8 improvement from the raw swat performance with cca bias corrected nse values being larger than 0 6 fig 8a cca bias corrected performance shows an even larger increase in nse values for loadings shown in fig 8b with all the raw swat performance nse values being lower than 0 3 and bias corrected nse being all above 0 6 bias corrected streamflow performance for escambia river is nse 0 79 which is an improvement from the raw swat performance of nse 0 67 tar river basin nse 0 12 and ogeechee river basin nse 0 25 also improved the nse on the bias corrected streamflow shown in fig 8a considerable performance improvement is seen for bias corrected loadings with a nse value of 0 83 coming from a raw swat nse value of 0 29 in escambia river raw swat model performance in predicting loadest loadings at daily time scale was nse 0 23 but after cca nse improved to 0 84 ogeechee river did not exhibit any increase in performance for daily bias corrected loadings for cca in fact nse dropped by a value of 0 06 recall that for the daily timescale we are using daily loadest estimates for loadings in the y matrix of cca given that observed streamflow is a predictor in determining the loadest loadings estimates shown in 3 the observed cross correlation can be expected to be very high table 3 observed cross correlation between daily streamflow and daily loadest loadings are 0 99 which is close to 1 the upper limit of correlation for tar and escambia river cca is shown to perfectly preserve the observed cross correlation table 3 under extreme values of correlation which demonstrates the robust utility of cca since the entire daily bias corrected data set is too long to show in one window a hand picked 30 day window containing a high flow event in early march of 1998 is shown for examining advantages of cca fig 9 the nse performance over the full period is shown in the top left hand corners of the figure for reference fig 9 bias corrected loadings in fig 9 left from cca green line follow more closely with the loadest loadings blue line better than the raw swat model estimates red line likewise the bias corrected streamflow fig 9 right from the cca approach green follows more closely with the observed streamflow black line cca bias corrected values for both streamflow and loadings in fig 9 shows that are shifted away from the raw swat values red lines towards observed loadest values this 30 day window shows that the swat model over estimates the observed high flow event and underestimates the loadest loadings estimate for this case cca is able to reduce the overestimation in streamflow and underestimation in loadings considering the entire 60 year period cca is able to explain more observed variance than the raw swat model estimates shown by the nse terms in the upper left hand corner these two arguments illustrate the ability of cca to shift the magnitude and variability of model values towards observations since this cca bias correction technique for daily values uses local data points it is most suited for bias correcting predictions for continuous historical periods monthly bias correction using cca was conducted for every month of the year but discussion is summarized for only two months january and july with one from the winter season and another from the summer season for the tar river basin left column of fig 10 shows bias correction for loadings and the right column shows bias correction for streamflow in january top and in july bottom the red lines show the original raw swat simulations while the green lines show the cca bias corrected values in the loading plots fig 10 left monthly loadest values are shown as empty circles and in the streamflow plots fig 10 right the monthly observed means are shown as filled in black dots bias corrected loadings for both january and july show improvement from the raw swat performance which is reflected in the overall nse values with increases from 0 02 to 0 60 in the january and from 8 2 to 0 84 in july loadings from cca bias correction shifts from the raw swat values and towards the loadest values seen most prominently in january for the years 1994 and 1995 and for almost every year in july shown in fig 10 left streamflow also shows the same shift for cca bias corrected values moving away from swat values to observed monthly streamflow black dots for almost every january from the years 1981 2010 thus cca provides a better and robust methodology for bias correcting both streamflow and loadings from the swat model at daily and monthly time scales 5 discussion and concluding remarks modeling water quality constituents in mechanistic models is generally more difficult than streamflow modeling given the complex interactions between different constituents for instance total nitrogen concentration is the sum of organic ammonium nitrite and nitrate species all which have equations estimating their respective concentrations on a daily time scale thus the matrix of parameters determining total nitrogen estimates is very large and adjusting every possible parameter is time consuming and unwieldy further availability of limited and discontinuous records makes it hard to validate the predictions on the other hand calibrating and validating the swat model for streamflow is relatively easy and often results in nse values greater than 0 6 mainly due to the long observation period from usgs streamgages dating back before 1950 in addition capturing the observed variability in streamflow estimates comes mainly from the explained variability in precipitation inputs irrespective of the long record of streamflow it is always required to remove the systematic bias in the estimation of streamflow by the swat model using commonly available bias correction techniques koch and smillie 1986 given the vast literature on bias correcting the streamflow we suggest here a multivariate bias correction technique that removes bias in the estimation of observed moments of streamflow and loadings including the observed cross correlation between streamflow and loadings common bias correction techniques used in hydrological studies are univariate given that they aim to remove bias from streamflow alone these univariate techniques are commonly using simple linear regressions or quantile regressions that relate the probability of exceedence between the observed and model predicted values in studies where more than one variables are of interest in prediction multivariate techniques are more appropriate multivariate bias correction of precipitation and temperature by way of acca or macca has shown to be effective for using climate change projections the purpose of this paper was to propose a multivariate technique specifically cca for bias correcting streamflow and loadings simultaneously for improving water quality predictions this study has shown that the multivariate bias correction cca has potential in reducing individual variables biases from the swat model and also improves the bias in estimating the cross correlation between streamflow and loadings even with limited samples available from the wqn data observed variability is also better explained in terms of nse for bias corrected values in comparison to raw model estimates this partly stems from the reduced pbias for the bias corrected predictions to summarize cca bias correction is preferable to simple linear regression because the multivariate technique can preserve the observed cross correlation while univariate bias correction has limited ability in preserving the cross correlation the joint likelihood of estimating observed streamflow and loadings is also higher under cca compared to univariate technique using the moving window cca bias correction technique is also useful for extending daily records over long periods cca has also shown potential in reducing bias in moments including cross correlation at monthly time scale water quality models e g loadest that provide estimations of loadings also can offer estimations of concentrations to fill in sparse observations on the concentration side for this study we were mainly interested in bias correcting loadings and did not evaluate the performance of bias correction techniques in estimating tn concentration however plotting bias corrected loadings versus bias corrected streamflow for the observed wqn period can show how well the concentration was estimated fig 11 compares the performance of cca and lr in bias correcting swat model predicted loadings and streamflow for the selected three river basins from fig 11 we clearly see that the streamflow and loadings bias corrected by cca follow closely with the observed loadings and streamflow indicating better prediction of observed concentration a noticeable shift from the raw swat predictions could also be observed for both the cca and lr approach thus fig 11 shows that cca based bias correction improves the prediction of both streamflow and loadings resulting in overall improved estimates of predicted tn concentration this study recognizes that there is an inherent issue with calibrating and validating a water quality model given the infrequent and sparse observation data sets apart from using statistical models like loadest and wrtds for extending the data record this study uses a mechanistic model to develop continuous water quality records and also suggests a multivariate bias correction procedure that preserves the cross correlation structure between streamflow and loadings by considering the loadest estimations as the truth we evaluated the performance of the bias correction procedures at daily and monthly time scales for the three selected watersheds using loadest estimates as a surrogate in the observed matrix y have potential downfalls as the loadest estimates have errors associated with hence any application of bias correction techniques with loadest model as the truth should consider the performance of the loadest model oh and sankarasubramanian 2012 consider the r2 of loadest model and the tn forecasting model for potential application towards seasonal forecasting the primary advantage of using mechanistic model like swat with the proposed bias correction technique is in exploiting the long meteorological records to develop streamflow and loadings estimates for watersheds subjected to limited anthropogenic influence further bias correcting mechanistic model outputs could also provide streamflow and loadings under potential climate and land use changes improved bias correction techniques such as cca are especially useful for water quality modelers that provide improve joint probability of estimating observed streamflow and loadings our analyses over daily and monthly time scales has shown cca flexibility in preserving the cross correlation structure between streamflow and loadings bias correction on daily swat estimates is useful for monitoring downstream loadings from wastewater treatment plants that discharge loadings of effluents with different concentrations i e primary secondary and tertiary on a daily timescale the proposed bias correction framework can also be adapted for use in nutrient nitrogen or phosphorus loadings forecasting that could be used in management practices e g nutrient reduction plans to plan on the monthly timescale using climate forecasts the mechanistic or physical based models can be very useful for nutrient reduction plans by forecasting monthly to seasonal water quality incorporating monthly bias corrected streamflow and loadings is important for reservoir managers so that potential eutrophic conditions could be forecasted using climate forecasts forcing forecasted precipitation and temperature from climate models with the swat model one could obtain yield monthly forecasted loadings and streamflow for locations of interest bias correction can be done using hindcasted periods of streamflow and loadings as the training data set and used the retained coefficients and correlations to develop real time 1 3 month ahead streamflow and loadings forecasts i e 1 3 months ahead thus the demonstration of the multivariate bias correction approach based on cca can be useful in improving streamflow and water quality predictions at daily monthly and decadal time scales which have relevant applications from water quality management perspective acknowledgments we would like to thank the national science foundation for supporting this project under the carrer grant climate informed uncertainty analyses for integrated water resources sustainability no 0954405 
