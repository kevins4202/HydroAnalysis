index,text
3670,debris flow in or towards water bodies and bed load transport in open channels manifest from the interaction of fluid with deformable granular media at varied spatiotemporal scales the present study aims to formulate a robust two dimensional coupled depth averaged framework for simulation of submarine deformation of non cohesive granular media and the corresponding effect on water and the otherwise the unified framework consisting of conditional hyperbolic set of partial differential equations has been conceptualized as two concurrent yet independent systems interacting through source sink terms comprising of drag force shear and water surface gradient the system is solved on a regular finite volume grid through a robust modification of the harten lax van leer hll scheme the interaction terms are embedded into the interfacial fluxes where additional closure employs the effect of dry wet zone transition and flow arrest for both modules various aspects of the proposed framework are validated against an array of test cases ranging from landslide induced tsunami to dambreak induced scour the last representative scenario emphasizes the potential applicability of the model for real time extension to field scale problems a few one dimensional approximations are explored in the appendix to calculate relative velocity between interstitial fluid and granular media for computation of drag force keywords depth averaged granular flow augmented hll swes 1 introduction the movement of granular mass over unstable slopes towards water bodies such as lakes reservoirs and oceans has been a constant topic of interest for geosciences the collapse of submerged granular masses has far reaching consequences in terms of rapid water surface movements leading to devastating flood waves or tsunamis these landslides are broadly classified into three categories aerial sub aerial and submarine based on the submergence of the failure a rapidly moving or fluctuating water front may trigger the motion of bed material through the fluid pressure gradient and the bed shear as shown experimentally in spinewine 2005 and numerically in pahar and dhar 2017 the mathematical modeling of such complex phenomena requires the precise coupling of the fluid and solid phases which involves a varied range of both length and time scales such as an instant landslide into a water body zhao and shan 2013 to slow progression of a meandering river fraccarollo and toro 1995 in the past few decades several studies have attempted to model the extent of the failure and the flow rate by combining fluid and granular phases in numerous ways delannay et al 2017 ideally a three dimensional continuum model coupled with a discrete granular framework kafui et al 2002 natsui et al 2012 is a prudent choice to clearly describe the complex phenomena however its applicability is restricted to small scale experiments due to the sheer computational overhead zhao and shan 2013 shan and zhao 2014 granular media has also been modeled through a non newtonian assumption with various rheological approximations jop et al 2006 forterre and pouliquen 2008 lagrée et al 2011 chauchat 2014 three dimensional eulerian models require various techniques e g volume of fluid level set method for identification of free surface interface li et al 1999 which in turn amplifies the computational burden to alleviate the use of such special treatments lagrangian methods such as smoothed particle hydrodynamics moving particle semi implicit methods have recently been deployed to simulate landslide and resulting tsunami tan and chen 2017 yeylaghi et al 2017 jafari nodoushan et al 2018 however their usage is limited due to inherent complexities involved in computational expense originating mainly from particle searching algorithms consequently depth averaged models have been employed almost routinely in such cases owing to the scale of the problem fernández nieto et al 2008 yavari ramshe and ataie ashtiani 2016 submerged failure is frequently modeled as a mixture of debris and the interstitial fluid chauchat and médale 2010 these mixture models consider a unified behavior of granular mass and the interstitial flow with no relative velocity consideration between both the modules yavari ramshe et al 2015 li et al 2019 depth averaging of granular failure is performed based on the premise that the longitudinal extent of such flows is considerably large as compared to the vertical dimension the pioneering work of savage and hutter 1989 conceptualized a depth integrated granular model through an assumption of lithostatic pressure and constant bed friction coefficient their approach has been extended by numerous researchers to model different stages of granular movements along steep slopes gray and edwards 2014 baker et al 2016 viroulet et al 2017 xia and liang 2018 edwards et al 2021 a comprehensive review of various depth averaged debris flow models has been presented in pitman and le 2005 mcdougall 2017 thouret et al 2020 and peruzzetto et al 2021 the depth averaging makes the computation of the interstitial fluid velocity a challenge this has often led to the mixture models altogether neglecting the interstitial flow and consequently the drag force yavari ramshe et al 2015 neglecting the drag force may lead to a nonphysical parameter estimation such as an unreasonably high manning s coefficient 0 8 for a smooth glass bed ferreiro ferreiro et al 2020 the hysea model macías et al 2020 makes an explicit assumption of neglecting the effect of the overlying fluid pressure gradient on the debris flow thereby reducing the formulation to a weakly coupled one the fluid velocity is transcribed to the granular media as a component of the drag force through an empirical drag coefficient independent of the material properties hysea has been validated against a plethora of benchmark test cases for rigid and deformable slides though the drag force on fluid module has often been omitted sediment transport models are traditionally based in the coupling of exner s equation murillo and garcía navarro 2010 zhao et al 2019 with the hyperbolic shallow water equations for the overlying fluid layer the exner s equation based models may lose their hyperbolic nature in absence of a special treatment cordier et al 2011 the bedload flow rate is obtained from the semi empirical equations such as meyer peter muller s equation yang 1996 juez et al 2014 the empirical equations are mostly based on the bed shear stress and a threshold criterion with fluid pressure gradient being an inconsequential component the hyperbolic governing equations are solved using total variation diminishing tvd shock capturing schemes pitman et al 2003 denlinger and iverson 2004 applicable to the shallow water models hll scheme harten et al 1983 is one of the popular approximate riemann solvers used in finite volume for such flows it utilizes three regions demarcated by two waves for the calculation of fluxes at the cell interface murillo and garcía navarro 2012b proposed an augmented version of hll to incorporate source sink term within the flux which relies on an approximated jacobian comprising of the steady shock a similar technique was also developed by audusse et al 2015 to incorporate discontinuous bathymetry in the case of granular media the transition of fluid to the solid phase or vice versa requires special treatment of the source sink terms unlike traditional shallow flow models the bed shear stress varies significantly based on the nature solid fluid of the flow ouyang et al 2013 xia and liang 2018 often the angle of repose is used as a rigid criterion for stopping granular medium mangeney castelnau 2003 proposed a combination of dirac delta function coupled with coulomb s threshold to prevent the propagation of perturbation on either side murillo and garcía navarro 2012a proposed a correction of intermediate discharge according to gravitational frictional force to simulate stop and go mechanism of debris models it may be noted that three dimensional μ i rheology models jop et al 2006 are free of such ad hoc provisions as viscosity tends to infinity when strain rate vanishes thus effectively arresting the flow the current study attempts to develop a depth integrated coupled framework to analyze the deformation of submerged granular media and consequent effects on the water surface and vice versa the granular and fluid modules are connected through an interaction force pair a modified version of augmented hll scheme is developed for modeling the coupled framework which employs an additional closure of interfacial fluxes by embedding different aspects such as wet dry transitions granular flow arrest and interaction forces diverse facets of the proposed framework are investigated through a diverse set of experimental and hypothetical scenarios this paper is organized as follows section 2 deals with the vertical averaging of the coupled model equations originating from the macroscopic conservation laws constitutive relations for fluid and granular phases respectively the hyperbolic partial differential equations are solved through an augmented hll scheme in a regular finite volume grid in the section 3 section 4 validates the framework against three experimental test cases involving granular failure in the absence and presence of water two representative test cases are also included to highlight the applicability to discontinuities in the domain and possible real time extension to field scale problems in section 5 the sensitivity of the model parameters is discussed in detail finally the conclusions obtained in this study are presented in section 6 an attempt to develop a separate depth averaged equation one dimensional for fluid flow through granular media is presented in the appendix with an aim to quantify the drag force accurately 2 model equations the present model is based on the premise of the coupled nature of overlying fluid and submerged porous media dynamics the governing equations of the system are derived from the macroscopic conservation laws and constitutive relationships a generic representation of the domain of interest is shown in fig 1 η z g and z 0 represent the free surface the granular interface and the impermeable non erodible bed z 0 z 0 t respectively and are functions of x and y coordinates it is considered that the granular media remains submerged at all instances i e η z g following chauchat and médale 2010 the mass and momentum conservation laws for incompressible fluid and granular media are presented below 1a u f j x j 0 1b ϕ u s j x j 0 1c u f i t u f i u f j x j ρ f p f x i τ f ij x j ν 2 k u s i u f i g i 1d ϕ u s i t ϕ u s i u s j x j 1 ρ s p s x i τ s ij x j ϕ ρ s p f x i τ f ij x j ν ρ f 2 k ρ s u s i u f i ϕ g i where u is velocity vector u v w along x y z axes the symbols ρ p τ ν g ϕ and represent density pressure shear stress kinematic viscosity of the fluid acceleration due to gravity solid fraction and porosity of granular media subscripts f and s indicate fluid and granular phases respectively a force pair comprised of fluid pressure shear and drag force couples the fluid and solid phases kafui et al 2002 the coefficient of intrinsic permeability k is calculated using carman kozeny relationship as 2 k 3 d 2 κ 1 2 where d is particle diameter and κ is problem dependant parameter chauchat and médale 2010 jafari et al 2021 semi empirical relationships similar to eq 2 have been widely utilized by various researchers ergun 1952 di felice 1994 the current study considers only the linear component of the drag the shear stresses are computed as follows 3a τ f ij ρ ν d f ij 3b τ s ij μ i p s d s d s ij where d is strain rate u i x j u j x i shear stresses for fluid are calculated by using newton s law of viscosity whereas the granular module utilizes a μ i rheology jop et al 2006 chauchat 2014 2 1 depth averaging the choice of depth averaging has been discussed extensively in recent years it has been often argued that the flow should be averaged parallel to the bed chaudhary 2008 though direct averaging along vertical axis is also quite popular xia and liang 2018 delgado sánchez et al 2020 adopted a hybrid approach for modeling two layered fluid granular system parallel to the bed for granular media vertical integration for fluid depth averaging removes variation of flow information along the averaging direction castro orgaz and hager 2019 in the present study equation 1 is vertically integrated in two layers fluid and solid with the assumption of the kinematic boundary conditions at the free surface and the interface the fluid module is averaged between η and z g and the granular solids only unlike the existing mixture models media module within z g and z 0 the kinematic boundary conditions are expressed as 4a w η f η t u η f η x v η f η y 4b w z g α z g t u z g α z g x v z g α z g y 4c where α s f any quantity γ can be depth averaged for fluid γ f and granular layer γ s as 5a γ f 1 h f z g η γ dz γ f γ f 5b γ s 1 h s z 0 z g γ dz γ s γ s with h f η z g h s z g z 0 and denotes the fluctuating component along depth depth averaging assumes the streamlines to be parallel leading to negligible vertical momentum exchange and hydrostatic pressure distribution prevails p f z g ρ f η z p s z g ϕ ρ s ρ f z g z utilizing leibnitz integral rule and applying kinematic boundary conditions eq 4 the conservation laws reduce to the following depth averaged form 6 u t f x g y s p t p s τ t τ f τ x f τ y f d where 7 u h f u f h f v f h f h s u s h s v s h s f u f h f u f 2 h f 1 2 gh f 2 u f v f h f u s h s u s 2 h s 1 2 gh s 2 u s v s h s g v f h f u f v f h f v f 2 h f 1 2 gh f 2 v s h s u s v s h s v s 2 h s 1 2 gh s 2 s p 0 s p f 0 s p s t p 0 t p f 0 t p s s τ 0 s τ f 0 s τ s t τ 0 t τ f 0 t τ s f τ x 0 0 0 0 ϕ ρ s s τ f f τ y 0 0 0 0 ϕ ρ s t τ f f d 0 0 0 0 ζ s u s h s z 0 z g u f dz ζ s v s h s z 0 z g v f dz s p f gh f z g x 0 s p s gh s z 0 x ρ f ρ s h f x 0 t p f 0 gh f z g y t p s 0 gh s z 0 y ρ f ρ s h f y s τ f 1 ρ f τ f xx ρ f u f u f h f x τ f xx z g ρ f z g x τ f xz z g ρ f 1 ρ f τ f xy ρ f u f v f h f x τ f xy z g ρ f z g x s τ s 1 ρ s τ s xx ρ s u s u s h s x τ s xx z 0 ρ s z 0 x τ s xz z 0 ρ s 1 ρ s τ s xy ρ s u s v s h s x τ s xy z 0 ρ s z 0 x t τ f 1 ρ f τ f yx ρ f u f v f h f y τ f yx z g ρ f z g y 1 ρ f τ f yy ρ f v f v f h f y τ f yy z g ρ f z g y τ f yz z g ρ f t τ s 1 ρ s τ s yx ρ s u s v s h s y τ s yx z 0 ρ s z 0 y 1 ρ s τ s yy ρ s v s v s h s y τ s yy z 0 ρ s z 0 y τ s yz z 0 ρ s where ζ s ν 2 ρ f ϕ k ρ s subscripts p and τ represent the origin of the source sink terms f denotes the interaction term between fluid represented with subscript f and granular represented with subscript s modules the vectors u f g s p t p s τ t τ f τ x f τ y and f d correspond to the conserved state variables flux terms in x and y directions pressure and topography source sink terms in x and y directions shear stress terms in x and y directions interfacial stress terms on granular top surface in x and y directions and drag source sink terms respectively the drag term f d for the fluid phase becomes zero within the limits of integration applied the one dimensional width averaged model is presented in eq 8 8 u t f x s p s τ f τ x f d where 9 u h f u f h f h s u s h s f u f h f u f 2 h f 1 2 gh f 2 u s h s u s 2 h s 1 2 gh s 2 s p 0 s p f 0 s p s s τ 0 s τ f 0 s τ s f τ x 0 0 0 ϕ ρ s s τ f f d 0 0 0 ζ s u s h s z 0 z g u f dz s p f gh f z g x s p s gh s z 0 x ρ f ρ s h f x s τ f 1 ρ f τ f xx ρ f u f u f h f x τ f xx z g ρ f z g x τ f xz z g ρ f s τ s 1 ρ s τ s xx ρ s u s u s h s x τ s xx z 0 ρ s z 0 x τ s xz z 0 ρ s depth integration of μ i constitutive relationship involves empirical parameters gray and edwards 2014 along with the flow properties such as froude number and flow depth for brevity repose and avalanche angles lajeunesse et al 2004 are considered identical which reduces the basal shear to a mohr coulomb approximation xia and liang 2018 the fluid bed shear at the interface is computed using well known manning s equation 3 numerical modeling the current section deals with the numerical implementation of the model in a regular finite volume grid leveque 2002 toro 2015 for concision the one dimensional version of the unified framework has been presented here the equations are integrated over a control volume ω 10 ω u t d ω ω f x d ω ω s p s τ f τ x f d s d ω the framework considers the assumption of strong advective system zhao et al 2019 the jacobian a f u for the system is constructed in eq 11 11 a 0 1 0 0 u f 2 gh f 2 u f 0 0 0 0 0 1 0 0 u s 2 gh s 2 u s the roots of the jacobian i e eigenvalues of the system are always real and distinct thereby demonstrating the unconditional hyperbolicity of the model the set of equations form distinct sets of riemann problems and can be solved using the modified version of the approximate riemann solver which is described in the following subsection the system may become conditionally hyperbolic by involving non conservative source sink components s p s τ in the calculation of the jacobian the current study solves a conservative system whilst incorporating the source sink terms as a part of the interfacial flux computations a second order heun s method is adopted for explicit time stepping where denotes the intermediate steps 12a u i u i t δ t δ x f i 1 2 f i 1 2 r u t 12b u i u i δ t δ x r u 12c u i t δ t 1 2 u i u i f includes the contribution from the consolidated source sink vector s integral relations for calculation of fluxes are shown in the following subsections 3 1 independence of eigenvectors the eigenstructure of the jacobian a is computed in order to find the interdependence of the different modules in the flux calculation zhao et al 2019 the eigenvalues and the corresponding right eigenvectors of the jacobian are 13a λ f u f a f λ s u s a s 13b r 1 u f a f 0 1 u f a f 0 1 0 1 0 0 1 u s a s 0 1 u s a s 0 1 0 1 where a f gh f and a s gh s represent the celerities of fluid and granular modules respectively matrix r is used to evaluate generalized riemann invariants toro 2015 zhao et al 2019 for the superposition of multiple riemann problems at a point from equation 13 the following inferences may be drawn about the hyperbolic system 14 dh f 1 u f a f dq f 1 dh s 0 dq s 0 15 dh f 0 dq f 0 dh s 1 u s a s dq s 1 16 dh f 1 u f a f dq f 1 dh s 0 dq s 0 17 dh f 0 dq f 0 dh s 1 u s a s dq s 1 where q f and q s represent the flow rates of the fluid u f h f and the granular u s h s media respectively integrating eqs 14 17 along the corresponding eigenvalues i e the wave speeds following conclusions may be drawn 18 h s q s constant along dx dt u f a f 19 h f q f constant along dx dt u s a s the state variables of the complementary media do not alter the flux computation of each other thus the unified framework may be conceptualized as two concurrent systems coexisting in the same domain coupled through the source sink term s 3 2 augmented hll scheme the domain is discretized into regular finite volume grid with integral and half integral indices representing the cell centers and the cell faces respectively fluxes are calculated at the cell faces and state variables are updated accordingly at cell centers the unified system along with the eigenvalues is shown in fig 2a fig 2b depicts the individual riemann problem for both the modules the vectors s f and s s comprise of information from complementary modules alongwith the source sink terms from the corresponding module subscripts f and s indicate the fluid and the granular sub systems respectively for each module two wave speeds and three regions of solution are considered for evaluation of fluxes the consolidated source sink vector is embedded within the interfacial flux f a modified version of the augmented hll scheme harten et al 1983 has been chosen for flux computation at the cell interfaces the steps for solution of the hyperbolic pde partial differential equations with the source vector s are enlisted as follows 20 x l x r u x δ t dx u x r x l x r u r x l u l f r f l δ t x l x r 0 δ t s dtdx s δ t where x r λ r δ t and x l λ l δ t the source sink terms are incorporated as a single vector at the discontinuity the source sink terms are not constant in time and hence a cell averaged source sink term s is approximated based on known time level value few depth sensitive source sink terms such as manning s friction have been treated with incremental variations liang and marche 2009 to improve the stability of the scheme 21 x l x r u x δ t dx x r u r x l u l f r f l s δ t the integral average value u between x r and x l is obtained as follows 22a u λ r u r λ l u l f r f l s λ r λ l λ r u r λ l u l λ r λ l 22b u l x l 0 u x δ t dx δ t λ l 22c u r 0 x r u x δ t dx δ t λ r inclusion of source sink term necessitates an additional relation between u l and u r murillo and garcía navarro 2012b have incorporated an approximate form of jacobian coupled with source sink term audusse et al 2015 has detailed the continuity and pressure balances for closure while utilizing the absence of friction source sink term in momentum equation the present model is a coupled framework with the interaction force pair arising out of either of the modules fluid and granular improving upon audusse et al 2015 formulation a balance for all the forces has been provided in this formulation here the following direct relations between forces and discharge are imposed 23a h f l u f l h f r u f r 23b δ h f δ z g x l x r s τ f dx 23c h s l u s l h s r u s r 23d δ h s δ z 0 ρ f ρ s δ h f x l x r f d f τ x μ q s q s dx δ denotes the difference between right u r and left u l states across the steady shock implies non dimensional source sink terms by division with gh it is assumed that the discharge remains unchanged among left and right state for both fluid and granular modules following the introduction of source sink terms the new flux values are defined as f l f u l and f r f u r based on rankine hugonoit conditions across left and right waves and for steady shock at x 0 the following relations for fluxes at the faces are derived 24a f r λ r f l λ l f r λ r λ l u r u l λ r s λ l h λ r λ l 24b f l λ r f l λ l f r λ r λ l u r u l λ l s λ r h λ r λ l where h u r u l the transition from dry to wet region or vice versa needs to be incorporated while calculating h the following inequality needs to be satisfied for handling the vacuum state 25a h f l z g l z g r h f r 0 u f l u f r 0 25b h f r z g r z g l h f l 0 u f l u f r 0 25c h s l z 0 l ρ f ρ s h f l h f r z 0 r x l x r f d f τ x μ q s q s dx h s r 0 u s l u s r 0 25d h s r z 0 r ρ f ρ s h f r h f l z 0 l x l x r f d f τ x μ q s q s dx h s l 0 u s l u s r 0 the eigenstructure of the system implies that the granular flow will stop if surface gradient is zero in contravention to the physics of flow which suggests that it should stop when the surface gradient becomes lesser than the angle of repose mangeney castelnau 2003 when the granular discharge becomes zero due to basal friction there is a possibility that continuity flux containing λ r λ l λ r λ l h r h l will continue to produce non zero flux unless h r becomes equal to h l moreover in presence of a fluid pressure gradient the flow arrest criterion shifts to or away from the angle of repose contingent upon the direction of fluid surface gradient the basal shear stress in the granular system is expressed as s τ s μ gh s q s q s mohr coulomb theory this shear stress is not self sensitive unlike three dimensional rheological model jop et al 2006 towards flow arrest and certain key considerations towards restriction of flow have been made by mangeney castelnau 2003 the self sensitivity of the three dimensional rheological model pertains to the flow arrest when strain rate tends to zero which cannot be implored through mohr coulomb law few earlier works murillo and garcía navarro 2012a yavari ramshe and ataie ashtiani 2017 have concentrated on this aspect of the framework the momentum equation is generally replaced with q s 0 when the granular media turns solid the source sink term is amended suitably so as to achieve this objective in this work a novel interpretation of the fluid solid transition in granular media is proposed with an aim of simplifying the initiation stoppage phenomenon in the event the granular discharge at time t is zero the pressure term has to be balanced by the corresponding source sink term s to stop the flow such evaluation needs to be reflected in the continuity equation as well to avoid spurious flows at the instant of stoppage the continuity fluxes f r and f l should become zero which is attained by a suitable modification in the vector h to account for the flow stoppage at non zero gradients the continuity flux for granular media is modified by limiting the corresponding term in vector h to δ h s the friction coefficient μ is embedded in the inequality thus h is written as 26 h u r u l δ z g 0 δ z s 0 where 27a δ z g min h f l z g r z g l if z g r z g l 0 27b δ z g max h f r z g r z g l if z g r z g l 0 27c δ z s min δ h s δ z s if q s 0 27d δ z s max δ h s δ z s if q s 0 δ z g is a manifestation of the expressions 23a 25a and 25b based on the wet dry transition and vice versa similar description can be found in audusse et al 2015 a parallel may be drawn for the granular media while limiting the δ z s δ z 0 ρ f ρ s δ h f f d f τ x μ δ x q s q s this definition of h is consistent with the steady state of the coupled system the flux at the cell interface may be calculated as 28a f i 1 2 f l if λ l 0 f hll λ l λ r λ l s i 1 2 λ r h i 1 2 if λ l 0 λ r f r s i 1 2 if 0 λ r 28b f i 1 2 f l s i 1 2 if λ l 0 f hll λ r λ r λ l s i 1 2 λ l h i 1 2 if λ l 0 λ r f r if 0 λ r where f hll 1 λ r λ l λ r f l λ l f r λ r λ l u r u l the discrete source sink terms s and the vector h are modified suitably to reflect the lake at rest solution and the wet dry transitions wave speed estimate is the key to success of any hll scheme following fraccarollo and toro 1995 the wave speeds for both the modules are defined as follows 29a λ l min u l a l u a if h l δ u r 2 a r if h l δ 29b λ r max u r a r u a if h r δ u l 2 a l if h r δ where u and a are the velocity and celerity approximations based on the intermediate region and are given in equation 30 δ is a threshold value for wet dry transitions this choice of wave speeds has been shown to perform accurately for dry wet transition or vice versa the intermediate values are computed as follows 30a u u r u l 2 a l a r 30b a u l u r 4 a l a r 2 the time step is dictated by the cfl condition for both fluid and granular modules 31 δ t min ξ δ x max λ f λ s ξ is a problem dependent parameter 0 5 3 3 source sink terms various source and sink terms exist in this formulation and have to be appropriately discretized at the interface with respect to space and time in order to have a stable solution 32 s i 1 2 1 δ t δ x x i x i δ x t t δ t s p s τ f τ x f d dtdx s i 1 2 1 δ t δ x x i δ x x i t t δ t s p s τ f τ x f d dtdx a combination of implicit and explicit formulations for multiple source sink terms is employed the evaluation of source sink terms at different time step values arises due to the coupled nature of the system the fluctuation terms in the source sink vectors arising out of depth integration are considered to be negligible and thus omitted 33 s i 1 2 s p i 1 2 t s τ i 1 2 t δ t f τ x i 1 2 t δ t f d i 1 2 t the source sink terms f τ x and f d for fluid flow vanish in absence of granular media in s p s τ and f d apriori knowledge of the flow parameters such as fluid and granular depths and granular velocity is required which restricts the temporally incremental treatment of these terms the bed shear stress s τ f is calculated using manning s equation s τ f gn 2 q f q f h 7 3 a variant of liang and marche 2009 for computation of bed stress in fluid module has been proposed whilst embedding the corresponding source sink term in the interfacial fluxes the sequential process enables the computation of f τ x fluid stresses on granular module at the cell interfaces for granular media at t δ t the source sink term corresponding to the continuity equation is zero the second element of the vector s τ is expanded around t using taylor series liang and marche 2009 34 s τ f t δ t s τ f t s τ f q f t q f t δ t q f t the non linearity of s τ f with respect to q f hinders the evaluation of this source sink term at interface as it may require simultaneous solution of a system of non linear equations equal to the number of cell faces in a two dimensional framework the number of such equations will be twice as much in order to utilize the implicit formulation for the manning s friction term it is evaluated at cell centers instead of cell faces as follows 35 q f t δ t q f t δ t δ x χ i 1 2 χ i 1 2 d x f f i 1 2 t f f i 1 2 t where d x 1 δ t s τ f q f t 36a χ i 1 2 0 if λ l 0 λ l λ r λ l if λ l 0 λ r 1 if 0 λ r 36b χ i 1 2 1 if λ l 0 λ r λ r λ l if λ l 0 λ r 0 if 0 λ r f f represents the momentum equation flux for fluid module streamwise component of averaged shear stress τ f xx and the depthwise fluctuation u f are considered to be negligible the current implicit discretization provides additional stability to the system especially when bed shear becomes dominant friction term diverges to unphysical values at small depths near wet dry transition which may be avoided by restricting the scope of manning s equation to a threshold value of flow depth δ from eq 36 it may be observed that if the solution lies to either left or right regions of the intermediate state the fluid source sink term may produce non zero interfacial momentum flux at zero granular flow depths consequently the application of f τ x to the granular depths beyond threshold δ may result in spurious flow rates thus it is imperative to regularize this source sink term for low granular depths h s δ 4 test cases the applicability and the robustness of the proposed depth averaged model are demonstrated through a diverse range of test cases consisting of failure of the granular media in the presence absence of fluid in one and two dimensions first test case highlights the initiation arrest criterion for the granular media and the second test case corresponds to the failure of a dry granular column the third test case depicts failure of a submerged granular column and subsequent effects on water surface for different particle sizes in the fourth test case granular media failure with different configurations iv a and iv b of the fluid is depicted while as a dambreak over flat mobile bed is shown in iv c finally the fifth test case exhibits a two dimensional configuration of both the modules and underlines potential extension of the framework to the real time scenario the various material properties associated with the test cases are given in table 1 interstitial flow rate is assumed to be negligible z 0 z g u f dz 0 for the computation of the drag force throughout the scenarios where zero drag force assumption implies the interstitial fluid velocity to be identical to that of granular media scenarios iii and iv have also been simulated with zero drag force to display the impact of drag on failure pattern comparison of various interstitial velocity models for scenario iv a is shown in the appendix all the dimensions in test cases are in si units 4 1 scenario i anti symmetric discontinuities this hypothetical test case starts with an initially discontinuous granular media layer at the middle x 3 0 m and corresponding anti symmetric discontinuity in the water surface at the identical location as shown in fig 3 the density of the granular media ρ s friction coefficient μ and solid fraction ϕ are 2000 kg m 3 tan 30 and 0 5 respectively the fluid profile remains fixed throughout the simulation while no such restriction is placed on the granular module the interstitial flow velocity is assumed to be zero the left and right boundaries are impermeable in absence of fluid granular velocity interfacial shear disappears and the granular momentum equation reduces to x z 0 h s h f ρ f ρ s μ q s q s the initial dashed and final solid granular media and water surface profiles are presented in fig 4 this case corresponds to the stability condition of the granular media wherein an opposing fluid pressure gradient impedes the failure the granular media column although initially discontinuous does not move because of an opposite fluid pressure gradient it may also be observed that the transition from zero to non zero flow depth for the granular module is properly captured through the definition of h other source sink terms become active only when there is non zero velocity for either module 4 2 scenario ii dry column failure in this test a dry granular column bui et al 2008 of height 0 1 m in a domain of 0 6 m 0 2 m within the region 0 0 2 m 0 0 2 m as shown in fig 5 is simulated this case is simulated with negation of all the interactions that arise due to the presence of the fluid phase the granular media density is 2650 kg m 3 and the friction angle is 19 8 following the value deduced from shear box measurements by bui et al 2008 this case is simulated with δ x 0 01 m and δ t 0 0001 s for a period of 30 s the final granular profile alongwith the experimental data have been produced in fig 6 the depth averaged granular mass failure is generally faster as compared to the three dimensional counterpart due to strain rate independence of the basal shear stress the solid line represents the numerical results and triangles depict the experimental observations the final granular profile is in good agreement with the experimental data the granular media failure stops within 1 s of its initiation however the simulation is continued further to ascertain the flow arrest 4 3 scenario iii submerged granular column collapse in this test case lee et al 2018 the initially vertical submerged granular columns of different particle sizes are let to flow after lifting of the gate the water surface is initially horizontal 0 15 m in a domain of length 0 5 m the granular columns are 0 089 m high and 0 06 m in longitudinal extent fig 7 both the coarse and fine particles have same material properties except for the mean diameter 0 56 mm 0 12 mm the density and the solid fraction of the granular material are 2530 kg m 3 0 554 and angle of repose being 22 4 the spatial discretization δ x 0 01 m is used along with a constant time step of δ t 0 0001 s the experimental and numerical granular surface profiles for both coarse and fine granular media have been shown in figs 8 and 9 respectively the profiles for coarse media are shown at various time steps 0 1 s 0 4 s 0 8 s and 1 2 s while as for fine media only final profile at 1 2 s is depicted the deviation of numerical and experimental granular profiles in the fig 8a for coarse media may be attributed to the vertical gate opening process in the eventuality the extent and the depth of granular failure is well described by the proposed model in absence of drag force the profiles that include drag maybe ascribed to carman kozeny relationship eq 2 for drag coefficient where drag force becomes a non linear function of particle size thus the final profile for fine particles arises due to a substantially large drag coefficient owing to a very small particle size 4 4 scenario iv dambreak over mobile beds the fourth test case spinewine 2005 encompasses three different orientations of submerged granular movement in lieu of dambreak as shown in fig 10 the domain of length 6 0 m is divided in the center x 3 0 m by a gate arrangement the initial flow parameters to the left of the gate are subscripted as l and those to the right as r the different variants of h sl h sr h fl and h fr for three sub cases are described in table 2 the first set of initial conditions describes a granular media collapse in dam break without tailwater the second test includes the tailwater depth and the last case corresponds to a dam break over mobile bed the material properties are the same in all the three experiments with density solid fraction particle size and the friction angle of the granular media as 2683 kg m 3 0 53 1 82 mm and 30 respectively as in spinewine 2005 manning s coefficient has been approximated based on strickler s formula chaudhary 2008 the gate is lifted instantaneously t 0 0 s and both the media are allowed to move accordingly the spatial grid of dimension δ x 0 01 m is employed with constant time step of δ t 0 0001 s the chronological profiles of both the media for the three sub cases from t 0 25 s 1 50 s with a time interval of 0 25 s are shown in figs 11 13 respectively for the comparison the simulation is carried out with the inclusion and exclusion of the drag force the subsurface fluid flow rate in former is considered to be zero whereas in latter granular media and subsurface fluid are presumed to be moving at identical velocity the profiles that include the drag force closely replicate the experimental pattern and data in scenario iv a while the first two sub cases deal with the discontinuities in both granular and water profiles the third test case considers a continuous granular layer beneath a discontinuous water column the third sub case is considered to demonstrate the initiation of granular surface movement in absence of a discontinuity but under the influence of the water surface variation in the first two cases the granular mass displaces due to the initial discontinuity along with other factors including fluid pressure gradient drag and friction at the interface a perpetual hole fig 12 at the foot of failure plane is formed in the second sub case in the third sub case the unsteady water surface profile after the dambreak leads to movement of the granular mass according to the criterion proposed by yavari ramshe and ataie ashtiani 2017 the bed would remain horizontal scenario iv c at all times further the hysea model macías et al 2020 that negates the effect of water surface gradient on the underlying debris would also fail to initiate the granular displacement a small hole is developed at the gate and becomes a permanent feature of the granular media layer fig 13 the spatiotemporal variations of fluid flow depth discharge and granular flow depth with the inclusion of drag force are delineated in fig 14 the fluid front collides with the wall at around t 2 0 s and reflects back the resulting pressure gradient creates a fluctuation in the granular surface travelling with the water front fig 14g i this feature of the fluid flow interaction with granular layer is omitted in models like the hysea macías et al 2020 the magnitude of transient fluctuation differs in the three cases and also with the inclusion exclusion of the drag force in second sub case a small spike in the fluid discharge fig 14e is observed at the position of the hole fig 12 in granular media in the third sub case the undulation is more prominent fig 14i along with a depression in granular surface developed at the right boundary beyond 2 0 s 4 5 scenario v two dimensional representative case a two dimensional test case is demonstrated to exhibit the applicability of the proposed model in generalised scenario the domain 10 m 10 m comprises of a trapezoidal lake coupled with a sloping ground surface on the right side the initial condition is depicted in fig 15 there is a granular wedge 1 5 m 1 5 m positioned asymmetrically in the domain within the lake as shown in fig 15c the non erodible surface z 0 varies from 0 m at the bed of the water body and 1 5 m at the highest point in the adjoining v shaped basin fig 15a the impermeable bed has been perturbed throughout the domain with a gaussian noise of standard deviation 0 05 m to examine the sensitivity of wet dry transition for both media initial water surface level in the lake is 1 50 m and the basin is completely dry fig 15b the granular model properties are the same as the previous test case the evolution of granular media and its effect on fluid have been depicted in fig 16 the granular mass fails swiftly inside the water body thereby ensuing the changes in the lake s water surface beside the basin the water surface within the lake fluctuates intensely and overtops the opposite bank to inundate the basin the flow depth fluctuates between 1 3 m and 1 6 m the granular media strikes the opposite wall of the channel and subsequently moves along it as seen beyond t 4 0 s in fig 16e after a few seconds the water surface fluctuations in the channel attenuate though the overflowing water travels according to the basin slope 5 discussion the model has been substantiated by a diversified range of test cases some showcase its behaviour while others authenticate the model against standard experiments the three dimensional interaction force pair kafui et al 2002 comprises of the divergence of shear stress drag force and fluid pressure gradient for depth averaged variant the divergence of shear disappears due to velocity scale while keeping only the stress present f τ x f τ y at the interface of granular media and overlying fluid the bed shear stress fluid obtained semi implicitly using manning s roughness coefficient is embedded into interfacial fluxes eqs 32 36 and exerted to the granular module small water depth coupled with large fluid velocity tends to exaggerate the bed shear stress liang and marche 2009 though it has negligible contribution to granular movement as depicted in the sub cases iv a and iv c the nonphysical values of fluid source sink term at low flow depths are regularized by a threshold δ the computation of drag is essentially a three dimensional non linear feature di felice 1994 zhao and shan 2013 however depth averaging of the interstitial flow may amplify suppress the drag in a three dimensional case the effect of drag remains localized to the granular surface as fluid velocity reduces rapidly within porous media on the contrary linear approximation chauchat and médale 2010 and subsequent depth integration imply an average and constant drag force based on intrinsic permeability of the granular media with material dependence d throughout the depth existing depth averaged mixture models consider a combination of fluid and granular media beneath the interface z g the present model computes the interstitial fluid velocity for the calculation of drag through a dedicated equation in contrast to a unified velocity and a constant drag coefficient irrespective of the material properties in the hysea model the interstitial fluid is not allowed to depart the pores within granular media whereas the proposed framework allows for the different fluid and solid velocity approximations eq 7 unlike the mixture models a brief overview on the computation of the interstitial flow velocity has been presented in the appendix test cases iv and v are simulated with assumptions of non zero zero interstitial velocity and zero drag identical granular and interstitial velocities forces the test cases simulated with inclusion of the drag tend to produce better results in comparison to zero drag formulations in test case iv however in scenario iii the drag coefficient is large and the granular media flow arrest occurs faster compared to the experimental results the drag coefficient has a non linear inverse relationship eq 2 with the particle diameter as is reflected in the scenario iii d 0 56 mm 0 12 mm the amplification of the drag force arising out of small particle diameters restrains the movement of granular media prematurely nevertheless the scenario iv shows that employing drag force yields good agreement with experimental data which may be attributed to a reasonable drag coefficient for higher particle sizes the fluid pressure gradient contributes significantly in development of granular media failure patterns the choice of the test cases is such so as to highlight the water surface variation in an initially horizontal water column due to an underlying debris flow scenario iii and the effect of water surface gradient on the underlying initially discontinuous scenarios i iv a iv b horizontal test case iv c granular media the direction of water surface gradient unsteady is identical to that of granular media in scenarios iv a iv b whereas the first test case considers an opposing discontinuity for fluid steady and granular modules the first scenario highlights the inequality x z 0 h s ρ f ρ s h f μ q s q s such that the granular media does not fail in presence of a reverse step in overlying fluid column as the granular media s destabilizing fluxes are balanced by the fluid pressure gradient inclusion of the water surface gradient in the aforementioned inequality directly results in the restriction of the granular media generally overlooked in the existing models macías et al 2020 in absence of fluid pressure gradient the granular failure patterns of scenario iv a iv b will be identical as s p s becomes zero while f d f τ have negligible contributions figs 11 12 and 14 the angle of repose has frequently been utilized as a rigid criterion of transition between fluid solid regimes yavari ramshe and ataie ashtiani 2017 however such a rigid assertion may not be applicable for flow initiation arrest of submerged granular media in presence of a non zero water surface gradient the test case iv c if subjected to such assumptions s p s 0 s τ s 0 will not allow the granular flow initiation as opposed to the experimental findings last two dimensional representative test case shows the granular media is compelled to travel a small distance along opposite slope fig 16e due to combined effect of residual momentum and fluid pressure gradient it also exhibits the model s efficiency for a randomly perturbed bed incorporated through the h vector in a possible physical scenario the inundation of the floodplain and consequent wet dry transitions due to a submarine landslide are well captured by the proposed framework 6 conclusion a two dimensional coupled framework for fluid and granular media closely replicating the natural scenario is developed in this study the depth averaging of the fundamental conservation laws combined with granular media s constitutive relationship results in a hyperbolic set of governing equations the fluid and granular modules are coupled through an interaction force pair comprised of pressure shear and drag force a set of equations to describe the interstitial water flow is presented in the appendix the set of hyperbolic pdes is split into two individual riemann problems at each cell face considering eigenvalues independence for both media while essentially assuming no fluid transfer between surface and interstices the numerical scheme utilized is a modified form of an augmented hll wherein the consolidated source sink terms are embedded into the interfacial flux and is especially handy in dealing with irregular geometry as shown in the fifth test case the solid fluid and the wet dry transitions and lake at rest are a consequence of dealing with source sink terms as a part of the interfacial flux through vector h the applicability of the model has been established through a varied choice of test cases for initiation arrest of granular flow the depth averaged drag model may need suitable modification to reflect the localized influence near the surface credit authorship contribution statement naveed ul hassan bhat conceptualization methodology validation formal analysis visualization writing original draft writing review editing gourabananda pahar methodology writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is supported by indian institute of technology kanpur with grant no iitk ce 2018107 the first author acknowledges the ministry of education goi for pmrf doctoral funding appendix a a 1 interstitial flow drag force estimation requires the computation of the fluid flow rate within the granular media the one dimensional conservation laws for fluid within the bounds of granular media may be depth integrated to obtain the following set of equations 37 u g t f g x s p g s τ g f τ x g f d g where 38 u g h s u g h s f u g h s u g 2 h s 1 2 gh s 2 s p g 0 gh s z 0 x h f x s τ g 0 1 ρ f τ g xx ρ s u g u g h s x τ g xx z 0 ρ f z 0 x τ g xz z 0 ρ f f τ x g 0 1 ρ f s τ f f d g 0 ζ g h s u s u g subscript g denotes fluid flow within granular media and ζ g ν k multi layer depth averaging of fluid module implies that exchange of fluid cannot take place between surface and sub surface regions inclusion of the eq 37 in the system will result in an over deterministic set of equations 5 variables and 6 equations for one dimensional system flow rates in and outside of porous media are often assumed to be equal kumar and pahar 2020 bhat and pahar 2021 another trivial solution would be to consider identical velocities for fluid and granular media resulting in zero drag force it is assumed that near the rigid bed velocity approaches zero asymptotically the conservation equations for sub surface fluid are merged to obtain the following 39 q g t q g h s 2 h s t u g h s x gh s η x s τ f ρ f ζ g q s q g eq 39 determines the interstitial fluid flow based on a linear resistive drag and is a function of η the interstitial flow varies spatially in concurrence with the free surface though the scale of variation is strikingly different a two dimensional extension of the eq 39 is prone to inclusion of complexity in the model three approximations alongwith negligible zero velocity consideration to estimate the interstitial velocity have been presented here a dynamic shallow water model eq 39 followed by a zero inertia model eq 40a and a steady darcy s law eq 40b test case iv a has been simulated with all the considerations for interstitial flow in the fig 17 the granular media deformation and the overlying fluid flow depth for various definitions of the interstitial flow rate is depicted on the other hand a comparison between temporal evolution of the overlying and interstitial flow rates for each interstitial flow model has been in the fig 18 40a q g gh s ζ g η x s τ f ζ g ρ f q s 40b q g k ρ gh s μ η x zero inertia model neglects the temporal and the convective accelerations fernández pato and garcía navarro 2016 bhat and pahar 2021 while as the darcy s law bear 1979 further neglects the fluid friction and the granular media velocity dynamic and zero inertia models initially overestimate the interstitial velocity which advers ely affects the failure pattern however beyond t 1 0 s all the models produce comparable values of interstitial flow rate a 2 effect of the spatiotemporal resolution the formulation is tested for different spatiotemporal resolutions fig 19 exhibits the spatiotemporal variation of the water surface fluid discharge and the granular media depth for the fourth test case scenario iv a for spatial discretization of δ x 0 02 m 0 01 m and 0 0025 m respectively the cfl number has been kept identical for all the cases the results from all the three different grid resolutions show an identical pattern a fine spatial resolution produces sharp variation of fluid discharge and flow depth lesser numerical diffusion which in turn affects the granular module the intermediate value of δ x 0 01 m has been chosen for one dimensional cases throughout this study 
3670,debris flow in or towards water bodies and bed load transport in open channels manifest from the interaction of fluid with deformable granular media at varied spatiotemporal scales the present study aims to formulate a robust two dimensional coupled depth averaged framework for simulation of submarine deformation of non cohesive granular media and the corresponding effect on water and the otherwise the unified framework consisting of conditional hyperbolic set of partial differential equations has been conceptualized as two concurrent yet independent systems interacting through source sink terms comprising of drag force shear and water surface gradient the system is solved on a regular finite volume grid through a robust modification of the harten lax van leer hll scheme the interaction terms are embedded into the interfacial fluxes where additional closure employs the effect of dry wet zone transition and flow arrest for both modules various aspects of the proposed framework are validated against an array of test cases ranging from landslide induced tsunami to dambreak induced scour the last representative scenario emphasizes the potential applicability of the model for real time extension to field scale problems a few one dimensional approximations are explored in the appendix to calculate relative velocity between interstitial fluid and granular media for computation of drag force keywords depth averaged granular flow augmented hll swes 1 introduction the movement of granular mass over unstable slopes towards water bodies such as lakes reservoirs and oceans has been a constant topic of interest for geosciences the collapse of submerged granular masses has far reaching consequences in terms of rapid water surface movements leading to devastating flood waves or tsunamis these landslides are broadly classified into three categories aerial sub aerial and submarine based on the submergence of the failure a rapidly moving or fluctuating water front may trigger the motion of bed material through the fluid pressure gradient and the bed shear as shown experimentally in spinewine 2005 and numerically in pahar and dhar 2017 the mathematical modeling of such complex phenomena requires the precise coupling of the fluid and solid phases which involves a varied range of both length and time scales such as an instant landslide into a water body zhao and shan 2013 to slow progression of a meandering river fraccarollo and toro 1995 in the past few decades several studies have attempted to model the extent of the failure and the flow rate by combining fluid and granular phases in numerous ways delannay et al 2017 ideally a three dimensional continuum model coupled with a discrete granular framework kafui et al 2002 natsui et al 2012 is a prudent choice to clearly describe the complex phenomena however its applicability is restricted to small scale experiments due to the sheer computational overhead zhao and shan 2013 shan and zhao 2014 granular media has also been modeled through a non newtonian assumption with various rheological approximations jop et al 2006 forterre and pouliquen 2008 lagrée et al 2011 chauchat 2014 three dimensional eulerian models require various techniques e g volume of fluid level set method for identification of free surface interface li et al 1999 which in turn amplifies the computational burden to alleviate the use of such special treatments lagrangian methods such as smoothed particle hydrodynamics moving particle semi implicit methods have recently been deployed to simulate landslide and resulting tsunami tan and chen 2017 yeylaghi et al 2017 jafari nodoushan et al 2018 however their usage is limited due to inherent complexities involved in computational expense originating mainly from particle searching algorithms consequently depth averaged models have been employed almost routinely in such cases owing to the scale of the problem fernández nieto et al 2008 yavari ramshe and ataie ashtiani 2016 submerged failure is frequently modeled as a mixture of debris and the interstitial fluid chauchat and médale 2010 these mixture models consider a unified behavior of granular mass and the interstitial flow with no relative velocity consideration between both the modules yavari ramshe et al 2015 li et al 2019 depth averaging of granular failure is performed based on the premise that the longitudinal extent of such flows is considerably large as compared to the vertical dimension the pioneering work of savage and hutter 1989 conceptualized a depth integrated granular model through an assumption of lithostatic pressure and constant bed friction coefficient their approach has been extended by numerous researchers to model different stages of granular movements along steep slopes gray and edwards 2014 baker et al 2016 viroulet et al 2017 xia and liang 2018 edwards et al 2021 a comprehensive review of various depth averaged debris flow models has been presented in pitman and le 2005 mcdougall 2017 thouret et al 2020 and peruzzetto et al 2021 the depth averaging makes the computation of the interstitial fluid velocity a challenge this has often led to the mixture models altogether neglecting the interstitial flow and consequently the drag force yavari ramshe et al 2015 neglecting the drag force may lead to a nonphysical parameter estimation such as an unreasonably high manning s coefficient 0 8 for a smooth glass bed ferreiro ferreiro et al 2020 the hysea model macías et al 2020 makes an explicit assumption of neglecting the effect of the overlying fluid pressure gradient on the debris flow thereby reducing the formulation to a weakly coupled one the fluid velocity is transcribed to the granular media as a component of the drag force through an empirical drag coefficient independent of the material properties hysea has been validated against a plethora of benchmark test cases for rigid and deformable slides though the drag force on fluid module has often been omitted sediment transport models are traditionally based in the coupling of exner s equation murillo and garcía navarro 2010 zhao et al 2019 with the hyperbolic shallow water equations for the overlying fluid layer the exner s equation based models may lose their hyperbolic nature in absence of a special treatment cordier et al 2011 the bedload flow rate is obtained from the semi empirical equations such as meyer peter muller s equation yang 1996 juez et al 2014 the empirical equations are mostly based on the bed shear stress and a threshold criterion with fluid pressure gradient being an inconsequential component the hyperbolic governing equations are solved using total variation diminishing tvd shock capturing schemes pitman et al 2003 denlinger and iverson 2004 applicable to the shallow water models hll scheme harten et al 1983 is one of the popular approximate riemann solvers used in finite volume for such flows it utilizes three regions demarcated by two waves for the calculation of fluxes at the cell interface murillo and garcía navarro 2012b proposed an augmented version of hll to incorporate source sink term within the flux which relies on an approximated jacobian comprising of the steady shock a similar technique was also developed by audusse et al 2015 to incorporate discontinuous bathymetry in the case of granular media the transition of fluid to the solid phase or vice versa requires special treatment of the source sink terms unlike traditional shallow flow models the bed shear stress varies significantly based on the nature solid fluid of the flow ouyang et al 2013 xia and liang 2018 often the angle of repose is used as a rigid criterion for stopping granular medium mangeney castelnau 2003 proposed a combination of dirac delta function coupled with coulomb s threshold to prevent the propagation of perturbation on either side murillo and garcía navarro 2012a proposed a correction of intermediate discharge according to gravitational frictional force to simulate stop and go mechanism of debris models it may be noted that three dimensional μ i rheology models jop et al 2006 are free of such ad hoc provisions as viscosity tends to infinity when strain rate vanishes thus effectively arresting the flow the current study attempts to develop a depth integrated coupled framework to analyze the deformation of submerged granular media and consequent effects on the water surface and vice versa the granular and fluid modules are connected through an interaction force pair a modified version of augmented hll scheme is developed for modeling the coupled framework which employs an additional closure of interfacial fluxes by embedding different aspects such as wet dry transitions granular flow arrest and interaction forces diverse facets of the proposed framework are investigated through a diverse set of experimental and hypothetical scenarios this paper is organized as follows section 2 deals with the vertical averaging of the coupled model equations originating from the macroscopic conservation laws constitutive relations for fluid and granular phases respectively the hyperbolic partial differential equations are solved through an augmented hll scheme in a regular finite volume grid in the section 3 section 4 validates the framework against three experimental test cases involving granular failure in the absence and presence of water two representative test cases are also included to highlight the applicability to discontinuities in the domain and possible real time extension to field scale problems in section 5 the sensitivity of the model parameters is discussed in detail finally the conclusions obtained in this study are presented in section 6 an attempt to develop a separate depth averaged equation one dimensional for fluid flow through granular media is presented in the appendix with an aim to quantify the drag force accurately 2 model equations the present model is based on the premise of the coupled nature of overlying fluid and submerged porous media dynamics the governing equations of the system are derived from the macroscopic conservation laws and constitutive relationships a generic representation of the domain of interest is shown in fig 1 η z g and z 0 represent the free surface the granular interface and the impermeable non erodible bed z 0 z 0 t respectively and are functions of x and y coordinates it is considered that the granular media remains submerged at all instances i e η z g following chauchat and médale 2010 the mass and momentum conservation laws for incompressible fluid and granular media are presented below 1a u f j x j 0 1b ϕ u s j x j 0 1c u f i t u f i u f j x j ρ f p f x i τ f ij x j ν 2 k u s i u f i g i 1d ϕ u s i t ϕ u s i u s j x j 1 ρ s p s x i τ s ij x j ϕ ρ s p f x i τ f ij x j ν ρ f 2 k ρ s u s i u f i ϕ g i where u is velocity vector u v w along x y z axes the symbols ρ p τ ν g ϕ and represent density pressure shear stress kinematic viscosity of the fluid acceleration due to gravity solid fraction and porosity of granular media subscripts f and s indicate fluid and granular phases respectively a force pair comprised of fluid pressure shear and drag force couples the fluid and solid phases kafui et al 2002 the coefficient of intrinsic permeability k is calculated using carman kozeny relationship as 2 k 3 d 2 κ 1 2 where d is particle diameter and κ is problem dependant parameter chauchat and médale 2010 jafari et al 2021 semi empirical relationships similar to eq 2 have been widely utilized by various researchers ergun 1952 di felice 1994 the current study considers only the linear component of the drag the shear stresses are computed as follows 3a τ f ij ρ ν d f ij 3b τ s ij μ i p s d s d s ij where d is strain rate u i x j u j x i shear stresses for fluid are calculated by using newton s law of viscosity whereas the granular module utilizes a μ i rheology jop et al 2006 chauchat 2014 2 1 depth averaging the choice of depth averaging has been discussed extensively in recent years it has been often argued that the flow should be averaged parallel to the bed chaudhary 2008 though direct averaging along vertical axis is also quite popular xia and liang 2018 delgado sánchez et al 2020 adopted a hybrid approach for modeling two layered fluid granular system parallel to the bed for granular media vertical integration for fluid depth averaging removes variation of flow information along the averaging direction castro orgaz and hager 2019 in the present study equation 1 is vertically integrated in two layers fluid and solid with the assumption of the kinematic boundary conditions at the free surface and the interface the fluid module is averaged between η and z g and the granular solids only unlike the existing mixture models media module within z g and z 0 the kinematic boundary conditions are expressed as 4a w η f η t u η f η x v η f η y 4b w z g α z g t u z g α z g x v z g α z g y 4c where α s f any quantity γ can be depth averaged for fluid γ f and granular layer γ s as 5a γ f 1 h f z g η γ dz γ f γ f 5b γ s 1 h s z 0 z g γ dz γ s γ s with h f η z g h s z g z 0 and denotes the fluctuating component along depth depth averaging assumes the streamlines to be parallel leading to negligible vertical momentum exchange and hydrostatic pressure distribution prevails p f z g ρ f η z p s z g ϕ ρ s ρ f z g z utilizing leibnitz integral rule and applying kinematic boundary conditions eq 4 the conservation laws reduce to the following depth averaged form 6 u t f x g y s p t p s τ t τ f τ x f τ y f d where 7 u h f u f h f v f h f h s u s h s v s h s f u f h f u f 2 h f 1 2 gh f 2 u f v f h f u s h s u s 2 h s 1 2 gh s 2 u s v s h s g v f h f u f v f h f v f 2 h f 1 2 gh f 2 v s h s u s v s h s v s 2 h s 1 2 gh s 2 s p 0 s p f 0 s p s t p 0 t p f 0 t p s s τ 0 s τ f 0 s τ s t τ 0 t τ f 0 t τ s f τ x 0 0 0 0 ϕ ρ s s τ f f τ y 0 0 0 0 ϕ ρ s t τ f f d 0 0 0 0 ζ s u s h s z 0 z g u f dz ζ s v s h s z 0 z g v f dz s p f gh f z g x 0 s p s gh s z 0 x ρ f ρ s h f x 0 t p f 0 gh f z g y t p s 0 gh s z 0 y ρ f ρ s h f y s τ f 1 ρ f τ f xx ρ f u f u f h f x τ f xx z g ρ f z g x τ f xz z g ρ f 1 ρ f τ f xy ρ f u f v f h f x τ f xy z g ρ f z g x s τ s 1 ρ s τ s xx ρ s u s u s h s x τ s xx z 0 ρ s z 0 x τ s xz z 0 ρ s 1 ρ s τ s xy ρ s u s v s h s x τ s xy z 0 ρ s z 0 x t τ f 1 ρ f τ f yx ρ f u f v f h f y τ f yx z g ρ f z g y 1 ρ f τ f yy ρ f v f v f h f y τ f yy z g ρ f z g y τ f yz z g ρ f t τ s 1 ρ s τ s yx ρ s u s v s h s y τ s yx z 0 ρ s z 0 y 1 ρ s τ s yy ρ s v s v s h s y τ s yy z 0 ρ s z 0 y τ s yz z 0 ρ s where ζ s ν 2 ρ f ϕ k ρ s subscripts p and τ represent the origin of the source sink terms f denotes the interaction term between fluid represented with subscript f and granular represented with subscript s modules the vectors u f g s p t p s τ t τ f τ x f τ y and f d correspond to the conserved state variables flux terms in x and y directions pressure and topography source sink terms in x and y directions shear stress terms in x and y directions interfacial stress terms on granular top surface in x and y directions and drag source sink terms respectively the drag term f d for the fluid phase becomes zero within the limits of integration applied the one dimensional width averaged model is presented in eq 8 8 u t f x s p s τ f τ x f d where 9 u h f u f h f h s u s h s f u f h f u f 2 h f 1 2 gh f 2 u s h s u s 2 h s 1 2 gh s 2 s p 0 s p f 0 s p s s τ 0 s τ f 0 s τ s f τ x 0 0 0 ϕ ρ s s τ f f d 0 0 0 ζ s u s h s z 0 z g u f dz s p f gh f z g x s p s gh s z 0 x ρ f ρ s h f x s τ f 1 ρ f τ f xx ρ f u f u f h f x τ f xx z g ρ f z g x τ f xz z g ρ f s τ s 1 ρ s τ s xx ρ s u s u s h s x τ s xx z 0 ρ s z 0 x τ s xz z 0 ρ s depth integration of μ i constitutive relationship involves empirical parameters gray and edwards 2014 along with the flow properties such as froude number and flow depth for brevity repose and avalanche angles lajeunesse et al 2004 are considered identical which reduces the basal shear to a mohr coulomb approximation xia and liang 2018 the fluid bed shear at the interface is computed using well known manning s equation 3 numerical modeling the current section deals with the numerical implementation of the model in a regular finite volume grid leveque 2002 toro 2015 for concision the one dimensional version of the unified framework has been presented here the equations are integrated over a control volume ω 10 ω u t d ω ω f x d ω ω s p s τ f τ x f d s d ω the framework considers the assumption of strong advective system zhao et al 2019 the jacobian a f u for the system is constructed in eq 11 11 a 0 1 0 0 u f 2 gh f 2 u f 0 0 0 0 0 1 0 0 u s 2 gh s 2 u s the roots of the jacobian i e eigenvalues of the system are always real and distinct thereby demonstrating the unconditional hyperbolicity of the model the set of equations form distinct sets of riemann problems and can be solved using the modified version of the approximate riemann solver which is described in the following subsection the system may become conditionally hyperbolic by involving non conservative source sink components s p s τ in the calculation of the jacobian the current study solves a conservative system whilst incorporating the source sink terms as a part of the interfacial flux computations a second order heun s method is adopted for explicit time stepping where denotes the intermediate steps 12a u i u i t δ t δ x f i 1 2 f i 1 2 r u t 12b u i u i δ t δ x r u 12c u i t δ t 1 2 u i u i f includes the contribution from the consolidated source sink vector s integral relations for calculation of fluxes are shown in the following subsections 3 1 independence of eigenvectors the eigenstructure of the jacobian a is computed in order to find the interdependence of the different modules in the flux calculation zhao et al 2019 the eigenvalues and the corresponding right eigenvectors of the jacobian are 13a λ f u f a f λ s u s a s 13b r 1 u f a f 0 1 u f a f 0 1 0 1 0 0 1 u s a s 0 1 u s a s 0 1 0 1 where a f gh f and a s gh s represent the celerities of fluid and granular modules respectively matrix r is used to evaluate generalized riemann invariants toro 2015 zhao et al 2019 for the superposition of multiple riemann problems at a point from equation 13 the following inferences may be drawn about the hyperbolic system 14 dh f 1 u f a f dq f 1 dh s 0 dq s 0 15 dh f 0 dq f 0 dh s 1 u s a s dq s 1 16 dh f 1 u f a f dq f 1 dh s 0 dq s 0 17 dh f 0 dq f 0 dh s 1 u s a s dq s 1 where q f and q s represent the flow rates of the fluid u f h f and the granular u s h s media respectively integrating eqs 14 17 along the corresponding eigenvalues i e the wave speeds following conclusions may be drawn 18 h s q s constant along dx dt u f a f 19 h f q f constant along dx dt u s a s the state variables of the complementary media do not alter the flux computation of each other thus the unified framework may be conceptualized as two concurrent systems coexisting in the same domain coupled through the source sink term s 3 2 augmented hll scheme the domain is discretized into regular finite volume grid with integral and half integral indices representing the cell centers and the cell faces respectively fluxes are calculated at the cell faces and state variables are updated accordingly at cell centers the unified system along with the eigenvalues is shown in fig 2a fig 2b depicts the individual riemann problem for both the modules the vectors s f and s s comprise of information from complementary modules alongwith the source sink terms from the corresponding module subscripts f and s indicate the fluid and the granular sub systems respectively for each module two wave speeds and three regions of solution are considered for evaluation of fluxes the consolidated source sink vector is embedded within the interfacial flux f a modified version of the augmented hll scheme harten et al 1983 has been chosen for flux computation at the cell interfaces the steps for solution of the hyperbolic pde partial differential equations with the source vector s are enlisted as follows 20 x l x r u x δ t dx u x r x l x r u r x l u l f r f l δ t x l x r 0 δ t s dtdx s δ t where x r λ r δ t and x l λ l δ t the source sink terms are incorporated as a single vector at the discontinuity the source sink terms are not constant in time and hence a cell averaged source sink term s is approximated based on known time level value few depth sensitive source sink terms such as manning s friction have been treated with incremental variations liang and marche 2009 to improve the stability of the scheme 21 x l x r u x δ t dx x r u r x l u l f r f l s δ t the integral average value u between x r and x l is obtained as follows 22a u λ r u r λ l u l f r f l s λ r λ l λ r u r λ l u l λ r λ l 22b u l x l 0 u x δ t dx δ t λ l 22c u r 0 x r u x δ t dx δ t λ r inclusion of source sink term necessitates an additional relation between u l and u r murillo and garcía navarro 2012b have incorporated an approximate form of jacobian coupled with source sink term audusse et al 2015 has detailed the continuity and pressure balances for closure while utilizing the absence of friction source sink term in momentum equation the present model is a coupled framework with the interaction force pair arising out of either of the modules fluid and granular improving upon audusse et al 2015 formulation a balance for all the forces has been provided in this formulation here the following direct relations between forces and discharge are imposed 23a h f l u f l h f r u f r 23b δ h f δ z g x l x r s τ f dx 23c h s l u s l h s r u s r 23d δ h s δ z 0 ρ f ρ s δ h f x l x r f d f τ x μ q s q s dx δ denotes the difference between right u r and left u l states across the steady shock implies non dimensional source sink terms by division with gh it is assumed that the discharge remains unchanged among left and right state for both fluid and granular modules following the introduction of source sink terms the new flux values are defined as f l f u l and f r f u r based on rankine hugonoit conditions across left and right waves and for steady shock at x 0 the following relations for fluxes at the faces are derived 24a f r λ r f l λ l f r λ r λ l u r u l λ r s λ l h λ r λ l 24b f l λ r f l λ l f r λ r λ l u r u l λ l s λ r h λ r λ l where h u r u l the transition from dry to wet region or vice versa needs to be incorporated while calculating h the following inequality needs to be satisfied for handling the vacuum state 25a h f l z g l z g r h f r 0 u f l u f r 0 25b h f r z g r z g l h f l 0 u f l u f r 0 25c h s l z 0 l ρ f ρ s h f l h f r z 0 r x l x r f d f τ x μ q s q s dx h s r 0 u s l u s r 0 25d h s r z 0 r ρ f ρ s h f r h f l z 0 l x l x r f d f τ x μ q s q s dx h s l 0 u s l u s r 0 the eigenstructure of the system implies that the granular flow will stop if surface gradient is zero in contravention to the physics of flow which suggests that it should stop when the surface gradient becomes lesser than the angle of repose mangeney castelnau 2003 when the granular discharge becomes zero due to basal friction there is a possibility that continuity flux containing λ r λ l λ r λ l h r h l will continue to produce non zero flux unless h r becomes equal to h l moreover in presence of a fluid pressure gradient the flow arrest criterion shifts to or away from the angle of repose contingent upon the direction of fluid surface gradient the basal shear stress in the granular system is expressed as s τ s μ gh s q s q s mohr coulomb theory this shear stress is not self sensitive unlike three dimensional rheological model jop et al 2006 towards flow arrest and certain key considerations towards restriction of flow have been made by mangeney castelnau 2003 the self sensitivity of the three dimensional rheological model pertains to the flow arrest when strain rate tends to zero which cannot be implored through mohr coulomb law few earlier works murillo and garcía navarro 2012a yavari ramshe and ataie ashtiani 2017 have concentrated on this aspect of the framework the momentum equation is generally replaced with q s 0 when the granular media turns solid the source sink term is amended suitably so as to achieve this objective in this work a novel interpretation of the fluid solid transition in granular media is proposed with an aim of simplifying the initiation stoppage phenomenon in the event the granular discharge at time t is zero the pressure term has to be balanced by the corresponding source sink term s to stop the flow such evaluation needs to be reflected in the continuity equation as well to avoid spurious flows at the instant of stoppage the continuity fluxes f r and f l should become zero which is attained by a suitable modification in the vector h to account for the flow stoppage at non zero gradients the continuity flux for granular media is modified by limiting the corresponding term in vector h to δ h s the friction coefficient μ is embedded in the inequality thus h is written as 26 h u r u l δ z g 0 δ z s 0 where 27a δ z g min h f l z g r z g l if z g r z g l 0 27b δ z g max h f r z g r z g l if z g r z g l 0 27c δ z s min δ h s δ z s if q s 0 27d δ z s max δ h s δ z s if q s 0 δ z g is a manifestation of the expressions 23a 25a and 25b based on the wet dry transition and vice versa similar description can be found in audusse et al 2015 a parallel may be drawn for the granular media while limiting the δ z s δ z 0 ρ f ρ s δ h f f d f τ x μ δ x q s q s this definition of h is consistent with the steady state of the coupled system the flux at the cell interface may be calculated as 28a f i 1 2 f l if λ l 0 f hll λ l λ r λ l s i 1 2 λ r h i 1 2 if λ l 0 λ r f r s i 1 2 if 0 λ r 28b f i 1 2 f l s i 1 2 if λ l 0 f hll λ r λ r λ l s i 1 2 λ l h i 1 2 if λ l 0 λ r f r if 0 λ r where f hll 1 λ r λ l λ r f l λ l f r λ r λ l u r u l the discrete source sink terms s and the vector h are modified suitably to reflect the lake at rest solution and the wet dry transitions wave speed estimate is the key to success of any hll scheme following fraccarollo and toro 1995 the wave speeds for both the modules are defined as follows 29a λ l min u l a l u a if h l δ u r 2 a r if h l δ 29b λ r max u r a r u a if h r δ u l 2 a l if h r δ where u and a are the velocity and celerity approximations based on the intermediate region and are given in equation 30 δ is a threshold value for wet dry transitions this choice of wave speeds has been shown to perform accurately for dry wet transition or vice versa the intermediate values are computed as follows 30a u u r u l 2 a l a r 30b a u l u r 4 a l a r 2 the time step is dictated by the cfl condition for both fluid and granular modules 31 δ t min ξ δ x max λ f λ s ξ is a problem dependent parameter 0 5 3 3 source sink terms various source and sink terms exist in this formulation and have to be appropriately discretized at the interface with respect to space and time in order to have a stable solution 32 s i 1 2 1 δ t δ x x i x i δ x t t δ t s p s τ f τ x f d dtdx s i 1 2 1 δ t δ x x i δ x x i t t δ t s p s τ f τ x f d dtdx a combination of implicit and explicit formulations for multiple source sink terms is employed the evaluation of source sink terms at different time step values arises due to the coupled nature of the system the fluctuation terms in the source sink vectors arising out of depth integration are considered to be negligible and thus omitted 33 s i 1 2 s p i 1 2 t s τ i 1 2 t δ t f τ x i 1 2 t δ t f d i 1 2 t the source sink terms f τ x and f d for fluid flow vanish in absence of granular media in s p s τ and f d apriori knowledge of the flow parameters such as fluid and granular depths and granular velocity is required which restricts the temporally incremental treatment of these terms the bed shear stress s τ f is calculated using manning s equation s τ f gn 2 q f q f h 7 3 a variant of liang and marche 2009 for computation of bed stress in fluid module has been proposed whilst embedding the corresponding source sink term in the interfacial fluxes the sequential process enables the computation of f τ x fluid stresses on granular module at the cell interfaces for granular media at t δ t the source sink term corresponding to the continuity equation is zero the second element of the vector s τ is expanded around t using taylor series liang and marche 2009 34 s τ f t δ t s τ f t s τ f q f t q f t δ t q f t the non linearity of s τ f with respect to q f hinders the evaluation of this source sink term at interface as it may require simultaneous solution of a system of non linear equations equal to the number of cell faces in a two dimensional framework the number of such equations will be twice as much in order to utilize the implicit formulation for the manning s friction term it is evaluated at cell centers instead of cell faces as follows 35 q f t δ t q f t δ t δ x χ i 1 2 χ i 1 2 d x f f i 1 2 t f f i 1 2 t where d x 1 δ t s τ f q f t 36a χ i 1 2 0 if λ l 0 λ l λ r λ l if λ l 0 λ r 1 if 0 λ r 36b χ i 1 2 1 if λ l 0 λ r λ r λ l if λ l 0 λ r 0 if 0 λ r f f represents the momentum equation flux for fluid module streamwise component of averaged shear stress τ f xx and the depthwise fluctuation u f are considered to be negligible the current implicit discretization provides additional stability to the system especially when bed shear becomes dominant friction term diverges to unphysical values at small depths near wet dry transition which may be avoided by restricting the scope of manning s equation to a threshold value of flow depth δ from eq 36 it may be observed that if the solution lies to either left or right regions of the intermediate state the fluid source sink term may produce non zero interfacial momentum flux at zero granular flow depths consequently the application of f τ x to the granular depths beyond threshold δ may result in spurious flow rates thus it is imperative to regularize this source sink term for low granular depths h s δ 4 test cases the applicability and the robustness of the proposed depth averaged model are demonstrated through a diverse range of test cases consisting of failure of the granular media in the presence absence of fluid in one and two dimensions first test case highlights the initiation arrest criterion for the granular media and the second test case corresponds to the failure of a dry granular column the third test case depicts failure of a submerged granular column and subsequent effects on water surface for different particle sizes in the fourth test case granular media failure with different configurations iv a and iv b of the fluid is depicted while as a dambreak over flat mobile bed is shown in iv c finally the fifth test case exhibits a two dimensional configuration of both the modules and underlines potential extension of the framework to the real time scenario the various material properties associated with the test cases are given in table 1 interstitial flow rate is assumed to be negligible z 0 z g u f dz 0 for the computation of the drag force throughout the scenarios where zero drag force assumption implies the interstitial fluid velocity to be identical to that of granular media scenarios iii and iv have also been simulated with zero drag force to display the impact of drag on failure pattern comparison of various interstitial velocity models for scenario iv a is shown in the appendix all the dimensions in test cases are in si units 4 1 scenario i anti symmetric discontinuities this hypothetical test case starts with an initially discontinuous granular media layer at the middle x 3 0 m and corresponding anti symmetric discontinuity in the water surface at the identical location as shown in fig 3 the density of the granular media ρ s friction coefficient μ and solid fraction ϕ are 2000 kg m 3 tan 30 and 0 5 respectively the fluid profile remains fixed throughout the simulation while no such restriction is placed on the granular module the interstitial flow velocity is assumed to be zero the left and right boundaries are impermeable in absence of fluid granular velocity interfacial shear disappears and the granular momentum equation reduces to x z 0 h s h f ρ f ρ s μ q s q s the initial dashed and final solid granular media and water surface profiles are presented in fig 4 this case corresponds to the stability condition of the granular media wherein an opposing fluid pressure gradient impedes the failure the granular media column although initially discontinuous does not move because of an opposite fluid pressure gradient it may also be observed that the transition from zero to non zero flow depth for the granular module is properly captured through the definition of h other source sink terms become active only when there is non zero velocity for either module 4 2 scenario ii dry column failure in this test a dry granular column bui et al 2008 of height 0 1 m in a domain of 0 6 m 0 2 m within the region 0 0 2 m 0 0 2 m as shown in fig 5 is simulated this case is simulated with negation of all the interactions that arise due to the presence of the fluid phase the granular media density is 2650 kg m 3 and the friction angle is 19 8 following the value deduced from shear box measurements by bui et al 2008 this case is simulated with δ x 0 01 m and δ t 0 0001 s for a period of 30 s the final granular profile alongwith the experimental data have been produced in fig 6 the depth averaged granular mass failure is generally faster as compared to the three dimensional counterpart due to strain rate independence of the basal shear stress the solid line represents the numerical results and triangles depict the experimental observations the final granular profile is in good agreement with the experimental data the granular media failure stops within 1 s of its initiation however the simulation is continued further to ascertain the flow arrest 4 3 scenario iii submerged granular column collapse in this test case lee et al 2018 the initially vertical submerged granular columns of different particle sizes are let to flow after lifting of the gate the water surface is initially horizontal 0 15 m in a domain of length 0 5 m the granular columns are 0 089 m high and 0 06 m in longitudinal extent fig 7 both the coarse and fine particles have same material properties except for the mean diameter 0 56 mm 0 12 mm the density and the solid fraction of the granular material are 2530 kg m 3 0 554 and angle of repose being 22 4 the spatial discretization δ x 0 01 m is used along with a constant time step of δ t 0 0001 s the experimental and numerical granular surface profiles for both coarse and fine granular media have been shown in figs 8 and 9 respectively the profiles for coarse media are shown at various time steps 0 1 s 0 4 s 0 8 s and 1 2 s while as for fine media only final profile at 1 2 s is depicted the deviation of numerical and experimental granular profiles in the fig 8a for coarse media may be attributed to the vertical gate opening process in the eventuality the extent and the depth of granular failure is well described by the proposed model in absence of drag force the profiles that include drag maybe ascribed to carman kozeny relationship eq 2 for drag coefficient where drag force becomes a non linear function of particle size thus the final profile for fine particles arises due to a substantially large drag coefficient owing to a very small particle size 4 4 scenario iv dambreak over mobile beds the fourth test case spinewine 2005 encompasses three different orientations of submerged granular movement in lieu of dambreak as shown in fig 10 the domain of length 6 0 m is divided in the center x 3 0 m by a gate arrangement the initial flow parameters to the left of the gate are subscripted as l and those to the right as r the different variants of h sl h sr h fl and h fr for three sub cases are described in table 2 the first set of initial conditions describes a granular media collapse in dam break without tailwater the second test includes the tailwater depth and the last case corresponds to a dam break over mobile bed the material properties are the same in all the three experiments with density solid fraction particle size and the friction angle of the granular media as 2683 kg m 3 0 53 1 82 mm and 30 respectively as in spinewine 2005 manning s coefficient has been approximated based on strickler s formula chaudhary 2008 the gate is lifted instantaneously t 0 0 s and both the media are allowed to move accordingly the spatial grid of dimension δ x 0 01 m is employed with constant time step of δ t 0 0001 s the chronological profiles of both the media for the three sub cases from t 0 25 s 1 50 s with a time interval of 0 25 s are shown in figs 11 13 respectively for the comparison the simulation is carried out with the inclusion and exclusion of the drag force the subsurface fluid flow rate in former is considered to be zero whereas in latter granular media and subsurface fluid are presumed to be moving at identical velocity the profiles that include the drag force closely replicate the experimental pattern and data in scenario iv a while the first two sub cases deal with the discontinuities in both granular and water profiles the third test case considers a continuous granular layer beneath a discontinuous water column the third sub case is considered to demonstrate the initiation of granular surface movement in absence of a discontinuity but under the influence of the water surface variation in the first two cases the granular mass displaces due to the initial discontinuity along with other factors including fluid pressure gradient drag and friction at the interface a perpetual hole fig 12 at the foot of failure plane is formed in the second sub case in the third sub case the unsteady water surface profile after the dambreak leads to movement of the granular mass according to the criterion proposed by yavari ramshe and ataie ashtiani 2017 the bed would remain horizontal scenario iv c at all times further the hysea model macías et al 2020 that negates the effect of water surface gradient on the underlying debris would also fail to initiate the granular displacement a small hole is developed at the gate and becomes a permanent feature of the granular media layer fig 13 the spatiotemporal variations of fluid flow depth discharge and granular flow depth with the inclusion of drag force are delineated in fig 14 the fluid front collides with the wall at around t 2 0 s and reflects back the resulting pressure gradient creates a fluctuation in the granular surface travelling with the water front fig 14g i this feature of the fluid flow interaction with granular layer is omitted in models like the hysea macías et al 2020 the magnitude of transient fluctuation differs in the three cases and also with the inclusion exclusion of the drag force in second sub case a small spike in the fluid discharge fig 14e is observed at the position of the hole fig 12 in granular media in the third sub case the undulation is more prominent fig 14i along with a depression in granular surface developed at the right boundary beyond 2 0 s 4 5 scenario v two dimensional representative case a two dimensional test case is demonstrated to exhibit the applicability of the proposed model in generalised scenario the domain 10 m 10 m comprises of a trapezoidal lake coupled with a sloping ground surface on the right side the initial condition is depicted in fig 15 there is a granular wedge 1 5 m 1 5 m positioned asymmetrically in the domain within the lake as shown in fig 15c the non erodible surface z 0 varies from 0 m at the bed of the water body and 1 5 m at the highest point in the adjoining v shaped basin fig 15a the impermeable bed has been perturbed throughout the domain with a gaussian noise of standard deviation 0 05 m to examine the sensitivity of wet dry transition for both media initial water surface level in the lake is 1 50 m and the basin is completely dry fig 15b the granular model properties are the same as the previous test case the evolution of granular media and its effect on fluid have been depicted in fig 16 the granular mass fails swiftly inside the water body thereby ensuing the changes in the lake s water surface beside the basin the water surface within the lake fluctuates intensely and overtops the opposite bank to inundate the basin the flow depth fluctuates between 1 3 m and 1 6 m the granular media strikes the opposite wall of the channel and subsequently moves along it as seen beyond t 4 0 s in fig 16e after a few seconds the water surface fluctuations in the channel attenuate though the overflowing water travels according to the basin slope 5 discussion the model has been substantiated by a diversified range of test cases some showcase its behaviour while others authenticate the model against standard experiments the three dimensional interaction force pair kafui et al 2002 comprises of the divergence of shear stress drag force and fluid pressure gradient for depth averaged variant the divergence of shear disappears due to velocity scale while keeping only the stress present f τ x f τ y at the interface of granular media and overlying fluid the bed shear stress fluid obtained semi implicitly using manning s roughness coefficient is embedded into interfacial fluxes eqs 32 36 and exerted to the granular module small water depth coupled with large fluid velocity tends to exaggerate the bed shear stress liang and marche 2009 though it has negligible contribution to granular movement as depicted in the sub cases iv a and iv c the nonphysical values of fluid source sink term at low flow depths are regularized by a threshold δ the computation of drag is essentially a three dimensional non linear feature di felice 1994 zhao and shan 2013 however depth averaging of the interstitial flow may amplify suppress the drag in a three dimensional case the effect of drag remains localized to the granular surface as fluid velocity reduces rapidly within porous media on the contrary linear approximation chauchat and médale 2010 and subsequent depth integration imply an average and constant drag force based on intrinsic permeability of the granular media with material dependence d throughout the depth existing depth averaged mixture models consider a combination of fluid and granular media beneath the interface z g the present model computes the interstitial fluid velocity for the calculation of drag through a dedicated equation in contrast to a unified velocity and a constant drag coefficient irrespective of the material properties in the hysea model the interstitial fluid is not allowed to depart the pores within granular media whereas the proposed framework allows for the different fluid and solid velocity approximations eq 7 unlike the mixture models a brief overview on the computation of the interstitial flow velocity has been presented in the appendix test cases iv and v are simulated with assumptions of non zero zero interstitial velocity and zero drag identical granular and interstitial velocities forces the test cases simulated with inclusion of the drag tend to produce better results in comparison to zero drag formulations in test case iv however in scenario iii the drag coefficient is large and the granular media flow arrest occurs faster compared to the experimental results the drag coefficient has a non linear inverse relationship eq 2 with the particle diameter as is reflected in the scenario iii d 0 56 mm 0 12 mm the amplification of the drag force arising out of small particle diameters restrains the movement of granular media prematurely nevertheless the scenario iv shows that employing drag force yields good agreement with experimental data which may be attributed to a reasonable drag coefficient for higher particle sizes the fluid pressure gradient contributes significantly in development of granular media failure patterns the choice of the test cases is such so as to highlight the water surface variation in an initially horizontal water column due to an underlying debris flow scenario iii and the effect of water surface gradient on the underlying initially discontinuous scenarios i iv a iv b horizontal test case iv c granular media the direction of water surface gradient unsteady is identical to that of granular media in scenarios iv a iv b whereas the first test case considers an opposing discontinuity for fluid steady and granular modules the first scenario highlights the inequality x z 0 h s ρ f ρ s h f μ q s q s such that the granular media does not fail in presence of a reverse step in overlying fluid column as the granular media s destabilizing fluxes are balanced by the fluid pressure gradient inclusion of the water surface gradient in the aforementioned inequality directly results in the restriction of the granular media generally overlooked in the existing models macías et al 2020 in absence of fluid pressure gradient the granular failure patterns of scenario iv a iv b will be identical as s p s becomes zero while f d f τ have negligible contributions figs 11 12 and 14 the angle of repose has frequently been utilized as a rigid criterion of transition between fluid solid regimes yavari ramshe and ataie ashtiani 2017 however such a rigid assertion may not be applicable for flow initiation arrest of submerged granular media in presence of a non zero water surface gradient the test case iv c if subjected to such assumptions s p s 0 s τ s 0 will not allow the granular flow initiation as opposed to the experimental findings last two dimensional representative test case shows the granular media is compelled to travel a small distance along opposite slope fig 16e due to combined effect of residual momentum and fluid pressure gradient it also exhibits the model s efficiency for a randomly perturbed bed incorporated through the h vector in a possible physical scenario the inundation of the floodplain and consequent wet dry transitions due to a submarine landslide are well captured by the proposed framework 6 conclusion a two dimensional coupled framework for fluid and granular media closely replicating the natural scenario is developed in this study the depth averaging of the fundamental conservation laws combined with granular media s constitutive relationship results in a hyperbolic set of governing equations the fluid and granular modules are coupled through an interaction force pair comprised of pressure shear and drag force a set of equations to describe the interstitial water flow is presented in the appendix the set of hyperbolic pdes is split into two individual riemann problems at each cell face considering eigenvalues independence for both media while essentially assuming no fluid transfer between surface and interstices the numerical scheme utilized is a modified form of an augmented hll wherein the consolidated source sink terms are embedded into the interfacial flux and is especially handy in dealing with irregular geometry as shown in the fifth test case the solid fluid and the wet dry transitions and lake at rest are a consequence of dealing with source sink terms as a part of the interfacial flux through vector h the applicability of the model has been established through a varied choice of test cases for initiation arrest of granular flow the depth averaged drag model may need suitable modification to reflect the localized influence near the surface credit authorship contribution statement naveed ul hassan bhat conceptualization methodology validation formal analysis visualization writing original draft writing review editing gourabananda pahar methodology writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is supported by indian institute of technology kanpur with grant no iitk ce 2018107 the first author acknowledges the ministry of education goi for pmrf doctoral funding appendix a a 1 interstitial flow drag force estimation requires the computation of the fluid flow rate within the granular media the one dimensional conservation laws for fluid within the bounds of granular media may be depth integrated to obtain the following set of equations 37 u g t f g x s p g s τ g f τ x g f d g where 38 u g h s u g h s f u g h s u g 2 h s 1 2 gh s 2 s p g 0 gh s z 0 x h f x s τ g 0 1 ρ f τ g xx ρ s u g u g h s x τ g xx z 0 ρ f z 0 x τ g xz z 0 ρ f f τ x g 0 1 ρ f s τ f f d g 0 ζ g h s u s u g subscript g denotes fluid flow within granular media and ζ g ν k multi layer depth averaging of fluid module implies that exchange of fluid cannot take place between surface and sub surface regions inclusion of the eq 37 in the system will result in an over deterministic set of equations 5 variables and 6 equations for one dimensional system flow rates in and outside of porous media are often assumed to be equal kumar and pahar 2020 bhat and pahar 2021 another trivial solution would be to consider identical velocities for fluid and granular media resulting in zero drag force it is assumed that near the rigid bed velocity approaches zero asymptotically the conservation equations for sub surface fluid are merged to obtain the following 39 q g t q g h s 2 h s t u g h s x gh s η x s τ f ρ f ζ g q s q g eq 39 determines the interstitial fluid flow based on a linear resistive drag and is a function of η the interstitial flow varies spatially in concurrence with the free surface though the scale of variation is strikingly different a two dimensional extension of the eq 39 is prone to inclusion of complexity in the model three approximations alongwith negligible zero velocity consideration to estimate the interstitial velocity have been presented here a dynamic shallow water model eq 39 followed by a zero inertia model eq 40a and a steady darcy s law eq 40b test case iv a has been simulated with all the considerations for interstitial flow in the fig 17 the granular media deformation and the overlying fluid flow depth for various definitions of the interstitial flow rate is depicted on the other hand a comparison between temporal evolution of the overlying and interstitial flow rates for each interstitial flow model has been in the fig 18 40a q g gh s ζ g η x s τ f ζ g ρ f q s 40b q g k ρ gh s μ η x zero inertia model neglects the temporal and the convective accelerations fernández pato and garcía navarro 2016 bhat and pahar 2021 while as the darcy s law bear 1979 further neglects the fluid friction and the granular media velocity dynamic and zero inertia models initially overestimate the interstitial velocity which advers ely affects the failure pattern however beyond t 1 0 s all the models produce comparable values of interstitial flow rate a 2 effect of the spatiotemporal resolution the formulation is tested for different spatiotemporal resolutions fig 19 exhibits the spatiotemporal variation of the water surface fluid discharge and the granular media depth for the fourth test case scenario iv a for spatial discretization of δ x 0 02 m 0 01 m and 0 0025 m respectively the cfl number has been kept identical for all the cases the results from all the three different grid resolutions show an identical pattern a fine spatial resolution produces sharp variation of fluid discharge and flow depth lesser numerical diffusion which in turn affects the granular module the intermediate value of δ x 0 01 m has been chosen for one dimensional cases throughout this study 
3671,microcystis blooms that are caused by intensified human activities and global warming have become a challenging environmental problem in global lakes and reservoirs research has focused on microcystis genotypes to understand their proliferation and the development of blooms although knowledge gaps exist regarding how microcystis genotype succession occurs over long term time scales in this study high throughput sequencing was used to investigate decade long successional patterns of microcystis genotypes in the large shallow lake chaohu that has long suffered from microcystis blooms microcystis populations exhibited high overall genetic diversity with 11 431 genotypes and these were relatively stable over the last 70 years with 339 shared core genotypes and 1 dominant genotype microcystis genotype succession exhibited three distinct historical phases corresponding to 1944 1960 1964 1973 and 1976 2015 these successional patterns were clearly influenced by dam construction in 1963 and subsequent nutrient enrichment following the 1970 s after dam construction increased hydraulic retention times and slowing of hydrodynamic conditions influenced microcystis genotype diversity by altering population composition and decreasing genotype richness populations and dominant genotypes rapidly returned after dam construction combined with increased inferred interactions among genotypes network analysis also indicated that low abundance microcystis genotypes rather than dominant genotypes may be keystone taxa across the decadal scale co occurrence network of microcystis population keywords decadal scale genotype high throughput sequencing microcystis blooms sedimentary dna 1 introduction microcystis blooms have been observed in over 108 countries and caused widely concern due to serious threats to aquatic health and ecosystem services from toxic metabolites of microcystis e g microcystin harke et al 2016 eutrophication is the primary factor that triggers microcystis blooms although global climate warming can further promote bloom intensity and lengthen bloom periods hans and huisman 2008 understanding bloom processes and mechanisms is pivotal for predicting and controlling their occurrences although these areas have lacked resolution in recent years researchers have investigated microcystis genotype diversity primarily through sequencing internal transcribed spacer its regions between 16s and 23s rrna genes to further demonstrate their proliferation and development bozarth et al 2010 briand et al 2009 hundreds to thousands of microcystis genotypes have been observed during blooms and these can exhibit distinct physio ecological characteristics leading to their identification as different ecotypes bozarth et al 2010 huo et al 2018 however specific microcystis genotypes have been suggested to act as the primary progenitors of blooms for example the c3 genotype has been shown to dominate the entire grangent reservoir when microcystis populations reached their maximum cell numbers briand et al 2009 likewise different dominant genotypes were observed during two biomass peaks of microcystis blooms in the copco reservoir of northern california bozarth et al 2010 thus it is likely that these dominant genotypes were implicated in the formation of microcystis blooms and that the tracking of these dominant genotypes could aid in microcystis population monitoring and provide a means to identify the sources that trigger blooms briand et al 2009 huo et al 2018 however dominant genotypes have also not been observed during microcystis blooms in some ponds bi et al 2019 zhu et al 2012 and lakes pobel et al 2012 song et al 2015 implying that numerous complex factors influence the succession of microcystis genotypes denaturing gradient gel electrophoresis dgge and molecular clone sequencing methods have been traditionally used to explore microcystis genetic diversity however the limited number of genotypes obtained by these methods could result in underestimations or biases in investigations of genetic diversity mackey et al 2017 the development of high throughput sequencing hts techniques that target specific genomic regions can help overcome culture bias limitations and enable the comprehensive investigation of microbial community compositions at coverage levels that far surpass what is possible via the construction of clone libraries mackey et al 2017 huo et al 2018 first applied hts in combination with primers targeting the its region of microcystis genomes to evaluate microcystis intra species diversity within the yuqiao reservoir of the haihe river watersheds of china these studies have shown that microcystis populations can be extremely diverse comprising up to 2 005 genotypes when clustering at the 97 nucleotide nt sequence identity level this number far surpasses that which is achieved i e 618 genotypes using cloning based methods when defining a single base pair variant as a unique genotype liu et al 2016 temporal studies of microcystis genotypes have spanned ranges of up to two years zhu et al 2012 but longer decadal scale investigations not been performed sediment archives can provide long term records of biological community compositions via fossil dnas domaizon et al 2017 lake chaohu is located in middle and lower reaches of the yangtze river and has suffered serious eutrophication in recent decades due to increasing inputs of nutrients from agricultural development and urbanization li et al 2015 zan et al 2012 accordingly cyanobacterial blooms have formed throughout the entire lake from may to november every year since the 1980 s deng et al 2007 hts analysis of paleo environmental dna subsequently indicated that microcystis and cyanobium pico cyanobacteria were the predominant cyanobacterial taxa within the lake between the 1930 s to 2010 s zhang et al 2021 consequently lake chaohu is an ideal system to investigate the succession of microcystis genetic diversity over decadal scales and in response to anthropogenic activities and climate change such studies will enable a more comprehensive understanding of bloom proliferation and development to our knowledge the present study represents the first long term scale investigation of microcystis genotype succession within a eutrophic lake that has suffered a long history of microcystis blooms li et al 2015 zan et al 2012 in particular we investigated the succession of microcystis genotypes over 70 years using sedimentary dna sequencing and hypothesized that changes in genotypic diversity were driven by altered nutrient enrichment and hydrological conditions from dam construction the main objectives of the study were to 1 reconstruct the temporal succession of microcystis genotype diversity and associated variation over decades 2 identify key environmental variables that drive the succession of microcystis genotype diversity and 3 identify key genotypes and associations between different microcystis genotypes this study provides new insights into the mechanisms of microcystis blooms from a long term perspective of microcystis genotype succession 2 materials and methods 2 1 sediment sampling and processing lake chaohu 117 16 117 51 e 31 25 31 43 n fig s1 is the fifth largest freshwater in china and has a mean depth of 3 0 m and a surface area of 780 km2 a sediment core was collected away from lake banks stream inlets in order to avoid confounding observations due to the disturbance of sediment by sourcing or re suspension in december 2017 using a gravity corer fitted with a pmma tube inner diameter 8 cm length 50 cm the sample site was located in the central basin of the eastern lake and away from lake banks outlets and inflowing streams to avoid confounding sediment disturbances fig s1 the core was subsectioned at 1 cm intervals and divided into 30 subsamples followed by dating using 137cs and 210pb fallout radionuclides as described in detail in our previous studies zan et al 2012 zhang et al 2018 paleo physicochemical variables including total nitrogen tn total phosphorus tp total organic carbon toc and particle sizes were also measured as previously described zan et al 2012 zhang et al 2018 historical air temperature data were extracted from the cn05 1 dataset that was constructed using the anomaly approach during interpolation but with more station observation 2 400 in china zhang et al 2018 2 2 high throughput sequencing dna was extracted from 30 sediment subsamples using a powersoil dna isolation kit mo bio laboratories usa following the manufacturer s protocols dna concentrations and purity were evaluated using a nanodrop spectrophotometer nd 1000 nanodrop technologies usa the bottom three subsamples that failed to pass quality control measures were removed while the uppermost subsample was also removed from further analysis the remaining 26 subsamples were used to construct amplicon libraries libraries were prepared via polymerase chain reaction pcr amplification of its regions targeting microcystis populations with the primers htsits f 5 aagggagacctaattcrggta 3 and 340 5 cctctgtgtgcctaggtatcc 3 iteman et al 2000 huo et al 2018 reactions were performed in a total reaction volume of 20 μl and were subjected to denaturation at 95 c for 5 min followed by 20 cycles of 95 c for 30 s 55 c for 30 s and 72 c for 40 s all followed by a final extension at 72 c for 10 min pcr products were purified with an e z n a gel extraction kit omega america and sequenced on the illumina hiseq 2500 platform 2 250 paired ends at biomarker technologies china 2 3 identification of genotypes paired end reads were merged using flash v1 2 7 http ccb jhu edu software flash then quality filtered using trimmomatic v0 33 bolger et al 2014 amplicon sequence variants asvs were then generated using the dada2 algorithm based on one nt difference between sequences callahan et al 2016 the blast search tool was used to assign the taxonomy of asvs by comparison against the nt database of ncbi lobo 2012 thresholds including a sequence similarity of 90 and a coverage of 90 were used to select asvs that belonged to microcystis after comparison against reference microcystis sequences to minimize sequencing errors singletons doubletons and tripletons microcystis asvs with one two or three sequences respectively were eliminated across the whole dataset and a subset of 26 074 sequences were sub sampled from each sample based on the minimum number of sequences within samples to normalize sequencing efforts and allow for comparison across samples with the vegan r package each microcystis asv was treated as a single genotype 2 4 statistical analyses alpha diversity indices including the overall number of microcystis genotypes margalef richness and the shannon wiener diversity index were calculated using the primer v7 program clarke gorley 2015 a flower plot was also constructed to visualize the number of common and unique genotypes among and within the samples using the plotrix r package bayesian change point analysis was used to identify inflection points for alpha diversity over time using the bcp r package to further explore the timing and hierarchy of significant changes in population structure multivariate regression tree mrt analysis was performed using the mvpart package for r the anosim r statistic was calculated to reflect the degree of separation among groups with r 1 indicating complete separation and r 0 suggesting no separation spearman s rank correlations were calculated among environmental variables using the corrplot r package while mantel tests were used to investigate correlations between microcystis genotypes and environmental variables using the vegan r package distance based linear models distlms were used to quantitatively assess population variation in association with environmental variables and were visualized using a distance based redundancy analysis dbrda ordination plot dbrda plots were constrained to identify linear combinations of predictor variables that explained the greatest amount of variation in data prior to the analysis environmental variables were log x 1 transformed and genotype abundances were standardized then square root transformed dbrda and distlms analyses were all performed within the primer v7 software package clarke gorley 2015 to reduce noise and false positive predictions microcystis genotypes with relative mean abundances 0 01 and presence in 1 3 of samples were selected for network analyses spearman rank correlations were used to explore relationships among microcystis genotypes and environmental variables using the hmisc r package with correlation p value corrections using a benjamini hochberg standard false discovery rate correction benjamini hochberg 1995 only robust r 0 8 and significant p 0 05 correlations were incorporated into network analyses significant changes of alpha and beta diversity of microcystis genotypes were identified in 1964 just after dam construction in year 1963 and thus four networks were constructed for before years 1944 1960 and after years 1973 1985 1988 1997 and 1999 2008 dam construction to investigate whether dam construction affected the diversity and succession of microcystis genotypes to ensure the comparability of network topology features the same sample size was used to construct each network network visualizations were conducted using the gephi v0 9 2 software package with the fruchterman reingold placement algorithm network modularity classes and node level topological properties including degree betweenness centrality and closeness centrality were all also calculated within the gephi program a modularity class represents a sub community of a network and is composed of highly inter connected nodes with higher correlations than the nodes across other modularity classes one node represents a single microcystis genotype or environmental variable while degree centrality represents the number of robust correlations with other microcystis genotypes and environmental variables betweenness centrality is the number of shortest paths going through a node while closeness centrality is the number of shortest steps to access all other nodes in the network for a given node liu et al 2019 high node degree centrality and closeness centrality along with low betweenness centrality were used to identify keystone taxa within networks berry widder 2014 keystone taxa are those that exert large influences on community structure and integrity regardless of their abundances across space and time dunne et al 2002 lynch neufeld 2015 3 results and discussion 3 1 succession of microcystis genotypes over decades a total of 11 932 microcystis genotypes and 677 924 sequences were retained among the 26 total samples spanning the time period from 1944 to 2015 the lacustrine stratified sediments from the central site of the lake as ideal archives for the preservation of the cumulative environmental dna footprint are representative of the succession of aquatic ecosystem from a paleolimnological perspective domaizon et al 2017 zhang et al 2018 keck et al 2020 while the biases of dna degradation with sediment age are of concern for reconstruction of lake phytoplankton community in palaeo genetic studies including degradation by endogenous nucleases oxidation damage dna crosslinks and hydrolysis damage savichtcheva et al 2015 capo et al 2016 monchamp et al 2016 recent works have demonstrated sedimentary dna preserved well in cold anoxic aquatic sedimentary environments and successfully reconstructed the temporal changes of micro eukaryotic assemblages or phytoplankton communities and their response to anthropogenic activities and climate change savichtcheva et al 2015 monchamp et al 2016 zhang et al 2018 keck et al 2020 no significant signal of preferential dna degradation was observed in our dataset such as the abrupt disappearance of specific microcystis genotypes with sediment age fig 1 therefore dna degradation is likely a marginal confounding variable to affect the relative quantitative reconstruction of microcystis population on a 100 year time scale according to the previous research on lacustrine palaeo genetic studies even though sediment dna cannot be used to accurately quantify the historical populations monchamp et al 2016 domaizon et al 2017 keck et al 2020 microcystis genotypes in each sample accounted for over 99 of the total sequences obtained from lake chaohu sediments by amplification using microcystis specific its region primers table s1 a similar high fidelity of pcr and sequencing yields were previously observed for samples obtained from the yuqiao reservoir wherein 99 29 of microcystis genotypes were generated among the total sequence dataset huo et al 2018 moreover the species accumulation curve indicated that the sequencing data were sufficient to cover most microcystis genotypes fig s2 thus the hts analysis framework is well suited to identify microcystis populations and investigate comprehensive microcystis genetic diversity after sub sampling to normalize sequencing efforts across samples and facilitate comparison a total of 11 932 microcystis genotypes one nt difference were identified in lake chaohu indicating much higher microcystis genetic diversity than observed with cloning based methods that identified a total of 618 genotypes liu et al 2016 microcystis its sequences exhibit extremely high genetic diversity in its sequences with eight observed hyper variable regions van gremberghe et al 2011 microcystis species also exhibit flexible genomes and integrate genes from other individuals in addition to recombining within populations resulting in the generation and maintenance of high genetic diversity within microcystis populations zhang et al 2016 tanabe et al 2004 tanabe et al 2011 diverse genotypes were identified in lake chaohu across decades with the 15 most abundant genotypes being analyzed further fig 1 among these the microcystis genotype otu17743 dominated across decades regardless of whether microcystis blooms were present fig 1 a previous study observed that the t1 genotype was persistent and dominant across an entire year suggesting that this dominant genotype was potentially primarily responsible for triggering blooms in lake taihu liu et al 2016 significant changes in microcystis populations were detected in the 1960 s using constrained sums of squares cluster analysis coniss fig 1 this could be due to the disturbance from dam construction in 1963 that would have led to changes in dominant microcystis genotypes for example three dominant genotypes coexisted in 1952 otu17743 otu5010 and otu8165 while the dominant genotype otu17743 was replaced by otu16098 in 1964 fig 1 a high number of microcystis genotypes n 339 were shared among years and were dominant comprising 52 3 of all populations fig 2 unique genotypes in each sample ranged from 15 to 125 representing a significantly lower number than that of shared genotypes suggesting that microcystis genotypes in lake chaohu were relatively stable and persisted across years the alpha diversity of microcystis genotypes significantly increased across time in lake chaohu as noted by the number of genotypes r2 0 342 p 0 001 the margalef richness index r2 0 342 p 0 001 and the shannon wiener diversity index r2 0 111 p 0 05 fig 3 an inflection point of alpha diversity was observed in 1964 based on bayesian change point analysis suggesting that dam construction in 1963 led to decreased microcystis genotype diversity fig 3 in addition three distinct historical phases of microcystis genotypes were identified by mrt analysis corresponding to 1944 1960 1964 1973 and 1976 2015 fig 4 a these time periods were used as groups for subsequent anosim test based on bray curtis distances to reveal significant differences among the three historical phases r 0 389 p 0 01 fig 4b thus both the alpha and beta diversity of microcystis genotypes were altered by environmental disturbances associated with dam construction in 1963 suggesting that hydrological condition played a critical role in influencing microcystis genotype diversity in lake chaohu by affecting both population compositions and genotype diversity liu et al 2016 bi et al 2019 a previous study of cyanobacterial succession in chaohu lake also suggested that dam construction caused rapid changes in the diversity and structures of cyanobacterial communities zhang et al 2021 in contrast to the observation that changes in cyanobacterial species diversity lagged behind those of community composition zhang et al 2021 the genotypic diversity and structures of microcystis populations synchronously changed in this study figs 3 and 4 following the fluctuations in diversity associated with dam construction in the 1960 s significant increases in microcystis genotypic diversity were detected by bayesian change point analysis in 1973 and 1976 fig 3 that could be related to increased nutrient loading following the 1970 s zan et al 2012 3 2 nitrogen enrichment and hydrodynamics drive succession of microcystis genotypes the temporal succession of microcystis genotypes in lake chaohu could be driven by many factors including damming nutrient enrichment and climate warming harke et al 2016 paerl et al 2015 owing to the lack of long term monitoring physicochemical data sedimentary tn tp tn tp ratios and toc were used to reconstruct variation in the historical trophic states of lake chaohu fig s3 in addition average particle size was used to represent changes in hydrodynamic conditions such as velocity caused by dam construction while average annual temperature year t and the average temperatures for spring sp t summer su t autumn au t and winter wi t were used to investigated climate warming zan et al 2012 zhang et al 2021 among all 11 of the measured environmental variables tn the tn tp ratio and sediment particle size were all significantly associated with the composition of microcystis genotypes in lake chaohu fig 5 in addition five environmental variables including tn tp the tn tp ratio average particle size and mean temperature in winter wi t were significantly associated with variation in microcystis genotype composition based on distlm analysis table 1 the five environmental variables explained 64 7 of the variation in microcystis genotype composition using db rda analysis fig 6 table s2 nutrient enrichment has been implicated as the key driver related to the increase and maintenance of higher microcystis genotype diversity following nutrient loading in the 1970 s shang shang 2005 zan et al 2012 microcystis genotypic diversity was positively and significantly correlated with tn r2 0 304 p 0 006 and tp r2 0 221 p 0 018 increases over time these results contrasted with those from previous studies concluding that genetic diversity was negatively correlated with eutrophication level while sampling over a single year huo et al 2018 song et al 2015 moreover tn tp and the tn tp ratio all exhibited positive and strong correlations with microcystis genotype diversity during the third historical phase i e after 1976 fig 6 nutrient loading has accelerated since the 1970 s due to rapid agricultural and urbanization development in the lake chaohu catchment fig s3a b consistent with n and p enrichment influencing succession of microcystis genotype communities and increased microcystis blooms after the 1980 s shang shang 2005 zan et al 2012 zhang et al 2021 tn was significantly correlated with microcystis genotype diversity based on spearman correlation analysis and also most contributed to microcystis genotype variation based on distlm analysis i e explaining up to 7 89 of all variation fig 5 table 1 this result is consistent with those from other large lakes including taihu erie okeechobee and ponchartrain wherein n enrichment has played a key role in microcystis bloom proliferation chaffin and bridgeman 2014 paerl et al 2015 paerl huisman 2009 these dynamics are likely due in part to microcystis not being a nitrogen fixing cyanobacterial genera and requiring external nitrogen sources to support their growth schindler et al 2008 sediment particle size was strongly and positively correlated with microcystis genotype diversity and especially during the second historical phase 1964 1973 figs 5 and 6 dam construction in 1963 altered the hydrology of lake chaohu resulting in lowered discharge to the lake and decreased water exchange between the lake and the yangtze river particle size markedly decreased after dam construction fig s3e wherein fine grain fractions increased and coarse grain fractions decreased zan et al 2012 changes in particle sizes were also likely associated with the population dynamics of some cyanobacterial taxa because fine grain particle sizes 4 μm and 4 8 μm have been shown to be significantly and positively correlated with microcystis relative abundances zhang et al 2021 dam construction can lead to increased water residence times nutrient retention and sediment trapping ultimately amplifying primary production activities maavara et al 2015 stone 2016 consequently our results are consistent with dam construction playing a critical role in the succession of microcystis genotypes in lake chaohu by slowing down hydrological conditions and accelerating nutrient retention maavara et al 2015 the annual average air temperature and the temperatures for each of the four seasons significantly increased during the 1940 s 2010 s fig s3f i and were significantly correlated with microcystis genotype diversity fig 5 suggesting that temperature partially influenced the succession of microcystis genotypes in lake chaohu this is consistent with results from a previous study wherein increased hydraulic retention times and nutrients primarily drove decadal changes in cyanobacterial communities in lake chaohu while increased air temperature played a lesser role zhang et al 2021 wi t exhibited a lesser correlation with microcystis genotype diversity based on marginal tests table 1 in addition wi t exhibited minimal correlations with the dbrda1 axis 0 5 but explained microcystis genotype composition variation after the 1970 s fig 6 table s2 temperature as the key catalyst of algal bloom formation hans and huisman 2008 promotes cyanobacterial blooms occurred earlier and persisted longer with the increased temperatures over the past 20 years duan and ma 2009 zhang et al 2012 leading to microcystis blooms even persisting across the entire winter in some lakes ma et al 2016 likewise winters have become warmer in sweden s three largest lakes mälaren vänern and vättern since the 1990 s resulting in earlier development of phytoplankton blooms in spring weyhenmeyer 2001 3 3 changes in the ecological co occurrence network of microcystis genotypes owing to the observation that microcystis genotype diversity and community structure shifted in 1964 the co occurrence networks of microcystis genotypes before and after dam construction were evaluated to investigate whether dam introduction influenced microcystis genotype network interactions in lake chaohu the microcystis genotype networks consisted of 943 957 953 and 959 nodes linked by 30166 46451 37722 and 31 062 edges for the four periods of 1944 1960 1973 1985 1988 1997 and 1999 2008 respectively table 2 figure s4 the proportion of negative edges increased from 23 84 in the first period to the 33 01 34 57 and 44 28 in the second third and fourth period indicating the potentially increasing non overlapping niches or antagonistic interactions newman 2006 xue et al 2018 after dam construction increased algal biomass may have led interspecies competition for limited resources though nutrient loading increased which in support of resource driven co occurrence patterns paerl et al 2015 zhang et al 2021 the weighted modularity of the networks in the four periods is 0 885 1 114 1 391 and 4 878 respectively table 2 which show that the modularity increase from 1944 to 2008 liu et al 2019 chun et al 2020 interactions among microcystis genotypes intensified after dam construction with increasing nutrient loading and these interactions are likely related to recurrent microcystis blooms that have occurred since the 1980 s in lake chaohu chun et al 2020 overall co occurrence and correlation patterns found in this high throughput dataset provided valuable information about the predication of genotypes interactions before and after dam construction however it is an underdetermined problem that the sensitivity and specificity of co occurrence networks were affected by sampling breadth i e sample number and the analysis options i e the association metric used smet and marchal 2010 faust raes 2012 berry widder 2014 the model testing of co occurrence network and the validation of ecological interpretation should be expected in the future with the constant methodological innovation and technological advances smet and marchal 2010 faust raes 2012 co occurrence patterns between microcystis population and characteristics of environment also changed dramatically over time based on correlation based network analysis figure s4 table s3 numbers of connected otus with average particle size decreased from 81 to over 30 before and after the dam construction table s3 showing a significantly decreases of microcystis genotypes impacted by hydrological condition after the dam construction bozarth et al 2010 liu et al 2016 the number of otus connected with annual average temperature increased from 37 and 29 in the first two periods to 63 in the last two periods which indicated the increased annual average temperature as an inferential variable may played a more important role in microcystis population briand et al 2009 huo et al 2018 bi et al 2019 although the co occurrence patterns represent hypothetical interactions determined by statistically it should be further studied and vigilant to the increasing trend of microcystis genotypes sensitive to temperature under climate warming harke et al 2016 liu et al 2016 network analysis have also been used to reveal keystone taxa in microbiome communities xue et al 2018 liu et al 2019 in the four networks microcystis genotypes with low abundance such as otu2830 otu1879 otu5224 and otu9349 table s4 exhibited high node degree centrality and closeness centrality but low betweenness centrality indicating that it potentially represented a keystone taxon berry widder 2014 rare microorganisms have been shown to play important roles in biogeochemical processes including in nitrification denitrification methanogenesis methanotrophy and sulfate reduction banerjee et al 2018 in contrast the dominant microcystis genotype otu17743 shared correlations with few other genotypes and contributed less to the co occurrence network of microcystis genotypes table s4 previous studies have consistently studied dominant microcystis genotypes to understand microcystis blooms bozarth et al 2010 briand et al 2009 liu et al 2016 pobel et al 2012 sabart et al 2009 xu et al 2011 however it is unclear whether the dominant microcystis genotypes were the driver underlying blooms and controlled subsequent year blooms and this requires further exploration 4 conclusion in this study we investigated the long term decadal scale succession of microcystis genotypes using hts technology higher microcystis genetic diversity was observed relative to previous studies and this allowed the comprehensive investigation and unbiased evaluation of microcystis genotype succession new insights were also obtained suggesting that the succession of microcystis genotypes was relatively stable in the face of environmental disturbance over decade scales regardless if microcystis were blooming dam construction and nutrient enrichment likely drove variation in microcystis genotype diversity by altering community composition and decreasing genotype diversity after dam construction abrupt decreases in microcystis genotype diversity were synchronous with changes in population structures microcystis genotypes also exhibited intensified interactions which likely led to recurrent microcystis blooms in lake chaohu after the 1980 s the results indicate that low abundance microcystis genotypes rather than dominant genotypes may be keystone taxa among co occurrence networks of microcystis population data availability statement the original paired end reads generated in this study have been deposited in genbank and are publicly available under the bioproject accession prjna647272 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the national natural science foundation of china no 51922010 41521003 and the national key research and development program of china 2017yfa0605003 supported this study appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127451 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3671,microcystis blooms that are caused by intensified human activities and global warming have become a challenging environmental problem in global lakes and reservoirs research has focused on microcystis genotypes to understand their proliferation and the development of blooms although knowledge gaps exist regarding how microcystis genotype succession occurs over long term time scales in this study high throughput sequencing was used to investigate decade long successional patterns of microcystis genotypes in the large shallow lake chaohu that has long suffered from microcystis blooms microcystis populations exhibited high overall genetic diversity with 11 431 genotypes and these were relatively stable over the last 70 years with 339 shared core genotypes and 1 dominant genotype microcystis genotype succession exhibited three distinct historical phases corresponding to 1944 1960 1964 1973 and 1976 2015 these successional patterns were clearly influenced by dam construction in 1963 and subsequent nutrient enrichment following the 1970 s after dam construction increased hydraulic retention times and slowing of hydrodynamic conditions influenced microcystis genotype diversity by altering population composition and decreasing genotype richness populations and dominant genotypes rapidly returned after dam construction combined with increased inferred interactions among genotypes network analysis also indicated that low abundance microcystis genotypes rather than dominant genotypes may be keystone taxa across the decadal scale co occurrence network of microcystis population keywords decadal scale genotype high throughput sequencing microcystis blooms sedimentary dna 1 introduction microcystis blooms have been observed in over 108 countries and caused widely concern due to serious threats to aquatic health and ecosystem services from toxic metabolites of microcystis e g microcystin harke et al 2016 eutrophication is the primary factor that triggers microcystis blooms although global climate warming can further promote bloom intensity and lengthen bloom periods hans and huisman 2008 understanding bloom processes and mechanisms is pivotal for predicting and controlling their occurrences although these areas have lacked resolution in recent years researchers have investigated microcystis genotype diversity primarily through sequencing internal transcribed spacer its regions between 16s and 23s rrna genes to further demonstrate their proliferation and development bozarth et al 2010 briand et al 2009 hundreds to thousands of microcystis genotypes have been observed during blooms and these can exhibit distinct physio ecological characteristics leading to their identification as different ecotypes bozarth et al 2010 huo et al 2018 however specific microcystis genotypes have been suggested to act as the primary progenitors of blooms for example the c3 genotype has been shown to dominate the entire grangent reservoir when microcystis populations reached their maximum cell numbers briand et al 2009 likewise different dominant genotypes were observed during two biomass peaks of microcystis blooms in the copco reservoir of northern california bozarth et al 2010 thus it is likely that these dominant genotypes were implicated in the formation of microcystis blooms and that the tracking of these dominant genotypes could aid in microcystis population monitoring and provide a means to identify the sources that trigger blooms briand et al 2009 huo et al 2018 however dominant genotypes have also not been observed during microcystis blooms in some ponds bi et al 2019 zhu et al 2012 and lakes pobel et al 2012 song et al 2015 implying that numerous complex factors influence the succession of microcystis genotypes denaturing gradient gel electrophoresis dgge and molecular clone sequencing methods have been traditionally used to explore microcystis genetic diversity however the limited number of genotypes obtained by these methods could result in underestimations or biases in investigations of genetic diversity mackey et al 2017 the development of high throughput sequencing hts techniques that target specific genomic regions can help overcome culture bias limitations and enable the comprehensive investigation of microbial community compositions at coverage levels that far surpass what is possible via the construction of clone libraries mackey et al 2017 huo et al 2018 first applied hts in combination with primers targeting the its region of microcystis genomes to evaluate microcystis intra species diversity within the yuqiao reservoir of the haihe river watersheds of china these studies have shown that microcystis populations can be extremely diverse comprising up to 2 005 genotypes when clustering at the 97 nucleotide nt sequence identity level this number far surpasses that which is achieved i e 618 genotypes using cloning based methods when defining a single base pair variant as a unique genotype liu et al 2016 temporal studies of microcystis genotypes have spanned ranges of up to two years zhu et al 2012 but longer decadal scale investigations not been performed sediment archives can provide long term records of biological community compositions via fossil dnas domaizon et al 2017 lake chaohu is located in middle and lower reaches of the yangtze river and has suffered serious eutrophication in recent decades due to increasing inputs of nutrients from agricultural development and urbanization li et al 2015 zan et al 2012 accordingly cyanobacterial blooms have formed throughout the entire lake from may to november every year since the 1980 s deng et al 2007 hts analysis of paleo environmental dna subsequently indicated that microcystis and cyanobium pico cyanobacteria were the predominant cyanobacterial taxa within the lake between the 1930 s to 2010 s zhang et al 2021 consequently lake chaohu is an ideal system to investigate the succession of microcystis genetic diversity over decadal scales and in response to anthropogenic activities and climate change such studies will enable a more comprehensive understanding of bloom proliferation and development to our knowledge the present study represents the first long term scale investigation of microcystis genotype succession within a eutrophic lake that has suffered a long history of microcystis blooms li et al 2015 zan et al 2012 in particular we investigated the succession of microcystis genotypes over 70 years using sedimentary dna sequencing and hypothesized that changes in genotypic diversity were driven by altered nutrient enrichment and hydrological conditions from dam construction the main objectives of the study were to 1 reconstruct the temporal succession of microcystis genotype diversity and associated variation over decades 2 identify key environmental variables that drive the succession of microcystis genotype diversity and 3 identify key genotypes and associations between different microcystis genotypes this study provides new insights into the mechanisms of microcystis blooms from a long term perspective of microcystis genotype succession 2 materials and methods 2 1 sediment sampling and processing lake chaohu 117 16 117 51 e 31 25 31 43 n fig s1 is the fifth largest freshwater in china and has a mean depth of 3 0 m and a surface area of 780 km2 a sediment core was collected away from lake banks stream inlets in order to avoid confounding observations due to the disturbance of sediment by sourcing or re suspension in december 2017 using a gravity corer fitted with a pmma tube inner diameter 8 cm length 50 cm the sample site was located in the central basin of the eastern lake and away from lake banks outlets and inflowing streams to avoid confounding sediment disturbances fig s1 the core was subsectioned at 1 cm intervals and divided into 30 subsamples followed by dating using 137cs and 210pb fallout radionuclides as described in detail in our previous studies zan et al 2012 zhang et al 2018 paleo physicochemical variables including total nitrogen tn total phosphorus tp total organic carbon toc and particle sizes were also measured as previously described zan et al 2012 zhang et al 2018 historical air temperature data were extracted from the cn05 1 dataset that was constructed using the anomaly approach during interpolation but with more station observation 2 400 in china zhang et al 2018 2 2 high throughput sequencing dna was extracted from 30 sediment subsamples using a powersoil dna isolation kit mo bio laboratories usa following the manufacturer s protocols dna concentrations and purity were evaluated using a nanodrop spectrophotometer nd 1000 nanodrop technologies usa the bottom three subsamples that failed to pass quality control measures were removed while the uppermost subsample was also removed from further analysis the remaining 26 subsamples were used to construct amplicon libraries libraries were prepared via polymerase chain reaction pcr amplification of its regions targeting microcystis populations with the primers htsits f 5 aagggagacctaattcrggta 3 and 340 5 cctctgtgtgcctaggtatcc 3 iteman et al 2000 huo et al 2018 reactions were performed in a total reaction volume of 20 μl and were subjected to denaturation at 95 c for 5 min followed by 20 cycles of 95 c for 30 s 55 c for 30 s and 72 c for 40 s all followed by a final extension at 72 c for 10 min pcr products were purified with an e z n a gel extraction kit omega america and sequenced on the illumina hiseq 2500 platform 2 250 paired ends at biomarker technologies china 2 3 identification of genotypes paired end reads were merged using flash v1 2 7 http ccb jhu edu software flash then quality filtered using trimmomatic v0 33 bolger et al 2014 amplicon sequence variants asvs were then generated using the dada2 algorithm based on one nt difference between sequences callahan et al 2016 the blast search tool was used to assign the taxonomy of asvs by comparison against the nt database of ncbi lobo 2012 thresholds including a sequence similarity of 90 and a coverage of 90 were used to select asvs that belonged to microcystis after comparison against reference microcystis sequences to minimize sequencing errors singletons doubletons and tripletons microcystis asvs with one two or three sequences respectively were eliminated across the whole dataset and a subset of 26 074 sequences were sub sampled from each sample based on the minimum number of sequences within samples to normalize sequencing efforts and allow for comparison across samples with the vegan r package each microcystis asv was treated as a single genotype 2 4 statistical analyses alpha diversity indices including the overall number of microcystis genotypes margalef richness and the shannon wiener diversity index were calculated using the primer v7 program clarke gorley 2015 a flower plot was also constructed to visualize the number of common and unique genotypes among and within the samples using the plotrix r package bayesian change point analysis was used to identify inflection points for alpha diversity over time using the bcp r package to further explore the timing and hierarchy of significant changes in population structure multivariate regression tree mrt analysis was performed using the mvpart package for r the anosim r statistic was calculated to reflect the degree of separation among groups with r 1 indicating complete separation and r 0 suggesting no separation spearman s rank correlations were calculated among environmental variables using the corrplot r package while mantel tests were used to investigate correlations between microcystis genotypes and environmental variables using the vegan r package distance based linear models distlms were used to quantitatively assess population variation in association with environmental variables and were visualized using a distance based redundancy analysis dbrda ordination plot dbrda plots were constrained to identify linear combinations of predictor variables that explained the greatest amount of variation in data prior to the analysis environmental variables were log x 1 transformed and genotype abundances were standardized then square root transformed dbrda and distlms analyses were all performed within the primer v7 software package clarke gorley 2015 to reduce noise and false positive predictions microcystis genotypes with relative mean abundances 0 01 and presence in 1 3 of samples were selected for network analyses spearman rank correlations were used to explore relationships among microcystis genotypes and environmental variables using the hmisc r package with correlation p value corrections using a benjamini hochberg standard false discovery rate correction benjamini hochberg 1995 only robust r 0 8 and significant p 0 05 correlations were incorporated into network analyses significant changes of alpha and beta diversity of microcystis genotypes were identified in 1964 just after dam construction in year 1963 and thus four networks were constructed for before years 1944 1960 and after years 1973 1985 1988 1997 and 1999 2008 dam construction to investigate whether dam construction affected the diversity and succession of microcystis genotypes to ensure the comparability of network topology features the same sample size was used to construct each network network visualizations were conducted using the gephi v0 9 2 software package with the fruchterman reingold placement algorithm network modularity classes and node level topological properties including degree betweenness centrality and closeness centrality were all also calculated within the gephi program a modularity class represents a sub community of a network and is composed of highly inter connected nodes with higher correlations than the nodes across other modularity classes one node represents a single microcystis genotype or environmental variable while degree centrality represents the number of robust correlations with other microcystis genotypes and environmental variables betweenness centrality is the number of shortest paths going through a node while closeness centrality is the number of shortest steps to access all other nodes in the network for a given node liu et al 2019 high node degree centrality and closeness centrality along with low betweenness centrality were used to identify keystone taxa within networks berry widder 2014 keystone taxa are those that exert large influences on community structure and integrity regardless of their abundances across space and time dunne et al 2002 lynch neufeld 2015 3 results and discussion 3 1 succession of microcystis genotypes over decades a total of 11 932 microcystis genotypes and 677 924 sequences were retained among the 26 total samples spanning the time period from 1944 to 2015 the lacustrine stratified sediments from the central site of the lake as ideal archives for the preservation of the cumulative environmental dna footprint are representative of the succession of aquatic ecosystem from a paleolimnological perspective domaizon et al 2017 zhang et al 2018 keck et al 2020 while the biases of dna degradation with sediment age are of concern for reconstruction of lake phytoplankton community in palaeo genetic studies including degradation by endogenous nucleases oxidation damage dna crosslinks and hydrolysis damage savichtcheva et al 2015 capo et al 2016 monchamp et al 2016 recent works have demonstrated sedimentary dna preserved well in cold anoxic aquatic sedimentary environments and successfully reconstructed the temporal changes of micro eukaryotic assemblages or phytoplankton communities and their response to anthropogenic activities and climate change savichtcheva et al 2015 monchamp et al 2016 zhang et al 2018 keck et al 2020 no significant signal of preferential dna degradation was observed in our dataset such as the abrupt disappearance of specific microcystis genotypes with sediment age fig 1 therefore dna degradation is likely a marginal confounding variable to affect the relative quantitative reconstruction of microcystis population on a 100 year time scale according to the previous research on lacustrine palaeo genetic studies even though sediment dna cannot be used to accurately quantify the historical populations monchamp et al 2016 domaizon et al 2017 keck et al 2020 microcystis genotypes in each sample accounted for over 99 of the total sequences obtained from lake chaohu sediments by amplification using microcystis specific its region primers table s1 a similar high fidelity of pcr and sequencing yields were previously observed for samples obtained from the yuqiao reservoir wherein 99 29 of microcystis genotypes were generated among the total sequence dataset huo et al 2018 moreover the species accumulation curve indicated that the sequencing data were sufficient to cover most microcystis genotypes fig s2 thus the hts analysis framework is well suited to identify microcystis populations and investigate comprehensive microcystis genetic diversity after sub sampling to normalize sequencing efforts across samples and facilitate comparison a total of 11 932 microcystis genotypes one nt difference were identified in lake chaohu indicating much higher microcystis genetic diversity than observed with cloning based methods that identified a total of 618 genotypes liu et al 2016 microcystis its sequences exhibit extremely high genetic diversity in its sequences with eight observed hyper variable regions van gremberghe et al 2011 microcystis species also exhibit flexible genomes and integrate genes from other individuals in addition to recombining within populations resulting in the generation and maintenance of high genetic diversity within microcystis populations zhang et al 2016 tanabe et al 2004 tanabe et al 2011 diverse genotypes were identified in lake chaohu across decades with the 15 most abundant genotypes being analyzed further fig 1 among these the microcystis genotype otu17743 dominated across decades regardless of whether microcystis blooms were present fig 1 a previous study observed that the t1 genotype was persistent and dominant across an entire year suggesting that this dominant genotype was potentially primarily responsible for triggering blooms in lake taihu liu et al 2016 significant changes in microcystis populations were detected in the 1960 s using constrained sums of squares cluster analysis coniss fig 1 this could be due to the disturbance from dam construction in 1963 that would have led to changes in dominant microcystis genotypes for example three dominant genotypes coexisted in 1952 otu17743 otu5010 and otu8165 while the dominant genotype otu17743 was replaced by otu16098 in 1964 fig 1 a high number of microcystis genotypes n 339 were shared among years and were dominant comprising 52 3 of all populations fig 2 unique genotypes in each sample ranged from 15 to 125 representing a significantly lower number than that of shared genotypes suggesting that microcystis genotypes in lake chaohu were relatively stable and persisted across years the alpha diversity of microcystis genotypes significantly increased across time in lake chaohu as noted by the number of genotypes r2 0 342 p 0 001 the margalef richness index r2 0 342 p 0 001 and the shannon wiener diversity index r2 0 111 p 0 05 fig 3 an inflection point of alpha diversity was observed in 1964 based on bayesian change point analysis suggesting that dam construction in 1963 led to decreased microcystis genotype diversity fig 3 in addition three distinct historical phases of microcystis genotypes were identified by mrt analysis corresponding to 1944 1960 1964 1973 and 1976 2015 fig 4 a these time periods were used as groups for subsequent anosim test based on bray curtis distances to reveal significant differences among the three historical phases r 0 389 p 0 01 fig 4b thus both the alpha and beta diversity of microcystis genotypes were altered by environmental disturbances associated with dam construction in 1963 suggesting that hydrological condition played a critical role in influencing microcystis genotype diversity in lake chaohu by affecting both population compositions and genotype diversity liu et al 2016 bi et al 2019 a previous study of cyanobacterial succession in chaohu lake also suggested that dam construction caused rapid changes in the diversity and structures of cyanobacterial communities zhang et al 2021 in contrast to the observation that changes in cyanobacterial species diversity lagged behind those of community composition zhang et al 2021 the genotypic diversity and structures of microcystis populations synchronously changed in this study figs 3 and 4 following the fluctuations in diversity associated with dam construction in the 1960 s significant increases in microcystis genotypic diversity were detected by bayesian change point analysis in 1973 and 1976 fig 3 that could be related to increased nutrient loading following the 1970 s zan et al 2012 3 2 nitrogen enrichment and hydrodynamics drive succession of microcystis genotypes the temporal succession of microcystis genotypes in lake chaohu could be driven by many factors including damming nutrient enrichment and climate warming harke et al 2016 paerl et al 2015 owing to the lack of long term monitoring physicochemical data sedimentary tn tp tn tp ratios and toc were used to reconstruct variation in the historical trophic states of lake chaohu fig s3 in addition average particle size was used to represent changes in hydrodynamic conditions such as velocity caused by dam construction while average annual temperature year t and the average temperatures for spring sp t summer su t autumn au t and winter wi t were used to investigated climate warming zan et al 2012 zhang et al 2021 among all 11 of the measured environmental variables tn the tn tp ratio and sediment particle size were all significantly associated with the composition of microcystis genotypes in lake chaohu fig 5 in addition five environmental variables including tn tp the tn tp ratio average particle size and mean temperature in winter wi t were significantly associated with variation in microcystis genotype composition based on distlm analysis table 1 the five environmental variables explained 64 7 of the variation in microcystis genotype composition using db rda analysis fig 6 table s2 nutrient enrichment has been implicated as the key driver related to the increase and maintenance of higher microcystis genotype diversity following nutrient loading in the 1970 s shang shang 2005 zan et al 2012 microcystis genotypic diversity was positively and significantly correlated with tn r2 0 304 p 0 006 and tp r2 0 221 p 0 018 increases over time these results contrasted with those from previous studies concluding that genetic diversity was negatively correlated with eutrophication level while sampling over a single year huo et al 2018 song et al 2015 moreover tn tp and the tn tp ratio all exhibited positive and strong correlations with microcystis genotype diversity during the third historical phase i e after 1976 fig 6 nutrient loading has accelerated since the 1970 s due to rapid agricultural and urbanization development in the lake chaohu catchment fig s3a b consistent with n and p enrichment influencing succession of microcystis genotype communities and increased microcystis blooms after the 1980 s shang shang 2005 zan et al 2012 zhang et al 2021 tn was significantly correlated with microcystis genotype diversity based on spearman correlation analysis and also most contributed to microcystis genotype variation based on distlm analysis i e explaining up to 7 89 of all variation fig 5 table 1 this result is consistent with those from other large lakes including taihu erie okeechobee and ponchartrain wherein n enrichment has played a key role in microcystis bloom proliferation chaffin and bridgeman 2014 paerl et al 2015 paerl huisman 2009 these dynamics are likely due in part to microcystis not being a nitrogen fixing cyanobacterial genera and requiring external nitrogen sources to support their growth schindler et al 2008 sediment particle size was strongly and positively correlated with microcystis genotype diversity and especially during the second historical phase 1964 1973 figs 5 and 6 dam construction in 1963 altered the hydrology of lake chaohu resulting in lowered discharge to the lake and decreased water exchange between the lake and the yangtze river particle size markedly decreased after dam construction fig s3e wherein fine grain fractions increased and coarse grain fractions decreased zan et al 2012 changes in particle sizes were also likely associated with the population dynamics of some cyanobacterial taxa because fine grain particle sizes 4 μm and 4 8 μm have been shown to be significantly and positively correlated with microcystis relative abundances zhang et al 2021 dam construction can lead to increased water residence times nutrient retention and sediment trapping ultimately amplifying primary production activities maavara et al 2015 stone 2016 consequently our results are consistent with dam construction playing a critical role in the succession of microcystis genotypes in lake chaohu by slowing down hydrological conditions and accelerating nutrient retention maavara et al 2015 the annual average air temperature and the temperatures for each of the four seasons significantly increased during the 1940 s 2010 s fig s3f i and were significantly correlated with microcystis genotype diversity fig 5 suggesting that temperature partially influenced the succession of microcystis genotypes in lake chaohu this is consistent with results from a previous study wherein increased hydraulic retention times and nutrients primarily drove decadal changes in cyanobacterial communities in lake chaohu while increased air temperature played a lesser role zhang et al 2021 wi t exhibited a lesser correlation with microcystis genotype diversity based on marginal tests table 1 in addition wi t exhibited minimal correlations with the dbrda1 axis 0 5 but explained microcystis genotype composition variation after the 1970 s fig 6 table s2 temperature as the key catalyst of algal bloom formation hans and huisman 2008 promotes cyanobacterial blooms occurred earlier and persisted longer with the increased temperatures over the past 20 years duan and ma 2009 zhang et al 2012 leading to microcystis blooms even persisting across the entire winter in some lakes ma et al 2016 likewise winters have become warmer in sweden s three largest lakes mälaren vänern and vättern since the 1990 s resulting in earlier development of phytoplankton blooms in spring weyhenmeyer 2001 3 3 changes in the ecological co occurrence network of microcystis genotypes owing to the observation that microcystis genotype diversity and community structure shifted in 1964 the co occurrence networks of microcystis genotypes before and after dam construction were evaluated to investigate whether dam introduction influenced microcystis genotype network interactions in lake chaohu the microcystis genotype networks consisted of 943 957 953 and 959 nodes linked by 30166 46451 37722 and 31 062 edges for the four periods of 1944 1960 1973 1985 1988 1997 and 1999 2008 respectively table 2 figure s4 the proportion of negative edges increased from 23 84 in the first period to the 33 01 34 57 and 44 28 in the second third and fourth period indicating the potentially increasing non overlapping niches or antagonistic interactions newman 2006 xue et al 2018 after dam construction increased algal biomass may have led interspecies competition for limited resources though nutrient loading increased which in support of resource driven co occurrence patterns paerl et al 2015 zhang et al 2021 the weighted modularity of the networks in the four periods is 0 885 1 114 1 391 and 4 878 respectively table 2 which show that the modularity increase from 1944 to 2008 liu et al 2019 chun et al 2020 interactions among microcystis genotypes intensified after dam construction with increasing nutrient loading and these interactions are likely related to recurrent microcystis blooms that have occurred since the 1980 s in lake chaohu chun et al 2020 overall co occurrence and correlation patterns found in this high throughput dataset provided valuable information about the predication of genotypes interactions before and after dam construction however it is an underdetermined problem that the sensitivity and specificity of co occurrence networks were affected by sampling breadth i e sample number and the analysis options i e the association metric used smet and marchal 2010 faust raes 2012 berry widder 2014 the model testing of co occurrence network and the validation of ecological interpretation should be expected in the future with the constant methodological innovation and technological advances smet and marchal 2010 faust raes 2012 co occurrence patterns between microcystis population and characteristics of environment also changed dramatically over time based on correlation based network analysis figure s4 table s3 numbers of connected otus with average particle size decreased from 81 to over 30 before and after the dam construction table s3 showing a significantly decreases of microcystis genotypes impacted by hydrological condition after the dam construction bozarth et al 2010 liu et al 2016 the number of otus connected with annual average temperature increased from 37 and 29 in the first two periods to 63 in the last two periods which indicated the increased annual average temperature as an inferential variable may played a more important role in microcystis population briand et al 2009 huo et al 2018 bi et al 2019 although the co occurrence patterns represent hypothetical interactions determined by statistically it should be further studied and vigilant to the increasing trend of microcystis genotypes sensitive to temperature under climate warming harke et al 2016 liu et al 2016 network analysis have also been used to reveal keystone taxa in microbiome communities xue et al 2018 liu et al 2019 in the four networks microcystis genotypes with low abundance such as otu2830 otu1879 otu5224 and otu9349 table s4 exhibited high node degree centrality and closeness centrality but low betweenness centrality indicating that it potentially represented a keystone taxon berry widder 2014 rare microorganisms have been shown to play important roles in biogeochemical processes including in nitrification denitrification methanogenesis methanotrophy and sulfate reduction banerjee et al 2018 in contrast the dominant microcystis genotype otu17743 shared correlations with few other genotypes and contributed less to the co occurrence network of microcystis genotypes table s4 previous studies have consistently studied dominant microcystis genotypes to understand microcystis blooms bozarth et al 2010 briand et al 2009 liu et al 2016 pobel et al 2012 sabart et al 2009 xu et al 2011 however it is unclear whether the dominant microcystis genotypes were the driver underlying blooms and controlled subsequent year blooms and this requires further exploration 4 conclusion in this study we investigated the long term decadal scale succession of microcystis genotypes using hts technology higher microcystis genetic diversity was observed relative to previous studies and this allowed the comprehensive investigation and unbiased evaluation of microcystis genotype succession new insights were also obtained suggesting that the succession of microcystis genotypes was relatively stable in the face of environmental disturbance over decade scales regardless if microcystis were blooming dam construction and nutrient enrichment likely drove variation in microcystis genotype diversity by altering community composition and decreasing genotype diversity after dam construction abrupt decreases in microcystis genotype diversity were synchronous with changes in population structures microcystis genotypes also exhibited intensified interactions which likely led to recurrent microcystis blooms in lake chaohu after the 1980 s the results indicate that low abundance microcystis genotypes rather than dominant genotypes may be keystone taxa among co occurrence networks of microcystis population data availability statement the original paired end reads generated in this study have been deposited in genbank and are publicly available under the bioproject accession prjna647272 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the national natural science foundation of china no 51922010 41521003 and the national key research and development program of china 2017yfa0605003 supported this study appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127451 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3672,dew point temperature tdew plays an important role in hydrology meteorology and other related research this study evaluated the ability of a new machine learning model hybrid extreme gradient boosting with grasshopper optimization algorithm goa xgboost to estimate tdew and compared it with two other tree based models xgboost and random forest rf we collected meteorological data namely actual vapor pressure ea maximum air temperature tmax minimum air temperature tmin maximum relative humidity rhmax minimum relative humidity rhmin atmospheric pressure pa 2 m high wind speed ud during 2016 2019 on daily and hourly time scales from the sijiqinglin station in china to train test and validate each model the results showed that the goa xgboost model performed best and the rf model had severe over fitting problems during the validation phase at daily time scale the models showed the best accuracy and stability when the input was ea on average r2 1 000 rmse 0 296 mbe 0 001 mae 0 167 and kge 0 991 the models had more significant errors when the inputs were tmax tmin on average r2 0 721 rmse 6 756 mbe 0 101 mae 5 071 and kge 0 771 the estimation loss exhibited by the models were similar for the hourly and daily scale patterns t and rh were the most basic meteorological factors and adding extraneous factors would affect the estimation accuracy of the model the variability of meteorological data varied less on an hourly scale than on a daily scale therefore the accuracy of the models was higher but the data set and the volume of operations became larger this led to a possible reduction in model stability but the hourly scales are better suited for assessing the effects of simulations in extreme situations taking accuracy and stability into account the goa xgboost model was the best model and the most practical input for both time scales was ea therefore in subsequent studies the goa xgboost model can be combined with the input ea to estimate tdew accurately keywords dew point temperature grasshopper optimization algorithm extreme gradient boosting time scale cross validation 1 introduction dew point temperature tdew is the temperature at which water vapor in the air condenses into water droplets baghban et al 2016 accurate tdew data is vital in different scientific fields such as hydrology meteorology and agriculture cui et al 2021 achugbu et al 2021 pumo and noto 2021 yong et al 2021 lekouch et al 2012 lawrence 2005 with the accumulation of data over time tdew can be used as an essential variable in the study of climate change kim et al 2015 robinson 2000 tdew is usually used in combination with relative humidity rh to determine the moisture content of the air lawrence 2005 it can also be used in combination with the wet bulb temperature to obtain the ambient temperature for preventing frost on the crop indirectly affecting the productivity of the crop wasko et al 2018 drezner 2007 from various perspectives it is emphasized that accurate estimation of tdew is scientifically very important in all of the above areas in recent years scholars have commonly used non parametric machine learning techniques to estimate remotes sensing and metrological parameters such as precipitation soil moisture flood volume wind etc derin et al 2020 has developed an error model the nonparametric machine learning tree based quantile regression forest qrf to reduce precipitation retrieval error all validations showed that the precipitation error model based corrections can significantly reduce both the mean relative error and the random component of passive microwave pmw products bhuiyan et al 2017 evaluated a nonparametric error model for tropical rainfall measurement mission trmm pmw rainfall product over coverage in the southern continental united states and assess the impact of surface soil moisture information on the model s performance they concluded that the error model for precipitation products performed better when near surface soil moisture was used as an input parameter aboutalebi et al 2019 applied genetic programming gp in combination with high resolution multispectral images acquired by the unmanned aerial vehicle uav to estimate soil moisture at different scales they found that the gp produced satisfactory predictions lee et al 2019 used a deep learning dl method to estimate soil moisture based on the remote sensing data the soil moisture estimated by the dl was more accurate with a high correlation coefficient of 0 89 a low root mean square error 3 825 and bias 0 039 tyralis et al 2019 proposed a post processing of quantile regression and quantile regression forest overlay on simulations of the gr4j hydrological model for 511 watersheds in the united states the results illustrated a significant improvement in its performance relative to the base learner used ahn and palmer 2016 used the quantile regression technique qrt and parameter regression technique prt to combine data from 30 basin features in the northeastern usa for quantitative estimation of floods the results indicated that the prt outperformed the qrt in terms of accuracy and simplicity of calculation since it is easier to obtain common meteorological data it is easier to obtain common meteorological data through weather stations compared to remote sensing data however obtaining tdew data is more complicated this has led to restrictions on the use of tdew ukhurebor et al 2017 in previous studies researchers have mainly used empirical equations to estimate tdew lawrence 2005 was one of the researchers to use empirical equations to establish a general mathematical relationship between tdew and rh utilizing a simple conversion equation it had been found to be quite useful for approximating the conversion for moist air rh 50 in which tdew decreases by about 1 c for every 5 decrease in rh starting at tdew equal to dry bulb temperature and rh 100 the calculation of tdew can be considered as a complicated and nonlinear regression processes that depend on many meteorological variables dong et al 2020a moreover it requires a large amount of observational data therefore it is usually difficult to establish an empirical model to accurately describing all complex and nonlinear processes especially in the absence of some key information the most obvious limitation of empirical models is that their applicability is usually regional specific moreover the variation in tdew is non linear resulting in some uncertainty in the measured data by the empirical equation deka et al 2018 people have proposed various methods to solve the problem of the incompleteness of tdew data in particular machine learning models have been used by academics to estimate multiple variables including estimating tdew due to their excellent performance in dealing with the non linear relationship between inputs and outputs huang et al 2019 fan et al 2018a hubbard et al 2003 this is mainly because they require nothing on knowledge of internal variables and provide simple solutions for non linear and multi variable functions moreover they also have a strong modeling ability for some engineering problems and natural phenomena huang et al 2019 machine learning models include adaptive neuro fuzzy inference system anfis artificial neural network ann multivariate adaptive regression splines mars support vector machine svm extreme learning machine elm etc mohammad et al 2016 employed the anfis model to estimate the tdew of kerman and tabass in iran they compared the degree of influence of multiple variables on the estimation performance of the model they concluded that water vapor pressure vp and rh were the most and least relevant variables respectively kisi et al 2013 used four models to estimate daily tdew for three stations in korea models include the generalized regression neural networks model grnnm the kohonen self organizing feature maps neural networks model ksofm anfis model with sub clustering identification anfis sc and anfis model with grid partitioning identification anfis gp the results showed that the anfis sc anfis gp and grnnm models exhibited similar accuracy and outperformed the ksofm model ann models also have been applied to estimate tdew shank et al 2008 investigated the performance of the ann model combined with meteorological data to estimate tdew at 20 stations in georgia usa and confirmed the excellent performance of the ann model in estimating tdew some scholars have also optimized ann models to estimate tdew zounemat kermani 2012 evaluated multi linear regression mlr and levenberg marquardt lm feed forward neural network lm nn at geraldton station in canada to estimate the hourly tdew ability it was found that the lm nn model would perform better than the mlr model researchers often compare svm with elm models together because the elm model has better generalization properties and faster computing speed huang et al 2015 dong et al 2020a used ten machine learning models including mars svm and elm to estimate tdew values for the yangling station in china they confirmed that the estimation stability of the elm model would be better than that of the svm and mars model in a single model deka et al 2018 applied the svm and elm models to estimate daily tdew in humid and semi arid regions of india they found that the elm model performed better than the svm model in studies estimating daily tdew some researchers had also coupled other machine learning models with elm or svm models alizamir et al 2020 investigated the ability of the kernel elm k elm mars and three different models to estimate daily tdew in parts of the us and they concluded that the k elm model had the most consistent estimation performance of the five models wong et al 2015 applied the k elm and the least squares support vector machine ls svm models for predicting engine performance and compared them the results showed that the k elm and the ls svm had a similar and good performance amirmojahedi et al 2016 coupled elm and wavelet transform wt elm wt to estimate the tdew of bandar abass situated in iran and compared it with svm and ann models they demonstrated that the combined model provided better performance than the svm and ann models the validity of the optimization model in the estimation study could be seen in the above study results however many machine learning models are more complex and require high calculation time and computing memory in their computational processes fan et al 2018a hassan et al 2017 recently many academics have been interested in decision tree based models because their arithmetic process is relatively simple but still has robust classification and regression capabilities wu et al 2019a for example the rf m5 model tree m5tree moreover they are powerful models for pattern recognition and trend detection hassan et al 2017 with higher computational efficiency for large data size compared to other machine learning models hassan et al 2017 fan et al 2018a shiri 2019 studied the rf model for estimating daily tdew in east azerbaijan northwest iran he concluded that the rf model could be successfully used to estimate tdew with good performance feng et al 2017a applied four machine learning models such as backpropagation neural networks optimized by genetic algorithm gann rf and empirical models to estimate diffuse solar radiation rd in the north china plain region the results demonstrated that the rf model had better estimation performance than traditional empirical models wu et al 2019b used the combined model kernel based non linear extension of arps decline model knea with six models including the rf model to estimate daily global solar radiation in the humid subtropical region of china the results showed that the rf model would perform slightly worse than the knea model it also demonstrated the feasibility of the combined model in estimation feng et al 2017b compared the rf and generalized regression neural networks grnn models to estimate et0 values for southwest china they confirmed that both models had better performance but the rf model would be slightly better than the grnn model qasem et al 2019 applied the gene expression programming gep m5tree and support vector regression svr models to estimate the tdew of the iranian tabriz station and showed that the m5tree model exhibited the best performance some researchers had also studied the optimization of the m5tree model ghaemi et al 2019 coupled the mars and m5tree models with the maximum overlap discrete wavelet transform modwt to form the marsmodwt and mtmodwt models to estimate the monthly pan evaporation at turkey s siirt and diyarbakir meteorological stations it was also compared with the original model they found that the estimation accuracy of both hybrid models was better than that of the mars and m5tree models recently chen and guestrin 2016 proposed a novel and efficient tree based machine learning model extreme gradient boosting xgboost the xgboost model weights and superimpose all the weak classifiers for creating strong classifiers yan et al 2021 consequently it has a substantially lower estimation error and a higher estimation accuracy in addition it prevents models from being over fitted during training and increases computational efficiency through automatic parallel computing yan et al 2021 thus it is used in various fields of data processing wu et al 2019a evaluated the modeling ability of the xgboost model for estimating et0 in jiangxi province they demonstrated that the estimation performance of the xgboost model outperformed that of the svm and m5tree models when using local data dong et al 2020b employed the xgboost model to estimate rd for five meteorological stations in china and compared it with mars and svm it was found that the xgboost model would obtain better rd estimation values it is suitable for the study of estimating tdew considering the satisfactory performance that can be obtained with the xgboost model the estimation accuracy and stability of machine learning models depend mainly on the parameters nevertheless these parameters have to be tuned during model training for the efficient application of machine learning models the grid search is mostly used for model parameter selection olatomiwa et al 2015 due to the complexity of the parameters these algorithms usually have high computational complexity and are susceptible to local minima however hybrid models can effectively improve the problem of parameter complexity wu et al 2021 wang et al 2020 traditional models have high computational complexity therefore researchers have started to consider different coupling algorithms to improve the estimation performance of the models because it can derive the optimal solution to the optimization problem and improve the computational efficiency previous studies have also confirmed the viability of the hybrid model around this time biologically inspired algorithms came to the forefront of researchers minds for instance grasshopper optimization algorithm goa saremi et al 2017 particle swarm optimization pso marini and walczak 2015 scholars coupled metaheuristic algorithms with traditional machine learning models the aim is to combine the advantages of both models to optimize complex problems and provide optimal solutions it is also effective in increasing the speed of the model s operations it solves many research based problems for researchers hamad et al 2018 hybridized goa and svm models for detecting epilepsy and compared them with pso hybrid svm pso svm they found that the epileptic rate detected by goa svm was more accurate dong et al 2021 used the goa optimized for the knea model to estimate the daily et0 values for different climate zones in china they confirmed that the goa knea model could estimate the et0 values for each climate zone more accurately and its performance was good the xgboost model has multiple parameters that need to be tuned traditional methods may get stuck in a regional optimal solution and cannot obtain a global optimal solution however there are also very limited reports on optimizing the parameters of the xgboost model especially using the goa model however as far as the authors are aware the goa xgboost model has not been applied to tdew s research in previous studies researchers had mainly analyzed tdew on a single time scale for example hourly scale daily scale weekly scale etc comparing multiple time scales simultaneously facilitates the study of the applicability in estimating tdew of the model at different time scales therefore this study attempted to bring in a goa xgboost model to estimate tdew for the sijiqinglin station in china along with xgboost and rf models to better represent the performance of each model this article estimated tdew at different time scales daily and hourly scales for the target station respectively we also compared its accuracy and stability during the training testing and validation phases finally the influence of the input meteorological factors on the estimation of tdew by each model was analyzed and the selection of the optimal model and input that is best suited to estimate tdew 2 materials and methods 2 1 studied area and meteorological data in this study we selected meteorological data from a forestry station sijiqinglin located in the town of sijiqing in the western part of haidian district beijing china to estimate tdew the coordinate is located at 116 16 e 39 57 n the altitude is 55 m the area is mountainous to the northwest and plain to the southeast groundwater resources are abundant it belongs to the temperate humid monsoon climate zone it is warm rainy and the vegetation flourishes we collected meteorological data from the sijiqinglin station during 2016 2019 at the daily and hourly time scales to train test and validate each model used meteorological data were including actual vapor pressure ea maximum air temperature tmax minimum air temperature tmin maximum relative humidity rhmax minimum relative humidity rhmin atmospheric pressure pa 2 m high wind speed ud month month and hours time the basic information and geographical location of the selected station were shown in table 1 and fig 1 the selected meteorological data were provided and quality controlled by the national meteorological information centre nmic of the china meteorological administration cma http www cma cn the time resolution is 1 h and 1d if meteorological data was missing or if the ratio of measured tdew to actual tdew was above 1 the data were further excluded seventeen inputs of meteorological variables were utilized for training the rf xgboost and goa xgboost models details of the inputs are presented in table 2 among them inputs 1 8 were the inputs in the daily scale pattern and inputs 9 17 were the inputs in the hourly scale pattern in this study we used the 5 fold cross validation method on daily and hourly time scales of data processing in order to prevent overfitting problems to avoid specificity the collected dataset may 2016 to april 2019 was randomly divided into five equal parts three pieces were selected for training one piece for testing and the other for validation the process was repeated five times so that the chosen data was different each time therefore each part of the dataset would be validated once all the computations were run on computers with 2 intel xeon cpu e5 2670 2 6 3 3 ghz and 32 gb of ram memory 2 2 machine learning models for estimating daily dew point temperature 2 2 1 random forest rf the rf model was initially designed and developed by breiman 2001 using the classification and regression tree cart it is an evolutionary version of the bagging bag algorithm in other words the idea is still bagging but with a unique twist the model is important in the use of regression and estimation because it is an integrated learning algorithm for solving high dimensional regression problems the rf model can be used with subsets by automatic bootstrapping of the data i e the bootstrap resampling technology when dealing with random binary trees a new training sample set is generated from the n original training samples by repeatedly selecting a random set of t t n samples several samples may be collected several times throughout the selection process a random subset of the training dataset will be sampled from the original dataset and used to develop the model as shown in the flowchart in fig 2 the datasets not included in the model are called out of bags oob these uncollected datasets will not be involved in fitting the model and can be used to test the estimation capability of the model given an ensemble of classifiers h 1 x h 2 x h k x and with the training dataset drawn at random from the distribution of the random vector x y the margin function is expressed as breiman 2001 1 mg x y a v k i h k x y max j y a v k i h k x j where i is the indicator function the margin measures the extent to which the average number of votes at x y for the right class exceeding the average vote for any other classes therefore the larger the difference the greater the confidence in the classification moreover the generalization error of rf is 2 p e p x y m g x y 0 for a large number of decision trees two theorems can be given following from the law of large numbers theorem 1 as the number of trees increases for almost surely all sequences θ k p e converges to 3 p x y p θ h x θ y max j i p θ h x θ j 0 the theorem demonstrates that the rf model does not over fit as the number of trees increases but produces a limiting value of the generalization error theorem 2 the upper bound for the generalization error is expressed as 4 p e ρ 1 s 2 s 2 where ρ is the mean value of the correlation s 2 is the strength theorem 2 demonstrates that increasing the strength and decreasing the correlation of individual classifiers will reduce the upper bound of the generalization error feng et al 2017b rf uses a cart decision tree as a weak learner the cart algorithm in rf is different from other traditional algorithms cart is a binary tree which also means that each non leaf node can only produce two branches if a non leaf node is multiple greater than two discrete variables the variable may be used numerous times each feature selected for use in the rf tree is randomly generated from all m features to reduce the risk of overfitting effectively unlike other decision trees each rf tree is a part of the selected feature among these features the best features are selected to divide the left and right subtrees of the decision tree thus improving the stochasticity and the generalization of the model finally the mean of all the predicted variables can be derived overall the rf model estimates the average of the final aggregated data more detailed information on the rf model can be found in breiman s research breiman 2001 2 2 2 extreme gradient boosting xgboost the xgboost model has first proposed by chen and guestrin 2016 it is a new pattern of gradient boost machines gbms it is also based on a residual optimization algorithm which wishes to build k regression trees the predicted values of the tree population are made as close as possible to the true values accuracy and have a strong generalization capability the xgboost model provides efficiency and accuracy the xgboost model has optimized the decision tree algorithm to improve the handling of the dataset the accuracy is enhanced through regularization and built in cross validation to address the overfitting problem this is achieved by simplifying the objective functions these objective functions allow combining predictive and regularization terms to achieve and maintain the fastest possible speed furthermore during the training phase the functions in the xgboost model are run and computed automatically it is thus widely used for research in areas such as estimation dong et al 2020b and classification dong et al 2018 the xgboost model is derived from the concept of boosting which combines the predictions of a set of all weak learners with special training to develop strong learners fan et al 2018b the expressions are as follows 5 f i t k 1 t f k x i f i t 1 f t x i where f k x i and f t x i are the predicted values for the k th and t th iterations of the xgboost model respectively f i t and f i t 1 are the predicted values for the t and t 1 iterations of the i th sample x i is the input variable k 1 2 t i 1 2 n to prevent overfitting problems without affecting the computational speed of the model the xgboost model can be derived as follows 6 ob j t i 1 n l f i t f i t i 1 n ω f i where ob j t is the objective function l is the loss function f i t is the true value of the t th iteration of the i th sample ω f i is the canonical term of the objective function which is given by 7 ω f β t 1 2 λ ω 2 where β and λ are regularization parameters t is the number of leaf nodes more specific details can be found in chen and guestrin s research chen and guestrin 2016 2 2 3 hybrid extreme gradient boosting with grasshopper optimization algorithm goa xgboost the grasshopper optimization algorithm was first proposed by saremi et al 2017 as an intelligent optimization algorithm the basic idea of the algorithm is inspired by the foraging behavior of grasshoppers to solve some practical optimization problems the goa algorithm has two components exploration and development like most other algorithms this ensures that the algorithm has a strong global search capability and can effectively avoid stagnation in the local optimum grasshopper populations form a network that connects all the individuals the position of each grasshopper is made coherent individuals can determine the direction of predation through other individuals in the group fig 3 represents the social interaction of grasshoppers with their comfort zones in the network grasshopper populations have repulsion and attraction forces within a specific range grasshoppers are repulsive to each other when they are too close together and the closer they are the stronger the repulsion this prevents algorithm from converging together prematurely this also improves the exploration capabilities of the algorithm however the attractive force drives them to explore unknown areas grasshoppers have a stronger gravitational pull as they move beyond comfort zones the zone is called the optimal adaptation zone when the repulsion and attraction forces on individual grasshoppers are equal at a certain distance saremi et al 2017 since the target location is unknown the location of the grasshopper in the optimal adaptation region is considered the closest position to the target the grasshopper will move in the direction of the target in the network as the grasshoppers positions are updated the suitable range area will drop adaptively to balance the global search with the local search finally the grasshoppers converge and move closer to the optimal solution dong et al 2021 the optimal solution is output as the optimal parameters of the xgboost model as an optimization of the goa model for the xgboost model assuming there are n grasshoppers in the bee colony the d dimensional position of the i th grasshopper is x i d i 1 n eqn 4 and 5 have been used to simulate the predation process of grasshoppers 8 x i d c j 1 j i n c u b d l b d 2 s x j d x i d x j x i d ij t d 9 s r α exp r l s e x p r where u b d and l b d represent the upper and lower bounds of the d th dimension s is a function that defines social forces repulsive forces and gravitation force α represents gravitational strength ls is the length scalar of gravity dij is the distance between the i th and j th grasshoppers t d represents the d dimensional position where the target is optimal solution c is a decreasing coefficient more specific details can be found in the research of saremi et al 2017 2 2 4 parameter optimization the key parameters of rf xgboost and goa xgboost models were identified by the trial and error approach and optimized by the grid search method to prevent overfitting problems all models use root mean square error rmse as the optimization function the rmse values of the five trials were finally averaged as the expected generalization error when the minimum rmse value was obtained the optimization stopped and returned the best parameters basically all parameter pairs were tried and the best performing parameters were used for model training testing and validation in this study the upper and lower limits of parameters were first determined by the trial and error method a grid was then created to search for the best combination of parameters by setting different step sizes the main parameters of the rf algorithm are the maximum depth max depth and the number of trees trees are more prone to be overfitting if they have larger maximum depths for the rf model the max depth of trees varied between 2 and 16 at 2 intervals and the number of trees ranged from 100 to 1000 at 100 intervals the key parameters of the xgboost model were identified by the trial and error method and optimized by the grid search method the max depth learning rate eta maximum number of boosting iteration nrounds and subsample ratio of the training instance subsample in xgboost models were optimized with them ranging from 1 to 15 at 5 intervals from 0 to 1 at 0 1 intervals from 50 to 500 at 50 intervals and from 0 to 1 at 0 1 intervals respectively the key parameters of the goa algorithm were the number of population and the number of iterations which were set as 50 and 500 respectively additional parameters were taken as the default values 2 2 5 model comparison and statistical error analysis in the current study we have chosen five common statistical indicators to analyze and compare the performance of each model in estimating tdew on two time scales these statistical indicators are coefficient of determination r2 root mean square error rmse mean bias error mbe mean absolute error mae and kling gupta efficiency kge the mathematical equations for each statistical indicator are described below 10 r 2 i 1 n y i m y i m y i e y i e 2 i 1 n y i m y i m 2 i 1 n y i e y i e 2 11 rmse 1 n i 1 n y i m y i e 2 12 mbe 1 n i 1 n y i m y i e 13 mae 1 n i 1 n y i m y i e 14 kge 1 r 2 1 2 i 1 n y i e y i e 2 i 1 n y i m y i m 2 1 2 y i e y i m 1 2 where yi m yi e y i m y i e and n are the estimated tdew measured tdew mean measured tdew mean estimated tdew and the number of measurements respectively choosing a higher r2 and kge value i e the closer the value is to 1 represents better performance and the regression line pair can better fit the data conversely the lower the values of rmse mae and absolute mbe the better the estimation performance of each model 3 results and discussion this paper evaluated the performance of three decision tree based models i e rf xgboost and goa xgboost for estimating tdew on daily and hourly time scales then the accuracy and stability of the models were compared and analyzed 3 1 comparison of model performance under various inputs on a daily scale this section evaluated the ability of three models to estimate tdew on a daily scale using daily meteorological data including tmax tmin rhmax rhmin month pa and ud the specific inputs were shown in inputs 1 8 in table 2 table 3 presented the statistical results of the three machine learning models for estimating the daily tdew at the sijiqinglin station during the training testing and validation phases as seen from table 3 all the developed models could estimate daily tdew well in the three phases some of the models showed good accuracy the r2 rmse mbe mae and kge of these models ranged from 0 687 to 1 000 0 047 7 359 c 0 415 0 274 c 0 034 5 701 c and 0 661 1 000 respectively among the three phases the best performing model during the training phase was the rf model on average r2 0 967 rmse 2 088 mbe 0 005 mae 1 531 and kge 0 949 and the best performing model during the testing on average r2 0 850 rmse 4 458 mbe 0 138 mae 3 363 and kge 0 845 and validation on average r2 0 853 rmse 4 159 mbe 113 mae 3 132 and kge 0 815 phases was the goa xgboost model although the goa xgboost model showed a decreasing trend in performance during the process from the training phase to the validation phase however it still had high accuracy and outperformed the other two models the performance degradation of the rf model from the training phase to the validation phase indicated that the rf model suffered from the most severe overfitting problem this was consistent with the law exhibited by shiri s 2019 estimation of daily tdew using the rf model both of which produced overfitting problems moreover dong et al 2020a found that the rf model performed slightly worse than other models during the testing phase in their study of machine learning models to estimate tdew as could be seen in table 3 the best performance was shown by the models during the validation phase when the only ea was input on average r2 1 000 rmse 0 296 mbe 0 001 mae 0 167 and kge 0 991 the three models performed very close to each other in terms of accuracy and stability the best performing model was goa xgboost1 r2 1 000 rmse 0 245 mbe 0 006 mae 0 149 and kge 0 994 it indicated that ea was the most effective meteorological factor used to estimate tdew consistent with the conclusions obtained by mehdizadeh et al 2017 who estimated tdew using tmean tmax tmin rh pa and ea as inputs for the gep model both concluded that ea was the most efficient input although it has only one variable ea is derived by converting the four variables tmax tmin rhmax and rhmin in the validation phase the estimation performance of each model would be inferior to the input ea when the inputs are tmax tmin rhmax rhmin it showed that the inputs tmax tmin rhmax and rhmin are the same as the factor necessary for ea however the former had four variable inputs making it more computationally intensive leading to a reduction in the accuracy and stability of the models regarding the types of input variables it was found that models containing both t and rh inputs would be more accurate and stable than those with other variable inputs for example the models outperformed the inputs tmax tmin and rhmin on average r2 0 981 rmse 1 757 mbe 0 209 mae 1 395 and kge 0 770 during the validation phase when the inputs were tmax tmin and pa on average r2 0 719 rmse 6 794 mbe 0 047 mae 5 145 and kge 0 798 the r2 value decreased by 26 7 and the rmse value increased by 286 7 illustrating that t and rh were the most fundamental weather factors when using machine learning models to estimate daily tdew it was found that adding the factors month pa or ud inputs did not significantly improve the performance of each model when comparing the performance of the model with several other inputs tmax tmin the performance of each model was significantly improved only when the input factor rh was increased it indicated that adding the input of rh could improve the performance of the models in estimating daily tdew in terms of mbe values the worst performer during the validation phase was the rf7 model mbe 0 308 c followed by the rf5 mbe 0 256 c and rf6 models mbe 0 252 c respectively this indicated that among the three models the tdew estimated by the rf model was severely underestimated and produced serious overfitting problems which was consistent with the conclusions obtained in the previous paper during the validation phase the estimated and measured values of daily scale tdew for the three models with eight inputs of meteorological factors were plotted by scatter plots in fig 4 and analyzed for comparison it was clear from fig 4 that the scatter from each model converged more closely to the standard line and was more evenly distributed than the other inputs when the inputs were ea or tmax tmin rhmax rhmin it showed that using the four meteorological factors tmax tmin rhmax rhmin provided high estimation accuracy in estimating daily tdew the scatter plot exhibited no clear pattern when the input was tmax tmin and was scattered haphazardly on either side of the standard line consistent with the law derived from the data in table 3 it exhibited poor accuracy the scatter plot was still scattered when the factors month pa or ud were added to the input of tmax tmin the accuracy of the model did not increase significantly but partly decreased conversely increasing the input factor rh greatly enhanced the model s accuracy it indicated that pa month and ud were not necessary factors in estimating daily tdew instead increasing the input independent meteorological factors reduced the estimation performance of the model the worst performing model was the rf8 model in fig 4 r2 0 687 the best performers were the rf1 xgboost1 and goa xgboost1 models all with r2 values of 1 000 fig 5 showed the box plots derived from the difference between the measured daily tdew and the three machine learning models estimated values of daily tdew for eight inputs during the validation phase there was little difference in performance between the models by the median value the models goa xgboost1 xgboost1 and rf1 models performed best with the input ea followed by the inputs tmax tmin rhmax and tmax tmin rhmin from the point of view of the quartiles and the extremes this law remained the ea was shown once again to be the most effective meteorological factor when estimating tdew the estimated tdew from the models was significantly biased for the other five inputs the difference was not significant from the perspective of the quartiles however from an extreme value perspective the model did not simulate the standard extreme values well for any five inputs as could be seen from the box plots the best performing model was still the goa xgboost model and the highest performing input was ea 3 2 comparison of model performance under various inputs on an hourly scale this section compared the ability of the models to estimate tdew on hourly scales in terms of meteorological factors the hourly scale had one more time factor than the type of factor used to estimate tdew in the daily scale pattern the specific inputs were shown in inputs 9 17 in table 2 table 4 presented the statistical results of the estimated hourly tdew for the three machine learning models during the training testing and validation phases in the three phases the laws exhibited were generally consistent with those obtained in table 3 still ea was the most effective meteorological input for estimating tdew the difference was that the accuracy and stability of the models were very close during the validation phase for the input ea tmax tmin rhmax tmax tmin rhmin and tmax tmin rhmax rhmin on average r2 1 000 rmse 0 246 kge 0 992 r2 0 998 rmse 0 548 kge 0 998 r2 0 998 rmse 0 568 kge 0 998 r2 1 000 rmse 0 256 kge 0 997 respectively it showed that the variation in the meteorological data for temperature and humidity was not significant and remained almost identical in the hourly scale model this resulted in the high accuracy and stability of the model at this time it was also confirmed that t and rh were the most basic meteorological factors for estimating tdew comparing the estimation performance of each model for the validation phase with inputs of tmax tmin month and tmax tmin time the former was found to have an 8 2 increase in r2 values over the latter it indicated that the factor month was more important than time in estimating hourly tdew this could be due to the factor month having less data than time making the model less computationally intensive with less error and improved accuracy in table 4 it was clear that the goa xgboost model was still the optimal model in estimating the hourly tdew application the scatter plots of the estimated and measured hourly tdew values for the three models for eight omitted input of tmax tmin rhmin meteorological inputs were plotted in fig 6 for the validation phase the figure showed that the scatter was very close to the standard line and more evenly distributed when the input factor contained ea or t and rh factors it was suggested that the factors t and rh had an important role in estimating hourly tdew and could improve the model s performance the scatter obtained from the other inputs was very dispersed with no obvious rule the worst performing of these was the rf10 model r2 0 650 the input at this point was tmax tmin while this input of data was easily accessible the lack of a variety of variables required would reduce the accuracy of the model estimates as observed in fig 6 it was generally the goa xgboost model that would have a more uniform it concentrated scatter distribution than the other two models for the same input it indicated that the estimation performance of the goa xgboost model would be better than the other two models it also demonstrated that the hybrid model would better estimate performance and validity in estimation than some common models this was also consistent with the law obtained by wu et al 2019b using the hybrid model knea categorical boosting catboost and rf models to estimate solar radiation moreover amirmojahedi et al 2016 coupled elm with wt to estimate daily tdew and found that the hybrid model estimation performance would also outperform the single elm model fig 7 presented a box plot of the difference between the measured hourly tdew values and the estimated value from the three machine learning models for nine inputs during the validation phase as a whole from fig 7 the same inputs corresponding to each model had similar distribution laws for their box plots in terms of median quartiles and extreme values the performance law was the same as in fig 5 the individual models performed best with the input ea this was followed by tmax tmin rhmax rhmin tmax tmin rhmax and tmax tmin rhmin the box plot law of the model was very close for the four inputs because they both contain the factors t and rh as input at this point there was not much variation between the various meteorological data at the hourly scale leading to very high accuracy in all of the models akhlaghi et al 2021 the models exhibited a similar rule to fig 5 for several other inputs overall it was still clear from the figure that the performance ranking of the models was goa xgboost xgboost rf 3 3 compare daily and hourly model statistical indicators for different inputs to be able to compare better the performance of each model in estimating tdew for both daily and hourly scale patterns fig 8 integrated and compared the values of the statistical indicators for the two time scales during the validation phase the dotted line was the best standard line as shown in the figure the goa xgboost model performed relatively better from the point of view of rmse values which were both relatively small for the same input the rmse values of the models for inputs 1 9 13 14 and 15 converged to 0 and the models were stable the worst performer was the rf10 model rmse 8 494 c and the goa xgboost9 model had the smallest rmse value rmse 0 159 c from the point of r2 values the impact of each input on the estimation accuracy for the model differed significantly the model estimated better accuracy on both daily and hourly scales than other inputs as long as they contained both factor t and rh the worst performer remained the rf10 model r2 0 650 in terms of mbe values they were more dispersed across the models relative to the other indicators in the validation phase the hourly tdew estimated from the goa xgboost model was grossly underestimated while the rf model was grossly overestimated both suffering from overfitting problems among several statistical indicators the mae values of the models were closest to each other for the same input the regular distribution of the mae values for each model was similar to the regular distribution of the rmse values the statistical indicators of the models were analyzed together as seen in fig 8 each model performed better than the model performance under the other inputs when both t and rh parameters were included in the inputs the performance of the estimated tdew from each model was optimal when the input was ea either on a daily or hourly scale although ea was transformed from the four variables tmax tmin rhmax rhmin by the formula it would also outperform the respective models with inputs tmax tmin rhmax rhmin it might be that the latter had a larger input dataset than the former resulting in reduced estimation performance of the model therefore ea was the most influential input in estimating the use of tdew at this point to better illustrated the importance of the factors we further assessed the importance of the factors in estimating the tdew by the rf model at both time scales fig 9 of these the increase in node purity incnodepurity is an important assessment metric it represents the effect of each factor on the heterogeneity of observations at each node of the classification tree and thus compares the importance of each factor a higher incnodepurity value indicates a higher importance of the factor as could be seen in fig 9 the incnodepurity values for ea outperformed the other factors by a wide margin on both time scales it indicated that the factor ea was the most important in the study of estimating tdew secondly the factors were ranked in importance as tmin tmax rhmax rhmin pa ud month at the daily scale and tmin rhmax tmax rhmin month pa ud time at the hourly scale therefore it could be concluded from fig 9 that t and rh are the most significant factors in estimating tdew studies the other factors had relatively little influence in the research by mohammadi et al 2016 they used multiple variables as inputs to estimate tdew for the model the results indicated that tmin and vp were the most effective inputs for estimating tdew the multivariate approach was used to analyze how each meteorological factor influenced the model s estimate of tdew and find the best model and input this article showed that t and rh were the essential meteorological factors the models provided good estimation performance for studies estimating tdew on either daily or hourly scales traditional empirical equations were more demanding in terms of conditions and produced less than satisfactory accuracy lawrence 2005 however it is clear from the graph that the hourly scale would correspond to a better performance in terms of accuracy than the daily scale for each model it could be that the variation in meteorological data varies less on an hourly scale than would be the case on a daily scale pumo and noto 2021 therefore the accuracy would be higher however for all other indicators the inputs containing both t and rh performed well other inputs correspond to the opposite law in terms of stability the distribution of points would be more dispersed at the hourly scale than the daily scale in fig 8 it is possible that the hourly scale meteorological data set was larger than the daily scale data set which was more computationally intensive during the model s operation resulting in reduced stability of the model because the daily scale would be averaging out the extremes of the data to make the error smaller however the hourly scale was more suitable for assessing the effects of simulations in extreme situations kratzenberg et al 2015 investigated the estimation of daily and hourly irradiance using the rf model for comparison and confirmed the model s higher accuracy in estimating hourly irradiance overall goa xgboost as an optimization algorithm would perform better than the xgboost and rf models in estimating tdew and the most practical input was ea 4 conclusions accurate estimation of tdew is significant in the areas of water resources utilization and agricultural development this research evaluated the ability of hybrid extreme gradient boosting with a grasshopper optimization algorithm goa xgboost for estimating tdew at daily and hourly scales it was also compared with the xgboost and rf models we collected meteorological data including ea tmax tmin rhmax rhmin pa ud month and time from the sijiqinglin station in china during 2016 2019 at two time scales to modeling each model the results showed that each machine learning model was able to estimate tdew well the goa xgboost model performed best at the daily scale with the rf model had severe over fitting problems the models exhibited the best performance when the input was ea conversely the models exhibited larger errors when the inputs were tmax tmin but the data set required for this input was minimal and relatively easy to obtain the hourly and daily scales demonstrated similar estimation laws t and rh were the most basic meteorological factors and the addition of redundant extraneous factors affected the model s estimation performance the factor month would be more important than time at hourly scales the variation in meteorological data at hourly ranges was smaller than at daily ranges this resulted in a higher accuracy of the models but with a concomitant increased data set and computational effort this led to a possible reduction in model stability however the hourly scale was more suitable for assessing the effects of simulations in extreme situations overall considering both accuracy and stability factors the goa xgboost model was the best model and the most practical input for both time scales was ea in recent years using interpolation of meteorological data from cross stations to predict tdew at a target station has become increasingly popular in the absence of meteorological data from some stations different climatic regions with factors such as geography and environment can also affect the model s ability to estimate the use of meteorological data from cross stations in combination with different climatic regions can be considered in subsequent studies to validate the applicability of each model the effect of different climate zone environments and cross station processing on the estimation performance of the models will be investigated credit authorship contribution statement jianhua dong investigation data curation writing original draft visualization wenzhi zeng conceptualization methodology writing review editing funding acquisition supervision guoqing lei methodology formal analysis lifeng wu investigation validation formal analysis haorui chen methodology formal analysis jingwei wu jiesheng huang funding acquisition supervision thomas gaiser writing review editing amit kumar srivastava writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we are grateful for the financial support from the program of the national natural science foundation of china nsfc grant nos 51879196 and 51790533 
3672,dew point temperature tdew plays an important role in hydrology meteorology and other related research this study evaluated the ability of a new machine learning model hybrid extreme gradient boosting with grasshopper optimization algorithm goa xgboost to estimate tdew and compared it with two other tree based models xgboost and random forest rf we collected meteorological data namely actual vapor pressure ea maximum air temperature tmax minimum air temperature tmin maximum relative humidity rhmax minimum relative humidity rhmin atmospheric pressure pa 2 m high wind speed ud during 2016 2019 on daily and hourly time scales from the sijiqinglin station in china to train test and validate each model the results showed that the goa xgboost model performed best and the rf model had severe over fitting problems during the validation phase at daily time scale the models showed the best accuracy and stability when the input was ea on average r2 1 000 rmse 0 296 mbe 0 001 mae 0 167 and kge 0 991 the models had more significant errors when the inputs were tmax tmin on average r2 0 721 rmse 6 756 mbe 0 101 mae 5 071 and kge 0 771 the estimation loss exhibited by the models were similar for the hourly and daily scale patterns t and rh were the most basic meteorological factors and adding extraneous factors would affect the estimation accuracy of the model the variability of meteorological data varied less on an hourly scale than on a daily scale therefore the accuracy of the models was higher but the data set and the volume of operations became larger this led to a possible reduction in model stability but the hourly scales are better suited for assessing the effects of simulations in extreme situations taking accuracy and stability into account the goa xgboost model was the best model and the most practical input for both time scales was ea therefore in subsequent studies the goa xgboost model can be combined with the input ea to estimate tdew accurately keywords dew point temperature grasshopper optimization algorithm extreme gradient boosting time scale cross validation 1 introduction dew point temperature tdew is the temperature at which water vapor in the air condenses into water droplets baghban et al 2016 accurate tdew data is vital in different scientific fields such as hydrology meteorology and agriculture cui et al 2021 achugbu et al 2021 pumo and noto 2021 yong et al 2021 lekouch et al 2012 lawrence 2005 with the accumulation of data over time tdew can be used as an essential variable in the study of climate change kim et al 2015 robinson 2000 tdew is usually used in combination with relative humidity rh to determine the moisture content of the air lawrence 2005 it can also be used in combination with the wet bulb temperature to obtain the ambient temperature for preventing frost on the crop indirectly affecting the productivity of the crop wasko et al 2018 drezner 2007 from various perspectives it is emphasized that accurate estimation of tdew is scientifically very important in all of the above areas in recent years scholars have commonly used non parametric machine learning techniques to estimate remotes sensing and metrological parameters such as precipitation soil moisture flood volume wind etc derin et al 2020 has developed an error model the nonparametric machine learning tree based quantile regression forest qrf to reduce precipitation retrieval error all validations showed that the precipitation error model based corrections can significantly reduce both the mean relative error and the random component of passive microwave pmw products bhuiyan et al 2017 evaluated a nonparametric error model for tropical rainfall measurement mission trmm pmw rainfall product over coverage in the southern continental united states and assess the impact of surface soil moisture information on the model s performance they concluded that the error model for precipitation products performed better when near surface soil moisture was used as an input parameter aboutalebi et al 2019 applied genetic programming gp in combination with high resolution multispectral images acquired by the unmanned aerial vehicle uav to estimate soil moisture at different scales they found that the gp produced satisfactory predictions lee et al 2019 used a deep learning dl method to estimate soil moisture based on the remote sensing data the soil moisture estimated by the dl was more accurate with a high correlation coefficient of 0 89 a low root mean square error 3 825 and bias 0 039 tyralis et al 2019 proposed a post processing of quantile regression and quantile regression forest overlay on simulations of the gr4j hydrological model for 511 watersheds in the united states the results illustrated a significant improvement in its performance relative to the base learner used ahn and palmer 2016 used the quantile regression technique qrt and parameter regression technique prt to combine data from 30 basin features in the northeastern usa for quantitative estimation of floods the results indicated that the prt outperformed the qrt in terms of accuracy and simplicity of calculation since it is easier to obtain common meteorological data it is easier to obtain common meteorological data through weather stations compared to remote sensing data however obtaining tdew data is more complicated this has led to restrictions on the use of tdew ukhurebor et al 2017 in previous studies researchers have mainly used empirical equations to estimate tdew lawrence 2005 was one of the researchers to use empirical equations to establish a general mathematical relationship between tdew and rh utilizing a simple conversion equation it had been found to be quite useful for approximating the conversion for moist air rh 50 in which tdew decreases by about 1 c for every 5 decrease in rh starting at tdew equal to dry bulb temperature and rh 100 the calculation of tdew can be considered as a complicated and nonlinear regression processes that depend on many meteorological variables dong et al 2020a moreover it requires a large amount of observational data therefore it is usually difficult to establish an empirical model to accurately describing all complex and nonlinear processes especially in the absence of some key information the most obvious limitation of empirical models is that their applicability is usually regional specific moreover the variation in tdew is non linear resulting in some uncertainty in the measured data by the empirical equation deka et al 2018 people have proposed various methods to solve the problem of the incompleteness of tdew data in particular machine learning models have been used by academics to estimate multiple variables including estimating tdew due to their excellent performance in dealing with the non linear relationship between inputs and outputs huang et al 2019 fan et al 2018a hubbard et al 2003 this is mainly because they require nothing on knowledge of internal variables and provide simple solutions for non linear and multi variable functions moreover they also have a strong modeling ability for some engineering problems and natural phenomena huang et al 2019 machine learning models include adaptive neuro fuzzy inference system anfis artificial neural network ann multivariate adaptive regression splines mars support vector machine svm extreme learning machine elm etc mohammad et al 2016 employed the anfis model to estimate the tdew of kerman and tabass in iran they compared the degree of influence of multiple variables on the estimation performance of the model they concluded that water vapor pressure vp and rh were the most and least relevant variables respectively kisi et al 2013 used four models to estimate daily tdew for three stations in korea models include the generalized regression neural networks model grnnm the kohonen self organizing feature maps neural networks model ksofm anfis model with sub clustering identification anfis sc and anfis model with grid partitioning identification anfis gp the results showed that the anfis sc anfis gp and grnnm models exhibited similar accuracy and outperformed the ksofm model ann models also have been applied to estimate tdew shank et al 2008 investigated the performance of the ann model combined with meteorological data to estimate tdew at 20 stations in georgia usa and confirmed the excellent performance of the ann model in estimating tdew some scholars have also optimized ann models to estimate tdew zounemat kermani 2012 evaluated multi linear regression mlr and levenberg marquardt lm feed forward neural network lm nn at geraldton station in canada to estimate the hourly tdew ability it was found that the lm nn model would perform better than the mlr model researchers often compare svm with elm models together because the elm model has better generalization properties and faster computing speed huang et al 2015 dong et al 2020a used ten machine learning models including mars svm and elm to estimate tdew values for the yangling station in china they confirmed that the estimation stability of the elm model would be better than that of the svm and mars model in a single model deka et al 2018 applied the svm and elm models to estimate daily tdew in humid and semi arid regions of india they found that the elm model performed better than the svm model in studies estimating daily tdew some researchers had also coupled other machine learning models with elm or svm models alizamir et al 2020 investigated the ability of the kernel elm k elm mars and three different models to estimate daily tdew in parts of the us and they concluded that the k elm model had the most consistent estimation performance of the five models wong et al 2015 applied the k elm and the least squares support vector machine ls svm models for predicting engine performance and compared them the results showed that the k elm and the ls svm had a similar and good performance amirmojahedi et al 2016 coupled elm and wavelet transform wt elm wt to estimate the tdew of bandar abass situated in iran and compared it with svm and ann models they demonstrated that the combined model provided better performance than the svm and ann models the validity of the optimization model in the estimation study could be seen in the above study results however many machine learning models are more complex and require high calculation time and computing memory in their computational processes fan et al 2018a hassan et al 2017 recently many academics have been interested in decision tree based models because their arithmetic process is relatively simple but still has robust classification and regression capabilities wu et al 2019a for example the rf m5 model tree m5tree moreover they are powerful models for pattern recognition and trend detection hassan et al 2017 with higher computational efficiency for large data size compared to other machine learning models hassan et al 2017 fan et al 2018a shiri 2019 studied the rf model for estimating daily tdew in east azerbaijan northwest iran he concluded that the rf model could be successfully used to estimate tdew with good performance feng et al 2017a applied four machine learning models such as backpropagation neural networks optimized by genetic algorithm gann rf and empirical models to estimate diffuse solar radiation rd in the north china plain region the results demonstrated that the rf model had better estimation performance than traditional empirical models wu et al 2019b used the combined model kernel based non linear extension of arps decline model knea with six models including the rf model to estimate daily global solar radiation in the humid subtropical region of china the results showed that the rf model would perform slightly worse than the knea model it also demonstrated the feasibility of the combined model in estimation feng et al 2017b compared the rf and generalized regression neural networks grnn models to estimate et0 values for southwest china they confirmed that both models had better performance but the rf model would be slightly better than the grnn model qasem et al 2019 applied the gene expression programming gep m5tree and support vector regression svr models to estimate the tdew of the iranian tabriz station and showed that the m5tree model exhibited the best performance some researchers had also studied the optimization of the m5tree model ghaemi et al 2019 coupled the mars and m5tree models with the maximum overlap discrete wavelet transform modwt to form the marsmodwt and mtmodwt models to estimate the monthly pan evaporation at turkey s siirt and diyarbakir meteorological stations it was also compared with the original model they found that the estimation accuracy of both hybrid models was better than that of the mars and m5tree models recently chen and guestrin 2016 proposed a novel and efficient tree based machine learning model extreme gradient boosting xgboost the xgboost model weights and superimpose all the weak classifiers for creating strong classifiers yan et al 2021 consequently it has a substantially lower estimation error and a higher estimation accuracy in addition it prevents models from being over fitted during training and increases computational efficiency through automatic parallel computing yan et al 2021 thus it is used in various fields of data processing wu et al 2019a evaluated the modeling ability of the xgboost model for estimating et0 in jiangxi province they demonstrated that the estimation performance of the xgboost model outperformed that of the svm and m5tree models when using local data dong et al 2020b employed the xgboost model to estimate rd for five meteorological stations in china and compared it with mars and svm it was found that the xgboost model would obtain better rd estimation values it is suitable for the study of estimating tdew considering the satisfactory performance that can be obtained with the xgboost model the estimation accuracy and stability of machine learning models depend mainly on the parameters nevertheless these parameters have to be tuned during model training for the efficient application of machine learning models the grid search is mostly used for model parameter selection olatomiwa et al 2015 due to the complexity of the parameters these algorithms usually have high computational complexity and are susceptible to local minima however hybrid models can effectively improve the problem of parameter complexity wu et al 2021 wang et al 2020 traditional models have high computational complexity therefore researchers have started to consider different coupling algorithms to improve the estimation performance of the models because it can derive the optimal solution to the optimization problem and improve the computational efficiency previous studies have also confirmed the viability of the hybrid model around this time biologically inspired algorithms came to the forefront of researchers minds for instance grasshopper optimization algorithm goa saremi et al 2017 particle swarm optimization pso marini and walczak 2015 scholars coupled metaheuristic algorithms with traditional machine learning models the aim is to combine the advantages of both models to optimize complex problems and provide optimal solutions it is also effective in increasing the speed of the model s operations it solves many research based problems for researchers hamad et al 2018 hybridized goa and svm models for detecting epilepsy and compared them with pso hybrid svm pso svm they found that the epileptic rate detected by goa svm was more accurate dong et al 2021 used the goa optimized for the knea model to estimate the daily et0 values for different climate zones in china they confirmed that the goa knea model could estimate the et0 values for each climate zone more accurately and its performance was good the xgboost model has multiple parameters that need to be tuned traditional methods may get stuck in a regional optimal solution and cannot obtain a global optimal solution however there are also very limited reports on optimizing the parameters of the xgboost model especially using the goa model however as far as the authors are aware the goa xgboost model has not been applied to tdew s research in previous studies researchers had mainly analyzed tdew on a single time scale for example hourly scale daily scale weekly scale etc comparing multiple time scales simultaneously facilitates the study of the applicability in estimating tdew of the model at different time scales therefore this study attempted to bring in a goa xgboost model to estimate tdew for the sijiqinglin station in china along with xgboost and rf models to better represent the performance of each model this article estimated tdew at different time scales daily and hourly scales for the target station respectively we also compared its accuracy and stability during the training testing and validation phases finally the influence of the input meteorological factors on the estimation of tdew by each model was analyzed and the selection of the optimal model and input that is best suited to estimate tdew 2 materials and methods 2 1 studied area and meteorological data in this study we selected meteorological data from a forestry station sijiqinglin located in the town of sijiqing in the western part of haidian district beijing china to estimate tdew the coordinate is located at 116 16 e 39 57 n the altitude is 55 m the area is mountainous to the northwest and plain to the southeast groundwater resources are abundant it belongs to the temperate humid monsoon climate zone it is warm rainy and the vegetation flourishes we collected meteorological data from the sijiqinglin station during 2016 2019 at the daily and hourly time scales to train test and validate each model used meteorological data were including actual vapor pressure ea maximum air temperature tmax minimum air temperature tmin maximum relative humidity rhmax minimum relative humidity rhmin atmospheric pressure pa 2 m high wind speed ud month month and hours time the basic information and geographical location of the selected station were shown in table 1 and fig 1 the selected meteorological data were provided and quality controlled by the national meteorological information centre nmic of the china meteorological administration cma http www cma cn the time resolution is 1 h and 1d if meteorological data was missing or if the ratio of measured tdew to actual tdew was above 1 the data were further excluded seventeen inputs of meteorological variables were utilized for training the rf xgboost and goa xgboost models details of the inputs are presented in table 2 among them inputs 1 8 were the inputs in the daily scale pattern and inputs 9 17 were the inputs in the hourly scale pattern in this study we used the 5 fold cross validation method on daily and hourly time scales of data processing in order to prevent overfitting problems to avoid specificity the collected dataset may 2016 to april 2019 was randomly divided into five equal parts three pieces were selected for training one piece for testing and the other for validation the process was repeated five times so that the chosen data was different each time therefore each part of the dataset would be validated once all the computations were run on computers with 2 intel xeon cpu e5 2670 2 6 3 3 ghz and 32 gb of ram memory 2 2 machine learning models for estimating daily dew point temperature 2 2 1 random forest rf the rf model was initially designed and developed by breiman 2001 using the classification and regression tree cart it is an evolutionary version of the bagging bag algorithm in other words the idea is still bagging but with a unique twist the model is important in the use of regression and estimation because it is an integrated learning algorithm for solving high dimensional regression problems the rf model can be used with subsets by automatic bootstrapping of the data i e the bootstrap resampling technology when dealing with random binary trees a new training sample set is generated from the n original training samples by repeatedly selecting a random set of t t n samples several samples may be collected several times throughout the selection process a random subset of the training dataset will be sampled from the original dataset and used to develop the model as shown in the flowchart in fig 2 the datasets not included in the model are called out of bags oob these uncollected datasets will not be involved in fitting the model and can be used to test the estimation capability of the model given an ensemble of classifiers h 1 x h 2 x h k x and with the training dataset drawn at random from the distribution of the random vector x y the margin function is expressed as breiman 2001 1 mg x y a v k i h k x y max j y a v k i h k x j where i is the indicator function the margin measures the extent to which the average number of votes at x y for the right class exceeding the average vote for any other classes therefore the larger the difference the greater the confidence in the classification moreover the generalization error of rf is 2 p e p x y m g x y 0 for a large number of decision trees two theorems can be given following from the law of large numbers theorem 1 as the number of trees increases for almost surely all sequences θ k p e converges to 3 p x y p θ h x θ y max j i p θ h x θ j 0 the theorem demonstrates that the rf model does not over fit as the number of trees increases but produces a limiting value of the generalization error theorem 2 the upper bound for the generalization error is expressed as 4 p e ρ 1 s 2 s 2 where ρ is the mean value of the correlation s 2 is the strength theorem 2 demonstrates that increasing the strength and decreasing the correlation of individual classifiers will reduce the upper bound of the generalization error feng et al 2017b rf uses a cart decision tree as a weak learner the cart algorithm in rf is different from other traditional algorithms cart is a binary tree which also means that each non leaf node can only produce two branches if a non leaf node is multiple greater than two discrete variables the variable may be used numerous times each feature selected for use in the rf tree is randomly generated from all m features to reduce the risk of overfitting effectively unlike other decision trees each rf tree is a part of the selected feature among these features the best features are selected to divide the left and right subtrees of the decision tree thus improving the stochasticity and the generalization of the model finally the mean of all the predicted variables can be derived overall the rf model estimates the average of the final aggregated data more detailed information on the rf model can be found in breiman s research breiman 2001 2 2 2 extreme gradient boosting xgboost the xgboost model has first proposed by chen and guestrin 2016 it is a new pattern of gradient boost machines gbms it is also based on a residual optimization algorithm which wishes to build k regression trees the predicted values of the tree population are made as close as possible to the true values accuracy and have a strong generalization capability the xgboost model provides efficiency and accuracy the xgboost model has optimized the decision tree algorithm to improve the handling of the dataset the accuracy is enhanced through regularization and built in cross validation to address the overfitting problem this is achieved by simplifying the objective functions these objective functions allow combining predictive and regularization terms to achieve and maintain the fastest possible speed furthermore during the training phase the functions in the xgboost model are run and computed automatically it is thus widely used for research in areas such as estimation dong et al 2020b and classification dong et al 2018 the xgboost model is derived from the concept of boosting which combines the predictions of a set of all weak learners with special training to develop strong learners fan et al 2018b the expressions are as follows 5 f i t k 1 t f k x i f i t 1 f t x i where f k x i and f t x i are the predicted values for the k th and t th iterations of the xgboost model respectively f i t and f i t 1 are the predicted values for the t and t 1 iterations of the i th sample x i is the input variable k 1 2 t i 1 2 n to prevent overfitting problems without affecting the computational speed of the model the xgboost model can be derived as follows 6 ob j t i 1 n l f i t f i t i 1 n ω f i where ob j t is the objective function l is the loss function f i t is the true value of the t th iteration of the i th sample ω f i is the canonical term of the objective function which is given by 7 ω f β t 1 2 λ ω 2 where β and λ are regularization parameters t is the number of leaf nodes more specific details can be found in chen and guestrin s research chen and guestrin 2016 2 2 3 hybrid extreme gradient boosting with grasshopper optimization algorithm goa xgboost the grasshopper optimization algorithm was first proposed by saremi et al 2017 as an intelligent optimization algorithm the basic idea of the algorithm is inspired by the foraging behavior of grasshoppers to solve some practical optimization problems the goa algorithm has two components exploration and development like most other algorithms this ensures that the algorithm has a strong global search capability and can effectively avoid stagnation in the local optimum grasshopper populations form a network that connects all the individuals the position of each grasshopper is made coherent individuals can determine the direction of predation through other individuals in the group fig 3 represents the social interaction of grasshoppers with their comfort zones in the network grasshopper populations have repulsion and attraction forces within a specific range grasshoppers are repulsive to each other when they are too close together and the closer they are the stronger the repulsion this prevents algorithm from converging together prematurely this also improves the exploration capabilities of the algorithm however the attractive force drives them to explore unknown areas grasshoppers have a stronger gravitational pull as they move beyond comfort zones the zone is called the optimal adaptation zone when the repulsion and attraction forces on individual grasshoppers are equal at a certain distance saremi et al 2017 since the target location is unknown the location of the grasshopper in the optimal adaptation region is considered the closest position to the target the grasshopper will move in the direction of the target in the network as the grasshoppers positions are updated the suitable range area will drop adaptively to balance the global search with the local search finally the grasshoppers converge and move closer to the optimal solution dong et al 2021 the optimal solution is output as the optimal parameters of the xgboost model as an optimization of the goa model for the xgboost model assuming there are n grasshoppers in the bee colony the d dimensional position of the i th grasshopper is x i d i 1 n eqn 4 and 5 have been used to simulate the predation process of grasshoppers 8 x i d c j 1 j i n c u b d l b d 2 s x j d x i d x j x i d ij t d 9 s r α exp r l s e x p r where u b d and l b d represent the upper and lower bounds of the d th dimension s is a function that defines social forces repulsive forces and gravitation force α represents gravitational strength ls is the length scalar of gravity dij is the distance between the i th and j th grasshoppers t d represents the d dimensional position where the target is optimal solution c is a decreasing coefficient more specific details can be found in the research of saremi et al 2017 2 2 4 parameter optimization the key parameters of rf xgboost and goa xgboost models were identified by the trial and error approach and optimized by the grid search method to prevent overfitting problems all models use root mean square error rmse as the optimization function the rmse values of the five trials were finally averaged as the expected generalization error when the minimum rmse value was obtained the optimization stopped and returned the best parameters basically all parameter pairs were tried and the best performing parameters were used for model training testing and validation in this study the upper and lower limits of parameters were first determined by the trial and error method a grid was then created to search for the best combination of parameters by setting different step sizes the main parameters of the rf algorithm are the maximum depth max depth and the number of trees trees are more prone to be overfitting if they have larger maximum depths for the rf model the max depth of trees varied between 2 and 16 at 2 intervals and the number of trees ranged from 100 to 1000 at 100 intervals the key parameters of the xgboost model were identified by the trial and error method and optimized by the grid search method the max depth learning rate eta maximum number of boosting iteration nrounds and subsample ratio of the training instance subsample in xgboost models were optimized with them ranging from 1 to 15 at 5 intervals from 0 to 1 at 0 1 intervals from 50 to 500 at 50 intervals and from 0 to 1 at 0 1 intervals respectively the key parameters of the goa algorithm were the number of population and the number of iterations which were set as 50 and 500 respectively additional parameters were taken as the default values 2 2 5 model comparison and statistical error analysis in the current study we have chosen five common statistical indicators to analyze and compare the performance of each model in estimating tdew on two time scales these statistical indicators are coefficient of determination r2 root mean square error rmse mean bias error mbe mean absolute error mae and kling gupta efficiency kge the mathematical equations for each statistical indicator are described below 10 r 2 i 1 n y i m y i m y i e y i e 2 i 1 n y i m y i m 2 i 1 n y i e y i e 2 11 rmse 1 n i 1 n y i m y i e 2 12 mbe 1 n i 1 n y i m y i e 13 mae 1 n i 1 n y i m y i e 14 kge 1 r 2 1 2 i 1 n y i e y i e 2 i 1 n y i m y i m 2 1 2 y i e y i m 1 2 where yi m yi e y i m y i e and n are the estimated tdew measured tdew mean measured tdew mean estimated tdew and the number of measurements respectively choosing a higher r2 and kge value i e the closer the value is to 1 represents better performance and the regression line pair can better fit the data conversely the lower the values of rmse mae and absolute mbe the better the estimation performance of each model 3 results and discussion this paper evaluated the performance of three decision tree based models i e rf xgboost and goa xgboost for estimating tdew on daily and hourly time scales then the accuracy and stability of the models were compared and analyzed 3 1 comparison of model performance under various inputs on a daily scale this section evaluated the ability of three models to estimate tdew on a daily scale using daily meteorological data including tmax tmin rhmax rhmin month pa and ud the specific inputs were shown in inputs 1 8 in table 2 table 3 presented the statistical results of the three machine learning models for estimating the daily tdew at the sijiqinglin station during the training testing and validation phases as seen from table 3 all the developed models could estimate daily tdew well in the three phases some of the models showed good accuracy the r2 rmse mbe mae and kge of these models ranged from 0 687 to 1 000 0 047 7 359 c 0 415 0 274 c 0 034 5 701 c and 0 661 1 000 respectively among the three phases the best performing model during the training phase was the rf model on average r2 0 967 rmse 2 088 mbe 0 005 mae 1 531 and kge 0 949 and the best performing model during the testing on average r2 0 850 rmse 4 458 mbe 0 138 mae 3 363 and kge 0 845 and validation on average r2 0 853 rmse 4 159 mbe 113 mae 3 132 and kge 0 815 phases was the goa xgboost model although the goa xgboost model showed a decreasing trend in performance during the process from the training phase to the validation phase however it still had high accuracy and outperformed the other two models the performance degradation of the rf model from the training phase to the validation phase indicated that the rf model suffered from the most severe overfitting problem this was consistent with the law exhibited by shiri s 2019 estimation of daily tdew using the rf model both of which produced overfitting problems moreover dong et al 2020a found that the rf model performed slightly worse than other models during the testing phase in their study of machine learning models to estimate tdew as could be seen in table 3 the best performance was shown by the models during the validation phase when the only ea was input on average r2 1 000 rmse 0 296 mbe 0 001 mae 0 167 and kge 0 991 the three models performed very close to each other in terms of accuracy and stability the best performing model was goa xgboost1 r2 1 000 rmse 0 245 mbe 0 006 mae 0 149 and kge 0 994 it indicated that ea was the most effective meteorological factor used to estimate tdew consistent with the conclusions obtained by mehdizadeh et al 2017 who estimated tdew using tmean tmax tmin rh pa and ea as inputs for the gep model both concluded that ea was the most efficient input although it has only one variable ea is derived by converting the four variables tmax tmin rhmax and rhmin in the validation phase the estimation performance of each model would be inferior to the input ea when the inputs are tmax tmin rhmax rhmin it showed that the inputs tmax tmin rhmax and rhmin are the same as the factor necessary for ea however the former had four variable inputs making it more computationally intensive leading to a reduction in the accuracy and stability of the models regarding the types of input variables it was found that models containing both t and rh inputs would be more accurate and stable than those with other variable inputs for example the models outperformed the inputs tmax tmin and rhmin on average r2 0 981 rmse 1 757 mbe 0 209 mae 1 395 and kge 0 770 during the validation phase when the inputs were tmax tmin and pa on average r2 0 719 rmse 6 794 mbe 0 047 mae 5 145 and kge 0 798 the r2 value decreased by 26 7 and the rmse value increased by 286 7 illustrating that t and rh were the most fundamental weather factors when using machine learning models to estimate daily tdew it was found that adding the factors month pa or ud inputs did not significantly improve the performance of each model when comparing the performance of the model with several other inputs tmax tmin the performance of each model was significantly improved only when the input factor rh was increased it indicated that adding the input of rh could improve the performance of the models in estimating daily tdew in terms of mbe values the worst performer during the validation phase was the rf7 model mbe 0 308 c followed by the rf5 mbe 0 256 c and rf6 models mbe 0 252 c respectively this indicated that among the three models the tdew estimated by the rf model was severely underestimated and produced serious overfitting problems which was consistent with the conclusions obtained in the previous paper during the validation phase the estimated and measured values of daily scale tdew for the three models with eight inputs of meteorological factors were plotted by scatter plots in fig 4 and analyzed for comparison it was clear from fig 4 that the scatter from each model converged more closely to the standard line and was more evenly distributed than the other inputs when the inputs were ea or tmax tmin rhmax rhmin it showed that using the four meteorological factors tmax tmin rhmax rhmin provided high estimation accuracy in estimating daily tdew the scatter plot exhibited no clear pattern when the input was tmax tmin and was scattered haphazardly on either side of the standard line consistent with the law derived from the data in table 3 it exhibited poor accuracy the scatter plot was still scattered when the factors month pa or ud were added to the input of tmax tmin the accuracy of the model did not increase significantly but partly decreased conversely increasing the input factor rh greatly enhanced the model s accuracy it indicated that pa month and ud were not necessary factors in estimating daily tdew instead increasing the input independent meteorological factors reduced the estimation performance of the model the worst performing model was the rf8 model in fig 4 r2 0 687 the best performers were the rf1 xgboost1 and goa xgboost1 models all with r2 values of 1 000 fig 5 showed the box plots derived from the difference between the measured daily tdew and the three machine learning models estimated values of daily tdew for eight inputs during the validation phase there was little difference in performance between the models by the median value the models goa xgboost1 xgboost1 and rf1 models performed best with the input ea followed by the inputs tmax tmin rhmax and tmax tmin rhmin from the point of view of the quartiles and the extremes this law remained the ea was shown once again to be the most effective meteorological factor when estimating tdew the estimated tdew from the models was significantly biased for the other five inputs the difference was not significant from the perspective of the quartiles however from an extreme value perspective the model did not simulate the standard extreme values well for any five inputs as could be seen from the box plots the best performing model was still the goa xgboost model and the highest performing input was ea 3 2 comparison of model performance under various inputs on an hourly scale this section compared the ability of the models to estimate tdew on hourly scales in terms of meteorological factors the hourly scale had one more time factor than the type of factor used to estimate tdew in the daily scale pattern the specific inputs were shown in inputs 9 17 in table 2 table 4 presented the statistical results of the estimated hourly tdew for the three machine learning models during the training testing and validation phases in the three phases the laws exhibited were generally consistent with those obtained in table 3 still ea was the most effective meteorological input for estimating tdew the difference was that the accuracy and stability of the models were very close during the validation phase for the input ea tmax tmin rhmax tmax tmin rhmin and tmax tmin rhmax rhmin on average r2 1 000 rmse 0 246 kge 0 992 r2 0 998 rmse 0 548 kge 0 998 r2 0 998 rmse 0 568 kge 0 998 r2 1 000 rmse 0 256 kge 0 997 respectively it showed that the variation in the meteorological data for temperature and humidity was not significant and remained almost identical in the hourly scale model this resulted in the high accuracy and stability of the model at this time it was also confirmed that t and rh were the most basic meteorological factors for estimating tdew comparing the estimation performance of each model for the validation phase with inputs of tmax tmin month and tmax tmin time the former was found to have an 8 2 increase in r2 values over the latter it indicated that the factor month was more important than time in estimating hourly tdew this could be due to the factor month having less data than time making the model less computationally intensive with less error and improved accuracy in table 4 it was clear that the goa xgboost model was still the optimal model in estimating the hourly tdew application the scatter plots of the estimated and measured hourly tdew values for the three models for eight omitted input of tmax tmin rhmin meteorological inputs were plotted in fig 6 for the validation phase the figure showed that the scatter was very close to the standard line and more evenly distributed when the input factor contained ea or t and rh factors it was suggested that the factors t and rh had an important role in estimating hourly tdew and could improve the model s performance the scatter obtained from the other inputs was very dispersed with no obvious rule the worst performing of these was the rf10 model r2 0 650 the input at this point was tmax tmin while this input of data was easily accessible the lack of a variety of variables required would reduce the accuracy of the model estimates as observed in fig 6 it was generally the goa xgboost model that would have a more uniform it concentrated scatter distribution than the other two models for the same input it indicated that the estimation performance of the goa xgboost model would be better than the other two models it also demonstrated that the hybrid model would better estimate performance and validity in estimation than some common models this was also consistent with the law obtained by wu et al 2019b using the hybrid model knea categorical boosting catboost and rf models to estimate solar radiation moreover amirmojahedi et al 2016 coupled elm with wt to estimate daily tdew and found that the hybrid model estimation performance would also outperform the single elm model fig 7 presented a box plot of the difference between the measured hourly tdew values and the estimated value from the three machine learning models for nine inputs during the validation phase as a whole from fig 7 the same inputs corresponding to each model had similar distribution laws for their box plots in terms of median quartiles and extreme values the performance law was the same as in fig 5 the individual models performed best with the input ea this was followed by tmax tmin rhmax rhmin tmax tmin rhmax and tmax tmin rhmin the box plot law of the model was very close for the four inputs because they both contain the factors t and rh as input at this point there was not much variation between the various meteorological data at the hourly scale leading to very high accuracy in all of the models akhlaghi et al 2021 the models exhibited a similar rule to fig 5 for several other inputs overall it was still clear from the figure that the performance ranking of the models was goa xgboost xgboost rf 3 3 compare daily and hourly model statistical indicators for different inputs to be able to compare better the performance of each model in estimating tdew for both daily and hourly scale patterns fig 8 integrated and compared the values of the statistical indicators for the two time scales during the validation phase the dotted line was the best standard line as shown in the figure the goa xgboost model performed relatively better from the point of view of rmse values which were both relatively small for the same input the rmse values of the models for inputs 1 9 13 14 and 15 converged to 0 and the models were stable the worst performer was the rf10 model rmse 8 494 c and the goa xgboost9 model had the smallest rmse value rmse 0 159 c from the point of r2 values the impact of each input on the estimation accuracy for the model differed significantly the model estimated better accuracy on both daily and hourly scales than other inputs as long as they contained both factor t and rh the worst performer remained the rf10 model r2 0 650 in terms of mbe values they were more dispersed across the models relative to the other indicators in the validation phase the hourly tdew estimated from the goa xgboost model was grossly underestimated while the rf model was grossly overestimated both suffering from overfitting problems among several statistical indicators the mae values of the models were closest to each other for the same input the regular distribution of the mae values for each model was similar to the regular distribution of the rmse values the statistical indicators of the models were analyzed together as seen in fig 8 each model performed better than the model performance under the other inputs when both t and rh parameters were included in the inputs the performance of the estimated tdew from each model was optimal when the input was ea either on a daily or hourly scale although ea was transformed from the four variables tmax tmin rhmax rhmin by the formula it would also outperform the respective models with inputs tmax tmin rhmax rhmin it might be that the latter had a larger input dataset than the former resulting in reduced estimation performance of the model therefore ea was the most influential input in estimating the use of tdew at this point to better illustrated the importance of the factors we further assessed the importance of the factors in estimating the tdew by the rf model at both time scales fig 9 of these the increase in node purity incnodepurity is an important assessment metric it represents the effect of each factor on the heterogeneity of observations at each node of the classification tree and thus compares the importance of each factor a higher incnodepurity value indicates a higher importance of the factor as could be seen in fig 9 the incnodepurity values for ea outperformed the other factors by a wide margin on both time scales it indicated that the factor ea was the most important in the study of estimating tdew secondly the factors were ranked in importance as tmin tmax rhmax rhmin pa ud month at the daily scale and tmin rhmax tmax rhmin month pa ud time at the hourly scale therefore it could be concluded from fig 9 that t and rh are the most significant factors in estimating tdew studies the other factors had relatively little influence in the research by mohammadi et al 2016 they used multiple variables as inputs to estimate tdew for the model the results indicated that tmin and vp were the most effective inputs for estimating tdew the multivariate approach was used to analyze how each meteorological factor influenced the model s estimate of tdew and find the best model and input this article showed that t and rh were the essential meteorological factors the models provided good estimation performance for studies estimating tdew on either daily or hourly scales traditional empirical equations were more demanding in terms of conditions and produced less than satisfactory accuracy lawrence 2005 however it is clear from the graph that the hourly scale would correspond to a better performance in terms of accuracy than the daily scale for each model it could be that the variation in meteorological data varies less on an hourly scale than would be the case on a daily scale pumo and noto 2021 therefore the accuracy would be higher however for all other indicators the inputs containing both t and rh performed well other inputs correspond to the opposite law in terms of stability the distribution of points would be more dispersed at the hourly scale than the daily scale in fig 8 it is possible that the hourly scale meteorological data set was larger than the daily scale data set which was more computationally intensive during the model s operation resulting in reduced stability of the model because the daily scale would be averaging out the extremes of the data to make the error smaller however the hourly scale was more suitable for assessing the effects of simulations in extreme situations kratzenberg et al 2015 investigated the estimation of daily and hourly irradiance using the rf model for comparison and confirmed the model s higher accuracy in estimating hourly irradiance overall goa xgboost as an optimization algorithm would perform better than the xgboost and rf models in estimating tdew and the most practical input was ea 4 conclusions accurate estimation of tdew is significant in the areas of water resources utilization and agricultural development this research evaluated the ability of hybrid extreme gradient boosting with a grasshopper optimization algorithm goa xgboost for estimating tdew at daily and hourly scales it was also compared with the xgboost and rf models we collected meteorological data including ea tmax tmin rhmax rhmin pa ud month and time from the sijiqinglin station in china during 2016 2019 at two time scales to modeling each model the results showed that each machine learning model was able to estimate tdew well the goa xgboost model performed best at the daily scale with the rf model had severe over fitting problems the models exhibited the best performance when the input was ea conversely the models exhibited larger errors when the inputs were tmax tmin but the data set required for this input was minimal and relatively easy to obtain the hourly and daily scales demonstrated similar estimation laws t and rh were the most basic meteorological factors and the addition of redundant extraneous factors affected the model s estimation performance the factor month would be more important than time at hourly scales the variation in meteorological data at hourly ranges was smaller than at daily ranges this resulted in a higher accuracy of the models but with a concomitant increased data set and computational effort this led to a possible reduction in model stability however the hourly scale was more suitable for assessing the effects of simulations in extreme situations overall considering both accuracy and stability factors the goa xgboost model was the best model and the most practical input for both time scales was ea in recent years using interpolation of meteorological data from cross stations to predict tdew at a target station has become increasingly popular in the absence of meteorological data from some stations different climatic regions with factors such as geography and environment can also affect the model s ability to estimate the use of meteorological data from cross stations in combination with different climatic regions can be considered in subsequent studies to validate the applicability of each model the effect of different climate zone environments and cross station processing on the estimation performance of the models will be investigated credit authorship contribution statement jianhua dong investigation data curation writing original draft visualization wenzhi zeng conceptualization methodology writing review editing funding acquisition supervision guoqing lei methodology formal analysis lifeng wu investigation validation formal analysis haorui chen methodology formal analysis jingwei wu jiesheng huang funding acquisition supervision thomas gaiser writing review editing amit kumar srivastava writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we are grateful for the financial support from the program of the national natural science foundation of china nsfc grant nos 51879196 and 51790533 
3673,an important consequence of storms in river estuary systems is major changes in hydrology and nutrients being fluxed from the land to the coastal ocean however the impacts of storms on the nature and amount of dissolved inorganic nitrogen din in the river estuary continuum are poorly understood in this study two week s continuous observations on two lower riverine fixed stations and an estuarine fixed station in the jiulong river se china were carried out during a complete storm event in june 10th to 23rd 2019 suspended particulate matter spm nitrogen species and their isotopic ratios nitrifying and denitrifying functional genes were measured the increased river discharge caused the freshwater brackish water boundary to move downstream and altered the pattern of particle distribution and the location of the estuarine turbidity maximum the increased river spm and inorganic nitrogen was associated with watershed soil erosion sediment scour and land use both in the river and estuary the peak concentration of ammonium arrived faster than nitrate apart from river inputs there was an additional increase of 40 8 of din supplied within the tidal river and estuary the additional din mostly came from resuspended sediments and catchment runoff while increased nitrate also came from soil and ground waters increased nitrification and decreased denitrification in the estuary these results suggest that during baseflow conditions the wetlands in the upper estuary acts as a temporary nutrient trap and biogeochemical incubator while in storms the transformed pollutant n was fluxed from the river estuary continuum to the adjacent coastal areas keywords estuarine turbidity maxima storm flow biogeochemical sediment incubator nitrogen cycling nitrogen isotope jiulong river 1 introduction anthropogenic nitrogen is a major pollutant which has increased dramatically as a result of major fertilizer use to enable us to feed the world s increasing population galloway et al 2008 tilman et al 2002 vitousek et al 1997 with greater than 80 million tons of this extra nitrogen now produced artificially by the haber process liu et al 2005 tilman et al 2002 much of this excess anthropogenic nitrogen is eventually discharged into rivers and from rivers transported via estuaries to coastal waters causing eutrophication problems canfield et al 2010 duce et al 2008 galloway et al 2004 the nature of the nitrogen reaching the river system depends on the balance of anthropogenic activities in the catchment in a mixed activity catchment such as the jiulong river in s e china an important source of excess nitrogen is from the washout of excess fertilizers applied to the land in the form of ammonia and or urea fertilizers lin et al 2020a these fertilizers accumulate in surface soil waters and are subsequently discharged into the river often after having been converted to nitrate by in situ nitrification processes huang et al 2020 zhang et al 2021 the other main source of anthropogenic nitrogen in the jiulong river system is from human sewage discharges from the population centers and from wastes from intensive animal farming bai et al 2019 lin et al 2020b once discharged into the river channel microbial and other biological processes can change the nature of the anthropogenic nitrogen by biological uptake nitrification denitrification anammox and other more minor processes both in the river reservoirs and estuary kaushal et al 2021 lin et al 2020a while all of these processes occur during normal river flow the largest fluxes of nitrogen from the catchment to the sea occurs during major storms gao et al 2018 koschorreck and darwich 2003 rozemeijer et al 2021 during major storms there is generally higher soil erosion resulting in higher suspended particulate matter spm in the river channel baborowski et al 2004 chen et al 2018b excess fertilizers flushed from the fields soil waters and groundwater are discharged into streams and rivers and transported at higher water discharge rates de girolamo et al 2017 marcé et al 2018 storm flow also often causes increased water flow into and through sewage treatment works and intensive agricultural farms whitehead et al 2015 together these processes result in a pulse of higher nitrogen down the river and through the estuary to the sea estuaries are important locations for biogeochemical processes which can alter nutrient fluxes to the coastal sea during normal flow upper estuaries act as traps for nutrients sanders et al 1997 an important component of this trapping is particulate matter with its associated labile particle organic matter pon which is deposited kaiser et al 2014 in adjacent creeks and mudflats jickells et al 2016 in sub tropical estuaries such as the jiulong river an important component of such areas is fringing mangrove forests yu et al 2015 such wetland locations can act as biogeochemical incubators in which diagenetic changes occur in surface sediments which result in changes in chemical nature of the pollutant nitrogen by processes such as ammonification and nitrification and in loss to the atmosphere by denitrification and anammox dong et al 2009 kessler et al 2018 smith et al 2015 such processes are particularly important in the surficial sediments of mangrove wetlands wang et al 2019 wang et al 2021 zhang et al 2020 recently the wetland areas of estuaries worldwide are being reduced as a result of land reclamation which reduces the ability of estuaries to act as nutrient traps jickells et al 2016 and changes the niche and community of nitrogen cycling microbes oczkowski et al 2020 this general process has also occurred in the jiulong river estuary wang et al 2018 however during storms sediment from these wetlands can be resuspended releasing the transformed nutrients into the water column and hence fluxed through the estuary to the coast chen et al 2018a chen et al 2018b an important effect of climate change is that there are more frequent extreme weather events including larger storms annamalai and liu 2005 rozemeijer et al 2021 these general changes increase the importance of understanding in detail the effects of major storms on anthropogenic nitrogen processes and fluxes into the river catchment and through the estuarine system discharging into the ecologically vulnerable coastal areas river watersheds and coast seas were traditionally regarded as two separate systems we have recognized the importance of adopting a holistic perspective in the studies as well as management of these two systems as a whole body but simultaneous observations are still limited in this study we set out to determine in detail the effect of a major storm on the concentration and flux of nitrogen species to and through the jiulong river estuary system in s e china we intensively sampled the river both at the freshwater discharge points from the north and west jiulong river and at a station in the middle of the estuary to determine the rate of water discharge and the concentrations of spm the nitrogen species and their isotopic content the aim was to identify and quantify the fluxes out from the river catchment and estuary during the storm and particularly to examine and understand the biogeochemical and microbial processes which caused increases in the amount and changes in the nature of the nutrients fluxing through the estuary to the coast during the storm the study particularly shows how transformative processes in the upper estuary sediment incubator changes the nature and flux of n species through the river estuary system under storm condition 2 materials and methods 2 1 study site the jiulong river is the second largest river in fujian province southeast china which flows into xiamen bay and thence to the taiwan strait fig 1 with 14 740 km2 drainage area and 3 5 million population in the river catchment the multi year average rainfall in the watershed is 1400 1800 mm chen et al 2018a which is concentrated between may and august fig 2 a its subtropical monsoon climate causes high temperature and rainfall in summer when is frequently buffeted by tropical cyclones and storms the average daily total river discharge arriving to the estuary from the closest hydrological stations zd and pn fig 1 during 2016 to 2019 were 741 2016 el niño year 374 224 2018 la nina year and 425 m3 s 1 respectively the water discharge in baseflow to the jiulong river estuary jre is derived mainly from the north river njr 66 with the west river wjr supplying the remaining 34 chen et al 2018a the upper reaches of the njr pass through longyan city and adjacent areas where it receives discharges of domestic and animal waste lin et al 2020a the downstream flow is regulated by step hydropower stations lin et al 2020a the upper reaches of the wjr pass through large scale pomelo orchards and then flows past zhangzhou city which discharges treated domestic sewage into the river during periods of high flow dikes on both the njr and wjr are opened to control potential flooding upstream and to generate electricity chen et al 2018a the characteristics of the jre in baseflow period is a semi enclosed macrotidal estuary with 100 km2 open water area 3 16 m depth 2 7 4 m tidal range typical semidiurnal tide and 2 3 days of average flushing time cao et al 2005 the southern channel of the jre contains 90 of the discharge to xiamen bay three fixed sampling stations are shown in fig 1 the lower river stations stations zs and jd were chosen to be located above the reaches affected by tides and represent the downstream boundaries of wjr and njr the estuarine station e is in the middle channel of the southern jre and is the core area of estuarine turbidity maxima etm during baseflow period yu et al 2020 yu et al 2019 the catchment areas of wjr and njr are 4011 km2 and 9635 km2 respectively the tidal reach drainage areas above station e are 306 km2 2 2 sampling campaign the monitored storm event was the second major storm in the wet season of june 10th to 23rd 2019 fig 2a there was a period of increased flood discharge from june 11th to june 18th both in the njr and wjr fig 2a b the daily river total discharge was up to a maximum of 2250 m3 s 1 we divided the storm event into four phases initial rising falling and ending according to river total discharge fig 2b the periods of initial rising falling and ending were from 10th to 11th 2 samples 11th to 15th 32 samples 15th to 18th 21 samples and 18th to 23rd 21 samples in station e respectively the definition of baseflow and flood respectively are the periods when the river discharge is less than and more than 1 2 times of the baseflow as used in our previous research by an automatic segmentation procedure bfi f smoothed minima method chen et al 2018a gao et al 2018 yu et al 2019 according to the definition of flooding the storm event also can be divided into two major states baseflow initial and ending and flood rising and falling a total of 76 water samples were collected in station e during the storm including 10 times periods of intensive observation and sampling including 14 h time series measurement 11th to 17th 19th 21st and 23rd fig 2b one sample was taken for isotopic nitrate and one sample for isotopic ammonium were collected at station e each day from june 10 to june 19 the water samples were collected using the 5 l plexiglass samplers at 0 5 m depth situated several meters away from the estuarine bank to ensure that we were sampling the main estuarine conditions these water samples were immediately transferred to 1 l brown bottles using the bottom silicone tube on the plexiglass samplers all samples were immediately placed in portable fridges at 4 and then transported to lab every three days to analyze immediately before being sampled for analysis the brown bottles were shaken vigorously an in situ multi parameter sensor aqua troll 600 usa was fixed on the bottom water of station e 1 m above surface sediments to acquire hourly turbidity and salinity a total of 14 water samples were collected in each river station zs and jd per day during these periods of intensive sampling in station zs wjr a total of 9 isotopic nitrate samples and 9 isotopic ammonium samples were collected per day in station jd njr a total of 8 isotopic nitrate samples were collected per day the sampling and storage schemes in river stations were the same as for station e 2 3 physicochemical analysis in the lab about 500 ml of the water samples were filtered using 47 mm gf f 0 7 μm filters suspended particulate matter spm was determined as the difference between the unfiltered and filtered gf f filters after oven drying 105 to constant weight the filtrate was stored at 4 before being analyzed for ammonium nh4 n nitrate no3 n nitrite no2 n by segmented flow automated colorimetry san analyzer germany and was determined within less than one week the precision of nutrient was estimated by repeated determinations of 10 samples with less than 5 relative error the limit of detection of ammonium nitrate and nitrite was 0 4 μmol l 1 0 1 μmol l 1 and 0 04 μmol l 1 respectively another 50 ml filtrate was stored at 20 for subsequent isotopic analysis the determination of isotopic δ15n no3 and δ18o no3 was carried out by the denitrifier method casciotti et al 2002 sigman et al 2001 using isotope ratio mass spectrometer 100 irms uk isotopic δ15n nh4 was determined by ammonia diffusion method holmes et al 1998 using an isotope ratio mass spectrometer irms germany 2 4 molecular analysis an additional 1 l of water samples was filtered for analysis of nitrifying and denitrifying functional gene abundances using the methods given in detail in lin et al 2020a briefly dna samples were fileted by 3 μm and 0 22 μm isopore tm membrane 47 mm millipore usa and then stored at 80 dna extraction used fastdnatm spin kit for soil millipore usa the 3 μm and the 0 22 μm filters were used for collecting particle attached pa and free living fl microbes respectively nitrification microbes include ammonia oxidizing archaea aoa and bacteria aob by amoa gene and nitrite oxidizing bacteria nob by nxra gene table s1 denitrification reduces nitrate and nitrite by narg nitrate reductase and nirs nitrite reduce the primers of amoa aoa amoa aob nxra narg and nirs came from francis et al 2005 rotthauwe et al 1997 wertz et al 2008 lópez gutiérrez et al 2004 and jung et al 2011 respectively table s1 the qpcr amplification used a bio rad cfx96 qpcr table s2 2 5 auxiliary data calculations carried out and statistical analysis hourly river discharge was obtained from local government at the closest hydrological stations zd and pn fig 1 the tidal range at shima tide gauge was obtained from the national maritime information service https www cnss com cn tide the river fluxes were calculated using the formula flux njr wjr concentration njr wjr discharge njr wjr respectively where the concentration was the measured daily concentration and the discharge was the river discharge at the river exit points the estuarine flux was calculated using the formula flux jre concentration low tide discharge njr 1 03 discharge wjr 1 08 where the concentration was the measured concentrations at low tide 0 psu multiplied by the summed daily river discharge modified using the ratios of catchment area which was 1 03 njr and 1 08 wjr between hydrological stations zd and pn and station e to identify the impact of the storm events on estuarine velocity and salinity a three dimension numerical model regional ocean modeling system roms which has been developed for the jre cheng et al 2019 cheng et al 2020 this model calculates salinity and velocity with 15 layers 0 3 m depth per layers using 48 800 m grid spacing and 339 165 grid points the river discharge conditions used in the model was the measured river discharge during the storm and the average discharge of baseflow 745 m3 s 1 the δ water velocity shown in fig 2d indicates the difference between modeled hourly estuarine velocities under the storm and baseflow conditions δ concentration flux indicate the difference between the estuary station e and the flow weighted mean river concentration summed flux stations zs and jd anova analysis was performed using the spss program to test the difference of hydrological parameters and n species at low high tides during the four phases of the storm using the kolmogorov smirnov test and variances homogeneous test 3 results 3 1 hydrological conditions during the storm the njr contributed 73 4 of the total river discharge to jre while the wjr discharge was the remainder the average hourly river total discharge was 730 88 m3 s 1 in the baseflow increasing to 1544 442 m3 s 1 in the flood table 1 the hourly estuary discharge and velocity at station e respectively were 330 1388 m3 s 1 and 0 12 0 44 m s 1 the δ water velocity i e the increase caused by the storm was significantly higher during the rising 0 21 0 08 m s 1 than the other periods fig 2d during the baseflow station e had low salinity 0 3 psu at high tide and freshwater at low tide as the discharge increased rising and initial part of the falling freshwater occupied station e as the discharge decreased falling to ending there was again increased salinity during periods of high tide at station e fig 3 a b 3 2 variation of suspended particulate matter spm the average concentration of spm discharged from the two rivers during the baseflow was 17 8 mg l 1 wjr and 32 1 mg l 1 njr contributing to the total spm measured in the jre of 105 25 mg l 1 fig 4 a these concentrations resulted in a calculated riverine spm flux of 5049 4701 t d 1 njr and 918 645 t d 1 wjr to the jre which represented in total 27 10 of the flux calculated as passing through the estuary 20365 12469 t d 1 fig 5 a the spm discharged from the two rivers increased reaching a peak of 92 mg l 1 and 17839 t d 1 total calculated concentration towards the end of rising fig 3c the average concentration and flux of spm from the river then decreased back to baseflow values of 27 6 mg l 1 and 2007 438 t d 1 by the ending period during the storm period in addition to spm from the rivers there was additional spm present in the water column at station e fig 4a the flux and δ flux of spm at station e were considerably higher during the rising than during the other periods table 1 in addition to these major average changes in spm there were also relatively minor changes in the concentration of spm at station e between low tide and high tide fig 1a the concentration of spm in surface water was significantly correlated with water velocity during the baseflow both in ebb tide and flood tide fig s2a while the turbidity in bottom water was positively correlated water velocity during the storm only in flood tide fig s2b 3 3 changes in nitrogen species both the wjr and njr contributed riverine nitrogen input to estuary the wjr had higher concentrations of nh4 n no3 n and no2 n than njr fig 4 which resulted in similar total fluxes to the jre fig 5 riverine nh4 n and no2 n increased in concentration during the rising and peaked in the middle of rising before the maximum discharge then they decreased to a minimum at the beginning of falling and returned to baseflow values during the ending by contrast the concentration of no3 n in both the njr and wjr decreased as the discharge increased during the beginning of rising and then increased getting close to baseflow concentrations by the beginning of falling the storm event changed riverine nitrogen fluxes with different patterns for the njr and wjr fig 5 all nitrogen species increased fluxes with rising discharge and gradually recovered to baseflow conditions from the last day of the rising higher fluxes of nh4 n and no3 n were measured in the njr during the baseflow while the fluxes in the wjr exceeded njr during the flood the patterns of nitrogen concentration and flux observed in the estuary were different from the rivers fig 4 fig 5 estuarine nh4 n and no2 n reached its maximum concentration and flux at the beginning of the rising while another peak value of no2 n was detected during the ending fig 6 the ratio of nh4 n din increased from 11 4 to 13 5 during the rising table 1 by contrast the concentration and flux of no3 n started to rise at the beginning of rising and continued to increase reaching a maximum at the end of rising fig 5 fig 6 both the δ concentrations and fluxes of nh4 n and no3 n were considerably higher during the rising while no2 n remained roughly similar table 1 comparing the concentration between low tide and high tide low tide had higher nh4 n and lower no2 n without any significant difference of no3 n fig s1 3 4 nitrate and ammonium isotopes the riverine and estuarine nitrate and ammonium isotopic values are shown in fig 7 the ratios of δ15n no3 at station e 7 0 1 6 were lower than the samples from the exits from the rivers 7 6 0 9 wjr and 8 5 2 1 njr except on june 17th the njr diluted δ15n no3 to 7 2 during the initial and then increased to 9 2 during the rising which then gradually decreased with decreasing discharge the wjr decreased δ15n no3 from 8 2 initial to 6 0 rising and then increased to 8 1 falling by contrast δ15n nh4 estuarine values were lower than the wjr during the initial and then surpassed it during the rising until the late falling the relationship between δ15n nh4 and daily total river discharge was negative in the wjr but positive in the jre fig 7d 3 5 abundances of nitrogen functional genes the abundances of nitrifying and denitrifying genes at station e changed during the storm fig 8 nitrifying genes amoa aoa amoa aob and nxra nob increased 1 7 2 6 and 2 1 times during the flood the amoa aoa and nxra genes initially decreased during the first day of falling and then returned to baseflow values at the end of falling while amoa aob remained at peak abundance in the middle of falling and then decreased during the ending for those genes associated with nitrifiers aoa and nob reached their maximum abundance faster than aob nob was always less than aoa and aob during the baseflow while it exceeded ammonia oxidizing microbes aoa and aob during the flood aob was always more than aoa aob peaked during the falling by contrast denitrifying genes narg and nirs decreased 2 1 and 1 9 times during peak discharge fig 8d e the difference between narg and nirs abundances was similar during the initial and increased with increasing discharge resulting in far less narg than nirs the nirs gene reached low abundance earlier than the narg gene 4 discussion 4 1 effects of the storm on estuarine hydrological and sedimentological conditions during normal baseflow the freshwater brackish water boundary is in the region of a5 a7 fig 1 upstream of station e chen et al 2018b yu et al 2020 this is the location of the etm zone during storm flow the freshwater brackish water boundary moves downstream depending on the intensity of storms and the corresponding increase in freshwater discharge chen et al 2018a this was also the pattern in this study fig 3 during the baseflow there was fluctuating salinity at station e changing from 0 to 3 which is the characteristic of the etm fig 3a b during the rising and the most of falling the water column at station e was entirely fresh therefore the flow changed to the higher flow rate characteristic of typical river storm flow during the storm fig 3a b once the discharge decreased at the end of falling and through the ending period the freshwater brackish boundary migrated upstream to mid estuary station e again which had tidal changes in salinity again these changes in estuarine circulation have important consequences on sediment dynamics under normal baseflow conditions sediments brought down the river together are deposited in the upper estuary above station e forming a layer of relatively unconsolidated sediments in the main channel and in the adjacent wetland and side creeks including mangrove wetlands chen et al 2018a yu et al 2020 as typically occurs in storms there was an increase in total spm at station e which correlated with the increase in freshwater discharge during the rising table 1 this increased spm was due both to an increase in sediments brought down the river and an additional increase of spm due to sediment supplied by local resuspension processes in the upper estuary fig 4a during rainstorms the sediments load out from the jiulong river watershed increases chen et al 2018b this increase is caused by soil erosion in both the wjr and njr catchments together with deliberate flushing of sediments behind some of the hydroelectric dams particularly in the njr chen et al 2018a in addition there are also resuspended sediments scoured from the upper estuary channel and particularly adjacent wetlands and creeks de haas and eisma 1993 wengrove et al 2015 in the case of the jiulong estuary an important component of these areas are mangrove wetlands yu et al 2015 these sediments deposited during previous periods of low flow are likely to be rich in labile organic matter when deposited yu et al 2019 under the extant conditions of relatively high temperatures especially in summer these sediments act as a biogeochemical incubator undergoing characteristic diagenetic changes chen et al 2018b tan et al 2020 zhang et al 2020 as a result of the resuspension of these sediments and their pore waters during the storm there were considerable changes in the n biogeochemistry of the water column see following sections the maximum turbidity was 520 ntu rising fig 3c which was considerably higher than baseflow values but less than many previous storms thus yu et al 2019 found the maximum spm in the jre was up to 1500 mg l 1 during the peak discharge of 3000 m3 s 1 in 2016 the magnitude of spm during storms is a result of complex interaction of factors including the magnitude of the discharge and the period of time since the last major storm chen et al 2018b it is suggested the relatively low spm during this storm june 2019 maybe because this storm was not as intense as some previous storms and because it was the second one of a succession of storms fig 2a and thus much of the previously deposited sediments had already been flushed out from the upper estuary the variation of spm at station e was also partially controlled by tide throughout the storm there was higher spm in the surface water during low tide because the surface water was carrying higher amounts of river derived spm fig s1 in addition there was a significant positive correlation between water velocity and spm fig s2 the maximum values of landward velocity and spm were both during the rising table 1 during baseflow condition there was relatively higher spm in ebb tide bringing river derived particles than in flood tide which contained a higher proportion of particles derived from the brackish part of the estuary by contrast in the bottom water there was no difference in the amount of spm in the water column between ebb and flood tides 4 2 nature of nitrogen discharges into the river during periods of normal flow anthropogenically derived inorganic nitrogen chemical species are discharged into the river and transported towards the estuary lin et al 2020a higher fluxes of nh4 n and no2 n were detected in the njr than wjr during the baseflow fig 5b c most of the riverine nh4 n and no2 n comes from domestic secondary sewage discharge from zhangzhou city in the lower reaches of wjr chen et al 2014 chen et al 2015 and longyan city in the upper reaches of njr lin et al 2020a an additional important source of these nitrogen compounds is animal wastes particularly from the intensive pig production in the upper njr catchment cao et al 2015 lin et al 2020a by contrast no3 n predominantly comes from excess ammonium fertilizer added to upstream fields which is nitrified in or on the soil and then runs off into the river channels evidence confirming this pattern comes from the isotopic ratios determined in the water column fig 7 and a recent study by huang et al 2020 the slightly lower δ15n no3 in the wjr compared with njr fig 7a is inferred to be due to the high fertilizer application in the intensive pomelo orchards in the upper wjr catchment lin et al 2020a in addition both manure sewage ms and ammonium fertilizer af can be oxidized by nitrification to nitrate in the oxic water column of the river channels and within surface riverine sediments particularly during the wet summer season with higher ambient temperature lin et al 2020a the isotopic content from the initial to ending are shown in fig 7 the values are consistent with leached soil and groundwater which resulted in lower δ15n no3 from extensive in situ nitrification fig 7a b previous work has found that the isotopic values of δ15n no3 and δ18o no3 in both the njr and wjr during normal flow were the result of nitrate being flushed out into the river from different types of land use huang et al 2020 lin et al 2020a the dominant nitrate source in the njr was derived from the nitrification of domestic and animal derived sewage huang et al 2020 and as a result had elevated δ15n no3 9 2 to 29 7 johannsen et al 2008 as shown in fig 7a by contrast in the wjr most of the nitrate was derived from ammonium fertilizer fig 7b which was applied to agricultural soil in the watershed and had lower δ15n no3 0 4 kendall 1998 4 3 effects of the storm on riverine nitrogen as discharge increased during storms there had an increase in anthropogenic din exported from the jiulong watershed to the estuary gao et al 2018 as has been observed in other river systems mooney and mcclelland 2012 peierls et al 2003 nh4 n and no2 n increased rapidly in both concentration and total flux fig 4 fig 5 a major source of these increased nitrogen compounds was from the flushing of domestic waste from the sewage treatment works of the zhangzhou city on the wjr lin et al 2020b together with surface runoff from other agricultural pollutants such as manure animal waste and some types of fertilizer from fields in the lower watershed of both wjr and njr chen et al 2012 other possible sources are from animal waste particularly in the njr though this will take some time before it reaches the estuary cao et al 2015 the negative relationship of δ15n nh4 with river discharge in the wjr fig 7d indicates that dilution by rainfall was the major factor changing the fraction of riverine nitrogen isotope since the rainwater in south china has a lower δ15n nh4 12 4 to 0 6 jia and chen 2010 the only exception was on june 12th rising when there was an increase in isotopic ratio likely due to ammonia addition of urban sewage with higher δ15n nh4 9 2 to 29 7 lee et al 2016 by contrast to reduced nitrogen the increase in concentration of riverine no3 n was delayed somewhat with the concentration initially decreasing at the beginning of rising presumably by rainfall dilution and then increasing to peak value in the later part of rising fig 4d this pattern has been observed previous in the jiulong river gao et al 2018 and in the elbe river jacob et al 2016 it is likely that this delay is because a major source of no3 n is from nitrate present in the surface soil and groundwater which is leached out as the rainwater infiltrates into the soil and washes the interstitial nitrate out into the stream and hence river channels johannsen et al 2008 4 4 effects of the storm on estuarine nitrogen in addition to the increase in nitrogen reaching the estuary during the storm as a result of increased river discharge there was extra inorganic nitrogen added to the estuary water by processes within the tidal river and estuary this additional concentration and flux was considerably higher during the rising than other periods table 1 this also was the period in which there was major sediment scour from the upper estuary wetlands and catchment runoff this scour caused the sediment pore waters which are rich in nitrogen species dissolved and adsorbed together with their associated bacteria to be released into the overlying water and observed fluxing past station e in the middle of the rising there was a major net increase in nh4 n which tripled from 24 µmol l 1 to a maximum 67 µmol l 1 fig 6a which represented a net increase of greater than 100 t d 1 nh4 n added to the estuary compared to the river flux fig 5a the anoxic conversion of labile pon to ammonium is an important process in estuarine sediments particularly in recent mangrove wetlands salt marshes and creek sediments adjacent to estuaries chen et al 2018a sumi and koike 1990 this ammonium is likely to be flushed out by surface sediment scour and catchment runoff in the tidal river during the storm fig s1b simultaneously ammonium will be desorbed from resuspended sediment particles because the concentration of ammonium in the water column of jre is much lower than that in the surface sediment pore waters yu et al 2020 from its peak of 67 µmol l 1 at the beginning of rising fig 6a ammonium steadily decreased through the remaining rising and through falling to 20 µmol l 1 this decrease in added ammonium could be due to a decrease in the amount of ammonium associated with the scoured estuarine sediments after the first storm pulse fig 2a however an additional and likely important contributing factor to this decrease is nitrification in the water column evidence for this process comes several observations firstly there was a major increase in nitrate in the water column see below for discussion of possible other reasons for that increase in addition there was increasing gene copies of ammonia oxidizing microbes with peak values of aoa found in the middle of rising and aob in the falling fig 8a b there was also a general decrease in δ15n no3 vs δ18o no3 through the jre except for one anomalous point during the falling and a dramatic growth in δ15n nh4 fig 7 such changes are characteristic of nitrification böttcher et al 1990 casciotti et al 2002 the observed positive relationship between δ15n nh4 and daily river discharge in the jre fig 7d suggests that the increased δ15n nh4 could derive from nitrification 14 to 27 casciotti 2009 though it could also come in part from sewage inputs 9 2 to 29 7 lee et al 2016 as shown in fig 7c the concentration of nitrate between the lower river stations and station e increased considerably from 175 µmol l 1 initial to a maximum of 290 µmol l 1 at the end of rising fig 6c part of this increase in nitrate was likely due to nitrification in the water column from ammonium which decreased by 56 µmol l 1 from its maximum at the beginning of rising compared with its concentration at the end of rising however the increase in concentration of nitrate of 115 µmol l 1 was much greater than the decrease in ammonium while the calculated flux of nitrate through the estuary during the rising was five times more than the flux of ammonium table 1 this means that there had to be other sources of nitrate to the estuary other than in situ nitrification in the water column there are several possible additional processes which could add nitrate to the estuary during storms in estuarine and mangrove sediments there are typically a peak in nitrate at or close to the sediment water interface due to a nitrification denitrification couple as surface sediments are resuspended both nitrate and ammonium will be released into the water column the relative amounts of nitrate and ammonium will depend on the depth of scoured sediments it is likely to be particularly rich in nitrate in sediments which are periodically exposed during tidal changes as is typical in mangrove wetlands an additional contributing factor to this increase in nitrate was a decrease in denitrification it was observed that there was a decrease in the abundances of denitrifying genes towards the end of rising where these genes reached pre storm abundances only after the falling fig 8d e this is suggestive of a more oxic less anoxic system in the jre during the storm finally as noted above for the river sections during storm flow there was a substantial increase in nitrate which came from ground and soil water discharge which was slightly delayed from the initial increase in water discharge it is likely that there was a similar addition of nitrate from the areas in the immediate catchment of the estuary i e that the heavy rainfall will cause previously formed nitrate in the adjacent fields and mudflats to be flushed out into the estuary during storm flow it is not possible without a total nitrate budget to determine the relative importance of these various processes to the observed increase in nitrate through the jre during the peak of the storm during the storm the concentration of nitrite decreased from the initial until halfway through the rising fig 4c suggesting that nitrite was being diluted by increased discharge more than the increase of nitrite as an intermediate from in situ nitrification nitrite started to increase through the rising falling boundary with the major increase at the end of ending during the baseflow the amoa gene ammonia oxidizing microbes was greater than the nxra gene nitrite oxidation bacteria while the nxra gene increased substantially during the flood fig 8a b c when ammonium and the ratio of nh4 n din had increased in the water column table 1 yan et al 2019 showed that the ammonium oxidation rate occurred 10 20 times faster than the nitrite oxidation rate during periods of normal flow in the jre thus nitrite accumulated in normal baseflow condition as a result of incomplete nitrification at the etm area yu et al 2019 these results suggest there was more complete nitrification during the flood higher denitrifying ratio of nirs narg could also accelerate net nitrite consumption by denitrification fig 8d e as the estuary reverted to baseflow during the ending nitrite increased while nitrate decreased in the water column fig 6 this implied that there were non steady state changes in nitrification and denitrification rates the sampling was not continued for long enough for the system to revert to its initial steady state condition it has been shown in previous studies of estuaries carried out during normal baseflow that the wetlands and creeks adjacent to the upper estuary are locations where nutrients are removed and stored jickells et al 2014 sanders et al 1997 however as a result of recent land reclamation in many estuaries these areas of wetlands have been reduced thus decreasing the ability of estuaries to act as filters for anthropogenic nutrients fluxing into coastal areas jickells et al 2000 jickells et al 2016 in the jiulong river estuary the total area of the mangrove wetlands has been considerably reduced over the past 20 30 years wang et al 2018 despite this reduction of the wetland area the upper estuary still represents an important location for the removal of anthropogenic nitrogen during normal baseflow yu et al 2019 this area traps sediment containing a high content of labile organic matter yu et al 2015 these surficial sediments then act as a biogeochemical incubator with diagenetic changes taking place in which labile pon is broken down ammonia generated and nitrate formed in the oxic environment found in the surface layers of these tidally affected sediments it is also a location of considerable dissimilatory and other nitrate reduction cao et al 2016 zhang et al 2020 however in this study it has been shown that this removal of nutrients is only temporary since during storms a large fraction of this anthropogenic nitrogen is remobilised as resuspended sediment which results in an increased pulse of diagenetically altered nitrogen down the estuary to the coastal region the relative efficiency of the upper estuary as a temporary nutrient filter and biogeochemical incubator depends on various factors including how long the sediment remains in the wetlands and creek what the ambient temperature was for controlling microbial reaction rate when and how large the storm is and thus how much of sediment is resuspended the results of this study showed the key importance of non steady state floods in increasing the total flux of din exported from the river estuary systems to the nearby coast floods not only result in an increased flux of anthropogenic nitrogen from the river and tidal river catchment but they also remobilize nitrogen which had been temporarily deposited in the estuary during periods of low normal flow it is also noted that this storm was a relatively moderate storm in terms of total water discharge it is likely that storms which occur after a longer period of quiescence and or storms with higher water discharge are likely to result in even greater flushing out of pollutant n from the river estuary system to the coast this increased din flux is likely to result in greater estuarine and coastal eutrophication 5 summary the increased discharge of water from the river during the storm altered the pattern of estuarine salinity the particle distribution and the location of the etm the original location of the etm during the baseflow bracketed station e however during the peak of strom flow the freshwater brackish water boundary moved downstream the distance downstream was controlled by the strength of storm flow during the storm in june 2019 the water passing station e was only freshwater during the high discharge of rising and then changed back to the tidally changing brackish water characteristic of normal flow conditions as the discharge decreased during the storm the input of spm brought down the rivers to the estuary increased substantially in addition there was also a major increase in sediment added scoured in the upper estuary both from the estuary channel and from the adjacent mangrove wetlands and small creeks as the discharge decreased during the falling and particularly ending both the riverine spm and added estuarine spm decreased meanwhile tide also had an effect on the estuarine spm with higher concentrations during low tide high water velocity both during high flow periods of ebb and flood tides caused higher spm both concentrations and fluxes of river inorganic nitrogen increased during the storm the different land use of the jiulong river resulted in spatial differences of inorganic nitrogen between the njr and wjr the njr had high ammonium and nitrite from domestic sewage effluent and intensive animal farming in the upper reaches which were partially oxidized to nitrate by nitrification in the river channel resulting in elevated δ15n no3 the wjr had higher nitrate from excess ammonium fertilizer in upstream pomelo orchards resulting in decreased δ15n no3 in addition the different sources of inorganic nitrogen also resulted in the different response times of the peak value ammonium and nitrite reached peak values at the river mouths faster than nitrate both in the njr and wjr the major source of ammonium and nitrite were from domestic waste from the sewage treatment works together with surface runoff from other agricultural pollutants such as manure animal waste and some types of fertilizer from fields which caused the peak value of δ15n nh4 in the first day of rising however rainfall decreased δ15n nh4 in most river samples by contrast nitrate was delayed somewhat with the concentration firstly decreasing by dilution and then increasing to peak value in the rising the major source of nitrate was from leached soil and groundwater where in situ nitrification had oxidized ammonium fertilizer apart from the river inputs the flux of estuarine din had increased by 40 8 over the elevated values reaching the estuary during the storm the additional fluxes of nh4 n no3 n and no2 n were significantly higher in the rising 55 9 33 4 t d 1 252 8 59 9 t d 1 and 6 2 3 6 t d 1 respectively particularly for nh4 n with increased ratio of nh4 n din this additional nitrogen mostly came from the scour of surface sediments and catchment runoff in the tidal river which had been deposited in the upper estuary and adjacent mangrove wetlands and small creeks during periods of normal flow following falling discharge the concentration of nh4 n decreased both because of decreasing supply from sediment scour after the first storm pulse and due to increased nitrification in the water column evidence in support of this was from increased gene copies of nitrifiers aoa and aob which caused a general decrease in δ15n no3 vs δ18o no3 and a dramatic increase in the δ15n nh4 the sources of additional no3 n in the estuary came partly from increased nitrification however the large increase in no3 n flux compared with nh4 n flux suggested that there were additional processes fluxing nitrate into and through the estuary one such process was the scouring of surficial mangrove sediments which had a large peak of nitrate in the tidally exposed sediment decreased denitrification in the water column was confirmed by the number of copies of the relevant genes higher nxra and lower narg an additional major nitrate source came from ground and soil water discharge in the local estuarine catchment resulting in the delayed peak value as noted above for the river sections this study shows the importance of the upper estuary as a temporary location for nitrogen storage in surface sediments which act as a biogeochemical reactor at least part of these sediments are resuspended during storms and result in altered nitrogen species being transported into the estuary and from there to the coast credit authorship contribution statement jingjie lin conceptualization data curation formal analysis investigation methodology project administration software michael d krom conceptualization formal analysis fenfang wang investigation peng cheng methodology software qibiao yu methodology software nengwang chen conceptualization formal analysis funding acquisition project administration resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the national natural science foundation of china no 41676098 51961125203 we thank all the students who assisted with fieldwork and junou du for technical assistance this work was completed as we came out of the covid pandemic which meant that the collaboration between xiamen and haifa was by remote means and not carried out during a visit of michael d krom as originally planned appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127438 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3673,an important consequence of storms in river estuary systems is major changes in hydrology and nutrients being fluxed from the land to the coastal ocean however the impacts of storms on the nature and amount of dissolved inorganic nitrogen din in the river estuary continuum are poorly understood in this study two week s continuous observations on two lower riverine fixed stations and an estuarine fixed station in the jiulong river se china were carried out during a complete storm event in june 10th to 23rd 2019 suspended particulate matter spm nitrogen species and their isotopic ratios nitrifying and denitrifying functional genes were measured the increased river discharge caused the freshwater brackish water boundary to move downstream and altered the pattern of particle distribution and the location of the estuarine turbidity maximum the increased river spm and inorganic nitrogen was associated with watershed soil erosion sediment scour and land use both in the river and estuary the peak concentration of ammonium arrived faster than nitrate apart from river inputs there was an additional increase of 40 8 of din supplied within the tidal river and estuary the additional din mostly came from resuspended sediments and catchment runoff while increased nitrate also came from soil and ground waters increased nitrification and decreased denitrification in the estuary these results suggest that during baseflow conditions the wetlands in the upper estuary acts as a temporary nutrient trap and biogeochemical incubator while in storms the transformed pollutant n was fluxed from the river estuary continuum to the adjacent coastal areas keywords estuarine turbidity maxima storm flow biogeochemical sediment incubator nitrogen cycling nitrogen isotope jiulong river 1 introduction anthropogenic nitrogen is a major pollutant which has increased dramatically as a result of major fertilizer use to enable us to feed the world s increasing population galloway et al 2008 tilman et al 2002 vitousek et al 1997 with greater than 80 million tons of this extra nitrogen now produced artificially by the haber process liu et al 2005 tilman et al 2002 much of this excess anthropogenic nitrogen is eventually discharged into rivers and from rivers transported via estuaries to coastal waters causing eutrophication problems canfield et al 2010 duce et al 2008 galloway et al 2004 the nature of the nitrogen reaching the river system depends on the balance of anthropogenic activities in the catchment in a mixed activity catchment such as the jiulong river in s e china an important source of excess nitrogen is from the washout of excess fertilizers applied to the land in the form of ammonia and or urea fertilizers lin et al 2020a these fertilizers accumulate in surface soil waters and are subsequently discharged into the river often after having been converted to nitrate by in situ nitrification processes huang et al 2020 zhang et al 2021 the other main source of anthropogenic nitrogen in the jiulong river system is from human sewage discharges from the population centers and from wastes from intensive animal farming bai et al 2019 lin et al 2020b once discharged into the river channel microbial and other biological processes can change the nature of the anthropogenic nitrogen by biological uptake nitrification denitrification anammox and other more minor processes both in the river reservoirs and estuary kaushal et al 2021 lin et al 2020a while all of these processes occur during normal river flow the largest fluxes of nitrogen from the catchment to the sea occurs during major storms gao et al 2018 koschorreck and darwich 2003 rozemeijer et al 2021 during major storms there is generally higher soil erosion resulting in higher suspended particulate matter spm in the river channel baborowski et al 2004 chen et al 2018b excess fertilizers flushed from the fields soil waters and groundwater are discharged into streams and rivers and transported at higher water discharge rates de girolamo et al 2017 marcé et al 2018 storm flow also often causes increased water flow into and through sewage treatment works and intensive agricultural farms whitehead et al 2015 together these processes result in a pulse of higher nitrogen down the river and through the estuary to the sea estuaries are important locations for biogeochemical processes which can alter nutrient fluxes to the coastal sea during normal flow upper estuaries act as traps for nutrients sanders et al 1997 an important component of this trapping is particulate matter with its associated labile particle organic matter pon which is deposited kaiser et al 2014 in adjacent creeks and mudflats jickells et al 2016 in sub tropical estuaries such as the jiulong river an important component of such areas is fringing mangrove forests yu et al 2015 such wetland locations can act as biogeochemical incubators in which diagenetic changes occur in surface sediments which result in changes in chemical nature of the pollutant nitrogen by processes such as ammonification and nitrification and in loss to the atmosphere by denitrification and anammox dong et al 2009 kessler et al 2018 smith et al 2015 such processes are particularly important in the surficial sediments of mangrove wetlands wang et al 2019 wang et al 2021 zhang et al 2020 recently the wetland areas of estuaries worldwide are being reduced as a result of land reclamation which reduces the ability of estuaries to act as nutrient traps jickells et al 2016 and changes the niche and community of nitrogen cycling microbes oczkowski et al 2020 this general process has also occurred in the jiulong river estuary wang et al 2018 however during storms sediment from these wetlands can be resuspended releasing the transformed nutrients into the water column and hence fluxed through the estuary to the coast chen et al 2018a chen et al 2018b an important effect of climate change is that there are more frequent extreme weather events including larger storms annamalai and liu 2005 rozemeijer et al 2021 these general changes increase the importance of understanding in detail the effects of major storms on anthropogenic nitrogen processes and fluxes into the river catchment and through the estuarine system discharging into the ecologically vulnerable coastal areas river watersheds and coast seas were traditionally regarded as two separate systems we have recognized the importance of adopting a holistic perspective in the studies as well as management of these two systems as a whole body but simultaneous observations are still limited in this study we set out to determine in detail the effect of a major storm on the concentration and flux of nitrogen species to and through the jiulong river estuary system in s e china we intensively sampled the river both at the freshwater discharge points from the north and west jiulong river and at a station in the middle of the estuary to determine the rate of water discharge and the concentrations of spm the nitrogen species and their isotopic content the aim was to identify and quantify the fluxes out from the river catchment and estuary during the storm and particularly to examine and understand the biogeochemical and microbial processes which caused increases in the amount and changes in the nature of the nutrients fluxing through the estuary to the coast during the storm the study particularly shows how transformative processes in the upper estuary sediment incubator changes the nature and flux of n species through the river estuary system under storm condition 2 materials and methods 2 1 study site the jiulong river is the second largest river in fujian province southeast china which flows into xiamen bay and thence to the taiwan strait fig 1 with 14 740 km2 drainage area and 3 5 million population in the river catchment the multi year average rainfall in the watershed is 1400 1800 mm chen et al 2018a which is concentrated between may and august fig 2 a its subtropical monsoon climate causes high temperature and rainfall in summer when is frequently buffeted by tropical cyclones and storms the average daily total river discharge arriving to the estuary from the closest hydrological stations zd and pn fig 1 during 2016 to 2019 were 741 2016 el niño year 374 224 2018 la nina year and 425 m3 s 1 respectively the water discharge in baseflow to the jiulong river estuary jre is derived mainly from the north river njr 66 with the west river wjr supplying the remaining 34 chen et al 2018a the upper reaches of the njr pass through longyan city and adjacent areas where it receives discharges of domestic and animal waste lin et al 2020a the downstream flow is regulated by step hydropower stations lin et al 2020a the upper reaches of the wjr pass through large scale pomelo orchards and then flows past zhangzhou city which discharges treated domestic sewage into the river during periods of high flow dikes on both the njr and wjr are opened to control potential flooding upstream and to generate electricity chen et al 2018a the characteristics of the jre in baseflow period is a semi enclosed macrotidal estuary with 100 km2 open water area 3 16 m depth 2 7 4 m tidal range typical semidiurnal tide and 2 3 days of average flushing time cao et al 2005 the southern channel of the jre contains 90 of the discharge to xiamen bay three fixed sampling stations are shown in fig 1 the lower river stations stations zs and jd were chosen to be located above the reaches affected by tides and represent the downstream boundaries of wjr and njr the estuarine station e is in the middle channel of the southern jre and is the core area of estuarine turbidity maxima etm during baseflow period yu et al 2020 yu et al 2019 the catchment areas of wjr and njr are 4011 km2 and 9635 km2 respectively the tidal reach drainage areas above station e are 306 km2 2 2 sampling campaign the monitored storm event was the second major storm in the wet season of june 10th to 23rd 2019 fig 2a there was a period of increased flood discharge from june 11th to june 18th both in the njr and wjr fig 2a b the daily river total discharge was up to a maximum of 2250 m3 s 1 we divided the storm event into four phases initial rising falling and ending according to river total discharge fig 2b the periods of initial rising falling and ending were from 10th to 11th 2 samples 11th to 15th 32 samples 15th to 18th 21 samples and 18th to 23rd 21 samples in station e respectively the definition of baseflow and flood respectively are the periods when the river discharge is less than and more than 1 2 times of the baseflow as used in our previous research by an automatic segmentation procedure bfi f smoothed minima method chen et al 2018a gao et al 2018 yu et al 2019 according to the definition of flooding the storm event also can be divided into two major states baseflow initial and ending and flood rising and falling a total of 76 water samples were collected in station e during the storm including 10 times periods of intensive observation and sampling including 14 h time series measurement 11th to 17th 19th 21st and 23rd fig 2b one sample was taken for isotopic nitrate and one sample for isotopic ammonium were collected at station e each day from june 10 to june 19 the water samples were collected using the 5 l plexiglass samplers at 0 5 m depth situated several meters away from the estuarine bank to ensure that we were sampling the main estuarine conditions these water samples were immediately transferred to 1 l brown bottles using the bottom silicone tube on the plexiglass samplers all samples were immediately placed in portable fridges at 4 and then transported to lab every three days to analyze immediately before being sampled for analysis the brown bottles were shaken vigorously an in situ multi parameter sensor aqua troll 600 usa was fixed on the bottom water of station e 1 m above surface sediments to acquire hourly turbidity and salinity a total of 14 water samples were collected in each river station zs and jd per day during these periods of intensive sampling in station zs wjr a total of 9 isotopic nitrate samples and 9 isotopic ammonium samples were collected per day in station jd njr a total of 8 isotopic nitrate samples were collected per day the sampling and storage schemes in river stations were the same as for station e 2 3 physicochemical analysis in the lab about 500 ml of the water samples were filtered using 47 mm gf f 0 7 μm filters suspended particulate matter spm was determined as the difference between the unfiltered and filtered gf f filters after oven drying 105 to constant weight the filtrate was stored at 4 before being analyzed for ammonium nh4 n nitrate no3 n nitrite no2 n by segmented flow automated colorimetry san analyzer germany and was determined within less than one week the precision of nutrient was estimated by repeated determinations of 10 samples with less than 5 relative error the limit of detection of ammonium nitrate and nitrite was 0 4 μmol l 1 0 1 μmol l 1 and 0 04 μmol l 1 respectively another 50 ml filtrate was stored at 20 for subsequent isotopic analysis the determination of isotopic δ15n no3 and δ18o no3 was carried out by the denitrifier method casciotti et al 2002 sigman et al 2001 using isotope ratio mass spectrometer 100 irms uk isotopic δ15n nh4 was determined by ammonia diffusion method holmes et al 1998 using an isotope ratio mass spectrometer irms germany 2 4 molecular analysis an additional 1 l of water samples was filtered for analysis of nitrifying and denitrifying functional gene abundances using the methods given in detail in lin et al 2020a briefly dna samples were fileted by 3 μm and 0 22 μm isopore tm membrane 47 mm millipore usa and then stored at 80 dna extraction used fastdnatm spin kit for soil millipore usa the 3 μm and the 0 22 μm filters were used for collecting particle attached pa and free living fl microbes respectively nitrification microbes include ammonia oxidizing archaea aoa and bacteria aob by amoa gene and nitrite oxidizing bacteria nob by nxra gene table s1 denitrification reduces nitrate and nitrite by narg nitrate reductase and nirs nitrite reduce the primers of amoa aoa amoa aob nxra narg and nirs came from francis et al 2005 rotthauwe et al 1997 wertz et al 2008 lópez gutiérrez et al 2004 and jung et al 2011 respectively table s1 the qpcr amplification used a bio rad cfx96 qpcr table s2 2 5 auxiliary data calculations carried out and statistical analysis hourly river discharge was obtained from local government at the closest hydrological stations zd and pn fig 1 the tidal range at shima tide gauge was obtained from the national maritime information service https www cnss com cn tide the river fluxes were calculated using the formula flux njr wjr concentration njr wjr discharge njr wjr respectively where the concentration was the measured daily concentration and the discharge was the river discharge at the river exit points the estuarine flux was calculated using the formula flux jre concentration low tide discharge njr 1 03 discharge wjr 1 08 where the concentration was the measured concentrations at low tide 0 psu multiplied by the summed daily river discharge modified using the ratios of catchment area which was 1 03 njr and 1 08 wjr between hydrological stations zd and pn and station e to identify the impact of the storm events on estuarine velocity and salinity a three dimension numerical model regional ocean modeling system roms which has been developed for the jre cheng et al 2019 cheng et al 2020 this model calculates salinity and velocity with 15 layers 0 3 m depth per layers using 48 800 m grid spacing and 339 165 grid points the river discharge conditions used in the model was the measured river discharge during the storm and the average discharge of baseflow 745 m3 s 1 the δ water velocity shown in fig 2d indicates the difference between modeled hourly estuarine velocities under the storm and baseflow conditions δ concentration flux indicate the difference between the estuary station e and the flow weighted mean river concentration summed flux stations zs and jd anova analysis was performed using the spss program to test the difference of hydrological parameters and n species at low high tides during the four phases of the storm using the kolmogorov smirnov test and variances homogeneous test 3 results 3 1 hydrological conditions during the storm the njr contributed 73 4 of the total river discharge to jre while the wjr discharge was the remainder the average hourly river total discharge was 730 88 m3 s 1 in the baseflow increasing to 1544 442 m3 s 1 in the flood table 1 the hourly estuary discharge and velocity at station e respectively were 330 1388 m3 s 1 and 0 12 0 44 m s 1 the δ water velocity i e the increase caused by the storm was significantly higher during the rising 0 21 0 08 m s 1 than the other periods fig 2d during the baseflow station e had low salinity 0 3 psu at high tide and freshwater at low tide as the discharge increased rising and initial part of the falling freshwater occupied station e as the discharge decreased falling to ending there was again increased salinity during periods of high tide at station e fig 3 a b 3 2 variation of suspended particulate matter spm the average concentration of spm discharged from the two rivers during the baseflow was 17 8 mg l 1 wjr and 32 1 mg l 1 njr contributing to the total spm measured in the jre of 105 25 mg l 1 fig 4 a these concentrations resulted in a calculated riverine spm flux of 5049 4701 t d 1 njr and 918 645 t d 1 wjr to the jre which represented in total 27 10 of the flux calculated as passing through the estuary 20365 12469 t d 1 fig 5 a the spm discharged from the two rivers increased reaching a peak of 92 mg l 1 and 17839 t d 1 total calculated concentration towards the end of rising fig 3c the average concentration and flux of spm from the river then decreased back to baseflow values of 27 6 mg l 1 and 2007 438 t d 1 by the ending period during the storm period in addition to spm from the rivers there was additional spm present in the water column at station e fig 4a the flux and δ flux of spm at station e were considerably higher during the rising than during the other periods table 1 in addition to these major average changes in spm there were also relatively minor changes in the concentration of spm at station e between low tide and high tide fig 1a the concentration of spm in surface water was significantly correlated with water velocity during the baseflow both in ebb tide and flood tide fig s2a while the turbidity in bottom water was positively correlated water velocity during the storm only in flood tide fig s2b 3 3 changes in nitrogen species both the wjr and njr contributed riverine nitrogen input to estuary the wjr had higher concentrations of nh4 n no3 n and no2 n than njr fig 4 which resulted in similar total fluxes to the jre fig 5 riverine nh4 n and no2 n increased in concentration during the rising and peaked in the middle of rising before the maximum discharge then they decreased to a minimum at the beginning of falling and returned to baseflow values during the ending by contrast the concentration of no3 n in both the njr and wjr decreased as the discharge increased during the beginning of rising and then increased getting close to baseflow concentrations by the beginning of falling the storm event changed riverine nitrogen fluxes with different patterns for the njr and wjr fig 5 all nitrogen species increased fluxes with rising discharge and gradually recovered to baseflow conditions from the last day of the rising higher fluxes of nh4 n and no3 n were measured in the njr during the baseflow while the fluxes in the wjr exceeded njr during the flood the patterns of nitrogen concentration and flux observed in the estuary were different from the rivers fig 4 fig 5 estuarine nh4 n and no2 n reached its maximum concentration and flux at the beginning of the rising while another peak value of no2 n was detected during the ending fig 6 the ratio of nh4 n din increased from 11 4 to 13 5 during the rising table 1 by contrast the concentration and flux of no3 n started to rise at the beginning of rising and continued to increase reaching a maximum at the end of rising fig 5 fig 6 both the δ concentrations and fluxes of nh4 n and no3 n were considerably higher during the rising while no2 n remained roughly similar table 1 comparing the concentration between low tide and high tide low tide had higher nh4 n and lower no2 n without any significant difference of no3 n fig s1 3 4 nitrate and ammonium isotopes the riverine and estuarine nitrate and ammonium isotopic values are shown in fig 7 the ratios of δ15n no3 at station e 7 0 1 6 were lower than the samples from the exits from the rivers 7 6 0 9 wjr and 8 5 2 1 njr except on june 17th the njr diluted δ15n no3 to 7 2 during the initial and then increased to 9 2 during the rising which then gradually decreased with decreasing discharge the wjr decreased δ15n no3 from 8 2 initial to 6 0 rising and then increased to 8 1 falling by contrast δ15n nh4 estuarine values were lower than the wjr during the initial and then surpassed it during the rising until the late falling the relationship between δ15n nh4 and daily total river discharge was negative in the wjr but positive in the jre fig 7d 3 5 abundances of nitrogen functional genes the abundances of nitrifying and denitrifying genes at station e changed during the storm fig 8 nitrifying genes amoa aoa amoa aob and nxra nob increased 1 7 2 6 and 2 1 times during the flood the amoa aoa and nxra genes initially decreased during the first day of falling and then returned to baseflow values at the end of falling while amoa aob remained at peak abundance in the middle of falling and then decreased during the ending for those genes associated with nitrifiers aoa and nob reached their maximum abundance faster than aob nob was always less than aoa and aob during the baseflow while it exceeded ammonia oxidizing microbes aoa and aob during the flood aob was always more than aoa aob peaked during the falling by contrast denitrifying genes narg and nirs decreased 2 1 and 1 9 times during peak discharge fig 8d e the difference between narg and nirs abundances was similar during the initial and increased with increasing discharge resulting in far less narg than nirs the nirs gene reached low abundance earlier than the narg gene 4 discussion 4 1 effects of the storm on estuarine hydrological and sedimentological conditions during normal baseflow the freshwater brackish water boundary is in the region of a5 a7 fig 1 upstream of station e chen et al 2018b yu et al 2020 this is the location of the etm zone during storm flow the freshwater brackish water boundary moves downstream depending on the intensity of storms and the corresponding increase in freshwater discharge chen et al 2018a this was also the pattern in this study fig 3 during the baseflow there was fluctuating salinity at station e changing from 0 to 3 which is the characteristic of the etm fig 3a b during the rising and the most of falling the water column at station e was entirely fresh therefore the flow changed to the higher flow rate characteristic of typical river storm flow during the storm fig 3a b once the discharge decreased at the end of falling and through the ending period the freshwater brackish boundary migrated upstream to mid estuary station e again which had tidal changes in salinity again these changes in estuarine circulation have important consequences on sediment dynamics under normal baseflow conditions sediments brought down the river together are deposited in the upper estuary above station e forming a layer of relatively unconsolidated sediments in the main channel and in the adjacent wetland and side creeks including mangrove wetlands chen et al 2018a yu et al 2020 as typically occurs in storms there was an increase in total spm at station e which correlated with the increase in freshwater discharge during the rising table 1 this increased spm was due both to an increase in sediments brought down the river and an additional increase of spm due to sediment supplied by local resuspension processes in the upper estuary fig 4a during rainstorms the sediments load out from the jiulong river watershed increases chen et al 2018b this increase is caused by soil erosion in both the wjr and njr catchments together with deliberate flushing of sediments behind some of the hydroelectric dams particularly in the njr chen et al 2018a in addition there are also resuspended sediments scoured from the upper estuary channel and particularly adjacent wetlands and creeks de haas and eisma 1993 wengrove et al 2015 in the case of the jiulong estuary an important component of these areas are mangrove wetlands yu et al 2015 these sediments deposited during previous periods of low flow are likely to be rich in labile organic matter when deposited yu et al 2019 under the extant conditions of relatively high temperatures especially in summer these sediments act as a biogeochemical incubator undergoing characteristic diagenetic changes chen et al 2018b tan et al 2020 zhang et al 2020 as a result of the resuspension of these sediments and their pore waters during the storm there were considerable changes in the n biogeochemistry of the water column see following sections the maximum turbidity was 520 ntu rising fig 3c which was considerably higher than baseflow values but less than many previous storms thus yu et al 2019 found the maximum spm in the jre was up to 1500 mg l 1 during the peak discharge of 3000 m3 s 1 in 2016 the magnitude of spm during storms is a result of complex interaction of factors including the magnitude of the discharge and the period of time since the last major storm chen et al 2018b it is suggested the relatively low spm during this storm june 2019 maybe because this storm was not as intense as some previous storms and because it was the second one of a succession of storms fig 2a and thus much of the previously deposited sediments had already been flushed out from the upper estuary the variation of spm at station e was also partially controlled by tide throughout the storm there was higher spm in the surface water during low tide because the surface water was carrying higher amounts of river derived spm fig s1 in addition there was a significant positive correlation between water velocity and spm fig s2 the maximum values of landward velocity and spm were both during the rising table 1 during baseflow condition there was relatively higher spm in ebb tide bringing river derived particles than in flood tide which contained a higher proportion of particles derived from the brackish part of the estuary by contrast in the bottom water there was no difference in the amount of spm in the water column between ebb and flood tides 4 2 nature of nitrogen discharges into the river during periods of normal flow anthropogenically derived inorganic nitrogen chemical species are discharged into the river and transported towards the estuary lin et al 2020a higher fluxes of nh4 n and no2 n were detected in the njr than wjr during the baseflow fig 5b c most of the riverine nh4 n and no2 n comes from domestic secondary sewage discharge from zhangzhou city in the lower reaches of wjr chen et al 2014 chen et al 2015 and longyan city in the upper reaches of njr lin et al 2020a an additional important source of these nitrogen compounds is animal wastes particularly from the intensive pig production in the upper njr catchment cao et al 2015 lin et al 2020a by contrast no3 n predominantly comes from excess ammonium fertilizer added to upstream fields which is nitrified in or on the soil and then runs off into the river channels evidence confirming this pattern comes from the isotopic ratios determined in the water column fig 7 and a recent study by huang et al 2020 the slightly lower δ15n no3 in the wjr compared with njr fig 7a is inferred to be due to the high fertilizer application in the intensive pomelo orchards in the upper wjr catchment lin et al 2020a in addition both manure sewage ms and ammonium fertilizer af can be oxidized by nitrification to nitrate in the oxic water column of the river channels and within surface riverine sediments particularly during the wet summer season with higher ambient temperature lin et al 2020a the isotopic content from the initial to ending are shown in fig 7 the values are consistent with leached soil and groundwater which resulted in lower δ15n no3 from extensive in situ nitrification fig 7a b previous work has found that the isotopic values of δ15n no3 and δ18o no3 in both the njr and wjr during normal flow were the result of nitrate being flushed out into the river from different types of land use huang et al 2020 lin et al 2020a the dominant nitrate source in the njr was derived from the nitrification of domestic and animal derived sewage huang et al 2020 and as a result had elevated δ15n no3 9 2 to 29 7 johannsen et al 2008 as shown in fig 7a by contrast in the wjr most of the nitrate was derived from ammonium fertilizer fig 7b which was applied to agricultural soil in the watershed and had lower δ15n no3 0 4 kendall 1998 4 3 effects of the storm on riverine nitrogen as discharge increased during storms there had an increase in anthropogenic din exported from the jiulong watershed to the estuary gao et al 2018 as has been observed in other river systems mooney and mcclelland 2012 peierls et al 2003 nh4 n and no2 n increased rapidly in both concentration and total flux fig 4 fig 5 a major source of these increased nitrogen compounds was from the flushing of domestic waste from the sewage treatment works of the zhangzhou city on the wjr lin et al 2020b together with surface runoff from other agricultural pollutants such as manure animal waste and some types of fertilizer from fields in the lower watershed of both wjr and njr chen et al 2012 other possible sources are from animal waste particularly in the njr though this will take some time before it reaches the estuary cao et al 2015 the negative relationship of δ15n nh4 with river discharge in the wjr fig 7d indicates that dilution by rainfall was the major factor changing the fraction of riverine nitrogen isotope since the rainwater in south china has a lower δ15n nh4 12 4 to 0 6 jia and chen 2010 the only exception was on june 12th rising when there was an increase in isotopic ratio likely due to ammonia addition of urban sewage with higher δ15n nh4 9 2 to 29 7 lee et al 2016 by contrast to reduced nitrogen the increase in concentration of riverine no3 n was delayed somewhat with the concentration initially decreasing at the beginning of rising presumably by rainfall dilution and then increasing to peak value in the later part of rising fig 4d this pattern has been observed previous in the jiulong river gao et al 2018 and in the elbe river jacob et al 2016 it is likely that this delay is because a major source of no3 n is from nitrate present in the surface soil and groundwater which is leached out as the rainwater infiltrates into the soil and washes the interstitial nitrate out into the stream and hence river channels johannsen et al 2008 4 4 effects of the storm on estuarine nitrogen in addition to the increase in nitrogen reaching the estuary during the storm as a result of increased river discharge there was extra inorganic nitrogen added to the estuary water by processes within the tidal river and estuary this additional concentration and flux was considerably higher during the rising than other periods table 1 this also was the period in which there was major sediment scour from the upper estuary wetlands and catchment runoff this scour caused the sediment pore waters which are rich in nitrogen species dissolved and adsorbed together with their associated bacteria to be released into the overlying water and observed fluxing past station e in the middle of the rising there was a major net increase in nh4 n which tripled from 24 µmol l 1 to a maximum 67 µmol l 1 fig 6a which represented a net increase of greater than 100 t d 1 nh4 n added to the estuary compared to the river flux fig 5a the anoxic conversion of labile pon to ammonium is an important process in estuarine sediments particularly in recent mangrove wetlands salt marshes and creek sediments adjacent to estuaries chen et al 2018a sumi and koike 1990 this ammonium is likely to be flushed out by surface sediment scour and catchment runoff in the tidal river during the storm fig s1b simultaneously ammonium will be desorbed from resuspended sediment particles because the concentration of ammonium in the water column of jre is much lower than that in the surface sediment pore waters yu et al 2020 from its peak of 67 µmol l 1 at the beginning of rising fig 6a ammonium steadily decreased through the remaining rising and through falling to 20 µmol l 1 this decrease in added ammonium could be due to a decrease in the amount of ammonium associated with the scoured estuarine sediments after the first storm pulse fig 2a however an additional and likely important contributing factor to this decrease is nitrification in the water column evidence for this process comes several observations firstly there was a major increase in nitrate in the water column see below for discussion of possible other reasons for that increase in addition there was increasing gene copies of ammonia oxidizing microbes with peak values of aoa found in the middle of rising and aob in the falling fig 8a b there was also a general decrease in δ15n no3 vs δ18o no3 through the jre except for one anomalous point during the falling and a dramatic growth in δ15n nh4 fig 7 such changes are characteristic of nitrification böttcher et al 1990 casciotti et al 2002 the observed positive relationship between δ15n nh4 and daily river discharge in the jre fig 7d suggests that the increased δ15n nh4 could derive from nitrification 14 to 27 casciotti 2009 though it could also come in part from sewage inputs 9 2 to 29 7 lee et al 2016 as shown in fig 7c the concentration of nitrate between the lower river stations and station e increased considerably from 175 µmol l 1 initial to a maximum of 290 µmol l 1 at the end of rising fig 6c part of this increase in nitrate was likely due to nitrification in the water column from ammonium which decreased by 56 µmol l 1 from its maximum at the beginning of rising compared with its concentration at the end of rising however the increase in concentration of nitrate of 115 µmol l 1 was much greater than the decrease in ammonium while the calculated flux of nitrate through the estuary during the rising was five times more than the flux of ammonium table 1 this means that there had to be other sources of nitrate to the estuary other than in situ nitrification in the water column there are several possible additional processes which could add nitrate to the estuary during storms in estuarine and mangrove sediments there are typically a peak in nitrate at or close to the sediment water interface due to a nitrification denitrification couple as surface sediments are resuspended both nitrate and ammonium will be released into the water column the relative amounts of nitrate and ammonium will depend on the depth of scoured sediments it is likely to be particularly rich in nitrate in sediments which are periodically exposed during tidal changes as is typical in mangrove wetlands an additional contributing factor to this increase in nitrate was a decrease in denitrification it was observed that there was a decrease in the abundances of denitrifying genes towards the end of rising where these genes reached pre storm abundances only after the falling fig 8d e this is suggestive of a more oxic less anoxic system in the jre during the storm finally as noted above for the river sections during storm flow there was a substantial increase in nitrate which came from ground and soil water discharge which was slightly delayed from the initial increase in water discharge it is likely that there was a similar addition of nitrate from the areas in the immediate catchment of the estuary i e that the heavy rainfall will cause previously formed nitrate in the adjacent fields and mudflats to be flushed out into the estuary during storm flow it is not possible without a total nitrate budget to determine the relative importance of these various processes to the observed increase in nitrate through the jre during the peak of the storm during the storm the concentration of nitrite decreased from the initial until halfway through the rising fig 4c suggesting that nitrite was being diluted by increased discharge more than the increase of nitrite as an intermediate from in situ nitrification nitrite started to increase through the rising falling boundary with the major increase at the end of ending during the baseflow the amoa gene ammonia oxidizing microbes was greater than the nxra gene nitrite oxidation bacteria while the nxra gene increased substantially during the flood fig 8a b c when ammonium and the ratio of nh4 n din had increased in the water column table 1 yan et al 2019 showed that the ammonium oxidation rate occurred 10 20 times faster than the nitrite oxidation rate during periods of normal flow in the jre thus nitrite accumulated in normal baseflow condition as a result of incomplete nitrification at the etm area yu et al 2019 these results suggest there was more complete nitrification during the flood higher denitrifying ratio of nirs narg could also accelerate net nitrite consumption by denitrification fig 8d e as the estuary reverted to baseflow during the ending nitrite increased while nitrate decreased in the water column fig 6 this implied that there were non steady state changes in nitrification and denitrification rates the sampling was not continued for long enough for the system to revert to its initial steady state condition it has been shown in previous studies of estuaries carried out during normal baseflow that the wetlands and creeks adjacent to the upper estuary are locations where nutrients are removed and stored jickells et al 2014 sanders et al 1997 however as a result of recent land reclamation in many estuaries these areas of wetlands have been reduced thus decreasing the ability of estuaries to act as filters for anthropogenic nutrients fluxing into coastal areas jickells et al 2000 jickells et al 2016 in the jiulong river estuary the total area of the mangrove wetlands has been considerably reduced over the past 20 30 years wang et al 2018 despite this reduction of the wetland area the upper estuary still represents an important location for the removal of anthropogenic nitrogen during normal baseflow yu et al 2019 this area traps sediment containing a high content of labile organic matter yu et al 2015 these surficial sediments then act as a biogeochemical incubator with diagenetic changes taking place in which labile pon is broken down ammonia generated and nitrate formed in the oxic environment found in the surface layers of these tidally affected sediments it is also a location of considerable dissimilatory and other nitrate reduction cao et al 2016 zhang et al 2020 however in this study it has been shown that this removal of nutrients is only temporary since during storms a large fraction of this anthropogenic nitrogen is remobilised as resuspended sediment which results in an increased pulse of diagenetically altered nitrogen down the estuary to the coastal region the relative efficiency of the upper estuary as a temporary nutrient filter and biogeochemical incubator depends on various factors including how long the sediment remains in the wetlands and creek what the ambient temperature was for controlling microbial reaction rate when and how large the storm is and thus how much of sediment is resuspended the results of this study showed the key importance of non steady state floods in increasing the total flux of din exported from the river estuary systems to the nearby coast floods not only result in an increased flux of anthropogenic nitrogen from the river and tidal river catchment but they also remobilize nitrogen which had been temporarily deposited in the estuary during periods of low normal flow it is also noted that this storm was a relatively moderate storm in terms of total water discharge it is likely that storms which occur after a longer period of quiescence and or storms with higher water discharge are likely to result in even greater flushing out of pollutant n from the river estuary system to the coast this increased din flux is likely to result in greater estuarine and coastal eutrophication 5 summary the increased discharge of water from the river during the storm altered the pattern of estuarine salinity the particle distribution and the location of the etm the original location of the etm during the baseflow bracketed station e however during the peak of strom flow the freshwater brackish water boundary moved downstream the distance downstream was controlled by the strength of storm flow during the storm in june 2019 the water passing station e was only freshwater during the high discharge of rising and then changed back to the tidally changing brackish water characteristic of normal flow conditions as the discharge decreased during the storm the input of spm brought down the rivers to the estuary increased substantially in addition there was also a major increase in sediment added scoured in the upper estuary both from the estuary channel and from the adjacent mangrove wetlands and small creeks as the discharge decreased during the falling and particularly ending both the riverine spm and added estuarine spm decreased meanwhile tide also had an effect on the estuarine spm with higher concentrations during low tide high water velocity both during high flow periods of ebb and flood tides caused higher spm both concentrations and fluxes of river inorganic nitrogen increased during the storm the different land use of the jiulong river resulted in spatial differences of inorganic nitrogen between the njr and wjr the njr had high ammonium and nitrite from domestic sewage effluent and intensive animal farming in the upper reaches which were partially oxidized to nitrate by nitrification in the river channel resulting in elevated δ15n no3 the wjr had higher nitrate from excess ammonium fertilizer in upstream pomelo orchards resulting in decreased δ15n no3 in addition the different sources of inorganic nitrogen also resulted in the different response times of the peak value ammonium and nitrite reached peak values at the river mouths faster than nitrate both in the njr and wjr the major source of ammonium and nitrite were from domestic waste from the sewage treatment works together with surface runoff from other agricultural pollutants such as manure animal waste and some types of fertilizer from fields which caused the peak value of δ15n nh4 in the first day of rising however rainfall decreased δ15n nh4 in most river samples by contrast nitrate was delayed somewhat with the concentration firstly decreasing by dilution and then increasing to peak value in the rising the major source of nitrate was from leached soil and groundwater where in situ nitrification had oxidized ammonium fertilizer apart from the river inputs the flux of estuarine din had increased by 40 8 over the elevated values reaching the estuary during the storm the additional fluxes of nh4 n no3 n and no2 n were significantly higher in the rising 55 9 33 4 t d 1 252 8 59 9 t d 1 and 6 2 3 6 t d 1 respectively particularly for nh4 n with increased ratio of nh4 n din this additional nitrogen mostly came from the scour of surface sediments and catchment runoff in the tidal river which had been deposited in the upper estuary and adjacent mangrove wetlands and small creeks during periods of normal flow following falling discharge the concentration of nh4 n decreased both because of decreasing supply from sediment scour after the first storm pulse and due to increased nitrification in the water column evidence in support of this was from increased gene copies of nitrifiers aoa and aob which caused a general decrease in δ15n no3 vs δ18o no3 and a dramatic increase in the δ15n nh4 the sources of additional no3 n in the estuary came partly from increased nitrification however the large increase in no3 n flux compared with nh4 n flux suggested that there were additional processes fluxing nitrate into and through the estuary one such process was the scouring of surficial mangrove sediments which had a large peak of nitrate in the tidally exposed sediment decreased denitrification in the water column was confirmed by the number of copies of the relevant genes higher nxra and lower narg an additional major nitrate source came from ground and soil water discharge in the local estuarine catchment resulting in the delayed peak value as noted above for the river sections this study shows the importance of the upper estuary as a temporary location for nitrogen storage in surface sediments which act as a biogeochemical reactor at least part of these sediments are resuspended during storms and result in altered nitrogen species being transported into the estuary and from there to the coast credit authorship contribution statement jingjie lin conceptualization data curation formal analysis investigation methodology project administration software michael d krom conceptualization formal analysis fenfang wang investigation peng cheng methodology software qibiao yu methodology software nengwang chen conceptualization formal analysis funding acquisition project administration resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the national natural science foundation of china no 41676098 51961125203 we thank all the students who assisted with fieldwork and junou du for technical assistance this work was completed as we came out of the covid pandemic which meant that the collaboration between xiamen and haifa was by remote means and not carried out during a visit of michael d krom as originally planned appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127438 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3674,extreme rainfall events can devastate urban and rural infrastructure affect the economy and even lead to loss of life in this work we propose an approach based on long short term memory networks lstm to forecast precipitation volume extreme rainfall using multivariate time series data our methodology combines reanalysis data from 12 isobaric pressure levels surface data and data from meteorological stations from brazil s southeastern region our method allows handles the imbalanced data typical of time series data used for this type of problem in order to identify the best model we performed several experiments with different configurations of lstm networks the test results showed that the best prediction model has as input previous data up to 24 h for a forecast of 6 h ahead with a mean absolute error mae of 6 9 mm and root mean squared error rmse of 6 94 mm our methodology shows the possibility to use reanalysis data from global mathematical models to obtain less computationally expensive regional models keywords extreme rain event forecasting models data driven modelling long short term memory neural networks machine learning 1 introduction a large amount of the available scientific literature claims that in this century there will be a significant increase in extreme weather events and consequently extreme rainfall events or at the very least an increase in the proportion of heavy rainfall in many areas of the planet field et al 2012 frame et al 2020 lima et al 2021 machado et al 2021 as stated in the intergovernmental panel on climate change report titled managing the risk of extreme events and natural disasters and promoting adaptations to climate change ipcc 2012 even in regions where there will be a reduction in total annual precipitation there will be an increase of extreme rainfall events meaning more heavy rainfall events in a shorter period of time field et al 2012 extreme rainfall is a complex event governed by multiple atmospheric o gorman and schneider 2009 duan et al 2017 pour et al 2020 kodra et al 2020 traditionally weather forecast models are based on mathematical equations to represent the physical laws that govern the movements of the atmosphere and interactions among several different systems that compose the climate system when using data driven modelling ddm models are not based on primary laws instead they are derived directly from a learning algorithm using data from previous observations a data driven model should reflect the patterns in the training dataset as accurately as possible but it must also have a high level of generalization i e the ability to provide an adequate prediction for unseen data herzog et al 2018 a numerical weather forecasting system numerical weather prediction nwp involves a series of sub processes such as the collection modelling and processing of atmospheric data from surface and altitude weather stations satellites and weather radars these systems are used to calculate the atmospheric conditions of a region at a given time interval coiffier 2011 the nwp systems which combine mathematical models with observations create datasets for climate monitoring and research known as reanalysis data the reanalysis data contains estimates of atmospheric parameters such as air temperature pressure and wind at different altitudes and surface parameters such as precipitation soil moisture content height of ocean waves and temperature of the sea surface these estimates are produced for all locations on the planet and span several decades ddm using artificial intelligence techniques are not entirely new on weather prediction geng et al 2014 choubin et al 2016 ramsundram et al 2016 comeaud et al 2017 scher 2018 samadianfard et al 2019 in particular for extreme weather events several approaches have applied artificial intelligence techniques for prediction and classification of extreme rainfall and severe winds mcgovern et al 2017 predict cyclones atmospheric rivers frontal systems cold hot liu et al 2016 and prediction of heat waves iglesias et al 2015 weather forecasting based on ddm has series of challenges such as abstraction of spatio temporal information high dimensionality and imbalanced datasets in wang and ding 2015 the authors proposed a framework for learning patterns of the space time system and predicting extreme weather events using clustering and classification techniques di et al 2015 proposed an equivalent approach to the previous one but differentiating extreme and ordinary rainfall events forming clusters according to the volume of precipitation after balancing and reducing the dimensionality of the dataset they applied the k nearest neighbor algorithm knn to match events to their respective clusters essentially creating a predictive model similarly hua and simovici 2016 implemented a model combining hierarchical clustering to identify locations with similar atmospheric conditions and used a multivariate time series data model bayesian structural vector autoregression bsvar to make the prediction gaitan et al 2016 used several sources of data such as precipitation data social and economic data and data on flood incidents in the netherlands they applied clustering to obtain spatially well defined groups in relation to the volume of precipitation and were able to predict the impact of floods with a volume of 70 mm in 6 h yang et al 2007 segmented sequences of satellite images to extract information from images subsequently they trained a decision tree to classify rainfall events as extreme or ordinary lee et al 2014 used support vector machine svm to classify extreme and ordinary precipitation in order to address the high dimensionality of the data the authors employed a feature selection approach based on genetic algorithms in kisi et al 2019 the monthly rainfall amounts were estimated through the svm and the geostatistical kriging approaches so the latitude longitude altitude were introduced as model inputs for simulating monthly rainfall values other studies used artificial neural networks ann for rainfall prediction phusakulkajorn et al 2009 wu and chau 2013 taormina and kwok wing chau 2015 phusakulkajorn et al 2009 transformed the time series of rainfall volume by wavelet decomposition this preprocessing decomposes a series of data originally described in the time domain allowing it to be analyzed in different frequency scales and time periods after this transformation they used an ann to predict the volume of rain for consecutive days wu and chau 2013 combined soft computing approaches for rainfall prediction the authors proposed preprocessing techniques included moving average ma and singular spectrum analysis ssa ghil et al 2002 their results showed that the ma was superior to the ssa when combined with ann taormina and kwok wing chau 2015 proposed the estimation of prediction intervals pis for operational streamflow forecasting the method constructs an ann with two output neurons in order to approximate the lower and upper bounds of the pis the authors establish the importance of choosing the proper prediction interval in the design of forecasting models kisi and shiri 2011 and azad et al 2019 proposed models based on neuro fuzzy techniques for dealing with the non linear characteristics of the process of precipitation in kisi and shiri 2011 the authors considered wavelet coefficients as inputs in order to represent variations trends and periodicities in time series the results show that the proposed models are effective in forecasting daily precipitation and simulating monthly rainfall magnitudes respectively the main difference between these works and our proposal is that we make predictions of rainfall volume from 6 to 48 h ahead with 6 hour intervals furthermore we consider historical values of atmospheric variables without applying feature extraction processes from the time series these processes transform original data and can cause the loss of relevant information sulaiman et al 2018 modelled regional precipitation patterns considering three predictive models based on ann svm and random forest rf techniques for each region the authors discuss what technique was more efficient to predict the spatial distribution of precipitation in watersheds with limited meteorological data misra et al 2018 claim that long short term memory lstm neural networks are capable of capturing a signature on the variables at a time before the extreme rainfall event thus presenting better results than other algorithms it is worth noting that in that study there is a complex stage of pre processing to segment the rainfall into three categories according to its intensity weak medium and strong the authors also used principal component analysis and decision trees to select the best predictor variables to be used as input to the lstm neural network they used the following variables as predictive features maximum and minimum temperature mean sea level pressure specific humidity at 500 hpa zonal wind velocity and meridional wind velocity in contrast to the work proposed in misra et al 2018 our predictive variables were eleven surface variables eight pressure levels variables of 200 to 1000 hpa the pressure level of 1000 hpa was chosen based on the significant presence of humidity which can influence the rainfall after analyzing the related works we were able to enumerate the main challenges common to the different approaches 1 high dimensionality there is a large number of variables and information available to characterize the rainfall due to the fact that data are arranged according to time and space each data available can be multiplied by many different instances atmospheric levels for each latitude longitude quadrant etc thus a weather prediction dataset can easily have thousands or millions of variables 1 1 the european centre for medium range weather forecasts ecmwf era interim 2019 collects and provides global weather data every six hours considering only the northern hemisphere there are 320x161 grids and seven isobaric surfaces 200 300 500 700 850 925 and 1000hpa each grid has 254 climatic variables the total number of information fields in climatic data can reach 91 602 560 320x161x7x254 the era interim database considers information from several sources such as satellites radio aircraft ships etc from a data mining perspective domingos 2012 points out that high dimensionality is one of the biggest challenges in machine learning and highlights two problems 1 increase in generalization difficulty as the number of attributes grows and 2 breaking of thinking based on similarities typically two strategies are proposed to deal with this problem i to consider the whole dimension which demands adequate approaches techniques and algorithms for big data scenarios or ii to apply a dimensionality reduction process which demands a feature selection process e g via genetic algorithm genetic algorithms and other feature selection approaches notably demand great computational efforts in addition to that prediction of rainfall volume is a complex non linear and multivariable problem therefore any dimensionality reduction strategy can significantly impact the performance of the prediction model hence the participation of domain experts in the feature selection process is important in order to obtain more representative models deng et al 2020 2 data imbalance the imbalance problem is very common in the real world in cases of extreme rainfall prediction it is critical this is because the occurrence of extreme precipitation is much less common than ordinary precipitation in order to deal with the imbalance several articles wang and ding 2015 di et al 2015 wan et al 2012 gu and wan 2010 used several thresholds from 90 to 99 of the normal distribution to distinguish extreme rainfall from ordinary rainfall and then deal with the imbalance but there is no consensus for this threshold stephenson et al 2008 3 spatial resolution of the data versus the scope of the phenomenon depending on the spatial resolution and temporal evolution of the atmospheric variables it may be necessary to obtain a greater spatial resolution in order to accurately describe the phenomenon thus one must consider the capacity of the variables used to represent space time information and the relationship among them segregating and isolating data at a lower resolution may not be realistic as the dominant atmospheric process may operate at a scale greater than the chosen scale 4 to deal with the challenges mentioned above one of the main strategies observed in the literature is differentiating extreme moderate and mild rainfall events and predict precipitation volume according to the predicted severity of the event note that this differentiation implies two forecasts first knowing what level of severity the forecast is at and then determining the precipitation forecast within that category in order to increase the reliability of the model it would be interesting to reduce the number of stages of predictions thus a challenge would be to obtain standalone models for predicting all rainfall events including extreme and ordinary rainfall 5 complexity of models most of the proposed models involve the application of various techniques and are strongly dependent on an ordered sequence of procedures which normally are difficult to reproduce 6 explainability of models the proposed approaches may result in models with little capacity for interpretation understanding the cause and effect conditions of a given phenomenon is often as important as its prediction and this is the case with extreme rainfall events in this work we propose a data driven model ddm minaya et al 2018 from the exploratory study of reanalysis data and a methodology based on data mining dm techniques to predict extreme rainfall events the proposed approach combines reanalysis data from the european centre for medium range weather forecasts ecmwf era interim era interim 2019 dee et al 2011 to characterize the dominant processes over conditions of extreme rainfall seasonality on a regional scale with rainfall data from automatic surface stations at the national institute of meteorology inmet inmet 2020 the model aims to identify atmospheric patterns extracted from historical records of extreme rainfall events in order to predict based on the capture of atmospheric disturbances that occur in previous moments upcoming rainfall volume as a differential of our work we addressed the aforementioned challenges as follows with domain knowledge and as suggested by lima et al 2010 we selected 12 levels of atmospheric pressure and their predictive variables for rain events provided by the era interim database to represent each location in the dataset we gave the state of these variables between 6 and 96 h earlier prior to the target time point this framing of the problem is known as a multi stage time series forecasting problem with the possibility of also predicting several time points ahead in order to handle non linear characteristics of the atmospheric process we treated precipitation data as a complete time series and trained an lstm neural network capable of capturing cycle characteristics and seasonality of the series note that the proposed methodology is able to simplify additional steps unlike other studies such as balancing the dataset and reducing the dimensionality and it can be applied to other regions and localities provided that the target region is fixed besides lstms neural networks an improvement of the recurrent neural networks are able to capture spatial temporal dependencies these nets can preserve long term information control how much information to store and how much to discard this characteristic allows dealing with multi stage time series forecasting problems with the possibility of also forecasting several time points ahead for extreme and ordinary events as a case study we considered the metropolitan region of belo horizonte mrbh minas gerais state brazil latitude 18 75 to 20 25 and longitude 45 to 43 50 in the period from 2006 to 2016 in the chosen region drainage infrastructure is deficient even low magnitude rainfall if happening over short periods of time hours can cause flooding and have catastrophic consequences in the region marcelino et al 2006 this reinforces the relevance of proposing forecast models for predicting extreme rainfall events ere in this region the results suggest that climatic variables measured between 96 and 6 h before an ere can be used to reliably estimate the volume of precipitation in the near future 6 to 48 h and consequently whether there will be extreme rainfall event the classification of rainfall in belo horizonte shows that rainfall in the range of 30 to 50 mm is considered heavy rain and rainfall greater than 50 mm is classified as extremely intense reis et al 2004 it is important to emphasize that the proposed methodology is not dependent on a specific study region although the definition of extreme rainfall events may need to be localized 2 methodology materials and methods this section describes the considered databases and proposed methodology for building the forecasting model of extreme rainfall events fig 1 shows the flow of the methodology step 1 definition of the region and period of study step 2 data collection and extraction procedures step 3 conceptualization and characterization of the prediction model step 4 dataset composition combination era interim dataset with the precipitation variable from automatic stations and pre processing involving inconsistencies analysis data normalization dataset balancing training and validation processes step 5 construction of the lstm neural model finally step 6 tests and analysis of results in this last step we analyze several models considering different forecast horizons and previous historical data we identified the best models and highlighted their main characteristics we discuss the performance of our methodology for the prediction of extreme and ordinary rainfall situations and discuss its temporal predictive capacity 2 1 materials 2 1 1 data source from reanalysis database we used data from the era interim reanalysis database collected from 2006 to 2016 era interim 2019 the data has a spatial resolution of 0 75x0 75 80 km2 comprising the area between latitude 30 and 0 41 intervals and longitude 60 and 0 81 intervals totaling 3321 grids that correspond to brazil s southeastern region the reanalysis data from era interim are stored in the network common data form format netcdf3 for this study we consider only surface and pressure level variables fig 2 illustrates the grid for data collection at a horizontal resolution of 0 75 in latitude and longitude with 37 vertical pressure levels from the surface to 0 1 hpa 2 1 2 atmospheric variables from reanalysis era interim reanalysis data is available every 6 six hours namely 00 00 06 00 12 00 18 00 utc universal coordinated time of each day the database provides 254 atmospheric variables for 37 available pressure levels in our approach we considered 14 variables see table 1 the pressure levels are arranged from the highest isobaric altitude to the lowest altitude in the atmosphere from 1 to 1000 hpa table 2 shows the 77 surface variables available from era interim database grouped by category 2 1 3 data from the surface meteorological stations the precipitation data recorded on the surface were provided by the brazil s national institute of meteorology inmet inmet 2020 for the period from 2000 to 2016 recorded in 122 automatic meteorological stations in the southeastern region table 3 shows the 17 surface variables all of these available from inmet database 2 2 methods fig 3 shows an infographic detailing the different stage of our methodology steps 1 5 see fig 1 selection of the target region data extraction and collection procedures the conceptualization of prediction model dataset composition training and validation of the lstm model 2 2 1 definition of the study region as case study we selected the metropolitan region of belo horizonte brazil mrbh this region is located between the latitudes of 19 00 and 20 30 s and longitudes of 43 15 and 44 45 w in the central area of the state of minas gerais in southeast brazil altogether there are 34 municipalities with 9468 km2 of extension the region has about 6 million inhabitants dsec 2015 being brazil s third most largest urban area after são paulo and rio de janeiro s metropolitan regions in belo horizonte city according to the climatological normal 1981 2010 the pluviometric index is about 1600 mm per year distributed almost entirely between the months of october to march belo horizonte s temperature varies on average between 19 c and 24 c the mrbh is very sensitive to flooding due to the pattern of urbanization inefficient drainage infrastructure and topography where altitudes can vary greatly from one region to another the largest urbanization area is between 751 and 1000 m altitude from north to southwest while the lowest altitudes occur in the northeast between 650 and 750 m the largest altitudes occur in the south and southeast limits between 1001 and 1150 m reaching 1500 m at the top of serra do curral a previous study found a very high correlation of moderate to extreme rainfall with flooding in the mrbh region nunes 2018 hence the relevance of our study 2 2 2 data extraction and collection era interimthe data of the era interim were collected in an automated way in batch by a routine through an application programming interface api webapi 2019 available the ecmwf era interim 2019 using an access key previously requested and parameters such as variables of interest time period format area of interest and resolution due to a limit of 20 gb per request we collected the data over multiple requests over months and then merged them into a single dataset the files obtained from the era interim database in the netcdf3 format conventions cf 1 6 were stored locally and separated into monthly files spanning 10 years 2006 to 2016 each file has the same spatial resolution of 0 75x0 75 between latitude 30 to 0 and longitude 60 and 0 brazil s southeastern region 3 meteorological stations inmet the weather station data was obtained by digital media requested from inmet inmet 2020 stored in files in tabular format grouped by weather station and with hourly information for each variable 3 1 conceptualisation and characterisation of the forecasting model considering the available variables presented in tables 1 2 and 3 and being our goal building a model representative for interactions between the pressure and surface variables with the local precipitation target variable we built a conceptual model based on explicit and tacit knowledge from domain experts lima et al 2010 reis et al 2004 as mentioned the era interim database has 37 pressure levels available for this study we selected 12 levels 200 300 400 500 600 700 750 800 850 900 925 and 1000 hpa as suggested in lima et al 2010 the levels selection was based on the significant presence of humidity and wind component that conceptually contribute to the formation of extreme precipitation and are considered essential predictors in addition the values of the variables do not change significantly every 25 hpa which makes it possible to eliminate intermediate levels we selected 8 out of 14 pressure variables table 1 and 11 out of 77 surface variables table 2 all extracted from the era interim database the precipitation volume the target variable was obtained from inmet s database from automatic surface stations table 3 the temporal aspect of the model was incorporated considering the availability of information provided by era interim of measurements in 6 h intervals era interim was used to represent the best possible atmospheric data input which is data from the reanalysis collected from many sources and grouped with observed variables continuously every 6 h the era interim considers the most realistic atmospheric conditions with very few observation errors notably it can be said that the result of the proposed model has few influences of errors related to the quality of the input data which are very reliable because are real observations 3 1 1 threshold to define an extreme event the prediction of extreme rainfall events is usually performed according to the considered region for its application stephenson et al 2008 for this it is necessary to adjust a threshold in relation to accumulated precipitation in order to define extreme events in view of this there are several methodologies to classify extreme precipitation events e g in field et al 2012 the authors classify extreme rainfall events as those beyond the 99 percentile of accumulated rainfall usually greater or equal to 50 mm rainfall within 24 h in di et al 2015 the authors proposes a percentile threshold of 95 within 24 h wan et al 2012 and gu and wan 2010 adjusted the threshold in 90 considering the impact of extreme rain to set the threshold lee et al 2014 implemented a model to predict flooding the authors used a 70 0 mm threshold in 6 h based on knowledge from the study s region that this amount of rainfall was capable of causing serious consequences for urbanization for our case study we chose a fixed threshold of 50 mm in 24 h as suggested by field et al 2012 and reis et al 2004 the threshold that defines an extreme event may be different for other regions such as snow dominated regions monsoon regions or droughts regions the methodology proposed in this work uses the threshold to determine the precipitation volume in 24 h and to identify the atmospheric condition before and during this period notice that this allows us to characterize any rainfall event extreme or not independently of the threshold value making our proposal potentially applicable to other regions and thresholds as mentioned our approach uses multivariate regression models as a strategy and the non linear aspect typical of the climatic process is incorporated by means of a neural network lstm 3 1 2 characterisation of the prediction model we formally describe the considered variables set to predict the volume of extreme precipitation as shown in equation 1 1 ispp sfc p l p r e c where ispp corresponds of surface variables sfc pressure levels variables pl and precipitation volume prec the subset of surface variables sfc corresponds to the variables expressed by equation 2 where the past time windows are represented by t i 2 sfc s 1 s 2 s 11 t n s 1 s 2 s 11 t 1 s 1 s 2 s 11 t where s1 total column water kg m 2 s2 total column water vapour kg m 2 s3 mean sea level pressure pa s4 10 m u wind component m s 1 s5 10 m v wind component m s 1 s6 2 m temperature k s7 2 m dewpoint temperature k s8 volumetric soil water layer 1 m3 m3 s9 volumetric soil water layer 2 m3 m3 s10 volumetric soil water layer 3 m3 m3 s11 volumetric soil water layer 4 m3 m3 the subset of variables pl corresponds to the atmospheric variables pl p1 p2 p8 for different pressure levels 200 300 400 500 600 700 750 800 850 900 925 1000 see equation 3 3 pl p 200 1 p 200 2 p 200 8 p 300 1 p 300 2 p 300 8 p 1000 1 p 1000 2 p 1000 8 t n p 200 1 p 200 2 p 200 8 p 300 1 p 300 2 p 300 8 p 1000 1 p 1000 2 p 1000 8 t 1 p 200 1 p 200 2 p 200 8 p 300 1 p 300 2 p 300 8 p 1000 1 p 1000 2 p 1000 8 t where p level 1 potential vorticity m2 s 1 k kg 1 p level 2 geopotential m2 s 2 p level 3 temperature k p level 4 specific humidity kg kg p level 5 vertical velocity pa s 1 p level 6 u velocity m s 1 p level 7 v velocity m s 1 p level 8 relative humidity the precipitation volume prec mm comes from automatic weather stations for a given location at the current time t the generic model of precipitation forecast at time t involving the set of variables expressed by equations 2 and 3 is given by equation 4 4 pr e c t sf c t 1 s f c t 2 s f c t n p l t 1 p l t 2 p l t n 3 1 3 dataset composition and preparation 3 1 3 1 merging the era interim and meteorological station data the adopted process for merging the data was to consider the target area before synchronizing the databases the target location belo horizonte city is between the longitude 45 0 to 43 5 and latitude 18 75 to 20 25 corresponding to 9 grids 3x3 with 0 75x0 75 resolution from era interim see fig 3 in order to manipulate smaller files in this step we built 12 files corresponding to each selected pressure level 200 300 400 500 600 700 750 800 850 900 925 1000 containing 8 pressure variables equation 3 considering the 11 surface variables equation 2 and the target variable precipitation volume from the automatic station s data the datasets with pressure and surface variables were merged according to the dimensions latitude longitude time and level using the merge function of the pandas library pandas 2019 before to merge the target variable prec into the merged dataset we process the data to accumulate the total precipitation for each 24 h fig 4 illustrates this calculation the infographic considers a real example from 16 00 utc on 11 28 2006 the inmet belo horizonte pampulha station a521 accumulated 73 6 mm rainfall volume in 24 h which classifies this as an ere extreme rainfall event assuming the conditions for such an event are detectable at least 24 h before they were present in the surface and pressure variables hence the dataset considers the 24 h utc in advance with this upcoming total precipitation we then added the precipitation prec target variable completing the composition of the dataset 3 1 3 2 data preparation a analysing inconsistent records about 1 of the relative humidity records were outside the expected range 0 8 to 103 but have not been removed the support for this decision is as follows at any temperature and air pressure a specific maximum amount of water vapor in the air will produce a relative humidity rh of 100 supersaturated air contains more water vapor than is necessary to cause saturation the water vapor begins to condense into impurities in the air such as dust or salt particles as the relative humidity approaches 100 and a cloud or mist forms in the air absolutely devoid of impurities as is sometimes the case above 9 000 m but never at lower levels the ur can rise well above 100 b data normalisation a standard lstm neural network unit consists of a cell an input gate an output gate and a forget gate the cell processes values at arbitrary time intervals and the three gates regulate the flow of information into and out of the cell to address the vanishing gradient problem in an lstm we use a function whose second derivative can sustain for a long time before approaching zero typically in design of lstm the sigmoid and hyperbolic tangent functions are commonly used as activation functions in the network units in this work we selected both functions that have that property since the output gate of an lstm network has a hyperbolic tangent function we normalized the data in the 1 1 range c data balancing strategy because our approach does not separate extreme event records from ordinary events the dataset is unbalanced by having more instances of ordinary event records than extreme events in order to balance extreme and ordinary rainfall events the proposed regression model targets accumulated precipitation over 24 h so events with accumulated precipitation above 50 mm for each 6 hour window time window for changing input variables are treated as a unique event in the training stage that is if a single event lasts for multiple times of 6 h or even days it will be trained as multiple events of extreme rainfall 3 1 4 constructing the lstm neural models 3 1 4 1 temporal models for forecasting volume of precipitation forecasting the volume of precipitation is intrinsically a time series analysis problem normally for time series forecasting we use lagged observations e g t n as input variables to forecast in the time interval t h this can be called an h step ahead forecast or a horizon of h for the proposed model taking into account the range of data availability by the era interim system we consider that the time lag can be accumulated with previous observations such as t 1 t 2 t 3 t n respectively 6 12 18 h ago or 6 n hours ago to forecast the volume of precipitation at time t h where h 1 8 corresponding to a forecast horizon of 6 12 48 h ahead we trained and evaluated several models evaluating different temporal windows using the lstm neural networks considering the input variables from time t 16 t 12 t 8 t 4 t 2 and t 1 and the predicted variable prec t h for the forecast horizons of 6 12 48 h ahead the considered models are presented in equation 5 5a m o d e l 2 pr e c t h sf c t 2 s f c t 1 p l t 2 p l t 1 5b m o d e l 2 p r e c t h sf c t 2 s f c t 1 p l t 2 p l t 1 5c m o d e l 3 pr e c t h sf c t 4 s f c t 1 p l t 4 p l t 1 5d m o d e l 4 pr e c t h sf c t 8 s f c t 1 p l t 8 p l t 1 5e m o d e l 5 p r e c t h sf c t 12 s f c t 11 s f c t 1 p l t 12 p l t 11 p l t 1 5f m o d e l 2 p r e c t h sf c t 2 s f c t 1 p l t 2 p l t 1 3 1 4 2 lstm modeling the problems involving time series are more difficult to model unlike common regressive predictive modeling time series data adds the complexity of a historical sequence dependency between input variables and seasonality ann deal with the nonlinear relationships of complex systems bittencout and zárate 2011 long short term memory lstm networks hochreiter and schmidhuber 1997 are a modified version of recurrent ann which have the ability to forget and remember the most recent and relevant past a wide variety of architectures can be designed to an lstm in order to obtain good predictive models for problems involving time series malakar et al 2021 designing lstm networks is more difficult and there is no well founded theory on how to do it objectively thus we evaluated our models through several experiments some techniques aim to explore the different configurations using final results as criteria grid search is a technique based on the exhaustive search used to find the ideal hyper parameters that result in models with more accurate predictions the search takes place in a hyper parameter space defined by a manually specified interval typically a grid search algorithm must be guided by some performance metric usually measured by the cross validation technique in this work we used the walk forward validation technique as it is appropriate for time series data gers et al 1999 the mathematical model for lstms with forget gates gers et al 1999 considered in this work is given by equations 6a to 6f the w u and b matrices are determined through the training process of the neural network 6a f o r g e t g a t e f t σ w f x t u f h t 1 b f 6b u p d a t e g a t e i t σ w i x t u i h t 1 b i 6c c e l l c a n d i d a t e s t a t e c t t a n h w c x t u ci h t 1 b c o u t p u t g a t e o t σ w o x t u o h t 1 b o 6e m e m o r y u p d a t e c t f t c t 1 i t c t 6f o u t p u t g a t e h t o t t a n h c t where d number of inputs d 108 h number of hidden units h 300 t timestep index we use several timesteps in our models o hadamard product operator x t r d input vector for the lstm unit f t r h activation vector for the activation gate i t r h activation vector for the input update gates o t r h activation vector for the output gate h t r h output vector for the lstm unit c t r h activation vector for a candidate cell status c t r h cell status vector w r hxd synaptic weight matrix u r hxd synaptic weight matrix b r h polarization weights vector σ log sigmoid activation function tanh hyperbolic tangent activation function 3 1 4 3 strategies for training validation and testing when evaluating a model for time series prediction we are interested in the model s performance on data that was not used during training in machine learning we call this a test procedure with out of sample data which provides a more meaningful assessment this procedure was carried out by dividing the data into 2 sets approximately 8 years for training and 2 years for validation and tests simply by filtering by the date of occurrence of the events the evaluation of these forecasts will provide a good demonstration of the model s performance when used operationally approximately 80 of the total dataset 11 656 instances were used in the training process corresponding to approximately 8 years with 4 records per day 00 00 06 00 12 00 and 18 00 h utc between 2006 and 2014 for validation and testing we used the remaining data a set with 2 920 instances 20 of the total in the in time series forecast the evaluation of models in historical data is called backtesting as mentioned for this study we used the walk forward validation technique kirkpatrick et al 2015 where the data is divided into small data segments and chronologically ordered while in cross validation k folds are defined in which the set will be partitioned for the walk forward technique there is no predetermined number in each training execution all data available before the target time point is used in the training set and the unseen data is used as a validation set the process is done continuously until the time series ends subsequently the accuracy of the model is computed as the average between runs the number of executions varies from 1 up to the total number of predefined executions segments used for training 3 1 4 4 evaluation metrics to the prediction model mean absolute error mae and root mean squared error rmse are two metrics typically used to evaluate prediction models results based on time series mae corresponds to the mean over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight meanwhile rmse follows a quadratic score rule that also measures the mean magnitude of the error as rmse corresponds to the square root of the mean of squared differences between prediction and actual observation will always be greater than mae for the same results a feature of the rmse is that errors are squared before the mean be calculated therefore the different weights will be added to the sum and as the error values increase the rmse metric increases considerably as extreme precipitation is an outlier its weight will be greater for the rmse calculation and consequently it will affect your metric by making it larger as the main goal of this study aims to predict extreme precipitation among ordinary rains the best approach is to combine rmse and mae metrics in order to assess the performance of the proposed approach we carried out a continuous prediction process for historical data involving periods of ordinary and extreme rainfall the performance of the model for both situations is also analyzed and discussed 4 experiments and results analysis extreme rainfall events are concentrated within approximately 1 of the normal distribution pour et al 2020 kodra et al 2020 which makes it a challenge to obtain a model that can capture these extremes as well as predicting the volume of precipitation for ordinary rainfall events some models choose to separate only the few extreme events and train a more specific model only for the rainy season or for a specific period as mentioned our strategy was to treat the problem as a time series regression problem overcoming seasonality considering periods of low and high rain frequency and to forecast the volume of precipitation between a window of 6 to 48 h in order to evaluate our approach we analysed the results of training processes considering 11 656 registers from set 2006 to october 2014 we calculated the rmse and mae measures for all neural models for the different time lags tables 4 and 5 from the results shown in table 4 it is possible to observe that all models presented satisfactory results the minimum rmse value was 0 59 mm for the i4o2 model input 4 and output 2 and the maximum value was 2 39 mm for the i1o7 model input 1 and output 7 table 5 shows the mean absolute error mae for all models considered in table 4 note that the mean errors for each model correspond to values that can be considered low minimum mean of 0 31 mm for i4o2 and maximum mean of1 30 mm for i1o3 although the maximum mae value has reached in some cases values close to 30 mm it is important to emphasize that the standard deviation remained at low values for example for the i4o2 model the mae value was 0 31 mm and standard deviation of 0 49 mm considering a range around the mean and 2 times the standard deviation we can establish that 95 46 of the error values are within the range between 0 and 1 29 mm this allows us to conclude that the models are highly representative of the training set in order to infer the performance of the models for new data samples we calculated the confidence intervals for the 95 confidence level fig 5 it can be seen that the performance of the models is satisfactory for all configurations the mean mae mean absolute error varies between 0 31 and 1 65 mm and the confidence intervals range from 0 02 to 0 08 mm as is well known computational models based on data always present better results during the training process however when compared to performance during its operational use performance typically decreases in order to evaluate the models under operational conditions and identify the best prediction model a test process was carried out in the proposed models we evaluated the models using testing data contains 2920 registers 730 days 4 temporal windows of 6 h each one from october 2014 to october 2016 not considered during training process we calculated the rmse of all neural network configurations table 6 as well as mae and the standard deviation for the different time lags table 7 the best model input 4 and output 1 i4o1 in bold has rmse value of 6 94 mm see table 6 in bold mae value of 2 97 mm and standard deviation of 6 2 mm for the test data as shown in table 6 this model was trained with input from the previous 24 h 24 18 12 6 h to predict the volume of precipitation 6 h ahead the second and third best models are i2o1 and i8o1 which have a rmse value of 7 58 mm mae of 2 98 standard deviation of 6 9 and 7 79 mm mae of 3 30 standard deviation of 6 9 mm respectively from these three models it is possible to conclude that the better prediction corresponds to 6 h ahead o1 considering the previous atmospheric conditions until 48 h i8 it is important to highlight that the proposed methodology also presents satisfactory results to the forecasting of 12 and 18 h ahead see tables 6 and table 7 in bold i4o2 rmse 8 72 mae 3 49 i4o3 rmse 9 53 mae 4 07 these results are important because they can allow guiding anticipated preventive actions to avoid human and economic losses front eminent extreme events in order to infer the performance of models i2o1 i4o1 i8o1 i4o2 i4o3 considering testing data not used during training processes we calculated the confidence intervals for the 95 confidence level fig 6 notice that the performance of the models is satisfactory the amplitude of the confidence intervals varies from 0 23 mm i4o1 to 0 31 mm i4o3 it is important to highlight that our methodology allows predicting extreme rainfall events and ordinary rainfall in order to evaluate the performance of our approach in both rainfall situations fig 7 shows the predicted versus actual rainfall volume values from the models with lower mean absolute errors models with inputs 1 2 4 and 8 6 12 24 and 48 h ago respectively and forecasting of 6 h ahead note that the amount of data relating to low rainfall conditions is noticeably greater than the amount of data relating to extreme event conditions despite the applied balancing procedure subsection 2 2 4 2c it is expected that the models have a better prediction performance for low rainfall than for high rainfall events we performed additional experiments considering only data of extreme rainfall however due to the small amount of data the models did not perform any better the reason why we kept our forecast considering the complete time series it is important to emphasize that models based on neural networks are fitted from data and the more information is provided during the training process these networks are able to represent the qualitative relationships existing in the physical system as exposed in bittencout and zárate 2011 so we consider that modeling the climatic system as a time series regression problem preserves the greatest amount of information that is why we chose to work with global models to forecast precipitation regardless of low or high precipitation the value of the pearson correlation coefficient r 2 considering ordinary and extreme rainfalls for the four models considered i1o1 i2o1 i4o1 i8o1 are 0 71 0 73 0 72 and 0 70 respectively which can be considered with high correlation hinkle et al 2003 considering the best model i4o1 which obtained a rmse value of 6 94 mm the pearson correlations value considering rainfall events low and up of 50 mm were of 0 60 and 0 59 considered moderate correlation table 8 shows the number of events with rainfall for the study region specifically at the location of the a521 station latitude 19 53 2 22 longitude 43 58 9 83 altitude 854 m notice that of the 2920 records 600 rainfall events above 1 mm in 24 h occurred the model predicted 902 rainfall events above 1 mm being that the biggest difference occurs for the interval 1 10 where the number of predicted events were of 556 in relation to 264 actual events the difference is due to the prediction of actual events below and close to 1 mm for which the model predicted values between 1 10 it is still possible to note that in 2 years 2014 2016 there were 46 extreme rainfall events 50 mm in 24 h in bold corresponding to 7 6 of the total of events that occurred in the considered period the best model i4o1 was able to predict the precipitation value for 23 extreme events 50 of the total events we emphasize that the important thing for prediction is to know if an event will happen and if it will cause an impact in relation to the volume of precipitation we also observed that for the 50 70 interval which characterizes extreme events with socio economic impact our model correctly predicted 30 of the 34 events besides in table 8 we can highlight that the model i4o1 is also capable of predicting the value of precipitation for events of lesser intensity this increases the relevance of the model e g to predict the amount of rain for agricultural systems which can benefit from this information for planning irrigation periods as already mentioned due to a large amount of data referring to conditions of low precipitation the model presented a satisfactory performance for precipitations below 50 mm in order to evaluate the performance of temporal forecasting for the study region fig 8 shows typical rainfall events in southeastern brazil during the brazilian summer for the oct 2014 oct 2016 period the rainy season in the considered region typically begins at the end of october and lasts from 155 to 173 days minuzzi et al 2007 ending approximately at the beginning of march we observed that the highest concentration of critical extreme events above 50 mm of precipitation occurs between the months of december to february for the period considered table 9 shows the dates and times during which extreme events occurred the record groups indicate 24 hour accumulated rainfall recorded every 6 h observing the in bold groups it is possible to confirm that the best model i4o1 with previous data of 24 h predicts with greater precision the horizon of 6 h ahead for example for the group with date 2014 12 13 time 6 00 00 to date 2014 12 14 time 6 00 00 the prediction error continuously decreases reaching the value 0 8 mm this same behavior occurs in 7 54 cases of the groups shown in table 9 based on these results we can emphasize that the approach proposed in this work considers relevant atmospheric characteristics to predict the volume of precipitation in extreme event scenarios finally we compare our model with the autoregressive integrated moving average model arima the model was built considering the same training data used in our approach 11 656 registers from sep 2006 to october 2014 the best fitted model was arima 3 1 1 and the calculated coefficients are ar1 ar2 ar3 ma1 0 4095 0 0196 0 0552 0 9662 the arima model achieved an rmse value of 43 37 mm and mae value of 21 62 our best model i4o1 achieved during training an rmse value of 0 94 mm and mae value of 0 46 it is important to highlight that during the operational test our model achieved an rmse value of 6 94 mm and an mae value of 2 97 mm superior performance to that arima model this shows that our approach gives superior results to classical models based on time series fig 9 shows the responses of the i4o1 and arima models for a time window from nov 28 2006 00 00 to dec 01 2006 18 00 from training data considering that the precipitation forecast is carried out for 6 hours ahead it is observed that the auto regressive integrated moving average models always have a delayed response which is not of interest for the prediction of extreme events that would affect a city the best model proposed in this work i4o1 has predictive characteristics that allow it to track precipitation events without delay this behavior is due to the fact that our approach takes into account several atmospheric variables for different pressure levels such as potential vorticity specific humidity vertical velocity u velocity v velocity relative humidity among other surface variables which we relate through neural models to forecast rainfall it is important to emphasize that the forecast of the volume of precipitation in rain is extremely difficult due to the complexity of the meteorological system that produces them 5 conclusions and future directions in this work we proposed a model based on lstm neural networks to predict the volume of extreme precipitation and detect extreme rainfall events the model uses data from 8 atmospheric variables and 11 surface variables for 12 atmospheric pressure levels we evaluated several configurations and the model that obtained the best predictive accuracy uses 24 h prior information before the target event we believe that this work contributes towards a new approach to predict extremes rainfall events in southeastern brazil especially in belo horizonte and can lead to better predictability of extreme weather events the approach presented here can be applied in other regions and locations using the same data source era interim it would also be possible to use era5 era5 2020 data for training a similar forecast model era5 covers the earth in a 30 km grid and resolves the atmosphere using 137 surface levels up to a height of 80 km our methodology is inherently objective and reproducible and it can be implemented operationally to assist in the prediction of intense and potentially catastrophic events this study shows that era interim as input data resulted in models with a good performance for estimating most events of heavy precipitation naturally our data source can be replaced by other equivalent meteorological input data with real time or near real time measurements and serve as support to the monitoring of heavy precipitations the vast majority of approaches treat extreme rain events forecasting as an imbalanced problem such as the studies cited in our related works section thus the model requires a number of good positive class examples that represent the extreme events and their anomalous conditions the main contribution of our approach is that it is not necessary to separate scenarios of normal precipitation or absence of precipitation which is a drawback of similar approaches our model is capable of handling a complete time series without additional preprocessing required the proposed methodology and the results of this work can be used to predict extreme precipitation events in the city of belo horizonte 24 h in advance we highlight the following contributions a possibility to be used as a decision support tool associated with the forecasts made using global mathematical models b the processing required is less computationally expensive than the usual meteorological forecasting strategies c the model s specialization by season can contribute to direct attention to specific neighborhoods and regions and d flexibility to use various time windows for prediction between 6 and 48 h as limitations of this study we highlight a absence of spatial abstraction the model needs to be retrained for use in a new area and it is necessary to obtain and synchronize the data from the weather stations present in each target area b dependent on a significant historical interval the model used 8 years of historical data and using smaller intervals might reduce its generalization capacity and c absence of previous studies describing strategies for predicting extreme rainfall events without balancing the data as a future work we plan to experiment with other architectures and some methods of transforming non stationary time series data into stationary we also suggest a considering a comparative performance analysis with different activation functions for lstm networks as recommend in farzad et al 2019 the authors establish that other activation functions such as elliott similar to sigmoid can reduce average error and be faster to compute than the exponential sigmoid function b investigating new architectures such as a convolutional neural networks cnn which can be used as the encoder in an encoder decoder architecture with the intention of capturing spatial abstraction geolocation c replacing the era interim database with era 5 and observe how the models results are affected note that era 5 can be used in order to reproduce our results according to our methodology d using smaller temporal resolutions the era 5 data has hourly resolution e applying the proposed methodology in other regions to investigate how much the methodology can be generalized for different environments and f change the methodology to retrain the model whenever new daily data becomes available effectively making it an online system funding source this research received financial support of foundation for research support of the state of minas gerais fapemig brazil process no cex apq 00997 15 credit authorship contribution statement andré de sousa araújo conceptualization methodology software validation investigation data curation visualization adma raia silva conceptualization methodology luis e zárate conceptualization methodology validation formal analysis investigation visualization supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the fapemig foundation for research support of the state of minas gerais grant number cex apq 00997 15 the cnpq brazilian national council for scientific and technological development capes coordination for the improvement of higher education personnel and pontifical catholic university of minas gerais brazil 
3674,extreme rainfall events can devastate urban and rural infrastructure affect the economy and even lead to loss of life in this work we propose an approach based on long short term memory networks lstm to forecast precipitation volume extreme rainfall using multivariate time series data our methodology combines reanalysis data from 12 isobaric pressure levels surface data and data from meteorological stations from brazil s southeastern region our method allows handles the imbalanced data typical of time series data used for this type of problem in order to identify the best model we performed several experiments with different configurations of lstm networks the test results showed that the best prediction model has as input previous data up to 24 h for a forecast of 6 h ahead with a mean absolute error mae of 6 9 mm and root mean squared error rmse of 6 94 mm our methodology shows the possibility to use reanalysis data from global mathematical models to obtain less computationally expensive regional models keywords extreme rain event forecasting models data driven modelling long short term memory neural networks machine learning 1 introduction a large amount of the available scientific literature claims that in this century there will be a significant increase in extreme weather events and consequently extreme rainfall events or at the very least an increase in the proportion of heavy rainfall in many areas of the planet field et al 2012 frame et al 2020 lima et al 2021 machado et al 2021 as stated in the intergovernmental panel on climate change report titled managing the risk of extreme events and natural disasters and promoting adaptations to climate change ipcc 2012 even in regions where there will be a reduction in total annual precipitation there will be an increase of extreme rainfall events meaning more heavy rainfall events in a shorter period of time field et al 2012 extreme rainfall is a complex event governed by multiple atmospheric o gorman and schneider 2009 duan et al 2017 pour et al 2020 kodra et al 2020 traditionally weather forecast models are based on mathematical equations to represent the physical laws that govern the movements of the atmosphere and interactions among several different systems that compose the climate system when using data driven modelling ddm models are not based on primary laws instead they are derived directly from a learning algorithm using data from previous observations a data driven model should reflect the patterns in the training dataset as accurately as possible but it must also have a high level of generalization i e the ability to provide an adequate prediction for unseen data herzog et al 2018 a numerical weather forecasting system numerical weather prediction nwp involves a series of sub processes such as the collection modelling and processing of atmospheric data from surface and altitude weather stations satellites and weather radars these systems are used to calculate the atmospheric conditions of a region at a given time interval coiffier 2011 the nwp systems which combine mathematical models with observations create datasets for climate monitoring and research known as reanalysis data the reanalysis data contains estimates of atmospheric parameters such as air temperature pressure and wind at different altitudes and surface parameters such as precipitation soil moisture content height of ocean waves and temperature of the sea surface these estimates are produced for all locations on the planet and span several decades ddm using artificial intelligence techniques are not entirely new on weather prediction geng et al 2014 choubin et al 2016 ramsundram et al 2016 comeaud et al 2017 scher 2018 samadianfard et al 2019 in particular for extreme weather events several approaches have applied artificial intelligence techniques for prediction and classification of extreme rainfall and severe winds mcgovern et al 2017 predict cyclones atmospheric rivers frontal systems cold hot liu et al 2016 and prediction of heat waves iglesias et al 2015 weather forecasting based on ddm has series of challenges such as abstraction of spatio temporal information high dimensionality and imbalanced datasets in wang and ding 2015 the authors proposed a framework for learning patterns of the space time system and predicting extreme weather events using clustering and classification techniques di et al 2015 proposed an equivalent approach to the previous one but differentiating extreme and ordinary rainfall events forming clusters according to the volume of precipitation after balancing and reducing the dimensionality of the dataset they applied the k nearest neighbor algorithm knn to match events to their respective clusters essentially creating a predictive model similarly hua and simovici 2016 implemented a model combining hierarchical clustering to identify locations with similar atmospheric conditions and used a multivariate time series data model bayesian structural vector autoregression bsvar to make the prediction gaitan et al 2016 used several sources of data such as precipitation data social and economic data and data on flood incidents in the netherlands they applied clustering to obtain spatially well defined groups in relation to the volume of precipitation and were able to predict the impact of floods with a volume of 70 mm in 6 h yang et al 2007 segmented sequences of satellite images to extract information from images subsequently they trained a decision tree to classify rainfall events as extreme or ordinary lee et al 2014 used support vector machine svm to classify extreme and ordinary precipitation in order to address the high dimensionality of the data the authors employed a feature selection approach based on genetic algorithms in kisi et al 2019 the monthly rainfall amounts were estimated through the svm and the geostatistical kriging approaches so the latitude longitude altitude were introduced as model inputs for simulating monthly rainfall values other studies used artificial neural networks ann for rainfall prediction phusakulkajorn et al 2009 wu and chau 2013 taormina and kwok wing chau 2015 phusakulkajorn et al 2009 transformed the time series of rainfall volume by wavelet decomposition this preprocessing decomposes a series of data originally described in the time domain allowing it to be analyzed in different frequency scales and time periods after this transformation they used an ann to predict the volume of rain for consecutive days wu and chau 2013 combined soft computing approaches for rainfall prediction the authors proposed preprocessing techniques included moving average ma and singular spectrum analysis ssa ghil et al 2002 their results showed that the ma was superior to the ssa when combined with ann taormina and kwok wing chau 2015 proposed the estimation of prediction intervals pis for operational streamflow forecasting the method constructs an ann with two output neurons in order to approximate the lower and upper bounds of the pis the authors establish the importance of choosing the proper prediction interval in the design of forecasting models kisi and shiri 2011 and azad et al 2019 proposed models based on neuro fuzzy techniques for dealing with the non linear characteristics of the process of precipitation in kisi and shiri 2011 the authors considered wavelet coefficients as inputs in order to represent variations trends and periodicities in time series the results show that the proposed models are effective in forecasting daily precipitation and simulating monthly rainfall magnitudes respectively the main difference between these works and our proposal is that we make predictions of rainfall volume from 6 to 48 h ahead with 6 hour intervals furthermore we consider historical values of atmospheric variables without applying feature extraction processes from the time series these processes transform original data and can cause the loss of relevant information sulaiman et al 2018 modelled regional precipitation patterns considering three predictive models based on ann svm and random forest rf techniques for each region the authors discuss what technique was more efficient to predict the spatial distribution of precipitation in watersheds with limited meteorological data misra et al 2018 claim that long short term memory lstm neural networks are capable of capturing a signature on the variables at a time before the extreme rainfall event thus presenting better results than other algorithms it is worth noting that in that study there is a complex stage of pre processing to segment the rainfall into three categories according to its intensity weak medium and strong the authors also used principal component analysis and decision trees to select the best predictor variables to be used as input to the lstm neural network they used the following variables as predictive features maximum and minimum temperature mean sea level pressure specific humidity at 500 hpa zonal wind velocity and meridional wind velocity in contrast to the work proposed in misra et al 2018 our predictive variables were eleven surface variables eight pressure levels variables of 200 to 1000 hpa the pressure level of 1000 hpa was chosen based on the significant presence of humidity which can influence the rainfall after analyzing the related works we were able to enumerate the main challenges common to the different approaches 1 high dimensionality there is a large number of variables and information available to characterize the rainfall due to the fact that data are arranged according to time and space each data available can be multiplied by many different instances atmospheric levels for each latitude longitude quadrant etc thus a weather prediction dataset can easily have thousands or millions of variables 1 1 the european centre for medium range weather forecasts ecmwf era interim 2019 collects and provides global weather data every six hours considering only the northern hemisphere there are 320x161 grids and seven isobaric surfaces 200 300 500 700 850 925 and 1000hpa each grid has 254 climatic variables the total number of information fields in climatic data can reach 91 602 560 320x161x7x254 the era interim database considers information from several sources such as satellites radio aircraft ships etc from a data mining perspective domingos 2012 points out that high dimensionality is one of the biggest challenges in machine learning and highlights two problems 1 increase in generalization difficulty as the number of attributes grows and 2 breaking of thinking based on similarities typically two strategies are proposed to deal with this problem i to consider the whole dimension which demands adequate approaches techniques and algorithms for big data scenarios or ii to apply a dimensionality reduction process which demands a feature selection process e g via genetic algorithm genetic algorithms and other feature selection approaches notably demand great computational efforts in addition to that prediction of rainfall volume is a complex non linear and multivariable problem therefore any dimensionality reduction strategy can significantly impact the performance of the prediction model hence the participation of domain experts in the feature selection process is important in order to obtain more representative models deng et al 2020 2 data imbalance the imbalance problem is very common in the real world in cases of extreme rainfall prediction it is critical this is because the occurrence of extreme precipitation is much less common than ordinary precipitation in order to deal with the imbalance several articles wang and ding 2015 di et al 2015 wan et al 2012 gu and wan 2010 used several thresholds from 90 to 99 of the normal distribution to distinguish extreme rainfall from ordinary rainfall and then deal with the imbalance but there is no consensus for this threshold stephenson et al 2008 3 spatial resolution of the data versus the scope of the phenomenon depending on the spatial resolution and temporal evolution of the atmospheric variables it may be necessary to obtain a greater spatial resolution in order to accurately describe the phenomenon thus one must consider the capacity of the variables used to represent space time information and the relationship among them segregating and isolating data at a lower resolution may not be realistic as the dominant atmospheric process may operate at a scale greater than the chosen scale 4 to deal with the challenges mentioned above one of the main strategies observed in the literature is differentiating extreme moderate and mild rainfall events and predict precipitation volume according to the predicted severity of the event note that this differentiation implies two forecasts first knowing what level of severity the forecast is at and then determining the precipitation forecast within that category in order to increase the reliability of the model it would be interesting to reduce the number of stages of predictions thus a challenge would be to obtain standalone models for predicting all rainfall events including extreme and ordinary rainfall 5 complexity of models most of the proposed models involve the application of various techniques and are strongly dependent on an ordered sequence of procedures which normally are difficult to reproduce 6 explainability of models the proposed approaches may result in models with little capacity for interpretation understanding the cause and effect conditions of a given phenomenon is often as important as its prediction and this is the case with extreme rainfall events in this work we propose a data driven model ddm minaya et al 2018 from the exploratory study of reanalysis data and a methodology based on data mining dm techniques to predict extreme rainfall events the proposed approach combines reanalysis data from the european centre for medium range weather forecasts ecmwf era interim era interim 2019 dee et al 2011 to characterize the dominant processes over conditions of extreme rainfall seasonality on a regional scale with rainfall data from automatic surface stations at the national institute of meteorology inmet inmet 2020 the model aims to identify atmospheric patterns extracted from historical records of extreme rainfall events in order to predict based on the capture of atmospheric disturbances that occur in previous moments upcoming rainfall volume as a differential of our work we addressed the aforementioned challenges as follows with domain knowledge and as suggested by lima et al 2010 we selected 12 levels of atmospheric pressure and their predictive variables for rain events provided by the era interim database to represent each location in the dataset we gave the state of these variables between 6 and 96 h earlier prior to the target time point this framing of the problem is known as a multi stage time series forecasting problem with the possibility of also predicting several time points ahead in order to handle non linear characteristics of the atmospheric process we treated precipitation data as a complete time series and trained an lstm neural network capable of capturing cycle characteristics and seasonality of the series note that the proposed methodology is able to simplify additional steps unlike other studies such as balancing the dataset and reducing the dimensionality and it can be applied to other regions and localities provided that the target region is fixed besides lstms neural networks an improvement of the recurrent neural networks are able to capture spatial temporal dependencies these nets can preserve long term information control how much information to store and how much to discard this characteristic allows dealing with multi stage time series forecasting problems with the possibility of also forecasting several time points ahead for extreme and ordinary events as a case study we considered the metropolitan region of belo horizonte mrbh minas gerais state brazil latitude 18 75 to 20 25 and longitude 45 to 43 50 in the period from 2006 to 2016 in the chosen region drainage infrastructure is deficient even low magnitude rainfall if happening over short periods of time hours can cause flooding and have catastrophic consequences in the region marcelino et al 2006 this reinforces the relevance of proposing forecast models for predicting extreme rainfall events ere in this region the results suggest that climatic variables measured between 96 and 6 h before an ere can be used to reliably estimate the volume of precipitation in the near future 6 to 48 h and consequently whether there will be extreme rainfall event the classification of rainfall in belo horizonte shows that rainfall in the range of 30 to 50 mm is considered heavy rain and rainfall greater than 50 mm is classified as extremely intense reis et al 2004 it is important to emphasize that the proposed methodology is not dependent on a specific study region although the definition of extreme rainfall events may need to be localized 2 methodology materials and methods this section describes the considered databases and proposed methodology for building the forecasting model of extreme rainfall events fig 1 shows the flow of the methodology step 1 definition of the region and period of study step 2 data collection and extraction procedures step 3 conceptualization and characterization of the prediction model step 4 dataset composition combination era interim dataset with the precipitation variable from automatic stations and pre processing involving inconsistencies analysis data normalization dataset balancing training and validation processes step 5 construction of the lstm neural model finally step 6 tests and analysis of results in this last step we analyze several models considering different forecast horizons and previous historical data we identified the best models and highlighted their main characteristics we discuss the performance of our methodology for the prediction of extreme and ordinary rainfall situations and discuss its temporal predictive capacity 2 1 materials 2 1 1 data source from reanalysis database we used data from the era interim reanalysis database collected from 2006 to 2016 era interim 2019 the data has a spatial resolution of 0 75x0 75 80 km2 comprising the area between latitude 30 and 0 41 intervals and longitude 60 and 0 81 intervals totaling 3321 grids that correspond to brazil s southeastern region the reanalysis data from era interim are stored in the network common data form format netcdf3 for this study we consider only surface and pressure level variables fig 2 illustrates the grid for data collection at a horizontal resolution of 0 75 in latitude and longitude with 37 vertical pressure levels from the surface to 0 1 hpa 2 1 2 atmospheric variables from reanalysis era interim reanalysis data is available every 6 six hours namely 00 00 06 00 12 00 18 00 utc universal coordinated time of each day the database provides 254 atmospheric variables for 37 available pressure levels in our approach we considered 14 variables see table 1 the pressure levels are arranged from the highest isobaric altitude to the lowest altitude in the atmosphere from 1 to 1000 hpa table 2 shows the 77 surface variables available from era interim database grouped by category 2 1 3 data from the surface meteorological stations the precipitation data recorded on the surface were provided by the brazil s national institute of meteorology inmet inmet 2020 for the period from 2000 to 2016 recorded in 122 automatic meteorological stations in the southeastern region table 3 shows the 17 surface variables all of these available from inmet database 2 2 methods fig 3 shows an infographic detailing the different stage of our methodology steps 1 5 see fig 1 selection of the target region data extraction and collection procedures the conceptualization of prediction model dataset composition training and validation of the lstm model 2 2 1 definition of the study region as case study we selected the metropolitan region of belo horizonte brazil mrbh this region is located between the latitudes of 19 00 and 20 30 s and longitudes of 43 15 and 44 45 w in the central area of the state of minas gerais in southeast brazil altogether there are 34 municipalities with 9468 km2 of extension the region has about 6 million inhabitants dsec 2015 being brazil s third most largest urban area after são paulo and rio de janeiro s metropolitan regions in belo horizonte city according to the climatological normal 1981 2010 the pluviometric index is about 1600 mm per year distributed almost entirely between the months of october to march belo horizonte s temperature varies on average between 19 c and 24 c the mrbh is very sensitive to flooding due to the pattern of urbanization inefficient drainage infrastructure and topography where altitudes can vary greatly from one region to another the largest urbanization area is between 751 and 1000 m altitude from north to southwest while the lowest altitudes occur in the northeast between 650 and 750 m the largest altitudes occur in the south and southeast limits between 1001 and 1150 m reaching 1500 m at the top of serra do curral a previous study found a very high correlation of moderate to extreme rainfall with flooding in the mrbh region nunes 2018 hence the relevance of our study 2 2 2 data extraction and collection era interimthe data of the era interim were collected in an automated way in batch by a routine through an application programming interface api webapi 2019 available the ecmwf era interim 2019 using an access key previously requested and parameters such as variables of interest time period format area of interest and resolution due to a limit of 20 gb per request we collected the data over multiple requests over months and then merged them into a single dataset the files obtained from the era interim database in the netcdf3 format conventions cf 1 6 were stored locally and separated into monthly files spanning 10 years 2006 to 2016 each file has the same spatial resolution of 0 75x0 75 between latitude 30 to 0 and longitude 60 and 0 brazil s southeastern region 3 meteorological stations inmet the weather station data was obtained by digital media requested from inmet inmet 2020 stored in files in tabular format grouped by weather station and with hourly information for each variable 3 1 conceptualisation and characterisation of the forecasting model considering the available variables presented in tables 1 2 and 3 and being our goal building a model representative for interactions between the pressure and surface variables with the local precipitation target variable we built a conceptual model based on explicit and tacit knowledge from domain experts lima et al 2010 reis et al 2004 as mentioned the era interim database has 37 pressure levels available for this study we selected 12 levels 200 300 400 500 600 700 750 800 850 900 925 and 1000 hpa as suggested in lima et al 2010 the levels selection was based on the significant presence of humidity and wind component that conceptually contribute to the formation of extreme precipitation and are considered essential predictors in addition the values of the variables do not change significantly every 25 hpa which makes it possible to eliminate intermediate levels we selected 8 out of 14 pressure variables table 1 and 11 out of 77 surface variables table 2 all extracted from the era interim database the precipitation volume the target variable was obtained from inmet s database from automatic surface stations table 3 the temporal aspect of the model was incorporated considering the availability of information provided by era interim of measurements in 6 h intervals era interim was used to represent the best possible atmospheric data input which is data from the reanalysis collected from many sources and grouped with observed variables continuously every 6 h the era interim considers the most realistic atmospheric conditions with very few observation errors notably it can be said that the result of the proposed model has few influences of errors related to the quality of the input data which are very reliable because are real observations 3 1 1 threshold to define an extreme event the prediction of extreme rainfall events is usually performed according to the considered region for its application stephenson et al 2008 for this it is necessary to adjust a threshold in relation to accumulated precipitation in order to define extreme events in view of this there are several methodologies to classify extreme precipitation events e g in field et al 2012 the authors classify extreme rainfall events as those beyond the 99 percentile of accumulated rainfall usually greater or equal to 50 mm rainfall within 24 h in di et al 2015 the authors proposes a percentile threshold of 95 within 24 h wan et al 2012 and gu and wan 2010 adjusted the threshold in 90 considering the impact of extreme rain to set the threshold lee et al 2014 implemented a model to predict flooding the authors used a 70 0 mm threshold in 6 h based on knowledge from the study s region that this amount of rainfall was capable of causing serious consequences for urbanization for our case study we chose a fixed threshold of 50 mm in 24 h as suggested by field et al 2012 and reis et al 2004 the threshold that defines an extreme event may be different for other regions such as snow dominated regions monsoon regions or droughts regions the methodology proposed in this work uses the threshold to determine the precipitation volume in 24 h and to identify the atmospheric condition before and during this period notice that this allows us to characterize any rainfall event extreme or not independently of the threshold value making our proposal potentially applicable to other regions and thresholds as mentioned our approach uses multivariate regression models as a strategy and the non linear aspect typical of the climatic process is incorporated by means of a neural network lstm 3 1 2 characterisation of the prediction model we formally describe the considered variables set to predict the volume of extreme precipitation as shown in equation 1 1 ispp sfc p l p r e c where ispp corresponds of surface variables sfc pressure levels variables pl and precipitation volume prec the subset of surface variables sfc corresponds to the variables expressed by equation 2 where the past time windows are represented by t i 2 sfc s 1 s 2 s 11 t n s 1 s 2 s 11 t 1 s 1 s 2 s 11 t where s1 total column water kg m 2 s2 total column water vapour kg m 2 s3 mean sea level pressure pa s4 10 m u wind component m s 1 s5 10 m v wind component m s 1 s6 2 m temperature k s7 2 m dewpoint temperature k s8 volumetric soil water layer 1 m3 m3 s9 volumetric soil water layer 2 m3 m3 s10 volumetric soil water layer 3 m3 m3 s11 volumetric soil water layer 4 m3 m3 the subset of variables pl corresponds to the atmospheric variables pl p1 p2 p8 for different pressure levels 200 300 400 500 600 700 750 800 850 900 925 1000 see equation 3 3 pl p 200 1 p 200 2 p 200 8 p 300 1 p 300 2 p 300 8 p 1000 1 p 1000 2 p 1000 8 t n p 200 1 p 200 2 p 200 8 p 300 1 p 300 2 p 300 8 p 1000 1 p 1000 2 p 1000 8 t 1 p 200 1 p 200 2 p 200 8 p 300 1 p 300 2 p 300 8 p 1000 1 p 1000 2 p 1000 8 t where p level 1 potential vorticity m2 s 1 k kg 1 p level 2 geopotential m2 s 2 p level 3 temperature k p level 4 specific humidity kg kg p level 5 vertical velocity pa s 1 p level 6 u velocity m s 1 p level 7 v velocity m s 1 p level 8 relative humidity the precipitation volume prec mm comes from automatic weather stations for a given location at the current time t the generic model of precipitation forecast at time t involving the set of variables expressed by equations 2 and 3 is given by equation 4 4 pr e c t sf c t 1 s f c t 2 s f c t n p l t 1 p l t 2 p l t n 3 1 3 dataset composition and preparation 3 1 3 1 merging the era interim and meteorological station data the adopted process for merging the data was to consider the target area before synchronizing the databases the target location belo horizonte city is between the longitude 45 0 to 43 5 and latitude 18 75 to 20 25 corresponding to 9 grids 3x3 with 0 75x0 75 resolution from era interim see fig 3 in order to manipulate smaller files in this step we built 12 files corresponding to each selected pressure level 200 300 400 500 600 700 750 800 850 900 925 1000 containing 8 pressure variables equation 3 considering the 11 surface variables equation 2 and the target variable precipitation volume from the automatic station s data the datasets with pressure and surface variables were merged according to the dimensions latitude longitude time and level using the merge function of the pandas library pandas 2019 before to merge the target variable prec into the merged dataset we process the data to accumulate the total precipitation for each 24 h fig 4 illustrates this calculation the infographic considers a real example from 16 00 utc on 11 28 2006 the inmet belo horizonte pampulha station a521 accumulated 73 6 mm rainfall volume in 24 h which classifies this as an ere extreme rainfall event assuming the conditions for such an event are detectable at least 24 h before they were present in the surface and pressure variables hence the dataset considers the 24 h utc in advance with this upcoming total precipitation we then added the precipitation prec target variable completing the composition of the dataset 3 1 3 2 data preparation a analysing inconsistent records about 1 of the relative humidity records were outside the expected range 0 8 to 103 but have not been removed the support for this decision is as follows at any temperature and air pressure a specific maximum amount of water vapor in the air will produce a relative humidity rh of 100 supersaturated air contains more water vapor than is necessary to cause saturation the water vapor begins to condense into impurities in the air such as dust or salt particles as the relative humidity approaches 100 and a cloud or mist forms in the air absolutely devoid of impurities as is sometimes the case above 9 000 m but never at lower levels the ur can rise well above 100 b data normalisation a standard lstm neural network unit consists of a cell an input gate an output gate and a forget gate the cell processes values at arbitrary time intervals and the three gates regulate the flow of information into and out of the cell to address the vanishing gradient problem in an lstm we use a function whose second derivative can sustain for a long time before approaching zero typically in design of lstm the sigmoid and hyperbolic tangent functions are commonly used as activation functions in the network units in this work we selected both functions that have that property since the output gate of an lstm network has a hyperbolic tangent function we normalized the data in the 1 1 range c data balancing strategy because our approach does not separate extreme event records from ordinary events the dataset is unbalanced by having more instances of ordinary event records than extreme events in order to balance extreme and ordinary rainfall events the proposed regression model targets accumulated precipitation over 24 h so events with accumulated precipitation above 50 mm for each 6 hour window time window for changing input variables are treated as a unique event in the training stage that is if a single event lasts for multiple times of 6 h or even days it will be trained as multiple events of extreme rainfall 3 1 4 constructing the lstm neural models 3 1 4 1 temporal models for forecasting volume of precipitation forecasting the volume of precipitation is intrinsically a time series analysis problem normally for time series forecasting we use lagged observations e g t n as input variables to forecast in the time interval t h this can be called an h step ahead forecast or a horizon of h for the proposed model taking into account the range of data availability by the era interim system we consider that the time lag can be accumulated with previous observations such as t 1 t 2 t 3 t n respectively 6 12 18 h ago or 6 n hours ago to forecast the volume of precipitation at time t h where h 1 8 corresponding to a forecast horizon of 6 12 48 h ahead we trained and evaluated several models evaluating different temporal windows using the lstm neural networks considering the input variables from time t 16 t 12 t 8 t 4 t 2 and t 1 and the predicted variable prec t h for the forecast horizons of 6 12 48 h ahead the considered models are presented in equation 5 5a m o d e l 2 pr e c t h sf c t 2 s f c t 1 p l t 2 p l t 1 5b m o d e l 2 p r e c t h sf c t 2 s f c t 1 p l t 2 p l t 1 5c m o d e l 3 pr e c t h sf c t 4 s f c t 1 p l t 4 p l t 1 5d m o d e l 4 pr e c t h sf c t 8 s f c t 1 p l t 8 p l t 1 5e m o d e l 5 p r e c t h sf c t 12 s f c t 11 s f c t 1 p l t 12 p l t 11 p l t 1 5f m o d e l 2 p r e c t h sf c t 2 s f c t 1 p l t 2 p l t 1 3 1 4 2 lstm modeling the problems involving time series are more difficult to model unlike common regressive predictive modeling time series data adds the complexity of a historical sequence dependency between input variables and seasonality ann deal with the nonlinear relationships of complex systems bittencout and zárate 2011 long short term memory lstm networks hochreiter and schmidhuber 1997 are a modified version of recurrent ann which have the ability to forget and remember the most recent and relevant past a wide variety of architectures can be designed to an lstm in order to obtain good predictive models for problems involving time series malakar et al 2021 designing lstm networks is more difficult and there is no well founded theory on how to do it objectively thus we evaluated our models through several experiments some techniques aim to explore the different configurations using final results as criteria grid search is a technique based on the exhaustive search used to find the ideal hyper parameters that result in models with more accurate predictions the search takes place in a hyper parameter space defined by a manually specified interval typically a grid search algorithm must be guided by some performance metric usually measured by the cross validation technique in this work we used the walk forward validation technique as it is appropriate for time series data gers et al 1999 the mathematical model for lstms with forget gates gers et al 1999 considered in this work is given by equations 6a to 6f the w u and b matrices are determined through the training process of the neural network 6a f o r g e t g a t e f t σ w f x t u f h t 1 b f 6b u p d a t e g a t e i t σ w i x t u i h t 1 b i 6c c e l l c a n d i d a t e s t a t e c t t a n h w c x t u ci h t 1 b c o u t p u t g a t e o t σ w o x t u o h t 1 b o 6e m e m o r y u p d a t e c t f t c t 1 i t c t 6f o u t p u t g a t e h t o t t a n h c t where d number of inputs d 108 h number of hidden units h 300 t timestep index we use several timesteps in our models o hadamard product operator x t r d input vector for the lstm unit f t r h activation vector for the activation gate i t r h activation vector for the input update gates o t r h activation vector for the output gate h t r h output vector for the lstm unit c t r h activation vector for a candidate cell status c t r h cell status vector w r hxd synaptic weight matrix u r hxd synaptic weight matrix b r h polarization weights vector σ log sigmoid activation function tanh hyperbolic tangent activation function 3 1 4 3 strategies for training validation and testing when evaluating a model for time series prediction we are interested in the model s performance on data that was not used during training in machine learning we call this a test procedure with out of sample data which provides a more meaningful assessment this procedure was carried out by dividing the data into 2 sets approximately 8 years for training and 2 years for validation and tests simply by filtering by the date of occurrence of the events the evaluation of these forecasts will provide a good demonstration of the model s performance when used operationally approximately 80 of the total dataset 11 656 instances were used in the training process corresponding to approximately 8 years with 4 records per day 00 00 06 00 12 00 and 18 00 h utc between 2006 and 2014 for validation and testing we used the remaining data a set with 2 920 instances 20 of the total in the in time series forecast the evaluation of models in historical data is called backtesting as mentioned for this study we used the walk forward validation technique kirkpatrick et al 2015 where the data is divided into small data segments and chronologically ordered while in cross validation k folds are defined in which the set will be partitioned for the walk forward technique there is no predetermined number in each training execution all data available before the target time point is used in the training set and the unseen data is used as a validation set the process is done continuously until the time series ends subsequently the accuracy of the model is computed as the average between runs the number of executions varies from 1 up to the total number of predefined executions segments used for training 3 1 4 4 evaluation metrics to the prediction model mean absolute error mae and root mean squared error rmse are two metrics typically used to evaluate prediction models results based on time series mae corresponds to the mean over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight meanwhile rmse follows a quadratic score rule that also measures the mean magnitude of the error as rmse corresponds to the square root of the mean of squared differences between prediction and actual observation will always be greater than mae for the same results a feature of the rmse is that errors are squared before the mean be calculated therefore the different weights will be added to the sum and as the error values increase the rmse metric increases considerably as extreme precipitation is an outlier its weight will be greater for the rmse calculation and consequently it will affect your metric by making it larger as the main goal of this study aims to predict extreme precipitation among ordinary rains the best approach is to combine rmse and mae metrics in order to assess the performance of the proposed approach we carried out a continuous prediction process for historical data involving periods of ordinary and extreme rainfall the performance of the model for both situations is also analyzed and discussed 4 experiments and results analysis extreme rainfall events are concentrated within approximately 1 of the normal distribution pour et al 2020 kodra et al 2020 which makes it a challenge to obtain a model that can capture these extremes as well as predicting the volume of precipitation for ordinary rainfall events some models choose to separate only the few extreme events and train a more specific model only for the rainy season or for a specific period as mentioned our strategy was to treat the problem as a time series regression problem overcoming seasonality considering periods of low and high rain frequency and to forecast the volume of precipitation between a window of 6 to 48 h in order to evaluate our approach we analysed the results of training processes considering 11 656 registers from set 2006 to october 2014 we calculated the rmse and mae measures for all neural models for the different time lags tables 4 and 5 from the results shown in table 4 it is possible to observe that all models presented satisfactory results the minimum rmse value was 0 59 mm for the i4o2 model input 4 and output 2 and the maximum value was 2 39 mm for the i1o7 model input 1 and output 7 table 5 shows the mean absolute error mae for all models considered in table 4 note that the mean errors for each model correspond to values that can be considered low minimum mean of 0 31 mm for i4o2 and maximum mean of1 30 mm for i1o3 although the maximum mae value has reached in some cases values close to 30 mm it is important to emphasize that the standard deviation remained at low values for example for the i4o2 model the mae value was 0 31 mm and standard deviation of 0 49 mm considering a range around the mean and 2 times the standard deviation we can establish that 95 46 of the error values are within the range between 0 and 1 29 mm this allows us to conclude that the models are highly representative of the training set in order to infer the performance of the models for new data samples we calculated the confidence intervals for the 95 confidence level fig 5 it can be seen that the performance of the models is satisfactory for all configurations the mean mae mean absolute error varies between 0 31 and 1 65 mm and the confidence intervals range from 0 02 to 0 08 mm as is well known computational models based on data always present better results during the training process however when compared to performance during its operational use performance typically decreases in order to evaluate the models under operational conditions and identify the best prediction model a test process was carried out in the proposed models we evaluated the models using testing data contains 2920 registers 730 days 4 temporal windows of 6 h each one from october 2014 to october 2016 not considered during training process we calculated the rmse of all neural network configurations table 6 as well as mae and the standard deviation for the different time lags table 7 the best model input 4 and output 1 i4o1 in bold has rmse value of 6 94 mm see table 6 in bold mae value of 2 97 mm and standard deviation of 6 2 mm for the test data as shown in table 6 this model was trained with input from the previous 24 h 24 18 12 6 h to predict the volume of precipitation 6 h ahead the second and third best models are i2o1 and i8o1 which have a rmse value of 7 58 mm mae of 2 98 standard deviation of 6 9 and 7 79 mm mae of 3 30 standard deviation of 6 9 mm respectively from these three models it is possible to conclude that the better prediction corresponds to 6 h ahead o1 considering the previous atmospheric conditions until 48 h i8 it is important to highlight that the proposed methodology also presents satisfactory results to the forecasting of 12 and 18 h ahead see tables 6 and table 7 in bold i4o2 rmse 8 72 mae 3 49 i4o3 rmse 9 53 mae 4 07 these results are important because they can allow guiding anticipated preventive actions to avoid human and economic losses front eminent extreme events in order to infer the performance of models i2o1 i4o1 i8o1 i4o2 i4o3 considering testing data not used during training processes we calculated the confidence intervals for the 95 confidence level fig 6 notice that the performance of the models is satisfactory the amplitude of the confidence intervals varies from 0 23 mm i4o1 to 0 31 mm i4o3 it is important to highlight that our methodology allows predicting extreme rainfall events and ordinary rainfall in order to evaluate the performance of our approach in both rainfall situations fig 7 shows the predicted versus actual rainfall volume values from the models with lower mean absolute errors models with inputs 1 2 4 and 8 6 12 24 and 48 h ago respectively and forecasting of 6 h ahead note that the amount of data relating to low rainfall conditions is noticeably greater than the amount of data relating to extreme event conditions despite the applied balancing procedure subsection 2 2 4 2c it is expected that the models have a better prediction performance for low rainfall than for high rainfall events we performed additional experiments considering only data of extreme rainfall however due to the small amount of data the models did not perform any better the reason why we kept our forecast considering the complete time series it is important to emphasize that models based on neural networks are fitted from data and the more information is provided during the training process these networks are able to represent the qualitative relationships existing in the physical system as exposed in bittencout and zárate 2011 so we consider that modeling the climatic system as a time series regression problem preserves the greatest amount of information that is why we chose to work with global models to forecast precipitation regardless of low or high precipitation the value of the pearson correlation coefficient r 2 considering ordinary and extreme rainfalls for the four models considered i1o1 i2o1 i4o1 i8o1 are 0 71 0 73 0 72 and 0 70 respectively which can be considered with high correlation hinkle et al 2003 considering the best model i4o1 which obtained a rmse value of 6 94 mm the pearson correlations value considering rainfall events low and up of 50 mm were of 0 60 and 0 59 considered moderate correlation table 8 shows the number of events with rainfall for the study region specifically at the location of the a521 station latitude 19 53 2 22 longitude 43 58 9 83 altitude 854 m notice that of the 2920 records 600 rainfall events above 1 mm in 24 h occurred the model predicted 902 rainfall events above 1 mm being that the biggest difference occurs for the interval 1 10 where the number of predicted events were of 556 in relation to 264 actual events the difference is due to the prediction of actual events below and close to 1 mm for which the model predicted values between 1 10 it is still possible to note that in 2 years 2014 2016 there were 46 extreme rainfall events 50 mm in 24 h in bold corresponding to 7 6 of the total of events that occurred in the considered period the best model i4o1 was able to predict the precipitation value for 23 extreme events 50 of the total events we emphasize that the important thing for prediction is to know if an event will happen and if it will cause an impact in relation to the volume of precipitation we also observed that for the 50 70 interval which characterizes extreme events with socio economic impact our model correctly predicted 30 of the 34 events besides in table 8 we can highlight that the model i4o1 is also capable of predicting the value of precipitation for events of lesser intensity this increases the relevance of the model e g to predict the amount of rain for agricultural systems which can benefit from this information for planning irrigation periods as already mentioned due to a large amount of data referring to conditions of low precipitation the model presented a satisfactory performance for precipitations below 50 mm in order to evaluate the performance of temporal forecasting for the study region fig 8 shows typical rainfall events in southeastern brazil during the brazilian summer for the oct 2014 oct 2016 period the rainy season in the considered region typically begins at the end of october and lasts from 155 to 173 days minuzzi et al 2007 ending approximately at the beginning of march we observed that the highest concentration of critical extreme events above 50 mm of precipitation occurs between the months of december to february for the period considered table 9 shows the dates and times during which extreme events occurred the record groups indicate 24 hour accumulated rainfall recorded every 6 h observing the in bold groups it is possible to confirm that the best model i4o1 with previous data of 24 h predicts with greater precision the horizon of 6 h ahead for example for the group with date 2014 12 13 time 6 00 00 to date 2014 12 14 time 6 00 00 the prediction error continuously decreases reaching the value 0 8 mm this same behavior occurs in 7 54 cases of the groups shown in table 9 based on these results we can emphasize that the approach proposed in this work considers relevant atmospheric characteristics to predict the volume of precipitation in extreme event scenarios finally we compare our model with the autoregressive integrated moving average model arima the model was built considering the same training data used in our approach 11 656 registers from sep 2006 to october 2014 the best fitted model was arima 3 1 1 and the calculated coefficients are ar1 ar2 ar3 ma1 0 4095 0 0196 0 0552 0 9662 the arima model achieved an rmse value of 43 37 mm and mae value of 21 62 our best model i4o1 achieved during training an rmse value of 0 94 mm and mae value of 0 46 it is important to highlight that during the operational test our model achieved an rmse value of 6 94 mm and an mae value of 2 97 mm superior performance to that arima model this shows that our approach gives superior results to classical models based on time series fig 9 shows the responses of the i4o1 and arima models for a time window from nov 28 2006 00 00 to dec 01 2006 18 00 from training data considering that the precipitation forecast is carried out for 6 hours ahead it is observed that the auto regressive integrated moving average models always have a delayed response which is not of interest for the prediction of extreme events that would affect a city the best model proposed in this work i4o1 has predictive characteristics that allow it to track precipitation events without delay this behavior is due to the fact that our approach takes into account several atmospheric variables for different pressure levels such as potential vorticity specific humidity vertical velocity u velocity v velocity relative humidity among other surface variables which we relate through neural models to forecast rainfall it is important to emphasize that the forecast of the volume of precipitation in rain is extremely difficult due to the complexity of the meteorological system that produces them 5 conclusions and future directions in this work we proposed a model based on lstm neural networks to predict the volume of extreme precipitation and detect extreme rainfall events the model uses data from 8 atmospheric variables and 11 surface variables for 12 atmospheric pressure levels we evaluated several configurations and the model that obtained the best predictive accuracy uses 24 h prior information before the target event we believe that this work contributes towards a new approach to predict extremes rainfall events in southeastern brazil especially in belo horizonte and can lead to better predictability of extreme weather events the approach presented here can be applied in other regions and locations using the same data source era interim it would also be possible to use era5 era5 2020 data for training a similar forecast model era5 covers the earth in a 30 km grid and resolves the atmosphere using 137 surface levels up to a height of 80 km our methodology is inherently objective and reproducible and it can be implemented operationally to assist in the prediction of intense and potentially catastrophic events this study shows that era interim as input data resulted in models with a good performance for estimating most events of heavy precipitation naturally our data source can be replaced by other equivalent meteorological input data with real time or near real time measurements and serve as support to the monitoring of heavy precipitations the vast majority of approaches treat extreme rain events forecasting as an imbalanced problem such as the studies cited in our related works section thus the model requires a number of good positive class examples that represent the extreme events and their anomalous conditions the main contribution of our approach is that it is not necessary to separate scenarios of normal precipitation or absence of precipitation which is a drawback of similar approaches our model is capable of handling a complete time series without additional preprocessing required the proposed methodology and the results of this work can be used to predict extreme precipitation events in the city of belo horizonte 24 h in advance we highlight the following contributions a possibility to be used as a decision support tool associated with the forecasts made using global mathematical models b the processing required is less computationally expensive than the usual meteorological forecasting strategies c the model s specialization by season can contribute to direct attention to specific neighborhoods and regions and d flexibility to use various time windows for prediction between 6 and 48 h as limitations of this study we highlight a absence of spatial abstraction the model needs to be retrained for use in a new area and it is necessary to obtain and synchronize the data from the weather stations present in each target area b dependent on a significant historical interval the model used 8 years of historical data and using smaller intervals might reduce its generalization capacity and c absence of previous studies describing strategies for predicting extreme rainfall events without balancing the data as a future work we plan to experiment with other architectures and some methods of transforming non stationary time series data into stationary we also suggest a considering a comparative performance analysis with different activation functions for lstm networks as recommend in farzad et al 2019 the authors establish that other activation functions such as elliott similar to sigmoid can reduce average error and be faster to compute than the exponential sigmoid function b investigating new architectures such as a convolutional neural networks cnn which can be used as the encoder in an encoder decoder architecture with the intention of capturing spatial abstraction geolocation c replacing the era interim database with era 5 and observe how the models results are affected note that era 5 can be used in order to reproduce our results according to our methodology d using smaller temporal resolutions the era 5 data has hourly resolution e applying the proposed methodology in other regions to investigate how much the methodology can be generalized for different environments and f change the methodology to retrain the model whenever new daily data becomes available effectively making it an online system funding source this research received financial support of foundation for research support of the state of minas gerais fapemig brazil process no cex apq 00997 15 credit authorship contribution statement andré de sousa araújo conceptualization methodology software validation investigation data curation visualization adma raia silva conceptualization methodology luis e zárate conceptualization methodology validation formal analysis investigation visualization supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the fapemig foundation for research support of the state of minas gerais grant number cex apq 00997 15 the cnpq brazilian national council for scientific and technological development capes coordination for the improvement of higher education personnel and pontifical catholic university of minas gerais brazil 
