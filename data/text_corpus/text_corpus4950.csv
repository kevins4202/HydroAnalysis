index,text
24750,with successful mitigation of eutrophication and the reductions in nutrient concentrations and productivity of coastal waters the targets set in nature protection legislation in the eu and the united states may no longer be achievable in regions where key ecological functions are coupled to benthic productivity yet due to both the patchiness of invertebrate distribution and the fragmented and non integrated nature of monitoring data direct coupling between nutrients productivity and predators has proven difficult to achieve as a result assessments of the status of food webs based solely on monitoring data remains an almost impossible task the aim of this modelling study was to test the application of fine scale ecosystem models for assessing cost benefits or food web consequences of management decisions in relation to water quality of coastal waters we applied a fine scale ecosystem model calibrated against measurements in a coastal area in the baltic sea to quantify responses in higher trophic levels to changes in eutrophication over a 18 year period 1990 2007 the resulting spatio temporal trends reveal a number of characteristic responses and spatial dimensions in coastal food webs the coupled hydrodynamic bio geochemical and waterbird energetics modules indicated nutrient related changes and fine scale covariance patterns across all trophic levels a 50 decline in bivalve biomass was predicted in a zone characterised by the overall highest biomass of bivalves and highest densities of bivalve feeding waterbirds the nutrient driven local decline in productivity affected the entire food web with a predicted annual mortality of 72 000 long tailed ducks clangula hyemalis this model based study suggests a strong nutrient control of the available food supply to bivalve feeding birds in coastal areas our results also show that high resolution ecosystem models are required to resolve the heterogeneous distribution of effects keywords eutrophication coastal ecosystems food webs macrobenthos aquatic birds ecological modelling 1 introduction over the past decade increasing evidence of significant and wide ranging alterations of coastal benthic communities and ecosystems has emerged sorte et al 2016 analysed long term changes in the abundance of the blue mussel mytilus edulis over a 40 year period between 1972 and 2014 in the gulf of maine usa and documented declines above 60 this decline in mussel biomass coincided with a shift in benthic community composition from a sessile community to a community dominated by algae and was seemingly attributable to a range of anthropogenic influences including climate change harvest eutrophication and introduction of non native species a large scale reduction in the biomass of benthic macrofauna in the danish waters over the last 20 years was recently demonstrated by riemann et al 2015 a reduction which took place in parallel to reductions in nutrient concentrations and primary productivity during the same period the abundance of benthos feeding waterbirds has declined significantly in many areas of the baltic sea skov et al 2011 bellebaum et al 2014 suggesting a link between oligotrophication and reduced populations of macrofauna and predators in north america many species of bivalve eating seaducks have declined dramatically in number in recent decades without apparent cause schamber et al 2009 literature related to nutrient loading abounds with studies identifying the effects of eutrophication and consequent changes in benthic animal populations along with other changes in different ecosystem pearson and rosenberg 1978 cloern 2001 bonsdorff et al 2002 helcom 2009 but studies which evaluate knock on effects on benthic food webs including higher trophic levels to these changes are lacking despite apparent parallel tendencies in eutrophication levels and population sizes of top predators waterbirds in some coastal areas a direct coupling between nutrients productivity and predators has not been documented empirically this is due to the fact that existing data on benthic in and epifauna does not meet the requirements of food web studies due to both the patchiness of invertebrate distribution and a poor spatial and temporal coverage of standard monitoring data adding to this the data on benthos is normally decoupled from the monitoring of water chemistry and surveys of waterbird abundance are undertaken at 10 year intervals making assessments on the status of food webs based solely on monitoring data an almost impossible task in this paper we therefore aimed at studying the level of synchronous spatio temporal trends in main components of the coastal food web by using an ecosystem model as supplement to the existing monitoring programs specifically we studied the coupling between fine scale benthic productivity and benthic feeding waterbirds and reconstructed the recent history of spatio temporal dynamics of nutrient concentrations primary productivity mussel growth and carrying capacity in relation to waterbird fitness by examining coupled spatio temporal trends in nutrient loads and the modelled phytoplankton growth bivalve biomass and waterbird fitness we quantified changes driven by reduction in the load of nutrients to higher trophic levels of the coastal ecosystem of the gulf of riga baltic sea 2 materials and methods 2 1 study area the study region was the gulf of riga in the north eastern part of the baltic sea and irbe strait which is the main connection between the gulf of riga and the baltic sea fig 1 the gulf of riga is shallow with a maximum depth of 60 m the catchment area is about ten times larger than the surface area of the gulf the main rivers discharging their waters to the gulf are daugava lielupe gauja and pärnu rivers the salinity patterns in the gulf of riga are characterised by a lack of a permanent halocline and high spatio temporal variability from 0 5 2 0 psu close to river mouths and adjacent surface water in spring and up to 7 5 7 7 psu at the bottom of the irbe strait in spring and summer ojaveer 1995 kotta et al 2008 during the summer season a strong thermocline separates the upper 15 c and deeper 6 c water layers surface water 0 10 m temperature exceeds 10 c from the third week of may until the end of september kotta et al 2008 the duration of long term mean ice cover in the north eastern gulf of riga is 132 days ojaveer 1995 the seafloor of the gulf of riga is very diverse in structure and characterised by mainly being a deposition area dominated by sandy or silty sediments but northern shores have also extensive boulder reefs the coastline of the gulf is mostly open and exposed in the eastern western and southern parts while a system of shallow enclosed bays with soft deposition areas dominates in the northern part winter nutrient concentrations in the coastal areas of the region have declined by 30 after 1990 oesterwind et al 2016 and hence the study of co variation in nutrients fauna and waterbirds was focused on the period between 1990 and 2007 bivalves dominate the macrozoobenthic communities of the gulf of riga with the most prevalent species being macoma baltica cerastoderma glaucum mya arenaria and mytilus edulis kotta et al 2008 the waterbird fauna is dominated by non breeding concentrations of bivalve feeding seaducks of which the long tailed duck clangula hyemalis and velvet scoter melanitta fusca are the most abundant durinck et al 1994 the seaducks occupy the shallower parts of the gulf during the period from november to may 2 2 ecological model complex the ecological model complex was calibrated against local measurements and consists of a coupled hydrodynamic and bio geochemical model mike 3 fm ecolab https www mikepoweredbydhi com products eco lab coupled to a waterbird energetics module at a spatial resolution of 1 to 5 km covering the 18 year period between 1990 and 2007 fig 2 the coupled hydrodynamic and bio geochemical model describes concentration of and processes related to phytoplankton nutrients n p si detritus and dissolved oxygen furthermore advanced descriptions of the benthic vegetation community and growth of mussel and clam populations are implemented including descriptions of growth and death processes the waterbird energetics module was set up to focus on long tailed duck and velvet scoter with the aim to estimate how changes in available supply of bivalves induced by changes in nutrient levels might affect upper trophic levels of the gulf of riga as reflected by the survival and body condition of the bird predators the model grid covered the whole depth gradient from the coast to the lower sublittoral the overall modelling approach and data flow from hydrodynamic to the bio energetic models applied is shown in fig 2 and table 1 gives an overview of the different data sources used for developing and calibrating the model complex the model complex has been designed as an integrated series of deterministic models in which physical chemical and biological processes controlling the scale and magnitude of the effects are built into the models based on equations for the conservation of mass and momentum and biological dose response relationships this modular end to end modelling approach is advantageous for quantitative and spatial studies as it allows for an assessment of the direct effects of eutrophication on benthic fauna and waterbirds as well as bottom up effects due to changes in the supply of food predicted by the ecological model e g changes in mussel biomass details of the parametrisation and calibration of the model complex can be found in the supplement 2 3 hydrodynamic model the hydrodynamic model is based on the baltic sea model developed by dhi fehy 2013 with a refined bathymetric grid in the gulf of riga the model is a three dimensional hydrodynamic model based on the mike 3 fm modelling system dhi 2014 the hydrodynamic model uses data listed in table 1 for model mesh bathymetry model initial and boundary conditions salinity temperature water level current model forcing atmospheric forcing river inflow and model calibration data mainly in situ temperature and salinity the concept of the model is that the coarse regional model of the entire baltic sea is extended with a detailed bathymetry of the gulf of riga this is possible due to the flexible mesh approach applied in fig 1 the local mesh part of the gulf of riga is shown the model is forced by meteorological data in the form of wind air pressure and temperature relative humidity clearness precipitation and ice coverage these data enter the continuity momentum temperature and turbulence equations of the model specifically in areas with ice the wind forcing and heat exchange terms are dampened the river inflow run off to the gulf of riga is distributed into daugava river 64 lielupe river 14 gauja salaca and pärnu rivers 6 each and kasari river 4 the location of the local rivers is shown in fig 3 2 4 ecological biogeochemical model the ecological biogeochemical model is based on the eco lab modelling system dhi 2014 the ecological biogeochemical model is coupled to the hydrodynamic model which together form the basis of the total model complex the ecological biogeochemical model consists of 100 state variables table 2 including the bio geochemical cycle of c n and p three phytoplankton groups diatoms cyanobacteria and flagellates eelgrass and three macroalgae and microphytobenthos groups the benthic fauna is included with population models of the suspension feeders mytilus sp and mya sp and the deposit suspension feeder macoma baltica furthermore the template includes a description of organic c n and p in the sediment the benthic fauna mussel mussel model is a population model with 2 state variables abundance no m2 and dry weight of soft tissue for each length class of mytilus mya sp and macoma baltica the mytilus mya sp population is described by 12 logarithmically increasing size classes ranging from 5 5 mm to 74 mm whereas macoma baltica population is described by 10 logarithmically increasing size classes ranging from 0 5 mm to 25 mm the spatially explicit population processes included in the model are i growth a function of food concentration temperature and oxygen ii starvation mortality iii predation mean rate by crabs fish and waterbirds iv spawning and v upward transfer of number of mussel and biomass to a higher size classes the net growth of mussels in each size class depends on food supply temperature and oxygen conditions in each grid cell biomass loss is modelled through a general predation crab fish birds a starvation mortality and through release of gametes a fraction of the released gametes enters the biomass of zooplankton the remaining biomass of the gametes enters the detritus pools recruitments of new mussels to size class 1 are described as spat fall to the bottom where the biomass is taken from zooplankton macoma spat settle on soft bottom mytilus mya sp spat settles on hard surfaces and mya on sandy to soft sediments the biogeochemical model includes a series of sediment state variables for which initial maps have to be generated by dividing the bottom into erosion transport and deposition bottoms depending on the yearly frequency of resuspension which is estimated from shear stress generated by currents and waves using the mike 3d flow model and 2d wave model mike sw using the equations formulated by soulsby and clarke 2005 and applied to the ecological model as a forcing function supported by monitoring data initial maps are defined based on frequency of resuspension and depth the suspension feeding mussels like macoma baltica are feeding on suspended organic matter and are especially relying on the availability of phytoplankton the edibility or quality of the food is determined by the c n p ratio to be able to simulate the food source the sediment pool of c n and p was split into an unconsolidated layer on the sediment surface and a consolidated layer below see fig 4 2 5 seaduck individual based model a spatially explicit individual based model ibm was setup focusing on long tailed duck and velvet scoter and their interactions with the modelled prey bivalves fig 5 the overall purpose of the individual based model is to estimate how changes in bivalve biomass might affect local carrying capacity of the study area for the analysed seaducks when looking at their survival and body condition an overview of the parameters used to setup and calibrate the seaduck ibm is given in table 1 while the particular parameter values and results of sensitivity tests are provided in table s4 in the supplement the ibm which was constructed using package morph as a platform stillman 2008 relates individual behaviours such as feeding activity rate of food intake or inter specific competition to environmental factors and food availability and provides detailed insight into aspects which constrain species fitness and numbers of birds using certain resources the ibm runs at discrete time steps of a fixed duration 1 hour space is represented by discrete patches with fixed location patches are defined as a variable grid with cells of 2 2 km in shallow waters and 4 4 km in waters deeper than 20 m fig 5 during each time step global events are processed first followed by patch events and then forager events the adaptive traits of individual seaducks are their location and diet selection during each time step seaducks select the patch diet combination which maximises their perceived fitness once the forager has selected a patch and diet the consequences of this decision are determined by true probability of survival foragers remember their foraging success during a defined number of previous time steps this memory is used to calculate average state variables over previous time steps the model does not allow foragers to know the future values of any state variables 2 6 determination of patterns of benthic productivity the model estimates provided us the areas of high bivalve biomass g c m2 concentrations of bivalves macoma baltica and mytilus edulis and high relative densities of waterbirds n km2 clangula hyemalis and melanitta fusca the bivalve biomass was expressed as modelled mean biomass during the period 1990 2007 relative densities of waterbirds were estimated using an arbitrary scale based on the simulation allowing 200 000 long tailed ducks and 120 000 velvet scoters into the model system these numbers reflect the population of wintering seaducks in the gulf of riga in 2001 skov et al 2011 2 7 analysis of spatio temporal trends in biomass of food web components in response to changes in eutrophication spatial patterns of long term trends in the food web components nutrients chl a baltic clams blue mussels long tailed duck and velvet scoter were analysed using spatially explicit trend tests theil 1950 sen 1968 hoaglin et al 2000 which allowed the size and significance of the trends 1990 2007 in each component i e nutrients bivalves and waterbirds to be estimated for each of the 3040 model grid nodes and spatially visualised to identify zones with similar increasing decreasing trends in order to quantify and compare the degree of co variation between food web components the weekly estimates were standardised to z scores which also removed the seasonal trends from the long term trend standardisation was done by subtracting the long term average from each weekly estimate and standardising the resulting value to z scores by dividing with the standard deviation kreyszig 1979 the deseasoning and trend analyses were calculated for each grid node the non parametric median trend test theil 1950 sen 1968 hoaglin et al 2000 was used to calculate the significance α 0 05 of the long term trend based on the z scores at each grid node the median trend test is a robust non parametric trend operator which is less sensitive to outliers than least squares estimators it is calculated by computing slopes of lines crossing all possible pairs of points when x coordinates differ after calculating these n n 1 2 slopes the median of them is taken as slope estimator next the intercepts of n lines crossing each point and having calculated slope are calculated the median from them is the estimated intercept the median trend test was applied using data from the entire 18 year time series deseasoning and median trend tests were undertaken in terrset ver 18 21 clark labs clark university 2016 2 8 coupling productivity to energetic conditions of higher trophic levels waterbirds based on analyses of the trends in bivalve biomass a series of simulations were undertaken using the waterbird energetics module the simulations estimated the body condition and annually added mortality of long tailed duck and velvet scoter in the gulf of riga given the predicted level of reduction in bivalve biomass in different parts of the region the relative body condition and mortality were estimated for 0 50 reduction increase in bivalve biomass using 2001 as a base year 3 results 3 1 areas of enhanced bivalve biomass and waterbird abundance for the period 1990 2007 areas of high biomass of blue mussels and baltic clams were estimated in the shallower northern parts of the gulf of riga with water depths below 20 m fig 6 blue mussels displayed a patchy distribution with peak mean biomass values estimated in a zone stretching over 40 km in the irbe strait the distribution area of the baltic clams was wider yet overlapping with that of the blue mussels peak biomass values of baltic clams were estimated in the irbe strait and between the islands saaremaa and hiumaa and the estonian mainland the modelled patterns of densities of long tailed duck and velvet scoter highly co varied with the biomass of blue mussels and baltic clams with almost all birds occurring in areas shallower than 20 m and with high densities off the coast in the northern part of the gulf due to density dependence the distribution of the waterbirds was more dispersed than that of the bivalves and the highest densities of waterbirds did not exactly coincide with small patches of maximum bivalve biomass fig 6 the most extensive aggregation of waterbirds was estimated in the irbe strait the predicted high density areas fitted the patterns recorded during waterbird surveys in 2006 2008 skov et al 2011 3 2 spatial variability in food web responses to changes in eutrophication the spatial pattern of the median trend tests for nutrients chl a bivalves and waterbirds reflected by the standardised z scores are displayed in fig 7 and p values of the tests for the biomass of mussels and clams are mapped in fig 8 the pattern of the standardised trend for nitrogen and phosphorous was clearly spatially variable indicating minor decrease in concentrations of both nutrients in the baltic proper and around the islands saaremaa and hiumaa and stronger decrease in concentrations in most parts of the gulf of riga except close to the coast in the northern part the patterns of trends of nitrogen and phosphorous did not fully coincide and the zone with high biomass of bivalves and densities of waterbirds coincided with decreasing concentrations of nitrogen but increasing concentrations of phosphorous the pattern of chl a trends was more complex and showed increasing trends in the southeastern part of the gulf and around the islands of saaremaa and hiumaa opposing to decreasing trends in the zone with high biomass of bivalves and densities of waterbirds off the estonian coast and in the irbe strait the pattern of the bivalves exhibited a high degree of similarity in the standardised trends although trends of mussels had the highest trend scores and thus indicating overall larger changes during the period bivalve trends were generally positive in the southeastern part of the gulf and in the baltic proper but negative in the rest of the modelled region a continuous area of negative trends for blue mussels was depicted in the whole north western part of the gulf inshore along the estonian mainland and in the irbe strait for baltic clams the largest area showing declining trends was found in the irbe strait and close inshore along saaremaa and the estonian mainland the spatio temporal trends in the biomass of blue mussels during the period 1990 2007 were significant in most part of the model grid except for the deeper part of the gulf of riga and the baltic proper median trend test p 0 05 fig 8 for baltic clams the area representing significant results median trend test p 0 05 was smaller in the gulf of riga as approximately 1 3 of the modelled part of the gulf had p values above 0 05 the standardised trends in the zone of modelled decline in blue mussels and the entire modelled region were strikingly different indicating heterogeneous responses within the region of the gulf of riga fig 9 within the zone nitrogen declined sharply after 1993 and seemingly continued to decline until 2008 whereas nitrogen concentrations in the entire region showed only a weak decline in the early 1990 es while phosphorous concentrations clearly declined within the zone after 2004 the general decline in the model region was weak no discernible difference in chl a trends was found between the zone of declining mussel biomass and the entire region although the concentrations of chl a varied much more within the zone the trends in blue mussels were very different inside the zone as compared to the entire region as no clear tendency in modelled biomass values could be determined in the whole region while the biomass declined continuously from 1993 to 2008 within the zone the decline within the zone between 1993 and 2008 reflected a decline in mean biomass of blue mussels of 50 standardised trends for baltic clams were much weaker than for blue mussels and negative z scores were only estimated within the zone after 2006 3 3 energetic impact of reduced carrying capacity on higher trophic levels waterbirds the results of the scenarios of energetic impact of reduced supply of bivalve biomass on waterbird fitness are shown in fig 10 the additive annual mortality of long tailed ducks during the baseline year of 2001 was estimated at 2 000 birds the estimated additive mortality of long tailed ducks would increase to 21 000 per year with a 20 decline in bivalve biomass compared to 2001 to 48 000 with a 40 decline and to 73 000 with a 50 decline the estimated additive mortality of velvet scoters was less dramatic and would be zero for 2001 and increase to 2 000 per year with a 40 decline in bivalve biomass compared to 2001 and to 10 000 with a 50 decline in bivalve biomass 4 discussion 4 1 covariance patterns of nutrients plankton benthos and waterbird dynamics to our knowledge this modelling study is the first to attempt to link reductions in eutrophication to changes in the entire food web from plankton to top predators of a coastal ecosystem the resulting spatio temporal trends reveal a number of characteristic responses in the coastal food webs which have added important new insight into the spatial dimensions of interactions between components of the food web and far reaching implications for the ecological management and monitoring practices applied commonplace in coastal areas our study region in the baltic sea may be seen as a typical example of an eutrophicated coastal ecosystem which during the investigated period between 1990 and 2007 has undergone significant changes in nutrient levels benthos and waterbirds which to a large extent have been driven by reductions in nutrient loads from land based sources kotta et al 2008 helcom 2009 skov et al 2011 perhaps the most striking result is the degree of fine scale covariance in the spatio temporal trends across the entire food web from nutrients to waterbirds the apparent spatial heterogeneity in the trends in nutrient concentrations in the region which were also documented by helcom 2009 and oesterwind et al 2016 showed that reductions were in fact limited to the areas within the less exposed area of the gulf of riga the obvious spatial heterogeneity in the modelled trends of clams and mussels indicated strong gradients in the trends of benthos biomass with a coherent area of declining biomass in the north western part of the gulf inshore along the estonian mainland and in the irbe strait the trends in this area contrasted to increasing trends in bivalve biomass found in the south eastern part of the gulf of riga and in the more exposed areas of the baltic proper as the area of declining bivalve biomass overlapped with the zone with the overall highest biomass of bivalves and highest densities of mussel feeding waterbirds the consequences of decreasing nutrient concentrations on the coastal food web would most likely be limited to this area as indicated by the lack of a general negative trend in bivalve biomass over the entire region we hypothesize that the fine scale covariance patterns are driven by the fine scale variability in hydrodynamics in the gulf of riga which creates strong gradients in current speed and direction and persistent patterns of residual currents fronts upwellings and eddies ojaveer and kalejs 1974 in the frontal zone of the irbe strait which is part of the primary zone impacted by eutrophication the correlation between concentrations of nitrogen and benthos biomass has been corroborated by empirical data kotta et al 2008 the spatial patterns of the trends found in this study provide an important supplement to field data due to patchy bottom sediments in the gulf of riga the fragmented nature of monitoring data and the temporal mismatch in the sampling of the different food web components the difference in the biomass of the bivalve species between the southern and the northern parts of the gulf has been confirmed empirically kotta et al 2008 more importantly the overall decline in nutrient supply to the gulf in the 1990 es and the subsequent decline in the biomass of blue mussels and baltic clams in coastal areas have also been verified empirically fig 11 suursaar 1995 kotta et al 2008 kotta et al 2009 the ecosystem model offers new possibilities such as identifying more precisely the spatial extent of areas affected by the reduction in eutrophication and quantifying the spatial effects of changed nutrient loading at higher trophic levels 4 2 impact of eutrophication control on food webs in coastal areas with the implementation of policies to control eutrophication such as the us clean water act craig 2009 and the eu water framework directive european commission 2019 the benthic productivity of many coastal areas is likely to shrink this modelling study has shown how a nutrient driven local scale decline in productivity over the course of less than 20 years can affect the entire food web including waterbirds in both north america and northern europe large scale declines of benthic feeding waterbirds have been observed over the past 15 years in the baltic sea declines above 30 have been documented for seven out of 20 species of waterbirds since 1993 and declines in bivalve feeding seaducks of 47 65 skov et al 2011 similar figures are available for seaduck populations in north america population size estimates based on aerial counts of breeding long tailed ducks in both alaska and canada s yukon territory in early 2000s were nearly 50 lower than estimates from the mid 1970s schamber et al 2009 although the coverage of monitoring data does not generally allow for detection of synchronous trends in nutrients and benthos data from inner danish waters show a significant decline in the biomass of filter feeding macrofauna over the last 20 years riemann et al 2015 based on the functional requirements for growth of both suspension feeding and deposit feeding bivalve populations it is obvious that a great potential for eutrophication induced effects on the available food supply to predatory fish and birds exists in many coastal areas however these effects of eutrophication control may differ between the different coastal regions and even within regions the response may show a diversity of trends lundberg 2005 thus conceptual models showing responses of food webs to nutrient enrichment in coastal areas may ideally represent a dome shaped response reflecting both the impoverished benthic conditions and hypoxia in enclosed areas with mixing constraints and positive linear relations between eutrophication and the growth of benthos stocks that have been found in more exposed areas cloern 2001 wolowicz et al 2006 the consequences of the unified efforts to control eutrophication on coastal food webs will soon become more apparent as mitigation measures and policies are implemented widely despite spatial variability in the response of zoobenthos and waterbird populations our study has highlighted the fact that population declines of bivalves in some areas may be approaching thresholds of the carrying capacity of several key waterbird species jeopardizing the sustainability of these waterbird populations in the region the predicted annual additive mortality of more than 70 000 long tailed ducks given current declines in the productivity of the north western part of the gulf of riga and the irbe strait may not be sustainable and may result in further declines in the region as the species is affected by other anthropogenic pressures including oil pollution habitat destruction and competition for food from the non indigenous round goby neogobius melanostomus nurkse et al 2016 at the same time it should be noted that the estimated survival and mortality rates of long tailed ducks assume no emigration of birds to other areas with higher carrying capacity thus the estimates may be seen as conservative although similar reductions of benthic productivity most likely have also taken place in other coastal areas of the baltic sea consequently the aims set in the us clean water act and the eu water framework directive to reduce eutrophication and in us and eu nature protection legislation for conservation of benthos feeding waterbirds e g the us migratory bird treaty act https www fws gov birds policies and regulations laws legislations migratory bird treaty act php the north american wetlands conservation act https www fws gov birds grants north american wetland conservation act php the eu birds directive eu bird directive 1979 and the eu habitats directive eu habitats directive 1992 may not both be achievable in all regions 4 3 management applications of fine scale ecosystem models this study demonstrates that fine scale ecosystem models enable quantifying spatial gradients in the changes of coastal ecosystems as such these models are an important supplement to monitoring activities in order to achieve a process based understanding of the functioning and status required for a successful management of specific areas like marine protected areas today fine scale ecosystem models are not used to pursue targets and measures for improving water quality and maintaining biodiversity in marine protected areas nor for assessing cost benefits or food web consequences of management decisions related to these sites one of the benefits of a deterministic ecosystem model complex like the one used in this study is the ability to test the impacts of a range of management scenarios in an attempt to resolve synergies and set mutual targets for water quality and biodiversity conservation as nutrient concentrations in coastal waters are declining new baseline conditions in eutrophication controlled coastal areas will appear the ecological requirements for simultaneously reaching good water quality and conserving biodiversity conservation vary spatially and depend on how much the flow of energy from benthos to predators is controlled by nutrient loading eutrophication synergies may not be achievable unless a spatially explicit understanding of processes underlying local food webs is developed the complementary use of empirical and modelling approaches to derive population community and ecosystem indicators is key to the development of operational food web indicators for ecosystem based management in the marine environment rombouts et al 2013 to accommodate the difficulty of integrating across so many levels of organisation however requires new information as well as new methods our high resolution application of an ecological model complex stresses the importance of designing bio geochemical models with high spatial resolution as a basis for making reliable predictions on energy fluxes in coastal areas with strong gradients in hydrodynamics as shown by the comparison of general trends in benthic productivity with trends in specific zones of the gulf of riga invalid interpretations regarding the ecological status could easily have been made if based on a large scale model authors contributions alm managed the study jk co ordinated the benthic monitoring tu undertook the hydrodynamic modelling ekr was responsible for the ecological biogeochemical model work rz was responsible for the waterbird individual based model and hs analysed the spatio temporal trends in the model data and led the writing of the manuscript credit author statement this is to certify that all authors have seen and approved the final version of the revised version of the manuscript the manuscript is original and it has not been published before or is under consideration for publication elsewhere declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the modelling work is based on the bonus bio c3 project and has received funding from bonus the joint baltic sea research and development programme art 185 funded jointly from the european union s seventh programme for research technological development and demonstration and from the danish and estonian research council in addition the work has been supported by institutional research funding iut02 20 of the estonian research council supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2020 109249 appendix supplementary materials image application 1 
24750,with successful mitigation of eutrophication and the reductions in nutrient concentrations and productivity of coastal waters the targets set in nature protection legislation in the eu and the united states may no longer be achievable in regions where key ecological functions are coupled to benthic productivity yet due to both the patchiness of invertebrate distribution and the fragmented and non integrated nature of monitoring data direct coupling between nutrients productivity and predators has proven difficult to achieve as a result assessments of the status of food webs based solely on monitoring data remains an almost impossible task the aim of this modelling study was to test the application of fine scale ecosystem models for assessing cost benefits or food web consequences of management decisions in relation to water quality of coastal waters we applied a fine scale ecosystem model calibrated against measurements in a coastal area in the baltic sea to quantify responses in higher trophic levels to changes in eutrophication over a 18 year period 1990 2007 the resulting spatio temporal trends reveal a number of characteristic responses and spatial dimensions in coastal food webs the coupled hydrodynamic bio geochemical and waterbird energetics modules indicated nutrient related changes and fine scale covariance patterns across all trophic levels a 50 decline in bivalve biomass was predicted in a zone characterised by the overall highest biomass of bivalves and highest densities of bivalve feeding waterbirds the nutrient driven local decline in productivity affected the entire food web with a predicted annual mortality of 72 000 long tailed ducks clangula hyemalis this model based study suggests a strong nutrient control of the available food supply to bivalve feeding birds in coastal areas our results also show that high resolution ecosystem models are required to resolve the heterogeneous distribution of effects keywords eutrophication coastal ecosystems food webs macrobenthos aquatic birds ecological modelling 1 introduction over the past decade increasing evidence of significant and wide ranging alterations of coastal benthic communities and ecosystems has emerged sorte et al 2016 analysed long term changes in the abundance of the blue mussel mytilus edulis over a 40 year period between 1972 and 2014 in the gulf of maine usa and documented declines above 60 this decline in mussel biomass coincided with a shift in benthic community composition from a sessile community to a community dominated by algae and was seemingly attributable to a range of anthropogenic influences including climate change harvest eutrophication and introduction of non native species a large scale reduction in the biomass of benthic macrofauna in the danish waters over the last 20 years was recently demonstrated by riemann et al 2015 a reduction which took place in parallel to reductions in nutrient concentrations and primary productivity during the same period the abundance of benthos feeding waterbirds has declined significantly in many areas of the baltic sea skov et al 2011 bellebaum et al 2014 suggesting a link between oligotrophication and reduced populations of macrofauna and predators in north america many species of bivalve eating seaducks have declined dramatically in number in recent decades without apparent cause schamber et al 2009 literature related to nutrient loading abounds with studies identifying the effects of eutrophication and consequent changes in benthic animal populations along with other changes in different ecosystem pearson and rosenberg 1978 cloern 2001 bonsdorff et al 2002 helcom 2009 but studies which evaluate knock on effects on benthic food webs including higher trophic levels to these changes are lacking despite apparent parallel tendencies in eutrophication levels and population sizes of top predators waterbirds in some coastal areas a direct coupling between nutrients productivity and predators has not been documented empirically this is due to the fact that existing data on benthic in and epifauna does not meet the requirements of food web studies due to both the patchiness of invertebrate distribution and a poor spatial and temporal coverage of standard monitoring data adding to this the data on benthos is normally decoupled from the monitoring of water chemistry and surveys of waterbird abundance are undertaken at 10 year intervals making assessments on the status of food webs based solely on monitoring data an almost impossible task in this paper we therefore aimed at studying the level of synchronous spatio temporal trends in main components of the coastal food web by using an ecosystem model as supplement to the existing monitoring programs specifically we studied the coupling between fine scale benthic productivity and benthic feeding waterbirds and reconstructed the recent history of spatio temporal dynamics of nutrient concentrations primary productivity mussel growth and carrying capacity in relation to waterbird fitness by examining coupled spatio temporal trends in nutrient loads and the modelled phytoplankton growth bivalve biomass and waterbird fitness we quantified changes driven by reduction in the load of nutrients to higher trophic levels of the coastal ecosystem of the gulf of riga baltic sea 2 materials and methods 2 1 study area the study region was the gulf of riga in the north eastern part of the baltic sea and irbe strait which is the main connection between the gulf of riga and the baltic sea fig 1 the gulf of riga is shallow with a maximum depth of 60 m the catchment area is about ten times larger than the surface area of the gulf the main rivers discharging their waters to the gulf are daugava lielupe gauja and pärnu rivers the salinity patterns in the gulf of riga are characterised by a lack of a permanent halocline and high spatio temporal variability from 0 5 2 0 psu close to river mouths and adjacent surface water in spring and up to 7 5 7 7 psu at the bottom of the irbe strait in spring and summer ojaveer 1995 kotta et al 2008 during the summer season a strong thermocline separates the upper 15 c and deeper 6 c water layers surface water 0 10 m temperature exceeds 10 c from the third week of may until the end of september kotta et al 2008 the duration of long term mean ice cover in the north eastern gulf of riga is 132 days ojaveer 1995 the seafloor of the gulf of riga is very diverse in structure and characterised by mainly being a deposition area dominated by sandy or silty sediments but northern shores have also extensive boulder reefs the coastline of the gulf is mostly open and exposed in the eastern western and southern parts while a system of shallow enclosed bays with soft deposition areas dominates in the northern part winter nutrient concentrations in the coastal areas of the region have declined by 30 after 1990 oesterwind et al 2016 and hence the study of co variation in nutrients fauna and waterbirds was focused on the period between 1990 and 2007 bivalves dominate the macrozoobenthic communities of the gulf of riga with the most prevalent species being macoma baltica cerastoderma glaucum mya arenaria and mytilus edulis kotta et al 2008 the waterbird fauna is dominated by non breeding concentrations of bivalve feeding seaducks of which the long tailed duck clangula hyemalis and velvet scoter melanitta fusca are the most abundant durinck et al 1994 the seaducks occupy the shallower parts of the gulf during the period from november to may 2 2 ecological model complex the ecological model complex was calibrated against local measurements and consists of a coupled hydrodynamic and bio geochemical model mike 3 fm ecolab https www mikepoweredbydhi com products eco lab coupled to a waterbird energetics module at a spatial resolution of 1 to 5 km covering the 18 year period between 1990 and 2007 fig 2 the coupled hydrodynamic and bio geochemical model describes concentration of and processes related to phytoplankton nutrients n p si detritus and dissolved oxygen furthermore advanced descriptions of the benthic vegetation community and growth of mussel and clam populations are implemented including descriptions of growth and death processes the waterbird energetics module was set up to focus on long tailed duck and velvet scoter with the aim to estimate how changes in available supply of bivalves induced by changes in nutrient levels might affect upper trophic levels of the gulf of riga as reflected by the survival and body condition of the bird predators the model grid covered the whole depth gradient from the coast to the lower sublittoral the overall modelling approach and data flow from hydrodynamic to the bio energetic models applied is shown in fig 2 and table 1 gives an overview of the different data sources used for developing and calibrating the model complex the model complex has been designed as an integrated series of deterministic models in which physical chemical and biological processes controlling the scale and magnitude of the effects are built into the models based on equations for the conservation of mass and momentum and biological dose response relationships this modular end to end modelling approach is advantageous for quantitative and spatial studies as it allows for an assessment of the direct effects of eutrophication on benthic fauna and waterbirds as well as bottom up effects due to changes in the supply of food predicted by the ecological model e g changes in mussel biomass details of the parametrisation and calibration of the model complex can be found in the supplement 2 3 hydrodynamic model the hydrodynamic model is based on the baltic sea model developed by dhi fehy 2013 with a refined bathymetric grid in the gulf of riga the model is a three dimensional hydrodynamic model based on the mike 3 fm modelling system dhi 2014 the hydrodynamic model uses data listed in table 1 for model mesh bathymetry model initial and boundary conditions salinity temperature water level current model forcing atmospheric forcing river inflow and model calibration data mainly in situ temperature and salinity the concept of the model is that the coarse regional model of the entire baltic sea is extended with a detailed bathymetry of the gulf of riga this is possible due to the flexible mesh approach applied in fig 1 the local mesh part of the gulf of riga is shown the model is forced by meteorological data in the form of wind air pressure and temperature relative humidity clearness precipitation and ice coverage these data enter the continuity momentum temperature and turbulence equations of the model specifically in areas with ice the wind forcing and heat exchange terms are dampened the river inflow run off to the gulf of riga is distributed into daugava river 64 lielupe river 14 gauja salaca and pärnu rivers 6 each and kasari river 4 the location of the local rivers is shown in fig 3 2 4 ecological biogeochemical model the ecological biogeochemical model is based on the eco lab modelling system dhi 2014 the ecological biogeochemical model is coupled to the hydrodynamic model which together form the basis of the total model complex the ecological biogeochemical model consists of 100 state variables table 2 including the bio geochemical cycle of c n and p three phytoplankton groups diatoms cyanobacteria and flagellates eelgrass and three macroalgae and microphytobenthos groups the benthic fauna is included with population models of the suspension feeders mytilus sp and mya sp and the deposit suspension feeder macoma baltica furthermore the template includes a description of organic c n and p in the sediment the benthic fauna mussel mussel model is a population model with 2 state variables abundance no m2 and dry weight of soft tissue for each length class of mytilus mya sp and macoma baltica the mytilus mya sp population is described by 12 logarithmically increasing size classes ranging from 5 5 mm to 74 mm whereas macoma baltica population is described by 10 logarithmically increasing size classes ranging from 0 5 mm to 25 mm the spatially explicit population processes included in the model are i growth a function of food concentration temperature and oxygen ii starvation mortality iii predation mean rate by crabs fish and waterbirds iv spawning and v upward transfer of number of mussel and biomass to a higher size classes the net growth of mussels in each size class depends on food supply temperature and oxygen conditions in each grid cell biomass loss is modelled through a general predation crab fish birds a starvation mortality and through release of gametes a fraction of the released gametes enters the biomass of zooplankton the remaining biomass of the gametes enters the detritus pools recruitments of new mussels to size class 1 are described as spat fall to the bottom where the biomass is taken from zooplankton macoma spat settle on soft bottom mytilus mya sp spat settles on hard surfaces and mya on sandy to soft sediments the biogeochemical model includes a series of sediment state variables for which initial maps have to be generated by dividing the bottom into erosion transport and deposition bottoms depending on the yearly frequency of resuspension which is estimated from shear stress generated by currents and waves using the mike 3d flow model and 2d wave model mike sw using the equations formulated by soulsby and clarke 2005 and applied to the ecological model as a forcing function supported by monitoring data initial maps are defined based on frequency of resuspension and depth the suspension feeding mussels like macoma baltica are feeding on suspended organic matter and are especially relying on the availability of phytoplankton the edibility or quality of the food is determined by the c n p ratio to be able to simulate the food source the sediment pool of c n and p was split into an unconsolidated layer on the sediment surface and a consolidated layer below see fig 4 2 5 seaduck individual based model a spatially explicit individual based model ibm was setup focusing on long tailed duck and velvet scoter and their interactions with the modelled prey bivalves fig 5 the overall purpose of the individual based model is to estimate how changes in bivalve biomass might affect local carrying capacity of the study area for the analysed seaducks when looking at their survival and body condition an overview of the parameters used to setup and calibrate the seaduck ibm is given in table 1 while the particular parameter values and results of sensitivity tests are provided in table s4 in the supplement the ibm which was constructed using package morph as a platform stillman 2008 relates individual behaviours such as feeding activity rate of food intake or inter specific competition to environmental factors and food availability and provides detailed insight into aspects which constrain species fitness and numbers of birds using certain resources the ibm runs at discrete time steps of a fixed duration 1 hour space is represented by discrete patches with fixed location patches are defined as a variable grid with cells of 2 2 km in shallow waters and 4 4 km in waters deeper than 20 m fig 5 during each time step global events are processed first followed by patch events and then forager events the adaptive traits of individual seaducks are their location and diet selection during each time step seaducks select the patch diet combination which maximises their perceived fitness once the forager has selected a patch and diet the consequences of this decision are determined by true probability of survival foragers remember their foraging success during a defined number of previous time steps this memory is used to calculate average state variables over previous time steps the model does not allow foragers to know the future values of any state variables 2 6 determination of patterns of benthic productivity the model estimates provided us the areas of high bivalve biomass g c m2 concentrations of bivalves macoma baltica and mytilus edulis and high relative densities of waterbirds n km2 clangula hyemalis and melanitta fusca the bivalve biomass was expressed as modelled mean biomass during the period 1990 2007 relative densities of waterbirds were estimated using an arbitrary scale based on the simulation allowing 200 000 long tailed ducks and 120 000 velvet scoters into the model system these numbers reflect the population of wintering seaducks in the gulf of riga in 2001 skov et al 2011 2 7 analysis of spatio temporal trends in biomass of food web components in response to changes in eutrophication spatial patterns of long term trends in the food web components nutrients chl a baltic clams blue mussels long tailed duck and velvet scoter were analysed using spatially explicit trend tests theil 1950 sen 1968 hoaglin et al 2000 which allowed the size and significance of the trends 1990 2007 in each component i e nutrients bivalves and waterbirds to be estimated for each of the 3040 model grid nodes and spatially visualised to identify zones with similar increasing decreasing trends in order to quantify and compare the degree of co variation between food web components the weekly estimates were standardised to z scores which also removed the seasonal trends from the long term trend standardisation was done by subtracting the long term average from each weekly estimate and standardising the resulting value to z scores by dividing with the standard deviation kreyszig 1979 the deseasoning and trend analyses were calculated for each grid node the non parametric median trend test theil 1950 sen 1968 hoaglin et al 2000 was used to calculate the significance α 0 05 of the long term trend based on the z scores at each grid node the median trend test is a robust non parametric trend operator which is less sensitive to outliers than least squares estimators it is calculated by computing slopes of lines crossing all possible pairs of points when x coordinates differ after calculating these n n 1 2 slopes the median of them is taken as slope estimator next the intercepts of n lines crossing each point and having calculated slope are calculated the median from them is the estimated intercept the median trend test was applied using data from the entire 18 year time series deseasoning and median trend tests were undertaken in terrset ver 18 21 clark labs clark university 2016 2 8 coupling productivity to energetic conditions of higher trophic levels waterbirds based on analyses of the trends in bivalve biomass a series of simulations were undertaken using the waterbird energetics module the simulations estimated the body condition and annually added mortality of long tailed duck and velvet scoter in the gulf of riga given the predicted level of reduction in bivalve biomass in different parts of the region the relative body condition and mortality were estimated for 0 50 reduction increase in bivalve biomass using 2001 as a base year 3 results 3 1 areas of enhanced bivalve biomass and waterbird abundance for the period 1990 2007 areas of high biomass of blue mussels and baltic clams were estimated in the shallower northern parts of the gulf of riga with water depths below 20 m fig 6 blue mussels displayed a patchy distribution with peak mean biomass values estimated in a zone stretching over 40 km in the irbe strait the distribution area of the baltic clams was wider yet overlapping with that of the blue mussels peak biomass values of baltic clams were estimated in the irbe strait and between the islands saaremaa and hiumaa and the estonian mainland the modelled patterns of densities of long tailed duck and velvet scoter highly co varied with the biomass of blue mussels and baltic clams with almost all birds occurring in areas shallower than 20 m and with high densities off the coast in the northern part of the gulf due to density dependence the distribution of the waterbirds was more dispersed than that of the bivalves and the highest densities of waterbirds did not exactly coincide with small patches of maximum bivalve biomass fig 6 the most extensive aggregation of waterbirds was estimated in the irbe strait the predicted high density areas fitted the patterns recorded during waterbird surveys in 2006 2008 skov et al 2011 3 2 spatial variability in food web responses to changes in eutrophication the spatial pattern of the median trend tests for nutrients chl a bivalves and waterbirds reflected by the standardised z scores are displayed in fig 7 and p values of the tests for the biomass of mussels and clams are mapped in fig 8 the pattern of the standardised trend for nitrogen and phosphorous was clearly spatially variable indicating minor decrease in concentrations of both nutrients in the baltic proper and around the islands saaremaa and hiumaa and stronger decrease in concentrations in most parts of the gulf of riga except close to the coast in the northern part the patterns of trends of nitrogen and phosphorous did not fully coincide and the zone with high biomass of bivalves and densities of waterbirds coincided with decreasing concentrations of nitrogen but increasing concentrations of phosphorous the pattern of chl a trends was more complex and showed increasing trends in the southeastern part of the gulf and around the islands of saaremaa and hiumaa opposing to decreasing trends in the zone with high biomass of bivalves and densities of waterbirds off the estonian coast and in the irbe strait the pattern of the bivalves exhibited a high degree of similarity in the standardised trends although trends of mussels had the highest trend scores and thus indicating overall larger changes during the period bivalve trends were generally positive in the southeastern part of the gulf and in the baltic proper but negative in the rest of the modelled region a continuous area of negative trends for blue mussels was depicted in the whole north western part of the gulf inshore along the estonian mainland and in the irbe strait for baltic clams the largest area showing declining trends was found in the irbe strait and close inshore along saaremaa and the estonian mainland the spatio temporal trends in the biomass of blue mussels during the period 1990 2007 were significant in most part of the model grid except for the deeper part of the gulf of riga and the baltic proper median trend test p 0 05 fig 8 for baltic clams the area representing significant results median trend test p 0 05 was smaller in the gulf of riga as approximately 1 3 of the modelled part of the gulf had p values above 0 05 the standardised trends in the zone of modelled decline in blue mussels and the entire modelled region were strikingly different indicating heterogeneous responses within the region of the gulf of riga fig 9 within the zone nitrogen declined sharply after 1993 and seemingly continued to decline until 2008 whereas nitrogen concentrations in the entire region showed only a weak decline in the early 1990 es while phosphorous concentrations clearly declined within the zone after 2004 the general decline in the model region was weak no discernible difference in chl a trends was found between the zone of declining mussel biomass and the entire region although the concentrations of chl a varied much more within the zone the trends in blue mussels were very different inside the zone as compared to the entire region as no clear tendency in modelled biomass values could be determined in the whole region while the biomass declined continuously from 1993 to 2008 within the zone the decline within the zone between 1993 and 2008 reflected a decline in mean biomass of blue mussels of 50 standardised trends for baltic clams were much weaker than for blue mussels and negative z scores were only estimated within the zone after 2006 3 3 energetic impact of reduced carrying capacity on higher trophic levels waterbirds the results of the scenarios of energetic impact of reduced supply of bivalve biomass on waterbird fitness are shown in fig 10 the additive annual mortality of long tailed ducks during the baseline year of 2001 was estimated at 2 000 birds the estimated additive mortality of long tailed ducks would increase to 21 000 per year with a 20 decline in bivalve biomass compared to 2001 to 48 000 with a 40 decline and to 73 000 with a 50 decline the estimated additive mortality of velvet scoters was less dramatic and would be zero for 2001 and increase to 2 000 per year with a 40 decline in bivalve biomass compared to 2001 and to 10 000 with a 50 decline in bivalve biomass 4 discussion 4 1 covariance patterns of nutrients plankton benthos and waterbird dynamics to our knowledge this modelling study is the first to attempt to link reductions in eutrophication to changes in the entire food web from plankton to top predators of a coastal ecosystem the resulting spatio temporal trends reveal a number of characteristic responses in the coastal food webs which have added important new insight into the spatial dimensions of interactions between components of the food web and far reaching implications for the ecological management and monitoring practices applied commonplace in coastal areas our study region in the baltic sea may be seen as a typical example of an eutrophicated coastal ecosystem which during the investigated period between 1990 and 2007 has undergone significant changes in nutrient levels benthos and waterbirds which to a large extent have been driven by reductions in nutrient loads from land based sources kotta et al 2008 helcom 2009 skov et al 2011 perhaps the most striking result is the degree of fine scale covariance in the spatio temporal trends across the entire food web from nutrients to waterbirds the apparent spatial heterogeneity in the trends in nutrient concentrations in the region which were also documented by helcom 2009 and oesterwind et al 2016 showed that reductions were in fact limited to the areas within the less exposed area of the gulf of riga the obvious spatial heterogeneity in the modelled trends of clams and mussels indicated strong gradients in the trends of benthos biomass with a coherent area of declining biomass in the north western part of the gulf inshore along the estonian mainland and in the irbe strait the trends in this area contrasted to increasing trends in bivalve biomass found in the south eastern part of the gulf of riga and in the more exposed areas of the baltic proper as the area of declining bivalve biomass overlapped with the zone with the overall highest biomass of bivalves and highest densities of mussel feeding waterbirds the consequences of decreasing nutrient concentrations on the coastal food web would most likely be limited to this area as indicated by the lack of a general negative trend in bivalve biomass over the entire region we hypothesize that the fine scale covariance patterns are driven by the fine scale variability in hydrodynamics in the gulf of riga which creates strong gradients in current speed and direction and persistent patterns of residual currents fronts upwellings and eddies ojaveer and kalejs 1974 in the frontal zone of the irbe strait which is part of the primary zone impacted by eutrophication the correlation between concentrations of nitrogen and benthos biomass has been corroborated by empirical data kotta et al 2008 the spatial patterns of the trends found in this study provide an important supplement to field data due to patchy bottom sediments in the gulf of riga the fragmented nature of monitoring data and the temporal mismatch in the sampling of the different food web components the difference in the biomass of the bivalve species between the southern and the northern parts of the gulf has been confirmed empirically kotta et al 2008 more importantly the overall decline in nutrient supply to the gulf in the 1990 es and the subsequent decline in the biomass of blue mussels and baltic clams in coastal areas have also been verified empirically fig 11 suursaar 1995 kotta et al 2008 kotta et al 2009 the ecosystem model offers new possibilities such as identifying more precisely the spatial extent of areas affected by the reduction in eutrophication and quantifying the spatial effects of changed nutrient loading at higher trophic levels 4 2 impact of eutrophication control on food webs in coastal areas with the implementation of policies to control eutrophication such as the us clean water act craig 2009 and the eu water framework directive european commission 2019 the benthic productivity of many coastal areas is likely to shrink this modelling study has shown how a nutrient driven local scale decline in productivity over the course of less than 20 years can affect the entire food web including waterbirds in both north america and northern europe large scale declines of benthic feeding waterbirds have been observed over the past 15 years in the baltic sea declines above 30 have been documented for seven out of 20 species of waterbirds since 1993 and declines in bivalve feeding seaducks of 47 65 skov et al 2011 similar figures are available for seaduck populations in north america population size estimates based on aerial counts of breeding long tailed ducks in both alaska and canada s yukon territory in early 2000s were nearly 50 lower than estimates from the mid 1970s schamber et al 2009 although the coverage of monitoring data does not generally allow for detection of synchronous trends in nutrients and benthos data from inner danish waters show a significant decline in the biomass of filter feeding macrofauna over the last 20 years riemann et al 2015 based on the functional requirements for growth of both suspension feeding and deposit feeding bivalve populations it is obvious that a great potential for eutrophication induced effects on the available food supply to predatory fish and birds exists in many coastal areas however these effects of eutrophication control may differ between the different coastal regions and even within regions the response may show a diversity of trends lundberg 2005 thus conceptual models showing responses of food webs to nutrient enrichment in coastal areas may ideally represent a dome shaped response reflecting both the impoverished benthic conditions and hypoxia in enclosed areas with mixing constraints and positive linear relations between eutrophication and the growth of benthos stocks that have been found in more exposed areas cloern 2001 wolowicz et al 2006 the consequences of the unified efforts to control eutrophication on coastal food webs will soon become more apparent as mitigation measures and policies are implemented widely despite spatial variability in the response of zoobenthos and waterbird populations our study has highlighted the fact that population declines of bivalves in some areas may be approaching thresholds of the carrying capacity of several key waterbird species jeopardizing the sustainability of these waterbird populations in the region the predicted annual additive mortality of more than 70 000 long tailed ducks given current declines in the productivity of the north western part of the gulf of riga and the irbe strait may not be sustainable and may result in further declines in the region as the species is affected by other anthropogenic pressures including oil pollution habitat destruction and competition for food from the non indigenous round goby neogobius melanostomus nurkse et al 2016 at the same time it should be noted that the estimated survival and mortality rates of long tailed ducks assume no emigration of birds to other areas with higher carrying capacity thus the estimates may be seen as conservative although similar reductions of benthic productivity most likely have also taken place in other coastal areas of the baltic sea consequently the aims set in the us clean water act and the eu water framework directive to reduce eutrophication and in us and eu nature protection legislation for conservation of benthos feeding waterbirds e g the us migratory bird treaty act https www fws gov birds policies and regulations laws legislations migratory bird treaty act php the north american wetlands conservation act https www fws gov birds grants north american wetland conservation act php the eu birds directive eu bird directive 1979 and the eu habitats directive eu habitats directive 1992 may not both be achievable in all regions 4 3 management applications of fine scale ecosystem models this study demonstrates that fine scale ecosystem models enable quantifying spatial gradients in the changes of coastal ecosystems as such these models are an important supplement to monitoring activities in order to achieve a process based understanding of the functioning and status required for a successful management of specific areas like marine protected areas today fine scale ecosystem models are not used to pursue targets and measures for improving water quality and maintaining biodiversity in marine protected areas nor for assessing cost benefits or food web consequences of management decisions related to these sites one of the benefits of a deterministic ecosystem model complex like the one used in this study is the ability to test the impacts of a range of management scenarios in an attempt to resolve synergies and set mutual targets for water quality and biodiversity conservation as nutrient concentrations in coastal waters are declining new baseline conditions in eutrophication controlled coastal areas will appear the ecological requirements for simultaneously reaching good water quality and conserving biodiversity conservation vary spatially and depend on how much the flow of energy from benthos to predators is controlled by nutrient loading eutrophication synergies may not be achievable unless a spatially explicit understanding of processes underlying local food webs is developed the complementary use of empirical and modelling approaches to derive population community and ecosystem indicators is key to the development of operational food web indicators for ecosystem based management in the marine environment rombouts et al 2013 to accommodate the difficulty of integrating across so many levels of organisation however requires new information as well as new methods our high resolution application of an ecological model complex stresses the importance of designing bio geochemical models with high spatial resolution as a basis for making reliable predictions on energy fluxes in coastal areas with strong gradients in hydrodynamics as shown by the comparison of general trends in benthic productivity with trends in specific zones of the gulf of riga invalid interpretations regarding the ecological status could easily have been made if based on a large scale model authors contributions alm managed the study jk co ordinated the benthic monitoring tu undertook the hydrodynamic modelling ekr was responsible for the ecological biogeochemical model work rz was responsible for the waterbird individual based model and hs analysed the spatio temporal trends in the model data and led the writing of the manuscript credit author statement this is to certify that all authors have seen and approved the final version of the revised version of the manuscript the manuscript is original and it has not been published before or is under consideration for publication elsewhere declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the modelling work is based on the bonus bio c3 project and has received funding from bonus the joint baltic sea research and development programme art 185 funded jointly from the european union s seventh programme for research technological development and demonstration and from the danish and estonian research council in addition the work has been supported by institutional research funding iut02 20 of the estonian research council supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2020 109249 appendix supplementary materials image application 1 
24751,understanding natural mechanisms of maintaining diversity is a crucial pre requisite for successfully mitigating adverse effects of climate change such as the loss of diversity to make such an understanding possible both experiments and an effective continued monitoring of diversity are required recently spatial measures of plant diversity have greatly contributed to the quality of diversity monitoring in this article we first reviewed existing principles of nearest neighbour index construction and on this basis introduced a new spatially explicit size diversity index that is based on trigonometry i e the hyberbolic tangent index we discussed the index mathematical reasoning by explaining its relationship to individual based modelling and to other size diversity construction principles then we demonstrated the usefulness of the hyperbolic tangent index in indicating important interspecific relationships in mixed species forest ecosystems as part of studying the behaviour of the new size diversity construction principle we additionally found that there is a high correlation between the hyberbolic tangent index and absolute growth rates i e the index is suitable both as a diversity and a competition index finally a detailed correlation analysis in a norway spruce forest ecosystem with tree densities between 590 and 3800 trees per hectare made us understand that in most cases 7 10 neighbours are sufficient to consider when calculating the hyperbolic tangent index for explaining absolute growth rates when using the index as an indicator of plant diversity only smaller numbers of nearest neighbours may suffice the index is straightforward to apply even if the monitoring system used involves small circular sample plots keywords spatial size diversity indicator construction principles size diversity maintenance climate change individual based modelling mixed species woodlands trigonometry 1 introduction the analysis of plant species and size diversity offers great insight on the natural maintenance of biodiversity the ecological insurance hypothesis for example states that biodiversity promotes greater insurance when communities allow for some functional redundancy of species in favourable environmental conditions yachi and loreau 1999 matias et al 2013 and is directly related to the provision of ecosystem goods and services as well as to ecosystem resilience perry et al 2008 often different species populations of the same ecosystem have distinctively different size ranges leading to species size correlations wang et al 2020 pommerening et al 2020 much to our current concern ongoing climate change is decreasing biodiversity on earth at an unprecedented rate and effective monitoring of biodiversity is an essential pre requisite for mitigating adverse effects krebs 1999 magurran 2004 monitoring species diversity has a particularly long tradition gaston and spicer 2004 and the beginnings of measuring size diversity are much more recent ford 1975 weiner and solbrig 1984 where frequent semi synonyms of size diversity include size inequality and size dominance however recent research has shown that spatial species and size diversity are much related and should be studied simultaneously pommerening and uria diez 2017 wang et al 2020 pommerening et al 2020 the uptake of point process statistics in quantifying spatial diversity has considerably improved our ability to identify spatio temporal processes involved in the formation of plant diversity patterns and has contributed to a better understanding of the dynamics of plant diversity illian et al 2008 wiegand and moloney 2014 pommerening and grabarnik 2019 there are two main methods of constructing measures of spatial diversity nearest neighbour nn and second order methods with both approaches usually euclidean distance is used to define spatial scales and relationships but other distance definitions are also possible as part of the nearest neighbour approach first a local index value is calculated for each plant based on the information derived from every plant itself and its neighbourhood this index value describes the spatial diversity in the immediate vicinity of each individual i e in its local neighbourhood rajala and illian 2012 every plant within a given research plot acts once as subject or focus plant i in this local index the sizes of neighbouring plants need to be related to each other pommerening and grabarnik 2019 p 113 identified four principle methods i e size ratio size comparison size difference and size product for relating the sizes of subject plants and nearest neighbours the names of these methods are descriptors and give away the method in most cases basic mathematical operations are used to relate the size of neighbouring plants to each other such as dividing subtracting and multiplying in the case of size comparison an indicator function is used to return a value of one for all cases where subject tree i is larger than neighbour tree j and zero otherwise these scores are then summed over all neighbours j in a second step the local plant based indices are aggregated to produce summary characteristics for the whole plant community the objective of this work was to introduce and study a novel construction principle different from those used before in plant diversity monitoring that complements them and to apply this principle to a new nearest neighbour index i e the hyperbolic tangent index the construction of this index is based on trigonometric principles first we reviewed existing principles of quantifying size diversity and based on this brief review introduced the novel construction principle of the hyperbolic tangent index then we demonstrated the potential of the index to indicate different patterns of size dominance or size inequality in the context of mixed species woodlands finally we analysed how the new hyperbolic tangent index relates to tree growth rates and how the correlation depends on the number of nearest neighbours 2 materials and methods 2 1 existing measures of spatial size diversity an early measure of spatial size inequality in plants was the size differentiation index introduced by gadow 1993 as the mean of the ratio of smaller and larger plant sizes m of the k nearest neighbours subtracted from one eq 1 this index is based on the size ratio construction principle 1 t i 1 1 k j 1 k min m i m j max m i m j here m can be any quantifiable plant size measure e g biomass weight height stem diameter among others the value of ti increases with increasing average size difference between neighbouring trees t i 0 implies that neighbouring trees have equal size hui et al 1998 and aguirre et al 2003 proposed an index using the size comparison construction principle this method turns the continuous size variables into a binary problem the dominance index ui eq 2 is defined as the mean fraction of plants among the k nearest neighbours of a given plant i that are smaller than plant i 2 u i 1 k j 1 k 1 m i m j the indicator function returns 1 if the size mark of plant i exceeds that of neighbouring plant j otherwise 0 ui can have k 1 possible discrete outcomes based on the test function of the mark variogram pommerening et al 2011a introduced the mark variogram index this index is an example of the size difference construction principle 3 v i 1 2 k σ m 2 j 1 k m i m j 2 dividing by the size variance σ m 2 is a useful normalisation which eases the interpretation of index values and the comparison between different plants and plant communities the smaller vi the more similar the plant sizes considered are in this case either both plants are small or both plants are large no difference is made between these two scenarios finally inspired by the test function of the mark correlation function davies and pommerening 2008 introduced the size correlation index realising the size product construction principle this index compares the mean product of the sizes of a subject plant and its k nearest neighbours with the squared arithmetic mean size m 2 of all plants in a given community eq 4 4 c i m i j 1 k m j k m 2 values larger than 1 indicate positive correlation which can be the result of similar sized plants at close proximity whilst negative correlation indicated by ci 1 typically is the result of pairs of plants with large and very small sizes e g a dominant subject plant surrounded by smaller plants and pairs of plants with small sizes only 2 2 a new measure of spatial size diversity based on trigonometric principles in the context of individual based models ibm using interaction kernel functions for quantifying plant interaction schneider et al 2006 and adams et al 2011 suggested a hyperbolic function accounting for the sharing of resources of two plants i and j 5 f m i m j 1 tanh α lo g e m j m i ibms simulate populations and communities as being composed of discrete agents that represent individual organisms with sets of traits that vary among the agents following a strict bottom up approach pommerening and grabarnik 2019 p 217 in eq 5 mi and mj are again size variables of plant i and j plant i is the subject plant and plant j is a competitor or neighbour i e the function describes the resource loss incurred by the subject plant the main purpose of this function is to model the mode of interaction and parameter α introduces ecological symmetry α 0 or asymmetry α freckleton and watkinson 2001 function f mi mj increases the size dominance effect of plant j for mj mi and decreases size dominance of j otherwise in a comparative analysis of different interaction functions carried out by schneider et al 2006 the inclusion of eq 5 led to a marked reduction in the summed root squared error it was this use and the performance of f mi mj as a multiplier in spatial individual based modelling see also pommerening and grabarnik 2019 that inspired the idea to study this function in greater detail and to explore how it would perform in the context of monitoring size diversity based on the nearest neighbour principle hyperbolic functions are transcendental functions and are closely related to exponential functions the hyperbolic tangent function is denoted as tanh x and can be derived from hyperbolic sine and cosine functions as tanh x sinh x cosh x another possibility to express the hyperbolic function is through the exponential function i e tanh x e x e x e x e x e 2 x 1 e 2 x 1 for expressing size dominance of subject plant i and for constraining the index value si to the interval 0 1 it makes sense to swap indices i and j as in eq 6 we also discovered that this new variant of the hyperbolic tangent function can be expressed in terms of garcía s allotment function and also shares similarities with a function proposed earlier by adler garcía 2014 eq 4 in adler 1996 see appendix a 6 s i 1 2 k j 1 k 1 tanh α lo g e m i m j 1 k j 1 k m i 2 α m i 2 α m j 2 α 1 k j 1 k 1 1 m j m i 2 α factor 2 in the denominator of the first term before the sum symbol ensures that the index values lie between 0 and 1 see fig 1 the second term is based on garcía s allotment function garcía 2014 and offers an easier interpretation of the hyperbolic tangent index it shows that the index can be related to the size ratio principle however the ratio is more complex than the simple size ratio and involves power functions and sums in the simplest case of α 0 5 the plant sizes are raised to the power of 1 and as a consequence the second and third term of eq 6 further simplify to s i 1 k j 1 k m i m i m j 1 k j 1 k 1 1 m j m i however we prefer retaining the variability of the mode parameter α in order to be able to adjust the index to a wide range of different ecological situations in the analyses presented in this paper α 1 has proved to be a good assumption the larger the value calculated from eq 6 the larger the size dominance of plant i the arithmetic mean is a naïve estimator of the population hyperbolic tangent index but we recommend using the nn1 estimator instead eq 7 pommerening and stoyan 2006 7 s 1 λ i 1 n s i 1 d i s t i k c i f i in eq 7 distik is the distance between plant i and its kth nearest neighbour whilst ci is the distance between plant i and the nearest point on the boundary of the observation window the density estimator is calculated as λ i 1 n 1 d i s t i k c i f i and fi according to 8 f i a 2 d i s t i k b 2 d i s t i k for rectangular w r d i s t i k 2 π for circular w in eq 8 a and b are the sides of a rectangular observation window and r is the radius of a circular observation window for more detailed information probability density functions of si can be estimated based on the epanechnikov kernel see illian et al 2008 pommerening and grabarnik 2019 the estimation of the probability density function follows the same principle as the estimator in eq 7 as with any other spatial diversity index the hyperbolic tangent index and its probability density function can be estimated for whole plant communities regardless of species but also for individual species populations this is achieved by subsetting the point pattern according to species and by estimating the index for each species subset separately there is yet another way of considering spatial species and size diversity at the same time i e the interspecific case where subject plant i is of one species and the neighbours j are of another or in the case of many species simply are of species different from that of subject plant i this type of analysis is particularly useful when monitoring species interaction because the interspecific analysis clearly highlights the spatial interactions between the most abundant or competing species in a given plant ecosystem since interspecific diversity analyses are not often published and they are particularly useful for exploring the properties of the trigonometric construction principle we have applied them in this study in this paper we used trees and tree stem diameter a 1 3 m above ground level as example plants and size variable respectively however neither the trigonometric construction principle nor the hyperbolic tangent index is limited to plants with more or less single stems both can be applied to every plant with defined location coordinates such as the centre or the highest tip of a plant and quantifiable size attributes such as biomass or leaf area all calculations were carried out using our own r version 3 5 1 r development core team 2018 and image 1 code and the spatstat baddeley et al 2016 package 2 3 data manderscheid is a management demonstration plot 80 80 m situated in the west german federal state rhineland palatinate 50 11 n 6 8 e there are two species in this plot i e sessile oak quercus petraea matt intermingled with beech fagus sylvatica l this forest stand has been mainly managed for quality oak whilst beech was considered a minor by product helping to improve the quality of oak timber pommerening 2002 pommerening and uria diez 2017 if left to natural devices f sylvatica would dominate the site by supporting q petraea forest management also supports tree species diversity at the same time the södderich data are from the södderich a part of the göttinger wald near the city of göttingen in germany 51 57 n 10 08 e the research plot 80 65 m is dominated by beech fagus sylvatica l ash fraxinus excelsior l and sycamore acer pseudoplatanus l where for economic reasons the latter two species are favoured in forest management pommerening and uria diez 2017 naturally f sylvatica would also dominate this site and forest management therefore increases tree species diversity by removing f sylvatica trees norway spruce picea abies l karst spatio temporal data in 16 plots 30 40 m each at karlstift in austria 48 35 n 14 46 e with three re measurement were studied using the relationship between hyperbolic tangent index and absolute growth rate agr originally the plots were part of a replicated thinning experiment the trees have naturally regenerated and the plots are located at 930 m a s l with a mean annual temperature of 4 5 c and a mean annual precipitation of 950 mm the plots were established in 1964 in predominantly even aged p abies and re measured every five years until 2004 pommerening et al 2011b all trees with a minimum breast height diameter of 5 cm were included in the mapping at all three sites 3 results 3 1 applications of the hyperbolic index for indicating species size interactions the probability density functions for q petraea and f sylvatica in the manderscheid woodland clearly showed the contrasting behaviour of the two species fig 2 a here we applied the hyperbolic tangent index in such a way that for all q petraea subject trees the nearest k 4 neighbour trees were f sylvatica and the neighbours of all f sylvatica subject trees were in fact q petraea trees as described in section 2 2 as can be concluded from the probability density functions in fig 2a the population index values of this interspecific analysis were s 0 79 for q petraea and s 0 22 for f sylvatica rejecting the null hypothesis of size mark independence random labelling hypothesis pommerening and grabarnik 2019 p 183f the corresponding p values were 0 006 and 0 004 respectively i e both results are significant both the distributions and the population means indicate that q petraea trees dominate their f sylvatica neighbours in terms of size and most likely also in terms of resource exploitation in the context of the particular forest ecosystem at manderscheid this pattern stems from forest management where the economically more valuable and light demanding species q petraea is heavily promoted in thinnings on the expense of the economically less valuable shade tolerant species f sylvatica which would naturally dominate the site in practical terms competing f sylvatica trees close to q petraea trees were selectively removed q petraea would only regenerate naturally in such forest stands as a result of natural disturbances that interrupt the main forest canopy by creating gaps however q petraea seedlings and saplings would still face severe competition by f sylvatica since large specimens of q petraea provide many more micro habitats than those of f sylvatica this type of woodland management also promotes biodiversity in general still it is of interest to forest management here to maintain sub dominant f sylvatica trees as opposed to a pure stand of q petraea because the shade tolerant f sylvatica services q petraea by suppressing epicormic growth along the stem axes that would otherwise de value the oak timber a quite similar result is obtained from analysing the mixed species södderich woodland where one species is again f sylvatica that is analysed in relation to two other species f excelsior and a pseudoplatanus which are treated as one species group fig 2b like in the manderscheid woodland the f sylvatica trees are those that are dominated by other species in this case by f excelsior and a pseudoplatanus this interpretation is confirmed by the population index values which are s 0 73 for combined f excelsior and a pseudoplatanus and s 0 32 for f sylvatica the corresponding p values were 0 002 and 0 168 respectively apparently only the results for f excelsior and a pseudoplatanus are significant i e here the null hypothesis of size mark independence random labelling hypothesis pommerening and grabarnik 2019 p 183f can be rejected the population means are closer together than in the case of manderscheid and both si distributions are markedly more skewed in the södderich woodland this implies that the dominance separation between species is not as sharp as it is at manderscheid also at södderich the size dominance patterns are a result of selective near natural forest management that favours f excelsior and a pseudoplatanus at the expense of f sylvatica by removing any competitive f sylvatica tree in proximity to f excelsior and a pseudoplatanus trees the latter species would otherwise dominate and the former more light demanding species would not be able to coexist with such large abundances 3 2 hyperbolic tangent index and growth rates the hyperbolic tangent index si is correlated with both absolute and relative growth rates agr and rgr which is not a common property of spatially explicit size diversity indices we quantified agr and rgr as mean annual growth rates as defined in pommerening and muszta 2016 eq 7 and eq 9 for each plot we separately pooled the agr and rgr data over two survey periods 1994 1999 and 1999 2004 as well as the values of the hyperbolic tangent index measured in 1994 and 1999 in the data of the p abies time series at karlstift in austria we found a strong correlation between agr and si with an asymptotic pearson correlation coefficient between 0 5 and 0 9 there was also a linear relationship between rgr and si however in all 16 plots this was much weaker than the relationship with agr as an example we show the data for plot 42 in fig 3 in both cases the correlation is significant but the correlation coefficient is much higher for agr than for rgr when studying the correlation between hyperbolic tangent index and agr we were also interested in learning how the pearson correlation coefficient would change with increasing number of neighbours k again using the karlstift p abies time series data we calculated the pearson correlation coefficient for k 1 40 neighbours we deliberately used a very large upper number of k to be able to obtain reliable estimates of the upper asymptote of the relationship of interest to minimise edge effects periodic boundary conditions were applied in our simulations illian et al 2008 p 184 pommerening and grabarnik 2019 p 177 for most of the 16 plots there was an increasing correlation trend with increasing number of neighbours figs 4 and 5 particular for k 5 the results also revealed an asymptotic behaviour of correlation with increasing k in plots 11 23 33 and 41 the choice of k did not seem to matter much in most plots however the choice of k 7 10 appeared to be a reasonable compromise for avoiding low correlation coefficients due to small numbers of k in plots 11 13 33 41 and 43 the calculated correlation coefficients reach the asymptote estimated from the saturation model michelis menten 1913 particularly in plots 20 and 21 the correlation coefficients remain much below the asymptote also the shapes of the model trend lines markedly differ much from plot to plot for reasons that are not easy to understand we compiled the base characteristics of all 16 plots in table 1 to establish whether any of them could potentially explain the correlation patterns there was no characteristic however that particularly motivated the differences in the results of figs 4 and 5 interestingly the highest asymptotic correlation coefficients were often achieved in plots with high densities e g plots 10 12 20 30 and 42 the mean aggregation index by clark and evans 1954 ranged between tree locations that were completely randomly dispersed around 0 9 and 1 0 to very regular dispersal patterns 1 4 and 1 5 but did not help to explain the correlation patterns interestingly mean population hyperbolic tangent index s was always close to 0 50 which highlights that population values calculated regardless of species are not very informative they are of greater value in mixed species woodlands when calculated separately for each species as in section 3 1 and also the probability density distribution naturally offers more details than the simple population mean it was also interesting to see that the mean dbh coefficient of variation generally was very high indicating a high size diversity in all plots most likely as a result of planted p abies trees mixing with p abies trees that naturally colonised the plots but also as part of the quite different development stages captured in the data 4 discussion and conclusions our study has produced evidence that based on the nearest neighbour principle the trigonometric construction method indeed leads to a versatile spatial size diversity index the construction principle and corresponding index complement and extend the existing provision if spatially explicit size diversity measures our theoretical exposition in sections 2 1 2 2 and appendix a have highlighted that the new index uses a construction principle previously unknown i e the trigonometric construction principle this principle leads to a real valued index in contrast to the mark comparison construction principle in appendix a we have shown that this trigonometric construction principle is related to the size ratio principle however the ratio used in si is more complex because of the powers and sums involved eq 6 central term it is a particular strength of the hyperbolic tangent index to highlight size dominance differences between different species populations that occur in the same ecosystem this is particular helpful when managing ecosystems e g managing forest ecosystems for forestry purposes but also for conservation or recreation a very useful application of this index is the monitoring of invasive or endangered species for this purpose it is particularly helpful to consider the probability density distribution as summary characteristic fig 2 population characteristics summarising the size dominance situation in a single number such as s are only useful if computed separately for several species in a mixed species community in this context small numbers of nearest neighbours e g k 4 are sufficient the application of the hyperbolic tangent index is therefore likely to be a good indicator of spatial species and size diversity relationships pommerening and uria diez 2017 pommerening et al 2020 wang et al 2020 the hyperbolic tangent index can however additionally be used as a classic competition index with a view to explain and estimate relative and absolute growth rates the relationships involved are linear and particularly using agr as response variable can potentially lead to surprisingly large correlation coefficients this interesting outcome tells us that the hyperbolic tangent index is in fact a good descriptor of competition although the hyperbolic tangent function eq 5 was originally designed to model the mode of plant interaction complementing a kernel function that was supposed to quantify the strength of competition schneider et al 2006 this implies that in future ibm applications one has to be careful when combining hyperbolic tangent and kernel functions as both characteristics can compete with each other from a detailed correlation analysis we learned that the pearson correlation index often increases with increasing number of nearest neighbours k used for computing si applying k 7 10 neighbours should lead to reasonable correlations in forest ecosystems with a similar range of densities between 590 and 3800 trees per hectare we also tested an approach of spatially balanced k akin to the concept of spatially balanced sampling stevens and olsen 2004 grafström et al 2012 in analogy to their work we optimised k individually for each tree i so that the distance to the kth nearest neighbour was similar for all trees and approached the mean distances to the k 1 40 nearest neighbours this strategy made k dependent on local density so that k was large for trees situated at high local densities and small for trees in low local density situations although this method successfully decreased the variance of distances to the k nearest neighbours unfortunately the correlation coefficients did not improve compared to the results obtained from using fixed k instead results not shown this negative outcome confirmed that with a wide range of tree densities between 590 and 3800 trees per hectare it is indeed sufficient to apply k 7 10 neighbours as fixed k for all trees when calculating the hyperbolic tangent index for explaining absolute growth rates apparently the hyperbolic tangent index is suitable for basic agr estimations based on simple nearest neighbour information this study has defined a new versatile and meaningful construction principle for spatial size diversity indices that should prove useful in many situations where spatial size diversity needs to be monitored alongside spatial species diversity the hyperbolic tangent index can also be applied to small circular monitoring plots however in the spirit of plus sampling it is recommended to include any off plot nearest neighbours in the analyses as well see pommerening and grabarnik 2019 p 175ff to avoid edge bias effects rather than using the nn1 estimator in this case author contributions a p designed and tested the new spatial size diversity index programmed the required r and image 2 code and analysed the data a p j s and g z interpreted and discussed the results all authors contributed to the text declaration of competing interest none acknowledgements the authors thank oscar garcía dasometrics formerly university of northern british columbia for an interesting and inspiring discussion about the hyperbolic tangent index he contributed valuable conceptual ideas markus neumann austrian federal research and training centre for forests natural hazards and landscape vienna austria kindly provided the karlstift p abies time series data to this study for which the authors are very grateful g z s research visit to umeå was funded by the fundamental research funds for the central non profit research institution of the chinese academy of forestry project number cafybb2019gc001 2 appendix a in this appendix we explain the relationship between schneider s hyperbolic tangent function schneider et al 2006 adams et al 2011 and garcía s allotment function garcía 2014 schneider s original hyperbolic function can be written as a1 1 tanh α lo g e m j lo g e m i 1 tanh α lo g e m j α m i α based on the tanh definition tanh x e x e x e x e x e 2 x 1 e 2 x 1 we can conclude 1 1 1 tanh x 1 e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x 2 e x e x e x that a2 1 tanh x 2 e x e x 1 e x eq a2 allows us now to substitute the second term of eq a1 by a3 2 m j α m i α m j α m i α m i α m j α finally multiplying numerator and denominator by m j α m i α we obtain a4 2 m j 2 α m j 2 α m i 2 α 
24751,understanding natural mechanisms of maintaining diversity is a crucial pre requisite for successfully mitigating adverse effects of climate change such as the loss of diversity to make such an understanding possible both experiments and an effective continued monitoring of diversity are required recently spatial measures of plant diversity have greatly contributed to the quality of diversity monitoring in this article we first reviewed existing principles of nearest neighbour index construction and on this basis introduced a new spatially explicit size diversity index that is based on trigonometry i e the hyberbolic tangent index we discussed the index mathematical reasoning by explaining its relationship to individual based modelling and to other size diversity construction principles then we demonstrated the usefulness of the hyperbolic tangent index in indicating important interspecific relationships in mixed species forest ecosystems as part of studying the behaviour of the new size diversity construction principle we additionally found that there is a high correlation between the hyberbolic tangent index and absolute growth rates i e the index is suitable both as a diversity and a competition index finally a detailed correlation analysis in a norway spruce forest ecosystem with tree densities between 590 and 3800 trees per hectare made us understand that in most cases 7 10 neighbours are sufficient to consider when calculating the hyperbolic tangent index for explaining absolute growth rates when using the index as an indicator of plant diversity only smaller numbers of nearest neighbours may suffice the index is straightforward to apply even if the monitoring system used involves small circular sample plots keywords spatial size diversity indicator construction principles size diversity maintenance climate change individual based modelling mixed species woodlands trigonometry 1 introduction the analysis of plant species and size diversity offers great insight on the natural maintenance of biodiversity the ecological insurance hypothesis for example states that biodiversity promotes greater insurance when communities allow for some functional redundancy of species in favourable environmental conditions yachi and loreau 1999 matias et al 2013 and is directly related to the provision of ecosystem goods and services as well as to ecosystem resilience perry et al 2008 often different species populations of the same ecosystem have distinctively different size ranges leading to species size correlations wang et al 2020 pommerening et al 2020 much to our current concern ongoing climate change is decreasing biodiversity on earth at an unprecedented rate and effective monitoring of biodiversity is an essential pre requisite for mitigating adverse effects krebs 1999 magurran 2004 monitoring species diversity has a particularly long tradition gaston and spicer 2004 and the beginnings of measuring size diversity are much more recent ford 1975 weiner and solbrig 1984 where frequent semi synonyms of size diversity include size inequality and size dominance however recent research has shown that spatial species and size diversity are much related and should be studied simultaneously pommerening and uria diez 2017 wang et al 2020 pommerening et al 2020 the uptake of point process statistics in quantifying spatial diversity has considerably improved our ability to identify spatio temporal processes involved in the formation of plant diversity patterns and has contributed to a better understanding of the dynamics of plant diversity illian et al 2008 wiegand and moloney 2014 pommerening and grabarnik 2019 there are two main methods of constructing measures of spatial diversity nearest neighbour nn and second order methods with both approaches usually euclidean distance is used to define spatial scales and relationships but other distance definitions are also possible as part of the nearest neighbour approach first a local index value is calculated for each plant based on the information derived from every plant itself and its neighbourhood this index value describes the spatial diversity in the immediate vicinity of each individual i e in its local neighbourhood rajala and illian 2012 every plant within a given research plot acts once as subject or focus plant i in this local index the sizes of neighbouring plants need to be related to each other pommerening and grabarnik 2019 p 113 identified four principle methods i e size ratio size comparison size difference and size product for relating the sizes of subject plants and nearest neighbours the names of these methods are descriptors and give away the method in most cases basic mathematical operations are used to relate the size of neighbouring plants to each other such as dividing subtracting and multiplying in the case of size comparison an indicator function is used to return a value of one for all cases where subject tree i is larger than neighbour tree j and zero otherwise these scores are then summed over all neighbours j in a second step the local plant based indices are aggregated to produce summary characteristics for the whole plant community the objective of this work was to introduce and study a novel construction principle different from those used before in plant diversity monitoring that complements them and to apply this principle to a new nearest neighbour index i e the hyperbolic tangent index the construction of this index is based on trigonometric principles first we reviewed existing principles of quantifying size diversity and based on this brief review introduced the novel construction principle of the hyperbolic tangent index then we demonstrated the potential of the index to indicate different patterns of size dominance or size inequality in the context of mixed species woodlands finally we analysed how the new hyperbolic tangent index relates to tree growth rates and how the correlation depends on the number of nearest neighbours 2 materials and methods 2 1 existing measures of spatial size diversity an early measure of spatial size inequality in plants was the size differentiation index introduced by gadow 1993 as the mean of the ratio of smaller and larger plant sizes m of the k nearest neighbours subtracted from one eq 1 this index is based on the size ratio construction principle 1 t i 1 1 k j 1 k min m i m j max m i m j here m can be any quantifiable plant size measure e g biomass weight height stem diameter among others the value of ti increases with increasing average size difference between neighbouring trees t i 0 implies that neighbouring trees have equal size hui et al 1998 and aguirre et al 2003 proposed an index using the size comparison construction principle this method turns the continuous size variables into a binary problem the dominance index ui eq 2 is defined as the mean fraction of plants among the k nearest neighbours of a given plant i that are smaller than plant i 2 u i 1 k j 1 k 1 m i m j the indicator function returns 1 if the size mark of plant i exceeds that of neighbouring plant j otherwise 0 ui can have k 1 possible discrete outcomes based on the test function of the mark variogram pommerening et al 2011a introduced the mark variogram index this index is an example of the size difference construction principle 3 v i 1 2 k σ m 2 j 1 k m i m j 2 dividing by the size variance σ m 2 is a useful normalisation which eases the interpretation of index values and the comparison between different plants and plant communities the smaller vi the more similar the plant sizes considered are in this case either both plants are small or both plants are large no difference is made between these two scenarios finally inspired by the test function of the mark correlation function davies and pommerening 2008 introduced the size correlation index realising the size product construction principle this index compares the mean product of the sizes of a subject plant and its k nearest neighbours with the squared arithmetic mean size m 2 of all plants in a given community eq 4 4 c i m i j 1 k m j k m 2 values larger than 1 indicate positive correlation which can be the result of similar sized plants at close proximity whilst negative correlation indicated by ci 1 typically is the result of pairs of plants with large and very small sizes e g a dominant subject plant surrounded by smaller plants and pairs of plants with small sizes only 2 2 a new measure of spatial size diversity based on trigonometric principles in the context of individual based models ibm using interaction kernel functions for quantifying plant interaction schneider et al 2006 and adams et al 2011 suggested a hyperbolic function accounting for the sharing of resources of two plants i and j 5 f m i m j 1 tanh α lo g e m j m i ibms simulate populations and communities as being composed of discrete agents that represent individual organisms with sets of traits that vary among the agents following a strict bottom up approach pommerening and grabarnik 2019 p 217 in eq 5 mi and mj are again size variables of plant i and j plant i is the subject plant and plant j is a competitor or neighbour i e the function describes the resource loss incurred by the subject plant the main purpose of this function is to model the mode of interaction and parameter α introduces ecological symmetry α 0 or asymmetry α freckleton and watkinson 2001 function f mi mj increases the size dominance effect of plant j for mj mi and decreases size dominance of j otherwise in a comparative analysis of different interaction functions carried out by schneider et al 2006 the inclusion of eq 5 led to a marked reduction in the summed root squared error it was this use and the performance of f mi mj as a multiplier in spatial individual based modelling see also pommerening and grabarnik 2019 that inspired the idea to study this function in greater detail and to explore how it would perform in the context of monitoring size diversity based on the nearest neighbour principle hyperbolic functions are transcendental functions and are closely related to exponential functions the hyperbolic tangent function is denoted as tanh x and can be derived from hyperbolic sine and cosine functions as tanh x sinh x cosh x another possibility to express the hyperbolic function is through the exponential function i e tanh x e x e x e x e x e 2 x 1 e 2 x 1 for expressing size dominance of subject plant i and for constraining the index value si to the interval 0 1 it makes sense to swap indices i and j as in eq 6 we also discovered that this new variant of the hyperbolic tangent function can be expressed in terms of garcía s allotment function and also shares similarities with a function proposed earlier by adler garcía 2014 eq 4 in adler 1996 see appendix a 6 s i 1 2 k j 1 k 1 tanh α lo g e m i m j 1 k j 1 k m i 2 α m i 2 α m j 2 α 1 k j 1 k 1 1 m j m i 2 α factor 2 in the denominator of the first term before the sum symbol ensures that the index values lie between 0 and 1 see fig 1 the second term is based on garcía s allotment function garcía 2014 and offers an easier interpretation of the hyperbolic tangent index it shows that the index can be related to the size ratio principle however the ratio is more complex than the simple size ratio and involves power functions and sums in the simplest case of α 0 5 the plant sizes are raised to the power of 1 and as a consequence the second and third term of eq 6 further simplify to s i 1 k j 1 k m i m i m j 1 k j 1 k 1 1 m j m i however we prefer retaining the variability of the mode parameter α in order to be able to adjust the index to a wide range of different ecological situations in the analyses presented in this paper α 1 has proved to be a good assumption the larger the value calculated from eq 6 the larger the size dominance of plant i the arithmetic mean is a naïve estimator of the population hyperbolic tangent index but we recommend using the nn1 estimator instead eq 7 pommerening and stoyan 2006 7 s 1 λ i 1 n s i 1 d i s t i k c i f i in eq 7 distik is the distance between plant i and its kth nearest neighbour whilst ci is the distance between plant i and the nearest point on the boundary of the observation window the density estimator is calculated as λ i 1 n 1 d i s t i k c i f i and fi according to 8 f i a 2 d i s t i k b 2 d i s t i k for rectangular w r d i s t i k 2 π for circular w in eq 8 a and b are the sides of a rectangular observation window and r is the radius of a circular observation window for more detailed information probability density functions of si can be estimated based on the epanechnikov kernel see illian et al 2008 pommerening and grabarnik 2019 the estimation of the probability density function follows the same principle as the estimator in eq 7 as with any other spatial diversity index the hyperbolic tangent index and its probability density function can be estimated for whole plant communities regardless of species but also for individual species populations this is achieved by subsetting the point pattern according to species and by estimating the index for each species subset separately there is yet another way of considering spatial species and size diversity at the same time i e the interspecific case where subject plant i is of one species and the neighbours j are of another or in the case of many species simply are of species different from that of subject plant i this type of analysis is particularly useful when monitoring species interaction because the interspecific analysis clearly highlights the spatial interactions between the most abundant or competing species in a given plant ecosystem since interspecific diversity analyses are not often published and they are particularly useful for exploring the properties of the trigonometric construction principle we have applied them in this study in this paper we used trees and tree stem diameter a 1 3 m above ground level as example plants and size variable respectively however neither the trigonometric construction principle nor the hyperbolic tangent index is limited to plants with more or less single stems both can be applied to every plant with defined location coordinates such as the centre or the highest tip of a plant and quantifiable size attributes such as biomass or leaf area all calculations were carried out using our own r version 3 5 1 r development core team 2018 and image 1 code and the spatstat baddeley et al 2016 package 2 3 data manderscheid is a management demonstration plot 80 80 m situated in the west german federal state rhineland palatinate 50 11 n 6 8 e there are two species in this plot i e sessile oak quercus petraea matt intermingled with beech fagus sylvatica l this forest stand has been mainly managed for quality oak whilst beech was considered a minor by product helping to improve the quality of oak timber pommerening 2002 pommerening and uria diez 2017 if left to natural devices f sylvatica would dominate the site by supporting q petraea forest management also supports tree species diversity at the same time the södderich data are from the södderich a part of the göttinger wald near the city of göttingen in germany 51 57 n 10 08 e the research plot 80 65 m is dominated by beech fagus sylvatica l ash fraxinus excelsior l and sycamore acer pseudoplatanus l where for economic reasons the latter two species are favoured in forest management pommerening and uria diez 2017 naturally f sylvatica would also dominate this site and forest management therefore increases tree species diversity by removing f sylvatica trees norway spruce picea abies l karst spatio temporal data in 16 plots 30 40 m each at karlstift in austria 48 35 n 14 46 e with three re measurement were studied using the relationship between hyperbolic tangent index and absolute growth rate agr originally the plots were part of a replicated thinning experiment the trees have naturally regenerated and the plots are located at 930 m a s l with a mean annual temperature of 4 5 c and a mean annual precipitation of 950 mm the plots were established in 1964 in predominantly even aged p abies and re measured every five years until 2004 pommerening et al 2011b all trees with a minimum breast height diameter of 5 cm were included in the mapping at all three sites 3 results 3 1 applications of the hyperbolic index for indicating species size interactions the probability density functions for q petraea and f sylvatica in the manderscheid woodland clearly showed the contrasting behaviour of the two species fig 2 a here we applied the hyperbolic tangent index in such a way that for all q petraea subject trees the nearest k 4 neighbour trees were f sylvatica and the neighbours of all f sylvatica subject trees were in fact q petraea trees as described in section 2 2 as can be concluded from the probability density functions in fig 2a the population index values of this interspecific analysis were s 0 79 for q petraea and s 0 22 for f sylvatica rejecting the null hypothesis of size mark independence random labelling hypothesis pommerening and grabarnik 2019 p 183f the corresponding p values were 0 006 and 0 004 respectively i e both results are significant both the distributions and the population means indicate that q petraea trees dominate their f sylvatica neighbours in terms of size and most likely also in terms of resource exploitation in the context of the particular forest ecosystem at manderscheid this pattern stems from forest management where the economically more valuable and light demanding species q petraea is heavily promoted in thinnings on the expense of the economically less valuable shade tolerant species f sylvatica which would naturally dominate the site in practical terms competing f sylvatica trees close to q petraea trees were selectively removed q petraea would only regenerate naturally in such forest stands as a result of natural disturbances that interrupt the main forest canopy by creating gaps however q petraea seedlings and saplings would still face severe competition by f sylvatica since large specimens of q petraea provide many more micro habitats than those of f sylvatica this type of woodland management also promotes biodiversity in general still it is of interest to forest management here to maintain sub dominant f sylvatica trees as opposed to a pure stand of q petraea because the shade tolerant f sylvatica services q petraea by suppressing epicormic growth along the stem axes that would otherwise de value the oak timber a quite similar result is obtained from analysing the mixed species södderich woodland where one species is again f sylvatica that is analysed in relation to two other species f excelsior and a pseudoplatanus which are treated as one species group fig 2b like in the manderscheid woodland the f sylvatica trees are those that are dominated by other species in this case by f excelsior and a pseudoplatanus this interpretation is confirmed by the population index values which are s 0 73 for combined f excelsior and a pseudoplatanus and s 0 32 for f sylvatica the corresponding p values were 0 002 and 0 168 respectively apparently only the results for f excelsior and a pseudoplatanus are significant i e here the null hypothesis of size mark independence random labelling hypothesis pommerening and grabarnik 2019 p 183f can be rejected the population means are closer together than in the case of manderscheid and both si distributions are markedly more skewed in the södderich woodland this implies that the dominance separation between species is not as sharp as it is at manderscheid also at södderich the size dominance patterns are a result of selective near natural forest management that favours f excelsior and a pseudoplatanus at the expense of f sylvatica by removing any competitive f sylvatica tree in proximity to f excelsior and a pseudoplatanus trees the latter species would otherwise dominate and the former more light demanding species would not be able to coexist with such large abundances 3 2 hyperbolic tangent index and growth rates the hyperbolic tangent index si is correlated with both absolute and relative growth rates agr and rgr which is not a common property of spatially explicit size diversity indices we quantified agr and rgr as mean annual growth rates as defined in pommerening and muszta 2016 eq 7 and eq 9 for each plot we separately pooled the agr and rgr data over two survey periods 1994 1999 and 1999 2004 as well as the values of the hyperbolic tangent index measured in 1994 and 1999 in the data of the p abies time series at karlstift in austria we found a strong correlation between agr and si with an asymptotic pearson correlation coefficient between 0 5 and 0 9 there was also a linear relationship between rgr and si however in all 16 plots this was much weaker than the relationship with agr as an example we show the data for plot 42 in fig 3 in both cases the correlation is significant but the correlation coefficient is much higher for agr than for rgr when studying the correlation between hyperbolic tangent index and agr we were also interested in learning how the pearson correlation coefficient would change with increasing number of neighbours k again using the karlstift p abies time series data we calculated the pearson correlation coefficient for k 1 40 neighbours we deliberately used a very large upper number of k to be able to obtain reliable estimates of the upper asymptote of the relationship of interest to minimise edge effects periodic boundary conditions were applied in our simulations illian et al 2008 p 184 pommerening and grabarnik 2019 p 177 for most of the 16 plots there was an increasing correlation trend with increasing number of neighbours figs 4 and 5 particular for k 5 the results also revealed an asymptotic behaviour of correlation with increasing k in plots 11 23 33 and 41 the choice of k did not seem to matter much in most plots however the choice of k 7 10 appeared to be a reasonable compromise for avoiding low correlation coefficients due to small numbers of k in plots 11 13 33 41 and 43 the calculated correlation coefficients reach the asymptote estimated from the saturation model michelis menten 1913 particularly in plots 20 and 21 the correlation coefficients remain much below the asymptote also the shapes of the model trend lines markedly differ much from plot to plot for reasons that are not easy to understand we compiled the base characteristics of all 16 plots in table 1 to establish whether any of them could potentially explain the correlation patterns there was no characteristic however that particularly motivated the differences in the results of figs 4 and 5 interestingly the highest asymptotic correlation coefficients were often achieved in plots with high densities e g plots 10 12 20 30 and 42 the mean aggregation index by clark and evans 1954 ranged between tree locations that were completely randomly dispersed around 0 9 and 1 0 to very regular dispersal patterns 1 4 and 1 5 but did not help to explain the correlation patterns interestingly mean population hyperbolic tangent index s was always close to 0 50 which highlights that population values calculated regardless of species are not very informative they are of greater value in mixed species woodlands when calculated separately for each species as in section 3 1 and also the probability density distribution naturally offers more details than the simple population mean it was also interesting to see that the mean dbh coefficient of variation generally was very high indicating a high size diversity in all plots most likely as a result of planted p abies trees mixing with p abies trees that naturally colonised the plots but also as part of the quite different development stages captured in the data 4 discussion and conclusions our study has produced evidence that based on the nearest neighbour principle the trigonometric construction method indeed leads to a versatile spatial size diversity index the construction principle and corresponding index complement and extend the existing provision if spatially explicit size diversity measures our theoretical exposition in sections 2 1 2 2 and appendix a have highlighted that the new index uses a construction principle previously unknown i e the trigonometric construction principle this principle leads to a real valued index in contrast to the mark comparison construction principle in appendix a we have shown that this trigonometric construction principle is related to the size ratio principle however the ratio used in si is more complex because of the powers and sums involved eq 6 central term it is a particular strength of the hyperbolic tangent index to highlight size dominance differences between different species populations that occur in the same ecosystem this is particular helpful when managing ecosystems e g managing forest ecosystems for forestry purposes but also for conservation or recreation a very useful application of this index is the monitoring of invasive or endangered species for this purpose it is particularly helpful to consider the probability density distribution as summary characteristic fig 2 population characteristics summarising the size dominance situation in a single number such as s are only useful if computed separately for several species in a mixed species community in this context small numbers of nearest neighbours e g k 4 are sufficient the application of the hyperbolic tangent index is therefore likely to be a good indicator of spatial species and size diversity relationships pommerening and uria diez 2017 pommerening et al 2020 wang et al 2020 the hyperbolic tangent index can however additionally be used as a classic competition index with a view to explain and estimate relative and absolute growth rates the relationships involved are linear and particularly using agr as response variable can potentially lead to surprisingly large correlation coefficients this interesting outcome tells us that the hyperbolic tangent index is in fact a good descriptor of competition although the hyperbolic tangent function eq 5 was originally designed to model the mode of plant interaction complementing a kernel function that was supposed to quantify the strength of competition schneider et al 2006 this implies that in future ibm applications one has to be careful when combining hyperbolic tangent and kernel functions as both characteristics can compete with each other from a detailed correlation analysis we learned that the pearson correlation index often increases with increasing number of nearest neighbours k used for computing si applying k 7 10 neighbours should lead to reasonable correlations in forest ecosystems with a similar range of densities between 590 and 3800 trees per hectare we also tested an approach of spatially balanced k akin to the concept of spatially balanced sampling stevens and olsen 2004 grafström et al 2012 in analogy to their work we optimised k individually for each tree i so that the distance to the kth nearest neighbour was similar for all trees and approached the mean distances to the k 1 40 nearest neighbours this strategy made k dependent on local density so that k was large for trees situated at high local densities and small for trees in low local density situations although this method successfully decreased the variance of distances to the k nearest neighbours unfortunately the correlation coefficients did not improve compared to the results obtained from using fixed k instead results not shown this negative outcome confirmed that with a wide range of tree densities between 590 and 3800 trees per hectare it is indeed sufficient to apply k 7 10 neighbours as fixed k for all trees when calculating the hyperbolic tangent index for explaining absolute growth rates apparently the hyperbolic tangent index is suitable for basic agr estimations based on simple nearest neighbour information this study has defined a new versatile and meaningful construction principle for spatial size diversity indices that should prove useful in many situations where spatial size diversity needs to be monitored alongside spatial species diversity the hyperbolic tangent index can also be applied to small circular monitoring plots however in the spirit of plus sampling it is recommended to include any off plot nearest neighbours in the analyses as well see pommerening and grabarnik 2019 p 175ff to avoid edge bias effects rather than using the nn1 estimator in this case author contributions a p designed and tested the new spatial size diversity index programmed the required r and image 2 code and analysed the data a p j s and g z interpreted and discussed the results all authors contributed to the text declaration of competing interest none acknowledgements the authors thank oscar garcía dasometrics formerly university of northern british columbia for an interesting and inspiring discussion about the hyperbolic tangent index he contributed valuable conceptual ideas markus neumann austrian federal research and training centre for forests natural hazards and landscape vienna austria kindly provided the karlstift p abies time series data to this study for which the authors are very grateful g z s research visit to umeå was funded by the fundamental research funds for the central non profit research institution of the chinese academy of forestry project number cafybb2019gc001 2 appendix a in this appendix we explain the relationship between schneider s hyperbolic tangent function schneider et al 2006 adams et al 2011 and garcía s allotment function garcía 2014 schneider s original hyperbolic function can be written as a1 1 tanh α lo g e m j lo g e m i 1 tanh α lo g e m j α m i α based on the tanh definition tanh x e x e x e x e x e 2 x 1 e 2 x 1 we can conclude 1 1 1 tanh x 1 e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x e x 2 e x e x e x that a2 1 tanh x 2 e x e x 1 e x eq a2 allows us now to substitute the second term of eq a1 by a3 2 m j α m i α m j α m i α m i α m j α finally multiplying numerator and denominator by m j α m i α we obtain a4 2 m j 2 α m j 2 α m i 2 α 
24752,natural resource management has long recognised that the multi objective nature of management is important but has struggled to operationalise this into quantitative measurable objectives for functional use in management operationalising broader ecological and social objectives has been particularly problematic in fisheries management the focus has mainly been on target species sustainability and in the past few decades on profitability however multi objective management is now essential as fisheries have become recognised as complex social ecological systems policy and legislation demand a move towards quantitative approaches for reconciling multiple objectives and operationalising these within harvest strategies we present a quantitative non commensurable unit approach via a multi indicator value function with explicit objective preference weights we use a simulation to set total allowable catches tacs for three main species groups in a reef line fishery in australia s great barrier reef our method enables stakeholders to consider a richer range of tradeoffs than is possible with bio economic models moreover it allows the formal evaluation of performance across alternative stakeholder group preferences providing an impartial way to obtain an overall optimum tac the simulation requires extensive fishery data and requires the performance indicators associated with each objective to be quantitatively and defensibly defined thus our approach provides a pathway forward that forces managers and stakeholders to confront the associated data requirements keywords triple bottom line harvest strategy development reef line fishery stakeholder preference weightings multi objective trade offs simulation 1 introduction maintaining healthy ecosystems and healthy human communities that depend on them is increasingly recognised as important to natural resource management including fisheries asche et al 2018 berkes 2000 charles 1995 de young 2008 fao 2009 marshall et al 2017 voss et al 2014 elkington 1998 conceived the triple bottom line tbl encompassing economic ecological and social objectives as a tool for influencing a single decision maker to explicitly value non financial objectives by optimising over the three different objectives halpern et al 2013 note that maximising conservation goals and achieving equity in social outcomes while minimising overall costs is the ideal tbl outcome in a fisheries context stephenson et al 2017 proposed four pillars of sustainability that include institutional aspects in addition to economical ecological and social pillars pascoe et al 2013b also considered institutional or managerial objectives of simplifying and improving management structures in fisheries several jurisdictions have legislated the consideration of multiple objectives for example the united states magnuson stevens fishery conservation and management act 1996 mandates consideration of economic and social outcomes in addition to environmental outcomes in national standard 8 in australia the fisheries management act 1991 requires the effective integration of long term and short term economic environmental social and equity considerations into policy development for commonwealth managed fisheries department of agriculture and water resources 2018 while the productivity commission inquiry into marine fisheries and aquaculture also reinforced the need to include social economic and environmental considerations into fisheries policy and management productivity commission 2016 concurrent with the recognition of the need to include multiple objectives into fisheries management has been the increased development and adoption of harvest strategies to assist in management decision making harvest strategies comprise pre agreed monitoring and performance indicators usually obtained from a stock assessment and decision or harvest control rules invoked in response to the assessment that are collectively used to control fishing mortality on the target species butterworth and punt 2003 punt et al 2002 sainsbury et al 2000 in fisheries management harvest strategies are used for tactical fisheries management to set control variables such as the total allowable catch tac or limit recreational catch through daily bag limits per person garcia et al 2003 concomitant with the development of harvest strategies has been the development of quantitative tools to assess potential harvest strategies in particular management strategy evaluation mse has developed as a formalised approach to pre test different harvest strategies via simulation before their implementation punt et al 2016 smith 1994 smith et al 1999 although the recognition of the importance of consideration of tbl and in some cases the extended fourth pillar relating to governance outcomes in fisheries management has occurred concurrently with the recognised benefits of the use of harvest strategies to aid management decision making the implementation of tbl has not been operationalised within fishery harvest strategies mangel and dowling 2016 nor mse indeed elkington 2018 sought to recall and rethink the tbl concept stating that it has failed to bury the single bottom line economic paradigm in this paper we present a quantitative non commensurable unit approach via a multi indicator objective function to set tacs for three main species groups in the queensland reef line fishery on australia s great barrier reef the fishery is complex in that it i comprises several sectors with disparate motivations including commercial charter and recreation ii targets multiple important reef species and iii is undertaken in a world heritage area facing significant pressures ranging in scale from local to global great barrier reef marine park authority 2019 the queensland government s sustainable fisheries strategy 2017 2027 states that tbl objectives should be considered in the development of harvest strategies for all major fisheries that fall within their jurisdiction state of queensland 2017 we use simulation with explicit objective preference weights we focus the requisite methodology for explicitly incorporating all objectives as quantifiable and comparable through the development of a scaled performance indicator for each objective our approach is consistent with the efficiency frontier halpern et al 2013 which is a curve or surface on which optimal solutions lie different solutions representing different weights given to conservation versus equity goals we consider the objective weighting profile for different stakeholder groups as part of an integrated value function that is optimised across a suite of catch levels cf rindorf et al 2017 who progressively refine a suite of fishing mortalities corresponding to sustainable yield moreover our approach provides a means to reconcile alternate stakeholder objective preferences that is we present a formal way by which to trade off the objectives across the various sets of weightings where these show a lack of agreement amongst stakeholders this demonstrates a rational approach to mutually disagreeing 2 background 2 1 incorporating multiple objectives into fisheries management decision making to date consideration of the tbl and governance objectives has been largely limited to conceptual treatment stephenson et al 2017 or intuitive forecasting methods using expert opinion bernstein and cetron 1969 dichmont et al 2012 2014 pascoe et al 2019 for example pascoe et al 2009 presented a qualitative framework that aids in the analysis of alternative spatial management options in coastal fisheries the framework combined expert opinion and the analytic hierarchy process saaty 1980 to determine which options performed best taking into account the multiple objectives inherent in fisheries management read and west 2010 used a qualitative ecological risk assessment to assess the effectiveness of managed use zones in six multiple use marine parks located in new south wales dichmont et al 2012 2016 employed an expert group to qualitatively develop different governance strawmen or management strategies these were assessed by a group of industry stakeholders and experts using multi criteria decision analysis techniques against the different objectives one strawman clearly provided the best overall set of outcomes given the multiple objectives development of quantitative models such as those underlying standard mse to assess multi objective outcomes of harvest strategies has been complicated by the abstract nature of some of the objectives particularly social objectives a major problem is that arbitrary increases or decreases in catch or effort have often become a proxy for socio economic considerations mangel and dowling 2016 dichmont et al 2010 illustrate that this is a fraught assumption while maximum economic yield mey has been identified as a primary management objective for australian fisheries first attempts at estimating mey as an actual management target for an actual fishery rather than a conceptual or theoretical exercise highlighted some substantial complexities generally unconsidered by theoretical fisheries economists using a bioeconomic model of an australian fishery for which mey is the management target dichmont et al 2010 showed that unconstrained optimisation may result in effort trajectories that would not be acceptable to industry or managers for example while in theory it may be economically optimal to reduce fishing effort in the short term most bio economic models did not account for the costs associated with effort reduction or fishery closure nor may it be possible for fishers to survive a short term period of negative profits because vessels still need to cover their fixed costs see mangel 2006 pg 218 for a simple example additionally in the case of recreational fishing economic value extends to non catch aspects such as catch rates available fishing days and season length as well as the trade offs between attributes that are trip based and those that measure opportunity over a season young et al 2019 clearly catch and effort are not socio economic proxies so that both short and long term social objectives need to be considered explicitly within any formal evaluation framework that is used to operationalise the tbl benson and stephenson 2018 reviewed tbl methods and found that two of seven proposed tools to support decision making in the management system could provide tactical advice but only management strategy evaluation mse provided advice that was consistent with their criteria for generation transmission and use of scientific information in management advisory processes even mse e g plagányi et al 2012 2013 is conditioned on how tbl objectives are weighted and there is no means to formally make recommendations that reconcile different interest groups stephenson et al 2017 identified three key impediments to embracing tbl and governance objectives in a full quantitative analysis the lack of explicit social economic and institutional objectives the lack of a process for routine integration of all four pillars of sustainability and a bias towards biological considerations incorporating social relationships together with economic and ecological sustainability objectives into models to provide management advice is challenging particularly when this advice requires complex trade offs between objectives pascoe and dichmont 2017 the process is further complicated by differences in quality and quantity of data across fisheries and difficulties in quantifying social objectives and outcomes quantitative attempts to address the tbl have been made using bioeconomic modelling but social objectives have generally been downplayed and the treatment has largely been theoretical as opposed to operational pascoe et al 2017 plagányi et al 2012 and plagányi et al 2013 used a suite of integrated models to capture multiple objectives aimed at assessing tbl outcomes of different allocations between islander and non islander fishers of the torres strait rock lobster fishery as well as different management strategy outcomes these included a bayesian network model to assess how the islander sector might respond to different management strategies and allocations van putten et al 2013 and a model of non islander fleet adjustment under different quota allocations pascoe et al 2013a the economic implications of the fleets effort levels were assessed using a bioeconomic model plagányi et al 2012 where social objectives have been explicitly included in quantitative models these have often been limited to metrics that can be readily linked to catch or effort levels such as employment for example multi objective goal programming models included economic profits social employment and environmental stocks size discards etc objectives as specific targets and estimated the fleet structure and catches required to optimise the fishery performance across these objectives given different objective weights e g charles 1989 mardle et al 2000 pascoe and mardle 2001 more recently bioeconomic models based on co viability analysis have been developed to assess management strategies that achieve at least minimum levels of outcome under each tbl objective e g gourguet et al 2016 more commonly bioeconomic models have been applied to address just the economic and environmental tbl pillars zimmermann and yamazaki 2017 modelled a multi stock fishery to study how biological and economic management objectives were affected by stock interactions punt et al 2010 modelled the australian northern prawn fishery focusing on mey and the level of effort in each of two fishing strategies to maximise the net present value of fishery profits gaichas et al 2017 used a length structured multispecies multi fleet model to illustrate trade offs between objectives of yield biomass species diversity and revenue under changing environmental conditions guillen et al 2013 estimated msy and mey in multi species and multi fleet fisheries and analysed the resulting impacts on the optimal effort allocation between fleets that had different economic structures griffin and woodward 2011 analysed a wide range of recreational management strategies and their impacts on red snapper yield economic surplus and fish stock dichmont et al 2013 used an mse that included a bio economic and ecosystem model to evaluated marine spatial closures with conflicting fisheries and conservation objectives pascoe et al 2013b showed the importance of stakeholder preferences in tbl management by assessing the relative importance of the different objectives to different stakeholder groups in the queensland east coast otter trawl fishery australia across stakeholder interest groups preference weightings showed a 4 fold difference in economic outcomes 2 fold difference in social outcomes and almost 2 fold difference in environmental outcomes this motivates the need to reconcile weightings and tbl harvest strategies across interest groups to be sure operationalising the triple bottom line beyond a simple conceptualisation is complex embedding the tbl in formal management requires each of the tbl objectives to be operational quantifiable as a performance indicator and objectives need to be weighted according to individual preferences which will naturally vary across the fishery s stakeholders objectives need to be evaluated in the context of a formal harvest strategy and preference weightings need to be reconciled amongst and between stakeholder groups finally for quantitative evaluations operational objectives need to be direct or indirect functions of the management mechanism used within the harvest strategy despite these challenges legislative mandates require tacs to be set based on tbl objectives and their associated performance indicators the challenges need to be met in a quantitative manner the question remains as to how to optimise a tbl value function given a set of weightings across a range of scenarios and a range of stakeholder interest groups richerson et al 2010 showed that by using relative quantities triple bottom line performance metrics that were otherwise incompatible could be made commensurate mangel and dowling 2016 demonstrated a more fundamental way of interpreting weightings for various stakeholder groups in the form of a single tbl value function our simulation approach builds on and extends this previous work 2 2 case study fishery the queensland coral reef finfish fishery the queensland coral reef finfish fishery ranges from cape york 10 41 s in the north to bundaberg 24 30 s in the south operating mostly within the great barrier reef marine park the commercial sector mainly targets several species of coral trout plectropomus and variola spp ct of which p leopardus is predominantly landed as live fish and exported to asia red throat emperor lethrinus miniatus rte and over 100 other reef associated fish species os including groupers mainly serranidae emperors lethrinidae and tropical snappers mainly lutjanidae landed as dead whole fish thébaud et al 2014 in addition there is a large valuable and iconic recreational fishery a regional charter fishery and a small indigenous fishery commercial operators use hand held lines with baited hooks with vessels ranging from single small vessels that take short 12 48 hour trips to small fishing dories tender boats operating from larger mother vessels that undertake trips of up to three weeks commercial fishers employ various targeting strategies some boats are fully dedicated to live ct capture while others actively target a broader range of species the commercial fishery is subject to a range of input and output controls including limited entry a commercial total allowable catch allocated via individual transferable quota itq units tradability of input and output entitlements and seasonal spawning closures the recreational and charter fishery is controlled through control of inputs such as daily limits per species group per fisher and seasonal spawning closures within the great barrier reef marine park there are also no take areas that apply to this fishery the fishery has a working group consisting of stakeholders from the commercial recreational and charter sectors a conservation sector representative fisheries and marine park managers and scientists the working group provides advice to fisheries queensland on the operational aspects of the management of the fishery including the development of a harvest strategy for the fishery 3 methods 3 1 objectives performance indicators and preference weightings previous studies of fisheries management objectives in australian fisheries brooks et al 2015 farmery et al 2019 jennings et al 2016 pascoe et al 2014 2013b identified 75 different potential objectives each of which fell in one of the following categories ecological environmental economic social and institutional management with these as a starting point a series of workshops held with members of the working group approximately 20 different individuals were involved in the discussions allowed us to iteratively identify the 22 objectives of most relevance to the fishery table 1 one objective 4 2 2 was considered to be outside of the mandate of fisheries managers and therefore the control of a harvest strategy as a result only the remaining 21 objectives were considered in the simulation we translated each conceptual objective into an operational objective to be operational an objective had to be measurable and simulation achievable with quantitative performance indicators against which it could be assessed table 1 table si 1 we used a modified version of the analytical hierarchical process pascoe et al 2019 through an online survey of 110 fishery stakeholders to elicit preference weights the approach used comparisons of each set of objectives at each level of the hierarchy i e the overarching objectives sub objectives and specific objectives in table 1 and produced relative weights by stakeholder group at each level pascoe et al 2019 fully describe the approach taken to weight the objectives and details of the resultant weights associated with each of the objectives 3 2 simulation model to more quantitatively evaluate tbl and governance objectives we developed a simulation model approximating the three main species groups in the fishery coral trout ct red throat emperor rte and other species os the simulation is not fitted to data and is based on the assumption of perfect information it contains neither a stock assessment nor a sampling model to estimate underlying biomass however to give the simulation model more fidelity to nature we calibrated species biomass levels and trends using stock assessment models leigh et al 2006 2014 o neill et al 2011 and the historical catch data for the different sectors described in detail below we simplified the fishery to two latitudinal regions north and south noting that longitudinally all commercial fishers concentrate their effort on the mid shelf along an essentially north south coastline we chose the boundary between regions at latitude 18 1 s to allow for both lower fishing intensity and greatly decreased abundance of red throat emperor north of this latitude as presently occurs we assumed no fish movement between regions and region specific recruitment in the projections we assumed that the charter and recreational fishing mortality were equally distributed between regions we distributed the commercial fishing mortality as per equation 13 in supplementary material 1 5 little et al 2007 in a 31 year historical period of the simulation we calculated fishing mortality based on the species sector and region specific historical catches for the two regions after which we used the optimisation to determine a total allowable catch for each species group allocated to one or more sectors for a subsequent 25 years the tacs also had the option of being region specific in supplementary material 1 we provide a full description of the population dynamics we optimised over a range of possible tac levels a value function for each of a given set of stakeholder group weightings this approach allowed us to test any harvest strategy decision rule but here we limited our treatment to determining optimal species specific and for some scenarios region specific tacs across the operational objectives we assumed that the optimised tacs were fully realised with no over or under catch following richerson et al 2010 and munch et al 2017 we defined a quantitative performance indicator for each of the 21 operational objectives which had to be a function directly or indirectly of the management control in this case the tac defining these operational objectives required strong assumptions about the relationship between the resource fishery and control rule particularly for the social objectives table si 1 supplementary material 1 in general the objectives are denominated in different units so were normalised from 0 to 1 with 0 being the worst performance and 1 the best to make the performance metrics commensurate richerson et al 2010 in setting functional forms for the performance indicators i e determining the relationship between the performance indicator and the tac and associated target and limit reference points we had to ensure that the logic remained as consistent as possible throughout to avoid nonsensical or uninformative zones along the solution surface specifically we i avoided uninformative plateaus to the extent possible that is we avoided hockey stick style relationships where the value of the performance indicator remained at 1 above the target reference point and rather penalised the performance indicator as a function of its distance from the target ii detected and removed impossible conflicts that compromised the fitting process for example if the target reference points for the relative biomass of each species are such that os relative biomass is greater than its target reference point while ct and rte relative biomasses are less than theirs it is very difficult to optimise the tacs when different species are being driven in different directions and iii ran the simulation using single or subsets of performance indicators only to ensure that each was behaving as anticipated the functional forms of each performance indicator are illustrated in supplemental figure 1 8 having defined the 21 quantitative performance indicators we then applied a corresponding stakeholder preference weighting to each performance indicator and summed to obtain an overall value the value function in year y for any set of stakeholder group g s objective preference weightings is 1 v g g y j 1 21 p i j y w t j g where pij y is the value of performance indicator j in year y and wtj g is the weighting of performance indicator j by stakeholder group g in each year y of the simulation projection we optimised to find the species specific tacs that maximised v g g y mangel and dowling 2016 to ensure that the global minimum was achieved when optimising across a rugged likelihood profile we initialised peppered the model using 64 different parameter combinations of initial tac values for those scenarios for which tacs were also region specific one third of the species initial tac value was assigned to the northern region and two thirds to the southern region that is initial values for each species tac were set at 300t 1000t 2000t or 3000t 4 sets of values for each of 3 species 4 4 4 64 initial parameter value combinations these values were initial guesses for the tac parameters based on the historical catch levels and used for each year of the projections that were then changed through estimation by the optimisation process given the optimum tacs for each stakeholder group s weightings we calculated the value function using the weightings of every other stakeholder group for each year this gives a matrix of values according to each set of stakeholder group weightings calculated using the performance indicators derived from the optimal strategy tac for each stakeholder group we write this as a matrix in which each row represents one stakeholder group s optimal strategy which is applied to each stakeholder group s preference weighting by column thus for n stakeholder groups we have a matrix of the form v 1 1 y v 1 2 y v 1 g y v 1 n y v 2 1 y v 2 n y v g 1 y v g g y v n 1 y v n 2 y v n g y v n n y each column of the matrix is standardised relative to the value for that column s stakeholder group for which the strategy is optimal so that the diagonal elements are equal to 1 we used two alternative criteria to select the overall optimal tac i the highest average value across all stakeholder weightings i e the row of the matrix that has the highest average indicating that the strategy is overall optimal across all preference groups and ii the highest minimum value across all stakeholder weightings the maximin criterion the row of the matrix that has the highest minimum value across indicating that this strategy results in the minimum whinge across all preference groups 3 3 input data the historical harvest and effort data for each of the three species groups for each of the commercial charter and recreational sectors span the 31 years from the beginning of the queensland commercial logbook database in 1988 to 2018 specific species targeting information was generally not available the commercial sector focuses strongly on coral trout so that we could quantify effort from commercial vessels equipped for live ct but we could not delineate activity directed at dead ct rte and os commercial and charter harvest and effort came from the logbook database that has been compulsory for commercial fishers since 1988 and for charter fishers since 1996 we extrapolated charter data back to 1988 by assuming that they were constant over the period 1988 1996 recreational harvest and effort came primarily from the australia wide national recreational and indigenous fishing survey in 2000 and queensland s statewide recreational fishing surveys in 2011 and 2014 henry and lyle 2003 taylor et al 2012 webley et al 2015 information in some other years 1997 1999 2002 and 2005 came from queensland surveys that used different methodology the latter surveys were used only as a trend and their overall estimates were scaled to match that from the 2000 survey we interpolated data loglinearly for the years between 1997 and 2014 in which surveys were not carried out and assumed recreational harvest and effort were constant from 1988 to 1997 and from 2014 to 2018 we subtracted charter records from the recreational surveys in order to avoid double counting of charter data we regarded the charter logbook database as more accurate and it also included data from guests who did not live in queensland we defined effort for the commercial and charter sectors respectively as the number of commercial dory days or charter guest days on which any fish were caught reliable data were not available on any finer time scale such as hours fished or on days on which no fish were caught for the recreational sector we defined effort as the number of person days on which fishing took place including zero catches such measures of effort are particularly suited to tbl inputs such as costs of fishing quality of fishing experience and impacts on non target species their associated catch per unit effort cpue ratios were less accurate indices of abundance of fish than would have been produced by for example standardisation by generalised linear models in appendix table a1 we summarise the general model and biological input parameters they were derived from stock assessments of ct leigh et al 2014 rte leigh et al 2006 and parameters for tropical snappers lutjanus spp o neill et al 2011 lutjanus spp constitute a substantial proportion of the os catch and many of them are long lived thereby providing contrast with ct and rte and providing a precautionary slant to the analysis for the os group we used growth and weight at length for crimson snapper l erythropterus which are typical of the size of species in the os category we chose os values of 0 15 yr 1 for the natural mortality rate m and 8 years as the age at maturity as typical for tropical red snappers the value of the initial population size parameter see sm for details for os is a conservative educated guess to produce exploitable biomass approximately three times that for coral trout bearing in mind that the os category covers a multitude of species the proportional splits of recruit numbers into regions was based on historical catch sizes adjusted for the lesser intensity of commercial and charter fishing in the northern region see sm for further details the number of age classes 20 was sufficient to embrace the lifespans of ct and rte some of the os species such as lutjanus spp live to more than 40 years but are still adequately covered by 20 age classes because they grow relatively quickly moreover the final age class is a plus group containing all fish aged 19 years or more 3 4 alternative tac specifications 3 4 1 commercial tac only we began by applying a dynamic tac only to the commercial sector currently the charter and recreational sectors have no tac and the historical data for the charter and recreational sectors show a relatively constant catch over recent time fig 1 thus we fixed catch for these sectors based on the average catch for each species group over the final three years of the historical time series unless stated otherwise in this and all other scenarios used the highest average to obtain the winning stakeholder group preferences 3 4 1 1 commercial tac optimised with maximin criteria when determining the overall optimal tac across stakeholder groups we took as the default the highest average value across all stakeholder weightings in this scenario the tac was assigned to the commercial sector tac only but using the maximin criteria as opposed to using the highest average to obtain the winning stakeholder group preferences that is the maximin approach takes the highest minimum value across all stakeholder weightings indicating that this strategy results in the minimum loss of value across all preference groups 3 4 2 commercial and charter tac 3 4 2 2 base 2 tac and 1 area one of the alternative harvest strategy options proposed by the fishery working group was for the charter sector to have its own tac for this scenario we divided the modelled tac as a fixed proportion based on historical precedence between the commercial and charter sectors the recreational projected catch remained a fixed catch as described above this commercial and charter tac scenario formed the basis for several additional scenarios including simulating the effect of environmental perturbations and climate change the reasons for building from this 2 sector alternative scenario rather than a commercial only tac is because the former scenario conferred greater flexibility across the fishery through enabling the majority of the catch to be dynamically modelled and it was a key scenario considered in the pascoe et al 2019 study of the same fishery 3 4 2 3 cyclone acute event and climate change chronic regime shift to consider the effect of key environmental influences we simulated acute and chronic environmental change in a simple way although these simulations are rudimentary they allow us to acknowledge the importance of such external forces to the fishery hughes et al 2018 kim et al 2019 and to illustrate how their impacts might be considered tropical cyclones are semi regular events that correlate with major falls in fishery catch rates of the primary target species group coral trout ct in the southern region of the fishery with simultaneous increases in red throat emperor rte catch rates bureau of meteorology 2019 courtney et al 2015 queensland government 2019 we simulated a single cyclone event in the 5th year of the projection period by reducing the availability of the ct species group by 40 and increasing availability of the rte species group by 20 in the southern region for years 5 8 that is we assume no impact on the underlying biomass but rather on the availability of these species groups to the fishery we modelled climate change as a 1 per year migration of all species from the northern to the southern region as well as an overall reduction of abundance of all species by 0 7 per year these figures were chosen as levels that made a substantial difference but not enough to cause a complete fishery collapse 3 4 2 4 over exploited resource to acknowledge that the level of historical fishing pressure was not high for all species particularly for rte and os species groups we considered a scenario where the stock was heavily fished for an additional 10 years before the projections with constant catches by each fleet in each region of 1 6 times 100 times and 4 times that of the final historical year for ct rte and os respectively these multipliers were chosen to give catch levels that would drive each species toward the limit reference point of 20 of the initial biomass by the end of the additional 10 years in the case of rte the population biology was so resilient that even 100 times the final year catch only drove the stock level down to 47 of the initial stock size for the ct and os species groups any heavier fishing than 1 6 or 4 0 times the final historical year would drive older age classes to extinction 3 4 3 area specific tac scenario we also ran an additional simulation in which tacs were set by region thus 6 tacs per annum we used the fleet dynamics models developed in previous studies of the fishery little et al 2007 2016 to distribute fishing mortality by area 3 4 4 commercial charter and recreational tac in an additional scenario we assigned all sectors fixed proportions of the modelled tac for each of these scenarios the species group specific tacs were for the whole fishery with all regions combined 3 tacs per annum we used the previously developed fleet dynamics models little et al 2007 2016 to distribute fishing mortality it should be noted that an annual non charter recreational tac is not practicable for the fishery as there is no mechanism to record recreational harvest in close to real time this case is modelled but only as a single scenario 3 5 model uncertainties and sensitivity analysis because the emphasis of this paper is a simulation that operationalises a multi objective tbl and governance objectives harvest strategy and there are multiple levels of unknowns and assumptions the results should be interpreted with caution the underlying operating model incorporates assumptions around the groupings of species the fleet dynamics and fish movement and recruitment patterns and these are assumed known we also simplified the spatial regions and the characteristics of the commercial fleet in combining live and dead ct fishers dedicated rte and os fishers as well as various inferences to approximate the historical catch and effort for the recreational sector furthermore translating each conceptual objective into a quantifiable operational objective performance indicator that is some function of the catch or effort requires assumptions concerning the form of the relationship for each performance indicator the values of any associated reference points and tolerance thresholds table si 1 one way to have reduced the associated uncertainty would have been to have used higher order hence fewer objectives but we did not do so because these were too vague in their articulation and contained too much inherent hidden detail to be sufficient for purpose consequently we undertook simple sensitivity analyses wherein we fixed the form of the relationship of each performance indicator and considered only one alternative parameter specification the form of each sensitivity test is described in appendix table a2 we found that the performance indicators related to target species sustainability and commercial profitability resulted in the strongest changes increases or reductions in interannual variability in species group specific catch and across the suite of performance indicators the latter is unsurprising since most of the performance indicators are functions of catch and biomass in general the indicator values that were most strongly affected within sensitivity tests were those to which the change in specification was being applied however other performance indicators were affected by changes in the parameter values of any one performance indicator typically with an increase in variability about their mean if not a change in their mean values generally across all the indicator specific scenarios considered the most sensitive indicators were the ecological indicators pertaining to minimising risk to bycatch species objective 1 2 1 and discarding objective 1 2 2 and the related social perception of the fishery objective 4 2 1 the former two are functions of effort and size structure respectively which were more affected by the sensitivity tests than overall catch and biomass 4 results 4 1 historical catch data across both the north and south regions catches generally increased to a peak in about 1998 before stabilising or declining from around 2003 when there was a major fishery restructure through the introduction of itqs and no take areas were increased fig 1 catches were much higher in the southern region partly due to higher human population numbers and also due to regional differences in species distribution coral trout dominated the commercial catch while the other species group dominated the charter and recreational catches particularly the recreational sector in the south the charter sector had the lowest catches of the three sectors in terms of modelled relative biomass by the end of the 31 year historical time series ct was recovering from being reduced to 30 b0 at around year 22 to be at 40 b0 rte relative biomass was reduced to 75 b0 by year 17 but then increased to be above 90 b0 by the end of the historical time series os biomass was at 80 b0 by year 31 up from 73 b0 in year 17 4 2 key scenarios for each scenario we present time series of total catch fig 2 species specific catch time series are also provided in fig a1 total final biomass fig 3 biomass time series are also provided in fig a2 for each species group as well as the mean of each of the 21 performance indicators taken across the 25 projection years fig 4 means with standard deviations are also provided in fig a3 keeping the charter and recreational catches constant constrained the commercial tac setting total catch for each species showed very little variation from the final historical year fig 2 ct and os biomasses continued to increase to over 60 and 80 b0 respectively while rte biomass stabilised at over 90 b0 fig 3 this optimised economic benefits of minimising interannual variability in profit objective 2 4 and costs of management objective 2 5 and the social objective of maximising equity between sectors fig 4 however this was at the expense of the maximum economic yield not being reached per lower values of profitability performance indicators relating to objectives 2 1 1 2 1 3 with stocks not being fished to bmey to have achieved this would have required an extreme increase in commercial tac that would have compromised other performance indicators such as discarding a function of effort the equity between sectors objective 4 2 1 and interannual variability in profit objective 2 4 assigning tac to the commercial sector only but using the maximin criteria as opposed to using the highest average to obtain the winning stakeholder group preferences increased rte catch fig 2 such that rte biomass achieved its target fig 3 this shows the sensitivity to and hence the importance of the criteria used to determine the winning set of stakeholder group preference weightings in each year using the maximin criterion the most predominant winning stakeholder groups were quota owners and commercial fishers and processors buyers wholesaler while the charter and recreational and other group categories were the predominant winners using the highest average criterion the most marked differences between these sets of groups was that the former strongly favoured commercial and the directly related indigenous profits objective 2 1 driving increased catches in rte and assigned less weighting to equity across the fishing sectors objective 4 1 such that the increased rte catch for the commercial sector relative to the others was less important for brevity the results presented below are based only on the highest average criterion the working group s proposed scenario of allowing both commercial and charter sectors to have a dynamic tac gave greater flexibility to the model the catches of each species combined across sectors showed strong interannual oscillations that were highest in magnitude in the first 5 years of the projection but that ultimately fluctuated around an average fig 2 there was an approximately 20x overall increase in rte catch to average around 6000t a slight overall increase in average os catch to average around 1000t and ct catch averaged around 1000t the increases in rte and os catch drove their respective relative biomasses down such that all species stabilised around their targets of for ct and rte between 0 4 0 6 b0 and for os 0 4 b0 fig 3 we emphasise that we were careful to align the target reference points of all performance indicators and that when these were misaligned the oscillations lead to chaotic time series with inconsistent magnitudes with no discernible average when including performance indicators sequentially into the simulation results not shown it became clear that the commercial and charter profitability performance indicators were primarily responsible for the observed oscillations in catch when the catches of all species were combined the total catch across species resulted in a relatively stable time series essentially ct and rte catches were inversely correlated suggesting there were multiple optimal states combinations of species specific catch for which profit is optimal in terms of the performance indicators for this scenario the target species sustainability indicators relating to objectives 1 1 1 1 1 2 1 3 2 the profitability objectives 1 1 1 1 1 3 recreational value objective 2 2 and flow on economic benefits objective 2 3 were all optimal for this scenario fig 4 the cost of management specified as a function of catch also increased such that the objective to minimise this was compromised objective 2 5 as was obviously given the high variability in the early years especially the objective minimising interannual variability in profit objective 2 4 willingness to comply with the harvest strategy due to increased management complexity objective 3 was also slightly compromised the performance indicators were at zero indicating poorest possible performance for the objectives of minimising broader ecological risk and risk to threatened endangered and protected tep species risk to bycatch species was also high i e low value of objective 1 2 1 fig 4 these performance indicators were specified as functions of effort with targets and limits set at fractions of the historical value with the increase in effort associated with the higher catches of rte in particular the performance of these objectives was compromised performance was also poor for discard mortality risk objective 1 2 2 indicating the proportion of small sized fish in the catch increased as a result performance associated with the public perception risk associated with discards and tep species objective 4 2 1 was also low finally equity between sectors objective 4 1 and regions objective 4 3 2 was compromised since the targets were based on historical precedent and rte catch in particular broke that precedent the targets may need to be revised leading to a paradigm shift in the fishery management rule when all three sectors received tac the catch trajectories again showed strong fluctuations in the first 5 years of the projections fig 2 but thereafter were stable and smooth at levels that maintained the relative biomass at target levels with the exception of a slight decrease in os biomass at the end of the projected time series albeit one still within the 10 tolerance about the target reference point of 40 b0 fig 3 relative to tac being allocated to only the commercial and charter sectors the main trade off in terms of performance indicators was the charter sector profit since the tac allocation that had previously been assigned to this sector was now being shared with the non charter recreational sector fig 4 the performance indicator relating to objective 2 2 maximise value of recreational fishers and charter experience direct to participant was optimal for both scenarios because this is determined across both the charter and recreational sectors despite the stable total catch trajectory there was an increased interannual variability in commercial and charter profit and so a lower value for the performance indicator relating to objective 2 4 indicating higher interannual variability in how the catch is shared between sectors likely due to multiple uniform states across the likelihood profile across various relative tac proportions willingness to comply with the harvest strategy due to further increased management complexity objective 3 was also slightly compromised when tacs were set for the commercial and charter sectors separately for each of the two regions the increased flexibility had the result that the total catches for each species did not show the same strong interannual oscillations and particularly the overshooting in the first 5 years of the projection though for ct the longer term interannual oscillations in catch were stronger in magnitude than for the non region specific tac scenario fig 2 rte catch again increased by approximately 20 times and the average projected catches of all three species were ultimately similar to the non region specific tac scenario consequently the relative biomass trajectories were also similar to the non region specific tac scenario with the biomasses of all three species being driven to their target values fig 3 the ct biomass also was more stable than that for the non region specific tac scenario which continued to increase throughout the projection the stability is again likely due to the greater flexibility afforded by assigning tac by region and thereby being able to more directly achieve the sustainability objectives in terms of the performance indicators there was little difference between the region specific and non region specific tac scenarios fig 4 the main gains over non area specific tacs were small and were mostly in terms of three objectives the first two were i the reduced discarding of undersize fish objective 1 2 2 presumably because the tacs were now being directed towards to the regions of higher relative abundance and ii the related improved public perception that is partly related to discarding practices objective 4 2 1 the third was slight improvement in the perception of equitable access by region objective 4 3 2 possibly because despite the increase in rte catch the relative regional tac assignment may be more consistent with past relative catch patterns on which the target was based the cost of this improvement in performance indicators was in terms of the management willingness to comply objective objective 3 which is directly related to the increased number of management controls tacs despite the reduction in high magnitude oscillations in catch at the start of the time series there was no change to the average interannual variability in the performance indicator objective 2 4 relative to tacs being non region specific likely because the total catches across all species for both scenarios showed relatively small interannual changes beyond the first projection year the scenarios with environmental change resulted in very little medium to long term changes in catch and biomass fig 2 3 recall that we simulated a cyclone in the 5th year of the projection period by reducing the availability but not the actual abundance of the ct species group by 40 and increasing availability of the rte species group by 20 in the southern region for years 5 8 relative to the scenario with no environmental perturbations this was reflected by a short term reduction in ct catch from years 5 7 of the projection period years 36 38 however catch quickly recovered since the underlying abundance was assumed to be unaffected to its long term stable state in the same years a short term increase in rte catch occurred fig 2 given that all modelled species biomasses were well above their target reference points the effect of the simulated climate change was due more to the 1 per year migration of all species from the northern to the southern region than to the overall reduction of abundance of all species by 0 7 per year fig 3 there was no effect on overall catch or biomass nor most of the performance indicators fig 4 there was a slight relative increase in discarding a reduction in performance indicator relating to objective 1 2 2 as well as a worsening of the associated social perception indicator relating to objective 4 2 1 as a result of increased relative proportions of undersized fish in the catch possibly as a result of the reduction in abundance across all performance indicators the main difference was a reduction in the charter sector profitability this appears incongruous given that commercial profitability was unaffected but as opposed to commercial profitability charter profitability is simulated as a function of effort there is relatively higher charter catch in the southern region than the north total catches and the performance indicators pertaining to equitable access between sectors and regions indicated no significant sector or region specific differences in catch since we simulated effort for each sector in each year as the catch divided by the product of the catchability and the fishable biomass an increasing fishable biomass in the south led to a reduction in effort in the predominantly fished southern region and hence a reduction in charter sector profitability populations recovered to sustainable target levels when the biomass was historically more heavily fished down towards the limit reference point as with the earlier scenarios changes to the tac were greatest within the first 5 years of the projections fig 2 with large interannual changes in tac that compromised the performance indicator pertaining to interannual variability in profit objective 2 4 in this time period ct and os tacs were consistently very low while rte continually declined ct and rte total catches were stable thereafter with the exception of one inversely correlated year os catches increased over the final 8 years of the projection as a result of higher catches in the north for rte the projected catch did not increase substantively in the northern region thus most of the biomass increase occurred in the north the opposite was the case for os there was more overall biomass in the southern region for both species groups but the total rte biomass was within its target ranges after being fished down meaning the catch in the more abundant southern region did not significantly change total os biomass however was at its limit of 20 b0 after being fished down with very low relative biomass in the northern region as such much of the recovery of this species group was driven by low catch the southern region the northern region os catches actually increased keeping the biomass in this region low presumably because the relative contribution of the northern region to the recovery of the total os biomass was so low as to be negligible the depletion associated with fished down stocks affected the oldest age classes most strongly and hence the performance indicators related to discarding objectives 1 2 2 4 2 1 were minimal fig 4 as a result of the increased relative proportion of undersize fish in the catch the os sustainability performance indicator relating to objective 1 1 2 was also compromised due to this species group being the most heavily fished down the reductions in commercial and charter tac while recreational catch levels were kept constant also minimised the performance indicator pertaining to equity between sectors objective 4 3 2 we note that the model does not consider the ratios of tacs between species however it is unlikely that effort could be targeted to achieve species group specific catch limits particularly if these vary significantly from the historically achieved ratios discarding is therefore a risk around implementing unrealistic tac ratios similarly it is highly unlikely that 100 times the historical catch of rte would occur concomitant with small increases in ct and os catch as was simulated here for the fished down scenario 5 discussion our goal is to provide a tool for managers fishery management councils scientists and stakeholders to consider a richer range of tradeoffs than possible with bio economic models only consistent with policy and legislative requirements the model we developed provides a quantitative means to explicitly evaluate the four pillars tbl and governance and their tradeoffs in terms of clearly defined stakeholder objectives in addition it allows for formal evaluation of performance of the four pillars across alternative stakeholder group preferences providing an impartial means to obtaining an overall optimum harvest strategy here a set of species group specific tacs as opposed to semi quantitative expert judgement approaches that rank or rate alternative harvest strategy specifications our approach leads to both quantified alternative harvest strategy options and the optimal values for the management controls our model is less complex than many current ecosystem models it is relatively easy to implement and by placing all the indicators on the same scale disparate indicators can be compared importantly implementing it requires detailed discussions with stakeholders on objectives and their relative weights different stakeholder opinions in the form of weights on importance are overtly considered this linkage between a discussion on objectives without restriction to the model s needs was initially seen as a benefit but in hindsight has delivered some of the difficulties with the model while the model is conceptually not complex parameterising and optimising it was fraught with technical challenges given the number of objectives and performance indicators that came out of the stakeholder process the model is information hungry this led to having to define several indicators functional forms and their targets many of which are unknown to stakeholders and scientists alike and produced a likelihood function that was complex and resulted in a sensitive in an estimation sense model the formulation of separate performance indicators for each of the objectives estimated annually meant the model had no sense of consequence for an optimisation in following years finally as for many mathematical models stakeholder engagement is more restricted given the technical content of the model below we expand on these issues and then discuss possible solutions multi sector multi species fisheries such as the coral reef finfish fishery need to address the tbl however the quantity and quality of data are often mixed many reference points are uninformed and performance indicators vary in their quality of information broader environmental economic and particularly social information is often limited as data collection programs expand over time this difficulty will become less important but is unlikely to disappear had data been available for example for social performance indicators in the form of a survey we could at least have tuned the model to these in addition to stock status additionally while we were able to move beyond an abstract specification of objectives the information hungry nature of the model meant that many of the operational objectives performance indicators were still ultimately specified in terms of catch and effort as that is catch and effort were used as proxies for socio economic considerations as highlighted by mangel and dowling 2016 and dichmont et al 2010 these can be fraught assumptions as with all models a range of factors determine the nature of the results these include specification of the performance indicators and the choice of values for depending on the indicator s specification target or limit reference point values weightings penalties or parameters several of the performance indicators were extremely difficult to quantify especially those in the social objective arena and drove much of the model s sensitivity and initial instability this has also been found by others brooks et al 2015 pascoe et al 2017 symes and phillipson 2009 triantafillos et al 2014 vieira et al 2009 we addressed this issue head on by developing performance indicators and associated parameters as a function of a single management control tacs the sensitivity of the model to the scenarios as well as to the functional form of the performance indicators and their reference point values showed the risk of using many detailed performance indicators to obtain meaningful management advice we had to carefully construct the performance indicator specifications to ensure that these were aligned across objectives and we had to pepper the starting parameter values to avoid local minima in what was still a rugged solution surface separate objectives e g profitability and final biomass competed unless their targets were consistent and optimal for both e g the maximum economic yield and the biomass corresponding to maximum economic yield with 21 performance indicators ensuring such consistency was a challenge the projected time series of most of the model scenarios showed at least some years of interannual oscillation in the sector and species specific tac values particularly in the early years of the projection for rte and os historical catch levels had been well below those corresponding to target reference points most notably maximum economic yield however tacs oscillated rather than ramping up during projection years this occurred because by undertaking optimisation within each year the model has no sense of medium to long term consequences another issue contributing to inter annual oscillations in the sector and species specific tac was the inverse correlation of ct and rte catch in many of the scenarios while catches of these species and any dependent performance indicators showed interannual fluctuations the projected catch totalled across both species was relatively stable when examining performance indicators by incrementally including each the projected catch time series only became strongly interannually fluctuating with the inclusion of commercial and charter profitability performance indicators themselves direct functions of the ct and rte catch this speaks to alternate states of ct and rte relative catch that are equally profitable future work should optimise over the medium to longer term rather than annually because of such complexities we had less direct stakeholder involvement other than objective identification and weighting than more conceptually based semi quantitative approaches the results are also more technically challenging to interpret as both input and output are demanding of information this may mean that stakeholder buy in to the model will remain low until the method matures and absorbs some of the solutions discussed below one option for reducing the uncertainty and complexity of the simulation is to include fewer operational objectives and performance indicators katsikopoulos et al 2018 suggest that under such conditions simple models may be more appropriate than more complex models for decision making particularly in the case of repeated operational decisions such as are required when implementing a harvest strategy a high number of objectives may be excessive in a practical sense however reducing the number of objectives will require reconsideration of how to translate broader objectives into quantitative performance indicators one way this may be achieved could be to subsume many of the correlated performance indicators into single metrics for example profitability and target biomass could be combined as is done in a standard bio economic model reducing or subsuming the number of objectives and performance indicators may also help overcome the problem of roughly similar weightings across the different stakeholder groups see also pascoe et al 2019 the similar weightings across stakeholder groups may have been an artefact of the dilution effect of distributing higher level objective weights over many sub objectives an alternative way to define some of the objectives could be to use a bayesian belief network bbn to capture non quantitative objectives the outputs of the operating model would then feed into the bbn model to quantify the social components clearly a multi year forward optimisation process would have been preferable longer term expectations should be captured by the value at which the target reference points are set and if these are established correctly then the projections should eventually achieve them the forward optimisation can then also be constrained if needed by for example a smoothing term two alternatives to the model described here are viability and frontier analyses gourguet et al 2016 developed viability analysis for australia s northern prawn fishery with this approach one does not aim to identify an optimal outcome but instead aims to ensure at least a minimal acceptable level for each of the objectives it is thus analogous to simon s notion of satisficing e g simon et al 1950 in frontier analysis halpern et al 2013 the frontier consists of tbl solutions where one can optimise conservation goals and equity while minimising costs the frontier does not prescribe a single solution but instead presents the range of options all optimal that represent the trade off between stated goals the choice of the optimal solution by a decision maker will be based on their relative importance weights for each objective while potentially less transparent than the use of pre determined weights decisions are made with an explicit recognition of what is being given up the policy frontier thereby complements the decision making process without aiming to replace it sylvia and enríquez 1994 on the contrary our approach keeps harvest strategies in mind and leads to a recommended tac optimised across all multiple tbl plus governance objectives and acknowledges the alternative preference weightings of stakeholder groups and is suitable for embedding in an mse neither viability nor frontier analysis allows for this our approach also showed sensitivity to the criteria used to identify the winning set of stakeholder group preferences or weightings in each year the highest average approach gave markedly different outcomes to when the maximum minimum value criterion was utilised even with the sensitivities inherent assumptions and simplification our model illustrates the trade offs between multiple objectives and different stakeholder group preferences and the value of region and sector specific tacs in different environmental contexts the next step would be to reduce the number of objectives so as to reduce the inherent uncertainties and data requirements and the complexity of the solution surface and to optimise across the longer term policy and legislation demand that fishery management moves towards a quantitative approach to tbl objectives and operationalising these defensibly within harvest strategies we developed a model whose likelihood surface was proved highly complex and sensitive to inputs and assumptions which will force managers and stakeholders to confront extensive data requirements to advance tbl four pillar fishery management a high level of involvement of stakeholders is required in determining fishery objectives and their weightings an appreciation by management agencies of the data requirements of multi objective fishery management and a commitment to implement a quantitative approach that sets precise values for management controls is also recommended at the same time this should be tempered given data limitations and the need for a manageable number of objectives across the four pillars more broadly quantitative ways to operationalise multi objective harvest strategies are likely to have relevance for other renewable resource industries where the tbl matters provided these have management controls that can be changed our approach has provided a stepping stone towards this goal and a basis for further modification and has highlighted the technical pitfalls of using simulations to optimise across multiple objectives in complex fisheries credit authorship contribution statement natalie a dowling conceptualization methodology writing original draft investigation software formal analysis validation supervision funding acquisition catherine m dichmont conceptualization methodology writing original draft investigation software formal analysis validation supervision funding acquisition george m leigh conceptualization methodology writing original draft investigation software formal analysis validation data curation sean pascoe conceptualization methodology writing original draft investigation validation supervision funding acquisition rachel j pears methodology writing review editing funding acquisition tom roberts methodology writing review editing sian breen methodology writing review editing toni cannard methodology writing original draft visualization aaron mamula conceptualization methodology writing review editing marc mangel conceptualization methodology writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was funded by the fisheries research and development corporation frdc grant number 2015 013 in kind contributions were made by csiro queensland department of agriculture and fisheries and the great barrier reef marine park authority gbrmpa dr cameron speir noaa southwest fisheries science center is thanked for providing invaluable advice and input to the model and approach in its early stages peter campbell csiro provided scientific computing user support we thank two anonymous reviewers for their comprehensive and valuable feedback that significantly improved the manuscript supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2020 109243 appendix b supplementary materials image application 1 appendix a1 additional figures and tables figs a1 a3 and tables a1 a2 
24752,natural resource management has long recognised that the multi objective nature of management is important but has struggled to operationalise this into quantitative measurable objectives for functional use in management operationalising broader ecological and social objectives has been particularly problematic in fisheries management the focus has mainly been on target species sustainability and in the past few decades on profitability however multi objective management is now essential as fisheries have become recognised as complex social ecological systems policy and legislation demand a move towards quantitative approaches for reconciling multiple objectives and operationalising these within harvest strategies we present a quantitative non commensurable unit approach via a multi indicator value function with explicit objective preference weights we use a simulation to set total allowable catches tacs for three main species groups in a reef line fishery in australia s great barrier reef our method enables stakeholders to consider a richer range of tradeoffs than is possible with bio economic models moreover it allows the formal evaluation of performance across alternative stakeholder group preferences providing an impartial way to obtain an overall optimum tac the simulation requires extensive fishery data and requires the performance indicators associated with each objective to be quantitatively and defensibly defined thus our approach provides a pathway forward that forces managers and stakeholders to confront the associated data requirements keywords triple bottom line harvest strategy development reef line fishery stakeholder preference weightings multi objective trade offs simulation 1 introduction maintaining healthy ecosystems and healthy human communities that depend on them is increasingly recognised as important to natural resource management including fisheries asche et al 2018 berkes 2000 charles 1995 de young 2008 fao 2009 marshall et al 2017 voss et al 2014 elkington 1998 conceived the triple bottom line tbl encompassing economic ecological and social objectives as a tool for influencing a single decision maker to explicitly value non financial objectives by optimising over the three different objectives halpern et al 2013 note that maximising conservation goals and achieving equity in social outcomes while minimising overall costs is the ideal tbl outcome in a fisheries context stephenson et al 2017 proposed four pillars of sustainability that include institutional aspects in addition to economical ecological and social pillars pascoe et al 2013b also considered institutional or managerial objectives of simplifying and improving management structures in fisheries several jurisdictions have legislated the consideration of multiple objectives for example the united states magnuson stevens fishery conservation and management act 1996 mandates consideration of economic and social outcomes in addition to environmental outcomes in national standard 8 in australia the fisheries management act 1991 requires the effective integration of long term and short term economic environmental social and equity considerations into policy development for commonwealth managed fisheries department of agriculture and water resources 2018 while the productivity commission inquiry into marine fisheries and aquaculture also reinforced the need to include social economic and environmental considerations into fisheries policy and management productivity commission 2016 concurrent with the recognition of the need to include multiple objectives into fisheries management has been the increased development and adoption of harvest strategies to assist in management decision making harvest strategies comprise pre agreed monitoring and performance indicators usually obtained from a stock assessment and decision or harvest control rules invoked in response to the assessment that are collectively used to control fishing mortality on the target species butterworth and punt 2003 punt et al 2002 sainsbury et al 2000 in fisheries management harvest strategies are used for tactical fisheries management to set control variables such as the total allowable catch tac or limit recreational catch through daily bag limits per person garcia et al 2003 concomitant with the development of harvest strategies has been the development of quantitative tools to assess potential harvest strategies in particular management strategy evaluation mse has developed as a formalised approach to pre test different harvest strategies via simulation before their implementation punt et al 2016 smith 1994 smith et al 1999 although the recognition of the importance of consideration of tbl and in some cases the extended fourth pillar relating to governance outcomes in fisheries management has occurred concurrently with the recognised benefits of the use of harvest strategies to aid management decision making the implementation of tbl has not been operationalised within fishery harvest strategies mangel and dowling 2016 nor mse indeed elkington 2018 sought to recall and rethink the tbl concept stating that it has failed to bury the single bottom line economic paradigm in this paper we present a quantitative non commensurable unit approach via a multi indicator objective function to set tacs for three main species groups in the queensland reef line fishery on australia s great barrier reef the fishery is complex in that it i comprises several sectors with disparate motivations including commercial charter and recreation ii targets multiple important reef species and iii is undertaken in a world heritage area facing significant pressures ranging in scale from local to global great barrier reef marine park authority 2019 the queensland government s sustainable fisheries strategy 2017 2027 states that tbl objectives should be considered in the development of harvest strategies for all major fisheries that fall within their jurisdiction state of queensland 2017 we use simulation with explicit objective preference weights we focus the requisite methodology for explicitly incorporating all objectives as quantifiable and comparable through the development of a scaled performance indicator for each objective our approach is consistent with the efficiency frontier halpern et al 2013 which is a curve or surface on which optimal solutions lie different solutions representing different weights given to conservation versus equity goals we consider the objective weighting profile for different stakeholder groups as part of an integrated value function that is optimised across a suite of catch levels cf rindorf et al 2017 who progressively refine a suite of fishing mortalities corresponding to sustainable yield moreover our approach provides a means to reconcile alternate stakeholder objective preferences that is we present a formal way by which to trade off the objectives across the various sets of weightings where these show a lack of agreement amongst stakeholders this demonstrates a rational approach to mutually disagreeing 2 background 2 1 incorporating multiple objectives into fisheries management decision making to date consideration of the tbl and governance objectives has been largely limited to conceptual treatment stephenson et al 2017 or intuitive forecasting methods using expert opinion bernstein and cetron 1969 dichmont et al 2012 2014 pascoe et al 2019 for example pascoe et al 2009 presented a qualitative framework that aids in the analysis of alternative spatial management options in coastal fisheries the framework combined expert opinion and the analytic hierarchy process saaty 1980 to determine which options performed best taking into account the multiple objectives inherent in fisheries management read and west 2010 used a qualitative ecological risk assessment to assess the effectiveness of managed use zones in six multiple use marine parks located in new south wales dichmont et al 2012 2016 employed an expert group to qualitatively develop different governance strawmen or management strategies these were assessed by a group of industry stakeholders and experts using multi criteria decision analysis techniques against the different objectives one strawman clearly provided the best overall set of outcomes given the multiple objectives development of quantitative models such as those underlying standard mse to assess multi objective outcomes of harvest strategies has been complicated by the abstract nature of some of the objectives particularly social objectives a major problem is that arbitrary increases or decreases in catch or effort have often become a proxy for socio economic considerations mangel and dowling 2016 dichmont et al 2010 illustrate that this is a fraught assumption while maximum economic yield mey has been identified as a primary management objective for australian fisheries first attempts at estimating mey as an actual management target for an actual fishery rather than a conceptual or theoretical exercise highlighted some substantial complexities generally unconsidered by theoretical fisheries economists using a bioeconomic model of an australian fishery for which mey is the management target dichmont et al 2010 showed that unconstrained optimisation may result in effort trajectories that would not be acceptable to industry or managers for example while in theory it may be economically optimal to reduce fishing effort in the short term most bio economic models did not account for the costs associated with effort reduction or fishery closure nor may it be possible for fishers to survive a short term period of negative profits because vessels still need to cover their fixed costs see mangel 2006 pg 218 for a simple example additionally in the case of recreational fishing economic value extends to non catch aspects such as catch rates available fishing days and season length as well as the trade offs between attributes that are trip based and those that measure opportunity over a season young et al 2019 clearly catch and effort are not socio economic proxies so that both short and long term social objectives need to be considered explicitly within any formal evaluation framework that is used to operationalise the tbl benson and stephenson 2018 reviewed tbl methods and found that two of seven proposed tools to support decision making in the management system could provide tactical advice but only management strategy evaluation mse provided advice that was consistent with their criteria for generation transmission and use of scientific information in management advisory processes even mse e g plagányi et al 2012 2013 is conditioned on how tbl objectives are weighted and there is no means to formally make recommendations that reconcile different interest groups stephenson et al 2017 identified three key impediments to embracing tbl and governance objectives in a full quantitative analysis the lack of explicit social economic and institutional objectives the lack of a process for routine integration of all four pillars of sustainability and a bias towards biological considerations incorporating social relationships together with economic and ecological sustainability objectives into models to provide management advice is challenging particularly when this advice requires complex trade offs between objectives pascoe and dichmont 2017 the process is further complicated by differences in quality and quantity of data across fisheries and difficulties in quantifying social objectives and outcomes quantitative attempts to address the tbl have been made using bioeconomic modelling but social objectives have generally been downplayed and the treatment has largely been theoretical as opposed to operational pascoe et al 2017 plagányi et al 2012 and plagányi et al 2013 used a suite of integrated models to capture multiple objectives aimed at assessing tbl outcomes of different allocations between islander and non islander fishers of the torres strait rock lobster fishery as well as different management strategy outcomes these included a bayesian network model to assess how the islander sector might respond to different management strategies and allocations van putten et al 2013 and a model of non islander fleet adjustment under different quota allocations pascoe et al 2013a the economic implications of the fleets effort levels were assessed using a bioeconomic model plagányi et al 2012 where social objectives have been explicitly included in quantitative models these have often been limited to metrics that can be readily linked to catch or effort levels such as employment for example multi objective goal programming models included economic profits social employment and environmental stocks size discards etc objectives as specific targets and estimated the fleet structure and catches required to optimise the fishery performance across these objectives given different objective weights e g charles 1989 mardle et al 2000 pascoe and mardle 2001 more recently bioeconomic models based on co viability analysis have been developed to assess management strategies that achieve at least minimum levels of outcome under each tbl objective e g gourguet et al 2016 more commonly bioeconomic models have been applied to address just the economic and environmental tbl pillars zimmermann and yamazaki 2017 modelled a multi stock fishery to study how biological and economic management objectives were affected by stock interactions punt et al 2010 modelled the australian northern prawn fishery focusing on mey and the level of effort in each of two fishing strategies to maximise the net present value of fishery profits gaichas et al 2017 used a length structured multispecies multi fleet model to illustrate trade offs between objectives of yield biomass species diversity and revenue under changing environmental conditions guillen et al 2013 estimated msy and mey in multi species and multi fleet fisheries and analysed the resulting impacts on the optimal effort allocation between fleets that had different economic structures griffin and woodward 2011 analysed a wide range of recreational management strategies and their impacts on red snapper yield economic surplus and fish stock dichmont et al 2013 used an mse that included a bio economic and ecosystem model to evaluated marine spatial closures with conflicting fisheries and conservation objectives pascoe et al 2013b showed the importance of stakeholder preferences in tbl management by assessing the relative importance of the different objectives to different stakeholder groups in the queensland east coast otter trawl fishery australia across stakeholder interest groups preference weightings showed a 4 fold difference in economic outcomes 2 fold difference in social outcomes and almost 2 fold difference in environmental outcomes this motivates the need to reconcile weightings and tbl harvest strategies across interest groups to be sure operationalising the triple bottom line beyond a simple conceptualisation is complex embedding the tbl in formal management requires each of the tbl objectives to be operational quantifiable as a performance indicator and objectives need to be weighted according to individual preferences which will naturally vary across the fishery s stakeholders objectives need to be evaluated in the context of a formal harvest strategy and preference weightings need to be reconciled amongst and between stakeholder groups finally for quantitative evaluations operational objectives need to be direct or indirect functions of the management mechanism used within the harvest strategy despite these challenges legislative mandates require tacs to be set based on tbl objectives and their associated performance indicators the challenges need to be met in a quantitative manner the question remains as to how to optimise a tbl value function given a set of weightings across a range of scenarios and a range of stakeholder interest groups richerson et al 2010 showed that by using relative quantities triple bottom line performance metrics that were otherwise incompatible could be made commensurate mangel and dowling 2016 demonstrated a more fundamental way of interpreting weightings for various stakeholder groups in the form of a single tbl value function our simulation approach builds on and extends this previous work 2 2 case study fishery the queensland coral reef finfish fishery the queensland coral reef finfish fishery ranges from cape york 10 41 s in the north to bundaberg 24 30 s in the south operating mostly within the great barrier reef marine park the commercial sector mainly targets several species of coral trout plectropomus and variola spp ct of which p leopardus is predominantly landed as live fish and exported to asia red throat emperor lethrinus miniatus rte and over 100 other reef associated fish species os including groupers mainly serranidae emperors lethrinidae and tropical snappers mainly lutjanidae landed as dead whole fish thébaud et al 2014 in addition there is a large valuable and iconic recreational fishery a regional charter fishery and a small indigenous fishery commercial operators use hand held lines with baited hooks with vessels ranging from single small vessels that take short 12 48 hour trips to small fishing dories tender boats operating from larger mother vessels that undertake trips of up to three weeks commercial fishers employ various targeting strategies some boats are fully dedicated to live ct capture while others actively target a broader range of species the commercial fishery is subject to a range of input and output controls including limited entry a commercial total allowable catch allocated via individual transferable quota itq units tradability of input and output entitlements and seasonal spawning closures the recreational and charter fishery is controlled through control of inputs such as daily limits per species group per fisher and seasonal spawning closures within the great barrier reef marine park there are also no take areas that apply to this fishery the fishery has a working group consisting of stakeholders from the commercial recreational and charter sectors a conservation sector representative fisheries and marine park managers and scientists the working group provides advice to fisheries queensland on the operational aspects of the management of the fishery including the development of a harvest strategy for the fishery 3 methods 3 1 objectives performance indicators and preference weightings previous studies of fisheries management objectives in australian fisheries brooks et al 2015 farmery et al 2019 jennings et al 2016 pascoe et al 2014 2013b identified 75 different potential objectives each of which fell in one of the following categories ecological environmental economic social and institutional management with these as a starting point a series of workshops held with members of the working group approximately 20 different individuals were involved in the discussions allowed us to iteratively identify the 22 objectives of most relevance to the fishery table 1 one objective 4 2 2 was considered to be outside of the mandate of fisheries managers and therefore the control of a harvest strategy as a result only the remaining 21 objectives were considered in the simulation we translated each conceptual objective into an operational objective to be operational an objective had to be measurable and simulation achievable with quantitative performance indicators against which it could be assessed table 1 table si 1 we used a modified version of the analytical hierarchical process pascoe et al 2019 through an online survey of 110 fishery stakeholders to elicit preference weights the approach used comparisons of each set of objectives at each level of the hierarchy i e the overarching objectives sub objectives and specific objectives in table 1 and produced relative weights by stakeholder group at each level pascoe et al 2019 fully describe the approach taken to weight the objectives and details of the resultant weights associated with each of the objectives 3 2 simulation model to more quantitatively evaluate tbl and governance objectives we developed a simulation model approximating the three main species groups in the fishery coral trout ct red throat emperor rte and other species os the simulation is not fitted to data and is based on the assumption of perfect information it contains neither a stock assessment nor a sampling model to estimate underlying biomass however to give the simulation model more fidelity to nature we calibrated species biomass levels and trends using stock assessment models leigh et al 2006 2014 o neill et al 2011 and the historical catch data for the different sectors described in detail below we simplified the fishery to two latitudinal regions north and south noting that longitudinally all commercial fishers concentrate their effort on the mid shelf along an essentially north south coastline we chose the boundary between regions at latitude 18 1 s to allow for both lower fishing intensity and greatly decreased abundance of red throat emperor north of this latitude as presently occurs we assumed no fish movement between regions and region specific recruitment in the projections we assumed that the charter and recreational fishing mortality were equally distributed between regions we distributed the commercial fishing mortality as per equation 13 in supplementary material 1 5 little et al 2007 in a 31 year historical period of the simulation we calculated fishing mortality based on the species sector and region specific historical catches for the two regions after which we used the optimisation to determine a total allowable catch for each species group allocated to one or more sectors for a subsequent 25 years the tacs also had the option of being region specific in supplementary material 1 we provide a full description of the population dynamics we optimised over a range of possible tac levels a value function for each of a given set of stakeholder group weightings this approach allowed us to test any harvest strategy decision rule but here we limited our treatment to determining optimal species specific and for some scenarios region specific tacs across the operational objectives we assumed that the optimised tacs were fully realised with no over or under catch following richerson et al 2010 and munch et al 2017 we defined a quantitative performance indicator for each of the 21 operational objectives which had to be a function directly or indirectly of the management control in this case the tac defining these operational objectives required strong assumptions about the relationship between the resource fishery and control rule particularly for the social objectives table si 1 supplementary material 1 in general the objectives are denominated in different units so were normalised from 0 to 1 with 0 being the worst performance and 1 the best to make the performance metrics commensurate richerson et al 2010 in setting functional forms for the performance indicators i e determining the relationship between the performance indicator and the tac and associated target and limit reference points we had to ensure that the logic remained as consistent as possible throughout to avoid nonsensical or uninformative zones along the solution surface specifically we i avoided uninformative plateaus to the extent possible that is we avoided hockey stick style relationships where the value of the performance indicator remained at 1 above the target reference point and rather penalised the performance indicator as a function of its distance from the target ii detected and removed impossible conflicts that compromised the fitting process for example if the target reference points for the relative biomass of each species are such that os relative biomass is greater than its target reference point while ct and rte relative biomasses are less than theirs it is very difficult to optimise the tacs when different species are being driven in different directions and iii ran the simulation using single or subsets of performance indicators only to ensure that each was behaving as anticipated the functional forms of each performance indicator are illustrated in supplemental figure 1 8 having defined the 21 quantitative performance indicators we then applied a corresponding stakeholder preference weighting to each performance indicator and summed to obtain an overall value the value function in year y for any set of stakeholder group g s objective preference weightings is 1 v g g y j 1 21 p i j y w t j g where pij y is the value of performance indicator j in year y and wtj g is the weighting of performance indicator j by stakeholder group g in each year y of the simulation projection we optimised to find the species specific tacs that maximised v g g y mangel and dowling 2016 to ensure that the global minimum was achieved when optimising across a rugged likelihood profile we initialised peppered the model using 64 different parameter combinations of initial tac values for those scenarios for which tacs were also region specific one third of the species initial tac value was assigned to the northern region and two thirds to the southern region that is initial values for each species tac were set at 300t 1000t 2000t or 3000t 4 sets of values for each of 3 species 4 4 4 64 initial parameter value combinations these values were initial guesses for the tac parameters based on the historical catch levels and used for each year of the projections that were then changed through estimation by the optimisation process given the optimum tacs for each stakeholder group s weightings we calculated the value function using the weightings of every other stakeholder group for each year this gives a matrix of values according to each set of stakeholder group weightings calculated using the performance indicators derived from the optimal strategy tac for each stakeholder group we write this as a matrix in which each row represents one stakeholder group s optimal strategy which is applied to each stakeholder group s preference weighting by column thus for n stakeholder groups we have a matrix of the form v 1 1 y v 1 2 y v 1 g y v 1 n y v 2 1 y v 2 n y v g 1 y v g g y v n 1 y v n 2 y v n g y v n n y each column of the matrix is standardised relative to the value for that column s stakeholder group for which the strategy is optimal so that the diagonal elements are equal to 1 we used two alternative criteria to select the overall optimal tac i the highest average value across all stakeholder weightings i e the row of the matrix that has the highest average indicating that the strategy is overall optimal across all preference groups and ii the highest minimum value across all stakeholder weightings the maximin criterion the row of the matrix that has the highest minimum value across indicating that this strategy results in the minimum whinge across all preference groups 3 3 input data the historical harvest and effort data for each of the three species groups for each of the commercial charter and recreational sectors span the 31 years from the beginning of the queensland commercial logbook database in 1988 to 2018 specific species targeting information was generally not available the commercial sector focuses strongly on coral trout so that we could quantify effort from commercial vessels equipped for live ct but we could not delineate activity directed at dead ct rte and os commercial and charter harvest and effort came from the logbook database that has been compulsory for commercial fishers since 1988 and for charter fishers since 1996 we extrapolated charter data back to 1988 by assuming that they were constant over the period 1988 1996 recreational harvest and effort came primarily from the australia wide national recreational and indigenous fishing survey in 2000 and queensland s statewide recreational fishing surveys in 2011 and 2014 henry and lyle 2003 taylor et al 2012 webley et al 2015 information in some other years 1997 1999 2002 and 2005 came from queensland surveys that used different methodology the latter surveys were used only as a trend and their overall estimates were scaled to match that from the 2000 survey we interpolated data loglinearly for the years between 1997 and 2014 in which surveys were not carried out and assumed recreational harvest and effort were constant from 1988 to 1997 and from 2014 to 2018 we subtracted charter records from the recreational surveys in order to avoid double counting of charter data we regarded the charter logbook database as more accurate and it also included data from guests who did not live in queensland we defined effort for the commercial and charter sectors respectively as the number of commercial dory days or charter guest days on which any fish were caught reliable data were not available on any finer time scale such as hours fished or on days on which no fish were caught for the recreational sector we defined effort as the number of person days on which fishing took place including zero catches such measures of effort are particularly suited to tbl inputs such as costs of fishing quality of fishing experience and impacts on non target species their associated catch per unit effort cpue ratios were less accurate indices of abundance of fish than would have been produced by for example standardisation by generalised linear models in appendix table a1 we summarise the general model and biological input parameters they were derived from stock assessments of ct leigh et al 2014 rte leigh et al 2006 and parameters for tropical snappers lutjanus spp o neill et al 2011 lutjanus spp constitute a substantial proportion of the os catch and many of them are long lived thereby providing contrast with ct and rte and providing a precautionary slant to the analysis for the os group we used growth and weight at length for crimson snapper l erythropterus which are typical of the size of species in the os category we chose os values of 0 15 yr 1 for the natural mortality rate m and 8 years as the age at maturity as typical for tropical red snappers the value of the initial population size parameter see sm for details for os is a conservative educated guess to produce exploitable biomass approximately three times that for coral trout bearing in mind that the os category covers a multitude of species the proportional splits of recruit numbers into regions was based on historical catch sizes adjusted for the lesser intensity of commercial and charter fishing in the northern region see sm for further details the number of age classes 20 was sufficient to embrace the lifespans of ct and rte some of the os species such as lutjanus spp live to more than 40 years but are still adequately covered by 20 age classes because they grow relatively quickly moreover the final age class is a plus group containing all fish aged 19 years or more 3 4 alternative tac specifications 3 4 1 commercial tac only we began by applying a dynamic tac only to the commercial sector currently the charter and recreational sectors have no tac and the historical data for the charter and recreational sectors show a relatively constant catch over recent time fig 1 thus we fixed catch for these sectors based on the average catch for each species group over the final three years of the historical time series unless stated otherwise in this and all other scenarios used the highest average to obtain the winning stakeholder group preferences 3 4 1 1 commercial tac optimised with maximin criteria when determining the overall optimal tac across stakeholder groups we took as the default the highest average value across all stakeholder weightings in this scenario the tac was assigned to the commercial sector tac only but using the maximin criteria as opposed to using the highest average to obtain the winning stakeholder group preferences that is the maximin approach takes the highest minimum value across all stakeholder weightings indicating that this strategy results in the minimum loss of value across all preference groups 3 4 2 commercial and charter tac 3 4 2 2 base 2 tac and 1 area one of the alternative harvest strategy options proposed by the fishery working group was for the charter sector to have its own tac for this scenario we divided the modelled tac as a fixed proportion based on historical precedence between the commercial and charter sectors the recreational projected catch remained a fixed catch as described above this commercial and charter tac scenario formed the basis for several additional scenarios including simulating the effect of environmental perturbations and climate change the reasons for building from this 2 sector alternative scenario rather than a commercial only tac is because the former scenario conferred greater flexibility across the fishery through enabling the majority of the catch to be dynamically modelled and it was a key scenario considered in the pascoe et al 2019 study of the same fishery 3 4 2 3 cyclone acute event and climate change chronic regime shift to consider the effect of key environmental influences we simulated acute and chronic environmental change in a simple way although these simulations are rudimentary they allow us to acknowledge the importance of such external forces to the fishery hughes et al 2018 kim et al 2019 and to illustrate how their impacts might be considered tropical cyclones are semi regular events that correlate with major falls in fishery catch rates of the primary target species group coral trout ct in the southern region of the fishery with simultaneous increases in red throat emperor rte catch rates bureau of meteorology 2019 courtney et al 2015 queensland government 2019 we simulated a single cyclone event in the 5th year of the projection period by reducing the availability of the ct species group by 40 and increasing availability of the rte species group by 20 in the southern region for years 5 8 that is we assume no impact on the underlying biomass but rather on the availability of these species groups to the fishery we modelled climate change as a 1 per year migration of all species from the northern to the southern region as well as an overall reduction of abundance of all species by 0 7 per year these figures were chosen as levels that made a substantial difference but not enough to cause a complete fishery collapse 3 4 2 4 over exploited resource to acknowledge that the level of historical fishing pressure was not high for all species particularly for rte and os species groups we considered a scenario where the stock was heavily fished for an additional 10 years before the projections with constant catches by each fleet in each region of 1 6 times 100 times and 4 times that of the final historical year for ct rte and os respectively these multipliers were chosen to give catch levels that would drive each species toward the limit reference point of 20 of the initial biomass by the end of the additional 10 years in the case of rte the population biology was so resilient that even 100 times the final year catch only drove the stock level down to 47 of the initial stock size for the ct and os species groups any heavier fishing than 1 6 or 4 0 times the final historical year would drive older age classes to extinction 3 4 3 area specific tac scenario we also ran an additional simulation in which tacs were set by region thus 6 tacs per annum we used the fleet dynamics models developed in previous studies of the fishery little et al 2007 2016 to distribute fishing mortality by area 3 4 4 commercial charter and recreational tac in an additional scenario we assigned all sectors fixed proportions of the modelled tac for each of these scenarios the species group specific tacs were for the whole fishery with all regions combined 3 tacs per annum we used the previously developed fleet dynamics models little et al 2007 2016 to distribute fishing mortality it should be noted that an annual non charter recreational tac is not practicable for the fishery as there is no mechanism to record recreational harvest in close to real time this case is modelled but only as a single scenario 3 5 model uncertainties and sensitivity analysis because the emphasis of this paper is a simulation that operationalises a multi objective tbl and governance objectives harvest strategy and there are multiple levels of unknowns and assumptions the results should be interpreted with caution the underlying operating model incorporates assumptions around the groupings of species the fleet dynamics and fish movement and recruitment patterns and these are assumed known we also simplified the spatial regions and the characteristics of the commercial fleet in combining live and dead ct fishers dedicated rte and os fishers as well as various inferences to approximate the historical catch and effort for the recreational sector furthermore translating each conceptual objective into a quantifiable operational objective performance indicator that is some function of the catch or effort requires assumptions concerning the form of the relationship for each performance indicator the values of any associated reference points and tolerance thresholds table si 1 one way to have reduced the associated uncertainty would have been to have used higher order hence fewer objectives but we did not do so because these were too vague in their articulation and contained too much inherent hidden detail to be sufficient for purpose consequently we undertook simple sensitivity analyses wherein we fixed the form of the relationship of each performance indicator and considered only one alternative parameter specification the form of each sensitivity test is described in appendix table a2 we found that the performance indicators related to target species sustainability and commercial profitability resulted in the strongest changes increases or reductions in interannual variability in species group specific catch and across the suite of performance indicators the latter is unsurprising since most of the performance indicators are functions of catch and biomass in general the indicator values that were most strongly affected within sensitivity tests were those to which the change in specification was being applied however other performance indicators were affected by changes in the parameter values of any one performance indicator typically with an increase in variability about their mean if not a change in their mean values generally across all the indicator specific scenarios considered the most sensitive indicators were the ecological indicators pertaining to minimising risk to bycatch species objective 1 2 1 and discarding objective 1 2 2 and the related social perception of the fishery objective 4 2 1 the former two are functions of effort and size structure respectively which were more affected by the sensitivity tests than overall catch and biomass 4 results 4 1 historical catch data across both the north and south regions catches generally increased to a peak in about 1998 before stabilising or declining from around 2003 when there was a major fishery restructure through the introduction of itqs and no take areas were increased fig 1 catches were much higher in the southern region partly due to higher human population numbers and also due to regional differences in species distribution coral trout dominated the commercial catch while the other species group dominated the charter and recreational catches particularly the recreational sector in the south the charter sector had the lowest catches of the three sectors in terms of modelled relative biomass by the end of the 31 year historical time series ct was recovering from being reduced to 30 b0 at around year 22 to be at 40 b0 rte relative biomass was reduced to 75 b0 by year 17 but then increased to be above 90 b0 by the end of the historical time series os biomass was at 80 b0 by year 31 up from 73 b0 in year 17 4 2 key scenarios for each scenario we present time series of total catch fig 2 species specific catch time series are also provided in fig a1 total final biomass fig 3 biomass time series are also provided in fig a2 for each species group as well as the mean of each of the 21 performance indicators taken across the 25 projection years fig 4 means with standard deviations are also provided in fig a3 keeping the charter and recreational catches constant constrained the commercial tac setting total catch for each species showed very little variation from the final historical year fig 2 ct and os biomasses continued to increase to over 60 and 80 b0 respectively while rte biomass stabilised at over 90 b0 fig 3 this optimised economic benefits of minimising interannual variability in profit objective 2 4 and costs of management objective 2 5 and the social objective of maximising equity between sectors fig 4 however this was at the expense of the maximum economic yield not being reached per lower values of profitability performance indicators relating to objectives 2 1 1 2 1 3 with stocks not being fished to bmey to have achieved this would have required an extreme increase in commercial tac that would have compromised other performance indicators such as discarding a function of effort the equity between sectors objective 4 2 1 and interannual variability in profit objective 2 4 assigning tac to the commercial sector only but using the maximin criteria as opposed to using the highest average to obtain the winning stakeholder group preferences increased rte catch fig 2 such that rte biomass achieved its target fig 3 this shows the sensitivity to and hence the importance of the criteria used to determine the winning set of stakeholder group preference weightings in each year using the maximin criterion the most predominant winning stakeholder groups were quota owners and commercial fishers and processors buyers wholesaler while the charter and recreational and other group categories were the predominant winners using the highest average criterion the most marked differences between these sets of groups was that the former strongly favoured commercial and the directly related indigenous profits objective 2 1 driving increased catches in rte and assigned less weighting to equity across the fishing sectors objective 4 1 such that the increased rte catch for the commercial sector relative to the others was less important for brevity the results presented below are based only on the highest average criterion the working group s proposed scenario of allowing both commercial and charter sectors to have a dynamic tac gave greater flexibility to the model the catches of each species combined across sectors showed strong interannual oscillations that were highest in magnitude in the first 5 years of the projection but that ultimately fluctuated around an average fig 2 there was an approximately 20x overall increase in rte catch to average around 6000t a slight overall increase in average os catch to average around 1000t and ct catch averaged around 1000t the increases in rte and os catch drove their respective relative biomasses down such that all species stabilised around their targets of for ct and rte between 0 4 0 6 b0 and for os 0 4 b0 fig 3 we emphasise that we were careful to align the target reference points of all performance indicators and that when these were misaligned the oscillations lead to chaotic time series with inconsistent magnitudes with no discernible average when including performance indicators sequentially into the simulation results not shown it became clear that the commercial and charter profitability performance indicators were primarily responsible for the observed oscillations in catch when the catches of all species were combined the total catch across species resulted in a relatively stable time series essentially ct and rte catches were inversely correlated suggesting there were multiple optimal states combinations of species specific catch for which profit is optimal in terms of the performance indicators for this scenario the target species sustainability indicators relating to objectives 1 1 1 1 1 2 1 3 2 the profitability objectives 1 1 1 1 1 3 recreational value objective 2 2 and flow on economic benefits objective 2 3 were all optimal for this scenario fig 4 the cost of management specified as a function of catch also increased such that the objective to minimise this was compromised objective 2 5 as was obviously given the high variability in the early years especially the objective minimising interannual variability in profit objective 2 4 willingness to comply with the harvest strategy due to increased management complexity objective 3 was also slightly compromised the performance indicators were at zero indicating poorest possible performance for the objectives of minimising broader ecological risk and risk to threatened endangered and protected tep species risk to bycatch species was also high i e low value of objective 1 2 1 fig 4 these performance indicators were specified as functions of effort with targets and limits set at fractions of the historical value with the increase in effort associated with the higher catches of rte in particular the performance of these objectives was compromised performance was also poor for discard mortality risk objective 1 2 2 indicating the proportion of small sized fish in the catch increased as a result performance associated with the public perception risk associated with discards and tep species objective 4 2 1 was also low finally equity between sectors objective 4 1 and regions objective 4 3 2 was compromised since the targets were based on historical precedent and rte catch in particular broke that precedent the targets may need to be revised leading to a paradigm shift in the fishery management rule when all three sectors received tac the catch trajectories again showed strong fluctuations in the first 5 years of the projections fig 2 but thereafter were stable and smooth at levels that maintained the relative biomass at target levels with the exception of a slight decrease in os biomass at the end of the projected time series albeit one still within the 10 tolerance about the target reference point of 40 b0 fig 3 relative to tac being allocated to only the commercial and charter sectors the main trade off in terms of performance indicators was the charter sector profit since the tac allocation that had previously been assigned to this sector was now being shared with the non charter recreational sector fig 4 the performance indicator relating to objective 2 2 maximise value of recreational fishers and charter experience direct to participant was optimal for both scenarios because this is determined across both the charter and recreational sectors despite the stable total catch trajectory there was an increased interannual variability in commercial and charter profit and so a lower value for the performance indicator relating to objective 2 4 indicating higher interannual variability in how the catch is shared between sectors likely due to multiple uniform states across the likelihood profile across various relative tac proportions willingness to comply with the harvest strategy due to further increased management complexity objective 3 was also slightly compromised when tacs were set for the commercial and charter sectors separately for each of the two regions the increased flexibility had the result that the total catches for each species did not show the same strong interannual oscillations and particularly the overshooting in the first 5 years of the projection though for ct the longer term interannual oscillations in catch were stronger in magnitude than for the non region specific tac scenario fig 2 rte catch again increased by approximately 20 times and the average projected catches of all three species were ultimately similar to the non region specific tac scenario consequently the relative biomass trajectories were also similar to the non region specific tac scenario with the biomasses of all three species being driven to their target values fig 3 the ct biomass also was more stable than that for the non region specific tac scenario which continued to increase throughout the projection the stability is again likely due to the greater flexibility afforded by assigning tac by region and thereby being able to more directly achieve the sustainability objectives in terms of the performance indicators there was little difference between the region specific and non region specific tac scenarios fig 4 the main gains over non area specific tacs were small and were mostly in terms of three objectives the first two were i the reduced discarding of undersize fish objective 1 2 2 presumably because the tacs were now being directed towards to the regions of higher relative abundance and ii the related improved public perception that is partly related to discarding practices objective 4 2 1 the third was slight improvement in the perception of equitable access by region objective 4 3 2 possibly because despite the increase in rte catch the relative regional tac assignment may be more consistent with past relative catch patterns on which the target was based the cost of this improvement in performance indicators was in terms of the management willingness to comply objective objective 3 which is directly related to the increased number of management controls tacs despite the reduction in high magnitude oscillations in catch at the start of the time series there was no change to the average interannual variability in the performance indicator objective 2 4 relative to tacs being non region specific likely because the total catches across all species for both scenarios showed relatively small interannual changes beyond the first projection year the scenarios with environmental change resulted in very little medium to long term changes in catch and biomass fig 2 3 recall that we simulated a cyclone in the 5th year of the projection period by reducing the availability but not the actual abundance of the ct species group by 40 and increasing availability of the rte species group by 20 in the southern region for years 5 8 relative to the scenario with no environmental perturbations this was reflected by a short term reduction in ct catch from years 5 7 of the projection period years 36 38 however catch quickly recovered since the underlying abundance was assumed to be unaffected to its long term stable state in the same years a short term increase in rte catch occurred fig 2 given that all modelled species biomasses were well above their target reference points the effect of the simulated climate change was due more to the 1 per year migration of all species from the northern to the southern region than to the overall reduction of abundance of all species by 0 7 per year fig 3 there was no effect on overall catch or biomass nor most of the performance indicators fig 4 there was a slight relative increase in discarding a reduction in performance indicator relating to objective 1 2 2 as well as a worsening of the associated social perception indicator relating to objective 4 2 1 as a result of increased relative proportions of undersized fish in the catch possibly as a result of the reduction in abundance across all performance indicators the main difference was a reduction in the charter sector profitability this appears incongruous given that commercial profitability was unaffected but as opposed to commercial profitability charter profitability is simulated as a function of effort there is relatively higher charter catch in the southern region than the north total catches and the performance indicators pertaining to equitable access between sectors and regions indicated no significant sector or region specific differences in catch since we simulated effort for each sector in each year as the catch divided by the product of the catchability and the fishable biomass an increasing fishable biomass in the south led to a reduction in effort in the predominantly fished southern region and hence a reduction in charter sector profitability populations recovered to sustainable target levels when the biomass was historically more heavily fished down towards the limit reference point as with the earlier scenarios changes to the tac were greatest within the first 5 years of the projections fig 2 with large interannual changes in tac that compromised the performance indicator pertaining to interannual variability in profit objective 2 4 in this time period ct and os tacs were consistently very low while rte continually declined ct and rte total catches were stable thereafter with the exception of one inversely correlated year os catches increased over the final 8 years of the projection as a result of higher catches in the north for rte the projected catch did not increase substantively in the northern region thus most of the biomass increase occurred in the north the opposite was the case for os there was more overall biomass in the southern region for both species groups but the total rte biomass was within its target ranges after being fished down meaning the catch in the more abundant southern region did not significantly change total os biomass however was at its limit of 20 b0 after being fished down with very low relative biomass in the northern region as such much of the recovery of this species group was driven by low catch the southern region the northern region os catches actually increased keeping the biomass in this region low presumably because the relative contribution of the northern region to the recovery of the total os biomass was so low as to be negligible the depletion associated with fished down stocks affected the oldest age classes most strongly and hence the performance indicators related to discarding objectives 1 2 2 4 2 1 were minimal fig 4 as a result of the increased relative proportion of undersize fish in the catch the os sustainability performance indicator relating to objective 1 1 2 was also compromised due to this species group being the most heavily fished down the reductions in commercial and charter tac while recreational catch levels were kept constant also minimised the performance indicator pertaining to equity between sectors objective 4 3 2 we note that the model does not consider the ratios of tacs between species however it is unlikely that effort could be targeted to achieve species group specific catch limits particularly if these vary significantly from the historically achieved ratios discarding is therefore a risk around implementing unrealistic tac ratios similarly it is highly unlikely that 100 times the historical catch of rte would occur concomitant with small increases in ct and os catch as was simulated here for the fished down scenario 5 discussion our goal is to provide a tool for managers fishery management councils scientists and stakeholders to consider a richer range of tradeoffs than possible with bio economic models only consistent with policy and legislative requirements the model we developed provides a quantitative means to explicitly evaluate the four pillars tbl and governance and their tradeoffs in terms of clearly defined stakeholder objectives in addition it allows for formal evaluation of performance of the four pillars across alternative stakeholder group preferences providing an impartial means to obtaining an overall optimum harvest strategy here a set of species group specific tacs as opposed to semi quantitative expert judgement approaches that rank or rate alternative harvest strategy specifications our approach leads to both quantified alternative harvest strategy options and the optimal values for the management controls our model is less complex than many current ecosystem models it is relatively easy to implement and by placing all the indicators on the same scale disparate indicators can be compared importantly implementing it requires detailed discussions with stakeholders on objectives and their relative weights different stakeholder opinions in the form of weights on importance are overtly considered this linkage between a discussion on objectives without restriction to the model s needs was initially seen as a benefit but in hindsight has delivered some of the difficulties with the model while the model is conceptually not complex parameterising and optimising it was fraught with technical challenges given the number of objectives and performance indicators that came out of the stakeholder process the model is information hungry this led to having to define several indicators functional forms and their targets many of which are unknown to stakeholders and scientists alike and produced a likelihood function that was complex and resulted in a sensitive in an estimation sense model the formulation of separate performance indicators for each of the objectives estimated annually meant the model had no sense of consequence for an optimisation in following years finally as for many mathematical models stakeholder engagement is more restricted given the technical content of the model below we expand on these issues and then discuss possible solutions multi sector multi species fisheries such as the coral reef finfish fishery need to address the tbl however the quantity and quality of data are often mixed many reference points are uninformed and performance indicators vary in their quality of information broader environmental economic and particularly social information is often limited as data collection programs expand over time this difficulty will become less important but is unlikely to disappear had data been available for example for social performance indicators in the form of a survey we could at least have tuned the model to these in addition to stock status additionally while we were able to move beyond an abstract specification of objectives the information hungry nature of the model meant that many of the operational objectives performance indicators were still ultimately specified in terms of catch and effort as that is catch and effort were used as proxies for socio economic considerations as highlighted by mangel and dowling 2016 and dichmont et al 2010 these can be fraught assumptions as with all models a range of factors determine the nature of the results these include specification of the performance indicators and the choice of values for depending on the indicator s specification target or limit reference point values weightings penalties or parameters several of the performance indicators were extremely difficult to quantify especially those in the social objective arena and drove much of the model s sensitivity and initial instability this has also been found by others brooks et al 2015 pascoe et al 2017 symes and phillipson 2009 triantafillos et al 2014 vieira et al 2009 we addressed this issue head on by developing performance indicators and associated parameters as a function of a single management control tacs the sensitivity of the model to the scenarios as well as to the functional form of the performance indicators and their reference point values showed the risk of using many detailed performance indicators to obtain meaningful management advice we had to carefully construct the performance indicator specifications to ensure that these were aligned across objectives and we had to pepper the starting parameter values to avoid local minima in what was still a rugged solution surface separate objectives e g profitability and final biomass competed unless their targets were consistent and optimal for both e g the maximum economic yield and the biomass corresponding to maximum economic yield with 21 performance indicators ensuring such consistency was a challenge the projected time series of most of the model scenarios showed at least some years of interannual oscillation in the sector and species specific tac values particularly in the early years of the projection for rte and os historical catch levels had been well below those corresponding to target reference points most notably maximum economic yield however tacs oscillated rather than ramping up during projection years this occurred because by undertaking optimisation within each year the model has no sense of medium to long term consequences another issue contributing to inter annual oscillations in the sector and species specific tac was the inverse correlation of ct and rte catch in many of the scenarios while catches of these species and any dependent performance indicators showed interannual fluctuations the projected catch totalled across both species was relatively stable when examining performance indicators by incrementally including each the projected catch time series only became strongly interannually fluctuating with the inclusion of commercial and charter profitability performance indicators themselves direct functions of the ct and rte catch this speaks to alternate states of ct and rte relative catch that are equally profitable future work should optimise over the medium to longer term rather than annually because of such complexities we had less direct stakeholder involvement other than objective identification and weighting than more conceptually based semi quantitative approaches the results are also more technically challenging to interpret as both input and output are demanding of information this may mean that stakeholder buy in to the model will remain low until the method matures and absorbs some of the solutions discussed below one option for reducing the uncertainty and complexity of the simulation is to include fewer operational objectives and performance indicators katsikopoulos et al 2018 suggest that under such conditions simple models may be more appropriate than more complex models for decision making particularly in the case of repeated operational decisions such as are required when implementing a harvest strategy a high number of objectives may be excessive in a practical sense however reducing the number of objectives will require reconsideration of how to translate broader objectives into quantitative performance indicators one way this may be achieved could be to subsume many of the correlated performance indicators into single metrics for example profitability and target biomass could be combined as is done in a standard bio economic model reducing or subsuming the number of objectives and performance indicators may also help overcome the problem of roughly similar weightings across the different stakeholder groups see also pascoe et al 2019 the similar weightings across stakeholder groups may have been an artefact of the dilution effect of distributing higher level objective weights over many sub objectives an alternative way to define some of the objectives could be to use a bayesian belief network bbn to capture non quantitative objectives the outputs of the operating model would then feed into the bbn model to quantify the social components clearly a multi year forward optimisation process would have been preferable longer term expectations should be captured by the value at which the target reference points are set and if these are established correctly then the projections should eventually achieve them the forward optimisation can then also be constrained if needed by for example a smoothing term two alternatives to the model described here are viability and frontier analyses gourguet et al 2016 developed viability analysis for australia s northern prawn fishery with this approach one does not aim to identify an optimal outcome but instead aims to ensure at least a minimal acceptable level for each of the objectives it is thus analogous to simon s notion of satisficing e g simon et al 1950 in frontier analysis halpern et al 2013 the frontier consists of tbl solutions where one can optimise conservation goals and equity while minimising costs the frontier does not prescribe a single solution but instead presents the range of options all optimal that represent the trade off between stated goals the choice of the optimal solution by a decision maker will be based on their relative importance weights for each objective while potentially less transparent than the use of pre determined weights decisions are made with an explicit recognition of what is being given up the policy frontier thereby complements the decision making process without aiming to replace it sylvia and enríquez 1994 on the contrary our approach keeps harvest strategies in mind and leads to a recommended tac optimised across all multiple tbl plus governance objectives and acknowledges the alternative preference weightings of stakeholder groups and is suitable for embedding in an mse neither viability nor frontier analysis allows for this our approach also showed sensitivity to the criteria used to identify the winning set of stakeholder group preferences or weightings in each year the highest average approach gave markedly different outcomes to when the maximum minimum value criterion was utilised even with the sensitivities inherent assumptions and simplification our model illustrates the trade offs between multiple objectives and different stakeholder group preferences and the value of region and sector specific tacs in different environmental contexts the next step would be to reduce the number of objectives so as to reduce the inherent uncertainties and data requirements and the complexity of the solution surface and to optimise across the longer term policy and legislation demand that fishery management moves towards a quantitative approach to tbl objectives and operationalising these defensibly within harvest strategies we developed a model whose likelihood surface was proved highly complex and sensitive to inputs and assumptions which will force managers and stakeholders to confront extensive data requirements to advance tbl four pillar fishery management a high level of involvement of stakeholders is required in determining fishery objectives and their weightings an appreciation by management agencies of the data requirements of multi objective fishery management and a commitment to implement a quantitative approach that sets precise values for management controls is also recommended at the same time this should be tempered given data limitations and the need for a manageable number of objectives across the four pillars more broadly quantitative ways to operationalise multi objective harvest strategies are likely to have relevance for other renewable resource industries where the tbl matters provided these have management controls that can be changed our approach has provided a stepping stone towards this goal and a basis for further modification and has highlighted the technical pitfalls of using simulations to optimise across multiple objectives in complex fisheries credit authorship contribution statement natalie a dowling conceptualization methodology writing original draft investigation software formal analysis validation supervision funding acquisition catherine m dichmont conceptualization methodology writing original draft investigation software formal analysis validation supervision funding acquisition george m leigh conceptualization methodology writing original draft investigation software formal analysis validation data curation sean pascoe conceptualization methodology writing original draft investigation validation supervision funding acquisition rachel j pears methodology writing review editing funding acquisition tom roberts methodology writing review editing sian breen methodology writing review editing toni cannard methodology writing original draft visualization aaron mamula conceptualization methodology writing review editing marc mangel conceptualization methodology writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was funded by the fisheries research and development corporation frdc grant number 2015 013 in kind contributions were made by csiro queensland department of agriculture and fisheries and the great barrier reef marine park authority gbrmpa dr cameron speir noaa southwest fisheries science center is thanked for providing invaluable advice and input to the model and approach in its early stages peter campbell csiro provided scientific computing user support we thank two anonymous reviewers for their comprehensive and valuable feedback that significantly improved the manuscript supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2020 109243 appendix b supplementary materials image application 1 appendix a1 additional figures and tables figs a1 a3 and tables a1 a2 
24753,evidence is accumulating to show that changes in host diversity can affect disease risk yet the relationship between them is still disputed understanding what factors influence this relationship will help to reconcile this debate in this paper through spatially explicit simulations we investigated the effects of host spatial distribution patterns the scale of host interactions i e local vs global interactions the presence or absence of life history trade offs and community assembly rules on the diversity disease relationship when the pathogen was a generalist the results showed that intraspecific aggregation enhanced disease risk while increased global interactions between hosts reduced disease risk for a given host species richness level the effect of the scale of host interactions on disease risk increased with intraspecific aggregation however neither species distribution patterns nor the scale of host interactions could reverse the diversity disease relationship the direction and strength of diversity on disease risk depended on community assembly and life history trade offs these results suggest that species distribution patterns and the scale of host interactions do not contribute to the discrepancy in results that lead to the debate over dilution effect highlighting the complexity of mechanisms underlying the diversity disease relationship keywords dilution effect spatial autocorrelation spatially explicit simulation life history trade offs 1 introduction with the continuing loss of diversity and the emergence of new diseases understanding the relationship between diversity and disease risk is of great importance to the maintenance and functioning of ecosystems keesing et al 2006 keesing et al 2010 the dilution effect where high host species diversity reduces disease risk has been reported for a wide range of infectious diseases clay et al 2009 suzán et al 2009 johnson et al 2013 and may be a widespread ecosystem service of biodiversity keesing and ostfeld 2012 ostfeld and keesing 2012 civitello et al 2015 however the generality of the dilution effect is still disputed randolph and dobson 2012 salkeld et al 2013 wood et al 2014 rohr et al 2019 some reports suggest that high diversity can amplify disease risk i e an amplification effect lafferty 2009 chen et al 2018 or have no influence on the outcomes of disease risk under some circumstances cardinale et al 2012 salkeld et al 2013 determining the factors that influence the diversity disease relationship may help to reconcile this debate such as host spatial distribution scale of host interactions and host competence many previous theoretical studies on multi host pathogen systems often use spatially implicit models with the assumption that all hosts live in a well mixed non spatially structured habitat dobson 2004 andy and pedersen 2005 however this assumption can rarely be met in nature many field studies found that species can be aggregated random or regularly distributed within or among other species in space levine and murrell 2003 liu et al 2013 zhang et al 2013 for example plant species are often intra specifically aggregated in tibetan plateau meadow vegetation liu et al 2013 stoll and prati 2001 experimentally established a community of interspecifically aggregated plants to compare it with one of randomly dispersed plants to elucidate the precise consequences of intraspecific aggregation on species interactions the spatial distribution of host species can alter disease transmission by affecting host movements the distribution of hosts and or vectors micro environments and species interactions boots and sasaki 2002 estrada peña et al 2014 all of which potentially have profound influences on the diversity disease relationship for example craft et al 2008 used a spatially explicit stochastic sir model to examine the dynamics of disease transmission involving one to three sympatric species with contrasting social organizations e g isolation or connected territorial structures and the results showed that differences in social structure could significantly influence the size and velocity of an epidemic and social structures that permit higher intraspecific transmission were more likely to transmit disease to other species further huang et al 2015 discussed the role of habitat fragmentation and showed that increased connectivity between patches can either dilute or amplify the spread of disease depending on the competence the ability to obtain and transmit diseases of the added host species the scale of host interactions is important for disease transmission boots and mealor 2007 webb et al 2007 wodarz et al 2013 wilber et al 2020 for many human and animal populations global interactions where an agent can interact with any other agent in the system between individuals might be a good approximation but for terrestrial plants many marine invertebrates corals and other sessile organisms each individual can only interact with a subset of individuals within a certain range due to spatially restricted interactions tilman and peter 1997 webb et al 2007 the scale of host interactions has proven critical in determining the stability and persistence of the system for example wodarz 2013 studied the persistence of host pathogen systems in two extreme cases of completely local transmission and completely global transmission and found that local transmission promoted population extinction more than the global case webb 2007 thought that realistic interactions likely lie between these two extremes so they used a multi scale pair approximation model to explore the effects of transmission scale on host parasite dynamics the results showed that local transmission led to reduced persistence of disease and a greater possibility of pathogen driven extinction up until now how the scale of host interactions and species distribution patterns affect diversity disease relationship remain poorly understood in addition to the scale of host interactions and spatial distribution patterns it is poorly understood how host competence contributes to the diversity disease relationship especially given that it varies widely among species logiudice et al 2003 life history theory suggests that increased investment in growth and reproduction often comes at the cost of reduced investment into defense against pathogens martin ii et al 2006 lee et al 2008 therefore species with higher abundance often have higher competence and lower extinction risk johnson et al 2012 joseph et al 2013 which is considered a prerequisite for the dilution effect in addition many studies showed that the effect of diversity on disease risk depended on community assembly how community size varies with species richness rohr et al 2019 community assembly can range from substitutive in which individuals of a new species replace individuals of existing species in a community to additive in which adding new species adds more individuals to a community rudolf and antonovics 2005 however the influence of life history trade offs and community assembly rules on disease risk under different spatial patterns remains unclear in this paper we used spatially explicit simulations to investigate the effects of host species distribution patterns the scale of host interactions the presence or absence of life history trade offs and community assembly rules on the diversity disease relationship when the pathogen is a generalist we expect that global scale of host interactions will dilute disease risk while intraspecific aggregation will amplify disease risk especially when pathogen transmission mainly occurs at local scales community assembly rules and life history trade offs may affect the direction or strength of diversity disease relationship 2 materials and methods spatially explicit stochastic simulations were used to study the disease transmission in a spatially structured multi host community the habitat was divided into a two dimensional lattice of 128 128 cells but different habitat sizes did not change the basic results reported below where each cell contained at most one host individual of any species the detailed simulations were as follows 2 1 generating different species distribution patterns at each species richness level the spatial distribution patterns of hosts were generated in two steps first we used the recursive quadtree subdivision algorithm to generate spatially autocorrelated habitat matrix h gu et al 2002 rybicki and hanski 2013 spatial autocorrelation indicates that the relationship between given variables is a function of their spatial distance or position dale et al 2002 the detailed process of the above algorithm was as follows we divided the landscape into four rectangles and randomly selected a value from a uniform distribution 0 1 for each of the four rectangles the division was continued until each sub area reached the size of a single cell that could not be divided further for example for a square landscape of size 2 d 2 d for some positive integer d the habitat is divided into four equal sub squares a1 1 a1 2 a1 3 a1 4 having values of x11 x14 that are randomly chosen from a uniform distribution 0 1 then after k recursions 4k new rectangles ak 1 ak 2 ak 4 k were created for each ak i we randomly selected corresponding xk i from a uniform distribution 0 1 finally when d steps are finished the value h i j of grid cell i j is h i j 1 w k 1 d l 1 4 k i j a k l w k x k l where wk w k is the weight at scale k and w wk is used to normalize the values of h i j into 0 1 here i j a k l is an indicator function if i j ak l i j ak l 1 otherwise it equals to 0 the single parameter w is used to control the scale of spatial autocorrelation of habitat the larger w is the greater the level of spatial autocorrelation and vice versa in this paper we considered values of 0 5 1 0 1 5 and 2 0 for w to denote four different spatial autocorrelation cases for each w we repeated above processes 1000 times to generate 1000 different habitats to minimize random effects note that in this step we only generated empty habitats with spatial autocorrelation without any species in them second we filled these empty habitats with species to generate different species distribution patterns suppose there were 10 species in the community initially for each w we grouped cells as follows 0 h i j 1 10 1 10 h i j 2 10 9 10 h i j 1 counted the total number of cells of each group and sorted them in descending order then let species i occupy the cells with abundance ranked i th i 1 2 10 therefore the abundance of species i was the total number of cells ranked in the i th species 1 was the most abundant and species 10 was the least in this way when w takes 0 5 1 0 1 5 and 2 0 respectively we obtained four species distribution patterns with species richness of 10 from the above process the levels of spatial autocorrelation can be used to characterize species distribution patterns the higher the spatial autocorrelation level w the higher degree of intraspecific aggregation in contrast when spatial autocorrelation level is low individuals of different species tend to be mixed fig 1 illustrated four distribution patterns when species richness was 10 next we removed species from the above community to create a species richness gradient the results were not sensitive to whether one or two species were removed at a time yet computational time increased rapidly with the number of removals therefore we generated a species richness gradient of 10 8 6 4 and 2 the order in which species were removed was determined by the presence or absence of a life history trade off according to life history theory the most abundant species has the lowest extinction risk therefore if a life history trade off exists the removed species were the least abundant species otherwise species were removed randomly in each case presence or absence of trade offs we considered two scenarios of community assembly substitutive method and additive method in substitutive method community size was fixed independent of species richness to achieve this a compensatory increase proportional to each extant species abundance after species removal was performed for example when 2 species were removed the abundance and distribution of the extant 8 species were determined as follows firstly the cells were divided into 8 groups 0 h i j 1 8 1 8 h i j 2 8 7 8 h i j 1 secondly we counted the total number of cells of each group and sorted them in descending order then let species i occupied the cells with abundance ranked i th i 1 2 8 the substitutive method was analogous to the field experiment of fixing the size of the host community to isolate the effect of host richness or the situation under which the resource was limited so that the maximum number of hosts supported by the resource was fixed chen and zhou 2015 in the additive method community size was positively related to species richness so the abundance and distributions of each extant species were not changed before and after species removal this situation corresponded to cases where the total resource was adequate the total number of hosts in the community increased with host species richness or controlled experiment designs for example using a removal experiment in an alpine meadow liu et al 2016 created a plant biodiversity gradient by manipulating plot level plant diversity with equal abundance of each single plant species across the biodiversity gradient i e additive assembly 2 2 measurement of disease risk as we mentioned above when a life history trade off exists the most abundant species are the most competent and so on to simulate this we drew intraspecific transmission rates βii from the uniform distribution u 0 5 sorted in descending order and then assigned them to each species in addition we also randomized the relationship between βii and species abundance to simulate the situation when the life history trade offs did not exist then in each case 5 species richness levels and 4 spatial autocorrelation levels combined to produce 20 different cases we randomly selected 10 individuals to be infected across all the species the landscape is assumed to be a torus that is cells on the right edge are neighbors of those on the left and cells on the bottom are neighbors of those on the top this assumption avoids any spurious edge effects we considered both within and between species transmission the between species transmission rate from species j to i was described as βij cij βii βjj 2 dobson 2004 the parameter cij is a scaling parameter that allowed us to adjust the magnitude of between species transmission rate in this paper we assumed that between species transmission rates were lower than within species which reflected that species were more likely to interact with individuals of the same species woolhouse et al 2001 then given that between species transmission rate cij may vary among species pairs we selected cij from uniform distribution u 0 1 to examine the robustness of the results the scale of host interactions can occur both locally eight nearest neighbors with probability 1 gp and globally with gp zurita gutiérrez and lion 2015 a value of gp 0 indicates completely local transmission and gp 1 indicates completely global transmission whereas 0 gp 1 corresponds to a mixture of both local and global transmission we followed zurita gutiérrez and lion 2015 to calculate the force of infection of an infected individual of species i f i 1 g p j 1 n β i j q j i g p j 1 n β i j p j where n is the host species richness pj is the global density of susceptible host j and qj i is the number of susceptible individuals of species j in the eight nearest neighbors of species i fig 2 we repeated the above process 100 times and averaged these values to obtain the community level force of infection f which indicates the average number of infected individuals produced by an infected individual per unit time we used this metric f to denote as disease risk note that we were not stochastically simulating the infection process on the landscape rather we explored how intraspecific aggregation the scale of host interactions community assembly and life history trade offs affected community level disease risk f when pathogen first invaded 3 results regardless of the species distribution patterns and the scale of host interactions species richness either dilute or amplify disease risk depending on community assembly method fig 3 and s1 for the substitutive method there was a clear dilution effect of species richness on disease risk especially in the presence of life history trade offs the lower the intraspecific aggregation the more significant the dilution effect figs 3a for the additive method an increase in species richness amplified disease risk especially for lower intraspecific aggregation w 0 5 1 0 however such an amplification effect became weaker at higher intraspecific aggregation w 1 5 2 0 figs 3b these conclusions still held without life history trade offs but the strength was weaker than before figs 3c and d all the results suggested that the direction and strength of diversity on disease risk depended on community assembly and life history trade offs in order to test whether the results depended on interspecific transmission parameter cij we varied cij to follow uniform distribution u 0 1 and similar results were obtained fig s1 in addition the above results held for other transmission scale fig s2 or habitat size for example 64 64 fig s3 both host spatial distribution patterns and the scale of host interactions affect disease risk intraspecific aggregation enhanced disease risk fig s4 while increased global interactions between hosts reduced disease risk fig 4 no matter the presence or absence of life history trade offs for a given host species richness the effect of host interactions on disease risk increased with intraspecific aggregation for example when intraspecific aggregation was low w 0 5 the scale of host interactions had almost no effect on the disease risk the red lines in fig 4 the greater the intraspecific aggregation the more obvious the downward trend of disease risk it should be noted that when the scale of host interactions was entirely global gp 1 the disease risk should be independent of intraspecific aggregation w i e all f values should be converged to the same value at gp 1 however this was not the exact case in the simulations because the landscape level abundance of a species differed with different values of w due to stochasticity anyway species distribution patterns and the scale of host interactions did not contribute to the discrepancy in results that led to the debate over dilution effect both of them quantitatively but not qualitatively affect the diversity disease relationship figs 3 and 4 4 discussion using a series of spatially explicit stochastic simulations we investigated whether and how host spatial distribution patterns the presence or absence of life history trade offs community assembly rules and the scale of host interactions affected the diversity disease relationship we found that intraspecific aggregation enhanced disease risk while increased global interactions between hosts reduced disease risk however neither of them could reverse the diversity disease relationship regardless of the levels of spatial autocorrelation and the scale of host interactions diversity can either dilute or amplify disease risk depending on if community assembly is substitutive or additive method when community assembly is substitutive the dilution effect is always expected this is because the host community size is fixed regardless of species richness under this method rudolf and antonovics 2005 with an increase in species richness the added species will dilute the number high competent species and reduce effective contact between competent species and pathogens which will lead to a reduction in disease risk keesing et al 2006 this result has also been confirmed in some empirical studies mitchell et al 2002 rottstock et al 2014 where they manipulated the plant species richness with equal plot level total abundances across the plant diversity gradient so the abundances of each single plant species decrease proportionally with species richness i e substitutive assembly under the additive method higher species richness means a higher community size which leads to higher contact rate between host species and pathogens especially when disease is density dependent transmitted thus the amplification effect occurs however these scenarios are two extreme cases of real nature in fact both substitutive and additive assembly can occur during community assembly a community often starts with additive assembly and then shift to substitutive assembly as niches become more fully occupied and the intensity of competition increases therefore some studies argued that saturated assembly is more likely to be realistic mihaljevic et al 2014 which requires more theoretical and empirical researches to verify some mechanisms have been proposed to explain the dilution effect keesing et al 2006 for example susceptible host regulation is a mechanism where non hosts or incompetent hosts regulate high competent host density this mechanism explains why the dilution effect often occurs for substitutive method while the amplification effect occurs for additive method strauss et al 2015 in addition our model assumed that transmission was density dependent and excluded the possibility of transmission interference this assumption may be the main reason why these factors did not reverse the host diversity disease risk patterns since transmission interference was a dilution mechanism keesing et al 2006 furthermore some studies have shown that the more realistic disease transmission in nature varies between the two extremes with density dependent at low population densities and frequency dependent at high densities hopkins et al 2020 roberts and heesterbeek 2018 if host host contacts saturated at high host densities i e independent of total density then transmission interference should be incorporated intraspecific aggregation generally enhances disease risk because it changes the frequency of inter vs intra specific encounters so that individuals interfere more often with conspecifics boots and sasaki 2002 dobson 2004 in addition between species contact and transmission rates are lower than that of within species therefore a high degree of intraspecific aggregation will contribute to disease transmission especially when pathogen transmission mainly occur at local scales on the contrary when intraspecific aggregation is low individuals of different species are fully mixed and local species distribution patterns are almost identical to global ones in this case fig 1a therefore the scale of pathogen transmission almost had no effect on disease risk our results showed that species distribution patterns and the scale of host interactions could not reverse the diversity disease relationship which may not conflict with some previous studies for example cohen et al 2016 showed that the strength of diversity disease relationships weakens at increasingly large scale rohr et al 2019 used the meta analysis to show that scale is the primary reason for debates over the dilution effect however although we investigated different scales of transmission we measured disease risk at the whole habitat for comparison in other words only one scale i e 128 128 cells was considered in measuring disease risk in this study it should be noted that although changes in interspecific aggregation also affect the spread of the disease caron et al 2010 it was not the focus of this study the aggregation in this study was investigated at the level of individual species we generated four scenarios of species distribution patterns leaving different species similarly but independently distributed in space this model is crucial for us to understand the effects of host distribution patterns and the scale of host pathogen interactions on biodiversity disease relationship however the actual species distribution is more complicated than what we simulated rust and appel 1985 for example species could show intraspecific aggregation and interspecific segregation simultaneously stoll and prati 2001 stone and roberts 1990 and different species might differ remarkably in community wide patterns of aggregation condit et al 2000 depickère et al 2004 spatial modeling combined with real spatial distribution data may be important in the future research in addition the level of intraspecific aggregation and the scale of host interactions were assumed to be independent in natural communities however this assumption may hardly be true spatial theory suggests that intraspecific aggregation often represents a spatial genetic structure so that individuals that are tightly clumped together tend to be genetically related with each other kalisz et al 1999 stoll and prati 2001 which may enhance to local transmission of disease this study to our knowledge is the first to combine host species distribution patterns the presence or absence of life history trade offs community assembly rules and the scale of host interactions into the study of the diversity disease relationship our study clarifies that species distribution patterns and the scale of host interactions do not contribute to the discrepancy in results that lead to the debate over dilution effect highlighting the complexity of mechanisms underlying the diversity disease relationship credit authorship contribution statement lifan chen methodology software writing original draft xiang liu methodology zechen peng software shurong zhou conceptualization methodology writing review editing declaration of competing interest all authors have no conflict of interest to declare acknowledgements we greatly appreciate min su for her valuable suggestions we would like to thank prof simon queenborough at the yale university for his assistance with english language editing of the manuscript this work was supported by the national natural science foundation of china 31700466 31830009 31770518 
24753,evidence is accumulating to show that changes in host diversity can affect disease risk yet the relationship between them is still disputed understanding what factors influence this relationship will help to reconcile this debate in this paper through spatially explicit simulations we investigated the effects of host spatial distribution patterns the scale of host interactions i e local vs global interactions the presence or absence of life history trade offs and community assembly rules on the diversity disease relationship when the pathogen was a generalist the results showed that intraspecific aggregation enhanced disease risk while increased global interactions between hosts reduced disease risk for a given host species richness level the effect of the scale of host interactions on disease risk increased with intraspecific aggregation however neither species distribution patterns nor the scale of host interactions could reverse the diversity disease relationship the direction and strength of diversity on disease risk depended on community assembly and life history trade offs these results suggest that species distribution patterns and the scale of host interactions do not contribute to the discrepancy in results that lead to the debate over dilution effect highlighting the complexity of mechanisms underlying the diversity disease relationship keywords dilution effect spatial autocorrelation spatially explicit simulation life history trade offs 1 introduction with the continuing loss of diversity and the emergence of new diseases understanding the relationship between diversity and disease risk is of great importance to the maintenance and functioning of ecosystems keesing et al 2006 keesing et al 2010 the dilution effect where high host species diversity reduces disease risk has been reported for a wide range of infectious diseases clay et al 2009 suzán et al 2009 johnson et al 2013 and may be a widespread ecosystem service of biodiversity keesing and ostfeld 2012 ostfeld and keesing 2012 civitello et al 2015 however the generality of the dilution effect is still disputed randolph and dobson 2012 salkeld et al 2013 wood et al 2014 rohr et al 2019 some reports suggest that high diversity can amplify disease risk i e an amplification effect lafferty 2009 chen et al 2018 or have no influence on the outcomes of disease risk under some circumstances cardinale et al 2012 salkeld et al 2013 determining the factors that influence the diversity disease relationship may help to reconcile this debate such as host spatial distribution scale of host interactions and host competence many previous theoretical studies on multi host pathogen systems often use spatially implicit models with the assumption that all hosts live in a well mixed non spatially structured habitat dobson 2004 andy and pedersen 2005 however this assumption can rarely be met in nature many field studies found that species can be aggregated random or regularly distributed within or among other species in space levine and murrell 2003 liu et al 2013 zhang et al 2013 for example plant species are often intra specifically aggregated in tibetan plateau meadow vegetation liu et al 2013 stoll and prati 2001 experimentally established a community of interspecifically aggregated plants to compare it with one of randomly dispersed plants to elucidate the precise consequences of intraspecific aggregation on species interactions the spatial distribution of host species can alter disease transmission by affecting host movements the distribution of hosts and or vectors micro environments and species interactions boots and sasaki 2002 estrada peña et al 2014 all of which potentially have profound influences on the diversity disease relationship for example craft et al 2008 used a spatially explicit stochastic sir model to examine the dynamics of disease transmission involving one to three sympatric species with contrasting social organizations e g isolation or connected territorial structures and the results showed that differences in social structure could significantly influence the size and velocity of an epidemic and social structures that permit higher intraspecific transmission were more likely to transmit disease to other species further huang et al 2015 discussed the role of habitat fragmentation and showed that increased connectivity between patches can either dilute or amplify the spread of disease depending on the competence the ability to obtain and transmit diseases of the added host species the scale of host interactions is important for disease transmission boots and mealor 2007 webb et al 2007 wodarz et al 2013 wilber et al 2020 for many human and animal populations global interactions where an agent can interact with any other agent in the system between individuals might be a good approximation but for terrestrial plants many marine invertebrates corals and other sessile organisms each individual can only interact with a subset of individuals within a certain range due to spatially restricted interactions tilman and peter 1997 webb et al 2007 the scale of host interactions has proven critical in determining the stability and persistence of the system for example wodarz 2013 studied the persistence of host pathogen systems in two extreme cases of completely local transmission and completely global transmission and found that local transmission promoted population extinction more than the global case webb 2007 thought that realistic interactions likely lie between these two extremes so they used a multi scale pair approximation model to explore the effects of transmission scale on host parasite dynamics the results showed that local transmission led to reduced persistence of disease and a greater possibility of pathogen driven extinction up until now how the scale of host interactions and species distribution patterns affect diversity disease relationship remain poorly understood in addition to the scale of host interactions and spatial distribution patterns it is poorly understood how host competence contributes to the diversity disease relationship especially given that it varies widely among species logiudice et al 2003 life history theory suggests that increased investment in growth and reproduction often comes at the cost of reduced investment into defense against pathogens martin ii et al 2006 lee et al 2008 therefore species with higher abundance often have higher competence and lower extinction risk johnson et al 2012 joseph et al 2013 which is considered a prerequisite for the dilution effect in addition many studies showed that the effect of diversity on disease risk depended on community assembly how community size varies with species richness rohr et al 2019 community assembly can range from substitutive in which individuals of a new species replace individuals of existing species in a community to additive in which adding new species adds more individuals to a community rudolf and antonovics 2005 however the influence of life history trade offs and community assembly rules on disease risk under different spatial patterns remains unclear in this paper we used spatially explicit simulations to investigate the effects of host species distribution patterns the scale of host interactions the presence or absence of life history trade offs and community assembly rules on the diversity disease relationship when the pathogen is a generalist we expect that global scale of host interactions will dilute disease risk while intraspecific aggregation will amplify disease risk especially when pathogen transmission mainly occurs at local scales community assembly rules and life history trade offs may affect the direction or strength of diversity disease relationship 2 materials and methods spatially explicit stochastic simulations were used to study the disease transmission in a spatially structured multi host community the habitat was divided into a two dimensional lattice of 128 128 cells but different habitat sizes did not change the basic results reported below where each cell contained at most one host individual of any species the detailed simulations were as follows 2 1 generating different species distribution patterns at each species richness level the spatial distribution patterns of hosts were generated in two steps first we used the recursive quadtree subdivision algorithm to generate spatially autocorrelated habitat matrix h gu et al 2002 rybicki and hanski 2013 spatial autocorrelation indicates that the relationship between given variables is a function of their spatial distance or position dale et al 2002 the detailed process of the above algorithm was as follows we divided the landscape into four rectangles and randomly selected a value from a uniform distribution 0 1 for each of the four rectangles the division was continued until each sub area reached the size of a single cell that could not be divided further for example for a square landscape of size 2 d 2 d for some positive integer d the habitat is divided into four equal sub squares a1 1 a1 2 a1 3 a1 4 having values of x11 x14 that are randomly chosen from a uniform distribution 0 1 then after k recursions 4k new rectangles ak 1 ak 2 ak 4 k were created for each ak i we randomly selected corresponding xk i from a uniform distribution 0 1 finally when d steps are finished the value h i j of grid cell i j is h i j 1 w k 1 d l 1 4 k i j a k l w k x k l where wk w k is the weight at scale k and w wk is used to normalize the values of h i j into 0 1 here i j a k l is an indicator function if i j ak l i j ak l 1 otherwise it equals to 0 the single parameter w is used to control the scale of spatial autocorrelation of habitat the larger w is the greater the level of spatial autocorrelation and vice versa in this paper we considered values of 0 5 1 0 1 5 and 2 0 for w to denote four different spatial autocorrelation cases for each w we repeated above processes 1000 times to generate 1000 different habitats to minimize random effects note that in this step we only generated empty habitats with spatial autocorrelation without any species in them second we filled these empty habitats with species to generate different species distribution patterns suppose there were 10 species in the community initially for each w we grouped cells as follows 0 h i j 1 10 1 10 h i j 2 10 9 10 h i j 1 counted the total number of cells of each group and sorted them in descending order then let species i occupy the cells with abundance ranked i th i 1 2 10 therefore the abundance of species i was the total number of cells ranked in the i th species 1 was the most abundant and species 10 was the least in this way when w takes 0 5 1 0 1 5 and 2 0 respectively we obtained four species distribution patterns with species richness of 10 from the above process the levels of spatial autocorrelation can be used to characterize species distribution patterns the higher the spatial autocorrelation level w the higher degree of intraspecific aggregation in contrast when spatial autocorrelation level is low individuals of different species tend to be mixed fig 1 illustrated four distribution patterns when species richness was 10 next we removed species from the above community to create a species richness gradient the results were not sensitive to whether one or two species were removed at a time yet computational time increased rapidly with the number of removals therefore we generated a species richness gradient of 10 8 6 4 and 2 the order in which species were removed was determined by the presence or absence of a life history trade off according to life history theory the most abundant species has the lowest extinction risk therefore if a life history trade off exists the removed species were the least abundant species otherwise species were removed randomly in each case presence or absence of trade offs we considered two scenarios of community assembly substitutive method and additive method in substitutive method community size was fixed independent of species richness to achieve this a compensatory increase proportional to each extant species abundance after species removal was performed for example when 2 species were removed the abundance and distribution of the extant 8 species were determined as follows firstly the cells were divided into 8 groups 0 h i j 1 8 1 8 h i j 2 8 7 8 h i j 1 secondly we counted the total number of cells of each group and sorted them in descending order then let species i occupied the cells with abundance ranked i th i 1 2 8 the substitutive method was analogous to the field experiment of fixing the size of the host community to isolate the effect of host richness or the situation under which the resource was limited so that the maximum number of hosts supported by the resource was fixed chen and zhou 2015 in the additive method community size was positively related to species richness so the abundance and distributions of each extant species were not changed before and after species removal this situation corresponded to cases where the total resource was adequate the total number of hosts in the community increased with host species richness or controlled experiment designs for example using a removal experiment in an alpine meadow liu et al 2016 created a plant biodiversity gradient by manipulating plot level plant diversity with equal abundance of each single plant species across the biodiversity gradient i e additive assembly 2 2 measurement of disease risk as we mentioned above when a life history trade off exists the most abundant species are the most competent and so on to simulate this we drew intraspecific transmission rates βii from the uniform distribution u 0 5 sorted in descending order and then assigned them to each species in addition we also randomized the relationship between βii and species abundance to simulate the situation when the life history trade offs did not exist then in each case 5 species richness levels and 4 spatial autocorrelation levels combined to produce 20 different cases we randomly selected 10 individuals to be infected across all the species the landscape is assumed to be a torus that is cells on the right edge are neighbors of those on the left and cells on the bottom are neighbors of those on the top this assumption avoids any spurious edge effects we considered both within and between species transmission the between species transmission rate from species j to i was described as βij cij βii βjj 2 dobson 2004 the parameter cij is a scaling parameter that allowed us to adjust the magnitude of between species transmission rate in this paper we assumed that between species transmission rates were lower than within species which reflected that species were more likely to interact with individuals of the same species woolhouse et al 2001 then given that between species transmission rate cij may vary among species pairs we selected cij from uniform distribution u 0 1 to examine the robustness of the results the scale of host interactions can occur both locally eight nearest neighbors with probability 1 gp and globally with gp zurita gutiérrez and lion 2015 a value of gp 0 indicates completely local transmission and gp 1 indicates completely global transmission whereas 0 gp 1 corresponds to a mixture of both local and global transmission we followed zurita gutiérrez and lion 2015 to calculate the force of infection of an infected individual of species i f i 1 g p j 1 n β i j q j i g p j 1 n β i j p j where n is the host species richness pj is the global density of susceptible host j and qj i is the number of susceptible individuals of species j in the eight nearest neighbors of species i fig 2 we repeated the above process 100 times and averaged these values to obtain the community level force of infection f which indicates the average number of infected individuals produced by an infected individual per unit time we used this metric f to denote as disease risk note that we were not stochastically simulating the infection process on the landscape rather we explored how intraspecific aggregation the scale of host interactions community assembly and life history trade offs affected community level disease risk f when pathogen first invaded 3 results regardless of the species distribution patterns and the scale of host interactions species richness either dilute or amplify disease risk depending on community assembly method fig 3 and s1 for the substitutive method there was a clear dilution effect of species richness on disease risk especially in the presence of life history trade offs the lower the intraspecific aggregation the more significant the dilution effect figs 3a for the additive method an increase in species richness amplified disease risk especially for lower intraspecific aggregation w 0 5 1 0 however such an amplification effect became weaker at higher intraspecific aggregation w 1 5 2 0 figs 3b these conclusions still held without life history trade offs but the strength was weaker than before figs 3c and d all the results suggested that the direction and strength of diversity on disease risk depended on community assembly and life history trade offs in order to test whether the results depended on interspecific transmission parameter cij we varied cij to follow uniform distribution u 0 1 and similar results were obtained fig s1 in addition the above results held for other transmission scale fig s2 or habitat size for example 64 64 fig s3 both host spatial distribution patterns and the scale of host interactions affect disease risk intraspecific aggregation enhanced disease risk fig s4 while increased global interactions between hosts reduced disease risk fig 4 no matter the presence or absence of life history trade offs for a given host species richness the effect of host interactions on disease risk increased with intraspecific aggregation for example when intraspecific aggregation was low w 0 5 the scale of host interactions had almost no effect on the disease risk the red lines in fig 4 the greater the intraspecific aggregation the more obvious the downward trend of disease risk it should be noted that when the scale of host interactions was entirely global gp 1 the disease risk should be independent of intraspecific aggregation w i e all f values should be converged to the same value at gp 1 however this was not the exact case in the simulations because the landscape level abundance of a species differed with different values of w due to stochasticity anyway species distribution patterns and the scale of host interactions did not contribute to the discrepancy in results that led to the debate over dilution effect both of them quantitatively but not qualitatively affect the diversity disease relationship figs 3 and 4 4 discussion using a series of spatially explicit stochastic simulations we investigated whether and how host spatial distribution patterns the presence or absence of life history trade offs community assembly rules and the scale of host interactions affected the diversity disease relationship we found that intraspecific aggregation enhanced disease risk while increased global interactions between hosts reduced disease risk however neither of them could reverse the diversity disease relationship regardless of the levels of spatial autocorrelation and the scale of host interactions diversity can either dilute or amplify disease risk depending on if community assembly is substitutive or additive method when community assembly is substitutive the dilution effect is always expected this is because the host community size is fixed regardless of species richness under this method rudolf and antonovics 2005 with an increase in species richness the added species will dilute the number high competent species and reduce effective contact between competent species and pathogens which will lead to a reduction in disease risk keesing et al 2006 this result has also been confirmed in some empirical studies mitchell et al 2002 rottstock et al 2014 where they manipulated the plant species richness with equal plot level total abundances across the plant diversity gradient so the abundances of each single plant species decrease proportionally with species richness i e substitutive assembly under the additive method higher species richness means a higher community size which leads to higher contact rate between host species and pathogens especially when disease is density dependent transmitted thus the amplification effect occurs however these scenarios are two extreme cases of real nature in fact both substitutive and additive assembly can occur during community assembly a community often starts with additive assembly and then shift to substitutive assembly as niches become more fully occupied and the intensity of competition increases therefore some studies argued that saturated assembly is more likely to be realistic mihaljevic et al 2014 which requires more theoretical and empirical researches to verify some mechanisms have been proposed to explain the dilution effect keesing et al 2006 for example susceptible host regulation is a mechanism where non hosts or incompetent hosts regulate high competent host density this mechanism explains why the dilution effect often occurs for substitutive method while the amplification effect occurs for additive method strauss et al 2015 in addition our model assumed that transmission was density dependent and excluded the possibility of transmission interference this assumption may be the main reason why these factors did not reverse the host diversity disease risk patterns since transmission interference was a dilution mechanism keesing et al 2006 furthermore some studies have shown that the more realistic disease transmission in nature varies between the two extremes with density dependent at low population densities and frequency dependent at high densities hopkins et al 2020 roberts and heesterbeek 2018 if host host contacts saturated at high host densities i e independent of total density then transmission interference should be incorporated intraspecific aggregation generally enhances disease risk because it changes the frequency of inter vs intra specific encounters so that individuals interfere more often with conspecifics boots and sasaki 2002 dobson 2004 in addition between species contact and transmission rates are lower than that of within species therefore a high degree of intraspecific aggregation will contribute to disease transmission especially when pathogen transmission mainly occur at local scales on the contrary when intraspecific aggregation is low individuals of different species are fully mixed and local species distribution patterns are almost identical to global ones in this case fig 1a therefore the scale of pathogen transmission almost had no effect on disease risk our results showed that species distribution patterns and the scale of host interactions could not reverse the diversity disease relationship which may not conflict with some previous studies for example cohen et al 2016 showed that the strength of diversity disease relationships weakens at increasingly large scale rohr et al 2019 used the meta analysis to show that scale is the primary reason for debates over the dilution effect however although we investigated different scales of transmission we measured disease risk at the whole habitat for comparison in other words only one scale i e 128 128 cells was considered in measuring disease risk in this study it should be noted that although changes in interspecific aggregation also affect the spread of the disease caron et al 2010 it was not the focus of this study the aggregation in this study was investigated at the level of individual species we generated four scenarios of species distribution patterns leaving different species similarly but independently distributed in space this model is crucial for us to understand the effects of host distribution patterns and the scale of host pathogen interactions on biodiversity disease relationship however the actual species distribution is more complicated than what we simulated rust and appel 1985 for example species could show intraspecific aggregation and interspecific segregation simultaneously stoll and prati 2001 stone and roberts 1990 and different species might differ remarkably in community wide patterns of aggregation condit et al 2000 depickère et al 2004 spatial modeling combined with real spatial distribution data may be important in the future research in addition the level of intraspecific aggregation and the scale of host interactions were assumed to be independent in natural communities however this assumption may hardly be true spatial theory suggests that intraspecific aggregation often represents a spatial genetic structure so that individuals that are tightly clumped together tend to be genetically related with each other kalisz et al 1999 stoll and prati 2001 which may enhance to local transmission of disease this study to our knowledge is the first to combine host species distribution patterns the presence or absence of life history trade offs community assembly rules and the scale of host interactions into the study of the diversity disease relationship our study clarifies that species distribution patterns and the scale of host interactions do not contribute to the discrepancy in results that lead to the debate over dilution effect highlighting the complexity of mechanisms underlying the diversity disease relationship credit authorship contribution statement lifan chen methodology software writing original draft xiang liu methodology zechen peng software shurong zhou conceptualization methodology writing review editing declaration of competing interest all authors have no conflict of interest to declare acknowledgements we greatly appreciate min su for her valuable suggestions we would like to thank prof simon queenborough at the yale university for his assistance with english language editing of the manuscript this work was supported by the national natural science foundation of china 31700466 31830009 31770518 
24754,it is critical to have long term carbon dioxide co2 flux observations in forest ecosystems to understand how changing climate can affect forest carbon c stocks and co2 exchange between forests and the atmosphere in this study fifteen years 2002 2016 of continuous eddy covariance flux and climate measurements in an intermediate aged douglas fir stand on the east coast of vancouver island canada were analyzed first the eddy covariance measured co2 fluxes were partitioned into gross primary production and ecosystem respiration using two artificial neural networks second the responses of net ecosystem production gross primary production and ecosystem respiration to interannual climate variability including five el niño southern oscillation events were determined three hyper parameters number of layers hidden units and batch size of each artificial neural network were set by bayesian optimization using sequential model based optimization while the remaining hyper parameters were taken from the literature the first artificial neural network was fitted using only nighttime co2 flux data and applied to estimate nighttime and daytime ecosystem respiration values and the second one was used to gap fill gross primary production values in addition a predictor analysis was done to investigate the most influential predictors i e environmental variables within seasons and years when applied to half hourly data the ecosystem respiration model had an r2 of 0 43 whereas the gross primary production model had an r2 of 0 80 the stand was a moderate c sink average net ecosystem production of 118 404 g c m 2 year 1 during the entire study period except for the years 2002 2006 when the stand was a moderate c source the mean annual values of gross primary production and ecosystem respiration were 1649 157 g c m 2 year 1 and 1531 410 g c m 2 year 1 respectively our analysis showed that soil temperature was the most important predictor for the ecosystem respiration model and photosynthetically active irradiance was the most important predictor for the gross primary production model however during dry periods in late summer soil moisture became the most important predictor interannual variability of net ecosystem production was only slightly affected by annual total precipitation mean soil temperature and mean air temperature instead it depended on spring mean air temperature start of the growing season summer total precipitation indicative of water deficiency and mean summer air temperature el niño and la niña events generally resulted in lower and higher annual net ecosystem production respectively keywords artificial neural network net ecosystem exchange partitioning eddy covariance douglas fir el niño predictor analysis 1 introduction globally forest ecosystems are the largest land carbon c sink and they account for more than half of the c stored in terrestrial ecosystems hui et al 2015 understanding the role of forest ecosystems in the global c cycle is critical to projecting the future strength of the land c sink and its effect on future climate change thus it is urgent to have a better understanding of how climate change may influence forest c stocks and carbon dioxide co2 exchange between forests and the atmosphere froelich et al 2015 this requires measurements of net ecosystem production nep and estimation of its partitioned components gross primary production gpp and ecosystem respiration r e and knowledge of the biotic and climatic factors influencing them stand level co2 fluxes from forest stands can be directly measured using the eddy covariance ec technique baldocchi and meyers 1988 with more long term ec datasets it is possible to assess the responses of forest ecosystems to climate variability climate change and disturbance aubinet et al 2018 baldocchi et al 2018 oishi et al 2018 teets et al 2018 to improve our understanding of environmental effects on forest growth trajectories pinnington et al 2017 xu et al 2017 and to improve ecosystem c dynamics models richardson et al 2010 a broad variety of approaches for partitioning nep into r e and gpp has been developed and applied in the literature the most common partitioning approaches can be roughly divided into those using only nighttime data to establish empirical relationships between r e and soil or air temperature followed by determining daytime r e using these relationships and using daytime intercept of the nep vs photosynthetically active irradiance q relationship and nighttime data for estimating daytime and nighttime r e respectively aubinet et al 2012 jassal et al 2007 keenan et al 2019 lee et al 2020 gap filling of gpp is usually done using methods such as the michaelis menten equation look up tables and monte carlo techniques moffat et al 2007 recently attention has been directed toward designing testing and applying artificial neural network ann models to identify environmental controls for better understanding of how trace gas fluxes may respond to environmental changes liu et al 2018 the ann technique is a powerful tool for accounting for the controls of trace gas fluxes because of its ability to process information in a non linear manner beale and jackson 1990 raiche 1991 which enables completely unconstrained optimization and determination of input output responses demuth et al 1994 kosko 1992 schulz and härtling 2003 in addition moffat et al 2007 have pointed out that anns are one of the best methods for partitioning and gap filling ec measured co2 flux data furthermore the ann model does not rely on pre described functional relationships with a limited number of environmental drivers this allows the impact of different environmental factors on r e gpp and nep to be evaluated few studies have used anns for this purpose for forest sites dou et al 2015 moffat et al 2007 papale and valentini 2003 pau et al 2018 and non forest sites baldocchi et al 2015 knox et al 2015 safa et al 2019 wen et al 2014 however most of these studies used a simple ann architecture and applied a straightforward trial and error method to determine the optimal hyper parameter composition such as the number of layers and hidden units baldocchi et al 2015 dou et al 2015 papale and valentini 2003 in this study we used a bayesian optimization approach to investigate the optimal hyper parameter composition to develop two anns that explain environmental and physiological constraints on co2 fluxes using a long term 15 year dataset from an intermediate aged coastal douglas fir stand the specific objectives were to 1 partition and gap fill the 15 years of ec measured nee data using the ann technique and compare it with an established method that uses the daytime intercept approach on the same dataset lee et al 2020 2 identify the environmental factors controlling the co2 fluxes using a predictor analysis and 3 determine changes in forest atmosphere co2 exchange in response to interannual climate variability including el niño southern oscillation enso events 2 material and methods 2 1 study site and instrumentation the study site is part of a chronosequence of three different aged douglas fir stands on the east coast of vancouver island bc canada in this study 15 years 2002 2016 of data from the middle aged stand hdf88 ameriflux site id ca ca3 were analyzed hdf88 was planted in 1988 75 douglas fir 21 western red cedar and 4 grand fir after the previous stand was clear cut and burned in 1987 the understory contains mainly deciduous and evergreen species such as fireweed epilobium angustifolium l s l sword polystichum munitum kaulf c presl and bracken fern pteridium aquilinum l kuhn salal gaultheria shallon pursh rubus spp and red huckleberry vaccinium parvifolium sm jassal et al 2012 the study site is located at an elevation of 170 m above sea level around 3 1 km off the coastline of the salish sea humphreys et al 2006 the soil at the site is classified as a humo ferric podzol with a gravelly loam texture krishnan et al 2009 the site is categorized as seasonally dry temperate rainforest and is located in the coastal western hemlock biogeoclimatic zone meidinger and pojar 1991 mean annual air temperature t a and precipitation p over the15 years of the study period were 8 9 c and 1569 mm respectively the growing season lasts from march to october the dominant wind direction is affected by anabatic katabatic air flow and the land sea circulation between the salish sea and vancouver island the flux tower 21 m height was built in 2001 at the study site to provide continuous flux and climate measurements throughout the ec technique was used to continuously measure turbulent fluxes of co2 which were aggregated into half hourly fluxes f c turbulent fluxes were measured above the canopy with the measurement height being raised over time 12 m for 2001 to 2005 15 m for 2006 to june 2015 21 m for july 2015 to december 2016 due to increasing tree height three axis sonic anemometers model r3 gill instruments ltd lymington uk with an open path infrared gas co2 h2o analyzer irga li 7500 li cor inc lincoln ne usa from 2001 to 2003 september and a closed path irga li 7000 li cor inc lincoln ne usa from october 2003 to december 2016 were used for measuring vertical wind speed w and co2 mixing ratio s c respectively f c was corrected by adding the estimated rate of change in co2 storage in the air column below the ec sensor height to obtain the net ecosystem exchange nee hollinger et al 1994 morgenstern et al 2004 nep was calculated as nep nee besides ec measurements continuous measurements of several environmental variables were made a housed fan aspirated radiation shield model 076b met one instruments inc grants pass or usa temperature and humidity probe model hmp 35c vaisala oyj helsinki finland at the height of the ec instrumentation was used to measure t a and relative humidity jassal et al 2009 in addition half hourly profile measurements of volumetric soil water content θ s 4 12 45 and 85 cm depths and soil temperature t s 5 10 20 50 and 100 cm depths were made model cs 615 campbell scientific inc csi logan ut usa and copper constantan thermocouples respectively jassal et al 2010 additionally soil water storage was estimated considering the depth down to 100 cm soil depth p was measured using two tipping bucket rain gauges model 2501 sierra misco berkeley ca usa one was mounted on the flux tower just above the canopy and one on the ground in an opening in the stand the gage in the opening was modified with a snowfall adapter model cs705 csi to allow measurements of p as snow jassal et al 2010 photosynthetically active irradiance photon flux density q was measured on the tower 3 m above the height of the ec instrumentation with a quantum sensor model li 190sb li cor inc jassal et al 2012 a net radiometer model cnr1 kipp and zonen deft the netherlands was installed on top of the tower to measure upwelling and downwelling shortwave and longwave radiation sw sw lw lw in addition climate data from an adjacent environment canada weather station comox airport dnd 2018 were used for climate analysis 2 2 data preprocessing the collected ec and environmental data were subjected to a comprehensive processing and quality control that flagged suspicious data thresholds and limits of the quality control and the percentage of occurrence of each variable are shown in table 1 data points exceeding these limits were flagged measured values of relative humidity between 100 and 105 were set to 100 considering measurement errors whereas relative humidity values 105 were flagged afterwards the flagged or missing values were replaced by simple linear interpolation gaps shorter than 6 h or recalculated by linear regression models gaps longer than 6 h table a 1 shows the response and explanatory variables used in the linear regression models this was done to keep the number of values of each variable constant since incomplete half hourly data cannot be used to train anns all linear regression models were fitted using a normal distribution for the response variable except for relative humidity which followed a beta distribution for relative humidity and t a data from comox airport were used to improve the model fit of the linear regression models data from comox airport had an hourly resolution as the data from the study site had a half hourly resolution half hourly data from the comox airport were generated by interpolation of hourly values the percentage of data that were missing i e gaps were the highest for relative humidity at 11 62 whereas t a and t s had virtually no gaps 0 01 to account for possible measurement errors when q was 0 μmol m 2 s 1 and 5 μmol m 2 s 1 these values were set to 0 μmol m 2 s 1 the regression models for lw and sw followed a log normal distribution whereas sw and lw followed a normal distribution missing wind speed p and sw data were not gap filled since they were not used as model predictors nighttime r e r en was provided from nighttime nee nep under well mixed conditions u 0 19 m s 1 jassal et al 2012 u was calculated from the covariance of w and the horizontal wind velocity components aubinet et al 2012 nighttime was defined as the period with half hourly average q 5 μmol m 2 s 1 ec measured flux data had 16 03 gaps before u correction that needed to be filled one additional predictor was created for each of θ s and t s by simple averaging these for all soil depths θ s t s additional predictors were created based on seasonal and diurnal patterns of p the p sum of the past 30 days precip 30d and hours since the last p event h last precip were calculated because they represent the current soil moisture and humidity conditions better than half hourly p values the sum of the past 30 days was chosen because it takes recent dry periods into account which could have an effect on present c fluxes a sensitivity analysis to determine the optimal number of days was not carried out for computational costs in addition to take potential radiation day of year seasonality and day length into account three supplementary predictors were added papale and valentini 2003 these predictors were created by applying a complete sine curve 2π on annual and daily bases to add separated periodic information besides diurnally and annually fluctuating temperatures and radiative predictors one curve was fitted for solely the seasonal patterns oscillating between summer and winter year ws sin without diurnal fluctuations the diurnal sine curve oscillates only between midday and midnight day sin without seasonality a third sine curve was added to account for a potential annual hysteresis that accounts for the seasonal offset of the r e and gpp activity between spring and autumn this curve oscillates between spring and autumn year sa sin 2 3 ann model development the keras package for r chollet and allaire 2017 core team 2013 originally a python python software foundation https www python org library keras chollet et al 2015 was used the package gives an optimal framework using tensorflow for building a user specific network with a wide variety of adjustable features hyper parameters for specific model tuning and provides a good structure for regression problems 2 3 1 evaluation metric as model evaluation metric mean squared error mse was used the mse was calculated by 5 fold cross validation james et al 2013 kuhn and johnson 2013 for that purpose the model dataset was split into five randomly drawn datasets four folds were used as a training dataset 80 for the ann models whereas the remaining fold 20 were split in two equal groups one as validation dataset and one as test dataset the validation dataset was necessary to evaluate the training process of the anns by giving feedback on how the anns performed on the validation dataset chollet and allaire 2018 at the end of the training process the mse was calculated for the test dataset this was done by using the trained model to predict values on the test dataset yi r en or gpp with yi and the observed values from the test dataset y i the mse was calculated as follows 1 mse 1 n i 1 n y i y i 2 from the five folds of the cross validation every fold was used once as validation and test data the 5 fold cross validation was repeated to gain more precise information about model accuracy for the predictor pre analysis the 5 fold cross validation was repeated ten times six times for the hyper parameter analysis and four times for the following stepwise predictor analysis this scheme was chosen because of increasing computational costs of the different model steps the calculated mses were averaged the model with the lowest mse was chosen for further analysis 2 3 2 data preparation and predictor pre selection prior to model selection the data needed to be prepared for the ann predictors had to be normalized hastie et al 2009 for this purpose different data normalization methods were tested in which the standardization method mean 0 standard deviation 1 showed the best results i e with the lowest mse the predictors were first split into three folds training 80 test 10 and evaluation folds 10 chollet and allaire 2018 the mean and standard deviation of the training fold were calculated and used for the standardization of the training test and evaluation folds chollet and allaire 2018 to prevent a biased training process towards higher data coverage of certain environmental conditions or seasons previous work has clustered the data baldocchi et al 2015 knox et al 2015 aiming to prevent this bias we conducted a k means cluster analysis to cluster the data by nep the data were divided into four natural clusters by the cluster algorithm nep cluster means were 1 59 μmol m 2 s 1 4 02 μmol m 2 s 1 7 53 μmol m 2 s 1 and 14 51 μmol m 2 s 1 and sizes were 51 33 14 and 2 respectively a combination of each cluster subset was used as an alternative dataset to the full dataset rasmussen and williams 2005 however in this study the un clustered dataset had a lower mse 4 74 μmol m 2 s 1 2 than the clustered dataset 16 95 μmol m 2 s 1 2 thus the un clustered dataset was selected for the modeling process after data preparation two simple anns one with t s and one with θ s as predictors were run to determine which soil depths t s and θ swere the most influential and to avoid highly correlated predictors therefore a small ann was set up with two layers containing 40 hidden units in the first layer and 20 hidden units in the second layer with a batch size of 30 the remaining hyper parameters were the same as for the main models 2 3 3 hyper parameter optimization and predictor analysis in the next step the r en model was optimized ann 1 in fig 1 therefore a sequential ann linear stack of layers was set up the best hyper parameter composition was determined by bayesian optimization specifically by a sequential model based optimization based on gaussian process models appendix b bergstra et al 2011 brochu et al 2010 rasmussen and williams 2005 the advantage of bayesian optimization approaches over grid or random searches is that bayesian approaches take past evaluation results into account to improve the sampling method in the next step bergstra et al 2011 this means less model evaluations are needed to find the best hyper parameter set brochu et al 2010 sequential model based optimization was applied to obtain three hyper parameters layers hidden units and batch size whereas the remaining hyper parameters were taken from the literature see table 2 the optimization suggested an ann architecture for the r en model with two layers 59 hidden units and a batch size of 62 after the hyper parameter composition with lowest mse was found a forward selection of the predictors was done to investigate the most influential predictors of the r en model see appendix c daytime r e values were modeled by this r en model gpp was then calculated as gpp r e nep when measured daytime nep was available a gpp model was developed by applying the same procedure hyper parameter optimization and predictor analysis as used for the r en model ann 2 in fig 1 the ann architecture with the lowest mse for the gpp model had three layers 145 hidden units and a batch size of 83 with this model gaps in the gpp data were filled finally gaps in nep and nee were calculated with complete r e and gpp data the predictors used for both models are shown in table 1 2 3 4 model evaluation model evaluation and model error estimation were done by bootstrapping the best model structure and predictor subset hastie et al 2009 100 datasets were randomly drawn each ann was trained with every single dataset and predictions were made the mean standard deviation and 95 confidence intervals of the predictions from 100 bootstrap replications were calculated with the mean representing the estimated value of the model the total error was calculated using model and random errors the 95 confidence interval was used as model error random error was calculated by applying a 20 random uncertainty to the measured values of nee which is a typical random error reported for ec measurements of co2 fluxes in the literature morgenstern et al 2004 2 4 analysis of enso effect to investigate whether enso events have an impact on nep or not the relationships between co2 fluxes annual gpp r e and nep and spring march may and summer june september total p and average t a were investigated for this purpose spearman s rank correlation coefficient spearman s ρ of annual spring and summer total p and average t a was calculated to quantify the effect of seasonal weather conditions on annual totals table d 1 spearman s ρ is a nonparametric measure of rank correlation and was chosen because the correlation coefficient is calculated only for a monotonic relationship and not for a linear relationship alvo and yu 2014 3 results 3 1 climate the 30 year 1981 to 2010 mean annual t a at the nearby comox airport was 10 0 c whereas the mean annual t a during the study period 2002 to 2016 was slightly higher at 10 2 c in particular the years at the beginning of the measurement period were the coldest with both 2008 and 2011 at 9 4 c while years towards the end were warmest 11 0 c in 2014 and 11 3 c in 2015 fig 2 the mean annual p during the study period was 1148 mm which is similar to the 30 year mean value of 1153 mm at comox airport in 2008 and 2013 the site was dry with only 70 of the mean annual p whereas the year 2016 was unusually wet with 145 of the mean annual p between 2002 and 2016 two strong la niña events 2007 2008 and 2010 2012 and three strong el niño events 2002 2003 2009 2010 and 2014 2016 occurred climate prediction center 2019 even with these events starting and ending in the middle of the year mean annual t a was higher during el niño years and lower during la niña years monthly mean t a and monthly p for the study period are shown in fig 3 it can be clearly seen that almost all months except march april and september were 0 2 c to 0 4 c warmer than the 30 year averages p during the summer months was lower than 30 year average by a few mm 10 25 3 2 annual seasonal and monthly nep r e and gpp the mean annual totals based on ann modeling over the 15 year study period were 118 404 g c m 2 year 1 for nep 1649 157 g c m 2 year 1 for gpp and 1531 410 g c m 2 year 1 for r e fig 4 from 2002 to 2004 annual nep was approximately 200 g c m 2 year 1 and thus the forest was a moderate c source fig 4 a in 2005 and 2006 nep was close to zero before the stand became a c sink starting in 2007 with the highest c sequestration occurring in 2012 368 444 g c m 2 year 1 after 2012 nep decreased slightly before it increased again in 2016 gpp increased from 2003 to 2007 except 2006 before it started to fluctuate at a higher level between 1650 and 1860 g c m 2 year 1 fig 4 b r e totals did not show a clear trend over the 15 years and fluctuated between 1400 and 1660 g c m 2 year 1 fig 4 c annual nep values calculated by lee et al 2020 and those obtained using the anns showed similar temporal patterns however regarding the uncertainty analysis only modeled gpp showed different results within uncertainty ann modelled nep was slightly lower average of 150 g c m 2 year 1 than that obtained using the traditional gap filling approach employed by lee et al 2020 this was because the difference between ann estimated r e and that obtained by lee et al 2020 was generally slightly larger than the difference between ann estimated gpp and that obtained by lee et al 2020 the ecosystem acted as a c sink from march to august and as a c source from september to february with ann modeling indicating that the highest c sequestration rate nep was in june 72 47 g c m 2 month 1 and the highest c net emission rate was in october 44 42 g c m 2 month 1 fig 5 a the error estimations of ann modelled nep were higher in summer than in winter monthly gpp increased from january to june and decreased from june to december with the highest monthly ann modelled value of 287 20 g c m 2 month 1 and the lowest monthly value of 33 9 g c m 2 month 1 fig 5 b r e response to meteorological conditions was somewhat slower compared to gpp this is recognizable due to the hysteresis effect such that r e takes longer than gpp to decrease in autumn fig 5 c the highest ann modelled r e was observed in june 215 54 g c m 2 month 1 while monthly r e remained relatively high until october the lowest r e was in january 54 15 g c m 2 month 1 the estimated error in r e was larger in summer than in winter in comparison with the results from lee et al 2020 the findings for annual and monthly totals were quite similar especially regarding the uncertainty analysis nep gpp and r e totals were largely consistent except of gpp and r e estimations in early summer and autumn 3 3 environmental controls 3 3 1 controls on annual and seasonal gpp among the environmental controls of annual gpp q was ranked first and lw was ranked third for almost all different modeled windows fig 6 however lw was not relevant in the first two years of the study period rank 11 and 13 respectively lw was relevant in almost all years except for 2004 2005 and from 2011 to 2013 values for 2011 2012 and 2012 2013 t s did not have a high rank except for 2004 2005 θ s and lw were irrelevant in 2004 2005 whereas t s was ranked second in these years θ s was more important during 2002 2004 and 2011 2013 the model accuracy r2 varied between 0 36 and 0 71 for the most important predictor and 0 68 0 92 for the five predictors with r2 for the entire study period being 0 80 at the monthly scale fig 7 shows the five most important predictors of the gpp model as expected q was the single most important factor controlling gpp followed by lw and lw during the summer months θ s was less important in the gpp model in fact θ s and lw had the least explanatory power in june and september respectively when they both ranked last t s was ranked high from january to march lw was almost ranked second or third except for february and march the gpp model showed no seasonality in model accuracy moreover the model accuracy increased appreciably by adding more predictors r2 of 0 8 3 3 2 controls on annual and seasonal r e among environmental controls of annual r e the five most important predictors in the moving window r en models were t s θ s lw year sa sin and year ws sin fig 8 as expected t s was the predictor describing the most variance for every computed window ranks of the remaining four predictors out of the best five varied in the years 2008 2009 and 2011 2013 θ s was the second most important predictor however θ s was less relevant in years 2004 2005 and 2015 2016 in years 2002 2003 and 2007 2008 lw was ranked low before it became more important in the second half of the study period the sine functions which represent seasonality had their lowest ranks in years 2008 2010 but were of higher importance in the first half of the study period from 2012 to 2015 the p related predictors became more relevant h last precip and precip 30d with rank 3 and 4 not shown here model accuracy increased to its maximum in 2007 2008 r2 of 0 6 afterwards it decreased to a r2 value of almost 0 20 model accuracy did not increase by adding additional predictors the average value of r2 for the entire study period was 0 43 fig 9 b shows the ranking of three predictors of r e explaining the most variance t s t a and lw and additionally θ s t s was the most important predictor in the r en model for most of the year followed by lw and t a in the summer months july september however t s lost its relevance while θ s otherwise almost negligible during the rest of the year became the single most relevant factor in the r en model model accuracy varied widely within a year for spring and autumn the r en model explained more variance than for summer and winter the model fitted the data in summer and winter poorly r2 of 0 1 adding additional predictors did not increase model accuracy significantly 4 discussion 4 1 controls on gpp re and nep 4 1 1 controls on gpp there are several reasons for the increase of annual gpp over the study period besides interannual variability of climatic conditions there are also long term controls of gpp a major long term control of gpp is stand age explained by an increase in foliar biomass baldocchi et al 2018 humphreys et al 2006 krishnan et al 2009 zhou et al 2015 hdf88 was 14 years old at the beginning of the study period and 28 years old at the end besides stand age n fertilization applied in 2007 had a strong impact on gpp especially in the first years after n fertilization dou et al 2015 jassal et al 2010 in addition lee et al 2020 found an increase of gpp in the first two years after n fertilization with no appreciable change in the following eight years the main cause of interannual variability in gpp was both annual and seasonal climate variability other workers have found that annual mean t a spring t a and θ s in summer dry season greatly influence the interannual variability of gpp baldocchi et al 2018 chen et al 2009 krishnan et al 2009 thus it is necessary to understand seasonal variability of gpp to determine the controlling factors influencing its interannual variability high t a in spring leads to an earlier start of the growing season and thus to higher annual gpp krishnan et al 2009 low θ s can cause direct stress on plants stomata closure or indirect stress by reducing lai through needle loss which reduces gpp bréda et al 2006 law et al 2002 for spring march may model fit of the gpp model with the three most important predictors q lw and lw was almost as high as using the full set of predictors r2 of 0 80 and 0 82 this means the gpp model needs only radiation data to reach high accuracy in spring fig 7 however q lw and lw explained considerably less variance for summer june september which resulted in a lower model fit r2 of 0 58 0 71 hence in summer these predictors are not sufficient to explain the variation in gpp besides temperature the predictor analysis shows that at least one other predictor e g θ s is needed q was ranked as the single most important predictor during the whole year whereas θ s had a high rank in late summer however the results do not show a clear dependency of annual gpp totals on annual p the spearman s ρ values for annual mean t a and p with annual gpp are 0 73 and 0 07 respectively table d 1 however spearman s ρ for annual gpp and summer p was 0 48 which points to the importance of summer p these results are in accordance with former studies chen et al 2009 jassal et al 2008 krishnan et al 2009 high annual mean t a tends to decrease annual gpp in addition the predictor analysis at the annual time scale shows that θ s became more important in warm years when the importance of temperature related predictors declined fig 6 the first five years and the last four years of the study period were exceedingly warm whereas the period in between was exceedingly cold these climatic conditions favor a strong increase in gpp in the middle of the study period since interannual variability of gpp cannot be completely described without a knowledge of its seasonal variation annual gpp totals were related to summer june september p and summer t a the summers of 2010 2013 and 2016 were colder than the 15 year mean whereas the summers of 2002 2004 2009 and 2014 2015 were warmer additionally the summers of 2002 2003 and 2014 were dry a clear relationship between annual gpp and weather conditions in summer was found which is in accordance with other studies in the same region chen et al 2009 jassal et al 2007 krishnan et al 2009 in conclusion seasonal and annual variations of gpp were affected by temporal environmental patterns as gpp showed a strong seasonality in terms of water availability it is difficult to draw conclusions from annual environmental conditions because the seasonal timing of warming and water stress are more critical baldocchi et al 2018 chen et al 2009 we found that the ann based estimates of annual and seasonal in june gpp are slightly higher than in lee et al 2020 jassal et al 2010 and wohlfahrt et al 2005 concluded that daytime leaf respiration is subjected to light inhibition applying the nighttime r en model to daytime data neglects differences in respiration process during night and day moffat et al 2007 according to the partitioning procedure of this study the r en model was established first before the gpp model could be fitted after the r e values were estimated using r en model gpp was calculated as gpp nep r e this procedure can cause higher gpp totals than those obtained by lee et al 2020 because of higher r e estimates 4 1 2 controls on r e annual r e did not show a long term trend but only interannual variability stand age seems to have a minor impact on r e at least during the study period stand age from 14 to 28 years this result was in accordance with other studies on long term measurements in forest chronosequences humphreys et al 2006 krishnan et al 2009 wharton and falk 2016 the long term effect of n fertilization on r e is not clear yet dou et al 2015 analyzed a four year period after fertilization and concluded that r e for this stand increased in the first year after fertilization before it decreased in the subsequent years r e responded equally well to seasonal changes in t a t s and water availability as gpp a warm spring can lead to earlier enhancement of r e and thus to higher annual r e totals morgenstern et al 2004 dry summers however can inhibit r e because of lower soil respiration r s jassal et al 2008 hence understanding the influence of seasonal climate variability on r e is required for describing interannual variability in winter when r e was low model accuracy was also low the r en model performed best in spring march may and autumn october november which shows that predicting r e in summer is difficult t s is generally the most important predictor of r e baldocchi et al 2018 in summer however r e was limited by water availability and thus model accuracy decreased because t s was no longer the main factor affecting r e θ s on the other hand became the most important predictor of the r en model in july to september these results are consistent with observed seasonal variation of r e chen et al 2009 humphreys et al 2006 krishnan et al 2009 and r s jassal et al 2008 in addition results from spearman correlations agreed with these relationships spearman s ρ values for annual r e with annual mean t s and annual p were 0 47 and 0 17 respectively table d 1 however spearman s ρ for annual r e with spring t s was 0 66 and for summer p and annual r e was 0 65 hence r e totals were more precisely described by late winter and spring t s and summer p than by annual mean t s and annual p investigating interannual variability of r e needs to take the dependency of seasonal variability of weather conditions into account t s was always the most important predictor and explained almost as much variance as the five most important predictors together the ranking of the remaining predictors however could give information about weather effects during the study period θ s was always ranked between second and fourth except for the years 2004 2005 2013 2014 and 2015 2016 for which it was ranked lower furthermore 2002 2005 and 2015 2016 were the years having higher mean annual t s but did not have higher annual r e comparing annual r e totals with spring and summer p showed a clear pattern the years 2004 2005 2007 and 2016 with a warm spring high t s had the highest r e totals in addition the years 2004 and 2007 were wet and the years 2005 and 2016 had average summer p the years with minimum annual r e 2009 2011 and 2012 were cold in spring and dry in summer except 2011 with average summer p in summary annual p or annual mean t s values provided no information on interannual variability in r e annual variability of r e is better described by seasonal weather conditions like the spring mean t s or summer total p r e totals estimated by the anns were higher than by lee et al 2020 but the difference did not exceed the error estimation however the observed difference between the estimations within the uncertainty has several reasons such as data coverage different u threshold or different partitioning methods daytime light intercept method used in lee et al 2020 since the ann was trained with only nighttime data the light inhibition effect has not been taken into account in this study 4 1 3 controls on nep both interannual and seasonal variability of nep depend on variabilities of r e and gpp increasing nep as a long term trend is expected since stand age has a proven effect baldocchi et al 2018 krishnan et al 2009 zhou et al 2015 the high uncertainty of nep was caused by the high uncertainty of the r en model as already discussed interannual variability of gpp and r e was poorly explained by annual climate variabilities but better by seasonal conditions spearman s ρ between annual nep and gpp is 0 85 between annual nep and r e it is 0 38 these correlation coefficients lead to the conclusion that gpp has a stronger effect on nep than r e the results of this study show that summer p had a positive effect on both annual gpp and r e whether high summer p results in increased annual nep depends on the response of gpp and r e to summer p however nep was not affected by higher summer p spearman s ρ of 0 06 see table d 1 because positive effects of summer p on annual gpp and r e were very similar an early rise of temperature in late winter early spring had a strong positive effect on annual r e spearman s ρ of 0 60 summer mean t a on the other hand had a stronger impact on annual gpp than on annual r e spearman s ρ of 0 77 warm summers led to decreasing annual gpp this means years with warm spring and summer can have low annual nep because of lower gpp in summer and higher r e in spring see also krishnan et al 2009 in conclusion annual mean t a could have a direct effect on annual nep because of time varying dependencies of gpp and r e on t a and t s the decrease of nep in 2015 was caused by higher annual mean t a and thus lower gpp however no clear relationship of annual nep with annual and summer p was found these results indicate that this intermediate aged douglas fir stand was more sensitive to t a and t s variabilities than to p variabilities in terms of c sequestration krishnan et al 2009 who analyzed nep data from 1998 to 2006 concluded that gpp and r e were more sensitive to dry conditions for hdf88 than for an older stand hdf88 was less affected by dry conditions in the second part of the study period which could be caused by increased stand age 4 2 effect of enso events el niño and la niña events showed a strong response to annual mean t a but not to annual p sums in addition el niño and la niña events started and ended in most cases in the middle of the year thus the annual p sums may not represent these events satisfactorily therefore the effects of enso on nep will be discussed focusing on t a as already discussed in section 4 1 3 the effects of spring and summer t a on nep underlay time varying dependencies of gpp and r e the warm years of the study period 2002 2005 2015 were at the same time el niño events 2002 2003 2004 2005 2015 2016 which resulted in low annual nep values spearman s ρ between annual t a and nep 0 83 in the years 2009 2010 however nep increased during the el niño event this increase was caused by the timing of the el niño event this event lasted from summer 2009 to late winter 2010 with a cold spring and a warm summer in 2009 climate prediction center 2019 cold springs can cause low r e and warm summers can cause low gpp spearman s ρ of 0 60 and 0 77 and respectively in 2009 the effects of the cold spring with low r e could have exceeded the negative effects of the warm summer causing low gpp resulting in increased annual nep the summer of 2010 however was relatively cold as a part of a la niña event high gpp and caused higher annual nep the increased nep in 2016 can be explained by similar processes the spring was warm whereas the summer was relatively cold because of a following small la niña event the years 2007 2008 and 2010 2012 were part of la niña events and cold weather these years had high annual nep with the highest in 2012 these results show that enso events had a strong influence on nep of hdf88 however the timing of enso events is crucial as gpp and r e have different responses to t a in spring and summer see section 4 1 3 furthermore enso events appeared to have a stronger influence on gpp than on r e these findings are contrary to morgenstern et al 2004 who analyzed the impact of enso events on c fluxes for a 50 year old douglas fir stand the contrary findings could be caused by the different stand ages krishnan et al 2009 analyzed a chronosequence of three different aged douglas fir stands on vancouver island and concluded that interannual variability of annual nep of old stands is caused mainly by interannual variability of r e compared to interannual variability of gpp for younger stands 4 3 model limitations r2 values for the r en model are close to those from humphreys et al 2006 r2 of 0 43 and 0 45 who analyzed data from the same study site in 2002 but used an exponential relationship between r en and t s as the gap filling model one reason for the moderate model accuracy is more data availability for the training process which has a strong impact on the final model fit the r en model was trained only with 22 10 of the potentially usable data because of u filtering and gaps in the measurement data another reason could be the predictor selection the gpp model using all predictors showed an excellent accuracy r2 of 0 80 the high model accuracy can be explained by more data availability for the training process of the ann calculated gpp had only 45 gaps which means 55 of the data were available for training the gpp model the used ann approach sequential model using densely connected layers led to promising results however different ann architectures or hybrid models fister et al 2016 and combining anns with physical or other machine learning models could lead to different results and increase model accuracy dou and yang 2017 also using additional predictors can increase model accuracy e g wind speed calculated wind direction or gpp proxy used by tramontana et al 2020 furthermore a sensitivity analysis on number of days for the predictor precip 30d could have helped to find a more sensitive predictor 5 conclusions the aim of this study was to develop a new nep partitioning method using the ann technique for an intermediate aged douglas fir stand hdf88 with 15 years of continuous ec and climate measurements by taking advantage of ann models controls on r e and gpp were identified independently furthermore environmental controls of r e and gpp and effects of enso events on nep at annual and monthly scale were investigated the main findings are summarized as follows 1 using a bayesian optimization approach to investigate the optimal hyper parameter composition of an ann for partitioning nep led to promising results the estimated nep over the 15 year period was 118 404 g c m 2 year 1 which is similar to the nep values reported by lee et al 2020 using the daytime intercept method however the average annual gpp and r e derived from the current ann models at 1649 157 g c m 2 year 1 and 1531 410 g c m 2 year 1 respectively were higher than in lee et al 2020 the difference might have been caused by different u thresholds in the two studies but also possibly by lacking the consideration of light inhibition of daytime r e in the current ann approach nevertheless in contrast to the daytime intercept partitioning these anns have the advantage of taking various additional environmental variables into account using additional predictors a further developed fine tuning of the hyper parameters or different model architectures could have led to different results and increased model accuracy 2 the results from the ann models showed that the interannual variability of r e and gpp and hence of nep were mainly caused by late winter and spring t a and summer p an early increase of t a in late winter spring resulted in higher annual r e whereas a dry summer low summer p decreased gpp annual mean t a can explain interannual variability of gpp but not of r e this means that seasonal weather conditions are more appropriate than annual averages or totals to characterize interannual variability of nep 3 the predictor analysis showed that q was the single most important predictor in the gpp model q explained more than half r2 of 0 44 of the variance explained by the gpp model using all predictors r2 of 0 80 including θ s lw and lw resulted in an r2 of 0 72 lower θ s contributed appreciably to a reduction in gpp in the years 2002 2004 and 2011 2013 which were years with dry summer months july september 4 t s was the most important predictor in the r en model explaining 88 r2 of 0 38 of the total explained variance in the r en model using all predictors the r en model using all predictors explained only slightly more r2 of 0 43 however θ s became the single most important predictor in the r en model in late summer july september 5 at the study site enso events were characterized by higher and lower annual t a for el niño and la niña events respectively el niño and la niña events generally resulted in lower and higher annual nep respectively over the 15 years however due to the different responses of r e and gpp to t a changes in spring and summer the timing of enso events was crucial in determining whether annual nep increased or decreased in addition enso events appeared to have a stronger influence on gpp than on r e credit authorship contribution statement ferdinand briegel conceptualization methodology software visualization writing original draft sung ching lee data curation writing review editing t andrew black project administration supervision writing review editing rachhpal s jassal andreas christen supervision resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported and funded by the natural sciences and engineering research council of canada discovery grants ac tab and by the university of freiburg ac the research infrastructure has been supported by the canada foundation for innovation cfi we sincerely thank island timberlands lp for the permission to work on their land and their logistical support we greatly appreciate the assistance of robert halsall rick ketler and zoran nesic for maintaining the long term climate and ec observations appendix appendix a linear regressions appendix b sequential model based optimization the aim of the sequential model based optimization process is to find a hyper parameter set which will minimize the objective function in this case mse on the test dataset to set up the optimization process five steps are required 1 defining a range domain for the hyper parameters over which to search hyper parameter space 2 creating an objective function here mse which must be maximized minimized 3 creating a prior for the first fit of the probabilistic model gaussian process model using an initial random search in hyper parameter space 4 creating a surrogate gaussian process model of the objective function 5 choosing an acquisition function for determining which hyper parameter combination to choose next expected improvement the defined ranges for the number of layers hidden units and the batch size are given in table 2 r en model layers 1 3 hidden units 30 120 batch size 10 80 gpp model layers 1 3 hidden units 80 150 batch size 30 110 the number of hidden units per layer was halved in each subsequent layer the objective function is the ann with the number of layers hidden units and the batch size as hyper parameters and mse as the evaluation metric score as the objective function is time consuming to compute the surrogate model is optimized instead the surrogate model is also called a response surface since it describes the probability representation of the hyper parameters and their respective objective function scores mse using the results of the initial random search hence a continuous score function over the hyper parameter space was approximated step 4 rasmussen and williams 2005 the gaussian process model was used as the surrogate model brochu et al 2010 the covariance function controls the smoothness and amplitude of samples from the gaussian process model a matérn kernel with v 5 2 was used as the covariance function rasmussen and williams 2005 from this distribution of score functions of the gaussian process model the acquisition function computed the hyper parameter composition leading to the largest expected improvement over the current score step 5 in this process the acquisition function finds a trade off between exploration and exploitation brochu et al 2010 the computed hyper parameter composition was then used by the objective function the computed score by objective function and the corresponding hyper parameter set update the data of the surrogate model posterior and a new distribution of functions was drawn by the gaussian process model the acquisition function could then identify another hyper parameter composition this means that steps 4 and 5 were repeated iteratively the initial random search was 20 random drawn hyper parameter compositions the bayesian optimization was iterated 25 times in total 45 hyper parameter compositions were computed appendix c predictor analysis after the hyper parameter optimization of the ann models a predictor analysis was conducted to investigate the driving factors explaining r e and gpp a stepwise forward selection was implemented which adds one predictor at a time beysolow ii 2017 every predictor was 5 fold cross validated four times the predictor with the highest model improvement reduced mse was added to the model using eleven predictors led to 66 and 91 r en and gpp models respectively that had to be run the impact of different weather conditions the effect of enso events during the study period and seasonal patterns on predictor importance were investigated by an interannual and seasonal predictor analysis for this purpose a moving window of two years was applied over the 15 year study period moving forward one year at a time for each two year window a complete model selection process was conducted and also a predictor analysis the moving window was applied to the data to determine whether interannual variability results in varying predictor importance the same procedures were applied to investigate whether predictor relevance changes within a year by using a moving window of three months moving forward one month at a time the monthly moving window used data from the entire study period because some months had poor data coverage and anns were much less reliable when there is little training data in addition our study aimed to determine the seasonal effects of environmental variables on r e gpp and nep appendix d spearman correlations 
24754,it is critical to have long term carbon dioxide co2 flux observations in forest ecosystems to understand how changing climate can affect forest carbon c stocks and co2 exchange between forests and the atmosphere in this study fifteen years 2002 2016 of continuous eddy covariance flux and climate measurements in an intermediate aged douglas fir stand on the east coast of vancouver island canada were analyzed first the eddy covariance measured co2 fluxes were partitioned into gross primary production and ecosystem respiration using two artificial neural networks second the responses of net ecosystem production gross primary production and ecosystem respiration to interannual climate variability including five el niño southern oscillation events were determined three hyper parameters number of layers hidden units and batch size of each artificial neural network were set by bayesian optimization using sequential model based optimization while the remaining hyper parameters were taken from the literature the first artificial neural network was fitted using only nighttime co2 flux data and applied to estimate nighttime and daytime ecosystem respiration values and the second one was used to gap fill gross primary production values in addition a predictor analysis was done to investigate the most influential predictors i e environmental variables within seasons and years when applied to half hourly data the ecosystem respiration model had an r2 of 0 43 whereas the gross primary production model had an r2 of 0 80 the stand was a moderate c sink average net ecosystem production of 118 404 g c m 2 year 1 during the entire study period except for the years 2002 2006 when the stand was a moderate c source the mean annual values of gross primary production and ecosystem respiration were 1649 157 g c m 2 year 1 and 1531 410 g c m 2 year 1 respectively our analysis showed that soil temperature was the most important predictor for the ecosystem respiration model and photosynthetically active irradiance was the most important predictor for the gross primary production model however during dry periods in late summer soil moisture became the most important predictor interannual variability of net ecosystem production was only slightly affected by annual total precipitation mean soil temperature and mean air temperature instead it depended on spring mean air temperature start of the growing season summer total precipitation indicative of water deficiency and mean summer air temperature el niño and la niña events generally resulted in lower and higher annual net ecosystem production respectively keywords artificial neural network net ecosystem exchange partitioning eddy covariance douglas fir el niño predictor analysis 1 introduction globally forest ecosystems are the largest land carbon c sink and they account for more than half of the c stored in terrestrial ecosystems hui et al 2015 understanding the role of forest ecosystems in the global c cycle is critical to projecting the future strength of the land c sink and its effect on future climate change thus it is urgent to have a better understanding of how climate change may influence forest c stocks and carbon dioxide co2 exchange between forests and the atmosphere froelich et al 2015 this requires measurements of net ecosystem production nep and estimation of its partitioned components gross primary production gpp and ecosystem respiration r e and knowledge of the biotic and climatic factors influencing them stand level co2 fluxes from forest stands can be directly measured using the eddy covariance ec technique baldocchi and meyers 1988 with more long term ec datasets it is possible to assess the responses of forest ecosystems to climate variability climate change and disturbance aubinet et al 2018 baldocchi et al 2018 oishi et al 2018 teets et al 2018 to improve our understanding of environmental effects on forest growth trajectories pinnington et al 2017 xu et al 2017 and to improve ecosystem c dynamics models richardson et al 2010 a broad variety of approaches for partitioning nep into r e and gpp has been developed and applied in the literature the most common partitioning approaches can be roughly divided into those using only nighttime data to establish empirical relationships between r e and soil or air temperature followed by determining daytime r e using these relationships and using daytime intercept of the nep vs photosynthetically active irradiance q relationship and nighttime data for estimating daytime and nighttime r e respectively aubinet et al 2012 jassal et al 2007 keenan et al 2019 lee et al 2020 gap filling of gpp is usually done using methods such as the michaelis menten equation look up tables and monte carlo techniques moffat et al 2007 recently attention has been directed toward designing testing and applying artificial neural network ann models to identify environmental controls for better understanding of how trace gas fluxes may respond to environmental changes liu et al 2018 the ann technique is a powerful tool for accounting for the controls of trace gas fluxes because of its ability to process information in a non linear manner beale and jackson 1990 raiche 1991 which enables completely unconstrained optimization and determination of input output responses demuth et al 1994 kosko 1992 schulz and härtling 2003 in addition moffat et al 2007 have pointed out that anns are one of the best methods for partitioning and gap filling ec measured co2 flux data furthermore the ann model does not rely on pre described functional relationships with a limited number of environmental drivers this allows the impact of different environmental factors on r e gpp and nep to be evaluated few studies have used anns for this purpose for forest sites dou et al 2015 moffat et al 2007 papale and valentini 2003 pau et al 2018 and non forest sites baldocchi et al 2015 knox et al 2015 safa et al 2019 wen et al 2014 however most of these studies used a simple ann architecture and applied a straightforward trial and error method to determine the optimal hyper parameter composition such as the number of layers and hidden units baldocchi et al 2015 dou et al 2015 papale and valentini 2003 in this study we used a bayesian optimization approach to investigate the optimal hyper parameter composition to develop two anns that explain environmental and physiological constraints on co2 fluxes using a long term 15 year dataset from an intermediate aged coastal douglas fir stand the specific objectives were to 1 partition and gap fill the 15 years of ec measured nee data using the ann technique and compare it with an established method that uses the daytime intercept approach on the same dataset lee et al 2020 2 identify the environmental factors controlling the co2 fluxes using a predictor analysis and 3 determine changes in forest atmosphere co2 exchange in response to interannual climate variability including el niño southern oscillation enso events 2 material and methods 2 1 study site and instrumentation the study site is part of a chronosequence of three different aged douglas fir stands on the east coast of vancouver island bc canada in this study 15 years 2002 2016 of data from the middle aged stand hdf88 ameriflux site id ca ca3 were analyzed hdf88 was planted in 1988 75 douglas fir 21 western red cedar and 4 grand fir after the previous stand was clear cut and burned in 1987 the understory contains mainly deciduous and evergreen species such as fireweed epilobium angustifolium l s l sword polystichum munitum kaulf c presl and bracken fern pteridium aquilinum l kuhn salal gaultheria shallon pursh rubus spp and red huckleberry vaccinium parvifolium sm jassal et al 2012 the study site is located at an elevation of 170 m above sea level around 3 1 km off the coastline of the salish sea humphreys et al 2006 the soil at the site is classified as a humo ferric podzol with a gravelly loam texture krishnan et al 2009 the site is categorized as seasonally dry temperate rainforest and is located in the coastal western hemlock biogeoclimatic zone meidinger and pojar 1991 mean annual air temperature t a and precipitation p over the15 years of the study period were 8 9 c and 1569 mm respectively the growing season lasts from march to october the dominant wind direction is affected by anabatic katabatic air flow and the land sea circulation between the salish sea and vancouver island the flux tower 21 m height was built in 2001 at the study site to provide continuous flux and climate measurements throughout the ec technique was used to continuously measure turbulent fluxes of co2 which were aggregated into half hourly fluxes f c turbulent fluxes were measured above the canopy with the measurement height being raised over time 12 m for 2001 to 2005 15 m for 2006 to june 2015 21 m for july 2015 to december 2016 due to increasing tree height three axis sonic anemometers model r3 gill instruments ltd lymington uk with an open path infrared gas co2 h2o analyzer irga li 7500 li cor inc lincoln ne usa from 2001 to 2003 september and a closed path irga li 7000 li cor inc lincoln ne usa from october 2003 to december 2016 were used for measuring vertical wind speed w and co2 mixing ratio s c respectively f c was corrected by adding the estimated rate of change in co2 storage in the air column below the ec sensor height to obtain the net ecosystem exchange nee hollinger et al 1994 morgenstern et al 2004 nep was calculated as nep nee besides ec measurements continuous measurements of several environmental variables were made a housed fan aspirated radiation shield model 076b met one instruments inc grants pass or usa temperature and humidity probe model hmp 35c vaisala oyj helsinki finland at the height of the ec instrumentation was used to measure t a and relative humidity jassal et al 2009 in addition half hourly profile measurements of volumetric soil water content θ s 4 12 45 and 85 cm depths and soil temperature t s 5 10 20 50 and 100 cm depths were made model cs 615 campbell scientific inc csi logan ut usa and copper constantan thermocouples respectively jassal et al 2010 additionally soil water storage was estimated considering the depth down to 100 cm soil depth p was measured using two tipping bucket rain gauges model 2501 sierra misco berkeley ca usa one was mounted on the flux tower just above the canopy and one on the ground in an opening in the stand the gage in the opening was modified with a snowfall adapter model cs705 csi to allow measurements of p as snow jassal et al 2010 photosynthetically active irradiance photon flux density q was measured on the tower 3 m above the height of the ec instrumentation with a quantum sensor model li 190sb li cor inc jassal et al 2012 a net radiometer model cnr1 kipp and zonen deft the netherlands was installed on top of the tower to measure upwelling and downwelling shortwave and longwave radiation sw sw lw lw in addition climate data from an adjacent environment canada weather station comox airport dnd 2018 were used for climate analysis 2 2 data preprocessing the collected ec and environmental data were subjected to a comprehensive processing and quality control that flagged suspicious data thresholds and limits of the quality control and the percentage of occurrence of each variable are shown in table 1 data points exceeding these limits were flagged measured values of relative humidity between 100 and 105 were set to 100 considering measurement errors whereas relative humidity values 105 were flagged afterwards the flagged or missing values were replaced by simple linear interpolation gaps shorter than 6 h or recalculated by linear regression models gaps longer than 6 h table a 1 shows the response and explanatory variables used in the linear regression models this was done to keep the number of values of each variable constant since incomplete half hourly data cannot be used to train anns all linear regression models were fitted using a normal distribution for the response variable except for relative humidity which followed a beta distribution for relative humidity and t a data from comox airport were used to improve the model fit of the linear regression models data from comox airport had an hourly resolution as the data from the study site had a half hourly resolution half hourly data from the comox airport were generated by interpolation of hourly values the percentage of data that were missing i e gaps were the highest for relative humidity at 11 62 whereas t a and t s had virtually no gaps 0 01 to account for possible measurement errors when q was 0 μmol m 2 s 1 and 5 μmol m 2 s 1 these values were set to 0 μmol m 2 s 1 the regression models for lw and sw followed a log normal distribution whereas sw and lw followed a normal distribution missing wind speed p and sw data were not gap filled since they were not used as model predictors nighttime r e r en was provided from nighttime nee nep under well mixed conditions u 0 19 m s 1 jassal et al 2012 u was calculated from the covariance of w and the horizontal wind velocity components aubinet et al 2012 nighttime was defined as the period with half hourly average q 5 μmol m 2 s 1 ec measured flux data had 16 03 gaps before u correction that needed to be filled one additional predictor was created for each of θ s and t s by simple averaging these for all soil depths θ s t s additional predictors were created based on seasonal and diurnal patterns of p the p sum of the past 30 days precip 30d and hours since the last p event h last precip were calculated because they represent the current soil moisture and humidity conditions better than half hourly p values the sum of the past 30 days was chosen because it takes recent dry periods into account which could have an effect on present c fluxes a sensitivity analysis to determine the optimal number of days was not carried out for computational costs in addition to take potential radiation day of year seasonality and day length into account three supplementary predictors were added papale and valentini 2003 these predictors were created by applying a complete sine curve 2π on annual and daily bases to add separated periodic information besides diurnally and annually fluctuating temperatures and radiative predictors one curve was fitted for solely the seasonal patterns oscillating between summer and winter year ws sin without diurnal fluctuations the diurnal sine curve oscillates only between midday and midnight day sin without seasonality a third sine curve was added to account for a potential annual hysteresis that accounts for the seasonal offset of the r e and gpp activity between spring and autumn this curve oscillates between spring and autumn year sa sin 2 3 ann model development the keras package for r chollet and allaire 2017 core team 2013 originally a python python software foundation https www python org library keras chollet et al 2015 was used the package gives an optimal framework using tensorflow for building a user specific network with a wide variety of adjustable features hyper parameters for specific model tuning and provides a good structure for regression problems 2 3 1 evaluation metric as model evaluation metric mean squared error mse was used the mse was calculated by 5 fold cross validation james et al 2013 kuhn and johnson 2013 for that purpose the model dataset was split into five randomly drawn datasets four folds were used as a training dataset 80 for the ann models whereas the remaining fold 20 were split in two equal groups one as validation dataset and one as test dataset the validation dataset was necessary to evaluate the training process of the anns by giving feedback on how the anns performed on the validation dataset chollet and allaire 2018 at the end of the training process the mse was calculated for the test dataset this was done by using the trained model to predict values on the test dataset yi r en or gpp with yi and the observed values from the test dataset y i the mse was calculated as follows 1 mse 1 n i 1 n y i y i 2 from the five folds of the cross validation every fold was used once as validation and test data the 5 fold cross validation was repeated to gain more precise information about model accuracy for the predictor pre analysis the 5 fold cross validation was repeated ten times six times for the hyper parameter analysis and four times for the following stepwise predictor analysis this scheme was chosen because of increasing computational costs of the different model steps the calculated mses were averaged the model with the lowest mse was chosen for further analysis 2 3 2 data preparation and predictor pre selection prior to model selection the data needed to be prepared for the ann predictors had to be normalized hastie et al 2009 for this purpose different data normalization methods were tested in which the standardization method mean 0 standard deviation 1 showed the best results i e with the lowest mse the predictors were first split into three folds training 80 test 10 and evaluation folds 10 chollet and allaire 2018 the mean and standard deviation of the training fold were calculated and used for the standardization of the training test and evaluation folds chollet and allaire 2018 to prevent a biased training process towards higher data coverage of certain environmental conditions or seasons previous work has clustered the data baldocchi et al 2015 knox et al 2015 aiming to prevent this bias we conducted a k means cluster analysis to cluster the data by nep the data were divided into four natural clusters by the cluster algorithm nep cluster means were 1 59 μmol m 2 s 1 4 02 μmol m 2 s 1 7 53 μmol m 2 s 1 and 14 51 μmol m 2 s 1 and sizes were 51 33 14 and 2 respectively a combination of each cluster subset was used as an alternative dataset to the full dataset rasmussen and williams 2005 however in this study the un clustered dataset had a lower mse 4 74 μmol m 2 s 1 2 than the clustered dataset 16 95 μmol m 2 s 1 2 thus the un clustered dataset was selected for the modeling process after data preparation two simple anns one with t s and one with θ s as predictors were run to determine which soil depths t s and θ swere the most influential and to avoid highly correlated predictors therefore a small ann was set up with two layers containing 40 hidden units in the first layer and 20 hidden units in the second layer with a batch size of 30 the remaining hyper parameters were the same as for the main models 2 3 3 hyper parameter optimization and predictor analysis in the next step the r en model was optimized ann 1 in fig 1 therefore a sequential ann linear stack of layers was set up the best hyper parameter composition was determined by bayesian optimization specifically by a sequential model based optimization based on gaussian process models appendix b bergstra et al 2011 brochu et al 2010 rasmussen and williams 2005 the advantage of bayesian optimization approaches over grid or random searches is that bayesian approaches take past evaluation results into account to improve the sampling method in the next step bergstra et al 2011 this means less model evaluations are needed to find the best hyper parameter set brochu et al 2010 sequential model based optimization was applied to obtain three hyper parameters layers hidden units and batch size whereas the remaining hyper parameters were taken from the literature see table 2 the optimization suggested an ann architecture for the r en model with two layers 59 hidden units and a batch size of 62 after the hyper parameter composition with lowest mse was found a forward selection of the predictors was done to investigate the most influential predictors of the r en model see appendix c daytime r e values were modeled by this r en model gpp was then calculated as gpp r e nep when measured daytime nep was available a gpp model was developed by applying the same procedure hyper parameter optimization and predictor analysis as used for the r en model ann 2 in fig 1 the ann architecture with the lowest mse for the gpp model had three layers 145 hidden units and a batch size of 83 with this model gaps in the gpp data were filled finally gaps in nep and nee were calculated with complete r e and gpp data the predictors used for both models are shown in table 1 2 3 4 model evaluation model evaluation and model error estimation were done by bootstrapping the best model structure and predictor subset hastie et al 2009 100 datasets were randomly drawn each ann was trained with every single dataset and predictions were made the mean standard deviation and 95 confidence intervals of the predictions from 100 bootstrap replications were calculated with the mean representing the estimated value of the model the total error was calculated using model and random errors the 95 confidence interval was used as model error random error was calculated by applying a 20 random uncertainty to the measured values of nee which is a typical random error reported for ec measurements of co2 fluxes in the literature morgenstern et al 2004 2 4 analysis of enso effect to investigate whether enso events have an impact on nep or not the relationships between co2 fluxes annual gpp r e and nep and spring march may and summer june september total p and average t a were investigated for this purpose spearman s rank correlation coefficient spearman s ρ of annual spring and summer total p and average t a was calculated to quantify the effect of seasonal weather conditions on annual totals table d 1 spearman s ρ is a nonparametric measure of rank correlation and was chosen because the correlation coefficient is calculated only for a monotonic relationship and not for a linear relationship alvo and yu 2014 3 results 3 1 climate the 30 year 1981 to 2010 mean annual t a at the nearby comox airport was 10 0 c whereas the mean annual t a during the study period 2002 to 2016 was slightly higher at 10 2 c in particular the years at the beginning of the measurement period were the coldest with both 2008 and 2011 at 9 4 c while years towards the end were warmest 11 0 c in 2014 and 11 3 c in 2015 fig 2 the mean annual p during the study period was 1148 mm which is similar to the 30 year mean value of 1153 mm at comox airport in 2008 and 2013 the site was dry with only 70 of the mean annual p whereas the year 2016 was unusually wet with 145 of the mean annual p between 2002 and 2016 two strong la niña events 2007 2008 and 2010 2012 and three strong el niño events 2002 2003 2009 2010 and 2014 2016 occurred climate prediction center 2019 even with these events starting and ending in the middle of the year mean annual t a was higher during el niño years and lower during la niña years monthly mean t a and monthly p for the study period are shown in fig 3 it can be clearly seen that almost all months except march april and september were 0 2 c to 0 4 c warmer than the 30 year averages p during the summer months was lower than 30 year average by a few mm 10 25 3 2 annual seasonal and monthly nep r e and gpp the mean annual totals based on ann modeling over the 15 year study period were 118 404 g c m 2 year 1 for nep 1649 157 g c m 2 year 1 for gpp and 1531 410 g c m 2 year 1 for r e fig 4 from 2002 to 2004 annual nep was approximately 200 g c m 2 year 1 and thus the forest was a moderate c source fig 4 a in 2005 and 2006 nep was close to zero before the stand became a c sink starting in 2007 with the highest c sequestration occurring in 2012 368 444 g c m 2 year 1 after 2012 nep decreased slightly before it increased again in 2016 gpp increased from 2003 to 2007 except 2006 before it started to fluctuate at a higher level between 1650 and 1860 g c m 2 year 1 fig 4 b r e totals did not show a clear trend over the 15 years and fluctuated between 1400 and 1660 g c m 2 year 1 fig 4 c annual nep values calculated by lee et al 2020 and those obtained using the anns showed similar temporal patterns however regarding the uncertainty analysis only modeled gpp showed different results within uncertainty ann modelled nep was slightly lower average of 150 g c m 2 year 1 than that obtained using the traditional gap filling approach employed by lee et al 2020 this was because the difference between ann estimated r e and that obtained by lee et al 2020 was generally slightly larger than the difference between ann estimated gpp and that obtained by lee et al 2020 the ecosystem acted as a c sink from march to august and as a c source from september to february with ann modeling indicating that the highest c sequestration rate nep was in june 72 47 g c m 2 month 1 and the highest c net emission rate was in october 44 42 g c m 2 month 1 fig 5 a the error estimations of ann modelled nep were higher in summer than in winter monthly gpp increased from january to june and decreased from june to december with the highest monthly ann modelled value of 287 20 g c m 2 month 1 and the lowest monthly value of 33 9 g c m 2 month 1 fig 5 b r e response to meteorological conditions was somewhat slower compared to gpp this is recognizable due to the hysteresis effect such that r e takes longer than gpp to decrease in autumn fig 5 c the highest ann modelled r e was observed in june 215 54 g c m 2 month 1 while monthly r e remained relatively high until october the lowest r e was in january 54 15 g c m 2 month 1 the estimated error in r e was larger in summer than in winter in comparison with the results from lee et al 2020 the findings for annual and monthly totals were quite similar especially regarding the uncertainty analysis nep gpp and r e totals were largely consistent except of gpp and r e estimations in early summer and autumn 3 3 environmental controls 3 3 1 controls on annual and seasonal gpp among the environmental controls of annual gpp q was ranked first and lw was ranked third for almost all different modeled windows fig 6 however lw was not relevant in the first two years of the study period rank 11 and 13 respectively lw was relevant in almost all years except for 2004 2005 and from 2011 to 2013 values for 2011 2012 and 2012 2013 t s did not have a high rank except for 2004 2005 θ s and lw were irrelevant in 2004 2005 whereas t s was ranked second in these years θ s was more important during 2002 2004 and 2011 2013 the model accuracy r2 varied between 0 36 and 0 71 for the most important predictor and 0 68 0 92 for the five predictors with r2 for the entire study period being 0 80 at the monthly scale fig 7 shows the five most important predictors of the gpp model as expected q was the single most important factor controlling gpp followed by lw and lw during the summer months θ s was less important in the gpp model in fact θ s and lw had the least explanatory power in june and september respectively when they both ranked last t s was ranked high from january to march lw was almost ranked second or third except for february and march the gpp model showed no seasonality in model accuracy moreover the model accuracy increased appreciably by adding more predictors r2 of 0 8 3 3 2 controls on annual and seasonal r e among environmental controls of annual r e the five most important predictors in the moving window r en models were t s θ s lw year sa sin and year ws sin fig 8 as expected t s was the predictor describing the most variance for every computed window ranks of the remaining four predictors out of the best five varied in the years 2008 2009 and 2011 2013 θ s was the second most important predictor however θ s was less relevant in years 2004 2005 and 2015 2016 in years 2002 2003 and 2007 2008 lw was ranked low before it became more important in the second half of the study period the sine functions which represent seasonality had their lowest ranks in years 2008 2010 but were of higher importance in the first half of the study period from 2012 to 2015 the p related predictors became more relevant h last precip and precip 30d with rank 3 and 4 not shown here model accuracy increased to its maximum in 2007 2008 r2 of 0 6 afterwards it decreased to a r2 value of almost 0 20 model accuracy did not increase by adding additional predictors the average value of r2 for the entire study period was 0 43 fig 9 b shows the ranking of three predictors of r e explaining the most variance t s t a and lw and additionally θ s t s was the most important predictor in the r en model for most of the year followed by lw and t a in the summer months july september however t s lost its relevance while θ s otherwise almost negligible during the rest of the year became the single most relevant factor in the r en model model accuracy varied widely within a year for spring and autumn the r en model explained more variance than for summer and winter the model fitted the data in summer and winter poorly r2 of 0 1 adding additional predictors did not increase model accuracy significantly 4 discussion 4 1 controls on gpp re and nep 4 1 1 controls on gpp there are several reasons for the increase of annual gpp over the study period besides interannual variability of climatic conditions there are also long term controls of gpp a major long term control of gpp is stand age explained by an increase in foliar biomass baldocchi et al 2018 humphreys et al 2006 krishnan et al 2009 zhou et al 2015 hdf88 was 14 years old at the beginning of the study period and 28 years old at the end besides stand age n fertilization applied in 2007 had a strong impact on gpp especially in the first years after n fertilization dou et al 2015 jassal et al 2010 in addition lee et al 2020 found an increase of gpp in the first two years after n fertilization with no appreciable change in the following eight years the main cause of interannual variability in gpp was both annual and seasonal climate variability other workers have found that annual mean t a spring t a and θ s in summer dry season greatly influence the interannual variability of gpp baldocchi et al 2018 chen et al 2009 krishnan et al 2009 thus it is necessary to understand seasonal variability of gpp to determine the controlling factors influencing its interannual variability high t a in spring leads to an earlier start of the growing season and thus to higher annual gpp krishnan et al 2009 low θ s can cause direct stress on plants stomata closure or indirect stress by reducing lai through needle loss which reduces gpp bréda et al 2006 law et al 2002 for spring march may model fit of the gpp model with the three most important predictors q lw and lw was almost as high as using the full set of predictors r2 of 0 80 and 0 82 this means the gpp model needs only radiation data to reach high accuracy in spring fig 7 however q lw and lw explained considerably less variance for summer june september which resulted in a lower model fit r2 of 0 58 0 71 hence in summer these predictors are not sufficient to explain the variation in gpp besides temperature the predictor analysis shows that at least one other predictor e g θ s is needed q was ranked as the single most important predictor during the whole year whereas θ s had a high rank in late summer however the results do not show a clear dependency of annual gpp totals on annual p the spearman s ρ values for annual mean t a and p with annual gpp are 0 73 and 0 07 respectively table d 1 however spearman s ρ for annual gpp and summer p was 0 48 which points to the importance of summer p these results are in accordance with former studies chen et al 2009 jassal et al 2008 krishnan et al 2009 high annual mean t a tends to decrease annual gpp in addition the predictor analysis at the annual time scale shows that θ s became more important in warm years when the importance of temperature related predictors declined fig 6 the first five years and the last four years of the study period were exceedingly warm whereas the period in between was exceedingly cold these climatic conditions favor a strong increase in gpp in the middle of the study period since interannual variability of gpp cannot be completely described without a knowledge of its seasonal variation annual gpp totals were related to summer june september p and summer t a the summers of 2010 2013 and 2016 were colder than the 15 year mean whereas the summers of 2002 2004 2009 and 2014 2015 were warmer additionally the summers of 2002 2003 and 2014 were dry a clear relationship between annual gpp and weather conditions in summer was found which is in accordance with other studies in the same region chen et al 2009 jassal et al 2007 krishnan et al 2009 in conclusion seasonal and annual variations of gpp were affected by temporal environmental patterns as gpp showed a strong seasonality in terms of water availability it is difficult to draw conclusions from annual environmental conditions because the seasonal timing of warming and water stress are more critical baldocchi et al 2018 chen et al 2009 we found that the ann based estimates of annual and seasonal in june gpp are slightly higher than in lee et al 2020 jassal et al 2010 and wohlfahrt et al 2005 concluded that daytime leaf respiration is subjected to light inhibition applying the nighttime r en model to daytime data neglects differences in respiration process during night and day moffat et al 2007 according to the partitioning procedure of this study the r en model was established first before the gpp model could be fitted after the r e values were estimated using r en model gpp was calculated as gpp nep r e this procedure can cause higher gpp totals than those obtained by lee et al 2020 because of higher r e estimates 4 1 2 controls on r e annual r e did not show a long term trend but only interannual variability stand age seems to have a minor impact on r e at least during the study period stand age from 14 to 28 years this result was in accordance with other studies on long term measurements in forest chronosequences humphreys et al 2006 krishnan et al 2009 wharton and falk 2016 the long term effect of n fertilization on r e is not clear yet dou et al 2015 analyzed a four year period after fertilization and concluded that r e for this stand increased in the first year after fertilization before it decreased in the subsequent years r e responded equally well to seasonal changes in t a t s and water availability as gpp a warm spring can lead to earlier enhancement of r e and thus to higher annual r e totals morgenstern et al 2004 dry summers however can inhibit r e because of lower soil respiration r s jassal et al 2008 hence understanding the influence of seasonal climate variability on r e is required for describing interannual variability in winter when r e was low model accuracy was also low the r en model performed best in spring march may and autumn october november which shows that predicting r e in summer is difficult t s is generally the most important predictor of r e baldocchi et al 2018 in summer however r e was limited by water availability and thus model accuracy decreased because t s was no longer the main factor affecting r e θ s on the other hand became the most important predictor of the r en model in july to september these results are consistent with observed seasonal variation of r e chen et al 2009 humphreys et al 2006 krishnan et al 2009 and r s jassal et al 2008 in addition results from spearman correlations agreed with these relationships spearman s ρ values for annual r e with annual mean t s and annual p were 0 47 and 0 17 respectively table d 1 however spearman s ρ for annual r e with spring t s was 0 66 and for summer p and annual r e was 0 65 hence r e totals were more precisely described by late winter and spring t s and summer p than by annual mean t s and annual p investigating interannual variability of r e needs to take the dependency of seasonal variability of weather conditions into account t s was always the most important predictor and explained almost as much variance as the five most important predictors together the ranking of the remaining predictors however could give information about weather effects during the study period θ s was always ranked between second and fourth except for the years 2004 2005 2013 2014 and 2015 2016 for which it was ranked lower furthermore 2002 2005 and 2015 2016 were the years having higher mean annual t s but did not have higher annual r e comparing annual r e totals with spring and summer p showed a clear pattern the years 2004 2005 2007 and 2016 with a warm spring high t s had the highest r e totals in addition the years 2004 and 2007 were wet and the years 2005 and 2016 had average summer p the years with minimum annual r e 2009 2011 and 2012 were cold in spring and dry in summer except 2011 with average summer p in summary annual p or annual mean t s values provided no information on interannual variability in r e annual variability of r e is better described by seasonal weather conditions like the spring mean t s or summer total p r e totals estimated by the anns were higher than by lee et al 2020 but the difference did not exceed the error estimation however the observed difference between the estimations within the uncertainty has several reasons such as data coverage different u threshold or different partitioning methods daytime light intercept method used in lee et al 2020 since the ann was trained with only nighttime data the light inhibition effect has not been taken into account in this study 4 1 3 controls on nep both interannual and seasonal variability of nep depend on variabilities of r e and gpp increasing nep as a long term trend is expected since stand age has a proven effect baldocchi et al 2018 krishnan et al 2009 zhou et al 2015 the high uncertainty of nep was caused by the high uncertainty of the r en model as already discussed interannual variability of gpp and r e was poorly explained by annual climate variabilities but better by seasonal conditions spearman s ρ between annual nep and gpp is 0 85 between annual nep and r e it is 0 38 these correlation coefficients lead to the conclusion that gpp has a stronger effect on nep than r e the results of this study show that summer p had a positive effect on both annual gpp and r e whether high summer p results in increased annual nep depends on the response of gpp and r e to summer p however nep was not affected by higher summer p spearman s ρ of 0 06 see table d 1 because positive effects of summer p on annual gpp and r e were very similar an early rise of temperature in late winter early spring had a strong positive effect on annual r e spearman s ρ of 0 60 summer mean t a on the other hand had a stronger impact on annual gpp than on annual r e spearman s ρ of 0 77 warm summers led to decreasing annual gpp this means years with warm spring and summer can have low annual nep because of lower gpp in summer and higher r e in spring see also krishnan et al 2009 in conclusion annual mean t a could have a direct effect on annual nep because of time varying dependencies of gpp and r e on t a and t s the decrease of nep in 2015 was caused by higher annual mean t a and thus lower gpp however no clear relationship of annual nep with annual and summer p was found these results indicate that this intermediate aged douglas fir stand was more sensitive to t a and t s variabilities than to p variabilities in terms of c sequestration krishnan et al 2009 who analyzed nep data from 1998 to 2006 concluded that gpp and r e were more sensitive to dry conditions for hdf88 than for an older stand hdf88 was less affected by dry conditions in the second part of the study period which could be caused by increased stand age 4 2 effect of enso events el niño and la niña events showed a strong response to annual mean t a but not to annual p sums in addition el niño and la niña events started and ended in most cases in the middle of the year thus the annual p sums may not represent these events satisfactorily therefore the effects of enso on nep will be discussed focusing on t a as already discussed in section 4 1 3 the effects of spring and summer t a on nep underlay time varying dependencies of gpp and r e the warm years of the study period 2002 2005 2015 were at the same time el niño events 2002 2003 2004 2005 2015 2016 which resulted in low annual nep values spearman s ρ between annual t a and nep 0 83 in the years 2009 2010 however nep increased during the el niño event this increase was caused by the timing of the el niño event this event lasted from summer 2009 to late winter 2010 with a cold spring and a warm summer in 2009 climate prediction center 2019 cold springs can cause low r e and warm summers can cause low gpp spearman s ρ of 0 60 and 0 77 and respectively in 2009 the effects of the cold spring with low r e could have exceeded the negative effects of the warm summer causing low gpp resulting in increased annual nep the summer of 2010 however was relatively cold as a part of a la niña event high gpp and caused higher annual nep the increased nep in 2016 can be explained by similar processes the spring was warm whereas the summer was relatively cold because of a following small la niña event the years 2007 2008 and 2010 2012 were part of la niña events and cold weather these years had high annual nep with the highest in 2012 these results show that enso events had a strong influence on nep of hdf88 however the timing of enso events is crucial as gpp and r e have different responses to t a in spring and summer see section 4 1 3 furthermore enso events appeared to have a stronger influence on gpp than on r e these findings are contrary to morgenstern et al 2004 who analyzed the impact of enso events on c fluxes for a 50 year old douglas fir stand the contrary findings could be caused by the different stand ages krishnan et al 2009 analyzed a chronosequence of three different aged douglas fir stands on vancouver island and concluded that interannual variability of annual nep of old stands is caused mainly by interannual variability of r e compared to interannual variability of gpp for younger stands 4 3 model limitations r2 values for the r en model are close to those from humphreys et al 2006 r2 of 0 43 and 0 45 who analyzed data from the same study site in 2002 but used an exponential relationship between r en and t s as the gap filling model one reason for the moderate model accuracy is more data availability for the training process which has a strong impact on the final model fit the r en model was trained only with 22 10 of the potentially usable data because of u filtering and gaps in the measurement data another reason could be the predictor selection the gpp model using all predictors showed an excellent accuracy r2 of 0 80 the high model accuracy can be explained by more data availability for the training process of the ann calculated gpp had only 45 gaps which means 55 of the data were available for training the gpp model the used ann approach sequential model using densely connected layers led to promising results however different ann architectures or hybrid models fister et al 2016 and combining anns with physical or other machine learning models could lead to different results and increase model accuracy dou and yang 2017 also using additional predictors can increase model accuracy e g wind speed calculated wind direction or gpp proxy used by tramontana et al 2020 furthermore a sensitivity analysis on number of days for the predictor precip 30d could have helped to find a more sensitive predictor 5 conclusions the aim of this study was to develop a new nep partitioning method using the ann technique for an intermediate aged douglas fir stand hdf88 with 15 years of continuous ec and climate measurements by taking advantage of ann models controls on r e and gpp were identified independently furthermore environmental controls of r e and gpp and effects of enso events on nep at annual and monthly scale were investigated the main findings are summarized as follows 1 using a bayesian optimization approach to investigate the optimal hyper parameter composition of an ann for partitioning nep led to promising results the estimated nep over the 15 year period was 118 404 g c m 2 year 1 which is similar to the nep values reported by lee et al 2020 using the daytime intercept method however the average annual gpp and r e derived from the current ann models at 1649 157 g c m 2 year 1 and 1531 410 g c m 2 year 1 respectively were higher than in lee et al 2020 the difference might have been caused by different u thresholds in the two studies but also possibly by lacking the consideration of light inhibition of daytime r e in the current ann approach nevertheless in contrast to the daytime intercept partitioning these anns have the advantage of taking various additional environmental variables into account using additional predictors a further developed fine tuning of the hyper parameters or different model architectures could have led to different results and increased model accuracy 2 the results from the ann models showed that the interannual variability of r e and gpp and hence of nep were mainly caused by late winter and spring t a and summer p an early increase of t a in late winter spring resulted in higher annual r e whereas a dry summer low summer p decreased gpp annual mean t a can explain interannual variability of gpp but not of r e this means that seasonal weather conditions are more appropriate than annual averages or totals to characterize interannual variability of nep 3 the predictor analysis showed that q was the single most important predictor in the gpp model q explained more than half r2 of 0 44 of the variance explained by the gpp model using all predictors r2 of 0 80 including θ s lw and lw resulted in an r2 of 0 72 lower θ s contributed appreciably to a reduction in gpp in the years 2002 2004 and 2011 2013 which were years with dry summer months july september 4 t s was the most important predictor in the r en model explaining 88 r2 of 0 38 of the total explained variance in the r en model using all predictors the r en model using all predictors explained only slightly more r2 of 0 43 however θ s became the single most important predictor in the r en model in late summer july september 5 at the study site enso events were characterized by higher and lower annual t a for el niño and la niña events respectively el niño and la niña events generally resulted in lower and higher annual nep respectively over the 15 years however due to the different responses of r e and gpp to t a changes in spring and summer the timing of enso events was crucial in determining whether annual nep increased or decreased in addition enso events appeared to have a stronger influence on gpp than on r e credit authorship contribution statement ferdinand briegel conceptualization methodology software visualization writing original draft sung ching lee data curation writing review editing t andrew black project administration supervision writing review editing rachhpal s jassal andreas christen supervision resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported and funded by the natural sciences and engineering research council of canada discovery grants ac tab and by the university of freiburg ac the research infrastructure has been supported by the canada foundation for innovation cfi we sincerely thank island timberlands lp for the permission to work on their land and their logistical support we greatly appreciate the assistance of robert halsall rick ketler and zoran nesic for maintaining the long term climate and ec observations appendix appendix a linear regressions appendix b sequential model based optimization the aim of the sequential model based optimization process is to find a hyper parameter set which will minimize the objective function in this case mse on the test dataset to set up the optimization process five steps are required 1 defining a range domain for the hyper parameters over which to search hyper parameter space 2 creating an objective function here mse which must be maximized minimized 3 creating a prior for the first fit of the probabilistic model gaussian process model using an initial random search in hyper parameter space 4 creating a surrogate gaussian process model of the objective function 5 choosing an acquisition function for determining which hyper parameter combination to choose next expected improvement the defined ranges for the number of layers hidden units and the batch size are given in table 2 r en model layers 1 3 hidden units 30 120 batch size 10 80 gpp model layers 1 3 hidden units 80 150 batch size 30 110 the number of hidden units per layer was halved in each subsequent layer the objective function is the ann with the number of layers hidden units and the batch size as hyper parameters and mse as the evaluation metric score as the objective function is time consuming to compute the surrogate model is optimized instead the surrogate model is also called a response surface since it describes the probability representation of the hyper parameters and their respective objective function scores mse using the results of the initial random search hence a continuous score function over the hyper parameter space was approximated step 4 rasmussen and williams 2005 the gaussian process model was used as the surrogate model brochu et al 2010 the covariance function controls the smoothness and amplitude of samples from the gaussian process model a matérn kernel with v 5 2 was used as the covariance function rasmussen and williams 2005 from this distribution of score functions of the gaussian process model the acquisition function computed the hyper parameter composition leading to the largest expected improvement over the current score step 5 in this process the acquisition function finds a trade off between exploration and exploitation brochu et al 2010 the computed hyper parameter composition was then used by the objective function the computed score by objective function and the corresponding hyper parameter set update the data of the surrogate model posterior and a new distribution of functions was drawn by the gaussian process model the acquisition function could then identify another hyper parameter composition this means that steps 4 and 5 were repeated iteratively the initial random search was 20 random drawn hyper parameter compositions the bayesian optimization was iterated 25 times in total 45 hyper parameter compositions were computed appendix c predictor analysis after the hyper parameter optimization of the ann models a predictor analysis was conducted to investigate the driving factors explaining r e and gpp a stepwise forward selection was implemented which adds one predictor at a time beysolow ii 2017 every predictor was 5 fold cross validated four times the predictor with the highest model improvement reduced mse was added to the model using eleven predictors led to 66 and 91 r en and gpp models respectively that had to be run the impact of different weather conditions the effect of enso events during the study period and seasonal patterns on predictor importance were investigated by an interannual and seasonal predictor analysis for this purpose a moving window of two years was applied over the 15 year study period moving forward one year at a time for each two year window a complete model selection process was conducted and also a predictor analysis the moving window was applied to the data to determine whether interannual variability results in varying predictor importance the same procedures were applied to investigate whether predictor relevance changes within a year by using a moving window of three months moving forward one month at a time the monthly moving window used data from the entire study period because some months had poor data coverage and anns were much less reliable when there is little training data in addition our study aimed to determine the seasonal effects of environmental variables on r e gpp and nep appendix d spearman correlations 
