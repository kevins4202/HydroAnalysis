index,text
520,continuous time random walk ctrw models of non fickian solute transport are defined by a temporal pdf and three parameters a velocity like constant a dispersion like constant and a time constant presently to identify a model all are jointly calibrated against solute breakthrough data we show that without loss of generality the time constant can be set to unity and velocity like and dispersion like ctrw parameters can be set equal to well defined classical counterparts and thus physically pre constrained thus only one entity the pdf requires empirical fitting during model calibration rather than four our assertions are backed by numerical analysis 1 introduction it is well known that classical solute transport models based on the advection dipserson equation do not always adequately capture reality in the subsurface two types of processes are generally responsible for this mobile immobile mass transfer mimt and heterogeneous advection mimt has long been treated by specialized modeling approaches including retardation factors explicit two domain models e g neretnieks 1980 and dual porosity approaches gerke and van genuchten 1993 following villermaux 1974 general time nonlocal approaches have been developed that treat the relationship between the mobile and immobile phase concentrations with a so called memory function haggerty and gorelick 1995 carrera et al 1998 schumer et al 2003 other time nonlocal formulations do not explicitly consider the immobile phase but rather the delay caused by immobilization events including the time domain random walk tdrw delay and bodin 2001 cvetkovic and haggerty 2002 painter et al 2008 and cognate approaches margolin et al 2003 benson and meerschaert 2009 hansen 2015 tdrw represents a special case of continuous time random walks ctrw with fixed spatial steps full ctrw has also been used to explicitly capture mimt dentz and berkowitz 2003 berkowitz et al 2008 for mimt the various time nonlocal approaches can be seen to be largely equivalent heterogeneous advection has also been recognized as a cause of non fickian transport willmann et al 2008 berkowitz et al 2008 gotovac et al 2009 zhang et al 2013 edery et al 2014 hansen et al 2018 fuks et al 2019 nissan and berkowitz 2019 to model such behavior the ctrw has proved a popular choice berkowitz et al 2008 srinivasan et al 2010 comolli and dentz 2017 including upscaled quasi 1d formulations using a tdrw simplification hansen and berkowitz 2014 cvetkovic et al 2014 2016 fractional calculus approaches schumer et al 2001 liu et al 2003 zhang et al 2009 benson et al 2013 have also been successfully employed although many valid conceptual approaches have been proposed for modeling non fickian transport owing to one or both of mimt and heterogeneous advection we focus here solely on the ctrw which is a popular paradigm that naturally captures non fickian and as a special case fickian transport arising from both types of physics this note does not attempt to provide a critical evaluation of the various non fickian transport models in existence considered from an eulerian point of view the ctrw is described by a generalized master equation with the following form berkowitz et al 2006 1 p x t t 0 t m t t v p x t x d 2 p x t x 2 d t in which p is random walker density m is a temporal memory function and v and d are constants in general the ctrw memory function is defined in the laplace domain in terms of an arbitrary transition time probability function ψ t according the formula 2 m s τ s ψ s 1 ψ s where superscript tilde denotes the laplace transform s is the laplace variable and τ is an arbitrary time constant which does not have an obvious physical interpretation in total the ctrw is defined by three parameters along with a single univariate pdf if m t δ t and v and d are respectively identified with an advection velocity v and fickian dispersion constant d then the ctrw master equation can be made to take the form of the familiar advection dispersion equation ade 3 p x t t v p x t x d 2 p x t x 2 however in the general case the physical interpretation of ψ t τ v and d remains unresolved in what remains the canonical review of usage of ctrw in hydrogeology berkowitz et al 2006 remark it is important to recognize that the transport velocity v is distinct from the average fluid velocity v whereas in the classical advection dispersion picture these velocities are identical similarly the dispersion d has a different physical interpretation than in the usual ade definition similarly in discussing ctrw and mobile immobile mass transfer mimt models fiori et al 2015 remark it is again emphasized that the parameters velocity and longitudinal dispersion which appear in both models have a different meaning and need not be equal also they are generally different from the same parameters appearing in the fickian equation for purely advective transport for instance velocity and longitudinal dispersion in the generalized linear model refer to the mobile domain in mimt hence the mean velocity is generally different and likely larger than the mean eulerian velocity while the opposite is expected for longitudinal dispersion on account of the lack of direct physical interpretation of the parameters they must be jointly calibrated by fitting combinations against solute breakthrough curves btc this is the technique illustrated in the user s manual for the popular ctrw toolbox cortis et al 2017 and is used in the recent large scale study by fiori et al 2015 validating the predictive nature of ctrw for both heterogeneous advection and mimt recent authors nissan et al 2016 have observed that the time constant may be subsumed into the other parameters it is clear that if τ were to be multiplied by any factor and v and d divided by the same factor then the form of 1 would be unchanged and does not require separate identification however it remains the state of the art to treat the ctrw velocity like and dispersion like terms as distinct from their ade counterparts and to calibrate them simultaneously with ψ t this is an under determined inverse problem hansen and berkowitz 2014 which requires identification over a relatively high dimensional space and whose non uniqueness precludes direct physical interpretation of the identified parameters below we demonstrate that significant further simplification of the ctrw parameter identification process is possible for ctrw models of both heterogeneous advection and mimt it is meaningful to speak of a classical v and d describing a portion of the dynamics we show that in such cases one may without loss of generality assume that v and d are respectively identical to v and d and thus may be pre constrained by physics prior to knowledge of btc behavior and furthermore assume that the time constant τ is always unity as a consequence only ψ t requires calibration greatly simplifying the task of model identification 2 analysis consider a random walk on a 1d lattice with spacing δ x at fixed times with temporal spacing δ t particles may move in either direction with probabilities π δ x and π δ x let p xn t be the number of walkers at node at x at time t and δ p x n t p x n t δ t p x n then 4 δ p x t p x δ x t π δ x p x δ x t π δ x p x t π δ x p x t π δ x we may define the following difference operators as employed by hansen and berkowitz 2015 5 d δ x 2 δ t π δ x π δ x 2 6 v 2 δ x δ t π δ x π δ x 2 these arise from the relations e x v δ t and e x e x 2 2 d δ t so the operator d 5 only approximates the growth rate of the position variance for small grid peclet numbers although the analysis of this section is valid for all values of π δ x and π δ x it follows from dividing both sides of 4 by δ t and rearranging that 7 δ p x t δ t v p x δ x t p x δ x t 2 δ x d p x δ x t 2 p x t p x δ x t δ x 2 noticing that the square brackets represent central finite difference approximations and considering the limit of small δ x and δ t we arrive at 8 p x t t v p x t x d 2 p x t x 2 this is the classical ade showing the physical interpretation of the difference operators v and d in the limiting case turning next to the ctrw master equation berkowitz et al 2006 appendix a presents a discrete site laplace domain picture of the ctrw which is subsequently used to develop 1 this is presented in our notation 9 s p x s x s ψ s 1 ψ s π x x p x s x s ψ s 1 ψ s π x x p x reducing the complexity of this expression by noticing that we are working on a 1d lattice with nearest neighbor transitions we write 10 s p x s s ψ s 1 ψ s p x δ x s π δ x p x δ x s π δ x p x s π δ x p x s π δ x observing that the square bracketed term on the rhs has an identical form as the rhs of 4 we can define difference operators v and d similar to those that were previously defined in 5 and 6 11 d δ x 2 τ π δ x π δ x 2 12 v 2 δ x τ π δ x π δ x 2 and manipulate 10 to arrive at 13 s p x s τ s ψ s 1 ψ s v p x δ x s p x n δ x s 2 δ x d p x δ x s 2 p x s p x δ x s δ x 2 in the limit of small δ x 14 s p x s τ s ψ s 1 ψ s v p x s x d 2 p x s x 2 which is the laplace transform of 1 we note in passing that these arguments extend unproblematically into higher dimensions the key point of the above manipulations is that v v and d d in exactly the case in which τ and δ t are identified in other words 1 it is possible to select τ in 2 so that v v and d d simultaneously so long as v and d are well defined for the system at hand 2 τ and ψ t form a pair such that ψ t represents the actual clock time taken to complete a transition that takes operational time τ to complete with only ade physics operative this gives a subordination interpretation to the additional physics not captured by the classical v and d and also indicates that on physical grounds for any value of τ there is a corresponding ψ t that such that the transport behavior described by 1 and 2 is unchanged straightforward analysis shows how τ and ψ t evolve together the convolution theorem for the laplace transform stipulates that l ψ t ψ t ψ 2 s where l represents the laplace transform operator or more generally that l ψ t n ψ n s for any integer n understanding τ and ψ t as a pair defining a mapping from operational to clock time it follows that the transformations τ nτ ψ s ψ n s preserve the behavior of 1 indeed it is easy to extend this analysis to any rational power m implying that τ mτ ψ s ψ m s preserve the behavior of 1 this property is demonstrated numerically in section 3 a consequence of this argument is that as long as v and d can be meaningfully spoken of in a system described by a ctrw model v and d can be constrained equal to them by selection of an appropriate τ and then this τ can be subsequently and without loss of generality be reset equal to unity with an appropriate modification to ψ t without changing the solution to 1 thus only ψ t requires identification from btc fitting analysis in this case but can v and d be meaningfully spoken of we can see that the answer is yes for the two key classes of subsurface ctrw models those describing mimt and those upscaling heterogeneous advection as well as combinations of the two types of physics for models of mimt the situation is straightforward v and d describe the transport of a particle that is not subject to capture into the immobile zone and the waiting time distribution ψ t represents the total time taken by a particle that is subject to such capture corresponding to mobile time τ the usage of ctrw where ψ t represents total time taken for unit mobile time is not new see e g dentz and berkowitz 2003 benson and meerschaert 2009 hansen et al 2016 however these and other previous efforts in the realm of mimt e g carrera et al 1998 schumer et al 2003 have led to eulerian governing equations of the form 15 p x t t g t v p x t x d 2 p x t x 2 rather than 1 where the memory function g does not obviously have an equivalent m reciprocals of laplace transforms are generally not themselves well defined laplace transforms the novelty in this context is the observation that v and d in 1 have their ordinary fickian interpretations under mimt we see that under the simplifications proposed here for ctrw calibration 1 is totally equivalent to 15 under the relation m s g s 1 defining g s to be the transform of the classic memory function of e g carrera et al 1998 where g s 1 g s it can be shown that ψ s can be expressed in terms of g s and vice versa g s has the interpretation of being the s domain ratio of immobile to mobile concentrations whereas in this context ψ t has the t domain interpretation of the ratio of mobile plus immobile time to mobile time we observe below that ψ t maintains a cognate interpretation even when there is no immobile phase for models of heterogeneous advection the most straightforward choice is to follow the approach of hansen and berkowitz 2014 by setting v u the mean field scale pore water velocity and d 0 defining a transition to occur each time a particle traverses an additional fixed distance down gradient here ψ t essentially represents the epistemic uncertainty about the time taken for darcy advection between these fixed milestones which would take place in time τ under pure advection we see that for both trapping type processes mimt models and partially resolved heterogeneous advection encompassing the hydrogeologic situations for which a ctrw approach might reasonably desired there exists a natural division of transport models into classical ade behavior that the ctrw v and d are defined to capture and additional physics defined by a subordination mapping τ 1 ψ t 3 numerical demonstrations 3 1 setting we look to demonstrate our claims in a straightforward setting the evaluation of breakthrough curves in 1d resulting from an instantaneous particle injection at x 0 m t 0 d we assume the governing transport physics are δ t 0 5 d v 0 05 m d d 5 10 4 m 2 d alongside pareto distributed ψ t 16 ψ t β τ β t β 1 t τ 0 t τ where here τ δ t 0 5 d and β 0 55 representing a heavy tailed pure delay process this pdf has the approximate laplace transform dentz et al 2015 17 ψ s 1 γ 1 β τ s β finally we observe that 1 and 2 are equally applicable to both resident concentration p and flux concentration cf dentz et al 2004 burnell et al 2017 and have known laplace domain solutions dentz et al 2004 the laplace domain solution corresponding to a semi infinite domain with boundary condition c f 0 t δ t is 18 c f x s e x 2 d v v 2 4 d s m s 3 2 the substitutions v v and d d 3 2 1 the underlying random walk langevin equations the eulerian master equation 1 is expressed in terms of particle concentration p this is an ensemble quantity representing the spatio temporal distribution of the locations of individual random walkers whose locations are each continuously updated by a stochastic differential equation known as a langevin equation langevin equations can be re expressed as discrete step analogs enabling the use of so called particle tracking pt numerical approaches pt has long been used to model both fickian kinzelbach 1988 and non fickian e g srinivasan et al 2010 transport and the corresponding discrete step langevin equations are well known we briefly summarize them here adapting the equations of kinzelbach 1988 to a compact matrix notation classical advective dispersive mass transfer with velocity vector v and dispersion tensor d is described by the discrete step equations 19 x i 1 x i v δ t 2 δ t b η 20 t i 1 t i δ t where η n 0 i is a random vector i is the time step index and b is defined implicitly by the factorization d bb t which always exists because d is a symmetric non negative definite matrix adding the subordination τ δ t ψ t is straightforward 21 x i 1 x i v δ t 2 δ t b η 22 t i 1 t i ζ in which ζ ψ t is a scalar random variable these equations directly describe advection with velocity vector v and fickian dispersion in accordance with tensor d acting in concert with a trapping process mapping a mobile time δ t to total mobile plus immobile time ψ t 3 2 2 comparison of ctrw master equation with langevin simulations the ctrw parameters defining 1 and 2 are correct exactly to the extent that they describe the evolution of the ensemble statistics of particles that evolve according the discrete step langevin equations 21 and 22 thus there is a natural way for us to numerically test the validity of our claims regarding v and d we first perform a pt simulation using 21 and 22 and arbitrary v d δ t and ψ t store particle trajectories and from them produce empirical concentration profiles and or breakthrough curves we finally make the assignments v v d d τ δ t in the laplace domain solution and numerically invert to the time domain using the algorithm of abate and valkó 2004 to compare with the histograms produced directly by pt they should be the same regardless of the choices of v d δ t and ψ t first we evaluate 21 and 22 using particle tracking and empirically determine the breakthrough curve at x 3 m by interpolating the arrival time histogram and normalizing it to have unit integral finally we numerically invert 18 when x 3 to determine the breakthrough curve predicted to correspond the pt histogram results are shown in fig 1 and demonstrate excellent fidelity between the true physics and the ctrw master equation 1 that purports to capture it when parameters are assigned v v d d τ δ t this corroborates our claims 3 3 the substitution τ 1 above we argued that the simultaneous transformations τ mτ ψ s ψ m s preserve the behavior of 1 allowing one first select τ to simultaneously set v v and d d and then reset τ 1 by use of m τ 1 without changing system behavior leaving the pdf ψ m as the only entity requiring calibration we illustrate this transformation by numerically inverting 18 with τ δ t 0 5 d and ψ s as defined in 17 and then again with τ mτ ψ s ψ m s for m 0 1 and 0 01 these three breakthrough curves are shown in fig 1 to be essentially identical 4 summary and conclusion a difficulty in ctrw solute transport model identification has been the multitude of parameters to be identified the parameters are under determined by transport data multiple different sets of parameters lead to the same transport behavior and lack general physical interpretations meaning that they are not pre constrained and must be jointly calibrated from btc data we argue that for ctrw subsurface transport models of both mimt and heterogeneous advection it is meaningful to speak of an advection velocity v and fickian dispersion d describing a classical portion of the transport behavior overlaid with a subordination process describing additional physics in such cases we show that it is possible to set the ctrw parameters v and d equal to v and d respectively and also to set the time constant τ 1 without loss of generality as a consequence only the ctrw pdf ψ t needs to be determined from fitting btc data our claims are corroborated numerically incidentally to our analysis we provide a lagrangian interpretation to the ctrw transition time distribution ψ t it is seen as a probabilistic mapping representing the amount of time taken under all applicable physics to complete transport that takes unit time under classical physics it is also apparent that under the simplifications on v d and τ that we suggest for the ctrw for mimt there is a direct one to one relation between the ctrw master equation and the left hand side convolution approach 15 derived from multi rate mass transfer declaration of competing interest i declare no conflicts of interest acknowledgment skh holds the helen unger career development chair in desert hydrogeology at ben gurion university 
520,continuous time random walk ctrw models of non fickian solute transport are defined by a temporal pdf and three parameters a velocity like constant a dispersion like constant and a time constant presently to identify a model all are jointly calibrated against solute breakthrough data we show that without loss of generality the time constant can be set to unity and velocity like and dispersion like ctrw parameters can be set equal to well defined classical counterparts and thus physically pre constrained thus only one entity the pdf requires empirical fitting during model calibration rather than four our assertions are backed by numerical analysis 1 introduction it is well known that classical solute transport models based on the advection dipserson equation do not always adequately capture reality in the subsurface two types of processes are generally responsible for this mobile immobile mass transfer mimt and heterogeneous advection mimt has long been treated by specialized modeling approaches including retardation factors explicit two domain models e g neretnieks 1980 and dual porosity approaches gerke and van genuchten 1993 following villermaux 1974 general time nonlocal approaches have been developed that treat the relationship between the mobile and immobile phase concentrations with a so called memory function haggerty and gorelick 1995 carrera et al 1998 schumer et al 2003 other time nonlocal formulations do not explicitly consider the immobile phase but rather the delay caused by immobilization events including the time domain random walk tdrw delay and bodin 2001 cvetkovic and haggerty 2002 painter et al 2008 and cognate approaches margolin et al 2003 benson and meerschaert 2009 hansen 2015 tdrw represents a special case of continuous time random walks ctrw with fixed spatial steps full ctrw has also been used to explicitly capture mimt dentz and berkowitz 2003 berkowitz et al 2008 for mimt the various time nonlocal approaches can be seen to be largely equivalent heterogeneous advection has also been recognized as a cause of non fickian transport willmann et al 2008 berkowitz et al 2008 gotovac et al 2009 zhang et al 2013 edery et al 2014 hansen et al 2018 fuks et al 2019 nissan and berkowitz 2019 to model such behavior the ctrw has proved a popular choice berkowitz et al 2008 srinivasan et al 2010 comolli and dentz 2017 including upscaled quasi 1d formulations using a tdrw simplification hansen and berkowitz 2014 cvetkovic et al 2014 2016 fractional calculus approaches schumer et al 2001 liu et al 2003 zhang et al 2009 benson et al 2013 have also been successfully employed although many valid conceptual approaches have been proposed for modeling non fickian transport owing to one or both of mimt and heterogeneous advection we focus here solely on the ctrw which is a popular paradigm that naturally captures non fickian and as a special case fickian transport arising from both types of physics this note does not attempt to provide a critical evaluation of the various non fickian transport models in existence considered from an eulerian point of view the ctrw is described by a generalized master equation with the following form berkowitz et al 2006 1 p x t t 0 t m t t v p x t x d 2 p x t x 2 d t in which p is random walker density m is a temporal memory function and v and d are constants in general the ctrw memory function is defined in the laplace domain in terms of an arbitrary transition time probability function ψ t according the formula 2 m s τ s ψ s 1 ψ s where superscript tilde denotes the laplace transform s is the laplace variable and τ is an arbitrary time constant which does not have an obvious physical interpretation in total the ctrw is defined by three parameters along with a single univariate pdf if m t δ t and v and d are respectively identified with an advection velocity v and fickian dispersion constant d then the ctrw master equation can be made to take the form of the familiar advection dispersion equation ade 3 p x t t v p x t x d 2 p x t x 2 however in the general case the physical interpretation of ψ t τ v and d remains unresolved in what remains the canonical review of usage of ctrw in hydrogeology berkowitz et al 2006 remark it is important to recognize that the transport velocity v is distinct from the average fluid velocity v whereas in the classical advection dispersion picture these velocities are identical similarly the dispersion d has a different physical interpretation than in the usual ade definition similarly in discussing ctrw and mobile immobile mass transfer mimt models fiori et al 2015 remark it is again emphasized that the parameters velocity and longitudinal dispersion which appear in both models have a different meaning and need not be equal also they are generally different from the same parameters appearing in the fickian equation for purely advective transport for instance velocity and longitudinal dispersion in the generalized linear model refer to the mobile domain in mimt hence the mean velocity is generally different and likely larger than the mean eulerian velocity while the opposite is expected for longitudinal dispersion on account of the lack of direct physical interpretation of the parameters they must be jointly calibrated by fitting combinations against solute breakthrough curves btc this is the technique illustrated in the user s manual for the popular ctrw toolbox cortis et al 2017 and is used in the recent large scale study by fiori et al 2015 validating the predictive nature of ctrw for both heterogeneous advection and mimt recent authors nissan et al 2016 have observed that the time constant may be subsumed into the other parameters it is clear that if τ were to be multiplied by any factor and v and d divided by the same factor then the form of 1 would be unchanged and does not require separate identification however it remains the state of the art to treat the ctrw velocity like and dispersion like terms as distinct from their ade counterparts and to calibrate them simultaneously with ψ t this is an under determined inverse problem hansen and berkowitz 2014 which requires identification over a relatively high dimensional space and whose non uniqueness precludes direct physical interpretation of the identified parameters below we demonstrate that significant further simplification of the ctrw parameter identification process is possible for ctrw models of both heterogeneous advection and mimt it is meaningful to speak of a classical v and d describing a portion of the dynamics we show that in such cases one may without loss of generality assume that v and d are respectively identical to v and d and thus may be pre constrained by physics prior to knowledge of btc behavior and furthermore assume that the time constant τ is always unity as a consequence only ψ t requires calibration greatly simplifying the task of model identification 2 analysis consider a random walk on a 1d lattice with spacing δ x at fixed times with temporal spacing δ t particles may move in either direction with probabilities π δ x and π δ x let p xn t be the number of walkers at node at x at time t and δ p x n t p x n t δ t p x n then 4 δ p x t p x δ x t π δ x p x δ x t π δ x p x t π δ x p x t π δ x we may define the following difference operators as employed by hansen and berkowitz 2015 5 d δ x 2 δ t π δ x π δ x 2 6 v 2 δ x δ t π δ x π δ x 2 these arise from the relations e x v δ t and e x e x 2 2 d δ t so the operator d 5 only approximates the growth rate of the position variance for small grid peclet numbers although the analysis of this section is valid for all values of π δ x and π δ x it follows from dividing both sides of 4 by δ t and rearranging that 7 δ p x t δ t v p x δ x t p x δ x t 2 δ x d p x δ x t 2 p x t p x δ x t δ x 2 noticing that the square brackets represent central finite difference approximations and considering the limit of small δ x and δ t we arrive at 8 p x t t v p x t x d 2 p x t x 2 this is the classical ade showing the physical interpretation of the difference operators v and d in the limiting case turning next to the ctrw master equation berkowitz et al 2006 appendix a presents a discrete site laplace domain picture of the ctrw which is subsequently used to develop 1 this is presented in our notation 9 s p x s x s ψ s 1 ψ s π x x p x s x s ψ s 1 ψ s π x x p x reducing the complexity of this expression by noticing that we are working on a 1d lattice with nearest neighbor transitions we write 10 s p x s s ψ s 1 ψ s p x δ x s π δ x p x δ x s π δ x p x s π δ x p x s π δ x observing that the square bracketed term on the rhs has an identical form as the rhs of 4 we can define difference operators v and d similar to those that were previously defined in 5 and 6 11 d δ x 2 τ π δ x π δ x 2 12 v 2 δ x τ π δ x π δ x 2 and manipulate 10 to arrive at 13 s p x s τ s ψ s 1 ψ s v p x δ x s p x n δ x s 2 δ x d p x δ x s 2 p x s p x δ x s δ x 2 in the limit of small δ x 14 s p x s τ s ψ s 1 ψ s v p x s x d 2 p x s x 2 which is the laplace transform of 1 we note in passing that these arguments extend unproblematically into higher dimensions the key point of the above manipulations is that v v and d d in exactly the case in which τ and δ t are identified in other words 1 it is possible to select τ in 2 so that v v and d d simultaneously so long as v and d are well defined for the system at hand 2 τ and ψ t form a pair such that ψ t represents the actual clock time taken to complete a transition that takes operational time τ to complete with only ade physics operative this gives a subordination interpretation to the additional physics not captured by the classical v and d and also indicates that on physical grounds for any value of τ there is a corresponding ψ t that such that the transport behavior described by 1 and 2 is unchanged straightforward analysis shows how τ and ψ t evolve together the convolution theorem for the laplace transform stipulates that l ψ t ψ t ψ 2 s where l represents the laplace transform operator or more generally that l ψ t n ψ n s for any integer n understanding τ and ψ t as a pair defining a mapping from operational to clock time it follows that the transformations τ nτ ψ s ψ n s preserve the behavior of 1 indeed it is easy to extend this analysis to any rational power m implying that τ mτ ψ s ψ m s preserve the behavior of 1 this property is demonstrated numerically in section 3 a consequence of this argument is that as long as v and d can be meaningfully spoken of in a system described by a ctrw model v and d can be constrained equal to them by selection of an appropriate τ and then this τ can be subsequently and without loss of generality be reset equal to unity with an appropriate modification to ψ t without changing the solution to 1 thus only ψ t requires identification from btc fitting analysis in this case but can v and d be meaningfully spoken of we can see that the answer is yes for the two key classes of subsurface ctrw models those describing mimt and those upscaling heterogeneous advection as well as combinations of the two types of physics for models of mimt the situation is straightforward v and d describe the transport of a particle that is not subject to capture into the immobile zone and the waiting time distribution ψ t represents the total time taken by a particle that is subject to such capture corresponding to mobile time τ the usage of ctrw where ψ t represents total time taken for unit mobile time is not new see e g dentz and berkowitz 2003 benson and meerschaert 2009 hansen et al 2016 however these and other previous efforts in the realm of mimt e g carrera et al 1998 schumer et al 2003 have led to eulerian governing equations of the form 15 p x t t g t v p x t x d 2 p x t x 2 rather than 1 where the memory function g does not obviously have an equivalent m reciprocals of laplace transforms are generally not themselves well defined laplace transforms the novelty in this context is the observation that v and d in 1 have their ordinary fickian interpretations under mimt we see that under the simplifications proposed here for ctrw calibration 1 is totally equivalent to 15 under the relation m s g s 1 defining g s to be the transform of the classic memory function of e g carrera et al 1998 where g s 1 g s it can be shown that ψ s can be expressed in terms of g s and vice versa g s has the interpretation of being the s domain ratio of immobile to mobile concentrations whereas in this context ψ t has the t domain interpretation of the ratio of mobile plus immobile time to mobile time we observe below that ψ t maintains a cognate interpretation even when there is no immobile phase for models of heterogeneous advection the most straightforward choice is to follow the approach of hansen and berkowitz 2014 by setting v u the mean field scale pore water velocity and d 0 defining a transition to occur each time a particle traverses an additional fixed distance down gradient here ψ t essentially represents the epistemic uncertainty about the time taken for darcy advection between these fixed milestones which would take place in time τ under pure advection we see that for both trapping type processes mimt models and partially resolved heterogeneous advection encompassing the hydrogeologic situations for which a ctrw approach might reasonably desired there exists a natural division of transport models into classical ade behavior that the ctrw v and d are defined to capture and additional physics defined by a subordination mapping τ 1 ψ t 3 numerical demonstrations 3 1 setting we look to demonstrate our claims in a straightforward setting the evaluation of breakthrough curves in 1d resulting from an instantaneous particle injection at x 0 m t 0 d we assume the governing transport physics are δ t 0 5 d v 0 05 m d d 5 10 4 m 2 d alongside pareto distributed ψ t 16 ψ t β τ β t β 1 t τ 0 t τ where here τ δ t 0 5 d and β 0 55 representing a heavy tailed pure delay process this pdf has the approximate laplace transform dentz et al 2015 17 ψ s 1 γ 1 β τ s β finally we observe that 1 and 2 are equally applicable to both resident concentration p and flux concentration cf dentz et al 2004 burnell et al 2017 and have known laplace domain solutions dentz et al 2004 the laplace domain solution corresponding to a semi infinite domain with boundary condition c f 0 t δ t is 18 c f x s e x 2 d v v 2 4 d s m s 3 2 the substitutions v v and d d 3 2 1 the underlying random walk langevin equations the eulerian master equation 1 is expressed in terms of particle concentration p this is an ensemble quantity representing the spatio temporal distribution of the locations of individual random walkers whose locations are each continuously updated by a stochastic differential equation known as a langevin equation langevin equations can be re expressed as discrete step analogs enabling the use of so called particle tracking pt numerical approaches pt has long been used to model both fickian kinzelbach 1988 and non fickian e g srinivasan et al 2010 transport and the corresponding discrete step langevin equations are well known we briefly summarize them here adapting the equations of kinzelbach 1988 to a compact matrix notation classical advective dispersive mass transfer with velocity vector v and dispersion tensor d is described by the discrete step equations 19 x i 1 x i v δ t 2 δ t b η 20 t i 1 t i δ t where η n 0 i is a random vector i is the time step index and b is defined implicitly by the factorization d bb t which always exists because d is a symmetric non negative definite matrix adding the subordination τ δ t ψ t is straightforward 21 x i 1 x i v δ t 2 δ t b η 22 t i 1 t i ζ in which ζ ψ t is a scalar random variable these equations directly describe advection with velocity vector v and fickian dispersion in accordance with tensor d acting in concert with a trapping process mapping a mobile time δ t to total mobile plus immobile time ψ t 3 2 2 comparison of ctrw master equation with langevin simulations the ctrw parameters defining 1 and 2 are correct exactly to the extent that they describe the evolution of the ensemble statistics of particles that evolve according the discrete step langevin equations 21 and 22 thus there is a natural way for us to numerically test the validity of our claims regarding v and d we first perform a pt simulation using 21 and 22 and arbitrary v d δ t and ψ t store particle trajectories and from them produce empirical concentration profiles and or breakthrough curves we finally make the assignments v v d d τ δ t in the laplace domain solution and numerically invert to the time domain using the algorithm of abate and valkó 2004 to compare with the histograms produced directly by pt they should be the same regardless of the choices of v d δ t and ψ t first we evaluate 21 and 22 using particle tracking and empirically determine the breakthrough curve at x 3 m by interpolating the arrival time histogram and normalizing it to have unit integral finally we numerically invert 18 when x 3 to determine the breakthrough curve predicted to correspond the pt histogram results are shown in fig 1 and demonstrate excellent fidelity between the true physics and the ctrw master equation 1 that purports to capture it when parameters are assigned v v d d τ δ t this corroborates our claims 3 3 the substitution τ 1 above we argued that the simultaneous transformations τ mτ ψ s ψ m s preserve the behavior of 1 allowing one first select τ to simultaneously set v v and d d and then reset τ 1 by use of m τ 1 without changing system behavior leaving the pdf ψ m as the only entity requiring calibration we illustrate this transformation by numerically inverting 18 with τ δ t 0 5 d and ψ s as defined in 17 and then again with τ mτ ψ s ψ m s for m 0 1 and 0 01 these three breakthrough curves are shown in fig 1 to be essentially identical 4 summary and conclusion a difficulty in ctrw solute transport model identification has been the multitude of parameters to be identified the parameters are under determined by transport data multiple different sets of parameters lead to the same transport behavior and lack general physical interpretations meaning that they are not pre constrained and must be jointly calibrated from btc data we argue that for ctrw subsurface transport models of both mimt and heterogeneous advection it is meaningful to speak of an advection velocity v and fickian dispersion d describing a classical portion of the transport behavior overlaid with a subordination process describing additional physics in such cases we show that it is possible to set the ctrw parameters v and d equal to v and d respectively and also to set the time constant τ 1 without loss of generality as a consequence only the ctrw pdf ψ t needs to be determined from fitting btc data our claims are corroborated numerically incidentally to our analysis we provide a lagrangian interpretation to the ctrw transition time distribution ψ t it is seen as a probabilistic mapping representing the amount of time taken under all applicable physics to complete transport that takes unit time under classical physics it is also apparent that under the simplifications on v d and τ that we suggest for the ctrw for mimt there is a direct one to one relation between the ctrw master equation and the left hand side convolution approach 15 derived from multi rate mass transfer declaration of competing interest i declare no conflicts of interest acknowledgment skh holds the helen unger career development chair in desert hydrogeology at ben gurion university 
521,the spatiotemporal monitoring of droughts is a complex task in the past decades drought monitoring has been increasingly developed while the consideration of its spatio temporal dynamics is still a challenge this study proposes a method to build the spatial tracks and paths of drought which can enhance its monitoring the steps for the drought tracks calculation are 1 identification of spatial units areas 2 centroids localisation and 3 centroids linkage the spatio temporal analysis performed here to extract the areas and centroids builds upon the contiguous drought area cda analysis the potential of the proposed methodology is illustrated using grid data from the standardized precipitation evaporation index spei global drought monitor over india 1901 2013 as an example the method to calculate the drought tracks allows for identification of drought paths delineated by an onset and an end in space and time tracks severity and duration of the drought are identified as well as localisation onset and end position and rotation the response of the drought tracking method to different combinations of parameters is also analysed further research is in progress to set up a model to predict the drought tracks for particular regions across the world including india https www researchgate net project stand spatio temporal analysis of drought graphical abstract image graphical abstract keywords spatio temporal drought analysis drought tracking drought dynamics drought monitoring drought characterisation 1 introduction drought is a regional phenomenon that often covers large territorial extensions world meteorological organization wmo 2006 it can occur anywhere in the world with severe consequences impacts in water resources and socioeconomic activities below et al 2007 sheffield and wood 2011 tallaksen and van lanen 2004 wilhite 2000 wmo stresses that to improve drought impacts mitigation it is necessary to develop and implement national policies based on the best description and characterisation of drought world meteorological organization wmo 2006 there is no unique definition of drought however there is an agreement that it is an anomaly in precipitation and temperature that when extended over a region causes a lack of soil moisture runoff and groundwater mishra and singh 2010 van loon 2015 this lack of water is expressed by a drought indicator which transforms the hydro meteorological variable into a value that is related to such a water anomaly mishra and singh 2011 wanders et al 2010 in drought monitoring the drought indicators are generally used to identify the lack of water regarding drought monitoring hao et al 2017 provide an overview of its status for regional and global applications they report as an essential advance the integration of more data resources to feed drought indicators allowing for a better description of hydro meteorological and vegetation condition this integration includes the use of hydrological simulations as well as remote sensing and forecasting data for instance the european drought observatory sepulcre cantó et al 2012 provides the condition of drought evolution development in europe based on satellite observations and modelled soil moisture on the one hand current drought monitoring allows for following drought development for a specific location or a given region mainly through the visualisation and analysis of time series of drought indicators on the other hand the spatial condition of drought including its extent is monitored with the help of time snapshots which provide qualitative information on the spatial behaviour of the phenomenon in terms of the spatial development of the drought nowadays the available drought monitors deliver information about the spatial extent of droughts i e snapshots however consistent procedures for tracking of drought areas are lacking not allowing for assessing temporal variations that form its spatio temporal dynamics hao et al 2017 in addition the spatial distribution of drought at a specific time does not give information about the spatial pathway of the droughts implementing the data analysis and hydroinformatics technologies to trace drought in space and in time on drought monitors can enhance its spatial tracking and prediction the necessity to increase our understanding of the spatio temporal development of drought has motivated the studies where drought is considered as a phenomenon that has at least the following main characteristics duration intensity magnitude and spatial extent area andreadis et al 2005 corzo perez et al 2011 diaz et al 2018 herrera estrada et al 2017 lloyd hughes 2012 sheffield et al 2009 tallaksen et al 2009 van huijgevoort et al 2013 vernieuwe et al 2019 a general framework for carrying out spatio temporal analysis of drought can be formulated based on these studies and it can be briefly described as follows first a given drought indicator is used to transform the hydro meteorological variable into water anomalies the drought indicator is computed in a spatial context where the study region is embedded in a grid then by establishing a threshold on the drought indicator the condition of non drought drought is identified in each of the cells of the grid this condition can be expressed in a binary way i e using 0 s and 1 s finally neighbouring cells showing the same drought condition are aggregated into regions clusters by applying a clustering technique in this way drought is defined in space and in time with a spatial extent and duration the spatio temporal analysis of drought that would also include the spatial drought tracking explicitly is however limited to a few studies such as diaz et al 2018 herrera estrada et al 2017 and zhou et al 2019 the first two address the analysis for large scale studies and the latter presents a basin scale application although there are other publications that consider the study of drought extent locations they miss the explicit calculation of spatial drought tracks following the framework mentioned in the previous paragraph after the extraction of drought extents areas it is possible to identify their location and further construction of the spatial tracks defined by the linkage between consecutive centroids in time the calculation and further analysis of these tracks along with outcome on drought areas may help to answer the following questions regarding drought dynamics what are the main places where drought remains are there predominant routes followed by drought how fast does drought change its extent and location along its spatial path literature review shows that the development of methodologies to describe drought dynamics is still in progress therefore more research is needed in this regard e g herrera estrada et al 2017 vernieuwe et al 2019 zhou et al 2019 this study aims to explain the main principles of a new method that complement current drought monitoring by tracking the spatial extent of drought referred to in this document as area or cluster in this study the description and the application of the methodology to calculate drought tracks are presented in detail the proposed method is accompanied by an algorithm to calculate the drought characteristics both methods are described after this introduction section the spatio temporal contiguous drought area cda analysis corzo perez et al 2011 is used as the basis for the development of the tracking method the cda is applied to identify the neighbouring cells that form the drought clusters a drought is defined by an onset location pathway over time and an end location based on the built tracks a new drought characteristic is introduced in this study namely rotation sect 2 2 a feature often used when tracking objects in space details in sect 2 2 the application of drought tracking method is performed over the country of india for the period 1901 2013 2 methods 2 1 s track spatial tracking of drought the spatial identification of drought tracks is firstly introduced by diaz et al 2018 and further developed in this research s track consists of the three main steps 1 calculation of the spatial drought units referred to here also as areas or clusters 2 localisation of centroids and 3 linkage of centroids fig 1 step 1 spatial drought units computation in the spatial context drought units are identified by means of the contiguous drought area cda analysis corzo perez et al 2011 a cda is composed of neighbouring cells in drought these cells in drought are identified in each time step when the drought indicator is below or equal to the selected threshold the value of 1 is used to indicate that the cell is in drought otherwise the value of 0 is used indicating non drought drought indicators dis are mathematical representations of a water anomaly see sect 2 3 1 in general cda can be applied over any di that is in a grid form following the cda methodology in each time step the cdas are computed cda analysis follows a connected component labelling approach to cluster the cells in drought haralick and shapiro 1992 in this approach a two scan algorithm is applied firstly each cell is numbered for location issues then the first run is performed where the binary grid is explored and connected contiguous components cells are assigned with provisional labels these labels point out the connection of every cell with its 8 nearest neighbours within the grid in a section of 3 3 cells 9 cells in total the central cell has 8 surroundings in this first run the cell s label does not refer to the number of cluster yet but to the cells with which the given cell is connected finally a second scan is carried out to find similar cell connections i e clusters which are given a unique label examination of the grid can be performed by columns or by rows cda analysis is conducted in each time step over the whole grid for more details on cda analysis refer to corzo perez et al 2011 the use of cda relies on the assumption that the binary description of drought condition 0 s and 1 s is homogeneous over the whole grid thus if two or more cells denote drought conditions value of 1 and are contiguous in space it is assumed that all of them are part of the same drought unit in this respect it is recommended to choose a drought indicator that considers the normalisation of the values in the spatial domain in this study a standardised drought indicator is applied as mentioned afterwards which allows the clustering of neighbouring cells in drought cells with 1 s after clusters areas in drought are identified the major largest one is identified in each time step t fig 1 as the tracking algorithm focuses on the calculation of the major spatial drought extent in each time step small or one cell units are discriminated with the selection of the largest one allowing the elimination of possible artefact drought areas step 2 centroids localisation after identification of the major largest drought cluster its centroid p is calculated in each time step this feature is used as the location of the cluster in a similar way as corzo perez et al 2011 and lloyd hughes 2012 present the way in which the clusters are joined in time is explained in the following step step 2 and 3 presented in this document are an extension of the cda analysis of corzo perez et al 2011 another possibility to indicate the location of a given cluster is for instance to use the point with the lowest drought indicator value andreadis et al 2005 herrera estrada et al 2017 in this research we chose the centroid since we already reduce the spatial representation of drought indicator by using only 1 s and 0 s i e drought and non drought condition respectively step 3 centroids linkage the algorithm to link centroids of consecutive clusters in time is a set of rules to separate or join the sequence in time fig 2 the rules consider two types of threshold parameters 1 two that control the magnitude size of the cluster a with dimensions l2 and 2 two that constrain the euclidean distance between consecutive clusters δl with dimensions l fig 2 the parameters are denoted as follows a b c and d the first two are used to the drought area a and the last two to the distance δl the output in this step is the time series of 0 s and 1 s denoted by s t here the value of 1 indicates the linkage of clusters in time if the cluster at time t is not connected with the cluster at time t 1 the value of 0 is used instead consecutive values of 1 s in the time series s show the occurrence of what is defined as a drought track the flowchart of the rules for linking the centroids is presented in fig 2 and below these rules are explained centroids linkage starts by identifying if the cluster area a is higher than a fig 2 rule 1 this first comparison helps to discriminate small clusters if a is below a there is no connection between consecutive clusters and this procedure finalises retrieving 0 before comparing the distance between areas δl the second comparison of a is applied to identify if it is a very large area fig 2 rule 2 parameter b is proposed to consider these large areas when a is below b the parameter c is used to compare distances between clusters fig 2 rule 3 otherwise when a is above b very large area to restrict the distances parameter d is considered instead fig 2 rule 4 the reason of the second comparison of cluster areas and the use of parameter d is because centroids of clusters with a considerable size may be located farther away from each other and then the distance δl could fall outside of the limit indicated by parameter c fig 3 another parameter that could be included in this linkage algorithm is the degree of overlap between consecutive clusters in time this way of intersection is not considered directly in our linkage algorithm as a parameter e g percentage of overlapping the overlap is contemplated in the use of the parameters that control the distance between clusters an intersection may occur when the distance between centroids is short fig 3 2 2 calculation of drought characteristics the methodology to build drought tracks allows for the identification of paths with an onset and an end location the information calculated along the paths can help to describe the occurrence of drought particularly it is possible to extract information regarding the duration severity as well as rotation in the following analysis of the spatio temporal drought dynamics severity has a different meaning compared to on site analysis or cda studies in the latter it expresses a certain degree of water missing an anomaly compared to normal conditions herein severity has a spatial meaning it is connected to the temporal evolution of the size of the area in drought irrespective of the strength of the drought in the following paragraphs the procedure to calculate drought characteristics is presented the proposed approach is called ddrastic spatial drought duration severity and intensity computing spatial events ddrastic spatial is applied after drought tracks are identified by the s track algorithm this approach has as a predecessor diaz et al 2019 which however does not consider the elements related to the spatial domain such as clusters locations and paths for the calculation of the drought duration firstly the onset and the end are obtained the time series s t of 1 s and 0 s calculated with s track method is analysed to do so as mentioned the consecutive sequence of 1 s in the time series s indicates the occurrence of a drought track one isolated value of 1 shows the linking of two clusters in time two consecutive values of 1 show the linkage of three clusters in time and so on in a sequence of 1 s the time of the first value of 1 t first is the time step at which the second and first cluster are connected the time step of the last value of 1 t last is the one when the last and the penultimate clusters are linked the onset ti is defined as ti t first 1 while the end tf as tf t last the duration dd is calculated with eq 1 1 d d t t i t f s t the magnitudes of areas of the largest clusters calculated in each time step with s track method are saved in the time series da drought area the drought area is used as the measure of the drought severity ds which is computed as the sum of drought areas of the period defined by the onset ti and the end tf eq 2 drought intensity di is defined as the ratio between drought severity and duration eq 3 2 d s t t i t f da t 3 d i d s d d identification of locations where a drought path starts and ends can provide its main direction the initial and final locations are identified using the centroids of the first and last cluster respectively the location is a relative position in the spatial domain of the study region it refers to a point in the axes south north s n and west east w e fig 4 the origin of the axes is assigned arbitrarily here it is proposed to place this origin in the centroid of the study region the centroid of a particular cluster can be located in one of the nine proposed positions centre c east e northeast ne north n northwest nw west w southwest sw south s and southeast se fig 4 centre c is situated in the centroid of the study region fig 4 a point centroid is in the centre if the distance r between such point and the origin is within the r min radius fig 4 if distance r is out of the r min radius the location is assigned based on the angle θ this angle is calculated between the w e axis and the line defined between the centroid and origin fig 4 all the rules to identify the centroid s location are presented in table 1 within the algorithm instead of letters locations are denoted by means of numerical identifiers ids as presented in the first column of table 1 drought tracks provide the visual overview of how drought moves in the spatial domain initial and end location initial and end point of the track help to identify the direction followed by a given drought cluster yet another characteristic that complements the description of the drought dynamics is its rotation this characteristic is defined as the circular orientation followed by the spatial extent of drought rotation is a feature commonly attributed to objects that experience changes in space it is an essential characteristic analysed in other weather related phenomena such as cyclones e g chavas et al 2017 rahman et al 2018 but that has not been used and explored much in droughts so far this characteristic is included because it is foreseen that it can help to analyse the impact of the drought drivers such as the climate and land surface control factors on the spatial development of droughts the drought rotation patterns are expected to be different for each combination of the aforementioned factors we see this study as an initial step towards developing a technological framework for identifying and interpreting the drought rotation as the drought track can switch between clockwise and counter clockwise along the pathway we propose to classify the rotation in a more general way as 1 mostly clockwise cw or 2 mostly counter clockwise ccw fig 5 to determine the rotation a procedure is suggested which makes use of the centroids coordinates the algorithm is based on computing a polygon s area a from the vector with the coordinates x and y representing the vertices eq 4 in this algorithm firstly the sum of products between the coordinates x and y denoted by ρ eq 5 is calculated then ρ is applied to define the rotation direction eq 6 the coordinates x and y are taken from the ones of centroids clusters when there are only two points two clusters or when the track is horizontal or vertical the rotation is not defined because ρ takes the value of zero in fig 5 two examples of the calculation of rotation are shown by way of illustration one example is presented for mostly counter clockwise fig 5 left and one for mostly clockwise fig 5 right we chose this approach to compute rotation because it distinguishes between big and small turns in the calculation eq 5 the fourth column in both tables presented in fig 5 provides examples of how the magnitude of each turn is considered differently in the rotation algorithm 4 a 1 2 ρ 5 ρ x 1 x n y 1 y n i 1 n 1 x i 1 x i y i 1 y i 6 ω cw mostly clockwise if ρ 0 ccw mostly couter clockwise if ρ 0 nan not defined if ρ 0 2 3 experimental setup 2 3 1 drought indicator data drought tracks were calculated with s track algorithm for the period 1901 to 2013 113 years the analysis was conducted for india on a monthly basis data from the standardized precipitation evaporation index spei global drought monitor http spei csic es was used beguería et al 2014 to test the proposed methodology for drought tracking and characterisation the procedure to calculate spei vicente serrano et al 2010 is similar to the one used to compute the standardized precipitation index spi mckee et al 1993 but taking into account precipitation p minus potential evaporation e instead of only p spei data from the drought monitor are in a grid form for different temporal aggregation periods in this study we used spei 6 which corresponds to anomalies of the six month accumulation of p e this aggregation usually refers to extended periods of lack of water availability therefore consequences of what is commonly called meteorological drought are closer to that caused by the so called hydrological drought world meteorological organization wmo 2012 2 3 2 drought areas and centroids before the application of the drought tracking algorithm the size of the largest clusters and the distances between the centroids of consecutive clusters in time were calculated this calculation was performed on the one hand to understand the order of their magnitude and frequency and on the other hand to set the values of the tracking algorithm parameters for the definition of drought areas usually the threshold of 1 is used to indicate drought condition in the drought indicators that follow a similar methodology than spi also referred to as standardised ones in this research the same threshold spei 1 was selected to define drought condition in each cell of the grid in each time step when spei was below 1 with 1 s the drought condition was indicated in another case with 0 s the non drought status was pointed out this binary representation allowed the identification of spatial drought units clusters through the application of the spatio temporal analysis of contiguous drought area cda sect 2 1 the largest clusters in each time step were then identified the area of the largest cluster was compared with the total one to identify the similarity in size between them it is assumed that the more similar the larger area to the total one the better the identification of the drought tracks will be this stands because the tracking algorithm focuses on only one area per time step for the comparison the area of all clusters da total and the area of the largest one da largest were calculated both areas were expressed as percentages calculated as the ratio between the number of cells in drought and the total number of cells the total number of cells considered for india was 1 173 once the centroids were identified the distances between consecutive centroids were calculated over time sect 2 1 both the clusters and the distances were calculated for the entire period of analysis on a monthly basis 2 3 3 tracking algorithm calibration and evaluation s track uses four parameters and they have to be user defined or better calibrated the problem of calibrating this algorithm is that there is no ground truth data on the drought tracks hence some aliases should be used a full fledged calibration procedure can be applied e g one of the randomised search algorithms like an evolutionary algorithm the optimal parameters should be selected based on information of reported drought in the absence of drought tracks it is necessary to have data at least on the onset and end month of the reported droughts the near optimal parameters are those that provide the best match between the observed and calculated onsets ends however in this paper we applied a simplified procedure considering that there is no available information to compare the calculated drought paths in the study area we limited the procedure to a qualitative analysis of the paths of the most severe droughts reported in the analysis period the droughts of 1905 1942 1965 1972 1987 2000 and 2002 were considered because their severe impacts were referenced guha sapir 2018 the qualitative evaluation was focused on the analysis of the extreme incidences using a combination of parameters from the whole set of combinations we have chosen three the one that produces the smallest number of droughts paths combination 1 the one that yields the largest number of droughts paths combination 3 as well as the one that produces the number of drought paths similar to the number of years of the analysis period combination 2 yet another important part of the algorithm evaluation is its sensitivity analysis it allows for assessing the robustness of the method through the analysis of the outputs under the variation of parameters pannell 1997 sensitivity analysis generally allows answering the following questions when evaluating an algorithm how parameters and output are related what level of accuracy in the parameters is required which parameters are more sensitive and what drought characteristics do they influence most what are the consequences of varying the parameters in principle calibration and sensitivity analysis steps have to be coordinated e g allowing for removal of less sensitive parameters from the set of the parameters to be calibrated e g to speed up calibration in this work as the algorithm is not computationally complex this approach was not followed the sensitivity analysis was performed to assess the effect of parameters over the identification of droughts tracks and characteristics the questions mentioned in the previous paragraph were used as a guideline to perform such an analysis 3 results 3 1 drought areas and centroids drought areas and centroids were computed for the period 1901 to 2013 with respect to the areas firstly the comparison between the area of all clusters da total and area of the largest one da largest was performed fig 6 shows the monthly values of both da total and da largest arranged in matrices columns indicate months from january j to december d while rows point out the year from 1901 to 2013 drought area magnitude is indicated with a colour scale where the darker the colour the higher the drought area is the white colour denotes months with small drought areas less than 10 it is observed that for almost all months da total and da largest have similar values and this agreement is especially high for the largest values the drought area average for the period was 17 4 for da total and 11 5 for da largest fig 6 right presents the difference between da total and da largest across the whole period the average of the differences was 5 9 as da largest and da total were very similar it can be considered that the largest cluster is a good proxy to analyse how drought changes in the region without considering the occurrence of two consecutive drought tracks the centroids of the largest clusters are presented in fig 7 the spatial drought extent is shown schematically with symbols that indicate four intervals of the percentage of drought area with respect to the country extent the origin of the axes is placed in the centre of the country it is observed that the spatial distribution of the centroids is almost uniformly distributed over india however a higher density of the areas with a considerable extent can be seen in the central region the distances between consecutive clusters in time were calculated also for the whole period fig a1 appendix a presents the area of the largest cluster da largest and the distance δl between consecutive clusters in time it can be observed that the occurrence of da largest is greater than 25 during all decades of the analysis period a pattern is observed between da largest and δl when da largest increases δl usually decreases this behaviour was expected because the more the area increases the smaller the distance between centroids becomes this means that the location of the consecutive clusters is becoming the same when δl does not follow this behaviour it might be because the consecutive areas in time are very far each other i e they are part of different drought paths fig 8 shows the frequency of both the largest cluster area da largest and the distance δl between consecutive clusters in time for both variables results are displayed in four intervals it was observed that as the area increases the frequency of long distances between these areas decreases while the frequency of small distances increases for the da largest the intervals of 25 50 and 50 the frequency of the small distances δl 250 km was slightly greater than half of all the distances this results of da largest and the distances δl confirm quantitatively what is observed in fig a1 in general when the area grows the distances between the centroids tend to decrease on the other hand the small value of the frequency of large distances in large areas intervals 25 50 and 50 indicates that there are large consecutive areas in time that are not necessarily connected to each other 3 2 sensitivity of s track results to the choice of parameters s track algorithm has a number of parameters for the reasons mentioned above sect 2 3 3 it is useful to study the sensitivity of its outputs to these parameters based on the results of areas and distances between clusters sect 3 1 the s track algorithm was set to take parameters values within the following ranges a 50 b 50 c 50 and d 50th percentile median as mentioned a and b are parameters that control the size of clusters areas and c and d are parameters that constrain the distances between consecutive clusters in time the average duration average severity onset location as well as end location were calculated for the different combinations of parameters results for a 30 40 and 50 b 50 70 and 90 c 50 60 70 80 and 90 and d 50 60 70 80 and 90 are presented in figs 9 and a2 to a6 appendix a the a and b parameters are expressed as percentage of drought area and c and d as km at the end of this section a summary of the results is presented fig 9 shows the number of drought paths combination of tracks linked in time it is observed that the number of drought paths in general increased when a decreased this is expected since parameter a is the one that determines if a cluster joins the consecutive clusters in each time step when a is small more clusters are expected to be connected in each time step and therefore more drought paths can be identified the value of b used for very large areas influenced the number of paths less than a e g so that when b increased there was a small proportional increase in the number of paths for all combinations of parameters the combined variation of b and c influenced more the number of paths for small values of d it was observed that in general the number of paths drops when a increases and both b c and d decrease in general the number of drought paths was more sensitive to the changes in parameter a in fig a2 the average duration of drought paths is presented although the variation of average duration was small to the changes of parameters a slight increase was observed as a decreased and both b c and d increased the average duration was more sensitive to the increase in c and d that are the parameters that control the distance between consecutive clusters in time regarding the severity it was smaller when a increased and both b c and d decreased fig a3 severity is calculated as the ratio between the total sum of drought areas and duration number of months so it is getting lower as duration increases see eqs 1 2 and 3 similarly to the number of drought paths the average severity was also sensitive to changes in parameter a it was observed that when the number of paths decreased the average severity increased figs a2 and a3 this behaviour in severity is the effect of the selection of a that controls the size of the areas that are joined in each instant of time if a is small more areas can be joined and severity may decrease due to the effect it produces the pooling of more areas of small sizes divided by a longer duration see eqs 1 2 and 3 figs a4 and a5 show the mode of onset and end location of drought paths respectively in fig a4 not many changes were observed in the onset location east was the most common onset location in most combinations of parameters followed by south on the other hand fig a5 shows the end locations that in most combinations the south followed by east were the most common when both a decrease and b increased the south was the most common end location fig a6 shows the mode of rotation it was observed in most cases that mostly clockwise cw was the common rotation in the drought paths when a decreased and b increased the mostly clockwise rotation was the most common rotation this was the case when more drought paths were obtained it was observed that rotation was most sensitive to the variations of c and d that are the parameters which control the distance between consecutive clusters in time summary of results table 2 shows a summary of how the tracking algorithm responds to different combinations of parameters in particular the behaviour of the number of paths duration severity onset and end location as well as rotation is indicated the combinations where it was observed that the values of these characteristics tend to increase or decrease is presented in general the most sensitive parameter important is the one that controls the minimum area parameter a changes in this parameter have more influence on the result of the number of drought paths and duration regarding duration and severity it is observed that as the paths last longer the severity decreases this may apply because the severity is calculated as the sum of the areas of clusters that belong to the drought duration thus while the duration increases the areas that are added tend to be smaller and then the sum does not increase significantly the combination 11 table 2 refers to the identification of paths of very large areas in this combination it is expected that the initial and final locations will be in the centre centroids of these cluster areas tend to be identical to that of the region for these paths it is also observed that the rotation tends to be clockwise in combinations 6 7 and 14 table 2 by decreasing the parameter that controls the minimum area parameter a more drought paths are identified with the characteristic of being long and with a small severity formed by a number of smaller areas in these combinations drought paths usually start in the east and end in the south with a clockwise rotation if the drought path starts in the south it usually ends in the east and in this case the rotation is counter clockwise i e the rotation follows the minor turn table 2 combination 14 in other words if the path starts in the south and ends in the east it is more likely to be directed towards the east showing a counter clockwise rotation instead of going firstly to the west then north and finally east showing a clockwise rotation in this case 3 3 qualitative evaluation of drought paths seven of the most extreme droughts reported during the analysis period were selected for testing s track these droughts as it was mentioned earlier correspond to the following years 1905 1942 1965 1972 1987 2000 and 2002 in the absence of information regarding the dynamics of the droughts such as trajectories our validation focused on the analysis of the calculated tracks in the period when the droughts occurred from the set of parameter combinations shown in the previous section three were selected to analyse the calculated drought tracks for the first combination combination 1 a 50 b 50 c 50 d 50 the number of drought paths obtained was the lowest for the second combination combination 2 a 40 b 50 c 70 d 80 the number of drought paths was similar to the number of years of the analysis period i e there was approximately one drought path per year finally in the third combination combination 3 a 30 b 70 c 90 d 50 the highest number of drought paths was identified fig 10 presents the occurrence of drought paths calculated for the three combinations of parameters columns indicate the months from january j to december d and the rows show the years consecutive cells in colour indicate the occurrence of a drought path fig 10 top the frequency per month was calculated to analyse the distribution of the tracks over the months fig 10 bottom in general the month with the less frequency of drought tracks was march from january to july the first part of the year the frequency was fewer than from august to december it was observed that when the number of drought paths increased fig 10 top from left to right the frequency of drought tracks in each month increased as well fig 10 bottom fig 11 shows the results from the calculation of clusters and distances between centroids to the construction of drought paths for the drought of 1987 1988 in appendix a one can see the other six droughts figs a7 a8 a9 a10 a11 and a12 in fig 11 top clusters and centroids are presented areas of largest cluster da largest and distances between consecutive areas in time δl are shown for the period from 1987 1 to 1988 6 fig 11 centre duration of the drought paths is indicated in a schematic way with a horizontal line for each combination of parameters drought tracks calculated with the three combinations of parameters are also presented fig 11 bottom in most of the seven droughts the maximum areas of the largest clusters were in the second half of the year and the first half of the following one e g fig 11 centre it was observed that in general when da largest increased δl usually tended to decrease e g fig 11 centre this relationship can be explored in further research to define quantitatively the onset and end of the droughts table 3 presents a summary of the duration of the selected droughts it was observed that although the number of drought paths increases from the combination 1 fig 10 left to the combination 3 fig 10 right in terms of the most severe droughts the durations remain almost similar table 3 column 2 and 4 and fig 11 bottom more drought tracks were identified in the first part of the year in combination 3 if the parameters c and d that control the distance between centroids are more flexible i e consider longer distances drought tracks of the second part of the year are more likely to join those of the first part of the next year as occurs in combination 2 in the combination 2 the drought paths showed the longest durations table 3 column 3 and fig 11 bottom centre in all the selected droughts figs 11 and a7 to a12 it was observed that consecutive clusters in time overlap considerably which suggests that the spatial extent after reaching a considerable size it remains in the same region this presence of large drought areas in the same region over time may explain the severity of drought events in those droughts there was no predominant pathway followed by droughts in those years in terms of spatial extent 2000 and 2002 events were the largest as shown in figs a11 and a12 respectively the drought with the longest duration was that of 1965 table 3 which is consistent with the reported in guha sapir 2018 4 discussion 4 1 drought indicator and areas in the presented version of the tracking method we used a unique threshold over the drought indicator to indicate drought and non drought conditions in each grid cell 1 s and 0 s this threshold is one of the most common used in drought studies when considering standardised drought indicators spei was applied in this research but it is possible to use any other including threshold approach wanders et al 2010 with the condition of being spatially distributed the effects of other drought indicator thresholds over the cluster size were not assessed because the scope of this study was limited to testing the drought tracking algorithm on the other hand the clustering algorithm used in this study assumes that all cell values in the space domain are homogeneous to ensure that this assumption is correct it is recommended the selection of a drought indicator that uses a normalization procedure into its calculation in addition our clustering approach is based only on drought indicator values and does not consider others aspects that can influence the delimitation of the spatial extent of drought such as topography land use and climate regions in further studies it is recommended to incorporate other elements to make the clustering method more general another way of considering the factors mentioned above without modifying changing the clustering algorithm is the use of a drought indicator that takes into account variables such as soil moisture or runoff 4 2 drought tracking method s track algorithm is an extension of the contiguous drought area cda analysis of corzo perez et al 2011 this drought tracking algorithm was firstly introduced in diaz et al 2018 and further developed in this research the current version of s track focuses on the largest drought areas in this way areas with a considerable territorial extent are identified we are aware that smaller intense droughts would not be captured by this tracking algorithm also that mild droughts over large areas obtained by the algorithm would overshadow smaller intense droughts although s track makes use of cda analysis for the extraction of drought clusters other algorithms used for the same purpose can also be considered these algorithms include the recursion based approach andreadis et al 2005 herrera estrada et al 2017 lloyd hughes 2012 sheffield et al 2009 and variations of the connected component labelling approach van huijgevoort et al 2013 vernieuwe et al 2019 the composition of drought clusters extracted with any of these algorithms should be similar the main difference between the algorithms is in the computational efficiency and processing time which is an important element to consider when processing a large amount of data in this sense algorithms based on connected component labelling are considered to be more efficient he et al 2009 to connect two consecutive clusters in time and ensure that they are not far in space the length between centroids of the clusters is taken into account similar to herrera estrada et al 2017 and zhou et al 2019 the degree of the overlap between these two clusters can be another way to handle the connection between them yet another and more comprehensive way of joining clusters in time is through the use of the cda approach but extended to the time domain i e to connect 26 nearest neighbour cells a forming a cube in space time domain as shown in corzo perez et al 2011 lloyd hughes 2012 and herrera estrada et al 2017 in cases when more than one drought track occurs at the same time the algorithm will aim to identify the one that is composed of the largest areas in its current version the algorithm neither detects simultaneous drought tracks nor merges the areas of the same time step into a single one in this research we compared the area of all clusters and the area of the largest one in each time step to see if the presence of more than one large area is predominant or not we found that difference between da total da largest was in most of the cases close to zero fig 6 this difference between da total and da largest indicates that the size of the area of the largest cluster is very similar to the total one based on the latter it is assumed that the presence of more than one large cluster at the same time step is not dominant then the research was focused on testing the tracking algorithm without considering the effect of the presence of more than one simultaneous drought track if the presence of more than one consecutive drought track is suspected an option to perform this algorithm is to carry our tracking for different sub regions of the study area analyse it by parts and then superimpose the drought tracks in this way one would expect to identify more than one track if any in future versions of the tracking algorithm it is recommended to include the identification of more than one simultaneous drought tracks the use of cda approach can retrieve areas with islands of non drought cells 0 s in this research we do not consider the possible effects of these holes over the drought tracks construction the centroid could be located in one of these holes we assume that centroid is a good spot to locate the contiguous drought area in largest clusters the centroid approaches the centroid of the analysis region this is an expected outcome because if the cluster covers the entire region of analysis the centroid will be similar to that one of the region in our case the maximum da largest was 70 7 therefore in the period of analysis no cluster covered the entire territory in addition two simultaneous large clusters are not expected although the drought tracks that occurred near the boundaries of the domain could not be considered appropriately i e the tracks could be miscalculated it is assumed that these boundary tracks do not significantly impact the region to improve the calculation in such cases it is recommended to increase the size of the analysed region 5 summary and conclusions in this study a method that allows the construction of drought tracks in space is introduced the onset and end of drought paths combination of linked drought tracks are used to compute the drought duration the information obtained during the path calculation is employed to compute the severity as well as the onset and end location direction and rotation all these features have been identified as drought characteristics and are framed within the ddrastic spatial methodology also presented in this paper outputs of the tracking algorithm s track and the method for drought characterisation ddrastic spatial help to describe the dynamics of droughts s track has four parameters parameters a and b control the size of the cluster area to be included in the drought tracks parameters c and d limit the distances between consecutive clusters in time sect 2 1 in this paper s track is used to construct the drought tracks in space from the application of s track some key findings are presented the number of drought paths duration and severity are more sensitive to the change of the parameter that limits the minimum drought area parameter a sect 2 1 if the duration of the drought paths increases severity does not necessarily do so because the longer the duration the areas that make up the path tend to be smaller sect 3 2 to obtain drought paths with longer durations it is important to be flexible with the parameters that control the distance between areas parameters c and d i e to consider larger distances the outcome of the approach presented in this paper is relevant for i drought forecasting i e drought tracks can help to predict how drought moves over a particular region and ii for improving knowledge on drought generating processes the first item is more for operational purposes short term and the second item for scientific research long term regarding the improvement of knowledge on drought generating processes i e the interaction between climate and land surface characteristics a new drought characteristic is introduced in this research the rotation sect 2 2 this feature is used in the study of other weather related phenomena such as cyclones because it helps in the description identification of forcing mechanisms behind their spatial development e g chavas et al 2017 rahman et al 2018 we are of the opinion that this drought characteristic can also help in the identification and description of climate and land surface control factors that drive the spatial behaviour of droughts for the considered case study in india we found that consecutive clusters in time overlap considerably in the droughts selected 1905 1942 1965 1972 1987 2000 and 2002 which suggests that the spatial extent of drought after reaching a considerable size remains in the same region this presence of large drought areas in the same region over time may explain the severity of droughts in those years there is no predominant pathway followed by droughts in those years in terms of spatial extent 2000 and 2002 events are the largest the drought with the longest duration is that of 1965 a paper was prepared where the parameters of the tracking algorithm were calibrated based on the information of droughts reported in that document a description of droughts is presented based on the drought paths and characteristics diaz et al 2019 further research is aimed at trying to develop an approach to predict the subsequent development of tracks identified by s track these progress of these developments and other aspects of the study can be found at www researchgate net project stand spatio temporal analysis of drought author contribution statement vd gacp hvl ds and eav contributed to the design and implementation of the research to the analysis of the results and to the writing of the manuscript appendix a declaration of competing interest the authors declare that there is no conflict of interest regarding the publication of this paper acknowledgements vd thanks the mexican national council for science and technology conacyt and alianza fiidem for the study grand 217776 382365 hvl is supported by the h2020 anywhere project grant agreement no 700099 ds acknowledges the grant no 17 77 30006of the russian science foundation and the hydroinformatics research fund of ihe delft in whose framework some research ideas and components were developed the study is also a contribution to the unesco ihp vii programme euro friend water project and the panta rhei initiative of the international association of hydrological sciences iahs supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103512 appendix supplementary materials image application 1 image application 2 
521,the spatiotemporal monitoring of droughts is a complex task in the past decades drought monitoring has been increasingly developed while the consideration of its spatio temporal dynamics is still a challenge this study proposes a method to build the spatial tracks and paths of drought which can enhance its monitoring the steps for the drought tracks calculation are 1 identification of spatial units areas 2 centroids localisation and 3 centroids linkage the spatio temporal analysis performed here to extract the areas and centroids builds upon the contiguous drought area cda analysis the potential of the proposed methodology is illustrated using grid data from the standardized precipitation evaporation index spei global drought monitor over india 1901 2013 as an example the method to calculate the drought tracks allows for identification of drought paths delineated by an onset and an end in space and time tracks severity and duration of the drought are identified as well as localisation onset and end position and rotation the response of the drought tracking method to different combinations of parameters is also analysed further research is in progress to set up a model to predict the drought tracks for particular regions across the world including india https www researchgate net project stand spatio temporal analysis of drought graphical abstract image graphical abstract keywords spatio temporal drought analysis drought tracking drought dynamics drought monitoring drought characterisation 1 introduction drought is a regional phenomenon that often covers large territorial extensions world meteorological organization wmo 2006 it can occur anywhere in the world with severe consequences impacts in water resources and socioeconomic activities below et al 2007 sheffield and wood 2011 tallaksen and van lanen 2004 wilhite 2000 wmo stresses that to improve drought impacts mitigation it is necessary to develop and implement national policies based on the best description and characterisation of drought world meteorological organization wmo 2006 there is no unique definition of drought however there is an agreement that it is an anomaly in precipitation and temperature that when extended over a region causes a lack of soil moisture runoff and groundwater mishra and singh 2010 van loon 2015 this lack of water is expressed by a drought indicator which transforms the hydro meteorological variable into a value that is related to such a water anomaly mishra and singh 2011 wanders et al 2010 in drought monitoring the drought indicators are generally used to identify the lack of water regarding drought monitoring hao et al 2017 provide an overview of its status for regional and global applications they report as an essential advance the integration of more data resources to feed drought indicators allowing for a better description of hydro meteorological and vegetation condition this integration includes the use of hydrological simulations as well as remote sensing and forecasting data for instance the european drought observatory sepulcre cantó et al 2012 provides the condition of drought evolution development in europe based on satellite observations and modelled soil moisture on the one hand current drought monitoring allows for following drought development for a specific location or a given region mainly through the visualisation and analysis of time series of drought indicators on the other hand the spatial condition of drought including its extent is monitored with the help of time snapshots which provide qualitative information on the spatial behaviour of the phenomenon in terms of the spatial development of the drought nowadays the available drought monitors deliver information about the spatial extent of droughts i e snapshots however consistent procedures for tracking of drought areas are lacking not allowing for assessing temporal variations that form its spatio temporal dynamics hao et al 2017 in addition the spatial distribution of drought at a specific time does not give information about the spatial pathway of the droughts implementing the data analysis and hydroinformatics technologies to trace drought in space and in time on drought monitors can enhance its spatial tracking and prediction the necessity to increase our understanding of the spatio temporal development of drought has motivated the studies where drought is considered as a phenomenon that has at least the following main characteristics duration intensity magnitude and spatial extent area andreadis et al 2005 corzo perez et al 2011 diaz et al 2018 herrera estrada et al 2017 lloyd hughes 2012 sheffield et al 2009 tallaksen et al 2009 van huijgevoort et al 2013 vernieuwe et al 2019 a general framework for carrying out spatio temporal analysis of drought can be formulated based on these studies and it can be briefly described as follows first a given drought indicator is used to transform the hydro meteorological variable into water anomalies the drought indicator is computed in a spatial context where the study region is embedded in a grid then by establishing a threshold on the drought indicator the condition of non drought drought is identified in each of the cells of the grid this condition can be expressed in a binary way i e using 0 s and 1 s finally neighbouring cells showing the same drought condition are aggregated into regions clusters by applying a clustering technique in this way drought is defined in space and in time with a spatial extent and duration the spatio temporal analysis of drought that would also include the spatial drought tracking explicitly is however limited to a few studies such as diaz et al 2018 herrera estrada et al 2017 and zhou et al 2019 the first two address the analysis for large scale studies and the latter presents a basin scale application although there are other publications that consider the study of drought extent locations they miss the explicit calculation of spatial drought tracks following the framework mentioned in the previous paragraph after the extraction of drought extents areas it is possible to identify their location and further construction of the spatial tracks defined by the linkage between consecutive centroids in time the calculation and further analysis of these tracks along with outcome on drought areas may help to answer the following questions regarding drought dynamics what are the main places where drought remains are there predominant routes followed by drought how fast does drought change its extent and location along its spatial path literature review shows that the development of methodologies to describe drought dynamics is still in progress therefore more research is needed in this regard e g herrera estrada et al 2017 vernieuwe et al 2019 zhou et al 2019 this study aims to explain the main principles of a new method that complement current drought monitoring by tracking the spatial extent of drought referred to in this document as area or cluster in this study the description and the application of the methodology to calculate drought tracks are presented in detail the proposed method is accompanied by an algorithm to calculate the drought characteristics both methods are described after this introduction section the spatio temporal contiguous drought area cda analysis corzo perez et al 2011 is used as the basis for the development of the tracking method the cda is applied to identify the neighbouring cells that form the drought clusters a drought is defined by an onset location pathway over time and an end location based on the built tracks a new drought characteristic is introduced in this study namely rotation sect 2 2 a feature often used when tracking objects in space details in sect 2 2 the application of drought tracking method is performed over the country of india for the period 1901 2013 2 methods 2 1 s track spatial tracking of drought the spatial identification of drought tracks is firstly introduced by diaz et al 2018 and further developed in this research s track consists of the three main steps 1 calculation of the spatial drought units referred to here also as areas or clusters 2 localisation of centroids and 3 linkage of centroids fig 1 step 1 spatial drought units computation in the spatial context drought units are identified by means of the contiguous drought area cda analysis corzo perez et al 2011 a cda is composed of neighbouring cells in drought these cells in drought are identified in each time step when the drought indicator is below or equal to the selected threshold the value of 1 is used to indicate that the cell is in drought otherwise the value of 0 is used indicating non drought drought indicators dis are mathematical representations of a water anomaly see sect 2 3 1 in general cda can be applied over any di that is in a grid form following the cda methodology in each time step the cdas are computed cda analysis follows a connected component labelling approach to cluster the cells in drought haralick and shapiro 1992 in this approach a two scan algorithm is applied firstly each cell is numbered for location issues then the first run is performed where the binary grid is explored and connected contiguous components cells are assigned with provisional labels these labels point out the connection of every cell with its 8 nearest neighbours within the grid in a section of 3 3 cells 9 cells in total the central cell has 8 surroundings in this first run the cell s label does not refer to the number of cluster yet but to the cells with which the given cell is connected finally a second scan is carried out to find similar cell connections i e clusters which are given a unique label examination of the grid can be performed by columns or by rows cda analysis is conducted in each time step over the whole grid for more details on cda analysis refer to corzo perez et al 2011 the use of cda relies on the assumption that the binary description of drought condition 0 s and 1 s is homogeneous over the whole grid thus if two or more cells denote drought conditions value of 1 and are contiguous in space it is assumed that all of them are part of the same drought unit in this respect it is recommended to choose a drought indicator that considers the normalisation of the values in the spatial domain in this study a standardised drought indicator is applied as mentioned afterwards which allows the clustering of neighbouring cells in drought cells with 1 s after clusters areas in drought are identified the major largest one is identified in each time step t fig 1 as the tracking algorithm focuses on the calculation of the major spatial drought extent in each time step small or one cell units are discriminated with the selection of the largest one allowing the elimination of possible artefact drought areas step 2 centroids localisation after identification of the major largest drought cluster its centroid p is calculated in each time step this feature is used as the location of the cluster in a similar way as corzo perez et al 2011 and lloyd hughes 2012 present the way in which the clusters are joined in time is explained in the following step step 2 and 3 presented in this document are an extension of the cda analysis of corzo perez et al 2011 another possibility to indicate the location of a given cluster is for instance to use the point with the lowest drought indicator value andreadis et al 2005 herrera estrada et al 2017 in this research we chose the centroid since we already reduce the spatial representation of drought indicator by using only 1 s and 0 s i e drought and non drought condition respectively step 3 centroids linkage the algorithm to link centroids of consecutive clusters in time is a set of rules to separate or join the sequence in time fig 2 the rules consider two types of threshold parameters 1 two that control the magnitude size of the cluster a with dimensions l2 and 2 two that constrain the euclidean distance between consecutive clusters δl with dimensions l fig 2 the parameters are denoted as follows a b c and d the first two are used to the drought area a and the last two to the distance δl the output in this step is the time series of 0 s and 1 s denoted by s t here the value of 1 indicates the linkage of clusters in time if the cluster at time t is not connected with the cluster at time t 1 the value of 0 is used instead consecutive values of 1 s in the time series s show the occurrence of what is defined as a drought track the flowchart of the rules for linking the centroids is presented in fig 2 and below these rules are explained centroids linkage starts by identifying if the cluster area a is higher than a fig 2 rule 1 this first comparison helps to discriminate small clusters if a is below a there is no connection between consecutive clusters and this procedure finalises retrieving 0 before comparing the distance between areas δl the second comparison of a is applied to identify if it is a very large area fig 2 rule 2 parameter b is proposed to consider these large areas when a is below b the parameter c is used to compare distances between clusters fig 2 rule 3 otherwise when a is above b very large area to restrict the distances parameter d is considered instead fig 2 rule 4 the reason of the second comparison of cluster areas and the use of parameter d is because centroids of clusters with a considerable size may be located farther away from each other and then the distance δl could fall outside of the limit indicated by parameter c fig 3 another parameter that could be included in this linkage algorithm is the degree of overlap between consecutive clusters in time this way of intersection is not considered directly in our linkage algorithm as a parameter e g percentage of overlapping the overlap is contemplated in the use of the parameters that control the distance between clusters an intersection may occur when the distance between centroids is short fig 3 2 2 calculation of drought characteristics the methodology to build drought tracks allows for the identification of paths with an onset and an end location the information calculated along the paths can help to describe the occurrence of drought particularly it is possible to extract information regarding the duration severity as well as rotation in the following analysis of the spatio temporal drought dynamics severity has a different meaning compared to on site analysis or cda studies in the latter it expresses a certain degree of water missing an anomaly compared to normal conditions herein severity has a spatial meaning it is connected to the temporal evolution of the size of the area in drought irrespective of the strength of the drought in the following paragraphs the procedure to calculate drought characteristics is presented the proposed approach is called ddrastic spatial drought duration severity and intensity computing spatial events ddrastic spatial is applied after drought tracks are identified by the s track algorithm this approach has as a predecessor diaz et al 2019 which however does not consider the elements related to the spatial domain such as clusters locations and paths for the calculation of the drought duration firstly the onset and the end are obtained the time series s t of 1 s and 0 s calculated with s track method is analysed to do so as mentioned the consecutive sequence of 1 s in the time series s indicates the occurrence of a drought track one isolated value of 1 shows the linking of two clusters in time two consecutive values of 1 show the linkage of three clusters in time and so on in a sequence of 1 s the time of the first value of 1 t first is the time step at which the second and first cluster are connected the time step of the last value of 1 t last is the one when the last and the penultimate clusters are linked the onset ti is defined as ti t first 1 while the end tf as tf t last the duration dd is calculated with eq 1 1 d d t t i t f s t the magnitudes of areas of the largest clusters calculated in each time step with s track method are saved in the time series da drought area the drought area is used as the measure of the drought severity ds which is computed as the sum of drought areas of the period defined by the onset ti and the end tf eq 2 drought intensity di is defined as the ratio between drought severity and duration eq 3 2 d s t t i t f da t 3 d i d s d d identification of locations where a drought path starts and ends can provide its main direction the initial and final locations are identified using the centroids of the first and last cluster respectively the location is a relative position in the spatial domain of the study region it refers to a point in the axes south north s n and west east w e fig 4 the origin of the axes is assigned arbitrarily here it is proposed to place this origin in the centroid of the study region the centroid of a particular cluster can be located in one of the nine proposed positions centre c east e northeast ne north n northwest nw west w southwest sw south s and southeast se fig 4 centre c is situated in the centroid of the study region fig 4 a point centroid is in the centre if the distance r between such point and the origin is within the r min radius fig 4 if distance r is out of the r min radius the location is assigned based on the angle θ this angle is calculated between the w e axis and the line defined between the centroid and origin fig 4 all the rules to identify the centroid s location are presented in table 1 within the algorithm instead of letters locations are denoted by means of numerical identifiers ids as presented in the first column of table 1 drought tracks provide the visual overview of how drought moves in the spatial domain initial and end location initial and end point of the track help to identify the direction followed by a given drought cluster yet another characteristic that complements the description of the drought dynamics is its rotation this characteristic is defined as the circular orientation followed by the spatial extent of drought rotation is a feature commonly attributed to objects that experience changes in space it is an essential characteristic analysed in other weather related phenomena such as cyclones e g chavas et al 2017 rahman et al 2018 but that has not been used and explored much in droughts so far this characteristic is included because it is foreseen that it can help to analyse the impact of the drought drivers such as the climate and land surface control factors on the spatial development of droughts the drought rotation patterns are expected to be different for each combination of the aforementioned factors we see this study as an initial step towards developing a technological framework for identifying and interpreting the drought rotation as the drought track can switch between clockwise and counter clockwise along the pathway we propose to classify the rotation in a more general way as 1 mostly clockwise cw or 2 mostly counter clockwise ccw fig 5 to determine the rotation a procedure is suggested which makes use of the centroids coordinates the algorithm is based on computing a polygon s area a from the vector with the coordinates x and y representing the vertices eq 4 in this algorithm firstly the sum of products between the coordinates x and y denoted by ρ eq 5 is calculated then ρ is applied to define the rotation direction eq 6 the coordinates x and y are taken from the ones of centroids clusters when there are only two points two clusters or when the track is horizontal or vertical the rotation is not defined because ρ takes the value of zero in fig 5 two examples of the calculation of rotation are shown by way of illustration one example is presented for mostly counter clockwise fig 5 left and one for mostly clockwise fig 5 right we chose this approach to compute rotation because it distinguishes between big and small turns in the calculation eq 5 the fourth column in both tables presented in fig 5 provides examples of how the magnitude of each turn is considered differently in the rotation algorithm 4 a 1 2 ρ 5 ρ x 1 x n y 1 y n i 1 n 1 x i 1 x i y i 1 y i 6 ω cw mostly clockwise if ρ 0 ccw mostly couter clockwise if ρ 0 nan not defined if ρ 0 2 3 experimental setup 2 3 1 drought indicator data drought tracks were calculated with s track algorithm for the period 1901 to 2013 113 years the analysis was conducted for india on a monthly basis data from the standardized precipitation evaporation index spei global drought monitor http spei csic es was used beguería et al 2014 to test the proposed methodology for drought tracking and characterisation the procedure to calculate spei vicente serrano et al 2010 is similar to the one used to compute the standardized precipitation index spi mckee et al 1993 but taking into account precipitation p minus potential evaporation e instead of only p spei data from the drought monitor are in a grid form for different temporal aggregation periods in this study we used spei 6 which corresponds to anomalies of the six month accumulation of p e this aggregation usually refers to extended periods of lack of water availability therefore consequences of what is commonly called meteorological drought are closer to that caused by the so called hydrological drought world meteorological organization wmo 2012 2 3 2 drought areas and centroids before the application of the drought tracking algorithm the size of the largest clusters and the distances between the centroids of consecutive clusters in time were calculated this calculation was performed on the one hand to understand the order of their magnitude and frequency and on the other hand to set the values of the tracking algorithm parameters for the definition of drought areas usually the threshold of 1 is used to indicate drought condition in the drought indicators that follow a similar methodology than spi also referred to as standardised ones in this research the same threshold spei 1 was selected to define drought condition in each cell of the grid in each time step when spei was below 1 with 1 s the drought condition was indicated in another case with 0 s the non drought status was pointed out this binary representation allowed the identification of spatial drought units clusters through the application of the spatio temporal analysis of contiguous drought area cda sect 2 1 the largest clusters in each time step were then identified the area of the largest cluster was compared with the total one to identify the similarity in size between them it is assumed that the more similar the larger area to the total one the better the identification of the drought tracks will be this stands because the tracking algorithm focuses on only one area per time step for the comparison the area of all clusters da total and the area of the largest one da largest were calculated both areas were expressed as percentages calculated as the ratio between the number of cells in drought and the total number of cells the total number of cells considered for india was 1 173 once the centroids were identified the distances between consecutive centroids were calculated over time sect 2 1 both the clusters and the distances were calculated for the entire period of analysis on a monthly basis 2 3 3 tracking algorithm calibration and evaluation s track uses four parameters and they have to be user defined or better calibrated the problem of calibrating this algorithm is that there is no ground truth data on the drought tracks hence some aliases should be used a full fledged calibration procedure can be applied e g one of the randomised search algorithms like an evolutionary algorithm the optimal parameters should be selected based on information of reported drought in the absence of drought tracks it is necessary to have data at least on the onset and end month of the reported droughts the near optimal parameters are those that provide the best match between the observed and calculated onsets ends however in this paper we applied a simplified procedure considering that there is no available information to compare the calculated drought paths in the study area we limited the procedure to a qualitative analysis of the paths of the most severe droughts reported in the analysis period the droughts of 1905 1942 1965 1972 1987 2000 and 2002 were considered because their severe impacts were referenced guha sapir 2018 the qualitative evaluation was focused on the analysis of the extreme incidences using a combination of parameters from the whole set of combinations we have chosen three the one that produces the smallest number of droughts paths combination 1 the one that yields the largest number of droughts paths combination 3 as well as the one that produces the number of drought paths similar to the number of years of the analysis period combination 2 yet another important part of the algorithm evaluation is its sensitivity analysis it allows for assessing the robustness of the method through the analysis of the outputs under the variation of parameters pannell 1997 sensitivity analysis generally allows answering the following questions when evaluating an algorithm how parameters and output are related what level of accuracy in the parameters is required which parameters are more sensitive and what drought characteristics do they influence most what are the consequences of varying the parameters in principle calibration and sensitivity analysis steps have to be coordinated e g allowing for removal of less sensitive parameters from the set of the parameters to be calibrated e g to speed up calibration in this work as the algorithm is not computationally complex this approach was not followed the sensitivity analysis was performed to assess the effect of parameters over the identification of droughts tracks and characteristics the questions mentioned in the previous paragraph were used as a guideline to perform such an analysis 3 results 3 1 drought areas and centroids drought areas and centroids were computed for the period 1901 to 2013 with respect to the areas firstly the comparison between the area of all clusters da total and area of the largest one da largest was performed fig 6 shows the monthly values of both da total and da largest arranged in matrices columns indicate months from january j to december d while rows point out the year from 1901 to 2013 drought area magnitude is indicated with a colour scale where the darker the colour the higher the drought area is the white colour denotes months with small drought areas less than 10 it is observed that for almost all months da total and da largest have similar values and this agreement is especially high for the largest values the drought area average for the period was 17 4 for da total and 11 5 for da largest fig 6 right presents the difference between da total and da largest across the whole period the average of the differences was 5 9 as da largest and da total were very similar it can be considered that the largest cluster is a good proxy to analyse how drought changes in the region without considering the occurrence of two consecutive drought tracks the centroids of the largest clusters are presented in fig 7 the spatial drought extent is shown schematically with symbols that indicate four intervals of the percentage of drought area with respect to the country extent the origin of the axes is placed in the centre of the country it is observed that the spatial distribution of the centroids is almost uniformly distributed over india however a higher density of the areas with a considerable extent can be seen in the central region the distances between consecutive clusters in time were calculated also for the whole period fig a1 appendix a presents the area of the largest cluster da largest and the distance δl between consecutive clusters in time it can be observed that the occurrence of da largest is greater than 25 during all decades of the analysis period a pattern is observed between da largest and δl when da largest increases δl usually decreases this behaviour was expected because the more the area increases the smaller the distance between centroids becomes this means that the location of the consecutive clusters is becoming the same when δl does not follow this behaviour it might be because the consecutive areas in time are very far each other i e they are part of different drought paths fig 8 shows the frequency of both the largest cluster area da largest and the distance δl between consecutive clusters in time for both variables results are displayed in four intervals it was observed that as the area increases the frequency of long distances between these areas decreases while the frequency of small distances increases for the da largest the intervals of 25 50 and 50 the frequency of the small distances δl 250 km was slightly greater than half of all the distances this results of da largest and the distances δl confirm quantitatively what is observed in fig a1 in general when the area grows the distances between the centroids tend to decrease on the other hand the small value of the frequency of large distances in large areas intervals 25 50 and 50 indicates that there are large consecutive areas in time that are not necessarily connected to each other 3 2 sensitivity of s track results to the choice of parameters s track algorithm has a number of parameters for the reasons mentioned above sect 2 3 3 it is useful to study the sensitivity of its outputs to these parameters based on the results of areas and distances between clusters sect 3 1 the s track algorithm was set to take parameters values within the following ranges a 50 b 50 c 50 and d 50th percentile median as mentioned a and b are parameters that control the size of clusters areas and c and d are parameters that constrain the distances between consecutive clusters in time the average duration average severity onset location as well as end location were calculated for the different combinations of parameters results for a 30 40 and 50 b 50 70 and 90 c 50 60 70 80 and 90 and d 50 60 70 80 and 90 are presented in figs 9 and a2 to a6 appendix a the a and b parameters are expressed as percentage of drought area and c and d as km at the end of this section a summary of the results is presented fig 9 shows the number of drought paths combination of tracks linked in time it is observed that the number of drought paths in general increased when a decreased this is expected since parameter a is the one that determines if a cluster joins the consecutive clusters in each time step when a is small more clusters are expected to be connected in each time step and therefore more drought paths can be identified the value of b used for very large areas influenced the number of paths less than a e g so that when b increased there was a small proportional increase in the number of paths for all combinations of parameters the combined variation of b and c influenced more the number of paths for small values of d it was observed that in general the number of paths drops when a increases and both b c and d decrease in general the number of drought paths was more sensitive to the changes in parameter a in fig a2 the average duration of drought paths is presented although the variation of average duration was small to the changes of parameters a slight increase was observed as a decreased and both b c and d increased the average duration was more sensitive to the increase in c and d that are the parameters that control the distance between consecutive clusters in time regarding the severity it was smaller when a increased and both b c and d decreased fig a3 severity is calculated as the ratio between the total sum of drought areas and duration number of months so it is getting lower as duration increases see eqs 1 2 and 3 similarly to the number of drought paths the average severity was also sensitive to changes in parameter a it was observed that when the number of paths decreased the average severity increased figs a2 and a3 this behaviour in severity is the effect of the selection of a that controls the size of the areas that are joined in each instant of time if a is small more areas can be joined and severity may decrease due to the effect it produces the pooling of more areas of small sizes divided by a longer duration see eqs 1 2 and 3 figs a4 and a5 show the mode of onset and end location of drought paths respectively in fig a4 not many changes were observed in the onset location east was the most common onset location in most combinations of parameters followed by south on the other hand fig a5 shows the end locations that in most combinations the south followed by east were the most common when both a decrease and b increased the south was the most common end location fig a6 shows the mode of rotation it was observed in most cases that mostly clockwise cw was the common rotation in the drought paths when a decreased and b increased the mostly clockwise rotation was the most common rotation this was the case when more drought paths were obtained it was observed that rotation was most sensitive to the variations of c and d that are the parameters which control the distance between consecutive clusters in time summary of results table 2 shows a summary of how the tracking algorithm responds to different combinations of parameters in particular the behaviour of the number of paths duration severity onset and end location as well as rotation is indicated the combinations where it was observed that the values of these characteristics tend to increase or decrease is presented in general the most sensitive parameter important is the one that controls the minimum area parameter a changes in this parameter have more influence on the result of the number of drought paths and duration regarding duration and severity it is observed that as the paths last longer the severity decreases this may apply because the severity is calculated as the sum of the areas of clusters that belong to the drought duration thus while the duration increases the areas that are added tend to be smaller and then the sum does not increase significantly the combination 11 table 2 refers to the identification of paths of very large areas in this combination it is expected that the initial and final locations will be in the centre centroids of these cluster areas tend to be identical to that of the region for these paths it is also observed that the rotation tends to be clockwise in combinations 6 7 and 14 table 2 by decreasing the parameter that controls the minimum area parameter a more drought paths are identified with the characteristic of being long and with a small severity formed by a number of smaller areas in these combinations drought paths usually start in the east and end in the south with a clockwise rotation if the drought path starts in the south it usually ends in the east and in this case the rotation is counter clockwise i e the rotation follows the minor turn table 2 combination 14 in other words if the path starts in the south and ends in the east it is more likely to be directed towards the east showing a counter clockwise rotation instead of going firstly to the west then north and finally east showing a clockwise rotation in this case 3 3 qualitative evaluation of drought paths seven of the most extreme droughts reported during the analysis period were selected for testing s track these droughts as it was mentioned earlier correspond to the following years 1905 1942 1965 1972 1987 2000 and 2002 in the absence of information regarding the dynamics of the droughts such as trajectories our validation focused on the analysis of the calculated tracks in the period when the droughts occurred from the set of parameter combinations shown in the previous section three were selected to analyse the calculated drought tracks for the first combination combination 1 a 50 b 50 c 50 d 50 the number of drought paths obtained was the lowest for the second combination combination 2 a 40 b 50 c 70 d 80 the number of drought paths was similar to the number of years of the analysis period i e there was approximately one drought path per year finally in the third combination combination 3 a 30 b 70 c 90 d 50 the highest number of drought paths was identified fig 10 presents the occurrence of drought paths calculated for the three combinations of parameters columns indicate the months from january j to december d and the rows show the years consecutive cells in colour indicate the occurrence of a drought path fig 10 top the frequency per month was calculated to analyse the distribution of the tracks over the months fig 10 bottom in general the month with the less frequency of drought tracks was march from january to july the first part of the year the frequency was fewer than from august to december it was observed that when the number of drought paths increased fig 10 top from left to right the frequency of drought tracks in each month increased as well fig 10 bottom fig 11 shows the results from the calculation of clusters and distances between centroids to the construction of drought paths for the drought of 1987 1988 in appendix a one can see the other six droughts figs a7 a8 a9 a10 a11 and a12 in fig 11 top clusters and centroids are presented areas of largest cluster da largest and distances between consecutive areas in time δl are shown for the period from 1987 1 to 1988 6 fig 11 centre duration of the drought paths is indicated in a schematic way with a horizontal line for each combination of parameters drought tracks calculated with the three combinations of parameters are also presented fig 11 bottom in most of the seven droughts the maximum areas of the largest clusters were in the second half of the year and the first half of the following one e g fig 11 centre it was observed that in general when da largest increased δl usually tended to decrease e g fig 11 centre this relationship can be explored in further research to define quantitatively the onset and end of the droughts table 3 presents a summary of the duration of the selected droughts it was observed that although the number of drought paths increases from the combination 1 fig 10 left to the combination 3 fig 10 right in terms of the most severe droughts the durations remain almost similar table 3 column 2 and 4 and fig 11 bottom more drought tracks were identified in the first part of the year in combination 3 if the parameters c and d that control the distance between centroids are more flexible i e consider longer distances drought tracks of the second part of the year are more likely to join those of the first part of the next year as occurs in combination 2 in the combination 2 the drought paths showed the longest durations table 3 column 3 and fig 11 bottom centre in all the selected droughts figs 11 and a7 to a12 it was observed that consecutive clusters in time overlap considerably which suggests that the spatial extent after reaching a considerable size it remains in the same region this presence of large drought areas in the same region over time may explain the severity of drought events in those droughts there was no predominant pathway followed by droughts in those years in terms of spatial extent 2000 and 2002 events were the largest as shown in figs a11 and a12 respectively the drought with the longest duration was that of 1965 table 3 which is consistent with the reported in guha sapir 2018 4 discussion 4 1 drought indicator and areas in the presented version of the tracking method we used a unique threshold over the drought indicator to indicate drought and non drought conditions in each grid cell 1 s and 0 s this threshold is one of the most common used in drought studies when considering standardised drought indicators spei was applied in this research but it is possible to use any other including threshold approach wanders et al 2010 with the condition of being spatially distributed the effects of other drought indicator thresholds over the cluster size were not assessed because the scope of this study was limited to testing the drought tracking algorithm on the other hand the clustering algorithm used in this study assumes that all cell values in the space domain are homogeneous to ensure that this assumption is correct it is recommended the selection of a drought indicator that uses a normalization procedure into its calculation in addition our clustering approach is based only on drought indicator values and does not consider others aspects that can influence the delimitation of the spatial extent of drought such as topography land use and climate regions in further studies it is recommended to incorporate other elements to make the clustering method more general another way of considering the factors mentioned above without modifying changing the clustering algorithm is the use of a drought indicator that takes into account variables such as soil moisture or runoff 4 2 drought tracking method s track algorithm is an extension of the contiguous drought area cda analysis of corzo perez et al 2011 this drought tracking algorithm was firstly introduced in diaz et al 2018 and further developed in this research the current version of s track focuses on the largest drought areas in this way areas with a considerable territorial extent are identified we are aware that smaller intense droughts would not be captured by this tracking algorithm also that mild droughts over large areas obtained by the algorithm would overshadow smaller intense droughts although s track makes use of cda analysis for the extraction of drought clusters other algorithms used for the same purpose can also be considered these algorithms include the recursion based approach andreadis et al 2005 herrera estrada et al 2017 lloyd hughes 2012 sheffield et al 2009 and variations of the connected component labelling approach van huijgevoort et al 2013 vernieuwe et al 2019 the composition of drought clusters extracted with any of these algorithms should be similar the main difference between the algorithms is in the computational efficiency and processing time which is an important element to consider when processing a large amount of data in this sense algorithms based on connected component labelling are considered to be more efficient he et al 2009 to connect two consecutive clusters in time and ensure that they are not far in space the length between centroids of the clusters is taken into account similar to herrera estrada et al 2017 and zhou et al 2019 the degree of the overlap between these two clusters can be another way to handle the connection between them yet another and more comprehensive way of joining clusters in time is through the use of the cda approach but extended to the time domain i e to connect 26 nearest neighbour cells a forming a cube in space time domain as shown in corzo perez et al 2011 lloyd hughes 2012 and herrera estrada et al 2017 in cases when more than one drought track occurs at the same time the algorithm will aim to identify the one that is composed of the largest areas in its current version the algorithm neither detects simultaneous drought tracks nor merges the areas of the same time step into a single one in this research we compared the area of all clusters and the area of the largest one in each time step to see if the presence of more than one large area is predominant or not we found that difference between da total da largest was in most of the cases close to zero fig 6 this difference between da total and da largest indicates that the size of the area of the largest cluster is very similar to the total one based on the latter it is assumed that the presence of more than one large cluster at the same time step is not dominant then the research was focused on testing the tracking algorithm without considering the effect of the presence of more than one simultaneous drought track if the presence of more than one consecutive drought track is suspected an option to perform this algorithm is to carry our tracking for different sub regions of the study area analyse it by parts and then superimpose the drought tracks in this way one would expect to identify more than one track if any in future versions of the tracking algorithm it is recommended to include the identification of more than one simultaneous drought tracks the use of cda approach can retrieve areas with islands of non drought cells 0 s in this research we do not consider the possible effects of these holes over the drought tracks construction the centroid could be located in one of these holes we assume that centroid is a good spot to locate the contiguous drought area in largest clusters the centroid approaches the centroid of the analysis region this is an expected outcome because if the cluster covers the entire region of analysis the centroid will be similar to that one of the region in our case the maximum da largest was 70 7 therefore in the period of analysis no cluster covered the entire territory in addition two simultaneous large clusters are not expected although the drought tracks that occurred near the boundaries of the domain could not be considered appropriately i e the tracks could be miscalculated it is assumed that these boundary tracks do not significantly impact the region to improve the calculation in such cases it is recommended to increase the size of the analysed region 5 summary and conclusions in this study a method that allows the construction of drought tracks in space is introduced the onset and end of drought paths combination of linked drought tracks are used to compute the drought duration the information obtained during the path calculation is employed to compute the severity as well as the onset and end location direction and rotation all these features have been identified as drought characteristics and are framed within the ddrastic spatial methodology also presented in this paper outputs of the tracking algorithm s track and the method for drought characterisation ddrastic spatial help to describe the dynamics of droughts s track has four parameters parameters a and b control the size of the cluster area to be included in the drought tracks parameters c and d limit the distances between consecutive clusters in time sect 2 1 in this paper s track is used to construct the drought tracks in space from the application of s track some key findings are presented the number of drought paths duration and severity are more sensitive to the change of the parameter that limits the minimum drought area parameter a sect 2 1 if the duration of the drought paths increases severity does not necessarily do so because the longer the duration the areas that make up the path tend to be smaller sect 3 2 to obtain drought paths with longer durations it is important to be flexible with the parameters that control the distance between areas parameters c and d i e to consider larger distances the outcome of the approach presented in this paper is relevant for i drought forecasting i e drought tracks can help to predict how drought moves over a particular region and ii for improving knowledge on drought generating processes the first item is more for operational purposes short term and the second item for scientific research long term regarding the improvement of knowledge on drought generating processes i e the interaction between climate and land surface characteristics a new drought characteristic is introduced in this research the rotation sect 2 2 this feature is used in the study of other weather related phenomena such as cyclones because it helps in the description identification of forcing mechanisms behind their spatial development e g chavas et al 2017 rahman et al 2018 we are of the opinion that this drought characteristic can also help in the identification and description of climate and land surface control factors that drive the spatial behaviour of droughts for the considered case study in india we found that consecutive clusters in time overlap considerably in the droughts selected 1905 1942 1965 1972 1987 2000 and 2002 which suggests that the spatial extent of drought after reaching a considerable size remains in the same region this presence of large drought areas in the same region over time may explain the severity of droughts in those years there is no predominant pathway followed by droughts in those years in terms of spatial extent 2000 and 2002 events are the largest the drought with the longest duration is that of 1965 a paper was prepared where the parameters of the tracking algorithm were calibrated based on the information of droughts reported in that document a description of droughts is presented based on the drought paths and characteristics diaz et al 2019 further research is aimed at trying to develop an approach to predict the subsequent development of tracks identified by s track these progress of these developments and other aspects of the study can be found at www researchgate net project stand spatio temporal analysis of drought author contribution statement vd gacp hvl ds and eav contributed to the design and implementation of the research to the analysis of the results and to the writing of the manuscript appendix a declaration of competing interest the authors declare that there is no conflict of interest regarding the publication of this paper acknowledgements vd thanks the mexican national council for science and technology conacyt and alianza fiidem for the study grand 217776 382365 hvl is supported by the h2020 anywhere project grant agreement no 700099 ds acknowledges the grant no 17 77 30006of the russian science foundation and the hydroinformatics research fund of ihe delft in whose framework some research ideas and components were developed the study is also a contribution to the unesco ihp vii programme euro friend water project and the panta rhei initiative of the international association of hydrological sciences iahs supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103512 appendix supplementary materials image application 1 image application 2 
522,we develop a phenomenological model for the effective conductivity of porous media that consist of two distinct materials characterized by different values of hydraulic conductivity our focus is two fold first to relate the terms and parameters of macroscale conductivity to the spatial variability of local flow and conductivity observed in computational experiments and second to develop a reduced order model for effective conductivity based on those observations darcys law is assumed to hold at local mesoscopic and large macroscopic scales at the mesoscale a composite medium is a configuration of irregular subdomains consisting of two different materials the resulting heterogeneities force fluid to flow along irregular paths and this produces spatial variability in the magnitude and the orientation of the darcy flux this variability along with the macroscopic effective conductivity depends on the proportion of the total volume allocated to each material the ratio of the two conductivity values and the spatial connectivity of material subvolumes computational experiments indicate that the effects of heterogeneity are most pronounced when the two conductivity values are very different and when the volume fraction of the more conductive material is near a percolation threshold the percolation threshold is the critical volume fraction of the more conductive material at which the medium is no longer traversed by connected paths through that material the percolation threshold determines the existence of three regimes in effective conductivity two where the effective conductivity obeys power laws and is dominated by one of the materials and a third intermediate regime that interpolates between the power laws keywords stochastic hydrogeology effective conductivity binary random media heterogeneous random fields 1 introduction applications of groundwater hydrology often depend on parameters such as hydraulic conductivity that are known to be highly variable at local scales but cannot be specified as such because the requisite data is not available at small scales for applications that require estimates of system states at scales much larger than the local scale it may be possible to substitute a constant effective parameter for the locally variable parameter in the example of hydraulic conductivity the effective conductivity ke substitutes for local hydraulic conductivity k x this requires the effective parameter to aggregate the critical features of the local parameter field that influence system states at the scale of application if the local parameter field is uniform in space and its variance is not too large an effective parameter based on stochastic averaging may suffice boschan and noetinger 2012 however these conditions are not met for composite porous media which consist of multiple disjoint subvolumes of different materials e g clay lenses in a sand aquifer when individual subvolumes are large enough to affect regional flow directly techniques of aggregation based on averaging over stationary fields will not usually apply such cases need effective parameterizations that are consistent with both the spatial structure of the subvolumes and their material properties if the spatial disposition of subvolumes in a composite medium is known to a good degree of approximation stochastic techniques like random domain decomposition tartakovsky and guadagnini 2004 winter and tartakovsky 2001 can be used to approximate states of flow in many cases however all that is known of the materials are good approximations of their relative volume fractions and average conductivities and the correlation or structure functions of their spatial distribution the modeling challenge becomes identifying the primary features of composite systems that influence regional flows and then to come up with effective parameterizations that produce flow regimes on macroscopic scales that are consistent with the aggregated effects of local flows in this paper we develop a phenomenological model of effective hydraulic conductivity for a large class of composite porous media we focus on media composed of two materials m 0 and m 1 that are arranged in multiple disjoint subvolumes filling a large scaled i e macroscopic domain fig 1 the total volume fractions occupied by subvolumes of the materials are fractions v 0 and v 1 of the total macroscopic volume a material subvolume has constant hydraulic conductivity k 0 or k 1 k 0 k 1 depending on whether it is composed of m 0 or m 1 two thought experiments and a large number 106 of mesoscale computational simulations are used to identify the principal phenomena that an effective conductivity parameter must reflect if it is to closely approximate macroscopic flows produced by a mesoscale composite medium the analysis is carried out in a parameter space v κ defined in terms of v v 1 the volume fraction of m 1 and κ k 0 k 1 the ratio of the two hydraulic conductivities recall m 1 is the more conductive material so 0 κ 1 the corresponding effective conductivity parameter is ke v κ and the model developed for ke v κ in section 4 is denoted by k e m v κ subvolumes of m 1 are said to percolate through an experimental volume when connected paths of m 1 extend from one end of the volume to the other percolation depends on a threshold vc which is the critical value of v that distinguishes between configurations that admit connected paths of m 1 from those that do not the term non percolating geometries refers to configurations where v vc and the term percolating geometries refers to configurations where v vc the proposed model is phenomenological in the sense that it represents the response of hydraulic conductivity to variations in material connectivity as a function of critical percolation depending on v and resistance quantified by κ although it is ad hoc the approach is based on statistical models of phase transitions caused by critical phenomena landau and lifshitz 1960 specifically reductions in flow through porous media induced by decreased connectivity among subvolumes of m 1 resistance to an electrical current due to the presence of a nonconductor in an otherwise conductive volume has long been interpreted as the result of critical percolation in heterogeneous materials landau and lifshitz 1960 experimental studies with percolation and conduction were originally performed by punching holes in carbon paper and measuring electrical conductivity last and thouless 1971 analytic studies kirkpatrick 1973 computer simulations webman et al 1975 and models based on power laws efros and shklovskii 1976 straley 1977 followed shortly thereafter early applications of site and bond percolation on lattices to scaling effective conductivity include the seminal work of kirkpatrick 1973 see isichenko 1992 hunt et al 2014 snarskii et al 2016 for current reviews and ghanbarian and daigle 2016 for recent approaches our work is more closely aligned with the stochastic geometries found in guadagnini et al 2003 renard and allard 2013 adler et al 1990 a number of computational experiments have compared the effective conductivity of realizations of 2d composite porous media to that of realizations augmented by additional connected paths of the more conductive material zinn and harvey 2003 knudby and carrera 2005 knudby et al 2006 finding that connected paths significantly affect the flow the properties of selected metrics for connectivity were investigated in renard and allard 2013 consideration of the effect of local heterogeneities on scale up of groundwater systems was pioneered by matheron 1967 see wen and gomez hernandez 1996 renard and de marsily 1997 dagan et al 2013 sanchez vila et al 2006 for reviews interest initially focused on obtaining bounds for ke in situations like ours where a conductivity field consists of two materials of known hydraulic conductivity in known volumetric proportion but in unspecified spatial configuration the upper and lower bounds for the effective conductivity are well known matheron 1967 in material science hashin and shtrikman 1962 derived tight upper and lower bounds for effective elastic moduli of mildly anisotropic and heterogenous multiphase materials arrayed arbitrarily when two conductive materials are arranged in layers of varying thickness that are perpendicular parallel to the direction of flow ke is the volume weighted harmonic arithmetic average of the hydraulic conductivities matheron 1967 in this study we allow the arrangement of materials to be irregular but isotropic and statistically stationary and we estimate the expected value and variance of the effective conductivity not the bounds from monte carlo simulations the process of decomposing the macroscale domain into irregular subvolumes of two different materials yields three distinct regimes in the effective conductivity ke v κ the regimes occur on subintervals of v given by i 0 v v a i i v a v v b i i i v b v 1 where va and vb depend on κ and satisfy va vc vb the physical basis for the three regimes is illustrated by thought experiments where κ 0 which occurs when either k 1 or k 0 0 snarskii et al 2016 each limit describes the behavior on either subinterval i or iii but not the other the reconciliation of their differences when κ 0 and v vc explains the existence of subinterval ii and motivates a phenomenological model for the effective conductivity over the domain 0 v 1 to motivate regime i consider the situation where k 0 0 and k 1 is finite e g steel and sand when v vc there can be no flow across the domain so k e v 0 on the other hand connected paths of m 1 traverse the domain when v vc so ke v is a positive increasing function of v and ke v 0 as v v c this behavior can be modeled as a power law in v v c with a positive exponent efros and shklovskii 1976 for situations where k 0 0 the fluid is not completely restricted to narrow and tortuous paths through m 1 but can flow through both materials albeit with more resistance when in m 0 in this case the thought experiment underestimates ke v and since ke v must be bounded below by k 0 for all v the prediction that ke v 0 as v v c is no longer physical since k 0 0 and the power law model requires a k 0 dependent modification near vc next consider the situation where k 1 and k 0 is finite to motivate regime iii this corresponds to a massless inviscid fluid flowing through air and clay for instance although this situation is not physical it does provide a valuable perspective when k 1 and v vc fluid is able to flow uninhibited across the domain along connected paths of m 1 so according to the terms of this thought experiment ke must be infinite when v vc connected paths do not exist and fluid must flow through regions of m 0 whose conductivity is finite when v vc ke v is a positive increasing function of v and ke v as v v c this behavior can also be modeled as a power law in v c v this time with a negative exponent efros and shklovskii 1976 when k 1 finite k 1 introduces resistance to the flow in m 1 and for each fixed v k 0 pair decreasing k 1 must decrease ke v the thought experiment has overestimated ke v and since ke must be bounded above by k 1 for all v the prediction that ke as v v c is no longer correct and the power law requires a k 1 dependent modification near vc we investigate how to correct both power laws to maintain physical behavior in subinterval ii when v vc in section 4 the parameters of the model are based on observable quantities our experiments are designed to mimic experiments that might be carried out when characterizing an actual aquifer consequently the physical dimensions of the domain are considered to be fixed known quantities we also assume that the correlation length scale of the conductivity field is known the relation between these length scales the integral scale and the correlation scale has been subject to previous investigation neuman and di federico 2003 boschan and noetinger 2012 dagan et al 2013 we limit our study to conductivity fields with only two materials extensions to conductivity fields with more than two materials could be investigated by similar computational studies we also concentrate only on 1st order effects of the material subvolumes more realistic representations of each material could include modeling a fine scale spatial variability of the hydraulic conductivity within each subvolume i e k i k i x for each material i overview of computational experiments the uncertainty associated with the effects of the unknown conductivity field is estimated by monte carlo simulation samples are generated from a realization of a correlated random field of three independent variables t x y z on the domain ω 0 1 3 for each realization a threshold γ determines the relative volume of each material v 0 and v 1 equivalently 1 v and v and designates material membership points in the domain where the topography is below the threshold are allocated to the more conductive material m 1 and assigned conductivity k 1 1 points in the domain where the topography is above the threshold are allocated to the less conductive material m 0 and assigned conductivity k 0 κ where κ varies systematically from 5 10 1 to 10 5 section 2 1 this process is repeated for n ω 100 different realizations of the correlated random field for each realization ω we generate 200 different random geometries by applying a threshold that corresponds to fixed value of v between v 0 and v 1 for each of the random geometries we then create 15 different conductivity fields by assigning a constant conductivity k 0 and k 1 to each of the materials we compute the effective conductivity as a function of v and κ and make four observations of the data i there are three regimes for conductivity that exist on subintervals of v κ that are governed by the percolation threshold ii the effective conductivity in regimes i and iii can be modeled by power laws in v v c iii the exponents of the power laws appear to be independent of κ and iv regime ii occupies 0 v 1 when κ 1 and collapses on vc as κ 0 section 3 1 to develop a practical and low order model capable of representing each of these observations we view the effective conductivity through the lens that the regimes are characterized by the critical exponents of the two power laws we define our phenomenological model for effective conductivity in composite media via an auxiliary function c v κ v v c v log k e v κ and note that differentiation and algebraic manipulation of power laws show that c v κ is constant on any interval where ke obeys a power law in v v c approximating c v κ by a suitable choice of sigmoid function gives the model 1 k e m v κ a 1 2 v c v 1 2 v c v 2 v c v a 2 α for v v c b 1 2 v v c 1 2 v v c 2 v b v c 2 β for v v c here vc is the critical volume for percolation and is approximately 0 11 the exponents α and β are fit to the data and found to be independent of κ the coefficients a and b and the parameters va and vb are determined by the constraints k e m 0 κ k 0 and k e m 1 κ k 1 and by enforcing continuity and differentiability at v v c flow fields are uniform when κ 1 and when v 0 or v 1 which each correspond to homogeneous media otherwise the flow fields show spatial variability which we represent by two descriptive statistics η the coefficient of variation in the magnitude of the darcy flux and θ the flux weighted average angle of deviation of the darcy flux from the external pressure gradient section 2 4 the simulations show that for each v the spatial variability is increasing as κ 0 and for κ 0 it is greatest when v vc section 3 3 for each v κ pair we compare the effective conductivity with each statistic for spatial variability by computing the correlation across all realizations with the same v and κ the data suggest that the spatial variability is positively correlated with ke for v vc and negatively correlated with ke for v vc further comparisons show that departures from maximum spatial variability coincide with the transition between regimes i and iii section 3 4 2 computation and simulation the unknown local conductivity is modeled as a random field and the effective conductivity is estimated by monte carlo simulation each simulation consists of three computational components first a means of generating realizations of irregular composite media from a chosen ensemble second a suitable method of solving the flow equations to determine local velocities and head gradients and third a means of computing the effective conductivity for each conductivity field two descriptive statistics for the spatial variability of the flow are computed and compared to the effective conductivity 2 1 generating realizations of irregular composite media the local conductivity is modeled by thresholded random fields which provides a computationally efficient means of generating spatially irregular composite media samples of random conductivity fields k x where x x y z t are generated by the following three step algorithm a realization of a correlated gaussian random field t x y z of three independent variables is generated by convolving a rectangular array of i i d random variables with a kernel a threshold γ defines the interfacial boundaries of the two materials by γ x t x γ and thereby determines material membership by m 0 x t x γ and m 1 x t x γ the level set definition of the boundary process implies that an increase in the threshold reallocates some of the domain from the less conductive material to the more conductive material so m 0 m 0 and m 1 m 1 whenever γ γ this has the effect of pushing the boundary strictly outwards from the perspective of the less conductive material so that the geometry of the configuration changes incrementally with γ and the topology of the configuration changes infrequently the volume fraction allocated to each material depends on the statistical properties of the correlated random field t and on the threshold γ this random field is fully defined by the i i d random variables and by the kernel adler and taylor 2007 adler et al 1990 hyman and winter 2014 all realizations of the topography are sampled from the same random field we non dimensionalize the spatial variables to l x l y l z 1 and set n x n y n z 100 we pick i i d random variables from a standard normal distribution and use a symmetric gaussian kernel of width 0 025 the width of the kernel determines the correlation length of the random topography which is rx 0 075 therefore the approximate number of independent features is given by the ratio l x r x 13 3 and the discretized resolution of each feature is given by the ratio r x δ x 7 5 2 2 numerical solution to the pde the flow equation k h 0 is discretized by defining the pressure head at the nodes and by defining the hydraulic conductivity and the darcy flux between adjacent nodes the conductivity field is originally defined at the nodes so values between adjacent nodes are approximated by taking the harmonic averages of the values at the nodes k i 1 2 j k 1 k i j k 1 k i 1 j k 1 2 dirichlet boundary conditions fixed hydraulic head are prescribed on the faces corresponding to x 0 and x 1 and periodic boundary conditions on the faces corresponding to y 0 y 1 z 0 and z 1 the derivatives are approximated by second order finite differences and the resulting linear system is solved using the biconjugate gradient method to a tolerance of 10 9 the solution to the system of equations is the pressure head at each node h i j k so the darcy flux between the nodes u i 1 2 j k v i j 1 2 k and w i j k 1 2 is recovered by darcy s law u i 1 2 j k k i 1 2 j k h i 1 j k h i j k δ x etc values of the darcy flux at the nodes q i j k u i j k v i j k w i j k are found by interpolation 2 3 computing effective conductivity each index i defines a transect plane perpendicular to the external head gradient the total flux through each transect qi is estimated by summation of the normal component of the darcy flux perpendicular to the transect u i j k for all indices j k and multiplication by δy δz it is verified that the flux through each transect is constant which we define as the total fluid flux q the effective conductivity is computed by 2 k e l x h 1 h 0 q l y l z where lx ly and lz are the physical dimensions of the domain and h 1 h 0 is the external pressure difference the effective conductivity is computed for each conductivity field so that k e k e v κ ω 2 4 analysis of flow fields the final component of each simulation is an analysis of the spatial variability of the flow field we represent the spatial variability of the flow by two descriptive statistics which quantify the variability in the magnitude and in the direction of fluid flow we first compute the magnitude of the darcy flux at each node q i j k u i j k 2 v i j k 2 w i j k 2 1 2 its mean μ v κ ω q i j k v κ ω where denotes spatial averaging and its variance σ 2 v κ ω q i j k v κ ω μ v κ ω 2 for each realization of the conductivity field the coefficient of variation of the magnitude of the darcy flux is given by 3a η v κ ω σ v κ ω μ v κ ω the first descriptive statistics is the expected coefficient of variation η v κ which is estimated by averaging over the number of realizations nw 3b η v κ 1 n ω ω η v κ ω to represent the variability in the orientation of the darcy flux we note that the boundary conditions impose an external head gradient that is oriented in the first x dimension therefore for a uniform conductivity field u i j k v κ ω is constant and v i j k v κ ω and w i j k v κ ω are zero for a spatially variable conductivity field however the flow is not generally aligned with the external gradient but occurs at an angle of deviation cos 1 u i j k v κ ω q i j k v κ ω for each conductivity field the flux weighted mean angle of deviation of the darcy flux from the direction of the external head gradient is given by 4a θ v κ ω q i j k v κ ω cos 1 u i j k v κ ω q i j k v κ ω q i j k v κ ω the second descriptive statistic is the expected angle of deviation θ v κ which is estimated by averaging over the number of realization nω 4b θ v κ 1 n ω ω θ v κ ω 3 computational results for each realization of the random topography ω and for each value of the heterogeneity ratio κ k 0 k 1 the data show that ke v κ ω is a positive increasing function of v and that k e 0 κ ω k 0 and k e 1 κ ω k 1 which correspond to homogeneous media with conductivity k 0 and k 1 respectively 3 1 influence of percolation on effective conductivity the percolation threshold for each realization of the random topography vc ω is computed using a connected components algorithm and found to be approximately normally distributed with mean 0 114 and standard deviation 0 016 recall that the percolation threshold is the critical volume that distinguishes geometries that admit connected paths of the more conductive material from those that do not admit such paths the thought experiments demonstrate the influence of the percolation threshold on the effective conductivity the data suggest that for each κ and for each ω the greatest relative increase in ke v κ ω occurs at vc ω the percolation threshold of the random topography for moderate values of κ e g κ 10 3 the effective conductivity is continuous for all v but for sufficiently small values of κ e g κ 10 5 there is a discontinuity at vc ω we vary the parameters of the simulation and make the following observations i interpolating the original conductivity field onto grids with finer resolution does not change the discontinuity ii the discontinuity persists when the increments in δv are refined to a single voxel and iii extending the conductivity field by doubling the side length of the domain with respect to a fixed correlation length of the random field rx and numerical resolution δx decreases the size of the discontinuity these observations suggest the discontinuity vc ω emerges because for any finite domain the sampling of the random environment becomes inadequate as κ 0 the irregular geometry forces the fluid to make longer detours as it optimizes its path through the domain as κ 0 and the discontinuity occurs when the typical length of the detours is greater than the size of the domain one consequence of this discontinuity is that ke v κ ω is sensitive to vc ω when v vc and κ is sufficiently small which can be observed in the quantiles of ke v κ ω fig 3 insets due to the high variance in the effective conductivity when v vc and κ is sufficiently small we use the geometric mean k e v κ ω 1 n ω k e v κ ω 1 n ω for averaging across realizations ω as with the effective conductivity for each realization the data show that the mean effective conductivity is a positive and increasing function and that the greatest relative increase occurs when v vc fig 3 3 2 regimes of effective conductivity the simulations support previous results isichenko 1992 snarskii et al 2016 and we find that for each κ 10 1 there exists a subinterval vb v 1 with vb vc where the effective conductivity obeys a power law in v v c and that the critical exponent β is independent of κ fig 4 b for our random media we find that β 1 68 the power laws are not observed for κ 10 1 because the two materials are very similar we refer to the behaviour of the effective conductivity on vb v 1 as regime iii previous results isichenko 1992 snarskii et al 2016 also suggest that there exists a subinterval 0 v va with va vc where the effective conductivity obeys a power law in v c v and that the critical exponent α is independent of κ for our random media we find that α 0 68 when 10 2 κ 10 4 the data do not clearly show power law behavior for κ 10 4 which may be a result of numerical error and the power laws are not observed for κ 10 1 because the two materials are very similar we refer to the behaviour of the effective conductivity on 0 v va as regime i the effective conductivity interpolates between the two power law regimes on the subinterval va v vb and we refer to the transition as regime ii the data suggest that v a v c and that v b v c as κ 0 when the two materials are similar the interpolating regime extends to the whole interval 0 v 1 we present a systematic way to define va and vb in section 4 3 3 spatial variability of flux the flow fields are uniform when the media are homogenous which occurs when κ 1 or when v 0 or 1 otherwise the irregular configuration of the materials induces flow fields that are spatially variable we represent this spatial variability by two descriptive statistics η v κ the coefficient of variation in the magnitude of the darcy flux and θ v κ the flux weighted average angle between the external head gradient and the darcy flux within each material the data suggest that for each v the spatial variability increases as κ 0 and that when κ 0 the spatial variability attains its maximum when v vc fig 5 for each realization of the random conductivity field we also define normalized statistics for spatial variability by comparing each statistic to the corresponding statistic for the same v and κ 10 5 that is η v κ η v κ η v 10 5 and θ v κ θ v κ θ v 10 5 for 10 5 κ 10 1 the normalized statistics are close to 1 when v is far from vc which indicates that the spatially variability is close to the maximum possible spatial variability permitted by the random geometry fig 5 insets when v vc the normalized statistics decrease to values much less than 1 indicating that the spatially variability is much less than the maximum possible spatially variability the interval of v where the normalized statistic is much less than 1 collapses on vc as κ 0 3 4 correlation between conductivity and spatial variability we investigate whether there is a relation between the effective conductivity and the spatial variability of the flow fields by defining for each v κ the vectors η ω v κ θ ω v κ and k e ω v κ which are nω 1 dimensional vectors with respective entries η v κ ω θ v κ ω and ke v κ ω for ω 1 n ω for each v κ we compute the correlation between the spatial variability η ω v κ or θ ω v κ and the effective conductivity ke v κ which results in two correlation coefficients that are functions of v and κ for each fixed v κ η v κ and θ v κ are positively correlated with ke v κ when v vc and negatively correlated with ke v κ when v vc fig 6 we observe that the transition between positive correlation and negative correlation occurs at v vc and that the transition becomes sharp as κ 0 4 model for effective conductivity our model for effective conductivity is based on the premise that the characterizing attributes are the power laws for regimes i and iii and we define the auxiliary function c v κ v v c v log k e v κ to model the transition between these regimes the auxiliary function c v κ v v c v log k e v κ indicates how strongly the effective conductivity is associated with each regime on any interval where the effective conductivity follows a power law in v v c c v κ is constant and takes the value of the exponent of the power law by quantifying how c v κ transitions on va v vb for each κ the model estimates how ke v κ transitions between the two power laws the data from the computational experiments show that c v κ has a zero at v v c and that the slope of c v κ near vc gets steeper as κ 0 fig 7 for κ 10 1 the data show that c v κ is approximately constant when v vc and attains a value of 1 68 for κ 10 1 the data show that c v κ does not reach 1 68 and is not constant on any vc v 1 for κ 10 3 the data show c v κ approaches 0 5 from above as v 0 but for κ 10 3 c v κ takes values between 0 5 and 1 5 on the interval 0 v 0 07 and that c v κ approaches 0 5 from below as v 0 we model c v κ by the function 5 c m v κ α v c v v c v 2 v c v a 2 for v v c β v v c v v c 2 v b v c 2 for v v c which is a sigmoid function that has a zero at v v c and asymptotes given by the parameters α and β for v and v respectively fig 7 the characteristic width of c m v κ is governed by the parameters va and vb which correspond to the values of v where c m v a κ α 2 and c m v b κ β 2 for this study the choice of sigmoid is made for easy algebraic manipulation and calculation of anti derivatives this particular choice gives the model 6 k e m v κ k 0 a 1 2 v c v 1 2 v c v 2 v c v a 2 α for v v c k 1 b 1 2 v v c 1 2 v v c 2 v b v c 2 β for v v c where the exponents α and β are equal to the two horizontal asymptotes of the sigmoid function given α and β the coefficients a and b are determined by the constraints that k e m 0 κ k 0 and k e m 1 κ k 1 and are given in terms of the parameters va and vb by 7a a 1 2 v c 0 1 2 v c 0 2 v c v a 2 α 7b b 1 2 1 v c 1 2 1 v c 2 v b v c 2 β enforcing continuity and differentiability of k e m at v v c yields two equations for va and vb 8a k 0 a 1 2 v c v a α k 1 b 1 2 v b v c β 8b k 0 a α 1 2 v c v a α 1 k 1 b β 1 2 v b v c β 1 which are solved numerically for each κ table 1 observe that a v c 0 α and b 1 v c β as κ 0 and write a a a and b b b where a v c 0 α and b 1 v c β this gives 9a a 1 4 α v c 0 α 2 v c v a 2 o v c v a 4 9b b 1 4 β 1 v c β 2 v b v c 2 o v b v c 4 with asymptotic limits a κ 2 α β and b κ 2 α β the asymptotic limits of v c v a and v b v c are found by dividing 8a by 8b by recognizing that v b v c 1 v c and v c v a v c 0 in the limit κ 0 8 reduces to 10a v c v a α v b v c β 10b v c v a α v b v c β 2 α β v c 0 α 1 v c β κ which gives v c v a κ 1 α β and v b v c κ 1 α β the model k e m v κ is compared to the data from the computational experiments ke v κ by plotting the difference in log conductivity fig 8 for κ 10 3 the difference is bounded by 0 03 which corresponds to a relative error of 7 for κ 10 5 the difference is bounded by 0 04 on 0 v 0 05 and on 0 15 v 1 but is 0 5 near the percolation threshold which indicates that the model underpredicts the data by a factor of 3 near the percolation threshold when κ is small we also compute the correlation coefficients between the normalized auxiliary function c v κ c v κ c v 10 5 and the normalized descriptive statistics for variability fig 6 insets the positive correlation suggests that the transition between the three regimes in effective conductivity is reflected in the proportion of the maximum possible spatial variability that is achieved 5 discussion a composite porous medium consists of multiple disjoint compact sub volumes of two or more different porous materials in this paper a sub volume is entirely composed of one or another of two different porous materials m 0 and m 1 having different constant conductivities k 0 k 1 the material sub volumes occupy total volume fractions v 1 v and v 0 1 v of the overall volume of a given composite medium and κ k 0 k 1 is a heterogeneity ratio hence composite media can be characterized as elements in a space v κ of particular importance are composites whose volume fraction is at a critical percolation threshold vc where connected paths of m 1 cease to extend across the given medium for the composites based on gaussian fields that we study vc 0 11 in 3d and vc 0 5 in 2d but the specific values depend on factors like the overall volume of the total medium and shape factors of the constituent sub volumes saturated flows in composite conductivity fields undergo a kind of phase change in the vicinity of vc which is especially dramatic when κ is small for instance κ 10 4 we focus on developing a phenomenological model k e m v κ for effective conductivity in composite media that reflects properties of flow regimes observed in computational experiments and thought experiments furthermore model parameters can be derived directly from observations without resort to free parameters effective conductivities ke v κ observed in computational experiments reported here fig 3 exhibit power law behavior in regions i 0 v v a v c and i i i v c v b v 1 below and above vc respectively which is consistent with well established computational results kirkpatrick 1973 snarskii et al 2016 computational experiments also indicate power law behavior in regimes i and iii and suggest that critical exponents α and β are independent of κ when 10 4 κ 10 2 an intermediate region i i v a v v b ke v κ increases rapidly with v when κ is also observed observations are also consistent with two thought experiments based on κ 0 the first thought experiment where k 0 0 demonstrates that k e k 1 at v 1 and ke 0 as v v c furthermore ke is a continuous positive increasing function of v on vc v 1 that can be modeled by a power law in v v c with a positive exponent in agreement with observations of region iii in the second thought experiment where k 1 k e k 0 at v 0 and ke as v v c also ke is a continuous positive and increasing function of v on 0 v vc can be modeled by a power law in v v c with a negative exponent the limits of ke at v v c proposed by the two thought experiments and modeled by the two power laws are non physical when κ 0 this is especially the case as v v c since ke must be bounded between k 0 and k 1 which are both finite and non zero when κ 0 to define a model with correct limits at v v c and power law behavior in regions i and iii we examine an auxiliary function c v κ v v c v log k e v κ basing the model k e m on the auxiliary sigmoid function 5 satisfies the asymptotic requirements for power law behavior of critical exponents α and β when v v c is large the critical exponents may be observed as properties of a given realization of a composite medium or estimated as population values through monte carlo simulation the auxiliary function 5 also presents natural definitions for va and vb where c m v a κ α 2 and c m v b κ β 2 respectively formulating the model in terms of the integral of c m v κ ensures that k e m v κ obeys a power law in v v c when v is far from vc and also allows the geometry of the problem domain to respond to the relative magnitudes of k 0 and k 1 through κ figs 3 and 4 when the two materials are very similar for instance κ 10 1 we find that va 0 and vb 1 i e regime ii extends over the entire interval 0 v 1 when κ 10 1 va 0 and vb 1 i e regimes i and iii are observed as κ 0 va and vb converge toward vc and discontinuities appear in ke v κ even if v vc the finite size of the experimental volume appears too small to allow flow paths to find connected regions of m 1 within the experimental volume when v vc specifically when v c v v c v a the model can be approximated by a v c v α where a is determined only by k 0 vc and α since this approximation does not depend on k 1 it suggests that when the resistance of m 1 is small it is effectively negligible when v vc when v vc specifically when v v c v b v c the model can be approximated by b v v c β where b is determined only by k 1 vc and β since this approximation does not depend on k 0 it suggests that when the conductivity of m 0 is small it is effectively non conductive when v vc statistics of the magnitudes and tortuosity of observed darcy fluxes are consistent with this picture indicating that the flow regime becomes complex when κ 10 3 fig 5 magnitudes of the darcy fluxes are quantified for given κ by their coefficients of variation η v κ and tortuosity θ v κ is quantified by the cosines of local flux vectors with the external head gradient when v vc coefficients of variation can exceed indicate magnitudes exceed their means by factors greater than 1 or 2 and tortuosities simultaneously exceed 0 5 and approach 1 the most likely interpretation is that flow has effectively ceased in the less conductive material m 0 and is compensated for by fluid taking trajectories in m 1 under those circumstances the additional work required to follow increasingly lengthy paths through the more conductive material m 1 appears to be offset by the much lower conductivity of m 0 normalized values η v κ and θ v κ are close to 1 when v is far from vc insets fig 5 when v vc the more conductive material m 1 appears to be so poorly connected that it contributes very little to the flow despite its relatively high conductivity small changes in k 1 have almost no effect on on ke when v vc on the other hand m 1 is so dominant that the fluid can easily avoid m 0 small changes in k 0 have almost no affect on the conductivity for a fixed v κ pair we observe strong correlation of ke v κ with η v κ and θ v κ fig 6 suggesting that the realizations most strongly associated with the power laws of the thought experiment are the realizations where the flow fields are most similar to those of their thought experiment counterparts and that regime ii occurs when the flow fields differ most significantly from those of the thought experiments 6 conclusion in this paper we present a series of computational experiments to investigate the effective conductivity of highly heterogeneous composite porous media the experiments inform a phenomenological model that is consonant with four key observations from the data i there exist three regimes in the effective conductivity that are determined by the percolation threshold vc ii regimes i and iii can be modeled by power laws in v v c iii the critical exponents for regimes i and iii are independent of κ and iv regime ii takes the whole interval 0 v 1 when κ 1 and collapses on vc as κ 0 analyzing the flow fields from numerical simulations allows us to relate these observations to the spatial conductivity of the darcy flux we acknowledge that the correlation between spatial variability and the effective conductivity could be caused by a third confounding variable for example our understanding of the flow suggests that both the spatial variability and the effective conductivity are influenced by how connected the more conductive material is with suitable metrics for connectivity this hypothesis could be tested by computational experiments similar to the one conducted for this study in a composite medium large obstacles of the less conductive material may contribute to lateral spreading of the fluid by increasing the tortuosity of the paths and well connected sections of more conductive material may contribute to transverse spreading by accelerating some of the fluid along preferential paths while some stagnates in the less conductive material although the exact connection between mixing and the spatial variability of the flux has not yet been established we propose that better understanding of the spatial variability may provide better estimates for the uncertainty associated with mass transport when obtaining estimates of a macroscale effective parameter the information provided by local and often sparse data may be improved by considering the connectivity of material subvolumes consideration of the correlation between spatial variability and effective conductivity presented in the computational results fig 6 may further improve estimates of uncertainty alternatively when effective parameters have been estimated at the macroscale by other means consideration of the distribution of different materials specifically the connectivity of local structures may improve uncertainty estimates on flow or pressure at local points of interest the validity of computational experiments depends on their ability to appropriately model system parameters in particular k x care must be taken to ensure that the generating algorithm defines a random field whose inherent heterogeneity and irregularity is suitable for modeling the actual conductivity field testing how different models for k x influence the irregularity of the configurations the spatial variability of the flow fields and the effective conductivity can be conducted by computational experiments similar to the one presented in this paper declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103507 appendix supplementary materials application application 1 
522,we develop a phenomenological model for the effective conductivity of porous media that consist of two distinct materials characterized by different values of hydraulic conductivity our focus is two fold first to relate the terms and parameters of macroscale conductivity to the spatial variability of local flow and conductivity observed in computational experiments and second to develop a reduced order model for effective conductivity based on those observations darcys law is assumed to hold at local mesoscopic and large macroscopic scales at the mesoscale a composite medium is a configuration of irregular subdomains consisting of two different materials the resulting heterogeneities force fluid to flow along irregular paths and this produces spatial variability in the magnitude and the orientation of the darcy flux this variability along with the macroscopic effective conductivity depends on the proportion of the total volume allocated to each material the ratio of the two conductivity values and the spatial connectivity of material subvolumes computational experiments indicate that the effects of heterogeneity are most pronounced when the two conductivity values are very different and when the volume fraction of the more conductive material is near a percolation threshold the percolation threshold is the critical volume fraction of the more conductive material at which the medium is no longer traversed by connected paths through that material the percolation threshold determines the existence of three regimes in effective conductivity two where the effective conductivity obeys power laws and is dominated by one of the materials and a third intermediate regime that interpolates between the power laws keywords stochastic hydrogeology effective conductivity binary random media heterogeneous random fields 1 introduction applications of groundwater hydrology often depend on parameters such as hydraulic conductivity that are known to be highly variable at local scales but cannot be specified as such because the requisite data is not available at small scales for applications that require estimates of system states at scales much larger than the local scale it may be possible to substitute a constant effective parameter for the locally variable parameter in the example of hydraulic conductivity the effective conductivity ke substitutes for local hydraulic conductivity k x this requires the effective parameter to aggregate the critical features of the local parameter field that influence system states at the scale of application if the local parameter field is uniform in space and its variance is not too large an effective parameter based on stochastic averaging may suffice boschan and noetinger 2012 however these conditions are not met for composite porous media which consist of multiple disjoint subvolumes of different materials e g clay lenses in a sand aquifer when individual subvolumes are large enough to affect regional flow directly techniques of aggregation based on averaging over stationary fields will not usually apply such cases need effective parameterizations that are consistent with both the spatial structure of the subvolumes and their material properties if the spatial disposition of subvolumes in a composite medium is known to a good degree of approximation stochastic techniques like random domain decomposition tartakovsky and guadagnini 2004 winter and tartakovsky 2001 can be used to approximate states of flow in many cases however all that is known of the materials are good approximations of their relative volume fractions and average conductivities and the correlation or structure functions of their spatial distribution the modeling challenge becomes identifying the primary features of composite systems that influence regional flows and then to come up with effective parameterizations that produce flow regimes on macroscopic scales that are consistent with the aggregated effects of local flows in this paper we develop a phenomenological model of effective hydraulic conductivity for a large class of composite porous media we focus on media composed of two materials m 0 and m 1 that are arranged in multiple disjoint subvolumes filling a large scaled i e macroscopic domain fig 1 the total volume fractions occupied by subvolumes of the materials are fractions v 0 and v 1 of the total macroscopic volume a material subvolume has constant hydraulic conductivity k 0 or k 1 k 0 k 1 depending on whether it is composed of m 0 or m 1 two thought experiments and a large number 106 of mesoscale computational simulations are used to identify the principal phenomena that an effective conductivity parameter must reflect if it is to closely approximate macroscopic flows produced by a mesoscale composite medium the analysis is carried out in a parameter space v κ defined in terms of v v 1 the volume fraction of m 1 and κ k 0 k 1 the ratio of the two hydraulic conductivities recall m 1 is the more conductive material so 0 κ 1 the corresponding effective conductivity parameter is ke v κ and the model developed for ke v κ in section 4 is denoted by k e m v κ subvolumes of m 1 are said to percolate through an experimental volume when connected paths of m 1 extend from one end of the volume to the other percolation depends on a threshold vc which is the critical value of v that distinguishes between configurations that admit connected paths of m 1 from those that do not the term non percolating geometries refers to configurations where v vc and the term percolating geometries refers to configurations where v vc the proposed model is phenomenological in the sense that it represents the response of hydraulic conductivity to variations in material connectivity as a function of critical percolation depending on v and resistance quantified by κ although it is ad hoc the approach is based on statistical models of phase transitions caused by critical phenomena landau and lifshitz 1960 specifically reductions in flow through porous media induced by decreased connectivity among subvolumes of m 1 resistance to an electrical current due to the presence of a nonconductor in an otherwise conductive volume has long been interpreted as the result of critical percolation in heterogeneous materials landau and lifshitz 1960 experimental studies with percolation and conduction were originally performed by punching holes in carbon paper and measuring electrical conductivity last and thouless 1971 analytic studies kirkpatrick 1973 computer simulations webman et al 1975 and models based on power laws efros and shklovskii 1976 straley 1977 followed shortly thereafter early applications of site and bond percolation on lattices to scaling effective conductivity include the seminal work of kirkpatrick 1973 see isichenko 1992 hunt et al 2014 snarskii et al 2016 for current reviews and ghanbarian and daigle 2016 for recent approaches our work is more closely aligned with the stochastic geometries found in guadagnini et al 2003 renard and allard 2013 adler et al 1990 a number of computational experiments have compared the effective conductivity of realizations of 2d composite porous media to that of realizations augmented by additional connected paths of the more conductive material zinn and harvey 2003 knudby and carrera 2005 knudby et al 2006 finding that connected paths significantly affect the flow the properties of selected metrics for connectivity were investigated in renard and allard 2013 consideration of the effect of local heterogeneities on scale up of groundwater systems was pioneered by matheron 1967 see wen and gomez hernandez 1996 renard and de marsily 1997 dagan et al 2013 sanchez vila et al 2006 for reviews interest initially focused on obtaining bounds for ke in situations like ours where a conductivity field consists of two materials of known hydraulic conductivity in known volumetric proportion but in unspecified spatial configuration the upper and lower bounds for the effective conductivity are well known matheron 1967 in material science hashin and shtrikman 1962 derived tight upper and lower bounds for effective elastic moduli of mildly anisotropic and heterogenous multiphase materials arrayed arbitrarily when two conductive materials are arranged in layers of varying thickness that are perpendicular parallel to the direction of flow ke is the volume weighted harmonic arithmetic average of the hydraulic conductivities matheron 1967 in this study we allow the arrangement of materials to be irregular but isotropic and statistically stationary and we estimate the expected value and variance of the effective conductivity not the bounds from monte carlo simulations the process of decomposing the macroscale domain into irregular subvolumes of two different materials yields three distinct regimes in the effective conductivity ke v κ the regimes occur on subintervals of v given by i 0 v v a i i v a v v b i i i v b v 1 where va and vb depend on κ and satisfy va vc vb the physical basis for the three regimes is illustrated by thought experiments where κ 0 which occurs when either k 1 or k 0 0 snarskii et al 2016 each limit describes the behavior on either subinterval i or iii but not the other the reconciliation of their differences when κ 0 and v vc explains the existence of subinterval ii and motivates a phenomenological model for the effective conductivity over the domain 0 v 1 to motivate regime i consider the situation where k 0 0 and k 1 is finite e g steel and sand when v vc there can be no flow across the domain so k e v 0 on the other hand connected paths of m 1 traverse the domain when v vc so ke v is a positive increasing function of v and ke v 0 as v v c this behavior can be modeled as a power law in v v c with a positive exponent efros and shklovskii 1976 for situations where k 0 0 the fluid is not completely restricted to narrow and tortuous paths through m 1 but can flow through both materials albeit with more resistance when in m 0 in this case the thought experiment underestimates ke v and since ke v must be bounded below by k 0 for all v the prediction that ke v 0 as v v c is no longer physical since k 0 0 and the power law model requires a k 0 dependent modification near vc next consider the situation where k 1 and k 0 is finite to motivate regime iii this corresponds to a massless inviscid fluid flowing through air and clay for instance although this situation is not physical it does provide a valuable perspective when k 1 and v vc fluid is able to flow uninhibited across the domain along connected paths of m 1 so according to the terms of this thought experiment ke must be infinite when v vc connected paths do not exist and fluid must flow through regions of m 0 whose conductivity is finite when v vc ke v is a positive increasing function of v and ke v as v v c this behavior can also be modeled as a power law in v c v this time with a negative exponent efros and shklovskii 1976 when k 1 finite k 1 introduces resistance to the flow in m 1 and for each fixed v k 0 pair decreasing k 1 must decrease ke v the thought experiment has overestimated ke v and since ke must be bounded above by k 1 for all v the prediction that ke as v v c is no longer correct and the power law requires a k 1 dependent modification near vc we investigate how to correct both power laws to maintain physical behavior in subinterval ii when v vc in section 4 the parameters of the model are based on observable quantities our experiments are designed to mimic experiments that might be carried out when characterizing an actual aquifer consequently the physical dimensions of the domain are considered to be fixed known quantities we also assume that the correlation length scale of the conductivity field is known the relation between these length scales the integral scale and the correlation scale has been subject to previous investigation neuman and di federico 2003 boschan and noetinger 2012 dagan et al 2013 we limit our study to conductivity fields with only two materials extensions to conductivity fields with more than two materials could be investigated by similar computational studies we also concentrate only on 1st order effects of the material subvolumes more realistic representations of each material could include modeling a fine scale spatial variability of the hydraulic conductivity within each subvolume i e k i k i x for each material i overview of computational experiments the uncertainty associated with the effects of the unknown conductivity field is estimated by monte carlo simulation samples are generated from a realization of a correlated random field of three independent variables t x y z on the domain ω 0 1 3 for each realization a threshold γ determines the relative volume of each material v 0 and v 1 equivalently 1 v and v and designates material membership points in the domain where the topography is below the threshold are allocated to the more conductive material m 1 and assigned conductivity k 1 1 points in the domain where the topography is above the threshold are allocated to the less conductive material m 0 and assigned conductivity k 0 κ where κ varies systematically from 5 10 1 to 10 5 section 2 1 this process is repeated for n ω 100 different realizations of the correlated random field for each realization ω we generate 200 different random geometries by applying a threshold that corresponds to fixed value of v between v 0 and v 1 for each of the random geometries we then create 15 different conductivity fields by assigning a constant conductivity k 0 and k 1 to each of the materials we compute the effective conductivity as a function of v and κ and make four observations of the data i there are three regimes for conductivity that exist on subintervals of v κ that are governed by the percolation threshold ii the effective conductivity in regimes i and iii can be modeled by power laws in v v c iii the exponents of the power laws appear to be independent of κ and iv regime ii occupies 0 v 1 when κ 1 and collapses on vc as κ 0 section 3 1 to develop a practical and low order model capable of representing each of these observations we view the effective conductivity through the lens that the regimes are characterized by the critical exponents of the two power laws we define our phenomenological model for effective conductivity in composite media via an auxiliary function c v κ v v c v log k e v κ and note that differentiation and algebraic manipulation of power laws show that c v κ is constant on any interval where ke obeys a power law in v v c approximating c v κ by a suitable choice of sigmoid function gives the model 1 k e m v κ a 1 2 v c v 1 2 v c v 2 v c v a 2 α for v v c b 1 2 v v c 1 2 v v c 2 v b v c 2 β for v v c here vc is the critical volume for percolation and is approximately 0 11 the exponents α and β are fit to the data and found to be independent of κ the coefficients a and b and the parameters va and vb are determined by the constraints k e m 0 κ k 0 and k e m 1 κ k 1 and by enforcing continuity and differentiability at v v c flow fields are uniform when κ 1 and when v 0 or v 1 which each correspond to homogeneous media otherwise the flow fields show spatial variability which we represent by two descriptive statistics η the coefficient of variation in the magnitude of the darcy flux and θ the flux weighted average angle of deviation of the darcy flux from the external pressure gradient section 2 4 the simulations show that for each v the spatial variability is increasing as κ 0 and for κ 0 it is greatest when v vc section 3 3 for each v κ pair we compare the effective conductivity with each statistic for spatial variability by computing the correlation across all realizations with the same v and κ the data suggest that the spatial variability is positively correlated with ke for v vc and negatively correlated with ke for v vc further comparisons show that departures from maximum spatial variability coincide with the transition between regimes i and iii section 3 4 2 computation and simulation the unknown local conductivity is modeled as a random field and the effective conductivity is estimated by monte carlo simulation each simulation consists of three computational components first a means of generating realizations of irregular composite media from a chosen ensemble second a suitable method of solving the flow equations to determine local velocities and head gradients and third a means of computing the effective conductivity for each conductivity field two descriptive statistics for the spatial variability of the flow are computed and compared to the effective conductivity 2 1 generating realizations of irregular composite media the local conductivity is modeled by thresholded random fields which provides a computationally efficient means of generating spatially irregular composite media samples of random conductivity fields k x where x x y z t are generated by the following three step algorithm a realization of a correlated gaussian random field t x y z of three independent variables is generated by convolving a rectangular array of i i d random variables with a kernel a threshold γ defines the interfacial boundaries of the two materials by γ x t x γ and thereby determines material membership by m 0 x t x γ and m 1 x t x γ the level set definition of the boundary process implies that an increase in the threshold reallocates some of the domain from the less conductive material to the more conductive material so m 0 m 0 and m 1 m 1 whenever γ γ this has the effect of pushing the boundary strictly outwards from the perspective of the less conductive material so that the geometry of the configuration changes incrementally with γ and the topology of the configuration changes infrequently the volume fraction allocated to each material depends on the statistical properties of the correlated random field t and on the threshold γ this random field is fully defined by the i i d random variables and by the kernel adler and taylor 2007 adler et al 1990 hyman and winter 2014 all realizations of the topography are sampled from the same random field we non dimensionalize the spatial variables to l x l y l z 1 and set n x n y n z 100 we pick i i d random variables from a standard normal distribution and use a symmetric gaussian kernel of width 0 025 the width of the kernel determines the correlation length of the random topography which is rx 0 075 therefore the approximate number of independent features is given by the ratio l x r x 13 3 and the discretized resolution of each feature is given by the ratio r x δ x 7 5 2 2 numerical solution to the pde the flow equation k h 0 is discretized by defining the pressure head at the nodes and by defining the hydraulic conductivity and the darcy flux between adjacent nodes the conductivity field is originally defined at the nodes so values between adjacent nodes are approximated by taking the harmonic averages of the values at the nodes k i 1 2 j k 1 k i j k 1 k i 1 j k 1 2 dirichlet boundary conditions fixed hydraulic head are prescribed on the faces corresponding to x 0 and x 1 and periodic boundary conditions on the faces corresponding to y 0 y 1 z 0 and z 1 the derivatives are approximated by second order finite differences and the resulting linear system is solved using the biconjugate gradient method to a tolerance of 10 9 the solution to the system of equations is the pressure head at each node h i j k so the darcy flux between the nodes u i 1 2 j k v i j 1 2 k and w i j k 1 2 is recovered by darcy s law u i 1 2 j k k i 1 2 j k h i 1 j k h i j k δ x etc values of the darcy flux at the nodes q i j k u i j k v i j k w i j k are found by interpolation 2 3 computing effective conductivity each index i defines a transect plane perpendicular to the external head gradient the total flux through each transect qi is estimated by summation of the normal component of the darcy flux perpendicular to the transect u i j k for all indices j k and multiplication by δy δz it is verified that the flux through each transect is constant which we define as the total fluid flux q the effective conductivity is computed by 2 k e l x h 1 h 0 q l y l z where lx ly and lz are the physical dimensions of the domain and h 1 h 0 is the external pressure difference the effective conductivity is computed for each conductivity field so that k e k e v κ ω 2 4 analysis of flow fields the final component of each simulation is an analysis of the spatial variability of the flow field we represent the spatial variability of the flow by two descriptive statistics which quantify the variability in the magnitude and in the direction of fluid flow we first compute the magnitude of the darcy flux at each node q i j k u i j k 2 v i j k 2 w i j k 2 1 2 its mean μ v κ ω q i j k v κ ω where denotes spatial averaging and its variance σ 2 v κ ω q i j k v κ ω μ v κ ω 2 for each realization of the conductivity field the coefficient of variation of the magnitude of the darcy flux is given by 3a η v κ ω σ v κ ω μ v κ ω the first descriptive statistics is the expected coefficient of variation η v κ which is estimated by averaging over the number of realizations nw 3b η v κ 1 n ω ω η v κ ω to represent the variability in the orientation of the darcy flux we note that the boundary conditions impose an external head gradient that is oriented in the first x dimension therefore for a uniform conductivity field u i j k v κ ω is constant and v i j k v κ ω and w i j k v κ ω are zero for a spatially variable conductivity field however the flow is not generally aligned with the external gradient but occurs at an angle of deviation cos 1 u i j k v κ ω q i j k v κ ω for each conductivity field the flux weighted mean angle of deviation of the darcy flux from the direction of the external head gradient is given by 4a θ v κ ω q i j k v κ ω cos 1 u i j k v κ ω q i j k v κ ω q i j k v κ ω the second descriptive statistic is the expected angle of deviation θ v κ which is estimated by averaging over the number of realization nω 4b θ v κ 1 n ω ω θ v κ ω 3 computational results for each realization of the random topography ω and for each value of the heterogeneity ratio κ k 0 k 1 the data show that ke v κ ω is a positive increasing function of v and that k e 0 κ ω k 0 and k e 1 κ ω k 1 which correspond to homogeneous media with conductivity k 0 and k 1 respectively 3 1 influence of percolation on effective conductivity the percolation threshold for each realization of the random topography vc ω is computed using a connected components algorithm and found to be approximately normally distributed with mean 0 114 and standard deviation 0 016 recall that the percolation threshold is the critical volume that distinguishes geometries that admit connected paths of the more conductive material from those that do not admit such paths the thought experiments demonstrate the influence of the percolation threshold on the effective conductivity the data suggest that for each κ and for each ω the greatest relative increase in ke v κ ω occurs at vc ω the percolation threshold of the random topography for moderate values of κ e g κ 10 3 the effective conductivity is continuous for all v but for sufficiently small values of κ e g κ 10 5 there is a discontinuity at vc ω we vary the parameters of the simulation and make the following observations i interpolating the original conductivity field onto grids with finer resolution does not change the discontinuity ii the discontinuity persists when the increments in δv are refined to a single voxel and iii extending the conductivity field by doubling the side length of the domain with respect to a fixed correlation length of the random field rx and numerical resolution δx decreases the size of the discontinuity these observations suggest the discontinuity vc ω emerges because for any finite domain the sampling of the random environment becomes inadequate as κ 0 the irregular geometry forces the fluid to make longer detours as it optimizes its path through the domain as κ 0 and the discontinuity occurs when the typical length of the detours is greater than the size of the domain one consequence of this discontinuity is that ke v κ ω is sensitive to vc ω when v vc and κ is sufficiently small which can be observed in the quantiles of ke v κ ω fig 3 insets due to the high variance in the effective conductivity when v vc and κ is sufficiently small we use the geometric mean k e v κ ω 1 n ω k e v κ ω 1 n ω for averaging across realizations ω as with the effective conductivity for each realization the data show that the mean effective conductivity is a positive and increasing function and that the greatest relative increase occurs when v vc fig 3 3 2 regimes of effective conductivity the simulations support previous results isichenko 1992 snarskii et al 2016 and we find that for each κ 10 1 there exists a subinterval vb v 1 with vb vc where the effective conductivity obeys a power law in v v c and that the critical exponent β is independent of κ fig 4 b for our random media we find that β 1 68 the power laws are not observed for κ 10 1 because the two materials are very similar we refer to the behaviour of the effective conductivity on vb v 1 as regime iii previous results isichenko 1992 snarskii et al 2016 also suggest that there exists a subinterval 0 v va with va vc where the effective conductivity obeys a power law in v c v and that the critical exponent α is independent of κ for our random media we find that α 0 68 when 10 2 κ 10 4 the data do not clearly show power law behavior for κ 10 4 which may be a result of numerical error and the power laws are not observed for κ 10 1 because the two materials are very similar we refer to the behaviour of the effective conductivity on 0 v va as regime i the effective conductivity interpolates between the two power law regimes on the subinterval va v vb and we refer to the transition as regime ii the data suggest that v a v c and that v b v c as κ 0 when the two materials are similar the interpolating regime extends to the whole interval 0 v 1 we present a systematic way to define va and vb in section 4 3 3 spatial variability of flux the flow fields are uniform when the media are homogenous which occurs when κ 1 or when v 0 or 1 otherwise the irregular configuration of the materials induces flow fields that are spatially variable we represent this spatial variability by two descriptive statistics η v κ the coefficient of variation in the magnitude of the darcy flux and θ v κ the flux weighted average angle between the external head gradient and the darcy flux within each material the data suggest that for each v the spatial variability increases as κ 0 and that when κ 0 the spatial variability attains its maximum when v vc fig 5 for each realization of the random conductivity field we also define normalized statistics for spatial variability by comparing each statistic to the corresponding statistic for the same v and κ 10 5 that is η v κ η v κ η v 10 5 and θ v κ θ v κ θ v 10 5 for 10 5 κ 10 1 the normalized statistics are close to 1 when v is far from vc which indicates that the spatially variability is close to the maximum possible spatial variability permitted by the random geometry fig 5 insets when v vc the normalized statistics decrease to values much less than 1 indicating that the spatially variability is much less than the maximum possible spatially variability the interval of v where the normalized statistic is much less than 1 collapses on vc as κ 0 3 4 correlation between conductivity and spatial variability we investigate whether there is a relation between the effective conductivity and the spatial variability of the flow fields by defining for each v κ the vectors η ω v κ θ ω v κ and k e ω v κ which are nω 1 dimensional vectors with respective entries η v κ ω θ v κ ω and ke v κ ω for ω 1 n ω for each v κ we compute the correlation between the spatial variability η ω v κ or θ ω v κ and the effective conductivity ke v κ which results in two correlation coefficients that are functions of v and κ for each fixed v κ η v κ and θ v κ are positively correlated with ke v κ when v vc and negatively correlated with ke v κ when v vc fig 6 we observe that the transition between positive correlation and negative correlation occurs at v vc and that the transition becomes sharp as κ 0 4 model for effective conductivity our model for effective conductivity is based on the premise that the characterizing attributes are the power laws for regimes i and iii and we define the auxiliary function c v κ v v c v log k e v κ to model the transition between these regimes the auxiliary function c v κ v v c v log k e v κ indicates how strongly the effective conductivity is associated with each regime on any interval where the effective conductivity follows a power law in v v c c v κ is constant and takes the value of the exponent of the power law by quantifying how c v κ transitions on va v vb for each κ the model estimates how ke v κ transitions between the two power laws the data from the computational experiments show that c v κ has a zero at v v c and that the slope of c v κ near vc gets steeper as κ 0 fig 7 for κ 10 1 the data show that c v κ is approximately constant when v vc and attains a value of 1 68 for κ 10 1 the data show that c v κ does not reach 1 68 and is not constant on any vc v 1 for κ 10 3 the data show c v κ approaches 0 5 from above as v 0 but for κ 10 3 c v κ takes values between 0 5 and 1 5 on the interval 0 v 0 07 and that c v κ approaches 0 5 from below as v 0 we model c v κ by the function 5 c m v κ α v c v v c v 2 v c v a 2 for v v c β v v c v v c 2 v b v c 2 for v v c which is a sigmoid function that has a zero at v v c and asymptotes given by the parameters α and β for v and v respectively fig 7 the characteristic width of c m v κ is governed by the parameters va and vb which correspond to the values of v where c m v a κ α 2 and c m v b κ β 2 for this study the choice of sigmoid is made for easy algebraic manipulation and calculation of anti derivatives this particular choice gives the model 6 k e m v κ k 0 a 1 2 v c v 1 2 v c v 2 v c v a 2 α for v v c k 1 b 1 2 v v c 1 2 v v c 2 v b v c 2 β for v v c where the exponents α and β are equal to the two horizontal asymptotes of the sigmoid function given α and β the coefficients a and b are determined by the constraints that k e m 0 κ k 0 and k e m 1 κ k 1 and are given in terms of the parameters va and vb by 7a a 1 2 v c 0 1 2 v c 0 2 v c v a 2 α 7b b 1 2 1 v c 1 2 1 v c 2 v b v c 2 β enforcing continuity and differentiability of k e m at v v c yields two equations for va and vb 8a k 0 a 1 2 v c v a α k 1 b 1 2 v b v c β 8b k 0 a α 1 2 v c v a α 1 k 1 b β 1 2 v b v c β 1 which are solved numerically for each κ table 1 observe that a v c 0 α and b 1 v c β as κ 0 and write a a a and b b b where a v c 0 α and b 1 v c β this gives 9a a 1 4 α v c 0 α 2 v c v a 2 o v c v a 4 9b b 1 4 β 1 v c β 2 v b v c 2 o v b v c 4 with asymptotic limits a κ 2 α β and b κ 2 α β the asymptotic limits of v c v a and v b v c are found by dividing 8a by 8b by recognizing that v b v c 1 v c and v c v a v c 0 in the limit κ 0 8 reduces to 10a v c v a α v b v c β 10b v c v a α v b v c β 2 α β v c 0 α 1 v c β κ which gives v c v a κ 1 α β and v b v c κ 1 α β the model k e m v κ is compared to the data from the computational experiments ke v κ by plotting the difference in log conductivity fig 8 for κ 10 3 the difference is bounded by 0 03 which corresponds to a relative error of 7 for κ 10 5 the difference is bounded by 0 04 on 0 v 0 05 and on 0 15 v 1 but is 0 5 near the percolation threshold which indicates that the model underpredicts the data by a factor of 3 near the percolation threshold when κ is small we also compute the correlation coefficients between the normalized auxiliary function c v κ c v κ c v 10 5 and the normalized descriptive statistics for variability fig 6 insets the positive correlation suggests that the transition between the three regimes in effective conductivity is reflected in the proportion of the maximum possible spatial variability that is achieved 5 discussion a composite porous medium consists of multiple disjoint compact sub volumes of two or more different porous materials in this paper a sub volume is entirely composed of one or another of two different porous materials m 0 and m 1 having different constant conductivities k 0 k 1 the material sub volumes occupy total volume fractions v 1 v and v 0 1 v of the overall volume of a given composite medium and κ k 0 k 1 is a heterogeneity ratio hence composite media can be characterized as elements in a space v κ of particular importance are composites whose volume fraction is at a critical percolation threshold vc where connected paths of m 1 cease to extend across the given medium for the composites based on gaussian fields that we study vc 0 11 in 3d and vc 0 5 in 2d but the specific values depend on factors like the overall volume of the total medium and shape factors of the constituent sub volumes saturated flows in composite conductivity fields undergo a kind of phase change in the vicinity of vc which is especially dramatic when κ is small for instance κ 10 4 we focus on developing a phenomenological model k e m v κ for effective conductivity in composite media that reflects properties of flow regimes observed in computational experiments and thought experiments furthermore model parameters can be derived directly from observations without resort to free parameters effective conductivities ke v κ observed in computational experiments reported here fig 3 exhibit power law behavior in regions i 0 v v a v c and i i i v c v b v 1 below and above vc respectively which is consistent with well established computational results kirkpatrick 1973 snarskii et al 2016 computational experiments also indicate power law behavior in regimes i and iii and suggest that critical exponents α and β are independent of κ when 10 4 κ 10 2 an intermediate region i i v a v v b ke v κ increases rapidly with v when κ is also observed observations are also consistent with two thought experiments based on κ 0 the first thought experiment where k 0 0 demonstrates that k e k 1 at v 1 and ke 0 as v v c furthermore ke is a continuous positive increasing function of v on vc v 1 that can be modeled by a power law in v v c with a positive exponent in agreement with observations of region iii in the second thought experiment where k 1 k e k 0 at v 0 and ke as v v c also ke is a continuous positive and increasing function of v on 0 v vc can be modeled by a power law in v v c with a negative exponent the limits of ke at v v c proposed by the two thought experiments and modeled by the two power laws are non physical when κ 0 this is especially the case as v v c since ke must be bounded between k 0 and k 1 which are both finite and non zero when κ 0 to define a model with correct limits at v v c and power law behavior in regions i and iii we examine an auxiliary function c v κ v v c v log k e v κ basing the model k e m on the auxiliary sigmoid function 5 satisfies the asymptotic requirements for power law behavior of critical exponents α and β when v v c is large the critical exponents may be observed as properties of a given realization of a composite medium or estimated as population values through monte carlo simulation the auxiliary function 5 also presents natural definitions for va and vb where c m v a κ α 2 and c m v b κ β 2 respectively formulating the model in terms of the integral of c m v κ ensures that k e m v κ obeys a power law in v v c when v is far from vc and also allows the geometry of the problem domain to respond to the relative magnitudes of k 0 and k 1 through κ figs 3 and 4 when the two materials are very similar for instance κ 10 1 we find that va 0 and vb 1 i e regime ii extends over the entire interval 0 v 1 when κ 10 1 va 0 and vb 1 i e regimes i and iii are observed as κ 0 va and vb converge toward vc and discontinuities appear in ke v κ even if v vc the finite size of the experimental volume appears too small to allow flow paths to find connected regions of m 1 within the experimental volume when v vc specifically when v c v v c v a the model can be approximated by a v c v α where a is determined only by k 0 vc and α since this approximation does not depend on k 1 it suggests that when the resistance of m 1 is small it is effectively negligible when v vc when v vc specifically when v v c v b v c the model can be approximated by b v v c β where b is determined only by k 1 vc and β since this approximation does not depend on k 0 it suggests that when the conductivity of m 0 is small it is effectively non conductive when v vc statistics of the magnitudes and tortuosity of observed darcy fluxes are consistent with this picture indicating that the flow regime becomes complex when κ 10 3 fig 5 magnitudes of the darcy fluxes are quantified for given κ by their coefficients of variation η v κ and tortuosity θ v κ is quantified by the cosines of local flux vectors with the external head gradient when v vc coefficients of variation can exceed indicate magnitudes exceed their means by factors greater than 1 or 2 and tortuosities simultaneously exceed 0 5 and approach 1 the most likely interpretation is that flow has effectively ceased in the less conductive material m 0 and is compensated for by fluid taking trajectories in m 1 under those circumstances the additional work required to follow increasingly lengthy paths through the more conductive material m 1 appears to be offset by the much lower conductivity of m 0 normalized values η v κ and θ v κ are close to 1 when v is far from vc insets fig 5 when v vc the more conductive material m 1 appears to be so poorly connected that it contributes very little to the flow despite its relatively high conductivity small changes in k 1 have almost no effect on on ke when v vc on the other hand m 1 is so dominant that the fluid can easily avoid m 0 small changes in k 0 have almost no affect on the conductivity for a fixed v κ pair we observe strong correlation of ke v κ with η v κ and θ v κ fig 6 suggesting that the realizations most strongly associated with the power laws of the thought experiment are the realizations where the flow fields are most similar to those of their thought experiment counterparts and that regime ii occurs when the flow fields differ most significantly from those of the thought experiments 6 conclusion in this paper we present a series of computational experiments to investigate the effective conductivity of highly heterogeneous composite porous media the experiments inform a phenomenological model that is consonant with four key observations from the data i there exist three regimes in the effective conductivity that are determined by the percolation threshold vc ii regimes i and iii can be modeled by power laws in v v c iii the critical exponents for regimes i and iii are independent of κ and iv regime ii takes the whole interval 0 v 1 when κ 1 and collapses on vc as κ 0 analyzing the flow fields from numerical simulations allows us to relate these observations to the spatial conductivity of the darcy flux we acknowledge that the correlation between spatial variability and the effective conductivity could be caused by a third confounding variable for example our understanding of the flow suggests that both the spatial variability and the effective conductivity are influenced by how connected the more conductive material is with suitable metrics for connectivity this hypothesis could be tested by computational experiments similar to the one conducted for this study in a composite medium large obstacles of the less conductive material may contribute to lateral spreading of the fluid by increasing the tortuosity of the paths and well connected sections of more conductive material may contribute to transverse spreading by accelerating some of the fluid along preferential paths while some stagnates in the less conductive material although the exact connection between mixing and the spatial variability of the flux has not yet been established we propose that better understanding of the spatial variability may provide better estimates for the uncertainty associated with mass transport when obtaining estimates of a macroscale effective parameter the information provided by local and often sparse data may be improved by considering the connectivity of material subvolumes consideration of the correlation between spatial variability and effective conductivity presented in the computational results fig 6 may further improve estimates of uncertainty alternatively when effective parameters have been estimated at the macroscale by other means consideration of the distribution of different materials specifically the connectivity of local structures may improve uncertainty estimates on flow or pressure at local points of interest the validity of computational experiments depends on their ability to appropriately model system parameters in particular k x care must be taken to ensure that the generating algorithm defines a random field whose inherent heterogeneity and irregularity is suitable for modeling the actual conductivity field testing how different models for k x influence the irregularity of the configurations the spatial variability of the flow fields and the effective conductivity can be conducted by computational experiments similar to the one presented in this paper declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103507 appendix supplementary materials application application 1 
523,drainage network modelling is often an essential component in urban flood prediction and risk assessment drainage network models most commonly use different numerical procedures to handle flows in pipes and junctions numerous numerical schemes and models of different levels of complexity have been developed and reported to predict flows in pipes however calculation of the flow conditions in junctions has received much less attention and has been traditionally achieved by solving only the continuity equation this method is easy to implement but it neglects the momentum exchange in the junctions and cannot provide sufficient boundary conditions for the pipe calculation in this work a novel numerical scheme based on the finite volume solution to the two dimensional 2d shallow water equations swes is proposed to calculate flow dynamics in junctions which directly takes into account both mass and momentum conservation and removes the necessity of implementing complicated boundary settings for pipe calculations this new junction simulation method is then coupled with the widely used two component pressure approach tpa for the pipe flow calculation leading to a new integrated drainage network model the new 1d 2d coupled drainage network model is validated against an experimental and several idealised test cases to demonstrate its potential for efficient and stable simulation of flow dynamics in drainage networks keywords drainage networks urban flood modelling junction calculation tpa shallow water equations transient flow 1 introduction flood inundation models have become an indispensable tool to predict flood dynamics and to evaluate flood impacts in cities drainage network modelling is often an integrated component of an urban flood simulation tool pipes and junctions are the two essential elements of any sizable urban drainage network and are commonly calculated by different model components in drainage network models to predict the flow dynamics in pipes the 1d saint venant equations or one of the modified simplified forms are often used and solved numerically in most of the drainage network models effective approaches have been developed to handle the transitioning free surface and pressurized flow conditions in pipes that repeatedly happen during an urban flood event one group of these approaches uses different equations for free surface and pressurized flows examples include the interface tracking model wiggert 1972 politano et al 2007 the rigid column based model mccorquodale and hamam 1983 li and mccorquodale 1999 and the illinois transient model itm león et al 2010a another type of widely used approach solves a single set of equations but is incorporated with the numerical calculation schemes to handle pressurised flows a typical example is the pressman slot scheme proposed by preissmann 1961 which has been widely adopted and further developed by many researchers e g cunge et al 1980 capart et al 1997 trajkovic et al 1999 malekpour and karney 2014 maranzoni et al 2015 noh et al 2016 an alternative method called the two component pressure approach tpa was also proposed and reported by vasconcelos et al 2006 2007 for simulating transient flows tpa models assume that the pipe walls are elastic and subsequently the cross sectional area of a pipe may expand when the flow inside is pressurized tpa models can effectively simulate various types of unsteady flows including free surface flow mixed flow partly gravity partly pressurized flow pressurized flow sub atmospheric pressure flow as well as flow transitions bousso et al 2012 the calculation of junction flows however has received much less attention despite the fact that they are an integrated part of a drainage network model and are essential to provide the necessary boundary conditions bcs for accurate calculation of pipe flows the traditional approach for the junction flow calculation neglects momentum conservation and considers only the continuity equation to estimate junction water depth such an approach has been widely used in drainage modelling and implemented in swmm swmm manual hsu et al 2000 burger et al 2014 and many other urban drainage models e g schmitt et al 2005 chang et al 2015 noh et al 2016 2018 leandro and martins 2016 although this traditional approach may be computationally efficient it normally requires additional complicated methods to provide sufficient bcs for transient flow calculations in pipes for example a decision tree method was implemented by capart et al 1999 at the interfaces between junctions and pipes to illustrate possible boundary flow regimes sanders and bradford 2010 extended this work and developed an improved framework to include different types of bcs for free surface and pressurized flows a similar effort has also been made in modelling the flow around an island in a river where the flow connections around the island are represented as junctions bifurcations to provide inner bcs to connect with the river flow franzini et al 2018 however these approaches require identification of various bcs according to the flow variables e g froude number water level dryness tolerance etc at each time step which is difficult to implement and may affect the computational efficiency and numerical stability of the overall drainage model león et al 2010b proposed a junction and drop shaft bc model which was coupled to an itm for the simulation of mixed flows in pipes separate ordinary differential equations odes derived from conservation of mass and momentum have been also used for estimating junction flows borsche and klar 2014 however the resulting approaches are complicated and computationally inefficient as a varying number of equations must be solved at each junction according to the connecting pipes and flow conditions computational fluid dynamics cfd models have also been adopted to simulate the complex flow dynamics including turbulence and vorticity inside junctions beg et al 2017 2018 however these models are considered to be over sophisticated for an urban scale drainage flow simulation where the localised fluid structures will have limited influence on the broad scale flow dynamics furthermore the lack of detailed junction data makes the computationally expensive effort of little practical value preliminary attempts have also been made to use 3d hong and kim 2011 or 2d bermúdez et al 2017 herty and seaïd 2008 domains to idealize junction nodes in gas pipe network modelling however such an approach has not been investigated in modelling storm water drainage networks as a summary the current numerical methods for junction flow calculations suffer from various numerical restrictions and further research is needed to develop alternative approaches to support accurate and computationally efficient drainage modelling for large scale real world applications this paper aims to develop and present an innovative strategy by treating the drainage junctions as 2d free surface domains taking into account mass and momentum conservation the new junction calculation model predicts water depth and flow rate to automatically provide complete bcs for the pipe flow calculations the new 2d junction model is then coupled with a tpa model to develop a new 1d 2d coupled drainage network modelling system the rest of the paper is organized as follow section 2 introduces the numerical models for the 1d pipe and 2d junction calculations the new coupled drainage model is tested and validated in section 3 finally brief conclusions are drawn in section 4 2 new 1d 2d coupled drainage network model in this section the proposed 1d 2d coupled model for simulating transient flows in drainage networks will be introduced in detail 2 1 pipe model to implement a tpa model for calculating transitioning flows in pipes the saint venant equations are extended to simulate both free surface and pressurized flows vasconcelos et al 2006 and can be written in the matrix form of 1d conservation laws as 1 u p t f p x s p b s p f 2 u p a q p f p q p q p 2 a i s p b 0 g a d z d x s p f 0 c d p q p q p a 2 where the subscripts p b and f respectively represent pipe bed and friction t denotes the time x is the longitudinal coordinate along the pipe direction a is the cross sectional area qp is the flow discharge z is the bottom elevation of the pipe above an arbitrary datum c d g n p 2 r p 1 3 is the roughness coefficient with np being the manning coefficient and rp being the hydraulic radius pis the wetted perimeter and i is the pressure term specifically the pressure term i must be calculated differently for free surface and pressurised flow conditions under the free surface flow conditions i is normally calculated by i p a ρ with p being the fluid pressure at the centroid of cross sectional area and ρ being the fluid density which may be expanded to become 3 i θ 1 24 3 sin θ 2 sin 3 θ 2 3 θ 2 cos θ 2 g d 3 where g is the gravitational acceleration d is the pipe diameter and θ is the wetted angle related to the water depth hp 4 θ 2 arccos 1 2 h p d related to θ the geometrical variables a and top width t are given by 5 a 1 8 θ sin θ d 2 6 t d sin θ 2 based on which the gravity wave celerity in a pipe is defined as 7 c g a t g d θ sin θ 8 sin θ 2 the variables a t and c are used in the calculation of numerical fluxes which will be introduced in more detail in the next section when the flow is under pressurized flow conditions a different pressure term related to the surcharge head can be obtained by assuming an elastic pipe wall and i may be accordingly estimated using 8 i h π 4 g d 2 h d 2 in which h is the pressurized head calculated by 9 h a 2 g a a p a p where a is the acoustic wave speed and ap is the original cross sectional area of the pipe under consideration the above 1d tpa governing eqs 1 and 2 are numerically solved using a first order godunov type finite volume scheme the 1d computational domain i e each of the pipes in a network is discretised using uniform grids in an arbitrary cell i the following finite volume time marching formula is used to update the flow variables from time level n to n 1 10 u p i n 1 u p i n δ t δ x f i 1 2 n f i 1 2 n δ t s p b i n s p f i n 1 in which δxis the cell length δt is the time step f i 1 2 n and f i 1 2 n are the numerical fluxes across the right and left cell interfaces s p b i n and s p f i n 1 represents the slope and friction source terms respectively 2 1 1 flux terms in order to update the flow variables to a new time level using eq 10 the interface fluxes f i 1 2 n and f i 1 2 n must be properly evaluated and an hll approximate riemann solver harten et al 1983 león et al 2006 sanders and bradford 2010 is adopted in this work 11 f f l if s l 0 f if s l 0 s r f r if s r 0 in which f l and f r are numerical fluxes defined using the left and right riemann states i e the values of the flow variables reconstructed at the left and right cell interfaces which are assumed to be the same as the cell centre values for a first order scheme and f is calculated using the hll flux formula 12 f s r f l s l f r s l s r u r u l s r s l where sl and sr are the left and right characteristic wave speeds calculated by 13 s l min v l c l v c s r max v c v r c r in which vis the averaged flow velocity defined as v q p a and v is calculated by 14 v 1 2 v l v r 1 2 ϕ l ϕ r where φ is a riemann invariant relating to θ and its approximations are given by sanders and bradford 2010 15 ϕ l r β g d 8 sin θ l r 4 β 6 41 and subsequently 16 ϕ 1 2 ϕ l ϕ r 1 2 v l v r when ϕ β g d 8 the flow is under free surface condition and the intermediate wave speed c is calculated using 17 c g d θ sin θ 8 sin θ 2 with 18 θ 4 arcsin ϕ β g d 8 when ϕ β g d 8 the water surface level may reach the crown of the pipe and the flow becomes pressurized the intermediate wave speed c is then set to be the acoustic wave speed a for the pressurized interface flux computation when evaluating the fluxes at the interfaces between pipes and junctions the boundary values of ab ib qb and hb with subtitle b representing boundary must be obtained before the fluxes can be calculated using the approximate riemann solver the boundary variables can be calculated using the water depth hj velocities u and v at the x and y directions in the connected junction according to the following two cases 1 if hj d the boundary cell is under a free surface flow condition ab and ib are calculated using eq 5 and eq 3 respectively hb does not exist in this case and qb will be obtained by projecting the flow rate in the junction along the normal direction of the pipe 2 ifhj d the pipe flow becomes pressurized hb is an unknown variable at the boundary interface and hence ib cannot be calculated using eq 8 a new approach is proposed herein to estimate the necessary boundary variables based on the hydrostatic pressure assumption the pressure term ib can be calculated using 19 i b g h j 1 2 d a p then hb and ab can be deduced from ib and calculated using eqs 8 and 9 respectively qb can be obtained in the same way as in case 1 the detailed implementation of the pipe boundary calculation at a pipe junction interface is summarised in table 1 where n p denotes the outward unit normal vector of the pipe interface n x and n y are respectively the unit vector along the x and y directions in the local junction coordinate system 2 1 2 source terms to update the flow variables using eq 10 it is also necessary to properly discretise the source terms the bed slope terms are simply estimated using a central difference scheme and this will not create any numerical issues as the bed slopes of drainage pipes are commonly gentle and nearly horizontal in practice for the friction source terms an efficient fully implicit scheme originally developed for the 2d swes xia and liang 2018 is adopted and modified herein for implementation in the current 1d tpa governing equations only the momentum equation in eq 10 contains a non zero friction term and needs to be considered which may be rewritten as 20 q p i n 1 q p i n δ t 1 δ x f i 1 2 n f i 1 2 n s p b i n δ t s p f i n 1 where s p f i n 1 g n p 2 p i n 4 3 q p i n 1 q p i n 1 a i n 7 3 defining α g n p 2 p i n 4 3 a i n 7 3 eq 20 becomes 21 α δ t q p i n 1 q p i n 1 q p i n 1 q p i n δ t 1 δ x f i 1 2 n f i 1 2 n s p b i n 0 further defining b q p i n δ t 1 δ x f i 1 2 n f i 1 2 n s p b i n the two sets of possible roots of the above quadratic equation are 22 q p i 1 n 1 1 1 4 α δ t b 2 α δ t if q p i n 1 0 23 q p i 2 n 1 1 1 4 α δ t b 2 α δ t if q p i n 1 0 and 24 q p i 3 n 1 1 1 4 α δ t b 2 α δ t if q p i n 1 0 25 q p i 4 n 1 1 1 4 α δ t b 2 α δ t if q p i n 1 0 since α 0 is always true for any meaningful cases both eqs 22 and 23 are negative if b 0 which is not consistent with the condition of q p i n 1 0 also eq 25 is positive when b 0 which is not consistent with the condition of q p i n 1 0 therefore eq 24 is the only admissible root for b 0 similarly eq 22 is the only admissible root for b 0 the two acceptable roots eqs 22 and 24 can be then combined to provide a single analytical solution for eq 21 given as follows 26 q p i n 1 1 1 4 α δ t b 2 α δ t sgn b where sgn denotes the sign function i e sgn b 1 if b 0 1 if b 0 substituting α g n p 2 p i n 4 3 a i n 7 3 in eq 26 leads to 27 q p i n 1 1 1 4 δ t b g n p 2 p i n 4 3 a i n 7 3 2 δ t sgn b n p 2 p i n 4 3 a i n 7 3 where b can be easily obtained after solving the governing equations without friction terms using the adopted finite volume scheme if a i n is excessively small a i n 7 3 may create an extremely small value that exceeds the machine precision limit and hence cause numerical instability to effectively avoid this both the numerator and denominator of eq 27 are multiplied by a i n 7 3 and the final expression for q p n 1 is obtained 28 q p i n 1 a i n 7 3 a i n 14 3 4 δ t b g n p 2 p i n 4 3 a i n 7 3 2 δ t sgn b n p 2 p i n 4 3 2 2 junction model free surface flow conditions commonly apply when calculating junction flows even when the water depth in the junction submerges all of the connecting pipes and the pipe flows are pressurized in this work each of the junctions in a drainage system is idealized as a 2d domain and the flow is subsequently calculated using a model that solves the fully 2d swes to 1 automatically take into account mass and momentum conservation and 2 avoid setting complicated bcs for calculating pipe flows for example fig 1 illustrates a schematic diagram for a junction connecting three pipes the diameter of each pipe is denoted by di i 1 2 3 p1 and p2 are assumed to be inflow pipes while p3 is an outflow pipe based on the layout of the inflow and outflow pipes the junction domain is approximated using an irregular 2d grid cell as shown in fig 1 b on such a grid a cell centred finite volume scheme is implemented to solve the 2d swes to predict the flow dynamics in the junction in this case the inflows from the two incoming pipes p1 and p2 are mixed and then discharged into the outflow pipe p3 during a simulation the cell edges connecting the pipes are all defined as open boundaries through which the inflow and outflow discharges q 1 q 2 and q 3 from the connecting pipes are obtained from the pipe calculations and imposed as the boundary conditions for the 2d junction flow calculation the inflow and outflow pipes are automatically defined according to the flow directions predicted by the pipe model this essentially defines a two way dynamic coupling scheme that links seamlessly the junction model with the pipe model effectively avoiding the requirement of any complicated bcs for the pipe flow calculations the 2d swes describing the free surface flow in a junction may be written in a matrix form as 29 u j t f j x g j y r s j b s j f where the vector terms are given by 30 u j h j u h j v h j f j u h j u 2 h j 1 2 g h j 2 u v h j g j v h j u v h j v 2 h j 1 2 g h j 2 r r 0 0 s j b 0 g h j z b x g h j z b y and s j f 0 τ b x ρ τ b y ρ where the subscript j represents the junction u and v are the depth averaged velocities along the x and y directions respectively f j and g j are the flux terms r s jb and s jf contain respectively the mass slope and friction source terms r is the external unit flow rate τ bx and τ by are bed friction stresses calculated by τ b x ρ c f u u 2 v 2 and τ b y ρ c f v u 2 v 2 with c f g n j 2 h j 1 3 being the bed roughness coefficient and nj being the manning coefficient at the junction when implementing the above junction model a finite volume scheme is employed and the resulting time marching formula is written as 31 u j n 1 u j n δ t ω p δ t r n s j b n s j f n 1 to couple with the 1d pipe model the flux terms f j and g j in the eq 30 has been revised and the new flux term is denoted as p see section 2 2 1 ω is the cell area that is set to be the actual junction area and hence its value is independent of the cell configuration 2 2 1 evaluating the flux terms as illustrated in fig 1 two different fluxes inside a junction cell are considered 1 the flux across the interface between junction and the connecting pipes denoted by p pk for the kth pipe and 2 a no flow flux at the wall interface denoted by p w therefore the flux vector can be written as 32 p k 1 n p p k p w where n is the number of the pipes connected to the junction 1 fluxes through a pipe junction interface to ensure strict mass and momentum conservation between the 1d pipe model and the 2d junction model the fluxes obtained from the 1d tpa calculation are converted into the local junction coordinate system to derive the numerical fluxes through the corresponding cell interfaces 33 p p k 1 0 0 n p k n x 0 n p k n y f 1 k f 2 k where n pk denotes the outward unit normal vector of the k th pipe interface f f 1 k f 2 k t contains the mass and momentum fluxes of pipe k predicted by the 1d tpa model 2 fluxes at a wall interface at the junction interface that is not connected to a pipe it is effectively a wall boundary and no flow is allowed to cross the interface subsequently only the pressure terms in the momentum equations are effective for the flux calculation a novel approach is proposed and used to evaluate the pressure terms in this work a junction connecting to three pipes as illustrated in fig 1 is again used as a demonstrative example considering the fluid water inside this enclosed domain i e the junction the final net hydrostatic pressure adding on the entire enclosed fluid boundary must be physically integrated to zero subsequently considering a force balance the total hydrostatic force acting on all of the interfaces between the pipes and the junction must be equal to that imposed on the interface between the surrounding wall excluding the pipe areas and the fluid but in the opposite direction the net pressure forces on the pipe junction interfaces may be then used to deduce the hydrostatic force adding on the wall interface so that the fluxes can subsequently be derived and given by 34 p w 0 k 1 n n p k n x i p k k 1 n n p k n y i p k where ipk denotes the pressure flux at the interface between the k th pipe and the junction when the junction water depth hj is smaller than the pipe diameter the pipe flow is under free surface conditions and ipk can be calculated according to eq 3 when hj rises higher than the crown level of the pipe pressurised flow occurs and ipk should be computed according to eq 19 2 2 2 source terms for the source terms in eq 31 the mass term r e g rainfall rate will be calculated or prescribed the slope terms are set to be zero since each of the junctions is approximated as a single cell and the bed elevation is considered to be homogeneous inside the cell the fully implicit friction discretization scheme proposed by xia and liang 2018 is implemented to discretise the friction source terms to ensure stable simulation when the water depth becomes small 2 3 stability criteria since the finite volume schemes adopted for the 1d pipe model and 2d junction model are both overall explicit the time step for the final coupled drainage network model is controlled by the cfl condition defined as follows 35 δ t cfl min δ t p δ t j where the cfl number is generally 0 cfl 1 and is set to be 0 5 for all of the simulations considered in this work δtp and δtj are defined as 36 δ t p min d x q p i a i a if a i n a p min d x q p i a i c i if a i n a p δ t j min ω i u j i 2 v j i 2 g h j 3 results and discussion in this section one experimental and three idealized test cases are simulated to validate the new drainage model and demonstrate its performance for pipe network simulations 3 1 experimental test in order to validate the proposed drainage model for the accurate simulation of transitional flow inside a drainage system an experimental test case is considered in this section and the numerical results are compared with the laboratory measurements reported by vasconcelos et al 2006 vwr experiment and also the alternative numerical predictions from the tpa model presented by vasconcelos et al 2006 tpa vwr and another tpa sewer network model proposed by sanders and bradford 2010 tpa sb fig 2 illustrates the laboratory apparatus which consists of an acrylic horizontal pipe connected by two junctions at both ends the pipe is 14 33 m in length and 9 4 cm in diameter the upstream junction has a square base of 25 cm side length the downstream cylindrical tank is 19 cm in diameter and is supposed to be deep enough to prevent overflowing a gate is installed at the downstream end of the pipe to prevent air from entering the cylindrical junction when the pipe is flooded a ventilation tower located just upstream of the gate is also installed to expel air from the pipe when it is under a pressurized condition during the simulation the wave speed a is set to 25 m s and the manning coefficient is 0 012 m 1 3 s the pipe is discretized using 20 cells to give δx 0 7165m the simulation begins with an initial water at rest throughout the whole system the still free surface water depth at the junctions is 7 3 cm above the pipe invert a 3 1 l s flow is imposed at the upstream junction to create a transient flow into the pipe which is regulated by a weir overflow structure integrated into the model as suggested by sanders and bradford 2010 fig 3 a shows the flow velocities at x 9 9 m from the left hand side edge of the pipe in which the numerical predictions from the current drainage model purple line the tpa vwr model red line and the tpa sb model blue line are compared with the experimental measurements yellow circle it is shown that the current model satisfactorily reproduces the time history of the velocity including peak values and the results are consistent with the two alternative models i e tpa sb and tpa vwr fig 3 b compares the pressure simulated by the three models with measurements at the same cross section all three models produce results that are again consistent with the experiment measurements although the predictions of pressure surges are slightly overestimated further simulations are carried out to investigate the sensitivity of the simulation results to relevant model parameters fig 4 shows the predictions of flow velocity and pressure at the same location using different grid resolutions to discretize the pipe i e n 20 and n 400 respectively where other model parameters remain the same the simulation results produced at high and low resolutions are in close agreement for both flow velocity and pressure fig 5 presents the results obtained using different acoustic wave speeds i e a 25 50 and 100 m s the predicted velocities are consistent and close to each other for all of the three selected acoustic wave speeds however the pressure produced with a 100 m s presents post shock oscillations of large magnitude at around t 8 s post shock oscillations are commonly observed in the simulations involving mixed flow regimes using tpa or pressman slot models due to the existence of a discontinuity in the wave speed for the current case it is recommended to use a 25 m s to reduce the numerical oscillations in the solution fig 6 provides further simulation results obtained using two different manning coefficients i e 0 012 m 1 3 s and 0 02 m 1 3 s the results show a certain level of sensitivity to the manning coefficient when increasing the manning coefficient from 0 012 m 1 3 s to 0 02 m 1 3 s the peak velocity slightly reduces and there is a small shift change in the temporal profile of the velocity fig 6 a which is accordingly reflected in the pressure profile as shown in fig 6 b finally the effect induced by the gate installed at the downstream end of the pipe is also investigated and the results are presented in fig 7 this partially closed gate may influence the flow hydrodynamics and sanders and bradford 2010 suggested to add a local head loss term to take into account the effect with the head loss coefficient set to be 1 25 after incorporating the gate effect the model produces results that are compared slightly better with the experimental measurements 3 2 unsteady flow through different drainage settings this idealized test is designed to demonstrate the effect of different junction pipe settings on the simulation results fig 8 illustrates a simple drainage system with two horizontal pipes connecting to two junctions with a radius of 0 5 m and one outfall water inside junction 1 will flow through the pipe to junction 2 and then discharge through the outfall at the end of pipe 2 during the simulations the manning coefficient in the whole junction pipe domain is set to be 0 035 m 1 3 s the pipes are discretized using uniform grids at 0 5 m resolution three cases are considered case 1 both of the pipes are 6 m long with a diameter of 0 5 m the upstream junction 1 is initialised with different water depths i e 20 40 60 and 80 of the pipe diameter for free surface flow and 120 140 160 and 180 of the pipe diameter for transitional pressurized flow to generate different unsteady flows case 2 the length of the pipes remains to be 6 m but different pipe diameters are used i e 0 3 0 4 0 5 and 0 6 m to investigate the response of the junction flow to the change of size ratio between the pipes and junctions the whole system is dry initially and an external inflow as given in fig 9 is imposed at junction 1 all of the simulations last for 400 s case 3 different pipe lengths i e 3 m 6 m and 12 m are further used to explore the effect of pipe length on junction flows the pipe diameter is fixed at 0 5 m initial and inflow conditions are set to be the same as case 2 for case 1 fig 10 a and b presents the time histories of free surface water depth and flow rate at the outfall predicted for different initial depths in junction 1 with the increase of the initial water depth the model predicts higher peaks of both the water depth and flow rate fig 10 c and d shows the temporal change of water depth and flow rate at the outfall under a pressurized flow condition it is evident that the predicted peaks of both water depth and flow rate under a pressurized condition are much sharper than those produced under a free surface condition for all of the simulations involving different initial depths all of the simulation results are as expected since the higher head at the upstream junction 1 drives the flow with higher velocity along this simple and straight junction pipe system and the pressure in the upstream junction aggravates this driving force fig 11 shows the simulation results in terms of flow depth and velocity in the two junctions for case 2 where the pipe diameter varies between 0 3 m and 0 6 m fig 11 a presents the time histories of water depth in junction 1 it is observed that higher water depth in junction 1 is predicted for smaller pipe diameters which is as expected due to the lower discharge capacity for smaller pipes fig 11 b plots the temporal change of flow velocities in junction 1 the peak velocity decreases as pipe diameter increases which is consistent with the water depth predictions as shown in fig 11 a fig 11 c and d illustrates the predicted water depths and velocities in the junction 2 in both junctions the water depth shows the similar shape as the external flow compared with the results in junction 1 the peak values of the water depth decrease while the peak velocities increase for the same pipe diameter which is again as expected intuitively a smaller pipe diameter will lead to lower drainage capacity and higher water depth in junction 1 the higher water depth in turn provides a larger head difference to drive an unsteady flow with higher momentum in the downstream connecting pipe pipe 1 and junction junction 2 fig 12 shows the simulation results for case 3 where the pipe length changes between 3 m and 12 m fig 12 a and b respectively plots the predicted water depths and flow velocities in junction 1 the peak water depth in junction 1 increases fig 12 a as the pipes become longer but the corresponding peak velocity decreases fig 12 b the simulation results in junction 2 as presented in fig 12 c and d are consistent with the results in junction 1 as the pipe becomes longer it takes longer for the flow to reach junction 2 and the predicted flow velocity in junction 2 appears to be more sensitive to the pipe length fig 12 d since the drainage system is horizontal the flow is only affected by the head difference and friction driven by the same external flow the longer pipes induce more friction losses and dissipate more momentum which subsequently slows down the flow and causes the water depths inside both junctions to rise and flow velocities to decrease overall all of the simulation results follow the physical processes of the water flow demonstrating the capacity of the current model in predicting unsteady flows in a simple junction pipe system 3 3 unsteady flow in v shape networks three v shape networks with different connecting angles are designed to investigate the importance of considering momentum exchange in the junction flow calculations as illustrated in fig 13 two pipes are connected to a common junction at three different angles i e 180⁰ 120⁰ and 30⁰ both of the pipes are 10 m long and 2 07 m in diameter and both of the two junctions have a radius of 4 m during the simulations the manning coefficient of the whole system is set to 0 035 m 1 3 s the pipes are discretized using a uniform grid of 0 5 m resolution initially the still water depth in junction 1 is set to 1 24 m 60 of the pipe diameter for the free surface flow simulations and to 3 31 m 160 of the pipe diameter for the transitional pressurized flow simulations respectively to quantify the effect of momentum exchange in junction flow calculation the predictions with the flow velocity inside the junctions set to zero i e neglecting momentum exchange named zero momentum model herein are compared with the simulation results predicted by the current model with momentum conservation automatically taken into account by the 2d swe model fig 14 compares the water depths and flow rates predicted by the models with and without taking into account momentum exchange in the junctions for the v shape junction pipe systems with different connecting angles for both of the free surface and pressurized flows it is clear that the difference between the peak flow values i e peak water depth and peak flow rate predicted by the models with and without considering momentum transfer becomes more predominant as the connecting angle increases this is because an acute connecting angle would cause more energy loss inside the junction leading to a lower flow velocity momentum into the discharging pipe when the connecting angle reaches 180⁰ the momentum of the flow from the upstream pipe 1 will be completely transferred to the middle junction and then to pipe 2 the effect of varying the connecting angle is evidently captured in the results produced by the current drainage model however the results obtained from the model with a zero junction velocity show no differences when the connecting angle is changed which is clearly not in line with practice this may become particularly problematic for the simulation of intense rainfall induced flood events in which the flood hydrodynamics in the drainage networks may be highly transient and can only be reliably predicted when momentum exchange in junctions is properly taken into account therefore it is essential to consider momentum conservation in junction flow calculation to ensure reliable simulation results this test case effectively confirms this and demonstrates that the current drainage model can automatically reinforce momentum conservation in junction calculation 3 4 a hypothetical drainage network system this final test case is considered to demonstrate the current model s capability in simulating flows in a more practical drainage network system the hypothetical system is consisted of 24 pipes 15 junctions and 2 outfalls that are set up to reflect a simple but practical urban drainage configuration as illustrated in fig 15 the junctions and outfalls have different elevations creating a slope to allow water to travel from the upstream inflow junction junction 1 to the downstream outfalls a diameter of 0 5 m is used for all pipes but the lengths of the pipes vary according to the network configuration as detailed in table 2 the pipes are discretized using 1 m uniform grids the junctions have three different radiuses i e 0 5 m 0 6 m and 0 75 m as detailed in table 3 during the simulation the manning coefficient is set to 0 035 m 1 3 s over the entire system an inflow hydrograph as shown in fig 16 is imposed at junction 1 to create a flow through the connecting pipes and junctions and finally discharging through outfall 1 and outfall 2 fig 17 presents the simulation results in terms of water depth and flow rate at the two outfalls overall the time histories of the outfall water depth and flow rate are consistent with the inflow hydrograph due to the shorter route between junction 1 and outfall 1 the flow arrives earlier at outfall 1 than at outfall 2 similarly outfall 1 welcomes the flood peak slightly earlier than outfall 2 both of the peak flow depth and discharge at outfall 1 are higher than those at outfall 2 to reach outfall 2 the flow must travel longer and more complicated routes that involve more junctions and pipes which will potentially lead to more complex flow hydrodynamics involving more momentum exchange and dissipation and subsequently lower peaks of the water depth and flow rate the inflow peaks before t 1000 s and terminates at t 1800 s and the simulation results clearly reflect the inflow pattern this indicates reasonable prediction and demonstrates the capability of the current model in predicting flow hydrodynamics in practical drainage systems involving wet dry fronts complex junction pipe outfall connections and dynamic flow transitions 4 conclusions this paper presents a novel 1d 2d coupled model for hydrodynamic simulation of transient flows in drainage networks the model adopts a 1d tpa model to simulate the flow dynamics in pipes which can effectively capture free surface and pressurized transient flows for the junction calculations an innovative approach that treats a junction as a 2d domain is proposed with the flow hydrodynamics in the junction calculated using a 2d swe model to automatically take into account both mass and momentum conservation the 2d junction calcutation approach is further implemented with a new method for evaluating the pressure fluxes over the wall interface finally the two modelling components are dynamically coupled together to become an integrated drainage model which is validated against one experimental and three idealized test cases with satisfactory results in one of the test cases the numerical predictions are also compared with the results neglecting momentum exchange inside the junctions to demonstrate the importance of reinforcing momentum conservation in the junction calculations in conclusion the proposed drainage model provides a potential tool for accurate simulation of transient flow hydrodynamics in urban drainage systems and has the following technical highlights 1 the presented drainage model adopts a 2d numerical method for the junction flow calculations which introduces a momentum based approach to automatically account for momentum exchange in multi pipe junctions with arbitrary entrance and exit angles 2 the model formulation streamlines the enforcement of boundary conditions between pipes and junctions effectively removing the requirement of numerous logical checks based on the possibility of either pressurized or free surface flow in the previously developed models e g sanders and bradford 2010 3 implemented with a finite volume shock capturing scheme and robust source term discretization methods the drainage model gives relatively smooth and stable predictions of complex flow that involves wet dry fronts and dynamic transition between free surface and pressurized flows in pipe networks of moderate complexity this demonstrates the model s potential for wider application in large scale urban drainage modelling credit authorship contribution statement qian li conceptualization methodology validation visualization writing original draft qiuhua liang supervision funding acquisition conceptualization methodology writing review editing xilin xia supervision funding acquisition conceptualization methodology declaration of competing interest on behalf of all of the authors of the above paper being submitted to advances in water resources i confirm that there is no conflict of interest has been identified or raised for this submission acknowledgments this work was funded by the uk natural environment research council nerc through the future drainage project ne s016678 1 and the royal academy of engineering through a newton fund research grant uufrip 100033 as part of the uk china urban flooding research impact programme the first author thanks the financial support provided by the china scholarship council scholarship the authors also thank prof brett f sanders and other two anonymous reviewers for their constructive comments supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103519 appendix supplementary materials image application 1 
523,drainage network modelling is often an essential component in urban flood prediction and risk assessment drainage network models most commonly use different numerical procedures to handle flows in pipes and junctions numerous numerical schemes and models of different levels of complexity have been developed and reported to predict flows in pipes however calculation of the flow conditions in junctions has received much less attention and has been traditionally achieved by solving only the continuity equation this method is easy to implement but it neglects the momentum exchange in the junctions and cannot provide sufficient boundary conditions for the pipe calculation in this work a novel numerical scheme based on the finite volume solution to the two dimensional 2d shallow water equations swes is proposed to calculate flow dynamics in junctions which directly takes into account both mass and momentum conservation and removes the necessity of implementing complicated boundary settings for pipe calculations this new junction simulation method is then coupled with the widely used two component pressure approach tpa for the pipe flow calculation leading to a new integrated drainage network model the new 1d 2d coupled drainage network model is validated against an experimental and several idealised test cases to demonstrate its potential for efficient and stable simulation of flow dynamics in drainage networks keywords drainage networks urban flood modelling junction calculation tpa shallow water equations transient flow 1 introduction flood inundation models have become an indispensable tool to predict flood dynamics and to evaluate flood impacts in cities drainage network modelling is often an integrated component of an urban flood simulation tool pipes and junctions are the two essential elements of any sizable urban drainage network and are commonly calculated by different model components in drainage network models to predict the flow dynamics in pipes the 1d saint venant equations or one of the modified simplified forms are often used and solved numerically in most of the drainage network models effective approaches have been developed to handle the transitioning free surface and pressurized flow conditions in pipes that repeatedly happen during an urban flood event one group of these approaches uses different equations for free surface and pressurized flows examples include the interface tracking model wiggert 1972 politano et al 2007 the rigid column based model mccorquodale and hamam 1983 li and mccorquodale 1999 and the illinois transient model itm león et al 2010a another type of widely used approach solves a single set of equations but is incorporated with the numerical calculation schemes to handle pressurised flows a typical example is the pressman slot scheme proposed by preissmann 1961 which has been widely adopted and further developed by many researchers e g cunge et al 1980 capart et al 1997 trajkovic et al 1999 malekpour and karney 2014 maranzoni et al 2015 noh et al 2016 an alternative method called the two component pressure approach tpa was also proposed and reported by vasconcelos et al 2006 2007 for simulating transient flows tpa models assume that the pipe walls are elastic and subsequently the cross sectional area of a pipe may expand when the flow inside is pressurized tpa models can effectively simulate various types of unsteady flows including free surface flow mixed flow partly gravity partly pressurized flow pressurized flow sub atmospheric pressure flow as well as flow transitions bousso et al 2012 the calculation of junction flows however has received much less attention despite the fact that they are an integrated part of a drainage network model and are essential to provide the necessary boundary conditions bcs for accurate calculation of pipe flows the traditional approach for the junction flow calculation neglects momentum conservation and considers only the continuity equation to estimate junction water depth such an approach has been widely used in drainage modelling and implemented in swmm swmm manual hsu et al 2000 burger et al 2014 and many other urban drainage models e g schmitt et al 2005 chang et al 2015 noh et al 2016 2018 leandro and martins 2016 although this traditional approach may be computationally efficient it normally requires additional complicated methods to provide sufficient bcs for transient flow calculations in pipes for example a decision tree method was implemented by capart et al 1999 at the interfaces between junctions and pipes to illustrate possible boundary flow regimes sanders and bradford 2010 extended this work and developed an improved framework to include different types of bcs for free surface and pressurized flows a similar effort has also been made in modelling the flow around an island in a river where the flow connections around the island are represented as junctions bifurcations to provide inner bcs to connect with the river flow franzini et al 2018 however these approaches require identification of various bcs according to the flow variables e g froude number water level dryness tolerance etc at each time step which is difficult to implement and may affect the computational efficiency and numerical stability of the overall drainage model león et al 2010b proposed a junction and drop shaft bc model which was coupled to an itm for the simulation of mixed flows in pipes separate ordinary differential equations odes derived from conservation of mass and momentum have been also used for estimating junction flows borsche and klar 2014 however the resulting approaches are complicated and computationally inefficient as a varying number of equations must be solved at each junction according to the connecting pipes and flow conditions computational fluid dynamics cfd models have also been adopted to simulate the complex flow dynamics including turbulence and vorticity inside junctions beg et al 2017 2018 however these models are considered to be over sophisticated for an urban scale drainage flow simulation where the localised fluid structures will have limited influence on the broad scale flow dynamics furthermore the lack of detailed junction data makes the computationally expensive effort of little practical value preliminary attempts have also been made to use 3d hong and kim 2011 or 2d bermúdez et al 2017 herty and seaïd 2008 domains to idealize junction nodes in gas pipe network modelling however such an approach has not been investigated in modelling storm water drainage networks as a summary the current numerical methods for junction flow calculations suffer from various numerical restrictions and further research is needed to develop alternative approaches to support accurate and computationally efficient drainage modelling for large scale real world applications this paper aims to develop and present an innovative strategy by treating the drainage junctions as 2d free surface domains taking into account mass and momentum conservation the new junction calculation model predicts water depth and flow rate to automatically provide complete bcs for the pipe flow calculations the new 2d junction model is then coupled with a tpa model to develop a new 1d 2d coupled drainage network modelling system the rest of the paper is organized as follow section 2 introduces the numerical models for the 1d pipe and 2d junction calculations the new coupled drainage model is tested and validated in section 3 finally brief conclusions are drawn in section 4 2 new 1d 2d coupled drainage network model in this section the proposed 1d 2d coupled model for simulating transient flows in drainage networks will be introduced in detail 2 1 pipe model to implement a tpa model for calculating transitioning flows in pipes the saint venant equations are extended to simulate both free surface and pressurized flows vasconcelos et al 2006 and can be written in the matrix form of 1d conservation laws as 1 u p t f p x s p b s p f 2 u p a q p f p q p q p 2 a i s p b 0 g a d z d x s p f 0 c d p q p q p a 2 where the subscripts p b and f respectively represent pipe bed and friction t denotes the time x is the longitudinal coordinate along the pipe direction a is the cross sectional area qp is the flow discharge z is the bottom elevation of the pipe above an arbitrary datum c d g n p 2 r p 1 3 is the roughness coefficient with np being the manning coefficient and rp being the hydraulic radius pis the wetted perimeter and i is the pressure term specifically the pressure term i must be calculated differently for free surface and pressurised flow conditions under the free surface flow conditions i is normally calculated by i p a ρ with p being the fluid pressure at the centroid of cross sectional area and ρ being the fluid density which may be expanded to become 3 i θ 1 24 3 sin θ 2 sin 3 θ 2 3 θ 2 cos θ 2 g d 3 where g is the gravitational acceleration d is the pipe diameter and θ is the wetted angle related to the water depth hp 4 θ 2 arccos 1 2 h p d related to θ the geometrical variables a and top width t are given by 5 a 1 8 θ sin θ d 2 6 t d sin θ 2 based on which the gravity wave celerity in a pipe is defined as 7 c g a t g d θ sin θ 8 sin θ 2 the variables a t and c are used in the calculation of numerical fluxes which will be introduced in more detail in the next section when the flow is under pressurized flow conditions a different pressure term related to the surcharge head can be obtained by assuming an elastic pipe wall and i may be accordingly estimated using 8 i h π 4 g d 2 h d 2 in which h is the pressurized head calculated by 9 h a 2 g a a p a p where a is the acoustic wave speed and ap is the original cross sectional area of the pipe under consideration the above 1d tpa governing eqs 1 and 2 are numerically solved using a first order godunov type finite volume scheme the 1d computational domain i e each of the pipes in a network is discretised using uniform grids in an arbitrary cell i the following finite volume time marching formula is used to update the flow variables from time level n to n 1 10 u p i n 1 u p i n δ t δ x f i 1 2 n f i 1 2 n δ t s p b i n s p f i n 1 in which δxis the cell length δt is the time step f i 1 2 n and f i 1 2 n are the numerical fluxes across the right and left cell interfaces s p b i n and s p f i n 1 represents the slope and friction source terms respectively 2 1 1 flux terms in order to update the flow variables to a new time level using eq 10 the interface fluxes f i 1 2 n and f i 1 2 n must be properly evaluated and an hll approximate riemann solver harten et al 1983 león et al 2006 sanders and bradford 2010 is adopted in this work 11 f f l if s l 0 f if s l 0 s r f r if s r 0 in which f l and f r are numerical fluxes defined using the left and right riemann states i e the values of the flow variables reconstructed at the left and right cell interfaces which are assumed to be the same as the cell centre values for a first order scheme and f is calculated using the hll flux formula 12 f s r f l s l f r s l s r u r u l s r s l where sl and sr are the left and right characteristic wave speeds calculated by 13 s l min v l c l v c s r max v c v r c r in which vis the averaged flow velocity defined as v q p a and v is calculated by 14 v 1 2 v l v r 1 2 ϕ l ϕ r where φ is a riemann invariant relating to θ and its approximations are given by sanders and bradford 2010 15 ϕ l r β g d 8 sin θ l r 4 β 6 41 and subsequently 16 ϕ 1 2 ϕ l ϕ r 1 2 v l v r when ϕ β g d 8 the flow is under free surface condition and the intermediate wave speed c is calculated using 17 c g d θ sin θ 8 sin θ 2 with 18 θ 4 arcsin ϕ β g d 8 when ϕ β g d 8 the water surface level may reach the crown of the pipe and the flow becomes pressurized the intermediate wave speed c is then set to be the acoustic wave speed a for the pressurized interface flux computation when evaluating the fluxes at the interfaces between pipes and junctions the boundary values of ab ib qb and hb with subtitle b representing boundary must be obtained before the fluxes can be calculated using the approximate riemann solver the boundary variables can be calculated using the water depth hj velocities u and v at the x and y directions in the connected junction according to the following two cases 1 if hj d the boundary cell is under a free surface flow condition ab and ib are calculated using eq 5 and eq 3 respectively hb does not exist in this case and qb will be obtained by projecting the flow rate in the junction along the normal direction of the pipe 2 ifhj d the pipe flow becomes pressurized hb is an unknown variable at the boundary interface and hence ib cannot be calculated using eq 8 a new approach is proposed herein to estimate the necessary boundary variables based on the hydrostatic pressure assumption the pressure term ib can be calculated using 19 i b g h j 1 2 d a p then hb and ab can be deduced from ib and calculated using eqs 8 and 9 respectively qb can be obtained in the same way as in case 1 the detailed implementation of the pipe boundary calculation at a pipe junction interface is summarised in table 1 where n p denotes the outward unit normal vector of the pipe interface n x and n y are respectively the unit vector along the x and y directions in the local junction coordinate system 2 1 2 source terms to update the flow variables using eq 10 it is also necessary to properly discretise the source terms the bed slope terms are simply estimated using a central difference scheme and this will not create any numerical issues as the bed slopes of drainage pipes are commonly gentle and nearly horizontal in practice for the friction source terms an efficient fully implicit scheme originally developed for the 2d swes xia and liang 2018 is adopted and modified herein for implementation in the current 1d tpa governing equations only the momentum equation in eq 10 contains a non zero friction term and needs to be considered which may be rewritten as 20 q p i n 1 q p i n δ t 1 δ x f i 1 2 n f i 1 2 n s p b i n δ t s p f i n 1 where s p f i n 1 g n p 2 p i n 4 3 q p i n 1 q p i n 1 a i n 7 3 defining α g n p 2 p i n 4 3 a i n 7 3 eq 20 becomes 21 α δ t q p i n 1 q p i n 1 q p i n 1 q p i n δ t 1 δ x f i 1 2 n f i 1 2 n s p b i n 0 further defining b q p i n δ t 1 δ x f i 1 2 n f i 1 2 n s p b i n the two sets of possible roots of the above quadratic equation are 22 q p i 1 n 1 1 1 4 α δ t b 2 α δ t if q p i n 1 0 23 q p i 2 n 1 1 1 4 α δ t b 2 α δ t if q p i n 1 0 and 24 q p i 3 n 1 1 1 4 α δ t b 2 α δ t if q p i n 1 0 25 q p i 4 n 1 1 1 4 α δ t b 2 α δ t if q p i n 1 0 since α 0 is always true for any meaningful cases both eqs 22 and 23 are negative if b 0 which is not consistent with the condition of q p i n 1 0 also eq 25 is positive when b 0 which is not consistent with the condition of q p i n 1 0 therefore eq 24 is the only admissible root for b 0 similarly eq 22 is the only admissible root for b 0 the two acceptable roots eqs 22 and 24 can be then combined to provide a single analytical solution for eq 21 given as follows 26 q p i n 1 1 1 4 α δ t b 2 α δ t sgn b where sgn denotes the sign function i e sgn b 1 if b 0 1 if b 0 substituting α g n p 2 p i n 4 3 a i n 7 3 in eq 26 leads to 27 q p i n 1 1 1 4 δ t b g n p 2 p i n 4 3 a i n 7 3 2 δ t sgn b n p 2 p i n 4 3 a i n 7 3 where b can be easily obtained after solving the governing equations without friction terms using the adopted finite volume scheme if a i n is excessively small a i n 7 3 may create an extremely small value that exceeds the machine precision limit and hence cause numerical instability to effectively avoid this both the numerator and denominator of eq 27 are multiplied by a i n 7 3 and the final expression for q p n 1 is obtained 28 q p i n 1 a i n 7 3 a i n 14 3 4 δ t b g n p 2 p i n 4 3 a i n 7 3 2 δ t sgn b n p 2 p i n 4 3 2 2 junction model free surface flow conditions commonly apply when calculating junction flows even when the water depth in the junction submerges all of the connecting pipes and the pipe flows are pressurized in this work each of the junctions in a drainage system is idealized as a 2d domain and the flow is subsequently calculated using a model that solves the fully 2d swes to 1 automatically take into account mass and momentum conservation and 2 avoid setting complicated bcs for calculating pipe flows for example fig 1 illustrates a schematic diagram for a junction connecting three pipes the diameter of each pipe is denoted by di i 1 2 3 p1 and p2 are assumed to be inflow pipes while p3 is an outflow pipe based on the layout of the inflow and outflow pipes the junction domain is approximated using an irregular 2d grid cell as shown in fig 1 b on such a grid a cell centred finite volume scheme is implemented to solve the 2d swes to predict the flow dynamics in the junction in this case the inflows from the two incoming pipes p1 and p2 are mixed and then discharged into the outflow pipe p3 during a simulation the cell edges connecting the pipes are all defined as open boundaries through which the inflow and outflow discharges q 1 q 2 and q 3 from the connecting pipes are obtained from the pipe calculations and imposed as the boundary conditions for the 2d junction flow calculation the inflow and outflow pipes are automatically defined according to the flow directions predicted by the pipe model this essentially defines a two way dynamic coupling scheme that links seamlessly the junction model with the pipe model effectively avoiding the requirement of any complicated bcs for the pipe flow calculations the 2d swes describing the free surface flow in a junction may be written in a matrix form as 29 u j t f j x g j y r s j b s j f where the vector terms are given by 30 u j h j u h j v h j f j u h j u 2 h j 1 2 g h j 2 u v h j g j v h j u v h j v 2 h j 1 2 g h j 2 r r 0 0 s j b 0 g h j z b x g h j z b y and s j f 0 τ b x ρ τ b y ρ where the subscript j represents the junction u and v are the depth averaged velocities along the x and y directions respectively f j and g j are the flux terms r s jb and s jf contain respectively the mass slope and friction source terms r is the external unit flow rate τ bx and τ by are bed friction stresses calculated by τ b x ρ c f u u 2 v 2 and τ b y ρ c f v u 2 v 2 with c f g n j 2 h j 1 3 being the bed roughness coefficient and nj being the manning coefficient at the junction when implementing the above junction model a finite volume scheme is employed and the resulting time marching formula is written as 31 u j n 1 u j n δ t ω p δ t r n s j b n s j f n 1 to couple with the 1d pipe model the flux terms f j and g j in the eq 30 has been revised and the new flux term is denoted as p see section 2 2 1 ω is the cell area that is set to be the actual junction area and hence its value is independent of the cell configuration 2 2 1 evaluating the flux terms as illustrated in fig 1 two different fluxes inside a junction cell are considered 1 the flux across the interface between junction and the connecting pipes denoted by p pk for the kth pipe and 2 a no flow flux at the wall interface denoted by p w therefore the flux vector can be written as 32 p k 1 n p p k p w where n is the number of the pipes connected to the junction 1 fluxes through a pipe junction interface to ensure strict mass and momentum conservation between the 1d pipe model and the 2d junction model the fluxes obtained from the 1d tpa calculation are converted into the local junction coordinate system to derive the numerical fluxes through the corresponding cell interfaces 33 p p k 1 0 0 n p k n x 0 n p k n y f 1 k f 2 k where n pk denotes the outward unit normal vector of the k th pipe interface f f 1 k f 2 k t contains the mass and momentum fluxes of pipe k predicted by the 1d tpa model 2 fluxes at a wall interface at the junction interface that is not connected to a pipe it is effectively a wall boundary and no flow is allowed to cross the interface subsequently only the pressure terms in the momentum equations are effective for the flux calculation a novel approach is proposed and used to evaluate the pressure terms in this work a junction connecting to three pipes as illustrated in fig 1 is again used as a demonstrative example considering the fluid water inside this enclosed domain i e the junction the final net hydrostatic pressure adding on the entire enclosed fluid boundary must be physically integrated to zero subsequently considering a force balance the total hydrostatic force acting on all of the interfaces between the pipes and the junction must be equal to that imposed on the interface between the surrounding wall excluding the pipe areas and the fluid but in the opposite direction the net pressure forces on the pipe junction interfaces may be then used to deduce the hydrostatic force adding on the wall interface so that the fluxes can subsequently be derived and given by 34 p w 0 k 1 n n p k n x i p k k 1 n n p k n y i p k where ipk denotes the pressure flux at the interface between the k th pipe and the junction when the junction water depth hj is smaller than the pipe diameter the pipe flow is under free surface conditions and ipk can be calculated according to eq 3 when hj rises higher than the crown level of the pipe pressurised flow occurs and ipk should be computed according to eq 19 2 2 2 source terms for the source terms in eq 31 the mass term r e g rainfall rate will be calculated or prescribed the slope terms are set to be zero since each of the junctions is approximated as a single cell and the bed elevation is considered to be homogeneous inside the cell the fully implicit friction discretization scheme proposed by xia and liang 2018 is implemented to discretise the friction source terms to ensure stable simulation when the water depth becomes small 2 3 stability criteria since the finite volume schemes adopted for the 1d pipe model and 2d junction model are both overall explicit the time step for the final coupled drainage network model is controlled by the cfl condition defined as follows 35 δ t cfl min δ t p δ t j where the cfl number is generally 0 cfl 1 and is set to be 0 5 for all of the simulations considered in this work δtp and δtj are defined as 36 δ t p min d x q p i a i a if a i n a p min d x q p i a i c i if a i n a p δ t j min ω i u j i 2 v j i 2 g h j 3 results and discussion in this section one experimental and three idealized test cases are simulated to validate the new drainage model and demonstrate its performance for pipe network simulations 3 1 experimental test in order to validate the proposed drainage model for the accurate simulation of transitional flow inside a drainage system an experimental test case is considered in this section and the numerical results are compared with the laboratory measurements reported by vasconcelos et al 2006 vwr experiment and also the alternative numerical predictions from the tpa model presented by vasconcelos et al 2006 tpa vwr and another tpa sewer network model proposed by sanders and bradford 2010 tpa sb fig 2 illustrates the laboratory apparatus which consists of an acrylic horizontal pipe connected by two junctions at both ends the pipe is 14 33 m in length and 9 4 cm in diameter the upstream junction has a square base of 25 cm side length the downstream cylindrical tank is 19 cm in diameter and is supposed to be deep enough to prevent overflowing a gate is installed at the downstream end of the pipe to prevent air from entering the cylindrical junction when the pipe is flooded a ventilation tower located just upstream of the gate is also installed to expel air from the pipe when it is under a pressurized condition during the simulation the wave speed a is set to 25 m s and the manning coefficient is 0 012 m 1 3 s the pipe is discretized using 20 cells to give δx 0 7165m the simulation begins with an initial water at rest throughout the whole system the still free surface water depth at the junctions is 7 3 cm above the pipe invert a 3 1 l s flow is imposed at the upstream junction to create a transient flow into the pipe which is regulated by a weir overflow structure integrated into the model as suggested by sanders and bradford 2010 fig 3 a shows the flow velocities at x 9 9 m from the left hand side edge of the pipe in which the numerical predictions from the current drainage model purple line the tpa vwr model red line and the tpa sb model blue line are compared with the experimental measurements yellow circle it is shown that the current model satisfactorily reproduces the time history of the velocity including peak values and the results are consistent with the two alternative models i e tpa sb and tpa vwr fig 3 b compares the pressure simulated by the three models with measurements at the same cross section all three models produce results that are again consistent with the experiment measurements although the predictions of pressure surges are slightly overestimated further simulations are carried out to investigate the sensitivity of the simulation results to relevant model parameters fig 4 shows the predictions of flow velocity and pressure at the same location using different grid resolutions to discretize the pipe i e n 20 and n 400 respectively where other model parameters remain the same the simulation results produced at high and low resolutions are in close agreement for both flow velocity and pressure fig 5 presents the results obtained using different acoustic wave speeds i e a 25 50 and 100 m s the predicted velocities are consistent and close to each other for all of the three selected acoustic wave speeds however the pressure produced with a 100 m s presents post shock oscillations of large magnitude at around t 8 s post shock oscillations are commonly observed in the simulations involving mixed flow regimes using tpa or pressman slot models due to the existence of a discontinuity in the wave speed for the current case it is recommended to use a 25 m s to reduce the numerical oscillations in the solution fig 6 provides further simulation results obtained using two different manning coefficients i e 0 012 m 1 3 s and 0 02 m 1 3 s the results show a certain level of sensitivity to the manning coefficient when increasing the manning coefficient from 0 012 m 1 3 s to 0 02 m 1 3 s the peak velocity slightly reduces and there is a small shift change in the temporal profile of the velocity fig 6 a which is accordingly reflected in the pressure profile as shown in fig 6 b finally the effect induced by the gate installed at the downstream end of the pipe is also investigated and the results are presented in fig 7 this partially closed gate may influence the flow hydrodynamics and sanders and bradford 2010 suggested to add a local head loss term to take into account the effect with the head loss coefficient set to be 1 25 after incorporating the gate effect the model produces results that are compared slightly better with the experimental measurements 3 2 unsteady flow through different drainage settings this idealized test is designed to demonstrate the effect of different junction pipe settings on the simulation results fig 8 illustrates a simple drainage system with two horizontal pipes connecting to two junctions with a radius of 0 5 m and one outfall water inside junction 1 will flow through the pipe to junction 2 and then discharge through the outfall at the end of pipe 2 during the simulations the manning coefficient in the whole junction pipe domain is set to be 0 035 m 1 3 s the pipes are discretized using uniform grids at 0 5 m resolution three cases are considered case 1 both of the pipes are 6 m long with a diameter of 0 5 m the upstream junction 1 is initialised with different water depths i e 20 40 60 and 80 of the pipe diameter for free surface flow and 120 140 160 and 180 of the pipe diameter for transitional pressurized flow to generate different unsteady flows case 2 the length of the pipes remains to be 6 m but different pipe diameters are used i e 0 3 0 4 0 5 and 0 6 m to investigate the response of the junction flow to the change of size ratio between the pipes and junctions the whole system is dry initially and an external inflow as given in fig 9 is imposed at junction 1 all of the simulations last for 400 s case 3 different pipe lengths i e 3 m 6 m and 12 m are further used to explore the effect of pipe length on junction flows the pipe diameter is fixed at 0 5 m initial and inflow conditions are set to be the same as case 2 for case 1 fig 10 a and b presents the time histories of free surface water depth and flow rate at the outfall predicted for different initial depths in junction 1 with the increase of the initial water depth the model predicts higher peaks of both the water depth and flow rate fig 10 c and d shows the temporal change of water depth and flow rate at the outfall under a pressurized flow condition it is evident that the predicted peaks of both water depth and flow rate under a pressurized condition are much sharper than those produced under a free surface condition for all of the simulations involving different initial depths all of the simulation results are as expected since the higher head at the upstream junction 1 drives the flow with higher velocity along this simple and straight junction pipe system and the pressure in the upstream junction aggravates this driving force fig 11 shows the simulation results in terms of flow depth and velocity in the two junctions for case 2 where the pipe diameter varies between 0 3 m and 0 6 m fig 11 a presents the time histories of water depth in junction 1 it is observed that higher water depth in junction 1 is predicted for smaller pipe diameters which is as expected due to the lower discharge capacity for smaller pipes fig 11 b plots the temporal change of flow velocities in junction 1 the peak velocity decreases as pipe diameter increases which is consistent with the water depth predictions as shown in fig 11 a fig 11 c and d illustrates the predicted water depths and velocities in the junction 2 in both junctions the water depth shows the similar shape as the external flow compared with the results in junction 1 the peak values of the water depth decrease while the peak velocities increase for the same pipe diameter which is again as expected intuitively a smaller pipe diameter will lead to lower drainage capacity and higher water depth in junction 1 the higher water depth in turn provides a larger head difference to drive an unsteady flow with higher momentum in the downstream connecting pipe pipe 1 and junction junction 2 fig 12 shows the simulation results for case 3 where the pipe length changes between 3 m and 12 m fig 12 a and b respectively plots the predicted water depths and flow velocities in junction 1 the peak water depth in junction 1 increases fig 12 a as the pipes become longer but the corresponding peak velocity decreases fig 12 b the simulation results in junction 2 as presented in fig 12 c and d are consistent with the results in junction 1 as the pipe becomes longer it takes longer for the flow to reach junction 2 and the predicted flow velocity in junction 2 appears to be more sensitive to the pipe length fig 12 d since the drainage system is horizontal the flow is only affected by the head difference and friction driven by the same external flow the longer pipes induce more friction losses and dissipate more momentum which subsequently slows down the flow and causes the water depths inside both junctions to rise and flow velocities to decrease overall all of the simulation results follow the physical processes of the water flow demonstrating the capacity of the current model in predicting unsteady flows in a simple junction pipe system 3 3 unsteady flow in v shape networks three v shape networks with different connecting angles are designed to investigate the importance of considering momentum exchange in the junction flow calculations as illustrated in fig 13 two pipes are connected to a common junction at three different angles i e 180⁰ 120⁰ and 30⁰ both of the pipes are 10 m long and 2 07 m in diameter and both of the two junctions have a radius of 4 m during the simulations the manning coefficient of the whole system is set to 0 035 m 1 3 s the pipes are discretized using a uniform grid of 0 5 m resolution initially the still water depth in junction 1 is set to 1 24 m 60 of the pipe diameter for the free surface flow simulations and to 3 31 m 160 of the pipe diameter for the transitional pressurized flow simulations respectively to quantify the effect of momentum exchange in junction flow calculation the predictions with the flow velocity inside the junctions set to zero i e neglecting momentum exchange named zero momentum model herein are compared with the simulation results predicted by the current model with momentum conservation automatically taken into account by the 2d swe model fig 14 compares the water depths and flow rates predicted by the models with and without taking into account momentum exchange in the junctions for the v shape junction pipe systems with different connecting angles for both of the free surface and pressurized flows it is clear that the difference between the peak flow values i e peak water depth and peak flow rate predicted by the models with and without considering momentum transfer becomes more predominant as the connecting angle increases this is because an acute connecting angle would cause more energy loss inside the junction leading to a lower flow velocity momentum into the discharging pipe when the connecting angle reaches 180⁰ the momentum of the flow from the upstream pipe 1 will be completely transferred to the middle junction and then to pipe 2 the effect of varying the connecting angle is evidently captured in the results produced by the current drainage model however the results obtained from the model with a zero junction velocity show no differences when the connecting angle is changed which is clearly not in line with practice this may become particularly problematic for the simulation of intense rainfall induced flood events in which the flood hydrodynamics in the drainage networks may be highly transient and can only be reliably predicted when momentum exchange in junctions is properly taken into account therefore it is essential to consider momentum conservation in junction flow calculation to ensure reliable simulation results this test case effectively confirms this and demonstrates that the current drainage model can automatically reinforce momentum conservation in junction calculation 3 4 a hypothetical drainage network system this final test case is considered to demonstrate the current model s capability in simulating flows in a more practical drainage network system the hypothetical system is consisted of 24 pipes 15 junctions and 2 outfalls that are set up to reflect a simple but practical urban drainage configuration as illustrated in fig 15 the junctions and outfalls have different elevations creating a slope to allow water to travel from the upstream inflow junction junction 1 to the downstream outfalls a diameter of 0 5 m is used for all pipes but the lengths of the pipes vary according to the network configuration as detailed in table 2 the pipes are discretized using 1 m uniform grids the junctions have three different radiuses i e 0 5 m 0 6 m and 0 75 m as detailed in table 3 during the simulation the manning coefficient is set to 0 035 m 1 3 s over the entire system an inflow hydrograph as shown in fig 16 is imposed at junction 1 to create a flow through the connecting pipes and junctions and finally discharging through outfall 1 and outfall 2 fig 17 presents the simulation results in terms of water depth and flow rate at the two outfalls overall the time histories of the outfall water depth and flow rate are consistent with the inflow hydrograph due to the shorter route between junction 1 and outfall 1 the flow arrives earlier at outfall 1 than at outfall 2 similarly outfall 1 welcomes the flood peak slightly earlier than outfall 2 both of the peak flow depth and discharge at outfall 1 are higher than those at outfall 2 to reach outfall 2 the flow must travel longer and more complicated routes that involve more junctions and pipes which will potentially lead to more complex flow hydrodynamics involving more momentum exchange and dissipation and subsequently lower peaks of the water depth and flow rate the inflow peaks before t 1000 s and terminates at t 1800 s and the simulation results clearly reflect the inflow pattern this indicates reasonable prediction and demonstrates the capability of the current model in predicting flow hydrodynamics in practical drainage systems involving wet dry fronts complex junction pipe outfall connections and dynamic flow transitions 4 conclusions this paper presents a novel 1d 2d coupled model for hydrodynamic simulation of transient flows in drainage networks the model adopts a 1d tpa model to simulate the flow dynamics in pipes which can effectively capture free surface and pressurized transient flows for the junction calculations an innovative approach that treats a junction as a 2d domain is proposed with the flow hydrodynamics in the junction calculated using a 2d swe model to automatically take into account both mass and momentum conservation the 2d junction calcutation approach is further implemented with a new method for evaluating the pressure fluxes over the wall interface finally the two modelling components are dynamically coupled together to become an integrated drainage model which is validated against one experimental and three idealized test cases with satisfactory results in one of the test cases the numerical predictions are also compared with the results neglecting momentum exchange inside the junctions to demonstrate the importance of reinforcing momentum conservation in the junction calculations in conclusion the proposed drainage model provides a potential tool for accurate simulation of transient flow hydrodynamics in urban drainage systems and has the following technical highlights 1 the presented drainage model adopts a 2d numerical method for the junction flow calculations which introduces a momentum based approach to automatically account for momentum exchange in multi pipe junctions with arbitrary entrance and exit angles 2 the model formulation streamlines the enforcement of boundary conditions between pipes and junctions effectively removing the requirement of numerous logical checks based on the possibility of either pressurized or free surface flow in the previously developed models e g sanders and bradford 2010 3 implemented with a finite volume shock capturing scheme and robust source term discretization methods the drainage model gives relatively smooth and stable predictions of complex flow that involves wet dry fronts and dynamic transition between free surface and pressurized flows in pipe networks of moderate complexity this demonstrates the model s potential for wider application in large scale urban drainage modelling credit authorship contribution statement qian li conceptualization methodology validation visualization writing original draft qiuhua liang supervision funding acquisition conceptualization methodology writing review editing xilin xia supervision funding acquisition conceptualization methodology declaration of competing interest on behalf of all of the authors of the above paper being submitted to advances in water resources i confirm that there is no conflict of interest has been identified or raised for this submission acknowledgments this work was funded by the uk natural environment research council nerc through the future drainage project ne s016678 1 and the royal academy of engineering through a newton fund research grant uufrip 100033 as part of the uk china urban flooding research impact programme the first author thanks the financial support provided by the china scholarship council scholarship the authors also thank prof brett f sanders and other two anonymous reviewers for their constructive comments supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103519 appendix supplementary materials image application 1 
524,we present the results of a hydraulic tomography led on a 60 40 m² fractured and karstic field in southern france in order to image in a model its transmissivity field the dataset employed for the tomography consists in drawdown responses to cross boreholes pumping tests reaching pseudo steady state with 8 different pumping wells and 22 measurement boreholes the inversion of the dataset was led on a 2d model coupling a discrete network and a continuum by following the discrete network deterministic inversion dndi method this method permits an optimization of both the transmissivity distribution and the structural geometry of the discrete network which represents in this case the interconnected fractures and conduits in the aquifer the optimized model obtained after inversion allows reproducing the observed drawdown in the field and proposes a contrasted imaging of the hydraulic properties as awaited in such fractured site the fracture network in the optimized model also shows coherent orientations of fracturing compared to the orientations effectively observed on the field even though this information was not included in the inversion a comparison of the results obtained with this coupled model to results obtained on the same data with equivalent porous media model without integration of a discrete network shows that the integration of a discrete network in the model greatly improves the ability of the model to reproduce the flows existing in such fractured fields and thus the observed drawdowns keywords inverse problem karst fractures discrete network pumping test hydraulic tomography 1 introduction characterization of the subsurface field hydraulic properties represents an important problematic for the hydrogeologists and engineers in fact the spatial distribution of the values of hydraulic properties such as transmissivity strongly influences the subsurface flows the assessment of these underground properties usually requires to analyze responses to a solicitation of the field such as drawdown responses to a groundwater pumping batu 1998 or other solicitations such as injections slug tests tracers as described in butler 2005 therefore the spatialization of the transmissivity values can be caught among other methods by simultaneously analyzing the responses to pumping tests led in different boreholes from the same field this is typically realized by a hydraulic tomography approach yeh and lee 2007 in this approach a large set of responses to cross borehole pumping tests is associated with an inversion process in order to map a transmissivity field in a model which is then able to reproduce the observed drawdowns when solving the flow equation illman et al 2009 cardiff and barrash 2011 cardiff et al 2013 fischer et al 2017a hydraulic tomography appears as a powerful tool for the characterization of fractured fields hydraulic properties in fact in fractured aquifers the groundwater flow paths are mostly constrained in the network of fractures because these fractures generate a local increase in the conductivity field this leads to high contrasts in hydraulic properties with a high conductivity fracture network surrounded by a lower conductivity rock matrix illman 2014 reviewed and highlighted the advantages brought by hydraulic tomography for the assessment of these contrasts in fractured site the scientific literature contains several works of hydraulic tomography on fractured fields some of these works being listed hereafter one main difference between these works concerns the representation of the heterogeneity within the transmissivity field in the model one of the approaches is to represent this heterogeneity with a single continuum in which the fractures and matrix properties are approximated with an equivalent hydraulic conductivity field in this case the solution of the inversion should be constrained in order to produce the expected contrast in the transmissivity field thus hao et al 2008 and sharmeen et al 2012 have used the sequential successive linear estimator developed by yeh and liu 2000 to image the conductivity fields of respectively a synthetic fractured case and a fractured rock block in laboratory the same approach was also tested more recently by mohammadi and illman 2019 on a synthetic karstic conduit network other possible inversion constraints for single continuum modeling have been tested on a same dataset from a fractured and karstified field in france the transitional probability generation wang et al 2017 the sparse non linear optimizer wang et al 2016 and a cellular automata based approach fischer et al 2017b single continuum 3d hydraulic tomography applications have been proposed by illman et al 2009 and zha et al 2015 for a large fractured field in japan and more recently for a fractured rock unit at a smaller scale by tiedeman and barrash 2019 a dual continuum considering two linked continuum one for the matrix and one for the fractures has been proposed in trottier et al 2014 as an alternative to the single continuum representation another possible representation for the imagery of fractured fields requires the integration of a discrete network in the model in this case a network of lines or planes representing the fractures is included in a 2d or 3d continuum which represents the matrix the matrix can be considered as impermeable leading to water fluxes only in the fracture networks or a low permeability background in a coupled model allowing for flows also in the matrix this type of representation has been adopted to infer the hydraulic properties of a simplified fracture network positioned in the model based on connectivity information in klepikova et al 2013 and klepikova et al 2014 however the main difficulty arising from this representation remains the construction of the discrete network within the model in fact in this case not only the property values of the fractures are important but also their positioning and their connectivity therefore when the information related to the fractures positioning is limited it may be necessary to optimize the network geometry in the model as well this can be achieved by generating networks stochastically from field information such as statistical cacas et al 1990 mechanical josnin et al 2002 bonneau et al 2013 or speleological templates pardo iguzquiza et al 2012 information more recently somogyvari et al 2017 have proposed to optimize the discrete network with a method based on a reversible jump markov chain monte carlo which allows for iterative semi random updates of its geometry based on statistical information however a deterministic optimization of the network of fractures is less common in the literature such a method to optimize the geometry of a network of interconnected fractures in a deterministic way has been proposed in fischer et al 2018a and tested on synthetic cases several works have discussed the importance of integrating discrete networks for the modeling of flows in fractured or karstic aquifers compared to single continuum models among them kovacs 2003 noticed that for a karstic aquifer at a watershed scale kilometric only the presence of discrete networks in the model could permit to reproduce in a same time the observed heads and the observed spring discharges more recently dong et al 2019 studied the conditions to obtain an equivalence between inverted single continuum simulations and simulations obtained from a synthetic discrete fracture network model they have observed that if the scale of the investigation within a fractured medium reaches the representative elementary volume rev then a single continuum model could provide good inversion results however if the scale was below the rev and the observation wells were limited a single continuum model permitted to only identify the dominant fractures in this work we aim to contribute to this discussion comparing single continuum and discrete network modeling approaches for the representation of a fractured field in a hydraulic tomography for this purpose we will apply the discrete network deterministic inversion dndi method proposed in fischer et al 2018a on steady state drawdown responses obtained at a decametric scale on the terrieu fractured and karstified field in france the results obtained from the discrete network modeling in this work will then be compared to those obtained from a more classical single continuum modeling these comparison will allow us to discuss the benefits of including discrete networks in the model for the representation of fractures conduits networks at a decametric scale in this paper we will first briefly present the terrieu site and the drawdown dataset used for its characterization then we will expose the parameterization of the transmissivity field in the model for the dndi method and its associated deterministic inversion for the optimization of both the network geometry and the transmissivity values in the last section we will present the results obtained with the dndi approach and discuss its differences benefits and limits to those obtained from other approaches without discrete networks 2 site presentation the terrieu experimental field is located on the medycyss observation site jourde et al 2011 part of the karst observatory network jourde et al 2018 initiated by the french institute insu cnrs this well known site has been recently studied in two phd thesis jazayeri noushabadi 2009 and dausse 2015 and characterized through different tomographic approaches wang et al 2016 wang et al 2017 fischer et al 2017b fischer et al 2018b this field is located in southern france at the north of the city montpellier see fig 1 it is part of the karstic and fractured lez regional aquifer whose spring is located a few kilometers downstream the terrieu field extends over an area of approximately 2500 m² and is equipped with 22 boreholes distributed over this area as presented in fig 1b geological logs in these boreholes indicate that the field is composed of thin layered marly limestones on its upper part and massive limestones below the interface between these two units is a slope monocline fractured plane dipping at 20 nord west and present at depths between 35 and 45 m above the field surface the fractures have an ene wsw global direction and a less important se nw secondary direction wang et al 2016 characterization investigations temperature logs electrical conductivity logs and packer tests presented in jazayeri noushabadi 2009 jazayeri noushabadi 2011 and dausse 2015 have highlighted the fact that the groundwater flows in this field were mostly constrained to the interface between the two geological units dausse et al 2019 wells downhole videos have indeed shown that a karstic network had preferentially developed within this sloped bedding plane with conduits aperture up to 25 cm width because of the low permeability of the rocks units on both sides of this fractured interface the aquifer part on this field is supposed to be confined the previous investigations also permitted to show that several boreholes of the site were well connected through this karstic network this known connectivity is presented in fig 1c with a blue line linking the connected boreholes the dataset employed for the hydraulic tomography approach presented in this article has been obtained from a cross boreholes pumping investigation performed within the framework of jazayeri noushabadi s phd eight alternated constant rate pumping tests have been performed on the field in the boreholes and with the pumping rates indicated in red in fig 1c the groundwater level during the different pumping tests was always kept above 35 m below the surface which means that the fractured and karstified horizon was continuously saturated during the pumping phases the drawdowns were measured continuously in all wells in the fields with ctd diver probes the pseudo steady state approaching the steady state drawdown responses measured in each well and for each pumping a total of 176 data constitute the dataset used for the modeling of flow field presented in the next section 3 algorithm presentation 3 1 forward problem and model parameterization the hydraulic tomography approach presented in this article has been performed with the discrete network deterministic inversion dndi algorithm as presented in fischer et al 2018a the dndi method is based on a coupled discrete continuum model γ in which the transmissivity is distributed over of a 1d discrete network γn representing the karstic fractures flows and a 2d continuum γm representing the flows in the matrix rock the forward problem f consists in solving the flows continuity equations in a steady state by considering the darcy s formulation in both parts 1 t m h q m s el in the matrix γ m t t n t h q n s el in the network γ n with tm tn the equivalent transmissivities of the matrix rock and of the fractures m² s h the piezometric level m q m q n punctual extractions rates m3 s at pumping locations and sel a model elementary surface at the given pumping locations m² t is the tangential gradient along the discrete elements of the model the coupled model is partitioned in px squared subspaces along the x axis and py along the y axis for a total of p px py subspaces the position of the discrete network in the model and the distribution of the transmissivities among the background and the fractures are piloted by two vectors of parameters p dir and p prop fig 2 p dir is a p vector i e of dimension p 1 containing the local directions of the network for each subspace of the model following an established encoding see encoding in fig 2 the generation of the network follows a node to node principle the encoding defines for each subspace how the network should propagate in it one over six possible directions if one of its node a corner between subspaces becomes activated during the generation process the generation starts at a chosen node which is initially considered as activated if a subspace connected to this activated node is encoded with a local direction going through this node the network propagates in the direction assigned to this area of the model the node newly reached by the generated network becomes activated allowing the generation of the network in new subspaces while the subspace in which the generation has already occurred becomes inhibited to another generation the node to node generation process continues until there is no more newly activated nodes some of the subspaces may not participate in the generation of the network in the end if none of their nodes is activated during the process or if their nodes activated during the generation are not involved in their encoded direction leading to a no fracture possibility p prop is a 2p vector containing the local values of transmissivity for the background matrix and fracture parts in each subspace thus a model γ can be generated and locally modified in an easy way through the values contained in p dir and p prop a model defined with these two parameters is noted γ p dir p prop solving the forward problem presented in eq 1 for a parameterized coupled model as presented in fig 2 permits to simulate the map of piezometric levels in this work we simulate the piezometric levels with the software comsol multiphysics considering an adaptive triangular mesh sizes between 0 06 m² and 1 5 m² for the finite element resolution of eq 1 in our case the piezometric levels will allow to assess the drawdowns generated from the pumping tests at the given measurement points 2 d f γ p dir p prop ε where d is a n vector of simulated drawdowns at different locations f is the forward problem described in eq 1 γ p dir p prop is a parameterized coupled model and ε is a gaussian noise with a zero mean for adding noise to the data and prevent an overfitting of the inversion 3 2 inverse problem the inverse problem involves the use of a forward problem in the optimization process in order to find a possible solution of the parameters p dir and p prop in a bayesian framework this consists in defining a model able to reproduce the set of observed drawdowns while also respecting some prior properties information our deterministic inversion process is sequential and iterative after each step the parameters are modified in order to reduce the values of the objective functions tarantola and valette 1982 3 ψ n e t w o r k p dir 1 2 d o b s f γ p dir p prop t c d 1 d o b s f γ p dir p prop 1 2 p dir p r i o r p dir t c p dir 1 p dir p r i o r p dir 4 ψ p r o p e r t i e s p prop 1 2 d o b s f γ p dir p prop t c d 1 d o b s f γ p dir p prop 1 2 p prop p r i o r p prop t c p prop 1 p prop p r i o r p prop with ψ network the structural objective function ψ properties the properties objective function d obs a n vector of observed drawdown to be reproduced by the model p dir prior and p prop prior are vectors of a priori parameter values to constrain the optimization c d is a n n covariance matrix on the drawdown data and c p dir and c p prop are p p and 2p 2p covariance matrices on the parameters values the deterministic inversion process is initialized with chosen values for the structural parameter p dir and the property parameter p prop the initial property values should be chosen wisely as in a deterministic process the initial model determines the local solution to which the process will converge then the optimization part permits to modify the parameters p dir and p prop in order to minimize the objective functions the parameters are not optimized simultaneously we use a sequential inversion modifying first p dir by considering the initial p prop and the objective function in eq 3 and then modifying p prop by considering the previously inverted p dir and the objective function in eq 4 finally the inversion process finishes with a posterior sensitivity analysis on the resulting model 3 3 optimization and uncertainties estimation the parameters contained in p dir and p prop are modified iteratively in the sequential optimization part of the inverse process this part modifies the parameters in order to minimize the objective functions in eqs 3 and 4 by using sensitivity analyses firstly the structural parameter p dir is optimized while we consider the initial p prop as constant for a given iteration k the optimization of p dir k uses a sensitivity analysis contained in a 6 p matrix jn k generated for an element i j of the matrix as follow 5 j n k i j 1 2 d o b s f γ p dir k p dir j i p prop t c d 1 d o b s f γ p dir k p dir j i p prop 1 2 p dir p r i o r j i t c p dir 1 p dir p r i o r j i with γ p dir k p dir j i p prop the model generated through a modification of the local direction i among the 6 possible as encoded in fig 2 in the subspace j of the model among the p subspaces of the model p dir k is updated from the minimum value found in jn k the minimum value represents the best minimization of the objective function in eq 3 for this iteration and its position i min j min in the matrix represents the modification of local direction i min in the subspace j min that has to be produced to generate p dir k 1 the iterative process continues until no more minimization can be found through the structural parameter for the objective function in eq 3 after the optimization part the distribution of the structural posterior uncertainties can be calculated for each subspace of the model in a p vector c p dir post 6 c p dir post j 1 6 i 1 6 j n post i j ψ n e t w o r k post c p dir 1 j j 1 where c p dir post j denotes the structural posterior uncertainty value associated to the subspace j jn post is the structural sensitivity matrix of the last optimization iteration and ψ netw ork post is the value of the structural objective function of the last optimization iteration secondly the property parameter p prop is optimized while we consider the previously optimized p dir as constant for a given iteration k the optimization of p prop k uses a linearization of the objective function in eq 4 7 p prop k 1 p prop k j p k t c d 1 j p k c p prop 1 1 j p k t c d 1 d o b s f γ p dir p prop k c p prop 1 p prop p r i o r p prop k where jp k is the n 2p sensitivity matrix computed from a finite difference method j p k i j f i p prop k p prop k j p prop k j δ p prop where δp prop is a finite difference step in this application δp prop 10 4 the iterative process continues until the value of the objective function in eq 3 converges to a minimum after the optimization part a matrix of posterior covariance can be calculated as follow 8 c p prop post j p post t c d 1 j p post c p prop 1 1 with jp post is the sensitivity matrix of the last optimization iteration the standard deviation uncertainty associated to the property values of each subspace can be inferred from the square root values of the diagonal entry of the posterior covariance matrix 4 application 4 1 hydraulic tomography result a 2d 60 40 m² model has represented a top down view of the fractured interface plane from the terrieu experimental field the model was surrounded by a large equivalent porous media area buffer zone in order to neglect the effect of the boundaries conditions on the drawdowns in the model the dndi algorithm was coded in matlab and linked to comsol multiphysics which solved the forward problem in steady state for the inversion the parameters considered in p prop were the transmissivity values in a log10 scale log 10 t the values of transmissivities in the model were taken as initially uniform within the matrix 10 6 m² s and the fracture 10 1 m² s these initial values were also used as a priori values during the inversion in p prop prior the transmissivity of the buffer zone was fixed for the whole inversion at a value 10 2 m² s these values were chosen accordingly to the previous studies and results obtained on this field wang et al 2016 fischer et al 2017b no a priori information concerning the fracture network local direction were considered in p dir prior the covariance matrices were constructed as diagonal matrices thus we chose c d 10 2 id n and c p prop σ i d m with σ 10 2 for the fracture log10 transmissivities and σ 1 for the matrix log10 transmissivities the inversion was initialized with a model containing one single linear fracture oriented east west with a starting node in coordinates 0 0 see fig 3 as the process is deterministic the initial model influences the inversion in particular starting from an initial model too far from the solution might result in a non convergence of the inversion a first partitioning of the model in 6 4 subspaces i e 10 10 m² square subspaces was chosen for the dndi method this partitioning was used for a first inversion fig 3a to b whose result was then repartitioned and used as initial model for a second inversion fig 3c to d this multi scale inversion has been already employed in previous works yoon et al 1999 grimstadt et al 2003 and permits to prioritize the flows in the model in this way the first inversion aimed to find the global trends of the discrete network while the second inversion permitted to detail local parts of the network in a deterministic problem this multi scale approach accelerates the inversion process and facilitates its convergence to a local minimum after partitioning it is especially interesting for deterministic inversion problems of highly heterogeneous fields which could easily diverge when the resolution of the model is too high although this high amount of inversion parameters is necessary to represent the heterogeneity the solution to which the deterministic inversion converged after optimization of the network geometry and the transmissivity values is presented in fig 4 b the result was obtained after 32 structural iterations and 3 properties iterations fig 4c presents the maps of structural uncertainties associated to the solution the lower the value of structural uncertainty the better the local direction is constrained by the data modifying this local direction would result in a bad reproduction of the observed responses fig 4d presents the maps of transmissivity standard deviations associated to the solution the distribution of transmissivities obtained after inversion presents a dense network of fractures in a heterogeneous matrix fig 4b the network of fracture can appear as rather unrealistic or simplistic regarding the known morphology of fractures and karst conduits however the dndi method is purely based on flow data and no morphologic information was provided to the inversion process therefore the network presented in the model shall mimic only the interconnected fractures influencing the groundwater flows induced by the pumping in the field the part of the fractures and conduits that do not contribute to these flows like dead end features for example can logically not be retrieved with this inversion method the model permits a good reproduction of the drawdowns root mean square error rmse of 0 18 m except for the very small drawdowns 50 cm fig 5 the uncertainties on the geometry of the network fig 4c indicate that the reproduction of the drawdowns is conditioned to the local directions identified for a large part of the network in the central part of the model this indicated that for the modeling of flows in a fractured media a good integration of the directions of the fractures is essential the part of the network around p5 and p6 appears as less constrained structurally but according to previous works dausse 2015 this area would be associated more likely to less important fractures and thus their orientations might have less impact on the flows the western part and south eastern parts of the network are not structurally constrained by the data which means that the fractures orientations in these parts don t play an important role in the reproduction of the observed drawdowns however the inversion process brought some modifications in these parts of the network densification of the fractures network which can be attributed to the simulation of more water income from these parts of the model indicating the existence of fractures which cannot be clearly identified due to the absence of boreholes in these area the uncertainty on the transmissivity values standard deviations in fig 4d have not been significantly lowered during the inversion except in some local parts in the center of the model this is due to the fact that in a fractured and karstic field the flows are more influenced by the orientation and localization of the fractures conduits and the contrast of hydraulic properties between matrix and fractures rather than by variations of property values within a fracture or in the matrix in fig 5 we present graphs showing the orientations of fractures in the model and observed on field as described in wang et al 2016 for the orientation of the fractures in the model we considered only the parts of the network which were structurally constrained by the model as the orientations of the fractures in the other parts may not be representative by comparing these two graphs it appears that the network obtained by inversion is rather coherent with the observed orientations of fracturing the main orientations of fractures in the model are ne sw and e w corresponding to the observed ene wsw orientations which cannot be represented in the model through the dndi method then the nw se orientation is also represented in the model and represents a secondary direction of fracturing while the n s orientation concerns only a few part of the network which is also coherent to the observations on the field in the inversion process these information of orientation could only be interpreted from the data as the initial model integrated only one single fracture oriented e w and no prior information concerning the fracture orientations were integrated in the inversion process therefore this comparison between modeled and observed fracture network represents one form of validation of the model the fracture network in the model however cannot reproduce the known high connectivity existing between some boreholes of the field see fig 1c two remarks can be proposed to explain this limitation first the dndi method limits the directions of fractures to four possible orientations which constrains the liberty for the fracture network optimization one possibility to reduce this limitation is a more important partitioning of the model for example in our case by continuing our inversion process with a 24 16 partitioning however the more the model is partitioned the more the inversion computation time will be important as this will necessarily increase the amount of subspaces in the model and thus the amount of parameters to be inverted secondary as suggested in fischer et al 2018b steady state responses are influenced by flows in all fractures and karstic structures of the field this might hide the information about the flows associated to the most important flowpath usually associated to conduits in the responses 4 2 discussion during the inversion presented in this article we performed a progressive multi scale partitioning we started the inversion with a 6 4 subspaces and used the result of this first inversion as initial model for a second inversion with a model repartitioned to 12 8 subspaces fig 6 compares the scatterplots of observed modeled drawdowns obtained after each inversion it shows that having a second partitioning to 12 8 subspaces was necessary to reach an acceptable reproduction of the observed drawdowns r² of 0 86 this is mainly due to the gain of liberty in the optimization obtained from a finer partitioning of the model however starting from a coarser partitioning with 6 4 subspaces instead of directly inverting a 12 8 subspaces model also presents the advantage of finding more quickly the main directions in the fracture network this is especially interesting as we chose to initiate the inversion with a very simple model it would have necessitate much more iterations to optimize the fracture network if we would have directly started with a finer partitioning in order to discuss the advantages brought by coupled model for the modeling of fractures fields we compare the result obtained with the dndi method with a discrete network integrated in the model to results obtained with equivalent porous media models therefore we have also performed inversions with model without a discrete network in these cases the inversions were performed in a same way then the dndi method but without the discrete network part in the model p dir and without the structural inversion part of eq 3 thus were limited to the minimization of the hydraulic properties of the continuum in eq 4 through its linearization in eq 7 fig 7 presents the inversion results transmissivity maps and scatterplots obtained from the dndi method and two results obtained from inversions of models without discrete network one at the same partitioning 12 8 than the dndi result and one reaching an equivalent ability of reproduction of the observed data but with a finer partitioning 48 32 it can be noted that the computation times necessary to obtain these different results are proportional to their complexity several days for the dndi solution in fig 7a about one day for the solution of fig 7c and a few hours for the one of fig 7b by comparing the result obtained with the dndi method fig 7a to the equivalent porous medium result with a same partitioning fig 7b it appears that the integration of a discrete network at this partitioning is crucial in fact without integrating fractures in the model the inversion fails at finding a distribution able to reproduce the observed drawdowns even though transmissivity values are set at high values in the model in order to simulate the fractures conduits flows these flows are locally constrained and thus a fine distribution of the properties is needed in the model in order to permit their simulation a model without a discrete network but with a finer resolution fig 7c is able to reproduce these flows and their induced drawdowns but is would require a much finer partitioning 48 32 than the dndi model 12 8 furthermore if some structures and fracture connectivity patterns may be identifiable in such model the distribution of the transmissivities remains rather smooth contrary to the awaited contrasted distribution in fractured fields and the values of transmissivities globally high unlike in the dndi result which allows for a good contrast between the fractures and the matrix the coupled discrete continuum model proposed with the dndi method appears thus as really interesting to image the properties of a fractured medium as it allows for a simulation of the complex flows even with a coarse partitioning of the model and it generated a contrasted distribution of transmissivities which also permits to characterize heterogeneity in the background matrix an alternative to represent the contrast of hydraulic properties from a fractures karstic field without integrating a discrete network in the model has been proposed in fischer et al 2017b by applying a cellular automata based deterministic inversion cadi method this application was led on the same site and with the same dataset than the one presented in this article which permits an interesting comparison between the two methods the cadi method unlike the dndi is based on a single continuum approach in which the fracture network is structured directly within the property field with cellular automata it allows for more liberty in the structural optimization of the property distribution than the dndi method therefore the network represented in the cadi result is more realistic regarding the knowledge of the field it permits for example the reproduction of the known high connectivity between some boreholes represented in fig 1c however and as discussed before with fig 7 the result obtained with the dndi method permits a better reproduction of the flows and the observed drawdowns even with a coarser partitioning r² 0 86 with 12 8 subspaces for the dndi model and r² 0 78 with 24 16 subspaces for the cadi model in fischer et al 2017b 5 conclusion we present an application of a hydraulic tomography led on the fractured and karstic terrieu field site in france in order to image its transmissivity field in a model the dataset consists in drawdown responses to pumping tests reaching the pseudo steady state the inversion was performed with the dndi method a method that allows for the optimization of the distribution of transmissivities in the model but also for the optimization of the structure of a discrete network in the model the model obtained after inversion of the dataset permits a good reproduction of the observed drawdowns and also reproduces the main directions of fracturing observed on the field even though this information was not included in the inversion process however the model fails at reproducing the known high connectivity conduit flows in the field this may be due to the limitations of the dndi method concerning the possible orientations of fractures for the optimization but also to the flow information contained in the steady state drawdown responses which might not permit to distinguish the major flowpaths from less important ones the results obtained with the dndi method on this application show two main advantages of using a coupled discrete continuum model for the characterization of the flows in fractured media compared to equivalent porous media models the discrete network in the model allows for a better contrast in the transmissivity distribution and induces a better reproduction of the observed drawdowns with a coarser partitioning of the model that would be needed with an equivalent porous medium model the contrast existing in a coupled model also allows for more details in the background of the model matrix whereas in equivalent porous media models the distinction between structures fracture conduit and matrix is less clear the dndi method can be applied to other types of hydraulic data simply by adapting the forward problem and the data used in the inversion for example it could be possible to lead a same type of modeling with drawdown curves in a time domain or with oscillatory response in a frequency domain as proposed in fischer et al 2018b nevertheless the dndi method still requires some improvement in order to provide more liberty in the structural optimization of the network with more liberty the results could provide even better localization and positioning of the fractures without having to increase the partitioning of the model which leads to more computation time furthermore at the moment this method has been developed only in 2d and would require some additions to work in 3d credit authorship contribution statement p fischer conceptualization methodology software validation writing original draft a jardani conceptualization validation writing review editing supervision h jourde investigation data curation writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank lisa ringel peter bayer and maria klepikova for their relevant comments and suggestions to improve the quality of this article data and characterization of the terrieu experimental site was realized within the framework of the medycyss observation site part of the karst observatory network initiated by the french institute insu cnrs data are available on demand on www sokarst org 
524,we present the results of a hydraulic tomography led on a 60 40 m² fractured and karstic field in southern france in order to image in a model its transmissivity field the dataset employed for the tomography consists in drawdown responses to cross boreholes pumping tests reaching pseudo steady state with 8 different pumping wells and 22 measurement boreholes the inversion of the dataset was led on a 2d model coupling a discrete network and a continuum by following the discrete network deterministic inversion dndi method this method permits an optimization of both the transmissivity distribution and the structural geometry of the discrete network which represents in this case the interconnected fractures and conduits in the aquifer the optimized model obtained after inversion allows reproducing the observed drawdown in the field and proposes a contrasted imaging of the hydraulic properties as awaited in such fractured site the fracture network in the optimized model also shows coherent orientations of fracturing compared to the orientations effectively observed on the field even though this information was not included in the inversion a comparison of the results obtained with this coupled model to results obtained on the same data with equivalent porous media model without integration of a discrete network shows that the integration of a discrete network in the model greatly improves the ability of the model to reproduce the flows existing in such fractured fields and thus the observed drawdowns keywords inverse problem karst fractures discrete network pumping test hydraulic tomography 1 introduction characterization of the subsurface field hydraulic properties represents an important problematic for the hydrogeologists and engineers in fact the spatial distribution of the values of hydraulic properties such as transmissivity strongly influences the subsurface flows the assessment of these underground properties usually requires to analyze responses to a solicitation of the field such as drawdown responses to a groundwater pumping batu 1998 or other solicitations such as injections slug tests tracers as described in butler 2005 therefore the spatialization of the transmissivity values can be caught among other methods by simultaneously analyzing the responses to pumping tests led in different boreholes from the same field this is typically realized by a hydraulic tomography approach yeh and lee 2007 in this approach a large set of responses to cross borehole pumping tests is associated with an inversion process in order to map a transmissivity field in a model which is then able to reproduce the observed drawdowns when solving the flow equation illman et al 2009 cardiff and barrash 2011 cardiff et al 2013 fischer et al 2017a hydraulic tomography appears as a powerful tool for the characterization of fractured fields hydraulic properties in fact in fractured aquifers the groundwater flow paths are mostly constrained in the network of fractures because these fractures generate a local increase in the conductivity field this leads to high contrasts in hydraulic properties with a high conductivity fracture network surrounded by a lower conductivity rock matrix illman 2014 reviewed and highlighted the advantages brought by hydraulic tomography for the assessment of these contrasts in fractured site the scientific literature contains several works of hydraulic tomography on fractured fields some of these works being listed hereafter one main difference between these works concerns the representation of the heterogeneity within the transmissivity field in the model one of the approaches is to represent this heterogeneity with a single continuum in which the fractures and matrix properties are approximated with an equivalent hydraulic conductivity field in this case the solution of the inversion should be constrained in order to produce the expected contrast in the transmissivity field thus hao et al 2008 and sharmeen et al 2012 have used the sequential successive linear estimator developed by yeh and liu 2000 to image the conductivity fields of respectively a synthetic fractured case and a fractured rock block in laboratory the same approach was also tested more recently by mohammadi and illman 2019 on a synthetic karstic conduit network other possible inversion constraints for single continuum modeling have been tested on a same dataset from a fractured and karstified field in france the transitional probability generation wang et al 2017 the sparse non linear optimizer wang et al 2016 and a cellular automata based approach fischer et al 2017b single continuum 3d hydraulic tomography applications have been proposed by illman et al 2009 and zha et al 2015 for a large fractured field in japan and more recently for a fractured rock unit at a smaller scale by tiedeman and barrash 2019 a dual continuum considering two linked continuum one for the matrix and one for the fractures has been proposed in trottier et al 2014 as an alternative to the single continuum representation another possible representation for the imagery of fractured fields requires the integration of a discrete network in the model in this case a network of lines or planes representing the fractures is included in a 2d or 3d continuum which represents the matrix the matrix can be considered as impermeable leading to water fluxes only in the fracture networks or a low permeability background in a coupled model allowing for flows also in the matrix this type of representation has been adopted to infer the hydraulic properties of a simplified fracture network positioned in the model based on connectivity information in klepikova et al 2013 and klepikova et al 2014 however the main difficulty arising from this representation remains the construction of the discrete network within the model in fact in this case not only the property values of the fractures are important but also their positioning and their connectivity therefore when the information related to the fractures positioning is limited it may be necessary to optimize the network geometry in the model as well this can be achieved by generating networks stochastically from field information such as statistical cacas et al 1990 mechanical josnin et al 2002 bonneau et al 2013 or speleological templates pardo iguzquiza et al 2012 information more recently somogyvari et al 2017 have proposed to optimize the discrete network with a method based on a reversible jump markov chain monte carlo which allows for iterative semi random updates of its geometry based on statistical information however a deterministic optimization of the network of fractures is less common in the literature such a method to optimize the geometry of a network of interconnected fractures in a deterministic way has been proposed in fischer et al 2018a and tested on synthetic cases several works have discussed the importance of integrating discrete networks for the modeling of flows in fractured or karstic aquifers compared to single continuum models among them kovacs 2003 noticed that for a karstic aquifer at a watershed scale kilometric only the presence of discrete networks in the model could permit to reproduce in a same time the observed heads and the observed spring discharges more recently dong et al 2019 studied the conditions to obtain an equivalence between inverted single continuum simulations and simulations obtained from a synthetic discrete fracture network model they have observed that if the scale of the investigation within a fractured medium reaches the representative elementary volume rev then a single continuum model could provide good inversion results however if the scale was below the rev and the observation wells were limited a single continuum model permitted to only identify the dominant fractures in this work we aim to contribute to this discussion comparing single continuum and discrete network modeling approaches for the representation of a fractured field in a hydraulic tomography for this purpose we will apply the discrete network deterministic inversion dndi method proposed in fischer et al 2018a on steady state drawdown responses obtained at a decametric scale on the terrieu fractured and karstified field in france the results obtained from the discrete network modeling in this work will then be compared to those obtained from a more classical single continuum modeling these comparison will allow us to discuss the benefits of including discrete networks in the model for the representation of fractures conduits networks at a decametric scale in this paper we will first briefly present the terrieu site and the drawdown dataset used for its characterization then we will expose the parameterization of the transmissivity field in the model for the dndi method and its associated deterministic inversion for the optimization of both the network geometry and the transmissivity values in the last section we will present the results obtained with the dndi approach and discuss its differences benefits and limits to those obtained from other approaches without discrete networks 2 site presentation the terrieu experimental field is located on the medycyss observation site jourde et al 2011 part of the karst observatory network jourde et al 2018 initiated by the french institute insu cnrs this well known site has been recently studied in two phd thesis jazayeri noushabadi 2009 and dausse 2015 and characterized through different tomographic approaches wang et al 2016 wang et al 2017 fischer et al 2017b fischer et al 2018b this field is located in southern france at the north of the city montpellier see fig 1 it is part of the karstic and fractured lez regional aquifer whose spring is located a few kilometers downstream the terrieu field extends over an area of approximately 2500 m² and is equipped with 22 boreholes distributed over this area as presented in fig 1b geological logs in these boreholes indicate that the field is composed of thin layered marly limestones on its upper part and massive limestones below the interface between these two units is a slope monocline fractured plane dipping at 20 nord west and present at depths between 35 and 45 m above the field surface the fractures have an ene wsw global direction and a less important se nw secondary direction wang et al 2016 characterization investigations temperature logs electrical conductivity logs and packer tests presented in jazayeri noushabadi 2009 jazayeri noushabadi 2011 and dausse 2015 have highlighted the fact that the groundwater flows in this field were mostly constrained to the interface between the two geological units dausse et al 2019 wells downhole videos have indeed shown that a karstic network had preferentially developed within this sloped bedding plane with conduits aperture up to 25 cm width because of the low permeability of the rocks units on both sides of this fractured interface the aquifer part on this field is supposed to be confined the previous investigations also permitted to show that several boreholes of the site were well connected through this karstic network this known connectivity is presented in fig 1c with a blue line linking the connected boreholes the dataset employed for the hydraulic tomography approach presented in this article has been obtained from a cross boreholes pumping investigation performed within the framework of jazayeri noushabadi s phd eight alternated constant rate pumping tests have been performed on the field in the boreholes and with the pumping rates indicated in red in fig 1c the groundwater level during the different pumping tests was always kept above 35 m below the surface which means that the fractured and karstified horizon was continuously saturated during the pumping phases the drawdowns were measured continuously in all wells in the fields with ctd diver probes the pseudo steady state approaching the steady state drawdown responses measured in each well and for each pumping a total of 176 data constitute the dataset used for the modeling of flow field presented in the next section 3 algorithm presentation 3 1 forward problem and model parameterization the hydraulic tomography approach presented in this article has been performed with the discrete network deterministic inversion dndi algorithm as presented in fischer et al 2018a the dndi method is based on a coupled discrete continuum model γ in which the transmissivity is distributed over of a 1d discrete network γn representing the karstic fractures flows and a 2d continuum γm representing the flows in the matrix rock the forward problem f consists in solving the flows continuity equations in a steady state by considering the darcy s formulation in both parts 1 t m h q m s el in the matrix γ m t t n t h q n s el in the network γ n with tm tn the equivalent transmissivities of the matrix rock and of the fractures m² s h the piezometric level m q m q n punctual extractions rates m3 s at pumping locations and sel a model elementary surface at the given pumping locations m² t is the tangential gradient along the discrete elements of the model the coupled model is partitioned in px squared subspaces along the x axis and py along the y axis for a total of p px py subspaces the position of the discrete network in the model and the distribution of the transmissivities among the background and the fractures are piloted by two vectors of parameters p dir and p prop fig 2 p dir is a p vector i e of dimension p 1 containing the local directions of the network for each subspace of the model following an established encoding see encoding in fig 2 the generation of the network follows a node to node principle the encoding defines for each subspace how the network should propagate in it one over six possible directions if one of its node a corner between subspaces becomes activated during the generation process the generation starts at a chosen node which is initially considered as activated if a subspace connected to this activated node is encoded with a local direction going through this node the network propagates in the direction assigned to this area of the model the node newly reached by the generated network becomes activated allowing the generation of the network in new subspaces while the subspace in which the generation has already occurred becomes inhibited to another generation the node to node generation process continues until there is no more newly activated nodes some of the subspaces may not participate in the generation of the network in the end if none of their nodes is activated during the process or if their nodes activated during the generation are not involved in their encoded direction leading to a no fracture possibility p prop is a 2p vector containing the local values of transmissivity for the background matrix and fracture parts in each subspace thus a model γ can be generated and locally modified in an easy way through the values contained in p dir and p prop a model defined with these two parameters is noted γ p dir p prop solving the forward problem presented in eq 1 for a parameterized coupled model as presented in fig 2 permits to simulate the map of piezometric levels in this work we simulate the piezometric levels with the software comsol multiphysics considering an adaptive triangular mesh sizes between 0 06 m² and 1 5 m² for the finite element resolution of eq 1 in our case the piezometric levels will allow to assess the drawdowns generated from the pumping tests at the given measurement points 2 d f γ p dir p prop ε where d is a n vector of simulated drawdowns at different locations f is the forward problem described in eq 1 γ p dir p prop is a parameterized coupled model and ε is a gaussian noise with a zero mean for adding noise to the data and prevent an overfitting of the inversion 3 2 inverse problem the inverse problem involves the use of a forward problem in the optimization process in order to find a possible solution of the parameters p dir and p prop in a bayesian framework this consists in defining a model able to reproduce the set of observed drawdowns while also respecting some prior properties information our deterministic inversion process is sequential and iterative after each step the parameters are modified in order to reduce the values of the objective functions tarantola and valette 1982 3 ψ n e t w o r k p dir 1 2 d o b s f γ p dir p prop t c d 1 d o b s f γ p dir p prop 1 2 p dir p r i o r p dir t c p dir 1 p dir p r i o r p dir 4 ψ p r o p e r t i e s p prop 1 2 d o b s f γ p dir p prop t c d 1 d o b s f γ p dir p prop 1 2 p prop p r i o r p prop t c p prop 1 p prop p r i o r p prop with ψ network the structural objective function ψ properties the properties objective function d obs a n vector of observed drawdown to be reproduced by the model p dir prior and p prop prior are vectors of a priori parameter values to constrain the optimization c d is a n n covariance matrix on the drawdown data and c p dir and c p prop are p p and 2p 2p covariance matrices on the parameters values the deterministic inversion process is initialized with chosen values for the structural parameter p dir and the property parameter p prop the initial property values should be chosen wisely as in a deterministic process the initial model determines the local solution to which the process will converge then the optimization part permits to modify the parameters p dir and p prop in order to minimize the objective functions the parameters are not optimized simultaneously we use a sequential inversion modifying first p dir by considering the initial p prop and the objective function in eq 3 and then modifying p prop by considering the previously inverted p dir and the objective function in eq 4 finally the inversion process finishes with a posterior sensitivity analysis on the resulting model 3 3 optimization and uncertainties estimation the parameters contained in p dir and p prop are modified iteratively in the sequential optimization part of the inverse process this part modifies the parameters in order to minimize the objective functions in eqs 3 and 4 by using sensitivity analyses firstly the structural parameter p dir is optimized while we consider the initial p prop as constant for a given iteration k the optimization of p dir k uses a sensitivity analysis contained in a 6 p matrix jn k generated for an element i j of the matrix as follow 5 j n k i j 1 2 d o b s f γ p dir k p dir j i p prop t c d 1 d o b s f γ p dir k p dir j i p prop 1 2 p dir p r i o r j i t c p dir 1 p dir p r i o r j i with γ p dir k p dir j i p prop the model generated through a modification of the local direction i among the 6 possible as encoded in fig 2 in the subspace j of the model among the p subspaces of the model p dir k is updated from the minimum value found in jn k the minimum value represents the best minimization of the objective function in eq 3 for this iteration and its position i min j min in the matrix represents the modification of local direction i min in the subspace j min that has to be produced to generate p dir k 1 the iterative process continues until no more minimization can be found through the structural parameter for the objective function in eq 3 after the optimization part the distribution of the structural posterior uncertainties can be calculated for each subspace of the model in a p vector c p dir post 6 c p dir post j 1 6 i 1 6 j n post i j ψ n e t w o r k post c p dir 1 j j 1 where c p dir post j denotes the structural posterior uncertainty value associated to the subspace j jn post is the structural sensitivity matrix of the last optimization iteration and ψ netw ork post is the value of the structural objective function of the last optimization iteration secondly the property parameter p prop is optimized while we consider the previously optimized p dir as constant for a given iteration k the optimization of p prop k uses a linearization of the objective function in eq 4 7 p prop k 1 p prop k j p k t c d 1 j p k c p prop 1 1 j p k t c d 1 d o b s f γ p dir p prop k c p prop 1 p prop p r i o r p prop k where jp k is the n 2p sensitivity matrix computed from a finite difference method j p k i j f i p prop k p prop k j p prop k j δ p prop where δp prop is a finite difference step in this application δp prop 10 4 the iterative process continues until the value of the objective function in eq 3 converges to a minimum after the optimization part a matrix of posterior covariance can be calculated as follow 8 c p prop post j p post t c d 1 j p post c p prop 1 1 with jp post is the sensitivity matrix of the last optimization iteration the standard deviation uncertainty associated to the property values of each subspace can be inferred from the square root values of the diagonal entry of the posterior covariance matrix 4 application 4 1 hydraulic tomography result a 2d 60 40 m² model has represented a top down view of the fractured interface plane from the terrieu experimental field the model was surrounded by a large equivalent porous media area buffer zone in order to neglect the effect of the boundaries conditions on the drawdowns in the model the dndi algorithm was coded in matlab and linked to comsol multiphysics which solved the forward problem in steady state for the inversion the parameters considered in p prop were the transmissivity values in a log10 scale log 10 t the values of transmissivities in the model were taken as initially uniform within the matrix 10 6 m² s and the fracture 10 1 m² s these initial values were also used as a priori values during the inversion in p prop prior the transmissivity of the buffer zone was fixed for the whole inversion at a value 10 2 m² s these values were chosen accordingly to the previous studies and results obtained on this field wang et al 2016 fischer et al 2017b no a priori information concerning the fracture network local direction were considered in p dir prior the covariance matrices were constructed as diagonal matrices thus we chose c d 10 2 id n and c p prop σ i d m with σ 10 2 for the fracture log10 transmissivities and σ 1 for the matrix log10 transmissivities the inversion was initialized with a model containing one single linear fracture oriented east west with a starting node in coordinates 0 0 see fig 3 as the process is deterministic the initial model influences the inversion in particular starting from an initial model too far from the solution might result in a non convergence of the inversion a first partitioning of the model in 6 4 subspaces i e 10 10 m² square subspaces was chosen for the dndi method this partitioning was used for a first inversion fig 3a to b whose result was then repartitioned and used as initial model for a second inversion fig 3c to d this multi scale inversion has been already employed in previous works yoon et al 1999 grimstadt et al 2003 and permits to prioritize the flows in the model in this way the first inversion aimed to find the global trends of the discrete network while the second inversion permitted to detail local parts of the network in a deterministic problem this multi scale approach accelerates the inversion process and facilitates its convergence to a local minimum after partitioning it is especially interesting for deterministic inversion problems of highly heterogeneous fields which could easily diverge when the resolution of the model is too high although this high amount of inversion parameters is necessary to represent the heterogeneity the solution to which the deterministic inversion converged after optimization of the network geometry and the transmissivity values is presented in fig 4 b the result was obtained after 32 structural iterations and 3 properties iterations fig 4c presents the maps of structural uncertainties associated to the solution the lower the value of structural uncertainty the better the local direction is constrained by the data modifying this local direction would result in a bad reproduction of the observed responses fig 4d presents the maps of transmissivity standard deviations associated to the solution the distribution of transmissivities obtained after inversion presents a dense network of fractures in a heterogeneous matrix fig 4b the network of fracture can appear as rather unrealistic or simplistic regarding the known morphology of fractures and karst conduits however the dndi method is purely based on flow data and no morphologic information was provided to the inversion process therefore the network presented in the model shall mimic only the interconnected fractures influencing the groundwater flows induced by the pumping in the field the part of the fractures and conduits that do not contribute to these flows like dead end features for example can logically not be retrieved with this inversion method the model permits a good reproduction of the drawdowns root mean square error rmse of 0 18 m except for the very small drawdowns 50 cm fig 5 the uncertainties on the geometry of the network fig 4c indicate that the reproduction of the drawdowns is conditioned to the local directions identified for a large part of the network in the central part of the model this indicated that for the modeling of flows in a fractured media a good integration of the directions of the fractures is essential the part of the network around p5 and p6 appears as less constrained structurally but according to previous works dausse 2015 this area would be associated more likely to less important fractures and thus their orientations might have less impact on the flows the western part and south eastern parts of the network are not structurally constrained by the data which means that the fractures orientations in these parts don t play an important role in the reproduction of the observed drawdowns however the inversion process brought some modifications in these parts of the network densification of the fractures network which can be attributed to the simulation of more water income from these parts of the model indicating the existence of fractures which cannot be clearly identified due to the absence of boreholes in these area the uncertainty on the transmissivity values standard deviations in fig 4d have not been significantly lowered during the inversion except in some local parts in the center of the model this is due to the fact that in a fractured and karstic field the flows are more influenced by the orientation and localization of the fractures conduits and the contrast of hydraulic properties between matrix and fractures rather than by variations of property values within a fracture or in the matrix in fig 5 we present graphs showing the orientations of fractures in the model and observed on field as described in wang et al 2016 for the orientation of the fractures in the model we considered only the parts of the network which were structurally constrained by the model as the orientations of the fractures in the other parts may not be representative by comparing these two graphs it appears that the network obtained by inversion is rather coherent with the observed orientations of fracturing the main orientations of fractures in the model are ne sw and e w corresponding to the observed ene wsw orientations which cannot be represented in the model through the dndi method then the nw se orientation is also represented in the model and represents a secondary direction of fracturing while the n s orientation concerns only a few part of the network which is also coherent to the observations on the field in the inversion process these information of orientation could only be interpreted from the data as the initial model integrated only one single fracture oriented e w and no prior information concerning the fracture orientations were integrated in the inversion process therefore this comparison between modeled and observed fracture network represents one form of validation of the model the fracture network in the model however cannot reproduce the known high connectivity existing between some boreholes of the field see fig 1c two remarks can be proposed to explain this limitation first the dndi method limits the directions of fractures to four possible orientations which constrains the liberty for the fracture network optimization one possibility to reduce this limitation is a more important partitioning of the model for example in our case by continuing our inversion process with a 24 16 partitioning however the more the model is partitioned the more the inversion computation time will be important as this will necessarily increase the amount of subspaces in the model and thus the amount of parameters to be inverted secondary as suggested in fischer et al 2018b steady state responses are influenced by flows in all fractures and karstic structures of the field this might hide the information about the flows associated to the most important flowpath usually associated to conduits in the responses 4 2 discussion during the inversion presented in this article we performed a progressive multi scale partitioning we started the inversion with a 6 4 subspaces and used the result of this first inversion as initial model for a second inversion with a model repartitioned to 12 8 subspaces fig 6 compares the scatterplots of observed modeled drawdowns obtained after each inversion it shows that having a second partitioning to 12 8 subspaces was necessary to reach an acceptable reproduction of the observed drawdowns r² of 0 86 this is mainly due to the gain of liberty in the optimization obtained from a finer partitioning of the model however starting from a coarser partitioning with 6 4 subspaces instead of directly inverting a 12 8 subspaces model also presents the advantage of finding more quickly the main directions in the fracture network this is especially interesting as we chose to initiate the inversion with a very simple model it would have necessitate much more iterations to optimize the fracture network if we would have directly started with a finer partitioning in order to discuss the advantages brought by coupled model for the modeling of fractures fields we compare the result obtained with the dndi method with a discrete network integrated in the model to results obtained with equivalent porous media models therefore we have also performed inversions with model without a discrete network in these cases the inversions were performed in a same way then the dndi method but without the discrete network part in the model p dir and without the structural inversion part of eq 3 thus were limited to the minimization of the hydraulic properties of the continuum in eq 4 through its linearization in eq 7 fig 7 presents the inversion results transmissivity maps and scatterplots obtained from the dndi method and two results obtained from inversions of models without discrete network one at the same partitioning 12 8 than the dndi result and one reaching an equivalent ability of reproduction of the observed data but with a finer partitioning 48 32 it can be noted that the computation times necessary to obtain these different results are proportional to their complexity several days for the dndi solution in fig 7a about one day for the solution of fig 7c and a few hours for the one of fig 7b by comparing the result obtained with the dndi method fig 7a to the equivalent porous medium result with a same partitioning fig 7b it appears that the integration of a discrete network at this partitioning is crucial in fact without integrating fractures in the model the inversion fails at finding a distribution able to reproduce the observed drawdowns even though transmissivity values are set at high values in the model in order to simulate the fractures conduits flows these flows are locally constrained and thus a fine distribution of the properties is needed in the model in order to permit their simulation a model without a discrete network but with a finer resolution fig 7c is able to reproduce these flows and their induced drawdowns but is would require a much finer partitioning 48 32 than the dndi model 12 8 furthermore if some structures and fracture connectivity patterns may be identifiable in such model the distribution of the transmissivities remains rather smooth contrary to the awaited contrasted distribution in fractured fields and the values of transmissivities globally high unlike in the dndi result which allows for a good contrast between the fractures and the matrix the coupled discrete continuum model proposed with the dndi method appears thus as really interesting to image the properties of a fractured medium as it allows for a simulation of the complex flows even with a coarse partitioning of the model and it generated a contrasted distribution of transmissivities which also permits to characterize heterogeneity in the background matrix an alternative to represent the contrast of hydraulic properties from a fractures karstic field without integrating a discrete network in the model has been proposed in fischer et al 2017b by applying a cellular automata based deterministic inversion cadi method this application was led on the same site and with the same dataset than the one presented in this article which permits an interesting comparison between the two methods the cadi method unlike the dndi is based on a single continuum approach in which the fracture network is structured directly within the property field with cellular automata it allows for more liberty in the structural optimization of the property distribution than the dndi method therefore the network represented in the cadi result is more realistic regarding the knowledge of the field it permits for example the reproduction of the known high connectivity between some boreholes represented in fig 1c however and as discussed before with fig 7 the result obtained with the dndi method permits a better reproduction of the flows and the observed drawdowns even with a coarser partitioning r² 0 86 with 12 8 subspaces for the dndi model and r² 0 78 with 24 16 subspaces for the cadi model in fischer et al 2017b 5 conclusion we present an application of a hydraulic tomography led on the fractured and karstic terrieu field site in france in order to image its transmissivity field in a model the dataset consists in drawdown responses to pumping tests reaching the pseudo steady state the inversion was performed with the dndi method a method that allows for the optimization of the distribution of transmissivities in the model but also for the optimization of the structure of a discrete network in the model the model obtained after inversion of the dataset permits a good reproduction of the observed drawdowns and also reproduces the main directions of fracturing observed on the field even though this information was not included in the inversion process however the model fails at reproducing the known high connectivity conduit flows in the field this may be due to the limitations of the dndi method concerning the possible orientations of fractures for the optimization but also to the flow information contained in the steady state drawdown responses which might not permit to distinguish the major flowpaths from less important ones the results obtained with the dndi method on this application show two main advantages of using a coupled discrete continuum model for the characterization of the flows in fractured media compared to equivalent porous media models the discrete network in the model allows for a better contrast in the transmissivity distribution and induces a better reproduction of the observed drawdowns with a coarser partitioning of the model that would be needed with an equivalent porous medium model the contrast existing in a coupled model also allows for more details in the background of the model matrix whereas in equivalent porous media models the distinction between structures fracture conduit and matrix is less clear the dndi method can be applied to other types of hydraulic data simply by adapting the forward problem and the data used in the inversion for example it could be possible to lead a same type of modeling with drawdown curves in a time domain or with oscillatory response in a frequency domain as proposed in fischer et al 2018b nevertheless the dndi method still requires some improvement in order to provide more liberty in the structural optimization of the network with more liberty the results could provide even better localization and positioning of the fractures without having to increase the partitioning of the model which leads to more computation time furthermore at the moment this method has been developed only in 2d and would require some additions to work in 3d credit authorship contribution statement p fischer conceptualization methodology software validation writing original draft a jardani conceptualization validation writing review editing supervision h jourde investigation data curation writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank lisa ringel peter bayer and maria klepikova for their relevant comments and suggestions to improve the quality of this article data and characterization of the terrieu experimental site was realized within the framework of the medycyss observation site part of the karst observatory network initiated by the french institute insu cnrs data are available on demand on www sokarst org 
