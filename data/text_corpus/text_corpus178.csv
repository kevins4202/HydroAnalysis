index,text
890,the detection and attribution of long term patterns in hydrological time series have been important research topics for decades a significant portion of the literature regards such patterns as deterministic components or trends even though the complexity of hydrological systems does not allow easy deterministic explanations and attributions consequently trend estimation techniques have been developed to make and justify statements about tendencies in the historical data which are often used to predict future events testing trend hypothesis on observed time series is widespread in the hydro meteorological literature mainly due to the interest in detecting consequences of human activities on the hydrological cycle this analysis usually relies on the application of some null hypothesis significance tests nhsts for slowly varying and or abrupt changes such as mann kendall pettitt or similar to summary statistics of hydrological time series e g annual averages maxima minima etc however the reliability of this application has seldom been explored in detail this paper discusses misuse misinterpretation and logical flaws of nhst for trends in the analysis of hydrological data from three different points of view historic logical semantic epistemological and practical based on a review of nhst rationale and basic statistical definitions of stationarity nonstationarity and ergodicity we show that even if the empirical estimation of trends in hydrological time series is always feasible from a numerical point of view it is uninformative and does not allow the inference of nonstationarity without assuming a priori additional information on the underlying stochastic process according to deductive reasoning this prevents the use of trend nhst outcomes to support nonstationary frequency analysis and modeling we also show that the correlation structures characterizing hydrological time series might easily be underestimated further compromising the attempt to draw conclusions about trends spanning the period of records moreover even though adjusting procedures accounting for correlation have been developed some of them are insufficient or are applied only to some tests while some others are theoretically flawed but still widely applied in particular using 250 unimpacted stream flow time series across the conterminous united states conus we show that the test results can dramatically change if the sequences of annual values are reproduced starting from daily stream flow records whose larger sizes enable a more reliable assessment of the correlation structures keywords trend hypothesis tests nonstationarity ergodicity hypothesis test interpretation trend attribution stream flow trends in the united states faced with a sample of unknown origin many applied statisticians working in economics meteorology and the like hasten to decompose it into a trend and an oscillation and added periodic terms they assume implicitly that the addends are attributable to distinct generating mechanisms and are statistically independent this last implicit assumption is quite unwarranted except when the sample is generated by brownian motion b b mandelbrot the fractal geometry of nature p 352 1982 1 introduction due to the complexity of hydrological systems their analysis and modeling heavily rely on historical records as theoretical reasoning and deduction are often inadequate this analysis is even more problematic when we depart from the hypothesis of stationarity to embrace that of nonstationarity even though the two notions of stationarity and nonstationarity should apply to models and not to the real world processes themselves see section 4 below considerable literature assumes that the observed time series generated by the real world seldom appear to be stationary but exhibit more complicated nonstationary behavior in many cases conclusions on nonstationarity are based on the outcome of trend tests applied to finite size time series covering relatively short periods of record a change of paradigm from stationary to nonstationary can be claimed to account for human activities producing predictable changes such as land use and land cover changes and water resources exploitation or more complex but less predictable phenomena such as the worldwide hydrologic change ascribed to anthropogenic climate change acc milly et al 2015 in this respect in the last three decades a huge number of studies have investigated possible human driven changes in the form of slowly varying trends or abrupt changes in time series of hydrological variables across different regions of the world broadly speaking and taking for granted unavoidable differences the aim of these studies has been to understand if these changes are detectable what is their pattern and ultimately to infer nonstationarity thus promoting the implementation of nonstationary models to support new design and planning strategies e g ouarda and el adlouni 2011 rootzén and katz 2013 cheng et al 2014 among many others therefore we believe there exists a need for careful inspection of the basic concepts of null hypothesis statistical tests nhsts for trends and their application to hydrological problems following serinaldi and kilsby 2015 this paper is an attempt to meet this need in fact the purpose of our work is neither to review the state of the art of the research related to trend analysis nor to give examples of the problems discussed thereto rather we summarize and attempt to shed some light on the reasons for contradictory results encountered in the literature and discuss widespread practices that can easily be identified in many studies therefore the conceptual perspective of this study should be seen as a guideline in agreement with the general but scientifically based and widely applicable statement by mandelbrot in the opening motto of this paper on the other hand we attempt to confute a certain mechanistic approach often characterizing the literature on the topic we highlight that conceptual arguments and mathematical definitions are necessary to provide practical advice to identify trends to interpret results and to avoid misleading usage and conclusions the paper is structured as follows by using a simple example section 2 introduces the discussion and research questions and summarizes our conclusions in order to provide the reader with a clear outline of what will follow section 3 reviews the role of trend testing and some problems related to historical derivation epistemological reasons and detection and attribution of changes under temporal persistence then in section 4 we discuss the importance of clear terminology corresponding to well defined concepts to avoid misunderstandings relying on different interpretation of the same terms section 5 gives an overview of the properties of some commonly used trend tests namely mann kendall mk and pettitt in section 6 we analyze 250 unimpacted stream flow time series across the conterminous united states spanning the period 1950 2011 discussion and final remarks are given in section 7 2 nhst for trends overview of key ideas 2 1 setting the scene with a simple example we start our discussion by a simple example of typical trend testing exercise familiar to practitioners as we want to highlight the basic concepts behind trend testing procedures fig 1 a and b shows the average annual discharge of two nearby rivers that we will call the nera river and velino river referring to the following discussion for an in depth description of these data both time series ranging from 1916 to 2015 show an apparent change point around the years 1974 1975 as well as statistically significant and similar autocorrelation functions fig 1 c and d the kendall correlation coefficient between the two time series is τ k 0 32 since we do not know if the autocorrelation is a consequence of a possible deterministic change of regime or the effect of the dependence structure we use statistical tests accounting for the latter therefore we apply both the classic pettitt tests and four additional versions accounting for possible first order markov autocorrelation structure and fractional gaussian noise fgn also known as hurst kolmogorov process serinaldi and kilsby 2016a following the common interpretation of trend tests the tests unanimously lead to the conclusion that a possible deterministic change around 1974 1975 at the 5 significance level after splitting the series into two sub series before and after the change point we find that their autocorrelation is not significant fig 1 e h therefore we next apply standard pettitt and mk tests to the two sub series for both rivers villarini et al 2009a since no significant trend or change point was found in the sub series we can conclude that autocorrelation is reasonably the effect of an abrupt change occurred around 1974 1975 based on these results the common approach attempts to explain such changes by some anthropogenic activities including some more easily recognizable i e river training water abstraction dam construction etc and some less i e acc climate teleconnections etc in the latter case the attribution is performed by some further statistically based analysis see e g merz et al 2012 viglione et al 2016 and references therein for an overview of the attribution problem and examples however the nature of the time series analyzed above is completely different in fact the true nature of these data is that they are nothing more than artificially generated series designed to be a complete contrast the nera river sequence is a step wise signal superimposed on a sample of independent pseudo random realizations drawn from a gaussian distribution fig 1 i whereas the velino river sequence is a sub set extracted from a longer time series of size 2000 which is a realization of a discrete time fgn with unit variance and hurst parameter h 0 8 fig 1 j this synthetic experiment highlights that even procedures specifically devised to account for the interplay between possible deterministic trends and or change points are not able to discriminate and can easily lead to incorrect conclusions in fact persistence generates local trends and abrupt changes and deterministic changes result in artificial persistence notice that sequences similar to velino time series can easily be extracted by a quick visual inspection of the entire time series since these local trends and step changes are a characteristic of persistent processes since abrupt changes can be seen as a special limit case of monotonic slowly varying trend in the following discussion we generally indicate both types with the term trend unless otherwise specified the null hypothesis is defined as h 0 there is no deterministic trend while the alternative hypothesis as h 1 there is deterministic trend further specifications are given according to the specific context throughout the text 2 2 forgotten questions whose answers are often taken for granted some research questions arise from the example in the previous section 1 what is the origin of slowly varying trends or step changes in hydro meteorological time series are they due to external drivers e g well defined human interventions or are they related to intrinsic persistence or other causes alternatively is measured persistence a spurious effect of trends induced by external forcing or are observed trends spurious effects of persistence or other generating mechanisms 2 can null hypothesis statistical tests nhsts for trends answer the above questions which information can trend nhsts provide 3 under the assumption that trend nhsts can provide information about trends in recorded series can one draw conclusions about nonstationarity thus justifying for instance the use of nonstationary modeling in hydrological frequency analysis 2 3 resetting some beliefs concerning nhst for trends since answers to the above questions require an extensive discussion of arguments often neglected in hydro meteorological applications in this section we firstly summarize the main conclusions and then we present in full detail the reasoning leading to them in the remainder of the paper broadly speaking searching for answers to the above questions reveals critical aspects related to trend nhst that can be classified as empirical methodological and theoretical the first refer to the nature of the data the second to the models used to make inference and the latter to logical foundations and semantics i e the link between symbol concept and referent eco 1976 all these aspects are already known and discussed but spread out in various research areas however they are often overlooked and their impact on results dramatically underestimated in many hydro meteorological studies following the structure of the subsequent sections these arguments can be summarized as follows 1 nhsts have a logically flawed rationale coming from ill posed and theoretically unfounded hybridization of fisher significance tests and neyman pearson hypothesis tests they do not provide the information that scientists need i e the likelihood of h 0 given the data and or physical significance do not allow conclusions about the truth of falsehood of any hypothesis and do not apply to exploratory non randomized studies trend tests share the general problems of nhst procedures such issues are concerned with the inverse probability problem the confusion between substantive and statistical hypotheses and the fact that nhsts are not devised for exploratory studies in fact hydro meteorological data are unique in the sense that every record is the only available realization or trajectory of the underlying process since alternative experiments cannot be performed these observations do not provide the type of independent information that would be obtained by observing the same variables over a period of similar length at another point in time even though hypothesis testing falls in the realm of so called confirmatory analysis its nature is basically dissenting as its outcomes can only be rejection or no rejection and both cases reflect lack of knowledge about the null hypothesis h 0 and the alternative hypothesis h 1 formal acceptance is not a contemplated option moreover statistical significance does not imply physical significance because the former depends on the sample size and almost every test assigns statistical significance to physically negligible differences for very large samples see sections 3 1 2 hydro meteorological data are commonly characterized by spatial and temporal dependence this property can greatly help to interpret and account for many features of hydro meteorological records such as apparently unexpected variability dependence is usually incorporated into the null hypothesis h 0 in order to compare the assumption h 1 of deterministic trend with a more realistic h 0 relaxing the assumption of independence nevertheless dependence can be strongly underestimated due to the limited extent and uniqueness of the hydro meteorological data which should therefore be carefully taken into account for example this study highlights that even more refined statistical techniques accounting for dependence can be not enough in fact we show that the nature quantity and quality of some annual summary statistics are not sufficient to infer the dependence and thus the variability resulting from the entire daily process see sections 3 2 and 6 3 trend tests are widely used to assess the effect of known external forcings e g land cover change on hydro meteorological records e g flow peaks in order to explore inhomogeneity or trends or nonstationarity e g mccuen 2003 such procedures often result in circular reasoning because if we assume that the forcing process is changing according to some deterministic function of time and thus it is nonstationary and it affects in some way a target process of interest e g flood intensity or frequency then we already know that the target process is nonstationary in these cases we are interested in the size of the effects and not in the presence absence of generating mechanism which is already known see section 3 3 4 the outcome of trend nhsts cannot support and justify the use of nonstationary models as a deterministic trend is a systematic change reflecting a time dependent process the mathematical rule describing the evolution of this change should be established by deductive reasoning a priori see e g poppick et al 2017 or assumed as a working hypothesis but cannot be inferred solely from the data without external information because without attribution new data might easily change the nature and shape of the supposed trend therefore trends cannot result for instance from fitting arbitrary parametric curves or applying smoothing filters to observed records despite the possible goodness of fit these pseudo trends might yield completely unreliable predictions this lack of reliability reveals the actual nature of such data driven trends i e that they refer to the time series and not to the underlying process and thus are affected by sampling uncertainty and can change as additional data become available luke et al 2017 serinaldi and kilsby 2015 therefore even though nonstationary modeling is legitimate every step should be approached with great care in order to be logically and scientifically correct bearing in mind the underlying assumptions of procedures methods and models used in each stage of the analysis beside possible ill posed selection of nonstationary models yielding unreliable predictions overlooking theoretical assumptions generates misconceptions such as the incorrect belief of the existence of temporally varying return periods and corresponding return levels and their confusion with time varying probabilities of exceedance and quantiles whereby the mathematical definitions of return period yield unique and comparable values in stationary and nonstationary contexts cooley 2013 olsen et al 1998 salas and obeysekera 2014 serinaldi 2015 serinaldi and kilsby 2015 volpi et al 2015 see sections 3 3 and 4 2 5 another consequence of the limited extent and uniqueness of the hydro meteorological data is that one needs to make a number of implicit but strong assumptions in order to treat these records as outcomes of deterministic stochastic or some mixed processes in this respect stationarity and ergodicity play a key role in statistical inference ergodic theory deals with the relationship between statistical averages and sample averages which is a central problem in the estimation of statistical parameters in terms of real data for example empirical summary statistics e g moments are informative only under the assumption that the process is stationary and ergodic for example even if the sample mean of an observed time series can always be estimated and does not change irrespective of stationary or nonstationary assumptions in the first case it is assumed to be representative of the process thanks to ergodicity while in the latter it is not if one does not account for the source of nonstationarity this means that other realizations of the same nonstationary process can have completely different sample averages none of which can give insight into the actual population mean of the process if any therefore assuming nonstationarity requires great care in order to understand what we can really infer from data under lack of ergodicity without supporting the nonstationary choice with deductive top down arguments identifying the mechanism generating the time dependent behavior of the process the modeling procedure reduces to a mechanistic numerical exercise attempting to minimize some performance criterion with the aim to follow local patterns of fitting data sets as mentioned above this approach yields models that reveal the weakness of their derivation and justification when predictions are compared with new future observations in validation data sets see sections 4 1 and 4 2 6 nonstationarity is a very stringent assumption as it implies that one or more characteristics of the distribution of a system depend on time by a deterministic function dt as the term deterministic implies being free of uncertainty nonstationarity cannot be claimed from the data only without an attribution identifying the source of the deterministic dependence on time therefore koutsoyiannis and montanari 2015 noted that because it explains in deterministic terms part of the variability a nonstationary description is associated with reduced uncertainty hence unjustified or inappropriate claim of nonstationarity results in underestimation of variability uncertainty and risk here uncertainty does not refer to specific parametrization but to the existence and overall behavior of time dependent deterministic processes for example the existence and general evolution of seasonal behavior is deduced from arguments independent from data i e planetary dynamics while its parametrization varies for each specific data set excluding spurious local trends characterizing stationary stochastic processes trends of interest in hydro meteorology are those related to mechanisms generating departures from the so called natural variability which is implicitly assumed to be stationary such trends are therefore a form of nonstationarity which implies the existence of a deterministic function of time dt requiring detection and attribution by combining deductive reasoning which supports and justifies the existence of dt and inductive inference which provides preliminary knowledge and quantication parametrization of dt the definition of deterministic trend has direct practical consequences see sections 4 3 and 4 4 a the commonly used approach of comparing nested models with time varying and constant parameters by using some performance criterion is not sufficient to infer nonstationarity if dt does not result from deductive reasoning but results from simple fitting procedures general poor performance in prediction confirms the weakness of such a bottom up procedure serinaldi and kilsby 2015 b replacing the dependence on time i e dt with dependence on teleconnection indices or other environmental variables showing clear stochastic behavior does not make models nonstationary but simply doubly stochastic stationary this replacement makes models nonstationary only if such auxiliary environmental variables are themselves nonstationary and thus time dependent according to a well defined function dt this is particularly important for a correct application and interpretation of frequency analysis based on generalized linear models glms generalized additive models gams or similar 7 trend nhsts suffer logical flaws and some of them are also incorrect or incorrectly applied for example the still widely applied so called trend free prewhitening tfpw yue et al 2002 was shown to be theoretically flawed serinaldi and kilsby 2016a as its original version does not address the variance inflation related to dependence which can be even exacerbated this explains the contradicting results reported in the literature concerning the outcome of this test compared with alternative procedures the correctness of applied tests or methodology in general should not be taken for granted and a preliminary check of their performance under h 0 controlled conditions should be performed by simulation before their application especially if the methodology was not developed by statisticians see section 5 the choice between stationary and nonstationary depends on a stringent process of attribution supported by deductive arguments which come before and go beyond statistical inference techniques see section 6 3 the non logic of trend hypothesis tests what they cannot say about trends and nonstationarity 3 1 the consequences of a difficult birth nhsts logical flaws and misinterpretations in several fields of applied science nhsts have been widely discussed and criticized for a long time cohen 1994 gill 1999 johnson 1999 levine et al 2008 beninger et al 2012 ellison et al 2014 nuzzo 2014 briggs 2016 greenland et al 2016 wasserstein and lazar 2016 and references therein but to our knowledge the problems concerning nhsts received little attention in hydrological sciences mcbride et al 1993 nicholls 2001 clarke 2010 nhst is a synthesis of the fisher test of significance developed as a general approach to scientific inference and the neyman pearson hypothesis test designed for applied decision making and quality control levine et al 2008 these methods are conceptually different and imply different interpretations of their outcomes neyman and pearson believed they had made fisher s theory of significance testing more complete and consistent whereas fisher never perceived the emerging neyman pearson theory as correcting and improving his own work on tests of significance gigerenzer et al 1989 pp 98 and 102 a heated controversy followed and although the debate continues among statisticians it was silently resolved in the cookbooks written in the 1940s to the 1960s largely by non statisticians to teach students in the social sciences the rules of statistics gigerenzer et al 1989 p 106 the result was a so called hybrid system i e nhst beninger et al 2012 merging fisher s easy to calculate p value into neyman and pearson s reassuringly rigorous rule based system nuzzo 2014 overlooking the great differences in conceptual interpretation this seemed perfectly acceptable to statistics end users partly because often the same formulas were used and the same numerical results obtained gigerenzer et al 1989 p 106 this has led to an enormous confusion about for instance the meaning of a significance level coining the well known expression the null hypothesis is rejected at the α level which occurs neither in fisher nor in the writings of neyman and pearson moreover the neglect of controversial issues and alternative theories and the anonymous presentation of an apparently monolithic body of statistical techniques often turned the hybrid theory into a mechanical ritual even though fisher and neyman pearson had all warned against drawing inferences from tests without judgment gigerenzer et al 1989 p 107 and 209 this historical digression confirms how damaging a mechanistic approach can be through overlooking subtle but fundamental theoretical concepts the differences between fisher and neyman pearson systems highlight their incompatibility and the problems affecting the nhst synthesis with fisher significance testing no explicit alternative hypothesis h 1 to the null h 0 is identified and the p value that results from the model and the data is evaluated as the strength of the evidence for the research hypothesis therefore there is no notion of power of test nor of accepting alternative hypothesis h 1 in the final interpretation conversely neyman pearson tests identify complementary hypotheses h 0 and h 1 in which rejection of one implies acceptance of the other and this rejection is based on a predetermined significance level α neyman pearson hypothesis test defines the significance level α a priori as a function of the test i e before even looking at the data whereas fisher s test of significance defines the significance level afterwards as a function of the data the nhst synthesis pretends to select α a priori but actually using a posteriori p values to evaluate the strength of the evidence this allows inclusion of the alternative hypothesis but removes the search for a more powerful test gill 1999 the power of a test is actually a problematic issue in hybrid nhst as it is most often undefined the sampling distributions of both h 0 and h 1 are specified in neyman pearson theory and an effect size or point prediction must be specified for h 1 in order for the concept of power to be meaningful and for defining the sample size required to obtain the required power conversely in hybrid nhst h 1 is simply specified to be not h 0 and vice versa e g h 0 there is no deterministic trend and h 1 there is deterministic trend i e h 0 and h 1 are written such that they are mutually exclusive and exhaustive levine et al 2008 moreover one of the nhst hypotheses is always labeled as the null hypothesis as in the fisher test whereas fisher intended the null hypothesis simply as something to be nullified or falsified in agreement with and influenced by the contemporary 1935 karl popper s logic of scientific discovery nhst partially uses the neyman pearson decision process except that failing to reject the null hypothesis is treated as a modest support for the null hypothesis gill 1999 leaving aside problems related to some abuses and misinterpretations that can be partially corrected the hybrid nhst suffers some logical flaws that cannot be overcome 1 converse inequality argument or inverse probability problem p values do not and cannot assess the strength of evidence supporting a hypothesis or model in fact a p value is simply the probability of obtaining the result data or evidence d if h 0 were true p d h 0 while the researcher is interested in the probability of the null hypothesis p h 0 or the probability of the null hypothesis given the data p h 0 d of course in general p h 0 d p d h 0 and they are related by the bayes theorem p h 0 d p d h 0 p h 0 p d interpreting p values as p h 0 d rather than p d h 0 corresponds to switching for instance the statements 1 most people who face a firing squad die from bullet wounds and 2 most people who die from bullet wounds have received them from a firing squad beninger et al 2012 the flawed logic of nhst is as follows i if h 0 is true then the data are highly likely to follow an expected pattern ii the data do not follow the expected pattern iii therefore h 0 is highly unlikely this can translate to statements such as i if a person is an american then it is highly unlikely she he is a member of congress ii the person is a member of congress iii therefore it is highly unlikely she he is an american in other words a low p value i e p congress american does not imply a low p american congress pollard and richardson 1987 gill 1999 thus p value says nothing about the truth or otherwise of h 0 or h 1 or the strength of evidence for or against either one in this respect neyman and pearson were very clear as far as a particular hypothesis is concerned no test based on the objective theory of probability can by itself provide any valuable evidence of the truth or falsehood of that hypothesis neyman and pearson 1933 2 substantive theories vs statistical hypotheses in hybrid nhst the statistical null hypothesis and the statistical alternative hypothesis are written such that they are mutually exclusive and collectively exhaustive therefore if we accept the incorrect assumption that one could reject h 0 on the basis of a small p value then h 1 is inferred to be probably true since no other alternatives besides h 0 and h 1 are logically possible levine et al 2008 however h 1 can result from multiple and conflicting substantive theories for example local step changes in fig 1 a and b can result from fluctuations of a persistent process or the superposition of uncorrelated random noise and a deterministic stepwise signal accepting a substantive theory on the basis of results concerning a statistical hypothesis relies on the formal fallacy of affirming the consequent i e if p then q q therefore p which is the form of all scientific inference aimed at supporting a theory by verifying its observational consequences statistical hypotheses are numerical consequences of the substantive theories not their semantic equivalents meehl 1997 it should be noted that fisher did not distinguish between substantive hypotheses and statistical hypotheses gigerenzer et al 1989 p 97 however the p value was intended simply as an informal way to judge whether evidence is worthy of a second look nuzzo 2014 and rejecting h 0 does not mean a categorical adoption of the belief that it is false in fact according to fisher in learning by experience conclusions are always provisional and in the nature of progress reports interpreting and embodying the evidence so far accrued fisher 1935 p 25 on the other hand neyman and pearson introduced their hypothesis test as a rule of behavior to make decisions accounting for possible consequences without hoping to know whether each separate hypothesis is true or false neyman and pearson 1933 in other words both fisher and neyman and pearson were well aware of the fallacy of affirming the consequent and the impossibility for inductive inference to make conclusions about the truth or falsehood of a scientific hypothesis statistical considerations alone cannot lead to a decision 3 classic nhst does not apply to exploratory studies most research studies can be generally classified as either experimental or observational flueck and brown 1993 the major distinction is that the former requires the ability of the scientist to control the principal inputs in order to assess the effects on the outputs therefore studies of trends in hydro meteorological variables can be classified as observational because there is no scope for controlling the inputs e g the researcher cannot control the amount of rainfall thus making such studies more difficult to plan and analyze than experimental ones both experimental and observational studies usually have three stages denoted as preliminary exploratory and confirmatory even if the third stage can or should actually aim to falsify disprove the scientific hypothesis according to the so called modus tollens of deductive inference i e if p then q no q therefore no p meehl 1997 leaving aside the preliminary stage concerning general insights into questions about the research topic e g which measurements are useful and can be made amount of available or collectable data in the study period etc exploratory studies aim to define claims about foreseen or unforeseen relations on the basis of a plausible conceptual model i e a researcher s description of the process of interest and appropriate scientific evidence whereas confirmatory studies are specifically defined processes focused on replicating or disproving a result while minimizing sampling and non sampling errors flueck and brown 1993 with small probability that results can come from causes different from the tested theory exploratory studies are flexible in their research of evidence e g variables to be included but this flexibility should not be confused with a superficial treatment of the data and methods focusing on data analyses can rely on randomized or non randomized samples nhst requires randomized samples as it involves three steps often overlooked but fundamental i the choice of the probabilities of occurrence α and β of type i and type ii errors not only the significance level α ii random selection of only n samples from the designed population whereby n is related to the sampling distribution of the test statistic α and β in order to guarantee the desired test s significance and power and iii the test must be performed only once all these steps should be performed before collecting data therefore logical flaws apart nhst yields valid results only if these steps are followed thus justifying the definition of design based inference when the above steps do not apply nhst is out of context because of lack of a priori basis in the case of research related to acc detection for instance most detection studies apply nhst to a sample of data and determine whether to reject the null hypothesis of zero trend in the atmospheric variable under consideration nicholls 2001 these studies typically use all the available records and these data are far from being randomly selected samples with size fulfilling the requirements in terms of α and β prosdocimi et al 2014 moreover hydro meteorological observations usually exhibit serial and spatial correlation and other properties that can be accounted for but make the outcomes further uncertain based on the above remarks it follows that such studies fall in the non randomized exploratory family thus excluding confirmatory tools such as nhst assuming that this is a logically coherent procedure and requiring in turn the use of split samples or future data subsets to provide confirmatory disproving information flueck and brown 1993 moreover in the exploratory stage one is really not interested in finding a statistically significant effect or trend which can always emerge by increasing the sample size but in physically significant effects assuming that one overlooks these aspects how should the outcome of nhsts be interpreted rejection of h 0 does not necessarily imply the acceptance of h 1 as the discrepancy of the observations from the conditions corresponding to h 0 can actually result from factors not included in the formulation of h 0 e g larger variability due to lack of independence and different from h 1 it is also less legitimate to accept substantive hypotheses owing to the formal logic fallacy of affirming the consequent on the other hand if h 0 is not rejected then this does not mean that it can be concluded that h 0 is true but only that experimental evidence does not support the rejection of the null hypothesis unfortunately the intricacy of such reasoning is once again a result of the hybrid nature of nhst in fact fisher intended significance tests as tools for screening situations worthy of deeper study without h 1 while neyman pearson hypothesis tests were proposed as rules of action implicitly accounting for the consequences quantified a priori by α and β of choosing between two competing alternatives therefore even overlooking logical flaws trend nhsts can only reveal possible changes which are not compatible with random fluctuations corresponding to very specific reference processes e g independent and identically distributed iid random variables thus requiring further investigation we can then extend to general trend nhsts what busuioc and von storch 1996 recommended for pettitt test trend change tests should be used not as tests but as mere tools for preliminary screening small large values of the test statistics should be taken as indications for possible upward or downward changes such changes should be accepted as physically meaningful if they can be related with a predictable process based on theoretical models e g logistic models describing population growth under limited resources and or well identified physical dynamics justifying causality e g dam building river training etc 3 2 hidden dependence the limits of short time series and the role of reference models once clarified what conclusions can not be drawn from trend nhsts and in which context we can better discuss the role of persistence in trend detection the example in section 2 1 shows that the underestimation of persistence plays a key role and should be accounted for the estimation of hurst parameter involved in pettitt tests adapted for fgn yields h values of 0 5 and 0 66 for the nera river and velino river respectively however while h 0 5 is consistent with the fact that the nera river data are actually independent the value h 0 66 underestimates the actual value 0 8 even though the estimator is corrected for the bias by the method described in appendix a this confirms that model identification under scarce observations i e short time series is a difficult statistical task subject to large uncertainty and bias koutsoyiannis and montanari 2007 have already investigated this aspect showing that very long time series thousands of observations are required to correctly recognize fgn therefore underestimation of persistence is an aspect that should not be overlooked when using whatever trend nhst involving a correction procedure for this property note that the underestimation of persistence might lead to consider data approximately independent and thus applying standard tests with no corrections this choice can inflate the number of detected significant deterministic trends one should also account for the underestimation of variance which is another well known phenomenon related to the persistence of some stochastic processes e g koutsoyiannis 2011 tyralis and koutsoyiannis 2011 koutsoyiannis and montanari 2015 arising from the fact that the process stays in a given subset of the state space for several time steps thus requiring much time to explore the entire state space for example even though the fgn time series in fig 1 j has theoretical unitary variance its 100 size subsets have an average variance equal to 0 9 note that the larger uncertainty related to persistence should not be confused with the assumption of a deterministic temporal change in the pdf specifically the second moment of a random process evidently from historical observations to future analysis period milly et al 2015 see section 4 for further details in other words persistence inflates the overall variance which is larger than that corresponding to the independent case of course as for persistence estimating the variance from short time series can yield substantial underestimation with similar consequences on the outcome of trend nhsts i e inflated number of detected deterministic trends dependence is introduced in trend nhsts to build a more realistic h 0 relaxing the assumption of independence in the iid model whereas deterministic trends relax the hypothesis of identical distribution in the iid model in the h 1 side since long term patterns in finite samples can result from be effects of both persistence and deterministic changes in distribution in trend nhsts we attempt to compare two hypotheses that can produce comparable effects knowing a priori that they can thus why is dependence considered a null condition while deterministic changes in distribution are assumed to produce an effect the difference between the two schemes is that the deterministic trends require attribution whereas persistence is compatible with pure stochastic processes implicitly assuming that persistence provides a realistic description of natural systems as mentioned above nhsts cannot tell us which model is the most credible and they cannot be used for such exploratory studies but only in a confirmatory disproving stage by using independent data and a well specified model reproducing properties that are unlikely to be reproduced by other competitors therefore in absence of physical theory both options persistence and deterministic changes are legitimate but the main issue concerns their ability to describe variations in the wider population this is usually only achievable when there are additional sources of data against which each model can be judged 3 3 distinguishing processes and time series a matter of attribution often trend nhst is the first step to infer systematic changes of the studied process over time and thus its nonstationarity eventually justifying the adoption of nonstationary models however this procedure is logically flawed and the opposite should be done exploratory analysis should suggest a set of theories models these models should be used to reproduce challenging properties of the observed data and then confirmatory disproving analysis in terms of prediction should be applied a successful model theory can provisionally be retained until disproved by further applications on new data the common inversion of reasoning is partly related to the confusion between processes and time series the problem of contaminated data series with trends and seasonal effects has been a matter of common experience for hydrologists the traditional way of dealing with such an issue is to produce a new time series the output of a certain filter or adjusting procedure which represents in some sense an estimate of what the real series would be if the contaminating effect were absent according to jaynes 2003 p 536 then choice of the best physically realizable filter is a difficult and basically indeterminate problem fortunately intuition has been able to invent filters good enough to be usable if one knows in advance what kind of contamination will occur when a data set is filtered according to incorrect assumptions detrending may introduce spurious artifacts that distort the information that statistics and probability theory could have extracted from the raw data so caution is advisable especially with refined filters giving a false sense of reliability whereby this can come only from reasoned judgment hence testing trends on finite and short time series can easily be inconclusive and or misleading because of the intrinsic difficulty if not impossibility of detecting nonstationarity of a process solely from data without exogenous information as is discussed later leaving aside the logical arguments discussed above let us suppose that a dam was built along a river thus influencing its regime according to the dam operation rules if we know a priori the existence of the dam we do not need to perform a trend analysis because we already know that the flow regime has been changed by dam construction we can study how the dam impacted on specific characteristics of the flow regime i e the effect size if this information is not already included in dam design specifications on the other hand if we do not have a priori information on the dam existence trend nhst can only tell us that some source of discrepancy from pure randomness is present however this does not allow one to infer nonstationarity of the underlying process without additional information identifying a clear causality rule in fact as shown in sections 2 1 3 1 and 3 2 multiple factors can generate such discrepancy in finite time series and trend nhst does not allow one to draw conclusions on the substantive causes in these circumstances we should propose a set of theories based on plausible reasoning develop suitable models and compare their prediction performance with independent observations however these models will be credible only if they incorporate rules describing the dynamics of the process e g dam s effects thus making its evolution predictable i e river flow will follow a given regime until the dam operates therefore without clear attribution via exogenous information trend nhst can only provide a generic indication that further investigation is required according to the rationale of fisher and neyman pearson original methodologies in this respect such attribution cannot be vague or based on some kind of statistical analysis affected by its own uncertainty because what is needed is not some sort of statistical correlation but a substantive causal physical relationship that should be general and valid beyond the period of the observed records therefore even sophisticated regression models e g glms gams etc do not fulfill these requirements as they fall in the class of analog models flueck and brown 1993 for which extrapolation is not advisable cooley 2013 and easily leads to physically inconsistent predictions serinaldi and kilsby 2015 luke et al 2017 nonstationarity requires the postulation of a law of temporal evolution of the process and this law should be based upon substantive hypotheses in order to be general and valid for prediction of still unobserved data poppick et al 2017 using the example of the dam glms fitted on the data can incorporate time dependent terms but these data driven regression laws do not say anything about the dam operation rules and their effect and their extrapolation in time is not supported by any reasoned judgment about the causes of the observed patterns are they real or spurious how will they evolve on the other hand additional information on the dam existence and operation and its mathematical formalization can justify the introduction of nonstationary models e g ayalew et al 2017 thus nonstationarity and corresponding modeling strategies are allowed only if we make a priori assumptions about the processes and the causes of nonstationarity are clearly identified and formalized via deductive reasoning about e g the effects of a dam on the river regime nonstationarity cannot result from inductive inference from data only as the observed patterns can be the effect of various unknown causes persistence nonlinearity nonstationarity etc which cannot be discriminated in exploratory studies or misusing questionable confirmatory tools it should be noted that these remarks are well known in climatology hasselmann 1997 for instance but seem to be overlooked in many hydro meteorological studies relying almost exclusively on trend testing to draw conclusions indeed according to mitchell et al 2001 p 700 detection is the process of demonstrating that an observed change is significantly different in a statistical sense than can be explained by natural internal variability however the detection of a change in climate does not necessarily imply that its causes are understood from a practical perspective attribution of observed climate change to a given combination of human activity and natural influences requires another approach this involves statistical analysis and the careful assessment of multiple lines of evidence to demonstrate within a pre specified margin of error that the observed changes are unlikely to be due entirely to internal variability consistent with the estimated responses to the given combination of anthropogenic and natural forcing and not consistent with alternative physically plausible explanations of recent climate change that exclude important elements of the given combination of forcings detection ruling out that observed changes are only an instance of internal variability is thus one component of the more complex and demanding process of attribution these recommendations are fully general and not restricted to the problem of acc detection and attribution they highlight the importance of defining the magnitude of internal variability space time covariance and dependence structure hasselmann 1993 1997 poppick et al 2017 which is a challenging task as discussed in section 3 2 and further in section 6 as well as the need of jointly using deductive and inductive methods and excluding other physically reasonable explanations before arriving at a clear attribution 4 voces significant res mediantibus conceptis 1 1 signs correspond to objects through interpretants eco 1976 missing interpretant generates a hiatus between sign and object 4 1 stationarity in the previous sections we discussed some theoretical and practical limits of trend testing including the problems posed by the intrinsic nature of the hydro meteorological data the misuse of confirmatory tools in exploratory analyses and the influence of dependence as well as the basis and logic of nhsts and their interpretation all these aspects raise serious questions regarding the actual information and conclusions that can be drawn from trend nhsts and exploratory studies relying on them however to better understand why nonstationarity cannot be inferred from this analysis we need to go back to basic concepts and definitions as the title of this section suggests we put the emphasis on the meaning of common terms in the context of trend testing as the semantics of those terms is often confusing in the literature although there is ongoing debate about this issue koutsoyiannis and montanari 2015 milly et al 2015 we believe it is worth recalling and expanding it where necessary because of its importance for correctly setting up and interpreting data analysis unless stated otherwise throughout this paper we use upper case letters for random variables and lower case letters for values parameters or constants referring to koutsoyiannis and montanari 2015 for a rigorous presentation of the formal definitions of stationarity and nonstationarity we recall that a stationary stochastic process in the sense of khinchin is a set of random variables xt depending on the parameter t t such that the distributions of the systems x t 1 x t 2 x t n and x t 1 τ x t 2 τ x t n τ coincide for any n t 1 t 2 tn and τ this definition has been translated in various ways such as stationarity means that hydrological variables fluctuate randomly within an unchanging envelope of variability bayazit 2015 or stationarity or temporally stable probability distribution functions pdf rice et al 2015 even though such definitions are acceptable in informal discussions the actual meaning of khinchin s definition merits some further discussion to avoid misunderstandings assuming that t denotes time khinchin s definition means that the n dimensional joint distribution of n random variables is identical independently of their location along the time axis however since the mathematical definition refers specifically to random variables xt the sets of realizations x t 1 x t 2 x t n and x t 1 τ x t 2 τ x t n τ are unavoidably different by the way mandelbrot 1982 p 384 emphasized that when mathematicians first encountered stationary processes having extremely erratic samples they marvelled that the notion of stationarity could encompass such wealth of unexpected behavior unfortunately this is a kind of behavior that many practitioners insist is not stationary so the actual problem in inductive exploratory analysis of trends is to understand if such fluctuations are consistent with a unique n dimensional joint distribution or they come from different distributions given the uniqueness of observed hydro meteorological records and the well known uncertainty in making inference from very short time series the most common case in hydro meteorology the problem is challenging in order to make the problem easier to treat one often focuses only on the first moments actually up to second order because of the high uncertainty in estimating higher order moments lombardo et al 2014 thus introducing the concept of weak stationarity where khinchin s definition reduces to identity of population means e xi population variances var xi and population covariances over n time steps independently of their location along the time axis 4 2 ergodicity we cannot emphasize too strongly the clear distinction between the population properties that are deduced logically from the theory and the sample properties that are determined empirically from observations sample estimates are derived from time averages whose relationship to the statistical parameters of the theoretical process must be established only in the form of ergodicity in order to highlight the importance of ergodicity it is worth recalling that a stochastic process x t ζ is a collection of time functions depending on the outcome ζ of an experiment l or a collection of random variables over a parametric support t time space etc papoulis 1991 pp 285 286 fig 2 helps to clarify these definitions for a fixed outcome ζ i e a fixed coordinate along the event space axis x t ζ is a single time function or trajectory describing a sample or realization of the given process one of these realizations can be the sequence of the truly observed records while the others are possible outcomes that did not occurred but could on the other hand if t is fixed as t and ζ varies then x t ζ is a random variable describing the state of the given process at time t if both t and ζ are fixed x t ζ is a number i e the specific value assumed by the process at the specific time in real world applications we often know only a single finite size sample of x t ζ e g a sequence of daily stream flow values between year t and t τ so a central problem is to infer the parameters of the underlying stochastic process from such sample this is possible only if the process is ergodic meaning that the time average of any integrable function g x t ζ equals the true ensemble expectation e g x t ζ as the size of the available sample tends to infinity papoulis 1991 pp 427 428 clearly this is not possible if e g x t ζ depends on t therefore we must assume a stationary underlying process focusing on the mean of the process ergodicity implies that 1 lim τ x τ t ζ obs lim τ 1 τ s t t τ x s ζ obs e x t ζ x f x d x more generally ergodicity allows the use of the empirical probability density function f obs or f i f j etc of a sample of x t ζ as an estimate of the probability density functions f x i f x j of the random variables x ti ζ x tj ζ describing the state of the process at time ti tj if a process is nonergodic then statistical inference from data is not allowed because sample averages variances and distributions are not representative of their population counterparts moreover we should consider that stationarity is a necessary but not sufficient condition to ergodicity of stochastic processes koutsoyiannis and montanari 2015 therefore a nonstationary process is nonergodic thus estimates from data are not representative of the process when we claim nonstationarity in fact nonstationarity implies that the population distributions f x i f x j and f x k in fig 2 are not identical to each other and thus f obs is no longer representative of any of them in fact the histogram is assumed at least implicitly to be an estimate of the marginal stationary distribution note that second order stationarity or one of the other forms of weak stationarity is not sufficient strong stationarity at least must exist for the special case of n 1 the number of points not the dimension of the space if the random function is not stationary at least to this extent then the histogram is not an estimate of a distribution related in a known way to the random function myers 1989 similarly if f x i f x j and f x k have different moments e g mean and or variance changing in time the empirical sample moments are not representative of any of these local population moments this can be surprising in light of the extensive use of nonstationary models such as glms and gams with time dependent parameters in hydro meteorological frequency analysis for instance of course the problem is not about these models by themselves but their misuse in fact these models actually fit local trends observed in the period of record that can be due to multiple factors anthropogenic activity persistence nonlinearity etc which in turn cannot be identified by data alone moreover they are often justified owing to the better performance compared with iid versions which are not challenging competitors and overlooking more realistic options that can yield patterns close to the observed ones nonstationary models are legitimate when there is additional information on the cause of time dependent behavior the identification of the cause of local trends is paramount for extrapolation in order to be sure that the nonstationary effects continue beyond the period of record without this additional information prediction based on pure data driven time dependent patterns easily yields physically inconsistent results when extrapolating into the future or past luke et al 2017 serinaldi and kilsby 2015 villarini et al 2009b actually low reliability and high uncertainty in predictions of evolution of nonstationary patterns might be an index of the little evidence supporting the nonstationary choice serinaldi and kilsby 2015 4 3 nonstationarity at this point a definition of nonstationarity is required in order to illustrate nonstationary processes koutsoyiannis and montanari 2015 considered the decomposition x t d t e t where e t is a stationary stochastic process and dt is a deterministic function of time dt d t milly et al 2015 proposed a similar representation namely x t a t b t e t where at and bt are deterministic and e t is stochastic we slightly generalize the decomposition suggested by koutsoyiannis and montanari 2015 as follows 2 g x t d t g e t where g is a generic operator some examples are given below according to koutsoyiannis and montanari 2015 a deterministic function of time is precisely known and perfectly predictable meaning that a system input corresponds to a single system response contrasting stochastic dynamics where a single input could result in multiple outputs since every inductive analysis based on observed data is always affected by uncertainty a deterministic function cannot be inferred from the data only but it should result from deductive reasoning and be validated by data which were not used in the model construction notice that this definition is consistent with the idea which became famous as laplace s demon i e the classical definition of strict physical determinism according to laplace the demon is indeed a superhuman intelligence that could know and model all details of the universe to infinite precision for such an intellect nothing would be uncertain and the future just like the past would be present before its eyes laplace 1814 in other words if all changes in nature are expressible through mathematical functions of time complete and precise knowledge of the initial conditions at a certain moment allows one to perfectly predict the conditions at all later and earlier times however predictability and determinism are also easy to disentangle in practical applications as shown in many studies on deterministic chaos the approximate character of scientific knowledge renders dynamical systems unpredictable even though they are fully governed by underlying deterministic laws sivakumar 2016 yevjevich 1974 actually determinism is a matter of spatio temporal scales in fact even if the process i e vector function representing the deterministic dynamics is perfectly known perfect predictability beyond a given temporal horizon can completely be lost owing to very small uncertainty in initial conditions berliner 1992 koutsoyiannis 2010 lorenz 1963 that is magnified by possible nonlinearity leading to emergence of deterministic chaotic behavior e g von storch and zwiers 2003 pp 1 2 while chaos theory explains unpredictability of a deterministic system in practice laplace s demon assumes perfect predictability under ideal complete and precise knowledge of the system including initial conditions therefore the two ideas are compatible with each other as already recognized by laplace himself who wrote all these efforts in the search for truth tend to lead it human mind back continually to the vast intelligence which we have just mentioned but from which it will always remain infinitely removed laplace 1814 the decomposition in eq 2 is a rather general description of nonstationarity in fact if g is the identity operator eq 2 describes the simplest decomposition of the process itself x t d t e t if g is the expectation we have e x t d t e e t referring to a process that is nonstationary in mean first moment when g denotes the variance then var x t d t var e t describing a process whose variance depends on a deterministic function of time such as the brownian motion bm with var xt t in other words nonstationarity implies that the distribution of the system x t 1 x t 2 x t n depends on time by a deterministic function which can however refer to one or more characteristics of the distribution e g mean variance higher order moments autocorrelation etc for bm as well as fractional bm and autoregressive integrated moving average processes arima nonstationarity refers to deterministic functions of statistical moments and inference is performed on the increment process y t x t 1 x t because taking the first difference yields a stationary process by removing the dependence of the moments on time whatever is the specific form of nonstationarity in mean variance etc statistical inference e g calculation of moments only applies to a corresponding stationary process obtained by suitable transformations e g differencing under the assumption that the original process has a specific form of nonstationarity however without an attribution identifying the source of the deterministic dependence on time nonstationarity cannot be claimed from the data only claiming nonstationarity i e the existence of a deterministic function of time for some statistical properties of xt on the basis of the outcome of nhsts such as mk pettitt or unit root nhsts such as dickey and fuller 1979 and kwiatkowski phillips schmidt shin kwiatkowski et al 1992 is simply not possible owing to the problems discussed in section 3 and the definitions given above 4 4 what is a trend we argue that some widespread misconceptions concerning trend detection and attribution result from a lack of definition of trend thus attempting a reasonable definition and opening the debate about this point seems useful first of all the concept of trend should be related to nonstationarity this seems a reasonable assumption as we are not interested in local but long term patterns spanning for instance the entire series of records and resulting from e g persistence of underlying stationary processes in this case the stochastic nature of persistent quasi periodic or monotonic patterns make their magnitude onset and end unpredictable and a pure stochastic stationary description is sufficient thus we should conclude that a trend of true interest which is the focus of the largest part of hydro meteorological literature on the topic should strictly be related to a form of nonstationarity if so recalling khinchin s definition of stationarity and the discussion in section 4 3 a stochastic process has a trend if one or more of its statistical properties vary in time according to a deterministic law of time dt the function dt can be monotonic non monotonic periodic and can refer to the average variance or other statistical properties of the process see section 4 3 in this respect there is no difference for instance among i trends defined as smooth long range changes in some moment parameter of the time varying distribution as used e g in glm gam modeling ii stochastic trends captured by random walk type processes i e bm fbm arfima etc or iii trend described by physical equations in processes involving stochastic differential equations or different types of physical statistical models in all of these cases for the parameters of glms gams for the variance of bm and fbm processes and for the specific characteristics described by the physical part of physical statistical models there is a function dt accounting for deterministic time dependent evolution of the system concerning dt a misconception widespread in glm gam based hydrological frequency analysis is the belief that replacing t with other variables makes the model nonstationary this is true only if such variables are themselves nonstationary and thus time dependent according to a well defined function replacing t with teleconnection indices e g north atlantic oscillation index or other variables showing clear stochastic behavior simply yields stationary doubly stochastic models if a trend is identified with the existence of a deterministic function of time dt and thus with nonstationarity remarks on detection and attribution provided in section 4 3 apply and in particular we should exclude the possibility to make inference from data only for example seasonal cycles are forms of dt resulting from a fundamental deductive reasoning exogenous information concerning planetary dynamics and corresponding mathematical theory this deductive step allows for the choice of inference tools and then a quantitative evaluation of seasonal components from data for each specific case seasonal cycles are predictable with negligible uncertainty as we are almost sure of the occurrence of equinoxes and solstices in the next decades or even centuries unless the occurrence of unpredictable catastrophic events acting at the solar system or galaxy scale here lack of uncertainty refers to the existence of the seasonal dt and not to its contingent parametrization which varies in each specific case under these premises introducing other forms of trend should rely on the same approach merging deductive and inductive reasoning for example a commonly used approach of comparing nested models with time varying and constant parameters by using some performance criterion is not enough if the time dependent function dt does not result from deductive reasoning but results from simple fitting procedures in these cases higher parametrized time dependent models might simply account for local apparent trends giving very poor performance in prediction owing to lack of identification of substantial causes acting beyond the period of record serinaldi and kilsby 2015 trends of interest in hydro meteorology are often monotonic or low frequency type spanning over the period of record possibly related to anthropogenic activity we argue that frequency is actually the main difference between seasonal trends and other forms of deterministic time dependent trends seasonal trends look like monotonic or half wave trends if the focus is on sub annual time windows because the process is not fully developed at such a time scale and one cannot retrieve signal components with frequencies lower than half period of record as described by the nyquist shannon sampling theorem therefore even the use of effective filtering methods such as singular spectrum analysis wavelet analysis or empirical mode decomposition cannot help in trend identification if we are not able to arrive at a clear attribution of the patterns described by the lowest frequency components resulting from filtering being a form of nonstationarity or its expression trends are allowed only if they rely on exogenous knowledge involving theoretical arguments or empirically well defined processes in agreement with mccuen 2003 without such an additional information trends cannot be inferred from the data only because they refer to the underlying process x t 1 x t 2 x t n and not to its realizations x t 1 x t 2 x t n i e observed time series in agreement with the starting point of chandler and scott 2011 without attribution to unique substantive cause and exclusion of any other possible cause exploratory tools filtering or model selection can only highlight local low frequency persistent fluctuations but they do not allow one to make conclusions on stationarity or nonstationarity this is in agreement with von storch and zwiers 2003 p 9 who stated trends in the large scale state of the climate system may reflect systematic forcing changes of the climate system such as variations in the earths orbit or increased co2 concentration in the atmosphere or low frequency internally generated variability of the climate system the latter may be deceptive because low frequency variability on short time series may be mistakenly interpreted as trends however if the length of such time series is increased a metamorphosis of the former trend takes place and it becomes apparent that the trend is a part of the natural variation of the system these remarks are general and hold true not only for climate but also in every context exhibiting large uncertainty about the number type and effect of the acting physical processes based on the discussion above we can then provide an unambiguous definition of trend as time dependent deterministic and therefore predictable change dt of the properties of a process xt where the term deterministic implies prediction variance equal to zero one to one relationship this definition highlights that trends and nonstationarity refer to the underlying process and attempting to infer nonstationarity requires both detection and attribution based on a combination of deductive reasoning which supports and justifies the existence of a time dependent deterministic function i e trends and nonstationarity and inductive reasoning which provides i preliminary knowledge by exploratory data analysis and ii quantification parametrization of dt by confirmatory disproving analysis and modeling we stress that prediction variance equal to zero does not refer to the specific parametrization of dt but its existence and its overall evolution for example the parametrization of seasonal trends components obviously varies even for the same process observed at different locations but the existence of the seasonal cycle and its effects in terms of alternation of wet dry and cold warm conditions along the calendar year are predictable with almost no uncertainty other forms of trend nonstationarity are allowed only if they are supported by the same kind of deductive and inductive arguments 5 trend and abrupt change tests an overview of overlooked critical aspects in practical applications in this section we discuss some problems concerning the practical application of two nhsts for trends i e the mann kendall mk mann 1945 kendall 1970 and pettitt tests pettitt 1979 the following remarks apply under the assumption that we disregard logical arguments in sections 3 and 4 still apply these tests for exploratory analysis and use them to make conclusions on trends nonstationarity among many available statistical testing procedures devised for assessing the significance of a change e g kundzewicz and robson 2004 the mk and pettitt tests are widely used rank based nonparametric tests to check the presence and timing of slowly varying and abrupt changes in the mean or median of hydro meteorological variables such as rainfall runoff and temperature e g villarini et al 2009a 2011b ferguson and villarini 2012 rougé et al 2013 tramblay et al 2013 guerreiro et al 2014 sagarika et al 2014 rice et al 2015 2016 mallakpour and villarini 2015 2016 ahn and palmer 2016 archfield et al 2016 do et al 2017 among others the popularity of these tests is related to their simplicity in terms of implementation their robustness against outliers or measurement errors as they are rank based and the availability of exact or asymptotic distributions of their test statistics under null hypothesis h 0 no trend no change and independence i e iid conditions moreover being based on the so called mann whitney statistic the pettitt test and the mk test are formally related to each other thus highlighting that distinguishing between slowly varying and abrupt changes is only a matter of scale and time of evolution of the change rougé et al 2013 serinaldi and kilsby 2016a even though these tests are used to check changes in the mean or median the first myth to dispel is that mk and pettitt tests are devised to detect changes in the central tendency summary statistics they actually check a wider hypothesis called stochastic ordering given a sequence of random variables x i i 1 n with cumulative distribution functions fi mk checks against the alternative hypothesis h 1 f i x f i k x for every i every x and every k 0 mann 1945 while pettitt checks against h 1 f b x f a x where f b f a is the common distribution of the m n m 1 random variables before after the change point pettitt 1979 therefore even though these hypotheses are commonly restricted to a shift in the location parameter these tests are sensitive to all possible conditions resulting in stochastic ordering serinaldi and kilsby 2016a based on the above belief when a change point or a monotonic trend is detected often the magnitude of the abrupt change is quantified by the difference in mean or median between the sub series before and after the change while the trend by the so called sen s slope e g khaliq et al 2009b rice et al 2015 2016 nilsen et al 2016 tananaev et al 2016 in light of the actual nature of mk and pettitt tests such quantification is not justified especially for mk in fact even if we assume that mk only checks for changes in mean median it refers to monotonic changes that can be linear or nonlinear stepwise s shaped or abrupt as a limiting case resulting from more general changes in the overall shape of the distribution of course the choice of linear trends reflects practical requirements indeed assuming more complicated higher parametrized patterns can be unjustified for usually short time series because of the additional uncertainty affecting the estimation since sen s estimator for the slope of a linear trend is rank based nonparametric it is considered more robust than classical mean square error mse however its nonparametric nature does not make it more coherent with mk outputs than mse estimates of linear trends even though the need of quantifying a possible change is understandable reducing the indication of possible monotonic trends given by mk to that of a linear trend is too restrictive and does not reflect the rationale and outcome of mk test since perfectly linear trends rarely describe realistic evolution patterns of complex hydro meteorological processes even under actual deterministic forcings such a kind of quantification should be at most purely qualitative and possibly avoided in order to provide a correct communication in any case it cannot be considered an actual trend in light of discussion on detection and attribution in section 4 4 of course trend tests can only detect inhomogeneities within the time interval covered by the observed records this also explains why they cannot be used to infer nonstationarity stationarity is a property of the theoretical process xt for t and concerns the identity of population statistical properties for every subset of random variables in every point of the time line while trend tests can only check possible changes in finite and usually short time windows where observed fluctuations might easily be spurious since we cannot extrapolate conclusions beyond the period of records without identifying a deterministic and predictable cause of such inhomogeneities the outcome of trend tests cannot be used to justify the application of nonstationary models for frequency analysis such a usage is inappropriate and might lead to unrealistic predictions serinaldi and kilsby 2015 the previous remarks have important consequences on the procedures used to account for the effects of the temporal correlation the effect of the autocorrelation on tests devised for independent data is a general increase of the rejection rate of the null hypothesis h 0 no trend of the statistical test even if the underlying process is stationary this is due to the information redundancy that makes the effective sample size smaller than the observed size thus implying that the effective variance of the test statistics to be used in the testing procedure under serial dependence is larger than that provided by standard results obtained under the hypothesis of independence e g bayley and hammersley 1946 koutsoyiannis and montanari 2007 this phenomenon is known as variance inflation and has been accounted for using three general approaches the explicit calculation of the inflated variance e g hamed and rao 1998 koutsoyiannis 2003 matalas and sankarasubramanian 2003 yue and wang 2004 hamed 2008 2009b prewhitening procedures e g katz 1988 kulkarni and von storch 1995 von storch 1999 yue et al 2002 yue and wang 2002 bayazit and önöz 2007 hamed 2009b and bootstrap techniques khaliq et al 2009a kundzewicz and robson 2004 referring to khaliq et al 2009b and bayazit 2015 for a review we focus on some aspects that are generally overlooked 1 firstly all tests involving the iid hypothesis should be corrected for the effect of autocorrelation neglecting this aspect might lead to contradictory results further discussed in section 6 3 2 since some procedures involve trend removal e g yue et al 2002 hamed 2008 this is usually supposed to be linear as mentioned above this choice is understandable from a practical point of view but less defensible if it is interpreted as a deterministic evolution of some physical hydro meteorological process linear trends cover a very limited subset of the actual hypothesis tested by mk and pettitt tests as well 3 the procedures proposed in the literature consider corrections based on the autocorrelation values estimated on the data themselves this poses two problems i for short time series autocorrelation is generally underestimated e g koutsoyiannis 2003 koutsoyiannis and montanari 2007 where the bias is larger if the underlying process exhibits long range dependence lrd thus when the correction procedure involves a specific dependence structure often markovian autocorrelation should be adjusted see serinaldi and kilsby 2016a and appendix a and ii it is taken for granted that the dependence structure of the underlying process can be retrieved by the analyzed summary statistics usually annual minima averages maxima etc the point ii is subtle but critical in fact the behavior of summary statistics can be strongly influenced by the nature of the underlying process for example processes with lrd yields maximum values over blocks of observations that tend to cluster in time e g bunde et al 2005 eichner et al 2011 this results in apparent trends in terms of frequency and magnitude if the analysis relies on short series of such maxima even though these summary statistics might easily show no or very weak autocorrelation since this behavior is found in stream flow time series serinaldi and kilsby 2016c we show in the case study that it might have a dramatic effect on trend nhst outcomes 4 in some cases correction procedures are flawed failing to provide any adjustment as an example among others the so called trend free prewhitening tfpw yue et al 2002 was shown to be theoretically flawed serinaldi and kilsby 2016a as its original version does not address the variance inflation problem which can be even exacerbated since it has been widely applied thanks to its relative simplicity results of several analyses reported in the literature should be taken with great care and possibly revised two aspects characterizing several published trend analyses based on nhst need to be mentioned i the correctness of applied tests or methodology in general is almost always taken for granted while a preliminary check of their performance under h 0 controlled conditions should be performed by simulation before their application especially if the tests were not developed by statisticians and result from some empirical reasoning without a necessary mathematical proof as shown for the hybridization of fisher and neyman pearson methods in section 3 ii empirical results are often interpreted without the necessary rigor thus resulting in misleading conclusions confusing artifacts with meaningful results 6 case study in this section we investigate the consequences of the above discussion on data analysis and its interpretation to this aim we use data already analyzed in the literature to show how results and conclusions can remarkably change if we account for logical methodological and practical issues discussed in previous sections note that our analysis is not exactly a study of reproducibility because data and some methods are not precisely equal to those applied in previous studies however the use of mk and pettit is justified for sake of comparison with previous studies and key general results are reproduced and then compared with new findings relying on more realistic null hypotheses 6 1 observational data long term trends in stream flows over the conterminous united states conus have been extensively studied referring to sagarika et al 2014 for a recent review we recall that the past studies focused on various summary statistics and or data sets including peak discharge records barrett and salis 2016 hirsch and ryberg 2012 lins and cohn 2011 mallakpour and villarini 2015 villarini et al 2009a villarini and smith 2010 villarini et al 2011a vogel et al 2011 monthly data kalra et al 2008 lettenmaier et al 1994 and mean daily observations ahn and palmer 2016 lins and slack 1999 mccabe and wolock 2002 rice et al 2016 2015 sagarika et al 2014 the interest for such an area is not only practical but is also related to the great variety of hydrologic regimes conditions across conus as well as the availability of data and metadata which allow for more accurate studies than in other parts of the globe since the trend analysis described below section 6 2 requires both daily data and summary statistics i e maxima or averages on a seasonal and annual basis in this study mean daily flow records are used the data set is extracted from the hydro climatic data network hcdn 2009 lins 2012 which comprises 743 stations maintained by the u s geological survey usgs hcdn 2009 is a subset of the wider usgs gages ii geospatial attributes of gages for evaluating streamflow version ii reference stations providing geospatial data and classifications for 9 322 stream gages hcdn 2009 provides a stream flow data set suitable for analyzing hydrologic variations and trends in a climatic context as it includes quality controlled time series from stations that were screened to exclude sites where human activities or other activities affect the natural flow and with sample size sufficiently large for analysis of patterns in stream flow over time lins 2012 a list of hcdn 2009 stations along with basic attributes can be found at the web site http water usgs gov osw hcdn 2009 while the data set is freely available at http waterdata usgs gov nwis sw this study focuses on 250 stations having continuous and simultaneous observations with no missing values between the water years 1951 and 2011 included i e october 1950 to september 2011 following sagarika et al 2014 the data set comprises only one station on a particular stream within each u s hydrologic unit code huc to reduce spatial bias in the results moreover even though some stations have continuous data spanning longer periods we selected only simultaneous data from 1951 to 2011 to guarantee temporal homogeneity and to allow some remarks on spatial correlation discussed later in section 6 3 for seasonal analysis seasons are defined as autumn october december winter january march spring april june and summer july september 6 2 methodology 6 2 1 testing local significance in this study possible slowly varying trends and abrupt changes of some stream flow properties are analyzed by mk and pettitt tests in four different settings 1 classical versions devised for independent random variables hereinafter they are denoted as standard mk and standard pettitt 2 a corrected and unbiased tfpw tfpwcu version of both tests accounting for first order autoregressive ar 1 dependence i e classic markovian dependence and bias correction for acf underestimation denoted as ar 1 tfpwcu mk and ar 1 tfpwcu pettitt tfpwcu procedure is applied to show that a correct tfpw procedure yields results different from those of the classical setting highlighting that the similarities of results often recognized in the literature are actually artifacts see section 5 the reader is referred to serinaldi and kilsby 2016a for further details 3 a prewhitening version accounting for fgn dependence proposed by hamed 2008 for mk test and adapted by serinaldi and kilsby 2016a for pettitt this version allows one to account for long range dependence lrd and improves the original prewhitening procedure by introducing bias corrected estimates of the hurst parameter h characterizing the fgn acf based on the formulas provided in appendix a these tests are denoted as fgn cpw mk and fgn cpw pettitt where cpw indicates conditional prewhitening meaning that the prewhitening procedure is applied only if h is found significantly different from 0 5 at the 5 significance level these versions are detailed in hamed 2008 and serinaldi and kilsby 2016a 4 the last version is based on monte carlo simulation of daily stream flow sequences in order to check the impact of daily dynamics on the annual seasonal statistics and trend test outcomes this way we introduce a more realistic null scenario in terms of dependence structures that is built by exploiting the whole available information instead of few tens of annual seasonal summary statistics in more detail each daily stream flow time series is deseasonalized following the procedure described by e g serinaldi and kilsby 2016c and serinaldi and kilsby 2016b and residuals are resampled by the iterative amplitude adjusted fourier transformation iaaft method schreiber and schmitz 1996 kugiumtzis 1999 schreiber and schmitz 2000 venema et al 2006a 2006b serinaldi and lombardo 2017 which allows for simulation of surrogate data preserving almost exactly the empirical distribution function and power spectrum acf of the observations iaaft surrogates are stationary franzke 2013 by construction because of randomization of fourier phases combining surrogate residuals and seasonal components yields synthetic daily stream flow time series under the null hypothesis preserving almost exactly both the marginal distribution and correlation structure of the observed ones small discrepancies in marginal distributions do not matter as the used trend tests are rank based therefore summary statistics of interest here averages and maxima on a seasonal and annual basis are extracted and standard mk and pettitt tests are applied the procedure is repeated many times to obtain the sampling distribution function of mk and pettitt test statistics accounting for the dependence properties of the daily process under stationary conditions in other words our new null hypothesis is observed trends in annual seasonal values are consistent with patterns coming from a stationary daily process with given observed marginal distribution and dependence structure 6 2 2 testing field significance when data from multiple stations are analyzed one can ask whether the results imply that there is a significant effect when considering the entire group of stations i e the so called field significance daniel et al 2012 katz and brown 1991 livezey and chen 1983 wilks 1997 2006 this recognizes that when performing multiple tests it is more likely to detect significant changes by chance this probability increases if the data are spatially correlated in this case spatial correlation acts similarly to temporal correlation introducing information redundancy owing to possible similar patterns across spatially correlated sequences referring to khaliq et al 2009b for an overview of methods to treat field significance we recall that they fall in two categories daniel et al 2012 one controls the false discovery rate fdr i e the expected fraction of local null hypothesis rejections that are incorrect benjamini and hochberg 1995 benjamini and yekutieli 2001 and is nearly equivalent to the walker test fisher 1929 katz 2002 wilks 2006 the other relies on counting the number of rejections at local level and then comparing these values with the selected critical values obtained from the empirical distribution of number of rejections resulting from bootstrap procedures preserving approximately spatial or spatio temporal correlation khaliq et al 2009b wilks 1997 daniel et al 2012 highlighted that the choice of method depends on the spatial nature of the studied effect e g trend if it is expected that the effect is widespread local it would be preferable to use the count based fdr approach while a combination of both approaches could be applied if there is no a priori expectation in this study we focus on the walker test because i it is easy to implement and robust to cross correlations khaliq et al 2009b wilks 2006 and ii the counting method requires intensive and different simulation procedures for iaaft based trend tests and the other tests standard ar 1 tfpwcu and fgn cpw we recall that the walker test consists of comparing the smallest of p value corresponding to the test statistics computed on k time series with the critical value p w 1 1 α global 1 k the global null hypothesis h 0 no global trend may be rejected at the a global level α global if the smallest of k independent local p values is less than or equal to p w wilks 2006 the counting method is only applied to check the variability of field significance for the lag 1 acf term ρ 1 and the hurst coefficient h in the series of annual seasonal summary statistics see khaliq et al 2009b p 121 for a detailed description all tests are performed at the 5 local and global significance level 6 3 results 6 3 1 temporal dependence of maximum and mean flows given the influence of autocorrelation on detection of possible trends the dependence structure of annual and seasonal maximum and mean flows are preliminarily investigated owing to the limited sample size of such a type of data only parsimonious models such as ar 1 and fgn are usually considered even though the latter would require very long time series for a reliable inference figs 3 and 4 show the spatial distribution of the sites where ρ 1 and h are found to be locally and globally significant along with the sites where both models are locally significant global significance is assessed at the huc scale of course the number of sites showing possible significant persistence are higher for mean values than for maxima owing to the higher variability of the latter no particular spatial patterns are evident these results are not surprising if we consider the persistence of the underlying flow process and recognize that maxima are values sampled from the daily process while mean values result from averaging all daily data in each season or year nonetheless figs 3 and 4 allow some methodological remarks when we test significance for ρ 1 and h we are implicitly assuming an underlying model ar 1 or fgn as alternative hypothesis h 1 this implies that the estimates should be corrected accordingly for possible bias for example testing ρ 1 under the assumption that the underlying process is fgn requires a bias correction procedure different to that used under the assumption of ar 1 process this aspect is often neglected and ρ 1 is commonly tested using biased estimates yielded by default estimators working under iid assumptions koutsoyiannis 2016 another remark concerns the output of the walker test and counting method for global significance when the two approaches yield different results the walker test tends to identify more areas with significant results according to the nature of the walker test which is sensitive to local effects in some of these cases field significance results from a single locally significant station falling in the huc area especially if the number of stations in that area is small daniel et al 2012 provided some insight into selecting suitable sub regions to assess field significance to avoid bias sub regions should be identified a priori before performing the analysis and domain limitation should be made as a result of some physical insight in this respect hucs are a credible choice however daniel et al 2012 also stress that if some region in a domain is seen to contain a large number of significant stations it is certainly inappropriate to apply the field significance test over just this limited domain without a physically based justification also in this case the clustering of significant trends might be due to the spatial correlation of large scale meteorological variables driving the flow processes in a specific area in other words local clusters in space are the natural effect of spatial correlation as local clusters of high low values in a time series might reflect temporal correlation since it is easy to confuse spatio temporal correlation with deterministic trends these remarks highlight the importance of using clear definitions in order to distinguish between stochastic fluctuations and deterministic changes whose attribution should be based on a priori information and causality 6 3 2 trend analysis of maximum and mean flows results of trend analysis are shown in figs 5 8 according to the aim of this study as for correlation the following remarks focus on methodological aspects in fact the spatial patterns of significant trends and their sign are similar to those published in the literature e g sagarika et al 2014 while their interpretation deserves some remark for example ar 1 tfpwcu mk and fgn cpw mk tests on maxima fig 5 tend to give similar number of rejections which is smaller than that of standard mk this contrasts with results often reported in the literature and confirm that they are related to the ineffectiveness of the original tfpw procedure as a variety of hypotheses has been proposed to explain the disagreement between tfpw and other prewhitening procedures in terms of possible physical causes it is therefore instructive to discover that they are pure speculations and results are simply artifacts another important result is the strong decrease of significant trends obtained by iaaft mk the annual seasonal maxima extracted from stationary series reproducing the observed persistence of the daily sequences show apparent trends that are stronger than those resulting from persistent models directly fitted on annual seasonal maxima thus reducing the evidence for deterministic trends in such summary statistics in other words focusing on annual seasonal maxima might lead to underestimate variability and temporal clustering of high low values similar remarks hold for annual seasonal average values fig 6 it should be noted that the residual clusters of positive trends in the new england north west for summer maximum and mean values figs 5 t and 6 t are coherent with the spatial correlation and climate dynamics of that area kingston et al 2007 this does not mean that the new england rivers have not witnessed a possible increase in the last 60 years however it might be explained in terms of spatial correlation as a shared behavior depending on a common meteorological driver acting in an area characterized by quite a uniform response obviously from a practical point of view such an increase raises management problems whose solutions however change if we assume that these changes are deterministic in the sense specified in section 4 or stochastic in fact in the first case we should identify a predictable evolution law making attribution which is unlikely linear or polynomial and cannot be deduced from the data themselves in the form of some arbitrary smoothing function results for the pettitt test in figs 7 and 8 highlight another aspect often overlooked in the literature and related to the fact that both tests rely on the mann whitney statistic and they are theoretically related to each other rougé et al 2013 this implies that standard mk and pettitt often yield similar results in terms of significant changes in a given direction upward downward even if such results are obviously interpreted in a different manner slowly varying monotonic changes and abrupt changes e g sagarika et al 2014 pathak et al 2016 the link between the two tests also implies that both are sensitive to autocorrelation serinaldi and kilsby 2016a and they should yield coherent results when autocorrelation is accounted for a comparison of figs 5 and 6 with figs 7 and 8 supports this conclusion showing that both tests yield similar spatial patterns in terms of significant upward downward changes in this context distinguishing and interpreting slowly varying and abrupt changes can be secondary as it is simply a matter of scales e g rougé et al 2013 this highlights once again the need for attribution based on exogenous information which is not derived exclusively on purely statistical non causal relationships results for iaaft based tests also show the dramatic decrease of evidence for deterministic changes when fluctuations of seasonal annual averages and maxima are influenced by the entire flow process at daily scale therefore even if the autocorrelation of the observed seasonal annual averages and maxima is properly accounted for in ar 1 tfpwcu and fgn cpw trend tests the above results reveal that it is not sufficient and might strongly underestimate the actual persistence of the underlying processes when this is taken into account apparently strong trends changes might become coherent with the intrinsic variability characterizing stationary but persistent processes recalling the discussion about the natural local clustering of significant results due to spatial correlation and testing multiplicity daniel et al 2012 we studied how the number of significant trends globally changes across the conus for the different types of tests i e the different treatment of the autocorrelation fig 9 summarizes the global number of rejections for all combinations of data and tests standard tests especially pettitt generally yield higher number of rejections for maximum values for mean flows there is not much difference between standard tests and ar 1 tfpwcu and fgn cpw versions in all cases iaaft version yields a dramatic decrease of significant outcomes fig 9 also reports the 95 prediction bands continuous red lines of the number of rejections expected over 250 independent trials i e performed tests prediction limits correspond to the 2 5th and 97 5th percentiles of a binomial distribution with parameters 250 and 0 05 i e the number of trials and the rate of successes the diagrams show that iaaft based tests yield a number of occurrences which is almost always consistent with what is expected when a purely random experiment with 5 of probability of success is performed in some cases the outcome is also close to the expected value 250 0 05 12 however the binomial distribution describes the outcome of independent experiments whereas stream flow time series are spatially correlated especially in some specific areas reacting in a similar way to common large scale meteo climatic dynamics cross correlation can be accounted for by simulation however a fast computation which is very accurate in several cases can be performed by using the beta binomial distribution see appendix b considering the 2 5th and 97 5th percentiles of the beta binomial distribution red dot dashed lines in fig 9 the number of significant outcomes always fall within the prediction bands for iaaft based tests while the rate of rejection for ar 1 tfpwcu and fgn cpw tests is less unexpected than under spatial independence in this respect it is worth recalling that the pairwise spatial correlation terms involved in the beta binomial parametrization refer to the spatial correlation of seasonal annual averages and maxima therefore stronger correlation and over dispersion is expected if the spatial correlation of daily series is taken into account it should also be noted that the estimation of the spatial cross correlation is affected by temporal correlation katz and brown 1991 hamed 2009a 2011 accounting for these aspects results in stronger spatial correlation and further increase of over dispersion this implies wider prediction intervals of the number of significant outcomes and thus even less evidence for global field significance these results confirm the dramatic impact of the spatial correlation on field significance douglas et al 2000 and the double effect of the autocorrelation on local trend detection and estimation of spatial correlation if we also consider that autocorrelation is a non optimal measure of dependence implying systematic underestimation of the actual intensity of persistence as shown above it can be concluded that we often strongly underestimate the actual spatio temporal variability of the processes generating the analyzed data we stress once again that all the above analyses do not allow any conclusion about the actual stochastic or deterministic nature of the observed trends results only tell us that a stochastic stationary representation cannot be excluded and several results reported in the literature simply depend on the choice of an unrealistic stationary option iid as a null hypothesis in other words observed trends are consistent with both a stationary and nonstationary assumptions when we choose a suitable and more realistic stationary benchmark the choice between the two modeling options depends upon a stringent process of attribution supported by additional information and the clear identification of a cause excluding any reasonable alternative explanation this process goes beyond the application of trend tests or detection of statistically significant correlation with other hydro meteorological variables by nhsts which we recall suffer logical flaws and are not devised for exploratory studies 7 discussion and conclusions published trend analysis in hydro meteorology often consists of a superficial application of statistical tools such as nhsts as cookbook recipes this attitude is further spread by the availability of powerful statistical software implementing the state of the art of statistical methodologies developed by statisticians but also questionable procedures developed by practitioners as already highlighted by von storch and zwiers 2003 this approach is particularly dangerous for anyone who is not sufficiently acquainted with the basic concepts of statistics moreover software availability also promotes the tendency to jointly apply combinations of sophisticated techniques often obscure redundant or even contrasting with each other that compound and amplify the problems caused by the indiscriminate use of recipes von storch and zwiers 2003 p 97 since every hydro meteorological record is the only available realization or trajectory of the underlying process this prevents the application of confirmatory analysis because any statement or null hypothesis cannot be contested with a statistical test since independent data are unavailable no statistical test regardless of its power or complexity can overcome this problem because it is not a matter of methodology but of available information the only possible solution is extending this information by additional data going backward i e collecting paleo data sets or forward i e awaiting the availability of new data to test theories in this respect the use of physics based models can partly help e g poppick et al 2017 however even such models can never be fully validated disproved as we do not know if they capture all the important properties of the physical processes and thus the answers given by such models could simply be spurious a rigorous attribution is required to attempt the identification of unique causes and exclusion of any other plausible alternative based on the above discussion the actual meaning interpretation and limits of trend tests should be recovered as every statistical test trend tests can be valuable tools in appropriate contexts while they cannot be an appropriate tool to infer nonstationarity they can at most be used as mere tools for preliminary screening whose outcome should be carefully checked and complemented with exogenous information if a clear physical mechanism related to a predictable evolution of the properties of the process at hand is not identified we cannot make conclusions about the reason of rejection or lack of rejection since multiple factors not included in the null and alternative hypotheses can actually play a role the case study presented in this paper shows the dramatic difference resulting from the use of trend tests involving different dependence structures namely unrealistic independence ar 1 and hk dependence estimated from the target annual summary statistics and empirical dependence of target variables resulting from that of the parent daily process we stress that our discussion and these results do not support stationarity versus nonstationarity dependence is only used as a more realistic and challenging alternative to deterministic trends in order to show that nhsts are actually inconclusive when we compare two options yielding similar observations and a decision concerning the generating mechanism of the studied process and its modeling cannot rely on data only since trend tests are also used as automatic criteria to justify the use of nonstationary models for frequency analysis we discourage such a kind of cookbook recipe usage as it is inappropriate and might lead to unreliable and paradoxical predictions serinaldi and kilsby 2015 of course nonstationary modeling is still legitimate when it is justified by preliminary attribution relying on additional deductive information on the cause of time dependent behavior it should also be noted that this study does not focus on the interpretation of the physical meaning of probability e g frequentist or bayesian approach to data analysis but on the role of inductive and deductive information and reasoning in the scientific inferential procedure following christakos 2011 pp 177 181 the knowledge bases can be classified between two major categories general or core denoted by kb g and specificatory or site specific kb s whereby the former may include scientific theories natural laws phenomenological models cultural relations and long established worldviews while the latter considers different sources of evidence that are tied to the particular local situation and may be not of general validity i e exact and inexact uncertain measurements and records this study shows how a mechanistic application of tests and models involving only kb s is not sufficient to draw conclusions on stationarity or nonstationarity regardless of the complexity or refinement of the analysis tools but seem to be the only source of information used in much literature on the other hand we emphasize the fundamental role of kb g that being based on wisdom of the past seems to be irretrievably lost in the postmodern world christakos 2011 p 179 in this respect how kb g and kb s are blended is a secondary aspect although bayesian framework offers attractive tools to perform a synthesis christakos 2011 pp 375 380 trend tests may be tools for very preliminary screening for example in large scale analyses involving e g large number of time series concerning data quality control where we are interested in detecting time series affected by systematic instrumental errors in these cases we know a priori the mechanism generating nonstationarity i e instrumental malfunction and its possible effects and an unambiguous attribution can be made from the knowledge of the instrument specifics in other cases rejections can be used to identify primary sub sets deserving further investigations for a clear attribution of the origin of the detected inhomogeneities however lack of rejection does not authorize the conclusion that nothing is happening in the remaining subset which should be further analyzed in any case other conclusions in this exploratory context go beyond what the trend tests can tell us acknowledgements fs and cgk were supported by the engineering and physical sciences research council epsrc grant ep k013513 1 flood memory multi event modelling of risk and recovery and willis research network information on hcdn 2009 data used in this study can be found at the web site http water usgs gov osw hcdn 2009 while the data set is freely available at http waterdata usgs gov nwis sw the authors wish to thank three anonymous reviewers for their remarks and constructive criticisms and prof hans von storch helmholtz zentrum geesthacht germany for his useful comments on an earlier version of this paper the analyses were performed in r development core team 2016 appendix a bias correction for the maximum likelihood estimates of h tests involving prewhitening based on fgn correlation structure require the estimation of the hurst parameter h it is well known that h is difficult to estimate especially for short time series koutsoyiannis and montanari 2007 following hamed 2008 for fgn cpw and fgn unconditional prewhitening fgn upw versions of mk and pettitt tests serinaldi and kilsby 2016a h is estimated by the maximum likelihood ml method mcleod and hipel 1978 mcleod et al 2007 which was proven to be more accurate tyralis and koutsoyiannis 2011 than other estimators relying on graphical diagnostic plots see e g serinaldi 2010 nonetheless residual bias affect ml estimates as well even though we showed that the direct assessment of persistence on summary statistics such as seasonal annual averages and maxima might lead to underestimation of persistence in any case it is worth adjusting the ml estimation bias in order to reduce the problem bias correction was defined based on an extensive monte carlo simulation using 10 000 random samples drawn from a fgn process for each combination of h between 0 5 and 0 99 by steps equal to 0 01 and sample size n ranging from 20 to 250 by steps equal to 5 the left side panels on fig 10 show a map and two projections of the surface describing the bias of the ml estimator as a function of h and n the correction involves two stages first the dependence of bias of h and n is adjusted by a rational polynomial of the first order and second the residual dependence on h middle column of panels in fig 10 is removed by a four order polynomial the right side panels in fig 10 show that procedure yields a final residual bias lower than 0 01 i e one order of magnitude lower than the original bias for all combinations of h and n the resulting bias correction formulas are a 1 h unb 0 826 3 889 h i 10 94 h i 2 10 91 h i 3 4 06 h i 4 where a 2 h i 3 40 n 92 674 271 609 n 77 280 98 470 n 156 590 96 862 n 240 783 h ml in which h ml is the original ml estimate and h unb is the corrected output appendix b beta binomial distribution the beta binomial bb distribution is a compound distribution resulting for the ordinary binomial distribution f k n k p k 1 p n k where p 0 1 represents the constant probability of a success in n trials when p is assumed to be no longer constant but fluctuating according to a beta distribution function f p p α 1 1 p β 1 b α β where b denotes beta function and α and β are two positive shape parameters the bb density function can be written as skellam 1948 b 1 f k n k b k α n k β b α β letting π α α β the mean and variance of beta binomial can be written as ahn and chen 1995 b 2 e k n π and b 3 var k n π 1 π 1 n 1 ρ bb where ρ bb 1 α β 1 is known as the intra class or intra cluster correlation being positive by definition ρ bb gives rise to over dispersion as it inflates the variance n π 1 π of the original binomial distribution with constant p on the other hand ρ bb does not affect the expected value which is identical for both bb and standard binomial for correlated experiments ρ bb j k ρ jk n n 1 where ρ jk denotes the pairwise correlation between experiment site j and k in the context of this study ρ bb is therefore the average cross correlation between the time series recorded across the conus area which is 0 04 this is the value used to compute the prediction limits reported in fig 9 it is worth noting the impact of ρ bb despite its apparently small value 
890,the detection and attribution of long term patterns in hydrological time series have been important research topics for decades a significant portion of the literature regards such patterns as deterministic components or trends even though the complexity of hydrological systems does not allow easy deterministic explanations and attributions consequently trend estimation techniques have been developed to make and justify statements about tendencies in the historical data which are often used to predict future events testing trend hypothesis on observed time series is widespread in the hydro meteorological literature mainly due to the interest in detecting consequences of human activities on the hydrological cycle this analysis usually relies on the application of some null hypothesis significance tests nhsts for slowly varying and or abrupt changes such as mann kendall pettitt or similar to summary statistics of hydrological time series e g annual averages maxima minima etc however the reliability of this application has seldom been explored in detail this paper discusses misuse misinterpretation and logical flaws of nhst for trends in the analysis of hydrological data from three different points of view historic logical semantic epistemological and practical based on a review of nhst rationale and basic statistical definitions of stationarity nonstationarity and ergodicity we show that even if the empirical estimation of trends in hydrological time series is always feasible from a numerical point of view it is uninformative and does not allow the inference of nonstationarity without assuming a priori additional information on the underlying stochastic process according to deductive reasoning this prevents the use of trend nhst outcomes to support nonstationary frequency analysis and modeling we also show that the correlation structures characterizing hydrological time series might easily be underestimated further compromising the attempt to draw conclusions about trends spanning the period of records moreover even though adjusting procedures accounting for correlation have been developed some of them are insufficient or are applied only to some tests while some others are theoretically flawed but still widely applied in particular using 250 unimpacted stream flow time series across the conterminous united states conus we show that the test results can dramatically change if the sequences of annual values are reproduced starting from daily stream flow records whose larger sizes enable a more reliable assessment of the correlation structures keywords trend hypothesis tests nonstationarity ergodicity hypothesis test interpretation trend attribution stream flow trends in the united states faced with a sample of unknown origin many applied statisticians working in economics meteorology and the like hasten to decompose it into a trend and an oscillation and added periodic terms they assume implicitly that the addends are attributable to distinct generating mechanisms and are statistically independent this last implicit assumption is quite unwarranted except when the sample is generated by brownian motion b b mandelbrot the fractal geometry of nature p 352 1982 1 introduction due to the complexity of hydrological systems their analysis and modeling heavily rely on historical records as theoretical reasoning and deduction are often inadequate this analysis is even more problematic when we depart from the hypothesis of stationarity to embrace that of nonstationarity even though the two notions of stationarity and nonstationarity should apply to models and not to the real world processes themselves see section 4 below considerable literature assumes that the observed time series generated by the real world seldom appear to be stationary but exhibit more complicated nonstationary behavior in many cases conclusions on nonstationarity are based on the outcome of trend tests applied to finite size time series covering relatively short periods of record a change of paradigm from stationary to nonstationary can be claimed to account for human activities producing predictable changes such as land use and land cover changes and water resources exploitation or more complex but less predictable phenomena such as the worldwide hydrologic change ascribed to anthropogenic climate change acc milly et al 2015 in this respect in the last three decades a huge number of studies have investigated possible human driven changes in the form of slowly varying trends or abrupt changes in time series of hydrological variables across different regions of the world broadly speaking and taking for granted unavoidable differences the aim of these studies has been to understand if these changes are detectable what is their pattern and ultimately to infer nonstationarity thus promoting the implementation of nonstationary models to support new design and planning strategies e g ouarda and el adlouni 2011 rootzén and katz 2013 cheng et al 2014 among many others therefore we believe there exists a need for careful inspection of the basic concepts of null hypothesis statistical tests nhsts for trends and their application to hydrological problems following serinaldi and kilsby 2015 this paper is an attempt to meet this need in fact the purpose of our work is neither to review the state of the art of the research related to trend analysis nor to give examples of the problems discussed thereto rather we summarize and attempt to shed some light on the reasons for contradictory results encountered in the literature and discuss widespread practices that can easily be identified in many studies therefore the conceptual perspective of this study should be seen as a guideline in agreement with the general but scientifically based and widely applicable statement by mandelbrot in the opening motto of this paper on the other hand we attempt to confute a certain mechanistic approach often characterizing the literature on the topic we highlight that conceptual arguments and mathematical definitions are necessary to provide practical advice to identify trends to interpret results and to avoid misleading usage and conclusions the paper is structured as follows by using a simple example section 2 introduces the discussion and research questions and summarizes our conclusions in order to provide the reader with a clear outline of what will follow section 3 reviews the role of trend testing and some problems related to historical derivation epistemological reasons and detection and attribution of changes under temporal persistence then in section 4 we discuss the importance of clear terminology corresponding to well defined concepts to avoid misunderstandings relying on different interpretation of the same terms section 5 gives an overview of the properties of some commonly used trend tests namely mann kendall mk and pettitt in section 6 we analyze 250 unimpacted stream flow time series across the conterminous united states spanning the period 1950 2011 discussion and final remarks are given in section 7 2 nhst for trends overview of key ideas 2 1 setting the scene with a simple example we start our discussion by a simple example of typical trend testing exercise familiar to practitioners as we want to highlight the basic concepts behind trend testing procedures fig 1 a and b shows the average annual discharge of two nearby rivers that we will call the nera river and velino river referring to the following discussion for an in depth description of these data both time series ranging from 1916 to 2015 show an apparent change point around the years 1974 1975 as well as statistically significant and similar autocorrelation functions fig 1 c and d the kendall correlation coefficient between the two time series is τ k 0 32 since we do not know if the autocorrelation is a consequence of a possible deterministic change of regime or the effect of the dependence structure we use statistical tests accounting for the latter therefore we apply both the classic pettitt tests and four additional versions accounting for possible first order markov autocorrelation structure and fractional gaussian noise fgn also known as hurst kolmogorov process serinaldi and kilsby 2016a following the common interpretation of trend tests the tests unanimously lead to the conclusion that a possible deterministic change around 1974 1975 at the 5 significance level after splitting the series into two sub series before and after the change point we find that their autocorrelation is not significant fig 1 e h therefore we next apply standard pettitt and mk tests to the two sub series for both rivers villarini et al 2009a since no significant trend or change point was found in the sub series we can conclude that autocorrelation is reasonably the effect of an abrupt change occurred around 1974 1975 based on these results the common approach attempts to explain such changes by some anthropogenic activities including some more easily recognizable i e river training water abstraction dam construction etc and some less i e acc climate teleconnections etc in the latter case the attribution is performed by some further statistically based analysis see e g merz et al 2012 viglione et al 2016 and references therein for an overview of the attribution problem and examples however the nature of the time series analyzed above is completely different in fact the true nature of these data is that they are nothing more than artificially generated series designed to be a complete contrast the nera river sequence is a step wise signal superimposed on a sample of independent pseudo random realizations drawn from a gaussian distribution fig 1 i whereas the velino river sequence is a sub set extracted from a longer time series of size 2000 which is a realization of a discrete time fgn with unit variance and hurst parameter h 0 8 fig 1 j this synthetic experiment highlights that even procedures specifically devised to account for the interplay between possible deterministic trends and or change points are not able to discriminate and can easily lead to incorrect conclusions in fact persistence generates local trends and abrupt changes and deterministic changes result in artificial persistence notice that sequences similar to velino time series can easily be extracted by a quick visual inspection of the entire time series since these local trends and step changes are a characteristic of persistent processes since abrupt changes can be seen as a special limit case of monotonic slowly varying trend in the following discussion we generally indicate both types with the term trend unless otherwise specified the null hypothesis is defined as h 0 there is no deterministic trend while the alternative hypothesis as h 1 there is deterministic trend further specifications are given according to the specific context throughout the text 2 2 forgotten questions whose answers are often taken for granted some research questions arise from the example in the previous section 1 what is the origin of slowly varying trends or step changes in hydro meteorological time series are they due to external drivers e g well defined human interventions or are they related to intrinsic persistence or other causes alternatively is measured persistence a spurious effect of trends induced by external forcing or are observed trends spurious effects of persistence or other generating mechanisms 2 can null hypothesis statistical tests nhsts for trends answer the above questions which information can trend nhsts provide 3 under the assumption that trend nhsts can provide information about trends in recorded series can one draw conclusions about nonstationarity thus justifying for instance the use of nonstationary modeling in hydrological frequency analysis 2 3 resetting some beliefs concerning nhst for trends since answers to the above questions require an extensive discussion of arguments often neglected in hydro meteorological applications in this section we firstly summarize the main conclusions and then we present in full detail the reasoning leading to them in the remainder of the paper broadly speaking searching for answers to the above questions reveals critical aspects related to trend nhst that can be classified as empirical methodological and theoretical the first refer to the nature of the data the second to the models used to make inference and the latter to logical foundations and semantics i e the link between symbol concept and referent eco 1976 all these aspects are already known and discussed but spread out in various research areas however they are often overlooked and their impact on results dramatically underestimated in many hydro meteorological studies following the structure of the subsequent sections these arguments can be summarized as follows 1 nhsts have a logically flawed rationale coming from ill posed and theoretically unfounded hybridization of fisher significance tests and neyman pearson hypothesis tests they do not provide the information that scientists need i e the likelihood of h 0 given the data and or physical significance do not allow conclusions about the truth of falsehood of any hypothesis and do not apply to exploratory non randomized studies trend tests share the general problems of nhst procedures such issues are concerned with the inverse probability problem the confusion between substantive and statistical hypotheses and the fact that nhsts are not devised for exploratory studies in fact hydro meteorological data are unique in the sense that every record is the only available realization or trajectory of the underlying process since alternative experiments cannot be performed these observations do not provide the type of independent information that would be obtained by observing the same variables over a period of similar length at another point in time even though hypothesis testing falls in the realm of so called confirmatory analysis its nature is basically dissenting as its outcomes can only be rejection or no rejection and both cases reflect lack of knowledge about the null hypothesis h 0 and the alternative hypothesis h 1 formal acceptance is not a contemplated option moreover statistical significance does not imply physical significance because the former depends on the sample size and almost every test assigns statistical significance to physically negligible differences for very large samples see sections 3 1 2 hydro meteorological data are commonly characterized by spatial and temporal dependence this property can greatly help to interpret and account for many features of hydro meteorological records such as apparently unexpected variability dependence is usually incorporated into the null hypothesis h 0 in order to compare the assumption h 1 of deterministic trend with a more realistic h 0 relaxing the assumption of independence nevertheless dependence can be strongly underestimated due to the limited extent and uniqueness of the hydro meteorological data which should therefore be carefully taken into account for example this study highlights that even more refined statistical techniques accounting for dependence can be not enough in fact we show that the nature quantity and quality of some annual summary statistics are not sufficient to infer the dependence and thus the variability resulting from the entire daily process see sections 3 2 and 6 3 trend tests are widely used to assess the effect of known external forcings e g land cover change on hydro meteorological records e g flow peaks in order to explore inhomogeneity or trends or nonstationarity e g mccuen 2003 such procedures often result in circular reasoning because if we assume that the forcing process is changing according to some deterministic function of time and thus it is nonstationary and it affects in some way a target process of interest e g flood intensity or frequency then we already know that the target process is nonstationary in these cases we are interested in the size of the effects and not in the presence absence of generating mechanism which is already known see section 3 3 4 the outcome of trend nhsts cannot support and justify the use of nonstationary models as a deterministic trend is a systematic change reflecting a time dependent process the mathematical rule describing the evolution of this change should be established by deductive reasoning a priori see e g poppick et al 2017 or assumed as a working hypothesis but cannot be inferred solely from the data without external information because without attribution new data might easily change the nature and shape of the supposed trend therefore trends cannot result for instance from fitting arbitrary parametric curves or applying smoothing filters to observed records despite the possible goodness of fit these pseudo trends might yield completely unreliable predictions this lack of reliability reveals the actual nature of such data driven trends i e that they refer to the time series and not to the underlying process and thus are affected by sampling uncertainty and can change as additional data become available luke et al 2017 serinaldi and kilsby 2015 therefore even though nonstationary modeling is legitimate every step should be approached with great care in order to be logically and scientifically correct bearing in mind the underlying assumptions of procedures methods and models used in each stage of the analysis beside possible ill posed selection of nonstationary models yielding unreliable predictions overlooking theoretical assumptions generates misconceptions such as the incorrect belief of the existence of temporally varying return periods and corresponding return levels and their confusion with time varying probabilities of exceedance and quantiles whereby the mathematical definitions of return period yield unique and comparable values in stationary and nonstationary contexts cooley 2013 olsen et al 1998 salas and obeysekera 2014 serinaldi 2015 serinaldi and kilsby 2015 volpi et al 2015 see sections 3 3 and 4 2 5 another consequence of the limited extent and uniqueness of the hydro meteorological data is that one needs to make a number of implicit but strong assumptions in order to treat these records as outcomes of deterministic stochastic or some mixed processes in this respect stationarity and ergodicity play a key role in statistical inference ergodic theory deals with the relationship between statistical averages and sample averages which is a central problem in the estimation of statistical parameters in terms of real data for example empirical summary statistics e g moments are informative only under the assumption that the process is stationary and ergodic for example even if the sample mean of an observed time series can always be estimated and does not change irrespective of stationary or nonstationary assumptions in the first case it is assumed to be representative of the process thanks to ergodicity while in the latter it is not if one does not account for the source of nonstationarity this means that other realizations of the same nonstationary process can have completely different sample averages none of which can give insight into the actual population mean of the process if any therefore assuming nonstationarity requires great care in order to understand what we can really infer from data under lack of ergodicity without supporting the nonstationary choice with deductive top down arguments identifying the mechanism generating the time dependent behavior of the process the modeling procedure reduces to a mechanistic numerical exercise attempting to minimize some performance criterion with the aim to follow local patterns of fitting data sets as mentioned above this approach yields models that reveal the weakness of their derivation and justification when predictions are compared with new future observations in validation data sets see sections 4 1 and 4 2 6 nonstationarity is a very stringent assumption as it implies that one or more characteristics of the distribution of a system depend on time by a deterministic function dt as the term deterministic implies being free of uncertainty nonstationarity cannot be claimed from the data only without an attribution identifying the source of the deterministic dependence on time therefore koutsoyiannis and montanari 2015 noted that because it explains in deterministic terms part of the variability a nonstationary description is associated with reduced uncertainty hence unjustified or inappropriate claim of nonstationarity results in underestimation of variability uncertainty and risk here uncertainty does not refer to specific parametrization but to the existence and overall behavior of time dependent deterministic processes for example the existence and general evolution of seasonal behavior is deduced from arguments independent from data i e planetary dynamics while its parametrization varies for each specific data set excluding spurious local trends characterizing stationary stochastic processes trends of interest in hydro meteorology are those related to mechanisms generating departures from the so called natural variability which is implicitly assumed to be stationary such trends are therefore a form of nonstationarity which implies the existence of a deterministic function of time dt requiring detection and attribution by combining deductive reasoning which supports and justifies the existence of dt and inductive inference which provides preliminary knowledge and quantication parametrization of dt the definition of deterministic trend has direct practical consequences see sections 4 3 and 4 4 a the commonly used approach of comparing nested models with time varying and constant parameters by using some performance criterion is not sufficient to infer nonstationarity if dt does not result from deductive reasoning but results from simple fitting procedures general poor performance in prediction confirms the weakness of such a bottom up procedure serinaldi and kilsby 2015 b replacing the dependence on time i e dt with dependence on teleconnection indices or other environmental variables showing clear stochastic behavior does not make models nonstationary but simply doubly stochastic stationary this replacement makes models nonstationary only if such auxiliary environmental variables are themselves nonstationary and thus time dependent according to a well defined function dt this is particularly important for a correct application and interpretation of frequency analysis based on generalized linear models glms generalized additive models gams or similar 7 trend nhsts suffer logical flaws and some of them are also incorrect or incorrectly applied for example the still widely applied so called trend free prewhitening tfpw yue et al 2002 was shown to be theoretically flawed serinaldi and kilsby 2016a as its original version does not address the variance inflation related to dependence which can be even exacerbated this explains the contradicting results reported in the literature concerning the outcome of this test compared with alternative procedures the correctness of applied tests or methodology in general should not be taken for granted and a preliminary check of their performance under h 0 controlled conditions should be performed by simulation before their application especially if the methodology was not developed by statisticians see section 5 the choice between stationary and nonstationary depends on a stringent process of attribution supported by deductive arguments which come before and go beyond statistical inference techniques see section 6 3 the non logic of trend hypothesis tests what they cannot say about trends and nonstationarity 3 1 the consequences of a difficult birth nhsts logical flaws and misinterpretations in several fields of applied science nhsts have been widely discussed and criticized for a long time cohen 1994 gill 1999 johnson 1999 levine et al 2008 beninger et al 2012 ellison et al 2014 nuzzo 2014 briggs 2016 greenland et al 2016 wasserstein and lazar 2016 and references therein but to our knowledge the problems concerning nhsts received little attention in hydrological sciences mcbride et al 1993 nicholls 2001 clarke 2010 nhst is a synthesis of the fisher test of significance developed as a general approach to scientific inference and the neyman pearson hypothesis test designed for applied decision making and quality control levine et al 2008 these methods are conceptually different and imply different interpretations of their outcomes neyman and pearson believed they had made fisher s theory of significance testing more complete and consistent whereas fisher never perceived the emerging neyman pearson theory as correcting and improving his own work on tests of significance gigerenzer et al 1989 pp 98 and 102 a heated controversy followed and although the debate continues among statisticians it was silently resolved in the cookbooks written in the 1940s to the 1960s largely by non statisticians to teach students in the social sciences the rules of statistics gigerenzer et al 1989 p 106 the result was a so called hybrid system i e nhst beninger et al 2012 merging fisher s easy to calculate p value into neyman and pearson s reassuringly rigorous rule based system nuzzo 2014 overlooking the great differences in conceptual interpretation this seemed perfectly acceptable to statistics end users partly because often the same formulas were used and the same numerical results obtained gigerenzer et al 1989 p 106 this has led to an enormous confusion about for instance the meaning of a significance level coining the well known expression the null hypothesis is rejected at the α level which occurs neither in fisher nor in the writings of neyman and pearson moreover the neglect of controversial issues and alternative theories and the anonymous presentation of an apparently monolithic body of statistical techniques often turned the hybrid theory into a mechanical ritual even though fisher and neyman pearson had all warned against drawing inferences from tests without judgment gigerenzer et al 1989 p 107 and 209 this historical digression confirms how damaging a mechanistic approach can be through overlooking subtle but fundamental theoretical concepts the differences between fisher and neyman pearson systems highlight their incompatibility and the problems affecting the nhst synthesis with fisher significance testing no explicit alternative hypothesis h 1 to the null h 0 is identified and the p value that results from the model and the data is evaluated as the strength of the evidence for the research hypothesis therefore there is no notion of power of test nor of accepting alternative hypothesis h 1 in the final interpretation conversely neyman pearson tests identify complementary hypotheses h 0 and h 1 in which rejection of one implies acceptance of the other and this rejection is based on a predetermined significance level α neyman pearson hypothesis test defines the significance level α a priori as a function of the test i e before even looking at the data whereas fisher s test of significance defines the significance level afterwards as a function of the data the nhst synthesis pretends to select α a priori but actually using a posteriori p values to evaluate the strength of the evidence this allows inclusion of the alternative hypothesis but removes the search for a more powerful test gill 1999 the power of a test is actually a problematic issue in hybrid nhst as it is most often undefined the sampling distributions of both h 0 and h 1 are specified in neyman pearson theory and an effect size or point prediction must be specified for h 1 in order for the concept of power to be meaningful and for defining the sample size required to obtain the required power conversely in hybrid nhst h 1 is simply specified to be not h 0 and vice versa e g h 0 there is no deterministic trend and h 1 there is deterministic trend i e h 0 and h 1 are written such that they are mutually exclusive and exhaustive levine et al 2008 moreover one of the nhst hypotheses is always labeled as the null hypothesis as in the fisher test whereas fisher intended the null hypothesis simply as something to be nullified or falsified in agreement with and influenced by the contemporary 1935 karl popper s logic of scientific discovery nhst partially uses the neyman pearson decision process except that failing to reject the null hypothesis is treated as a modest support for the null hypothesis gill 1999 leaving aside problems related to some abuses and misinterpretations that can be partially corrected the hybrid nhst suffers some logical flaws that cannot be overcome 1 converse inequality argument or inverse probability problem p values do not and cannot assess the strength of evidence supporting a hypothesis or model in fact a p value is simply the probability of obtaining the result data or evidence d if h 0 were true p d h 0 while the researcher is interested in the probability of the null hypothesis p h 0 or the probability of the null hypothesis given the data p h 0 d of course in general p h 0 d p d h 0 and they are related by the bayes theorem p h 0 d p d h 0 p h 0 p d interpreting p values as p h 0 d rather than p d h 0 corresponds to switching for instance the statements 1 most people who face a firing squad die from bullet wounds and 2 most people who die from bullet wounds have received them from a firing squad beninger et al 2012 the flawed logic of nhst is as follows i if h 0 is true then the data are highly likely to follow an expected pattern ii the data do not follow the expected pattern iii therefore h 0 is highly unlikely this can translate to statements such as i if a person is an american then it is highly unlikely she he is a member of congress ii the person is a member of congress iii therefore it is highly unlikely she he is an american in other words a low p value i e p congress american does not imply a low p american congress pollard and richardson 1987 gill 1999 thus p value says nothing about the truth or otherwise of h 0 or h 1 or the strength of evidence for or against either one in this respect neyman and pearson were very clear as far as a particular hypothesis is concerned no test based on the objective theory of probability can by itself provide any valuable evidence of the truth or falsehood of that hypothesis neyman and pearson 1933 2 substantive theories vs statistical hypotheses in hybrid nhst the statistical null hypothesis and the statistical alternative hypothesis are written such that they are mutually exclusive and collectively exhaustive therefore if we accept the incorrect assumption that one could reject h 0 on the basis of a small p value then h 1 is inferred to be probably true since no other alternatives besides h 0 and h 1 are logically possible levine et al 2008 however h 1 can result from multiple and conflicting substantive theories for example local step changes in fig 1 a and b can result from fluctuations of a persistent process or the superposition of uncorrelated random noise and a deterministic stepwise signal accepting a substantive theory on the basis of results concerning a statistical hypothesis relies on the formal fallacy of affirming the consequent i e if p then q q therefore p which is the form of all scientific inference aimed at supporting a theory by verifying its observational consequences statistical hypotheses are numerical consequences of the substantive theories not their semantic equivalents meehl 1997 it should be noted that fisher did not distinguish between substantive hypotheses and statistical hypotheses gigerenzer et al 1989 p 97 however the p value was intended simply as an informal way to judge whether evidence is worthy of a second look nuzzo 2014 and rejecting h 0 does not mean a categorical adoption of the belief that it is false in fact according to fisher in learning by experience conclusions are always provisional and in the nature of progress reports interpreting and embodying the evidence so far accrued fisher 1935 p 25 on the other hand neyman and pearson introduced their hypothesis test as a rule of behavior to make decisions accounting for possible consequences without hoping to know whether each separate hypothesis is true or false neyman and pearson 1933 in other words both fisher and neyman and pearson were well aware of the fallacy of affirming the consequent and the impossibility for inductive inference to make conclusions about the truth or falsehood of a scientific hypothesis statistical considerations alone cannot lead to a decision 3 classic nhst does not apply to exploratory studies most research studies can be generally classified as either experimental or observational flueck and brown 1993 the major distinction is that the former requires the ability of the scientist to control the principal inputs in order to assess the effects on the outputs therefore studies of trends in hydro meteorological variables can be classified as observational because there is no scope for controlling the inputs e g the researcher cannot control the amount of rainfall thus making such studies more difficult to plan and analyze than experimental ones both experimental and observational studies usually have three stages denoted as preliminary exploratory and confirmatory even if the third stage can or should actually aim to falsify disprove the scientific hypothesis according to the so called modus tollens of deductive inference i e if p then q no q therefore no p meehl 1997 leaving aside the preliminary stage concerning general insights into questions about the research topic e g which measurements are useful and can be made amount of available or collectable data in the study period etc exploratory studies aim to define claims about foreseen or unforeseen relations on the basis of a plausible conceptual model i e a researcher s description of the process of interest and appropriate scientific evidence whereas confirmatory studies are specifically defined processes focused on replicating or disproving a result while minimizing sampling and non sampling errors flueck and brown 1993 with small probability that results can come from causes different from the tested theory exploratory studies are flexible in their research of evidence e g variables to be included but this flexibility should not be confused with a superficial treatment of the data and methods focusing on data analyses can rely on randomized or non randomized samples nhst requires randomized samples as it involves three steps often overlooked but fundamental i the choice of the probabilities of occurrence α and β of type i and type ii errors not only the significance level α ii random selection of only n samples from the designed population whereby n is related to the sampling distribution of the test statistic α and β in order to guarantee the desired test s significance and power and iii the test must be performed only once all these steps should be performed before collecting data therefore logical flaws apart nhst yields valid results only if these steps are followed thus justifying the definition of design based inference when the above steps do not apply nhst is out of context because of lack of a priori basis in the case of research related to acc detection for instance most detection studies apply nhst to a sample of data and determine whether to reject the null hypothesis of zero trend in the atmospheric variable under consideration nicholls 2001 these studies typically use all the available records and these data are far from being randomly selected samples with size fulfilling the requirements in terms of α and β prosdocimi et al 2014 moreover hydro meteorological observations usually exhibit serial and spatial correlation and other properties that can be accounted for but make the outcomes further uncertain based on the above remarks it follows that such studies fall in the non randomized exploratory family thus excluding confirmatory tools such as nhst assuming that this is a logically coherent procedure and requiring in turn the use of split samples or future data subsets to provide confirmatory disproving information flueck and brown 1993 moreover in the exploratory stage one is really not interested in finding a statistically significant effect or trend which can always emerge by increasing the sample size but in physically significant effects assuming that one overlooks these aspects how should the outcome of nhsts be interpreted rejection of h 0 does not necessarily imply the acceptance of h 1 as the discrepancy of the observations from the conditions corresponding to h 0 can actually result from factors not included in the formulation of h 0 e g larger variability due to lack of independence and different from h 1 it is also less legitimate to accept substantive hypotheses owing to the formal logic fallacy of affirming the consequent on the other hand if h 0 is not rejected then this does not mean that it can be concluded that h 0 is true but only that experimental evidence does not support the rejection of the null hypothesis unfortunately the intricacy of such reasoning is once again a result of the hybrid nature of nhst in fact fisher intended significance tests as tools for screening situations worthy of deeper study without h 1 while neyman pearson hypothesis tests were proposed as rules of action implicitly accounting for the consequences quantified a priori by α and β of choosing between two competing alternatives therefore even overlooking logical flaws trend nhsts can only reveal possible changes which are not compatible with random fluctuations corresponding to very specific reference processes e g independent and identically distributed iid random variables thus requiring further investigation we can then extend to general trend nhsts what busuioc and von storch 1996 recommended for pettitt test trend change tests should be used not as tests but as mere tools for preliminary screening small large values of the test statistics should be taken as indications for possible upward or downward changes such changes should be accepted as physically meaningful if they can be related with a predictable process based on theoretical models e g logistic models describing population growth under limited resources and or well identified physical dynamics justifying causality e g dam building river training etc 3 2 hidden dependence the limits of short time series and the role of reference models once clarified what conclusions can not be drawn from trend nhsts and in which context we can better discuss the role of persistence in trend detection the example in section 2 1 shows that the underestimation of persistence plays a key role and should be accounted for the estimation of hurst parameter involved in pettitt tests adapted for fgn yields h values of 0 5 and 0 66 for the nera river and velino river respectively however while h 0 5 is consistent with the fact that the nera river data are actually independent the value h 0 66 underestimates the actual value 0 8 even though the estimator is corrected for the bias by the method described in appendix a this confirms that model identification under scarce observations i e short time series is a difficult statistical task subject to large uncertainty and bias koutsoyiannis and montanari 2007 have already investigated this aspect showing that very long time series thousands of observations are required to correctly recognize fgn therefore underestimation of persistence is an aspect that should not be overlooked when using whatever trend nhst involving a correction procedure for this property note that the underestimation of persistence might lead to consider data approximately independent and thus applying standard tests with no corrections this choice can inflate the number of detected significant deterministic trends one should also account for the underestimation of variance which is another well known phenomenon related to the persistence of some stochastic processes e g koutsoyiannis 2011 tyralis and koutsoyiannis 2011 koutsoyiannis and montanari 2015 arising from the fact that the process stays in a given subset of the state space for several time steps thus requiring much time to explore the entire state space for example even though the fgn time series in fig 1 j has theoretical unitary variance its 100 size subsets have an average variance equal to 0 9 note that the larger uncertainty related to persistence should not be confused with the assumption of a deterministic temporal change in the pdf specifically the second moment of a random process evidently from historical observations to future analysis period milly et al 2015 see section 4 for further details in other words persistence inflates the overall variance which is larger than that corresponding to the independent case of course as for persistence estimating the variance from short time series can yield substantial underestimation with similar consequences on the outcome of trend nhsts i e inflated number of detected deterministic trends dependence is introduced in trend nhsts to build a more realistic h 0 relaxing the assumption of independence in the iid model whereas deterministic trends relax the hypothesis of identical distribution in the iid model in the h 1 side since long term patterns in finite samples can result from be effects of both persistence and deterministic changes in distribution in trend nhsts we attempt to compare two hypotheses that can produce comparable effects knowing a priori that they can thus why is dependence considered a null condition while deterministic changes in distribution are assumed to produce an effect the difference between the two schemes is that the deterministic trends require attribution whereas persistence is compatible with pure stochastic processes implicitly assuming that persistence provides a realistic description of natural systems as mentioned above nhsts cannot tell us which model is the most credible and they cannot be used for such exploratory studies but only in a confirmatory disproving stage by using independent data and a well specified model reproducing properties that are unlikely to be reproduced by other competitors therefore in absence of physical theory both options persistence and deterministic changes are legitimate but the main issue concerns their ability to describe variations in the wider population this is usually only achievable when there are additional sources of data against which each model can be judged 3 3 distinguishing processes and time series a matter of attribution often trend nhst is the first step to infer systematic changes of the studied process over time and thus its nonstationarity eventually justifying the adoption of nonstationary models however this procedure is logically flawed and the opposite should be done exploratory analysis should suggest a set of theories models these models should be used to reproduce challenging properties of the observed data and then confirmatory disproving analysis in terms of prediction should be applied a successful model theory can provisionally be retained until disproved by further applications on new data the common inversion of reasoning is partly related to the confusion between processes and time series the problem of contaminated data series with trends and seasonal effects has been a matter of common experience for hydrologists the traditional way of dealing with such an issue is to produce a new time series the output of a certain filter or adjusting procedure which represents in some sense an estimate of what the real series would be if the contaminating effect were absent according to jaynes 2003 p 536 then choice of the best physically realizable filter is a difficult and basically indeterminate problem fortunately intuition has been able to invent filters good enough to be usable if one knows in advance what kind of contamination will occur when a data set is filtered according to incorrect assumptions detrending may introduce spurious artifacts that distort the information that statistics and probability theory could have extracted from the raw data so caution is advisable especially with refined filters giving a false sense of reliability whereby this can come only from reasoned judgment hence testing trends on finite and short time series can easily be inconclusive and or misleading because of the intrinsic difficulty if not impossibility of detecting nonstationarity of a process solely from data without exogenous information as is discussed later leaving aside the logical arguments discussed above let us suppose that a dam was built along a river thus influencing its regime according to the dam operation rules if we know a priori the existence of the dam we do not need to perform a trend analysis because we already know that the flow regime has been changed by dam construction we can study how the dam impacted on specific characteristics of the flow regime i e the effect size if this information is not already included in dam design specifications on the other hand if we do not have a priori information on the dam existence trend nhst can only tell us that some source of discrepancy from pure randomness is present however this does not allow one to infer nonstationarity of the underlying process without additional information identifying a clear causality rule in fact as shown in sections 2 1 3 1 and 3 2 multiple factors can generate such discrepancy in finite time series and trend nhst does not allow one to draw conclusions on the substantive causes in these circumstances we should propose a set of theories based on plausible reasoning develop suitable models and compare their prediction performance with independent observations however these models will be credible only if they incorporate rules describing the dynamics of the process e g dam s effects thus making its evolution predictable i e river flow will follow a given regime until the dam operates therefore without clear attribution via exogenous information trend nhst can only provide a generic indication that further investigation is required according to the rationale of fisher and neyman pearson original methodologies in this respect such attribution cannot be vague or based on some kind of statistical analysis affected by its own uncertainty because what is needed is not some sort of statistical correlation but a substantive causal physical relationship that should be general and valid beyond the period of the observed records therefore even sophisticated regression models e g glms gams etc do not fulfill these requirements as they fall in the class of analog models flueck and brown 1993 for which extrapolation is not advisable cooley 2013 and easily leads to physically inconsistent predictions serinaldi and kilsby 2015 luke et al 2017 nonstationarity requires the postulation of a law of temporal evolution of the process and this law should be based upon substantive hypotheses in order to be general and valid for prediction of still unobserved data poppick et al 2017 using the example of the dam glms fitted on the data can incorporate time dependent terms but these data driven regression laws do not say anything about the dam operation rules and their effect and their extrapolation in time is not supported by any reasoned judgment about the causes of the observed patterns are they real or spurious how will they evolve on the other hand additional information on the dam existence and operation and its mathematical formalization can justify the introduction of nonstationary models e g ayalew et al 2017 thus nonstationarity and corresponding modeling strategies are allowed only if we make a priori assumptions about the processes and the causes of nonstationarity are clearly identified and formalized via deductive reasoning about e g the effects of a dam on the river regime nonstationarity cannot result from inductive inference from data only as the observed patterns can be the effect of various unknown causes persistence nonlinearity nonstationarity etc which cannot be discriminated in exploratory studies or misusing questionable confirmatory tools it should be noted that these remarks are well known in climatology hasselmann 1997 for instance but seem to be overlooked in many hydro meteorological studies relying almost exclusively on trend testing to draw conclusions indeed according to mitchell et al 2001 p 700 detection is the process of demonstrating that an observed change is significantly different in a statistical sense than can be explained by natural internal variability however the detection of a change in climate does not necessarily imply that its causes are understood from a practical perspective attribution of observed climate change to a given combination of human activity and natural influences requires another approach this involves statistical analysis and the careful assessment of multiple lines of evidence to demonstrate within a pre specified margin of error that the observed changes are unlikely to be due entirely to internal variability consistent with the estimated responses to the given combination of anthropogenic and natural forcing and not consistent with alternative physically plausible explanations of recent climate change that exclude important elements of the given combination of forcings detection ruling out that observed changes are only an instance of internal variability is thus one component of the more complex and demanding process of attribution these recommendations are fully general and not restricted to the problem of acc detection and attribution they highlight the importance of defining the magnitude of internal variability space time covariance and dependence structure hasselmann 1993 1997 poppick et al 2017 which is a challenging task as discussed in section 3 2 and further in section 6 as well as the need of jointly using deductive and inductive methods and excluding other physically reasonable explanations before arriving at a clear attribution 4 voces significant res mediantibus conceptis 1 1 signs correspond to objects through interpretants eco 1976 missing interpretant generates a hiatus between sign and object 4 1 stationarity in the previous sections we discussed some theoretical and practical limits of trend testing including the problems posed by the intrinsic nature of the hydro meteorological data the misuse of confirmatory tools in exploratory analyses and the influence of dependence as well as the basis and logic of nhsts and their interpretation all these aspects raise serious questions regarding the actual information and conclusions that can be drawn from trend nhsts and exploratory studies relying on them however to better understand why nonstationarity cannot be inferred from this analysis we need to go back to basic concepts and definitions as the title of this section suggests we put the emphasis on the meaning of common terms in the context of trend testing as the semantics of those terms is often confusing in the literature although there is ongoing debate about this issue koutsoyiannis and montanari 2015 milly et al 2015 we believe it is worth recalling and expanding it where necessary because of its importance for correctly setting up and interpreting data analysis unless stated otherwise throughout this paper we use upper case letters for random variables and lower case letters for values parameters or constants referring to koutsoyiannis and montanari 2015 for a rigorous presentation of the formal definitions of stationarity and nonstationarity we recall that a stationary stochastic process in the sense of khinchin is a set of random variables xt depending on the parameter t t such that the distributions of the systems x t 1 x t 2 x t n and x t 1 τ x t 2 τ x t n τ coincide for any n t 1 t 2 tn and τ this definition has been translated in various ways such as stationarity means that hydrological variables fluctuate randomly within an unchanging envelope of variability bayazit 2015 or stationarity or temporally stable probability distribution functions pdf rice et al 2015 even though such definitions are acceptable in informal discussions the actual meaning of khinchin s definition merits some further discussion to avoid misunderstandings assuming that t denotes time khinchin s definition means that the n dimensional joint distribution of n random variables is identical independently of their location along the time axis however since the mathematical definition refers specifically to random variables xt the sets of realizations x t 1 x t 2 x t n and x t 1 τ x t 2 τ x t n τ are unavoidably different by the way mandelbrot 1982 p 384 emphasized that when mathematicians first encountered stationary processes having extremely erratic samples they marvelled that the notion of stationarity could encompass such wealth of unexpected behavior unfortunately this is a kind of behavior that many practitioners insist is not stationary so the actual problem in inductive exploratory analysis of trends is to understand if such fluctuations are consistent with a unique n dimensional joint distribution or they come from different distributions given the uniqueness of observed hydro meteorological records and the well known uncertainty in making inference from very short time series the most common case in hydro meteorology the problem is challenging in order to make the problem easier to treat one often focuses only on the first moments actually up to second order because of the high uncertainty in estimating higher order moments lombardo et al 2014 thus introducing the concept of weak stationarity where khinchin s definition reduces to identity of population means e xi population variances var xi and population covariances over n time steps independently of their location along the time axis 4 2 ergodicity we cannot emphasize too strongly the clear distinction between the population properties that are deduced logically from the theory and the sample properties that are determined empirically from observations sample estimates are derived from time averages whose relationship to the statistical parameters of the theoretical process must be established only in the form of ergodicity in order to highlight the importance of ergodicity it is worth recalling that a stochastic process x t ζ is a collection of time functions depending on the outcome ζ of an experiment l or a collection of random variables over a parametric support t time space etc papoulis 1991 pp 285 286 fig 2 helps to clarify these definitions for a fixed outcome ζ i e a fixed coordinate along the event space axis x t ζ is a single time function or trajectory describing a sample or realization of the given process one of these realizations can be the sequence of the truly observed records while the others are possible outcomes that did not occurred but could on the other hand if t is fixed as t and ζ varies then x t ζ is a random variable describing the state of the given process at time t if both t and ζ are fixed x t ζ is a number i e the specific value assumed by the process at the specific time in real world applications we often know only a single finite size sample of x t ζ e g a sequence of daily stream flow values between year t and t τ so a central problem is to infer the parameters of the underlying stochastic process from such sample this is possible only if the process is ergodic meaning that the time average of any integrable function g x t ζ equals the true ensemble expectation e g x t ζ as the size of the available sample tends to infinity papoulis 1991 pp 427 428 clearly this is not possible if e g x t ζ depends on t therefore we must assume a stationary underlying process focusing on the mean of the process ergodicity implies that 1 lim τ x τ t ζ obs lim τ 1 τ s t t τ x s ζ obs e x t ζ x f x d x more generally ergodicity allows the use of the empirical probability density function f obs or f i f j etc of a sample of x t ζ as an estimate of the probability density functions f x i f x j of the random variables x ti ζ x tj ζ describing the state of the process at time ti tj if a process is nonergodic then statistical inference from data is not allowed because sample averages variances and distributions are not representative of their population counterparts moreover we should consider that stationarity is a necessary but not sufficient condition to ergodicity of stochastic processes koutsoyiannis and montanari 2015 therefore a nonstationary process is nonergodic thus estimates from data are not representative of the process when we claim nonstationarity in fact nonstationarity implies that the population distributions f x i f x j and f x k in fig 2 are not identical to each other and thus f obs is no longer representative of any of them in fact the histogram is assumed at least implicitly to be an estimate of the marginal stationary distribution note that second order stationarity or one of the other forms of weak stationarity is not sufficient strong stationarity at least must exist for the special case of n 1 the number of points not the dimension of the space if the random function is not stationary at least to this extent then the histogram is not an estimate of a distribution related in a known way to the random function myers 1989 similarly if f x i f x j and f x k have different moments e g mean and or variance changing in time the empirical sample moments are not representative of any of these local population moments this can be surprising in light of the extensive use of nonstationary models such as glms and gams with time dependent parameters in hydro meteorological frequency analysis for instance of course the problem is not about these models by themselves but their misuse in fact these models actually fit local trends observed in the period of record that can be due to multiple factors anthropogenic activity persistence nonlinearity etc which in turn cannot be identified by data alone moreover they are often justified owing to the better performance compared with iid versions which are not challenging competitors and overlooking more realistic options that can yield patterns close to the observed ones nonstationary models are legitimate when there is additional information on the cause of time dependent behavior the identification of the cause of local trends is paramount for extrapolation in order to be sure that the nonstationary effects continue beyond the period of record without this additional information prediction based on pure data driven time dependent patterns easily yields physically inconsistent results when extrapolating into the future or past luke et al 2017 serinaldi and kilsby 2015 villarini et al 2009b actually low reliability and high uncertainty in predictions of evolution of nonstationary patterns might be an index of the little evidence supporting the nonstationary choice serinaldi and kilsby 2015 4 3 nonstationarity at this point a definition of nonstationarity is required in order to illustrate nonstationary processes koutsoyiannis and montanari 2015 considered the decomposition x t d t e t where e t is a stationary stochastic process and dt is a deterministic function of time dt d t milly et al 2015 proposed a similar representation namely x t a t b t e t where at and bt are deterministic and e t is stochastic we slightly generalize the decomposition suggested by koutsoyiannis and montanari 2015 as follows 2 g x t d t g e t where g is a generic operator some examples are given below according to koutsoyiannis and montanari 2015 a deterministic function of time is precisely known and perfectly predictable meaning that a system input corresponds to a single system response contrasting stochastic dynamics where a single input could result in multiple outputs since every inductive analysis based on observed data is always affected by uncertainty a deterministic function cannot be inferred from the data only but it should result from deductive reasoning and be validated by data which were not used in the model construction notice that this definition is consistent with the idea which became famous as laplace s demon i e the classical definition of strict physical determinism according to laplace the demon is indeed a superhuman intelligence that could know and model all details of the universe to infinite precision for such an intellect nothing would be uncertain and the future just like the past would be present before its eyes laplace 1814 in other words if all changes in nature are expressible through mathematical functions of time complete and precise knowledge of the initial conditions at a certain moment allows one to perfectly predict the conditions at all later and earlier times however predictability and determinism are also easy to disentangle in practical applications as shown in many studies on deterministic chaos the approximate character of scientific knowledge renders dynamical systems unpredictable even though they are fully governed by underlying deterministic laws sivakumar 2016 yevjevich 1974 actually determinism is a matter of spatio temporal scales in fact even if the process i e vector function representing the deterministic dynamics is perfectly known perfect predictability beyond a given temporal horizon can completely be lost owing to very small uncertainty in initial conditions berliner 1992 koutsoyiannis 2010 lorenz 1963 that is magnified by possible nonlinearity leading to emergence of deterministic chaotic behavior e g von storch and zwiers 2003 pp 1 2 while chaos theory explains unpredictability of a deterministic system in practice laplace s demon assumes perfect predictability under ideal complete and precise knowledge of the system including initial conditions therefore the two ideas are compatible with each other as already recognized by laplace himself who wrote all these efforts in the search for truth tend to lead it human mind back continually to the vast intelligence which we have just mentioned but from which it will always remain infinitely removed laplace 1814 the decomposition in eq 2 is a rather general description of nonstationarity in fact if g is the identity operator eq 2 describes the simplest decomposition of the process itself x t d t e t if g is the expectation we have e x t d t e e t referring to a process that is nonstationary in mean first moment when g denotes the variance then var x t d t var e t describing a process whose variance depends on a deterministic function of time such as the brownian motion bm with var xt t in other words nonstationarity implies that the distribution of the system x t 1 x t 2 x t n depends on time by a deterministic function which can however refer to one or more characteristics of the distribution e g mean variance higher order moments autocorrelation etc for bm as well as fractional bm and autoregressive integrated moving average processes arima nonstationarity refers to deterministic functions of statistical moments and inference is performed on the increment process y t x t 1 x t because taking the first difference yields a stationary process by removing the dependence of the moments on time whatever is the specific form of nonstationarity in mean variance etc statistical inference e g calculation of moments only applies to a corresponding stationary process obtained by suitable transformations e g differencing under the assumption that the original process has a specific form of nonstationarity however without an attribution identifying the source of the deterministic dependence on time nonstationarity cannot be claimed from the data only claiming nonstationarity i e the existence of a deterministic function of time for some statistical properties of xt on the basis of the outcome of nhsts such as mk pettitt or unit root nhsts such as dickey and fuller 1979 and kwiatkowski phillips schmidt shin kwiatkowski et al 1992 is simply not possible owing to the problems discussed in section 3 and the definitions given above 4 4 what is a trend we argue that some widespread misconceptions concerning trend detection and attribution result from a lack of definition of trend thus attempting a reasonable definition and opening the debate about this point seems useful first of all the concept of trend should be related to nonstationarity this seems a reasonable assumption as we are not interested in local but long term patterns spanning for instance the entire series of records and resulting from e g persistence of underlying stationary processes in this case the stochastic nature of persistent quasi periodic or monotonic patterns make their magnitude onset and end unpredictable and a pure stochastic stationary description is sufficient thus we should conclude that a trend of true interest which is the focus of the largest part of hydro meteorological literature on the topic should strictly be related to a form of nonstationarity if so recalling khinchin s definition of stationarity and the discussion in section 4 3 a stochastic process has a trend if one or more of its statistical properties vary in time according to a deterministic law of time dt the function dt can be monotonic non monotonic periodic and can refer to the average variance or other statistical properties of the process see section 4 3 in this respect there is no difference for instance among i trends defined as smooth long range changes in some moment parameter of the time varying distribution as used e g in glm gam modeling ii stochastic trends captured by random walk type processes i e bm fbm arfima etc or iii trend described by physical equations in processes involving stochastic differential equations or different types of physical statistical models in all of these cases for the parameters of glms gams for the variance of bm and fbm processes and for the specific characteristics described by the physical part of physical statistical models there is a function dt accounting for deterministic time dependent evolution of the system concerning dt a misconception widespread in glm gam based hydrological frequency analysis is the belief that replacing t with other variables makes the model nonstationary this is true only if such variables are themselves nonstationary and thus time dependent according to a well defined function replacing t with teleconnection indices e g north atlantic oscillation index or other variables showing clear stochastic behavior simply yields stationary doubly stochastic models if a trend is identified with the existence of a deterministic function of time dt and thus with nonstationarity remarks on detection and attribution provided in section 4 3 apply and in particular we should exclude the possibility to make inference from data only for example seasonal cycles are forms of dt resulting from a fundamental deductive reasoning exogenous information concerning planetary dynamics and corresponding mathematical theory this deductive step allows for the choice of inference tools and then a quantitative evaluation of seasonal components from data for each specific case seasonal cycles are predictable with negligible uncertainty as we are almost sure of the occurrence of equinoxes and solstices in the next decades or even centuries unless the occurrence of unpredictable catastrophic events acting at the solar system or galaxy scale here lack of uncertainty refers to the existence of the seasonal dt and not to its contingent parametrization which varies in each specific case under these premises introducing other forms of trend should rely on the same approach merging deductive and inductive reasoning for example a commonly used approach of comparing nested models with time varying and constant parameters by using some performance criterion is not enough if the time dependent function dt does not result from deductive reasoning but results from simple fitting procedures in these cases higher parametrized time dependent models might simply account for local apparent trends giving very poor performance in prediction owing to lack of identification of substantial causes acting beyond the period of record serinaldi and kilsby 2015 trends of interest in hydro meteorology are often monotonic or low frequency type spanning over the period of record possibly related to anthropogenic activity we argue that frequency is actually the main difference between seasonal trends and other forms of deterministic time dependent trends seasonal trends look like monotonic or half wave trends if the focus is on sub annual time windows because the process is not fully developed at such a time scale and one cannot retrieve signal components with frequencies lower than half period of record as described by the nyquist shannon sampling theorem therefore even the use of effective filtering methods such as singular spectrum analysis wavelet analysis or empirical mode decomposition cannot help in trend identification if we are not able to arrive at a clear attribution of the patterns described by the lowest frequency components resulting from filtering being a form of nonstationarity or its expression trends are allowed only if they rely on exogenous knowledge involving theoretical arguments or empirically well defined processes in agreement with mccuen 2003 without such an additional information trends cannot be inferred from the data only because they refer to the underlying process x t 1 x t 2 x t n and not to its realizations x t 1 x t 2 x t n i e observed time series in agreement with the starting point of chandler and scott 2011 without attribution to unique substantive cause and exclusion of any other possible cause exploratory tools filtering or model selection can only highlight local low frequency persistent fluctuations but they do not allow one to make conclusions on stationarity or nonstationarity this is in agreement with von storch and zwiers 2003 p 9 who stated trends in the large scale state of the climate system may reflect systematic forcing changes of the climate system such as variations in the earths orbit or increased co2 concentration in the atmosphere or low frequency internally generated variability of the climate system the latter may be deceptive because low frequency variability on short time series may be mistakenly interpreted as trends however if the length of such time series is increased a metamorphosis of the former trend takes place and it becomes apparent that the trend is a part of the natural variation of the system these remarks are general and hold true not only for climate but also in every context exhibiting large uncertainty about the number type and effect of the acting physical processes based on the discussion above we can then provide an unambiguous definition of trend as time dependent deterministic and therefore predictable change dt of the properties of a process xt where the term deterministic implies prediction variance equal to zero one to one relationship this definition highlights that trends and nonstationarity refer to the underlying process and attempting to infer nonstationarity requires both detection and attribution based on a combination of deductive reasoning which supports and justifies the existence of a time dependent deterministic function i e trends and nonstationarity and inductive reasoning which provides i preliminary knowledge by exploratory data analysis and ii quantification parametrization of dt by confirmatory disproving analysis and modeling we stress that prediction variance equal to zero does not refer to the specific parametrization of dt but its existence and its overall evolution for example the parametrization of seasonal trends components obviously varies even for the same process observed at different locations but the existence of the seasonal cycle and its effects in terms of alternation of wet dry and cold warm conditions along the calendar year are predictable with almost no uncertainty other forms of trend nonstationarity are allowed only if they are supported by the same kind of deductive and inductive arguments 5 trend and abrupt change tests an overview of overlooked critical aspects in practical applications in this section we discuss some problems concerning the practical application of two nhsts for trends i e the mann kendall mk mann 1945 kendall 1970 and pettitt tests pettitt 1979 the following remarks apply under the assumption that we disregard logical arguments in sections 3 and 4 still apply these tests for exploratory analysis and use them to make conclusions on trends nonstationarity among many available statistical testing procedures devised for assessing the significance of a change e g kundzewicz and robson 2004 the mk and pettitt tests are widely used rank based nonparametric tests to check the presence and timing of slowly varying and abrupt changes in the mean or median of hydro meteorological variables such as rainfall runoff and temperature e g villarini et al 2009a 2011b ferguson and villarini 2012 rougé et al 2013 tramblay et al 2013 guerreiro et al 2014 sagarika et al 2014 rice et al 2015 2016 mallakpour and villarini 2015 2016 ahn and palmer 2016 archfield et al 2016 do et al 2017 among others the popularity of these tests is related to their simplicity in terms of implementation their robustness against outliers or measurement errors as they are rank based and the availability of exact or asymptotic distributions of their test statistics under null hypothesis h 0 no trend no change and independence i e iid conditions moreover being based on the so called mann whitney statistic the pettitt test and the mk test are formally related to each other thus highlighting that distinguishing between slowly varying and abrupt changes is only a matter of scale and time of evolution of the change rougé et al 2013 serinaldi and kilsby 2016a even though these tests are used to check changes in the mean or median the first myth to dispel is that mk and pettitt tests are devised to detect changes in the central tendency summary statistics they actually check a wider hypothesis called stochastic ordering given a sequence of random variables x i i 1 n with cumulative distribution functions fi mk checks against the alternative hypothesis h 1 f i x f i k x for every i every x and every k 0 mann 1945 while pettitt checks against h 1 f b x f a x where f b f a is the common distribution of the m n m 1 random variables before after the change point pettitt 1979 therefore even though these hypotheses are commonly restricted to a shift in the location parameter these tests are sensitive to all possible conditions resulting in stochastic ordering serinaldi and kilsby 2016a based on the above belief when a change point or a monotonic trend is detected often the magnitude of the abrupt change is quantified by the difference in mean or median between the sub series before and after the change while the trend by the so called sen s slope e g khaliq et al 2009b rice et al 2015 2016 nilsen et al 2016 tananaev et al 2016 in light of the actual nature of mk and pettitt tests such quantification is not justified especially for mk in fact even if we assume that mk only checks for changes in mean median it refers to monotonic changes that can be linear or nonlinear stepwise s shaped or abrupt as a limiting case resulting from more general changes in the overall shape of the distribution of course the choice of linear trends reflects practical requirements indeed assuming more complicated higher parametrized patterns can be unjustified for usually short time series because of the additional uncertainty affecting the estimation since sen s estimator for the slope of a linear trend is rank based nonparametric it is considered more robust than classical mean square error mse however its nonparametric nature does not make it more coherent with mk outputs than mse estimates of linear trends even though the need of quantifying a possible change is understandable reducing the indication of possible monotonic trends given by mk to that of a linear trend is too restrictive and does not reflect the rationale and outcome of mk test since perfectly linear trends rarely describe realistic evolution patterns of complex hydro meteorological processes even under actual deterministic forcings such a kind of quantification should be at most purely qualitative and possibly avoided in order to provide a correct communication in any case it cannot be considered an actual trend in light of discussion on detection and attribution in section 4 4 of course trend tests can only detect inhomogeneities within the time interval covered by the observed records this also explains why they cannot be used to infer nonstationarity stationarity is a property of the theoretical process xt for t and concerns the identity of population statistical properties for every subset of random variables in every point of the time line while trend tests can only check possible changes in finite and usually short time windows where observed fluctuations might easily be spurious since we cannot extrapolate conclusions beyond the period of records without identifying a deterministic and predictable cause of such inhomogeneities the outcome of trend tests cannot be used to justify the application of nonstationary models for frequency analysis such a usage is inappropriate and might lead to unrealistic predictions serinaldi and kilsby 2015 the previous remarks have important consequences on the procedures used to account for the effects of the temporal correlation the effect of the autocorrelation on tests devised for independent data is a general increase of the rejection rate of the null hypothesis h 0 no trend of the statistical test even if the underlying process is stationary this is due to the information redundancy that makes the effective sample size smaller than the observed size thus implying that the effective variance of the test statistics to be used in the testing procedure under serial dependence is larger than that provided by standard results obtained under the hypothesis of independence e g bayley and hammersley 1946 koutsoyiannis and montanari 2007 this phenomenon is known as variance inflation and has been accounted for using three general approaches the explicit calculation of the inflated variance e g hamed and rao 1998 koutsoyiannis 2003 matalas and sankarasubramanian 2003 yue and wang 2004 hamed 2008 2009b prewhitening procedures e g katz 1988 kulkarni and von storch 1995 von storch 1999 yue et al 2002 yue and wang 2002 bayazit and önöz 2007 hamed 2009b and bootstrap techniques khaliq et al 2009a kundzewicz and robson 2004 referring to khaliq et al 2009b and bayazit 2015 for a review we focus on some aspects that are generally overlooked 1 firstly all tests involving the iid hypothesis should be corrected for the effect of autocorrelation neglecting this aspect might lead to contradictory results further discussed in section 6 3 2 since some procedures involve trend removal e g yue et al 2002 hamed 2008 this is usually supposed to be linear as mentioned above this choice is understandable from a practical point of view but less defensible if it is interpreted as a deterministic evolution of some physical hydro meteorological process linear trends cover a very limited subset of the actual hypothesis tested by mk and pettitt tests as well 3 the procedures proposed in the literature consider corrections based on the autocorrelation values estimated on the data themselves this poses two problems i for short time series autocorrelation is generally underestimated e g koutsoyiannis 2003 koutsoyiannis and montanari 2007 where the bias is larger if the underlying process exhibits long range dependence lrd thus when the correction procedure involves a specific dependence structure often markovian autocorrelation should be adjusted see serinaldi and kilsby 2016a and appendix a and ii it is taken for granted that the dependence structure of the underlying process can be retrieved by the analyzed summary statistics usually annual minima averages maxima etc the point ii is subtle but critical in fact the behavior of summary statistics can be strongly influenced by the nature of the underlying process for example processes with lrd yields maximum values over blocks of observations that tend to cluster in time e g bunde et al 2005 eichner et al 2011 this results in apparent trends in terms of frequency and magnitude if the analysis relies on short series of such maxima even though these summary statistics might easily show no or very weak autocorrelation since this behavior is found in stream flow time series serinaldi and kilsby 2016c we show in the case study that it might have a dramatic effect on trend nhst outcomes 4 in some cases correction procedures are flawed failing to provide any adjustment as an example among others the so called trend free prewhitening tfpw yue et al 2002 was shown to be theoretically flawed serinaldi and kilsby 2016a as its original version does not address the variance inflation problem which can be even exacerbated since it has been widely applied thanks to its relative simplicity results of several analyses reported in the literature should be taken with great care and possibly revised two aspects characterizing several published trend analyses based on nhst need to be mentioned i the correctness of applied tests or methodology in general is almost always taken for granted while a preliminary check of their performance under h 0 controlled conditions should be performed by simulation before their application especially if the tests were not developed by statisticians and result from some empirical reasoning without a necessary mathematical proof as shown for the hybridization of fisher and neyman pearson methods in section 3 ii empirical results are often interpreted without the necessary rigor thus resulting in misleading conclusions confusing artifacts with meaningful results 6 case study in this section we investigate the consequences of the above discussion on data analysis and its interpretation to this aim we use data already analyzed in the literature to show how results and conclusions can remarkably change if we account for logical methodological and practical issues discussed in previous sections note that our analysis is not exactly a study of reproducibility because data and some methods are not precisely equal to those applied in previous studies however the use of mk and pettit is justified for sake of comparison with previous studies and key general results are reproduced and then compared with new findings relying on more realistic null hypotheses 6 1 observational data long term trends in stream flows over the conterminous united states conus have been extensively studied referring to sagarika et al 2014 for a recent review we recall that the past studies focused on various summary statistics and or data sets including peak discharge records barrett and salis 2016 hirsch and ryberg 2012 lins and cohn 2011 mallakpour and villarini 2015 villarini et al 2009a villarini and smith 2010 villarini et al 2011a vogel et al 2011 monthly data kalra et al 2008 lettenmaier et al 1994 and mean daily observations ahn and palmer 2016 lins and slack 1999 mccabe and wolock 2002 rice et al 2016 2015 sagarika et al 2014 the interest for such an area is not only practical but is also related to the great variety of hydrologic regimes conditions across conus as well as the availability of data and metadata which allow for more accurate studies than in other parts of the globe since the trend analysis described below section 6 2 requires both daily data and summary statistics i e maxima or averages on a seasonal and annual basis in this study mean daily flow records are used the data set is extracted from the hydro climatic data network hcdn 2009 lins 2012 which comprises 743 stations maintained by the u s geological survey usgs hcdn 2009 is a subset of the wider usgs gages ii geospatial attributes of gages for evaluating streamflow version ii reference stations providing geospatial data and classifications for 9 322 stream gages hcdn 2009 provides a stream flow data set suitable for analyzing hydrologic variations and trends in a climatic context as it includes quality controlled time series from stations that were screened to exclude sites where human activities or other activities affect the natural flow and with sample size sufficiently large for analysis of patterns in stream flow over time lins 2012 a list of hcdn 2009 stations along with basic attributes can be found at the web site http water usgs gov osw hcdn 2009 while the data set is freely available at http waterdata usgs gov nwis sw this study focuses on 250 stations having continuous and simultaneous observations with no missing values between the water years 1951 and 2011 included i e october 1950 to september 2011 following sagarika et al 2014 the data set comprises only one station on a particular stream within each u s hydrologic unit code huc to reduce spatial bias in the results moreover even though some stations have continuous data spanning longer periods we selected only simultaneous data from 1951 to 2011 to guarantee temporal homogeneity and to allow some remarks on spatial correlation discussed later in section 6 3 for seasonal analysis seasons are defined as autumn october december winter january march spring april june and summer july september 6 2 methodology 6 2 1 testing local significance in this study possible slowly varying trends and abrupt changes of some stream flow properties are analyzed by mk and pettitt tests in four different settings 1 classical versions devised for independent random variables hereinafter they are denoted as standard mk and standard pettitt 2 a corrected and unbiased tfpw tfpwcu version of both tests accounting for first order autoregressive ar 1 dependence i e classic markovian dependence and bias correction for acf underestimation denoted as ar 1 tfpwcu mk and ar 1 tfpwcu pettitt tfpwcu procedure is applied to show that a correct tfpw procedure yields results different from those of the classical setting highlighting that the similarities of results often recognized in the literature are actually artifacts see section 5 the reader is referred to serinaldi and kilsby 2016a for further details 3 a prewhitening version accounting for fgn dependence proposed by hamed 2008 for mk test and adapted by serinaldi and kilsby 2016a for pettitt this version allows one to account for long range dependence lrd and improves the original prewhitening procedure by introducing bias corrected estimates of the hurst parameter h characterizing the fgn acf based on the formulas provided in appendix a these tests are denoted as fgn cpw mk and fgn cpw pettitt where cpw indicates conditional prewhitening meaning that the prewhitening procedure is applied only if h is found significantly different from 0 5 at the 5 significance level these versions are detailed in hamed 2008 and serinaldi and kilsby 2016a 4 the last version is based on monte carlo simulation of daily stream flow sequences in order to check the impact of daily dynamics on the annual seasonal statistics and trend test outcomes this way we introduce a more realistic null scenario in terms of dependence structures that is built by exploiting the whole available information instead of few tens of annual seasonal summary statistics in more detail each daily stream flow time series is deseasonalized following the procedure described by e g serinaldi and kilsby 2016c and serinaldi and kilsby 2016b and residuals are resampled by the iterative amplitude adjusted fourier transformation iaaft method schreiber and schmitz 1996 kugiumtzis 1999 schreiber and schmitz 2000 venema et al 2006a 2006b serinaldi and lombardo 2017 which allows for simulation of surrogate data preserving almost exactly the empirical distribution function and power spectrum acf of the observations iaaft surrogates are stationary franzke 2013 by construction because of randomization of fourier phases combining surrogate residuals and seasonal components yields synthetic daily stream flow time series under the null hypothesis preserving almost exactly both the marginal distribution and correlation structure of the observed ones small discrepancies in marginal distributions do not matter as the used trend tests are rank based therefore summary statistics of interest here averages and maxima on a seasonal and annual basis are extracted and standard mk and pettitt tests are applied the procedure is repeated many times to obtain the sampling distribution function of mk and pettitt test statistics accounting for the dependence properties of the daily process under stationary conditions in other words our new null hypothesis is observed trends in annual seasonal values are consistent with patterns coming from a stationary daily process with given observed marginal distribution and dependence structure 6 2 2 testing field significance when data from multiple stations are analyzed one can ask whether the results imply that there is a significant effect when considering the entire group of stations i e the so called field significance daniel et al 2012 katz and brown 1991 livezey and chen 1983 wilks 1997 2006 this recognizes that when performing multiple tests it is more likely to detect significant changes by chance this probability increases if the data are spatially correlated in this case spatial correlation acts similarly to temporal correlation introducing information redundancy owing to possible similar patterns across spatially correlated sequences referring to khaliq et al 2009b for an overview of methods to treat field significance we recall that they fall in two categories daniel et al 2012 one controls the false discovery rate fdr i e the expected fraction of local null hypothesis rejections that are incorrect benjamini and hochberg 1995 benjamini and yekutieli 2001 and is nearly equivalent to the walker test fisher 1929 katz 2002 wilks 2006 the other relies on counting the number of rejections at local level and then comparing these values with the selected critical values obtained from the empirical distribution of number of rejections resulting from bootstrap procedures preserving approximately spatial or spatio temporal correlation khaliq et al 2009b wilks 1997 daniel et al 2012 highlighted that the choice of method depends on the spatial nature of the studied effect e g trend if it is expected that the effect is widespread local it would be preferable to use the count based fdr approach while a combination of both approaches could be applied if there is no a priori expectation in this study we focus on the walker test because i it is easy to implement and robust to cross correlations khaliq et al 2009b wilks 2006 and ii the counting method requires intensive and different simulation procedures for iaaft based trend tests and the other tests standard ar 1 tfpwcu and fgn cpw we recall that the walker test consists of comparing the smallest of p value corresponding to the test statistics computed on k time series with the critical value p w 1 1 α global 1 k the global null hypothesis h 0 no global trend may be rejected at the a global level α global if the smallest of k independent local p values is less than or equal to p w wilks 2006 the counting method is only applied to check the variability of field significance for the lag 1 acf term ρ 1 and the hurst coefficient h in the series of annual seasonal summary statistics see khaliq et al 2009b p 121 for a detailed description all tests are performed at the 5 local and global significance level 6 3 results 6 3 1 temporal dependence of maximum and mean flows given the influence of autocorrelation on detection of possible trends the dependence structure of annual and seasonal maximum and mean flows are preliminarily investigated owing to the limited sample size of such a type of data only parsimonious models such as ar 1 and fgn are usually considered even though the latter would require very long time series for a reliable inference figs 3 and 4 show the spatial distribution of the sites where ρ 1 and h are found to be locally and globally significant along with the sites where both models are locally significant global significance is assessed at the huc scale of course the number of sites showing possible significant persistence are higher for mean values than for maxima owing to the higher variability of the latter no particular spatial patterns are evident these results are not surprising if we consider the persistence of the underlying flow process and recognize that maxima are values sampled from the daily process while mean values result from averaging all daily data in each season or year nonetheless figs 3 and 4 allow some methodological remarks when we test significance for ρ 1 and h we are implicitly assuming an underlying model ar 1 or fgn as alternative hypothesis h 1 this implies that the estimates should be corrected accordingly for possible bias for example testing ρ 1 under the assumption that the underlying process is fgn requires a bias correction procedure different to that used under the assumption of ar 1 process this aspect is often neglected and ρ 1 is commonly tested using biased estimates yielded by default estimators working under iid assumptions koutsoyiannis 2016 another remark concerns the output of the walker test and counting method for global significance when the two approaches yield different results the walker test tends to identify more areas with significant results according to the nature of the walker test which is sensitive to local effects in some of these cases field significance results from a single locally significant station falling in the huc area especially if the number of stations in that area is small daniel et al 2012 provided some insight into selecting suitable sub regions to assess field significance to avoid bias sub regions should be identified a priori before performing the analysis and domain limitation should be made as a result of some physical insight in this respect hucs are a credible choice however daniel et al 2012 also stress that if some region in a domain is seen to contain a large number of significant stations it is certainly inappropriate to apply the field significance test over just this limited domain without a physically based justification also in this case the clustering of significant trends might be due to the spatial correlation of large scale meteorological variables driving the flow processes in a specific area in other words local clusters in space are the natural effect of spatial correlation as local clusters of high low values in a time series might reflect temporal correlation since it is easy to confuse spatio temporal correlation with deterministic trends these remarks highlight the importance of using clear definitions in order to distinguish between stochastic fluctuations and deterministic changes whose attribution should be based on a priori information and causality 6 3 2 trend analysis of maximum and mean flows results of trend analysis are shown in figs 5 8 according to the aim of this study as for correlation the following remarks focus on methodological aspects in fact the spatial patterns of significant trends and their sign are similar to those published in the literature e g sagarika et al 2014 while their interpretation deserves some remark for example ar 1 tfpwcu mk and fgn cpw mk tests on maxima fig 5 tend to give similar number of rejections which is smaller than that of standard mk this contrasts with results often reported in the literature and confirm that they are related to the ineffectiveness of the original tfpw procedure as a variety of hypotheses has been proposed to explain the disagreement between tfpw and other prewhitening procedures in terms of possible physical causes it is therefore instructive to discover that they are pure speculations and results are simply artifacts another important result is the strong decrease of significant trends obtained by iaaft mk the annual seasonal maxima extracted from stationary series reproducing the observed persistence of the daily sequences show apparent trends that are stronger than those resulting from persistent models directly fitted on annual seasonal maxima thus reducing the evidence for deterministic trends in such summary statistics in other words focusing on annual seasonal maxima might lead to underestimate variability and temporal clustering of high low values similar remarks hold for annual seasonal average values fig 6 it should be noted that the residual clusters of positive trends in the new england north west for summer maximum and mean values figs 5 t and 6 t are coherent with the spatial correlation and climate dynamics of that area kingston et al 2007 this does not mean that the new england rivers have not witnessed a possible increase in the last 60 years however it might be explained in terms of spatial correlation as a shared behavior depending on a common meteorological driver acting in an area characterized by quite a uniform response obviously from a practical point of view such an increase raises management problems whose solutions however change if we assume that these changes are deterministic in the sense specified in section 4 or stochastic in fact in the first case we should identify a predictable evolution law making attribution which is unlikely linear or polynomial and cannot be deduced from the data themselves in the form of some arbitrary smoothing function results for the pettitt test in figs 7 and 8 highlight another aspect often overlooked in the literature and related to the fact that both tests rely on the mann whitney statistic and they are theoretically related to each other rougé et al 2013 this implies that standard mk and pettitt often yield similar results in terms of significant changes in a given direction upward downward even if such results are obviously interpreted in a different manner slowly varying monotonic changes and abrupt changes e g sagarika et al 2014 pathak et al 2016 the link between the two tests also implies that both are sensitive to autocorrelation serinaldi and kilsby 2016a and they should yield coherent results when autocorrelation is accounted for a comparison of figs 5 and 6 with figs 7 and 8 supports this conclusion showing that both tests yield similar spatial patterns in terms of significant upward downward changes in this context distinguishing and interpreting slowly varying and abrupt changes can be secondary as it is simply a matter of scales e g rougé et al 2013 this highlights once again the need for attribution based on exogenous information which is not derived exclusively on purely statistical non causal relationships results for iaaft based tests also show the dramatic decrease of evidence for deterministic changes when fluctuations of seasonal annual averages and maxima are influenced by the entire flow process at daily scale therefore even if the autocorrelation of the observed seasonal annual averages and maxima is properly accounted for in ar 1 tfpwcu and fgn cpw trend tests the above results reveal that it is not sufficient and might strongly underestimate the actual persistence of the underlying processes when this is taken into account apparently strong trends changes might become coherent with the intrinsic variability characterizing stationary but persistent processes recalling the discussion about the natural local clustering of significant results due to spatial correlation and testing multiplicity daniel et al 2012 we studied how the number of significant trends globally changes across the conus for the different types of tests i e the different treatment of the autocorrelation fig 9 summarizes the global number of rejections for all combinations of data and tests standard tests especially pettitt generally yield higher number of rejections for maximum values for mean flows there is not much difference between standard tests and ar 1 tfpwcu and fgn cpw versions in all cases iaaft version yields a dramatic decrease of significant outcomes fig 9 also reports the 95 prediction bands continuous red lines of the number of rejections expected over 250 independent trials i e performed tests prediction limits correspond to the 2 5th and 97 5th percentiles of a binomial distribution with parameters 250 and 0 05 i e the number of trials and the rate of successes the diagrams show that iaaft based tests yield a number of occurrences which is almost always consistent with what is expected when a purely random experiment with 5 of probability of success is performed in some cases the outcome is also close to the expected value 250 0 05 12 however the binomial distribution describes the outcome of independent experiments whereas stream flow time series are spatially correlated especially in some specific areas reacting in a similar way to common large scale meteo climatic dynamics cross correlation can be accounted for by simulation however a fast computation which is very accurate in several cases can be performed by using the beta binomial distribution see appendix b considering the 2 5th and 97 5th percentiles of the beta binomial distribution red dot dashed lines in fig 9 the number of significant outcomes always fall within the prediction bands for iaaft based tests while the rate of rejection for ar 1 tfpwcu and fgn cpw tests is less unexpected than under spatial independence in this respect it is worth recalling that the pairwise spatial correlation terms involved in the beta binomial parametrization refer to the spatial correlation of seasonal annual averages and maxima therefore stronger correlation and over dispersion is expected if the spatial correlation of daily series is taken into account it should also be noted that the estimation of the spatial cross correlation is affected by temporal correlation katz and brown 1991 hamed 2009a 2011 accounting for these aspects results in stronger spatial correlation and further increase of over dispersion this implies wider prediction intervals of the number of significant outcomes and thus even less evidence for global field significance these results confirm the dramatic impact of the spatial correlation on field significance douglas et al 2000 and the double effect of the autocorrelation on local trend detection and estimation of spatial correlation if we also consider that autocorrelation is a non optimal measure of dependence implying systematic underestimation of the actual intensity of persistence as shown above it can be concluded that we often strongly underestimate the actual spatio temporal variability of the processes generating the analyzed data we stress once again that all the above analyses do not allow any conclusion about the actual stochastic or deterministic nature of the observed trends results only tell us that a stochastic stationary representation cannot be excluded and several results reported in the literature simply depend on the choice of an unrealistic stationary option iid as a null hypothesis in other words observed trends are consistent with both a stationary and nonstationary assumptions when we choose a suitable and more realistic stationary benchmark the choice between the two modeling options depends upon a stringent process of attribution supported by additional information and the clear identification of a cause excluding any reasonable alternative explanation this process goes beyond the application of trend tests or detection of statistically significant correlation with other hydro meteorological variables by nhsts which we recall suffer logical flaws and are not devised for exploratory studies 7 discussion and conclusions published trend analysis in hydro meteorology often consists of a superficial application of statistical tools such as nhsts as cookbook recipes this attitude is further spread by the availability of powerful statistical software implementing the state of the art of statistical methodologies developed by statisticians but also questionable procedures developed by practitioners as already highlighted by von storch and zwiers 2003 this approach is particularly dangerous for anyone who is not sufficiently acquainted with the basic concepts of statistics moreover software availability also promotes the tendency to jointly apply combinations of sophisticated techniques often obscure redundant or even contrasting with each other that compound and amplify the problems caused by the indiscriminate use of recipes von storch and zwiers 2003 p 97 since every hydro meteorological record is the only available realization or trajectory of the underlying process this prevents the application of confirmatory analysis because any statement or null hypothesis cannot be contested with a statistical test since independent data are unavailable no statistical test regardless of its power or complexity can overcome this problem because it is not a matter of methodology but of available information the only possible solution is extending this information by additional data going backward i e collecting paleo data sets or forward i e awaiting the availability of new data to test theories in this respect the use of physics based models can partly help e g poppick et al 2017 however even such models can never be fully validated disproved as we do not know if they capture all the important properties of the physical processes and thus the answers given by such models could simply be spurious a rigorous attribution is required to attempt the identification of unique causes and exclusion of any other plausible alternative based on the above discussion the actual meaning interpretation and limits of trend tests should be recovered as every statistical test trend tests can be valuable tools in appropriate contexts while they cannot be an appropriate tool to infer nonstationarity they can at most be used as mere tools for preliminary screening whose outcome should be carefully checked and complemented with exogenous information if a clear physical mechanism related to a predictable evolution of the properties of the process at hand is not identified we cannot make conclusions about the reason of rejection or lack of rejection since multiple factors not included in the null and alternative hypotheses can actually play a role the case study presented in this paper shows the dramatic difference resulting from the use of trend tests involving different dependence structures namely unrealistic independence ar 1 and hk dependence estimated from the target annual summary statistics and empirical dependence of target variables resulting from that of the parent daily process we stress that our discussion and these results do not support stationarity versus nonstationarity dependence is only used as a more realistic and challenging alternative to deterministic trends in order to show that nhsts are actually inconclusive when we compare two options yielding similar observations and a decision concerning the generating mechanism of the studied process and its modeling cannot rely on data only since trend tests are also used as automatic criteria to justify the use of nonstationary models for frequency analysis we discourage such a kind of cookbook recipe usage as it is inappropriate and might lead to unreliable and paradoxical predictions serinaldi and kilsby 2015 of course nonstationary modeling is still legitimate when it is justified by preliminary attribution relying on additional deductive information on the cause of time dependent behavior it should also be noted that this study does not focus on the interpretation of the physical meaning of probability e g frequentist or bayesian approach to data analysis but on the role of inductive and deductive information and reasoning in the scientific inferential procedure following christakos 2011 pp 177 181 the knowledge bases can be classified between two major categories general or core denoted by kb g and specificatory or site specific kb s whereby the former may include scientific theories natural laws phenomenological models cultural relations and long established worldviews while the latter considers different sources of evidence that are tied to the particular local situation and may be not of general validity i e exact and inexact uncertain measurements and records this study shows how a mechanistic application of tests and models involving only kb s is not sufficient to draw conclusions on stationarity or nonstationarity regardless of the complexity or refinement of the analysis tools but seem to be the only source of information used in much literature on the other hand we emphasize the fundamental role of kb g that being based on wisdom of the past seems to be irretrievably lost in the postmodern world christakos 2011 p 179 in this respect how kb g and kb s are blended is a secondary aspect although bayesian framework offers attractive tools to perform a synthesis christakos 2011 pp 375 380 trend tests may be tools for very preliminary screening for example in large scale analyses involving e g large number of time series concerning data quality control where we are interested in detecting time series affected by systematic instrumental errors in these cases we know a priori the mechanism generating nonstationarity i e instrumental malfunction and its possible effects and an unambiguous attribution can be made from the knowledge of the instrument specifics in other cases rejections can be used to identify primary sub sets deserving further investigations for a clear attribution of the origin of the detected inhomogeneities however lack of rejection does not authorize the conclusion that nothing is happening in the remaining subset which should be further analyzed in any case other conclusions in this exploratory context go beyond what the trend tests can tell us acknowledgements fs and cgk were supported by the engineering and physical sciences research council epsrc grant ep k013513 1 flood memory multi event modelling of risk and recovery and willis research network information on hcdn 2009 data used in this study can be found at the web site http water usgs gov osw hcdn 2009 while the data set is freely available at http waterdata usgs gov nwis sw the authors wish to thank three anonymous reviewers for their remarks and constructive criticisms and prof hans von storch helmholtz zentrum geesthacht germany for his useful comments on an earlier version of this paper the analyses were performed in r development core team 2016 appendix a bias correction for the maximum likelihood estimates of h tests involving prewhitening based on fgn correlation structure require the estimation of the hurst parameter h it is well known that h is difficult to estimate especially for short time series koutsoyiannis and montanari 2007 following hamed 2008 for fgn cpw and fgn unconditional prewhitening fgn upw versions of mk and pettitt tests serinaldi and kilsby 2016a h is estimated by the maximum likelihood ml method mcleod and hipel 1978 mcleod et al 2007 which was proven to be more accurate tyralis and koutsoyiannis 2011 than other estimators relying on graphical diagnostic plots see e g serinaldi 2010 nonetheless residual bias affect ml estimates as well even though we showed that the direct assessment of persistence on summary statistics such as seasonal annual averages and maxima might lead to underestimation of persistence in any case it is worth adjusting the ml estimation bias in order to reduce the problem bias correction was defined based on an extensive monte carlo simulation using 10 000 random samples drawn from a fgn process for each combination of h between 0 5 and 0 99 by steps equal to 0 01 and sample size n ranging from 20 to 250 by steps equal to 5 the left side panels on fig 10 show a map and two projections of the surface describing the bias of the ml estimator as a function of h and n the correction involves two stages first the dependence of bias of h and n is adjusted by a rational polynomial of the first order and second the residual dependence on h middle column of panels in fig 10 is removed by a four order polynomial the right side panels in fig 10 show that procedure yields a final residual bias lower than 0 01 i e one order of magnitude lower than the original bias for all combinations of h and n the resulting bias correction formulas are a 1 h unb 0 826 3 889 h i 10 94 h i 2 10 91 h i 3 4 06 h i 4 where a 2 h i 3 40 n 92 674 271 609 n 77 280 98 470 n 156 590 96 862 n 240 783 h ml in which h ml is the original ml estimate and h unb is the corrected output appendix b beta binomial distribution the beta binomial bb distribution is a compound distribution resulting for the ordinary binomial distribution f k n k p k 1 p n k where p 0 1 represents the constant probability of a success in n trials when p is assumed to be no longer constant but fluctuating according to a beta distribution function f p p α 1 1 p β 1 b α β where b denotes beta function and α and β are two positive shape parameters the bb density function can be written as skellam 1948 b 1 f k n k b k α n k β b α β letting π α α β the mean and variance of beta binomial can be written as ahn and chen 1995 b 2 e k n π and b 3 var k n π 1 π 1 n 1 ρ bb where ρ bb 1 α β 1 is known as the intra class or intra cluster correlation being positive by definition ρ bb gives rise to over dispersion as it inflates the variance n π 1 π of the original binomial distribution with constant p on the other hand ρ bb does not affect the expected value which is identical for both bb and standard binomial for correlated experiments ρ bb j k ρ jk n n 1 where ρ jk denotes the pairwise correlation between experiment site j and k in the context of this study ρ bb is therefore the average cross correlation between the time series recorded across the conus area which is 0 04 this is the value used to compute the prediction limits reported in fig 9 it is worth noting the impact of ρ bb despite its apparently small value 
891,studies on the food energy and water few nexus lay a shared foundation for researchers policy makers practitioners and stakeholders to understand and manage linked production utilization and security of few systems the few nexus paradigm provides the water community specific channels to move forward in interdisciplinary research where integrated water resources management iwrm has fallen short here we help water researchers identify articulate utilize and extend our disciplinary strengths within the broader few communities while informing scientists in the food and energy domains about our unique skillset this paper explores the relevance of existing and ongoing scholarship within the water community as well as current research needs for understanding few processes and systems and implementing few solutions through innovations in technologies infrastructures and policies following the historical efforts in iwrm hydrologists water resources engineers economists and policy analysts are provided opportunities for interdisciplinary studies among themselves and in collaboration with energy and food communities united by a common path to achieve sustainability development goals keywords few nexus process system technology policy water resources 1 introduction the production utilization and security of food energy and water few are inextricably linked as global demand for few resources continues to increase supplies of these interconnected resources are becoming less secure hence in a timely manner the global research communities have united their efforts to study the few nexus in a holistic framework with an aim to address sustainable development goals sdgs recently proposed by the united nations bhaduri et al 2015 leck et al 2015 ringler et al 2013 it has been argued that the sdgs are not well integrated especially with respect to the few nexus weitz et al 2014 the few nexus paradigm is building up a common podium for researchers policy makers practitioners and stakeholders from energy food and water sectors to understand and resolve various complex issues linking the three sectors bizikova et al 2013 hoff 2011 these issues include resources allocation infrastructure investment socioeconomic development and environmental conservation as water researchers come together with food and energy research communities we share a working context that is broader than ever before and our community faces many research questions how can water researchers contribute to few system understanding and management based on our existing experiences and skills in what ways can we extend methodologies traditionally used to analyze water systems to now evaluate few systems on what specific issues can water researchers collaborate with those from energy and food sectors for hydrologists how will fundamental hydrologic processes influence or be influenced by processes of other sectors for water engineers and policy makers what will be the new directions for technology infrastructure and policy development as few understanding improves these questions motivate this perspective paper as we attempt to elucidate how water researchers and practitioners can uniquely contribute to emerging transdisciplinary few nexus literature the idea of integrated resources management is not new to water researchers dating back to the harvard water program maass et al 1962 there has been a call for researchers to study water within an interdisciplinary framework to understand water s multifaceted connections with human society and the environment since then advocacy for interdisciplinary water research has been pervasive actually the aim of few nexus studies which is to improve system efficiency pursue sustainability and increase system performance through holistic understanding and management of resources mirrors the objectives of integrated water resources management iwrm biswas 2004 iwrm is defined as a process which promotes the coordinated development and management of water land and related resources in order to maximize the resultant economic and social welfare in an equitable manner without compromising the sustainability of vital ecosystems global water partnership 2000 iwrm has been recognized as a key tenant of sustainable development by the united nations united nations 2012 and has been promoted by many leading international agencies hering and ingold 2012 nonetheless iwrm has not been implemented as widely as expected and has been criticized as a recipe for paralysis merrey 2008 and having the desire to do too much at one time schreiner and hassan 2011 hering and ingold 2012 proposed that moving forward requires setting bounds for integration and that transsectoral integration may nonetheless be required if the identified deficits are derived from activities based outside the water sector in fact iwrm has highlighted the linkage between water food and energy security hoff 2011 in contrast to iwrm we argue that the few nexus approach has a clearer scope of integration since it explicitly sets the sectoral bounds i e food energy and water resources of integration whereas iwrm attempts to integrate seemingly all resources and objectives related to water which is often subject to institutional barriers grigg 2008 mohtar and lawford 2016 moreover the three pronged emphasis of few may engage government agencies and other important stakeholders that have been reluctant to fully adopt iwrm since water related issues are not their chief concern or mandate and thus present a broader solution space not necessary centered around water which allows the cross pollination of ideas and integration of solutions across disciplines the nexus approach can also make the objectives of iwrm more palatable to stakeholders across political boundaries as is necessary in transboundary river basins since few does not require all solutions align with water management grigg 2008 thus under the scope of few iwrm s broader goals of efficient resource management synergistic thinking and equitable tradeoffs may seem more tenable to a wider set of stakeholders particularly those whose primary interest lie in the agriculture and energy sectors in addition iwrm achievements in solving a country s key water related development problems are limited due to the lack of innovative approaches biswas 2008 on the other hand few has inspired numerous research interests and efforts from both academic and practical communities in developing novel approaches and methods including models decision making theories and methods and technologies e g via the innovation in food energy and water systems infews program a research program initialized at the u s national science foundation nsf eventually we expect that the few nexus paradigm will refine and focus the scope of iwrm and provide water communities specific channels to move forward and collaborate with food and energy communities on many shared iwrm issues there are already a number of review and perspective papers on the few nexus in the literature a few are named here because of their close relevance to the background of this paper hoff 2011 presented the background paper for the bonn2011 conference the water energy and food security nexus which provides a comprehensive perspective on the few nexus for the first time including a discussion on the necessities and opportunities in few nexus studies and knowledge gaps in relevant science technology and policy areas the paper extends traditional food security perspectives to the nexus of security of food energy and water sectors to improve resource use efficiency mitigate tradeoffs build synergies and improve governance across sectors webber 2015 contended that the few nexus perspective is especially critical in regard to large infrastructure investments which are difficult to adapt should they prove counter productive across sectors webber also illustrated the connectedness of few systems through key examples of cascading failures in few systems highlighted synergistic technical solutions and acknowledged the lack of integrated policy implementation more recently scanlon et al 2017 called for extending the power of the scientific community to develop innovative prescriptive recommendations and adaptation pathways to deal with resources scarcity the authors highlighted the need for local and global nexus measurement and monitoring resource conservation technology to enhance supplies decision making techniques to deal with tradeoffs and more efficient storage transport and trade of few resources to satisfy the demands at the global scale the purpose of this perspective paper is to help water communities identify articulate utilize and extend our disciplinary strengths within the broader few communities while also informing scientists in the food and energy domains about the unique skill set we bring to address the few nexus we identify few relevant issues that water scientists face and discuss the existing and new methods to address those issues organizing our insights as pertaining to processes systems technologies or policies as displayed in fig 1 we illustrate that research on the few nexus must progress our understanding of the interactions of connected water and food and water and energy processes and systems and promote innovative water centric technologies infrastructures and policies toward the co benefits of few systems first however we present our vision of the few nexus in the following 2 vision of few nexus many review and perspective papers e g biggs et al 2015 keairns et al 2016 perrone and hornberger 2014 have provided varying definitions of the few nexus since a consensus has yet to be established we share our perspective of the form and scope of interconnected few systems illustrated in figs 2 and 3 the few nexus can be characterized by the following three forms of interactions i physical biophysical and chemical ii resource input output and iii via institutions markets and infrastructure first food energy and water are governed by separate but interconnected physical biophysical and chemical processes as displayed in the outermost linkages of fig 2 the processes that connect food energy and water drive the dynamics and performance of not only the individual systems but also the integrated system via mass and energy heat exchanges between the boundaries of each resource it should be noted that among the three sectors water is most directly subject to major natural variability which then drives much of the variability in other sectors ray et al 2015 scott and sugg 2015 additionally water is largely controlled by a physical boundary i e aquifers river basins while food and energy sectors have a stronger human influence shaping their spatial boundaries e g people decide where to grow food and build electricity transmission lines second food energy and water are critical inputs of production to the other resources as illustrated by the input output relations in fig 2 the inner interactions between the three sectors of the circle besides the input output interdependence these sectors also compete for few resources at local and regional scales e g energy and food production compete for water supplies water treatment and food production storage and shipment compete for energy supplies in particular water often acts as the limiting resource that dictates system outcomes especially in arid and semi arid regions and regions with extraordinary water demand falkenmark and molden 2008 gleick and palaniappan 2010 in fact two thirds of the world s population faces severe water scarcity at least one month of the year mekonnen and hoekstra 2016 third food energy and water are regulated by separate administrations markets and engineering infrastructure which often overlap and interact but do not fully integrate their efforts due to differing approaches objectives and institutional settings the effectiveness of any solution for a specific few nexus problem depends on how these independent entities coordinate with each other furthermore each of these three characteristic interactions the interconnected processes resources supply and demand and institutions markets and infrastructure can be influenced by technological innovations environmental changes and socioeconomic conditions system analysis starts with defining the system and specifying the spatial and temporal dimensions the few nexus exists at various spatial and temporal scales depending on the problem spatial scales can vary from microscopic to field farm or household to regional and global levels the mesoscale is shown in fig 3 likewise temporal scales can vary from seconds e g flow rate to daily e g systems operations to mid and long term horizons e g resource and infrastructure planning and development policy development and socio economic and environmental ramifications following iwrm we argue that the river basin or watershed can be used as a fundamental scale because food and energy can easily be transferred from distant locations to bolster regionally scarce resources or temporal variability of these resources while the spatial incongruence between water supplies and water demand cannot be as easily resolved davis et al 2016 in fact water is largely restricted within its natural boundaries although limited inter basin water transfers occur while the bounds of food and energy systems are chiefly delineated by humans and are thus more suitable for change nonetheless we must acknowledge that basin approaches often do not align with economic or social boundaries in many countries or regions especially where there is no river basin management authority and thus the suggested basin actions may be difficult to implement grigg 2008 hagemann and kirsche 2017 argued that a basin or sub basin scale that was used for the iwrm approach might not be an appropriate scale for the few approach therefore an appropriate scale or spatial unit for few nexus analysis and management may need to adhere to a particular society s needs of water energy and food as critical supplies for both human and natural systems moreover cross scale issues are a challenge for few system analysis because few processes system design and assessment prevail at different spatial and temporal scales it is particularly difficult for researchers to integrate information across the few nexus watkins et al 2015a to create tiered temporal and spatial interventions that account for and manage feedbacks across the few sectors hill and engle 2013 to mitigate environmental impacts over appropriate scales of time and space adger et al 2005 and to assess tradeoffs and synergies crossing scales davis et al 2016 kauneckis and andersson 2009 oates and portney 2003 given our few vision as described above the rest of this paper discusses knowledge gaps and research potentials for water resources researchers and the opportunities for collaboration with food and energy communities with respect to processes systems technologies and policies 3 interconnected processes considering the above vision of the few nexus a critical element of few system understanding is knowledge of the underlying individual processes and their connectedness some issues that have traditionally been addressed as water resources development and management problems are truly part of a larger interconnected few system and should be addressed as such the analyses of those issues such as irrigation water and wastewater treatment water supply hydropower or thermoelectric cooling have been largely based on hydrologic science and engineering principles yet these issues are pertinent to the food and energy sectors as well furthermore recent progress in eco hydrology and ecosystem restoration practices have provided deeper understanding of interactions between water and ecosystem services bakker 2012 especially those for food and energy production e g flow regime and water quality for aquatic fish habitats and water requirement for biomass production christian smith and merenlender 2010 palmer 2009 richardson et al 2011 to integrate understanding of the hydrologic cycle and its processes with understanding of few systems many outstanding issues connecting hydrologic processes to those in agriculture and energy areas must still be addressed in the following we identify knowledge gaps from a water perspective between water and food and between water and energy although the few nexus approach emphasizes the interactions of the three sectors we argue that there are still many knowledge gaps and research challenges in understanding the one to one process interactions and gaps which prevent the characterization and quantification of the nexus relationships 3 1 processes connecting water and food sectors 3 1 1 water to food hydrologic processes of precipitation evapotranspiration and flow in porous medium are all integral to agriculture production in particular despite extensive study by ecologists and hydrologists understanding crop evapotranspiration a fundamental process dictating crop water requirement allen et al 1998 has remained a research need particularly under climate change and environmental change e g variations in soil salinity droogers and van de giesen 2010 nistor et al 2017 in order to improve various stages of crop growth irrigation and drainage engineering measures are widely applied for manipulating soil moisture yet these practices are now challenged by more frequent and intense extreme weather events droughts heat waves and floods due to climate change numerous recent studies have revealed complex temporal and spatial variability in precipitation for example in the corn belt the shifting seasonality of rainfall pal et al 2013 wuebbles and hayhoe 2004 a tendency for a greater percentage of rainfall to occur during extreme events kunkel et al 2012 alternating periods of excessive wetness and dryness orlowsky and seneviratne 2012 and the impact of land use and land cover change on soil moisture across the region collectively make agriculture decisions more complex e g the crop land traditionally facilitated by drainage infrastructure in the late spring now often requires irrigation in the late summer how to make crops more capable of adapting to frequent and abrupt soil moisture changes via biological and hydrological engineering measures and how such conditions evolve in the future are pertinent research questions for the provision of adequate water for food production although irrigated agriculture often comes to mind when discussing water for food water is also essential for aquaculture an important source of food around the world especially in coastal regions nevertheless relatively little research has been published regarding the connections between hydrology and fisheries gephart et al 2017 though numerous studies have contributed to relating streamflow regime to aquatic habitats e g hydrologic alteration index iha poff et al 2010 collaboration between hydrologists and fishery ecologists is still under the call to develop more ecologically based hydrological indices and more explicit linkages between terrestrial and marine systems endo et al 2017 given the wide and intensive impacts of land and water use activities e g deforestation damming for hydropower etc studies are needed to develop guidelines for watershed management and water storage system operations which consider the interactions between hydrology and aquatic habitats schnier et al 2016 yang et al 2008 3 1 2 food to water agriculture production often uses large amounts of land water fertilizer and pesticide inputs causing major environmental changes in many regions around the world in particular non point source pollution due to extraordinary fertilizer and pesticide use in agricultural production has been a long standing yet unresolved problem for environmental protection and water supply quality for example in the u s midwest grain production and subsequent utilization for animal foodstuffs food processing and ethanol production have pervasive effects on water quantity and quality in downstream environments both locally 95 of waters have elevated nitrogen and phosphorus and nationally e g hypoxia zone in the gulf of mexico epa 2015 nutrient loading in waterways accelerates aquatic vegetative growth disrupts ecosystems and increases water treatment costs in the past society s major concern was water quality in the ecosystems but recently the concern has also been aggravated by the situation of water supply the des moines water works argued in a recent lawsuit that their water supply was adversely impacted by nitrate runoff from three grain producing counties in northwest iowa illuminating how food to water processes can exacerbate tensions between local stakeholders eller 2015 nutrient load problems within the united states have sparked a significant increase in federal natural resource and environment expenditures however there is no conclusive evidence that problems of sedimentation nutrient pollution and biodiversity loss in agriculturally dominated basins have been ameliorated through governmental efforts david et al 2015 2013 research is still needed for monitoring and simulating nutrient stocks and flows in soil woo and kumar 2016 nutrient loading and transport across scales from field to watershed and basin and water quality response to nutrient dynamics under both climatic variability and human interferences e g irrigation and land drainage research is also needed to develop technologies policies and best management practices to reduce fertilizer and pesticide use retain nutrients in soil and extract nutrients from wastewater i e resource recovery cai et al 2013 jarvie et al 2015 as detailed later in this paper agricultural activities also affect natural flow regimes yet the mechanism of the effects has not been well understood return flow from irrigation systems non consumptive portion of water withdrawals complicates flow balance and water use accounting at a basin scale cai et al 2003c and affects water quality de moraes et al 2010 determining return flow especially the utilizable return flow volume is important for not only understanding water balance in streams and aquifers but also determining water availability for the development of more reasonable and sustainable water rights at the river basin scale grafton et al 2012 the usefulness of return flow depends on the path of the flow i e via natural systems such as aquifers and interflow or man made pathways such as drainage systems the time lag occurring in the flow process and its quality all of which are very difficult to monitor and simulate hydrologic heterogeneity and a dearth of data have encumbered the development of inexpensive and widely acceptable methods for quantifying return flow at the river basin level 3 2 processes connecting water and energy sectors 3 2 1 water to energy energy production and supply both from traditional and emerging energy sources is often highly dependent on water supplies it is well known that considerable amounts of water are used for hydro energy generation and cooling within thermoelectric and nuclear power plants yet recently energy generation has been shifting toward unconventional and renewable energy technologies some of which have even larger water requirements compared to traditional thermal power mekonnen et al 2015 notably concentrated solar power requires significant cooling with water use rates often exceeding that of similarly sized coal and nuclear power plants bracken et al 2015 cultivation of biomass and processing to produce biofuels incurs significant water consumption housh et al 2015b song et al 2016 hydraulic fracturing of unconventional hydrocarbons requires 1 4 to 4 times as much water over its life cycle as conventional natural gas clark et al 2013 thus energy production and supply including both the traditional and emerging energy sources can be highly dependent on water supplies furthermore hydroclimatic variability propagates to the interlinked energy system and leads to diminished energy output many power plants or stations must adjust operations in response to extreme water conditions such as droughts and heat waves due to severe water availability and temperature limitations webber 2015 this emphasizes the role of hydroclimatic forecasts especially seasonal forecasts in water energy nexus studies conway et al 2015 perrone and hornberger 2016 3 2 2 energy to water on one hand water supply and delivery depend on energy for example energy use for moving and treating water and wastewater represents over 12 of total u s primary energy consumption sanders and webber 2012 on the other hand water withdrawal for and water discharge from energy generation have caused problems in water quantity and water quality especially for local ecosystems recent development of bioenergy and natural gas facilitated by hydraulic fracturing has brought new threats to water quality and riparian health for example in the u s midwest recent increases in corn based ethanol production have further constrained existing resource allocation i e competing land and water with corn as food and feed crops and threatened the regional environment simpson et al 2008 for many mid sized corn belt cities ethanol plants are the largest water user and discharge the largest quantities of wastewater to local sanitary districts phosphorus concentration in grain processing wastewater is several times greater than that of typical domestic wastewater illinois epa 2015 kim and dale 2005 watkins et al 2015b natural gas extraction creates substantial risk for water degradation with the lingering threat of pollution from transportation spills well casing leaks leaks through fractured rock drilling site discharge and wastewater disposal rozell and reaven 2012 for example vengosh et al 2014 analyzed the published data in the u s through january 2014 and found evidence for stray gas contamination surface water impacts in areas of intensive shale gas development and the accumulation of radium isotopes in natural gas disposal and spill sites thus increasing pollutant loads from new energy generation and distribution pathways have made water quality and environmental problems more complex than before this has stimulated both basic scientific research and technology development for example plant biologists have been exploring the second generation of bioenergy feedstocks that are both efficient in energy production and friendly to the environment mcisaac et al 2010 smith et al 2013 hydrologists can join the effort to assess the water requirement and impacts on water quantity and quality of these second generation feedstocks housh et al 2015b le et al 2011 ng et al 2010 the utility of hydropower remains a longstanding global debate within water resources development wcd 2000 while often proposed for energy provision purposes hydropower dams cause numerous incidental benefits and damages including the benefits for water storage for drought mitigation flood regulation and recreation and damages from disrupted sediment transport and inhibited fish migration also the timing of hydropower demand and other water demands namely irrigation can cause competition between benefits as zeng et al 2017 demonstrated to be the case for over half of globally installed hydropower moreover the green energy label attributed to hydropower may be misguided according to emerging research regarding the greenhouse gas emissions resulting from decomposition in reservoirs gunkel 2009 in light of these findings hydropower research should consider the full scope of few system impacts within dam design and operation in particular balancing the often conflicting requirements of aquatic habitats energy demand water supply and other water uses remains a challenge for the joint work of ecologists hydrologists and water resources engineers especially under hydrologic inflow uncertainty and variability suen et al 2009 yang and cai 2011 mitigating the tradeoffs among a dam s various purposes will require understanding of relevant physical processes such as flow states sediment transport wild and loucks 2014 and hydrodynamic conditions for fish within and downstream of reservoirs xu et al 2017 3 3 highlights of relevance to hydrologic research the few nexus adds new dimensions to classic hydrologic problems as demonstrated in the preceding section also see smajgl et al 2016 however it is not surprising that some classic problems for water scientists will remain and become even more complex in the context of the few nexus in particular quantifying and managing uncertainty is a long standing issue within in the hydrology community rajaram et al 2015 especially that of extreme events such as droughts heat waves and floods hydroclimatic uncertainty propagates to all sectors relying on water as a resource or being affected by water processes e g flooding additional complexity arises from the correlation of the various uncertainty sources from food energy and water sectors and their joint impacts on the performance of the few system leck et al 2015 watkins et al 2015a yang et al 2016b research on hydroclimatic forecasts characterized by forecast horizon and accuracy should consider the specific needs to secure the stability of food and energy production and markets hamlet et al 2002 koch and vögele 2013 exploration of outstanding scale and scaling up issues with few analysis and management as discussed earlier can be based on and extend the knowledge of hydrologic communities blöschl 2001 sivapalan 2003 soulsby et al 2006 advances in hydrologic modeling at large scales such as national continental or global rajaram et al 2015 provide scientific support for few nexus understanding at those scales by providing water availability assessment e g watergap global model döll and schmied 2012 streamflow and flood forecasts e g national water model maidment 2016 and demand and trade modeling of food rosegrant et al 2002 and energy hejazi et al 2015 engineering measures such as long distance water transfer and food and energy markets enhance the few nexus interconnectedness at large scales these expanded nexus relationships at a regional or national scale can impact local water resources development and the hydrologic cycle and thus increase the relevant scale of the local water system e g via inter basin water transfer pumping and lifting or food market that drives virtual water flow in turn regional or national outcomes are impacted by local outcomes that trickle up through interconnections these feedback loops that cross scales offer an exciting avenue for exploration among hydrologists watkins et al 2015a on the other hand some few nexus cases may indeed be confined to a local scale for example treatment of brackish water in coastal areas to irrigate crops and vegetables with high salt tolerance does not interact with a surrounding watershed or sub watershed another research direction arising from the few nexus paradigm and coinciding with the current concern of the hydrologic community is the human dimension of the hydrologic cycle including anthropogenic alterations and hydrologic co evolution with human systems rajaram et al 2015 vogel et al 2015 the inter sectoral connectedness of the few nexus extends the human dimension by involving stakeholders from multiple sectors and introduces more complex tradeoffs and synergies or co benefits among the stakeholders this broader human dimension interferes with the various physical processes and thematically complicates the interactions of human and natural system dynamics recent studies on coupled nature human systems cnhs reemphasize the need to integrate work among researchers in social and physical communities lund 2015 scanlon et al 2017 sivapalan et al 2012 and to link ecosystem services critical to food and energy production with various stakeholder outcomes de groot et al 2010 hein et al 2006 from a water perspective we are concerned with water supply of sufficient quantity and quality for food and energy production and the feedbacks of those water uses to hydrologic processes which reemphasizes the role of hydrology highlighting the interdisciplinary science of water in the context of cnhs as proposed by vogel et al 2015 the above processes and connections make up the complex system discussed hereafter we highlight these processes because they are particularly impactful within few systems and they represent current knowledge gaps as with any complex system few system understanding requires sound knowledge of the underlying processes and connections before the system can be effectively managed through infrastructure technology institutions and policy 4 the unique role of water in few system analysis managing integrated few systems represents a fundamental shift from the traditional but narrow goal of solely increasing benefits derived from either food energy or water resources with limited regard for the other few components instead a system of systems approach targets overall efficiency of few resources utilization and produces synergistic societal and environmental benefits water s foundational role in so many facets of human society as well as natural processes has necessitated systems thinking amongst water researchers for decades brown et al 2015 rogers and fiering 1986 maass et al 1962 as water scientists our long history of system thinking may act as springboard to understanding and managing the complex interdependencies within the few nexus following the discussion on interconnected processes in the preceding section here we address the interactions between food energy and water within a systems context we give special attention to the features and issues within water sub systems that will propagate up to the broader few system and may act as the key driver of few system outcomes broadly we identify sources of system complexity that challenge water resource system analysis and hence few system analysis and demonstrate how water resources systems analysis can be extended to address the complexities with few systems 4 1 interconnectedness circular demands and feedback loops complex few systems are diagnosed and described by their inherent interdependent linkages and feedbacks these system properties may lead to emergent characteristics which arise from the web of interconnections in a complex system kumar 2015 water systems are complex by themselves but many traditional water centric problems may need to be addressed in the context of few systems to avoid unexpected consequences for instance during a severe drought in 2012 kolkata india suffered a major blackout due to the linkages among the regional water and energy sectors webber 2015 in response to the drought farmers increased groundwater pumping in turn increased groundwater pumping placed increased demands on the regional electrical grid meanwhile low streamflow reduced hydropower production ultimately the drought event caused 690 million people to lose power webber 2015 this example illustrates how shocks to the water system can propagate through the food and energy sectors and circulate back to the water system itself identifying and understanding the interconnections that initiate circular demands or feedback loops is foundational to designing and managing overall few system behaviors water scientists have long studied the coupling between water and human systems noting the complicated nonlinear response of water systems to both natural němec and schaake 1982 and human thomas et al 2013 van der zaag and gupta 2008 wang and cai 2010 perturbations the couplings between few components society and ecosystems with nonlinear feedbacks and circular demands may create even more complex patterns of system performance across multiple spatial and temporal scales in particular instances of small gradual changes to either food energy or water resources can emerge as large and even disastrous changes in the overall few system or broader environment this is evident in the aral sea basin where steady increases in irrigated area and hydropower capacity over multiple decades led to a precipitous drop in the aral sea s surface area once a critical threshold of upstream irrigation was reached cai et al 2003b agriculture intensification which was seen in the aral sea basin and typically requires additional water and energy inputs is essential to feed the growing global population godfray et al 2010 yet will agriculture and energy intensification insidiously lead to similar environmental catastrophes in basins around the world will additional demand for water to irrigate food and biofuel crops lead to circular demands for few resources to answer these questions water scientists need to work with food and energy scientists to better understand local interconnected few processes and institutions see section 6 which determine water availability for food and energy production as well as the environmental impacts associated with these water uses additionally we need to understand the telecouplings between local resource use and the distant consumers that are remotely driving the system through the invisible hand of the global market marston and konar 2017 after all in the aral sea basin besides irrigated grains for local consumption irrigated cotton as both a major income source for people in central asia and a mandate for 95 percent of cotton used in the former soviet union was one of the primary water users in the aral sea basin the short term policies and profit driven decision making exhibited in the case of the aral sea basin did not account for externalities associated with extensive irrigation which eventually caused the environmental disaster in the region cai et al 2003b no study within the water resources literature has fully explained the tipping point leading to the sharp drop of inflow to the aral sea and corresponding recession of its surface area beginning in the 1970s and continuing today the aral sea represents a complex few system and highlights a specific instance where joint efforts from water agriculture and energy hydropower in the upstream of the basin communities are needed to explain the nonlinear phenomena and propose solutions to reverse an environmental and socioeconomic disaster 4 2 tradeoffs synergies and system efficiency nexus thinking requires a shift from a singular focus on production maximization to improving system efficiencies capturing synergies and managing tradeoffs the entangled and diverse uses of water have necessitated nexus thinking well before the few nexus came to the forefront of scientific discourse while water scientists past and ongoing work can inform few nexus research the few framework may offer a means for wider implementation of our work through the inclusion and engagement of those that have previously evaded a water centric approach within water systems researchers practitioners and decision makers have long considered tradeoffs of water quality versus water quantity upstream beneficiaries versus downstream beneficiaries and environmental health versus economic production among others in the context of few these tradeoffs become increasingly complicated as more sectors and stakeholders become involved our understanding of water resources is not complete without nexus thinking for example housh et al 2015b showed how adopting a second generation biofuel crop miscanthus in a central illinois watershed will improve biofuel production efficiency and reduce nutrient discharge but increase cost and volume of freshwater consumption compared to the current use of corn as feedstock the few nexus approach allows us to view this issue beyond tradeoffs of water quality vs water quantity and understand the underlying mechanisms that drive system outcomes food and energy markets transportation infrastructure farm management feedstock conversion rates and emerging energy technologies are among the drivers of this system extending our boundaries of analysis will make evident previously hidden and poorly understood tradeoffs dealing with such complicated tradeoffs needs stronger scientific support for the understanding of processes interventions and outcomes and stronger institutional support to balance the benefits of multiple groups of stakeholders in addition positive synergies in integrated few systems can be leveraged to overcome issues that have persistently plagued the water community for example in arid or semi arid areas with marginal water resources e g saline groundwater and wastewater and plentiful renewable energy sources e g solar and or wind power the energy sources can be used for desalination of saline groundwater and treatment of wastewater which can be applied to irrigating high value crops via vertical agriculture vertically stacked layers of farmed land in a building such coupling of water and energy resources for food production and storage purposes can generate synergies by 1 making more effective use of renewable energies given that wind mill and solar panel capacities are not fully used in many regions 2 increasing food production or reducing food waste 3 making marginal water saline water and wastewater useful the potential synergies rising from few systems are informative to water food and energy scientists and to engineers who design particular few systems that fit local resources and socioeconomic conditions issues such as cost effectiveness environmental impact and social impact see section 6 for more discussion must be addressed via few system analysis however the expected synergies in few systems can be weakened or even replaced by tradeoffs under changing environmental and social conditions within water resources multi purpose reservoirs provide one such example dams are often designed to serve multiple purposes including hydropower fishing irrigation public water supply among others during design objectives such as energy production and crop irrigation are balanced so as to meet the immediate needs of those reliant on the dam s water releases however years of continued damming of upstream waters land use change and climate change have altered hydrologic regimes as well as the timing of water requirement for hydropower and food production zeng et al 2017 thereby impacting the dam s operational synergies moreover changes in societal values regarding the environment and fish habitat have called into question previous water allocations marston and cai 2016 natural and societal change is unavoidable and seemingly happening more rapidly working together few researchers can make the food energy and water sectors more resilient to future changes by designing adaptable infrastructure and utilizing excess resources from each sector an example of this is conjunctive water use cu and managed aquifer recharge mar which stores excess water in depleted aquifers that can be extracted later to irrigate food or biofuel crops during drought scanlon et al 2016 further technological innovations paired with forward looking policy can lead to additional few synergies and make each sector more resilient to variability in natural and humans systems see section 5 for more discussion increasing water use efficiency amongst the energy and food sectors the two largest water users globally has been a long term effort in water science and technology communities however improving water use efficiency does not necessarily lead to better system performance when considering broader or different few objectives within the few nexus even the conceptual basis of efficiency must be reevaluated for instance closed loop thermoelectric cooling is considered more efficient than open loop cooling because it withdraws approximately 95 less water however closed loop cooling can consume nearly 60 more water than open loop cooling denooyer et al 2016 improving irrigation efficiencies may reduce water applied to crops but additional energy inputs are needed to pressurize more water efficient irrigation systems moreover measures of efficiency are highly dependent on the boundaries of analysis water efficiency improvements at the site scale may have little effect on basin efficiency defined as the ratio of beneficial water consumption over total water consumption within a basin since return flows from inefficient water users can be utilized downstream for food production hydro energy generation and other purposes cai et al 2003c 4 3 systems analysis techniques there is no singular method or clear best practice for understanding highly complex systems shalizi 2006 indeed several system analysis techniques that have been developed in the water sector can be extended for even more sophisticated analysis of few systems first water researchers have employed several approaches to evaluate water related tradeoffs in a holistic manner for instance mathematical programming yang et al 2016a including multi objective optimization hurford and harou 2014 and water management simulation models perrone and hornberger 2016 have been employed to create tradeoff frontiers between water supply and quality food production power generation social outcomes and environmental health this permits decisions makers and other stakeholders to visualize nexus outcomes and consider non economic goals alongside profits from water supply food production and power generation jägerskog et al 2013 embedded resource accounting approaches such as life cycle assessment and footprint assessment methods can also reveal the hidden linkages between few resources and the tradeoffs and synergies throughout the value chain gerbens leenes et al 2012 marston et al 2015 computable general equilibrium cge models with an ecological sector have been used to establish tradeoffs between economic benefits and the environment llop and ponce alifonso 2012 finally stochastic optimization techniques that have been developed for hydropower operation under hydroclimatic variability and uncertainty labadie 2004 yeh 1985 can be extended to a larger system of multiple complementary energy sources and water users under changing and uncertain environmental and socioeconomic conditions cai et al 2009 few systems interact not only in the physical environment but also the socio economic environment which requires appropriate modeling tools to analyze the interactions between natural and social systems hydro economic models cai 2008 harou et al 2009 integrate essential hydrologic and economic relationships in a consistent model to analyze the interactions between water supply water demand and economic policies such an approach can be naturally extended to few systems by adding physical economic relations of food and energy e g cai et al 2003a more recently water resource researchers have applied system of systems models to analyze the multi dimensional tradeoffs and synergies among the water food and energy sub systems housh et al 2015a agent based modeling abm is gaining traction within the water resources research community as it can be particularly useful in representing diverse human actors hu et al 2017 likewise abms are promising for few systems analysis due to the ability to represent heterogeneous behaviors among multiple stakeholders furthermore abms are often coupled with natural process models to address the interactions between human and natural dynamics for instance ng et al 2011 studied land allocation between food and biofuel crops and its impact on hydrologic flows and water quality in general the framework of coupled natural human system cnhs is well suited to few analysis to simulate the dynamic feedbacks between natural system mainly with water and human systems with stakeholders from all sectors elshafei et al 2015 finally networks depicting connections among processes state variables and fluxes known as process networks can provide a highly informative snapshot of the state of a complex system kumar 2015 which has been illustrated in water systems but have not yet been applied specifically to few system analysis to the authors knowledge for example the work of ruddell and kumar 2009a 2009b demonstrate the ability to produce process networks from time series data for a complex eco hydrologic network and should serve as proof of concept worth pursuing further in the few context another systems modeling method system dynamics has been used to study the behavior of complex non linear systems in water resources but it has not yet been utilized in few system analysis to its full potential halbe et al 2015 mirchi et al 2012 each of the above methods has proven valuable in a small sample of hydrologic and water resource systems applications and warrant further extension by water scientists in collaboration with food and energy scientists to diagnose and describe linkages feedbacks and emergent characteristics in few systems thereby advancing few understanding 5 technology development in the context of few systems few relevant water technologies and infrastructure design are rapidly advancing enabling new synergies and improved overall system efficiency water infrastructure is inherently relevant to the few nexus since it is often purposed to meet the water demands of the energy and food sectors yet water technologies and infrastructure design often do not consider few interdependencies bazilian et al 2011 webber 2015 currently there are 3700 large dams planned or under construction globally zarfl et al 2015 constituting a critical opportunity to incorporate broader few system outcomes when planning constructing and operating these new dams new water infrastructure and technologies should aim to increase total few benefits not just those derived from water amongst a wide range of stakeholders including the environment here we review a few key advancements in water technology and infrastructure highlight the ability of system designers to reimagine existing technology and warn of the surprises which may arise if implementation does not fully account for few system complexity 5 1 technology innovations many water technologies and infrastructure designs offer avenues to reduce tradeoffs enhance efficiencies or improve reliability within the few system for instance advancements in both multi stage flash distillation and reverse osmosis technologies have increased the energy efficiency of desalination plants thereby reducing the energy versus water tradeoff khawaji et al 2008 development of drought tolerant crops tester and langridge 2010 can mitigate water shortage vulnerability and also save energy for irrigation systems other examples include the use of saline water to irrigate some salt tolerant crops rozema and flowers 2008 reuse of wastewater after cost effective treatment becerra castro et al 2015 haruvy 1997 use of food waste for bioenergy production using low environmental impact technologies lin et al 2013 uçkun kiran et al 2014 another pathway to few savings has been the shift toward utilizing waste as a resource recently spearheaded by wastewater engineers in particular water reclaimed at treatment plants is used for thermoelectric power generation or to irrigate food and biofuel crops dong et al 2016 wastewater treatment systems have demonstrated the economic feasibility of recovering thermal energy for heating organic compounds which are incinerated for energy production and nutrients used to fertilize crops hering et al 2013 with innovative resource recovery technologies the environment and downstream water users benefit from improved water quality while farmers who apply captured phosphorus and nitrogen from wastewater to their fields can benefit from increased crop yields and reduced fertilizer cost however water scientists must beware of the few example investigated by rajagopal 2008 for example where societal benefits unexpectedly decreased as wasteland was converted into agricultural land for biofuel development as it turned out what planners had viewed as wasteland was actually a valuable resource for an overlooked community serving as a source of fuel and food for local impoverished peoples rajagopal 2008 as food energy and water operations are further integrated new opportunities may emerge for water scientists to utilize food and energy system waste or to redirect water system waste to systems where it may serve as a resource though limited some studies and projects have extended the evaluation of water technology and infrastructure to include the cascading effects throughout a few system villarroel walker et al 2014 evaluated the effects of four water sector technologies on the metabolism of the city of london the city s intake and output of nutrients energy and water through multi sectoral systems analysis they show which combinations of technologies are preferred for various resource conservation priorities villarroel walker et al 2014 there is also evidence that decentralized small scale water storage and hydropower schemes may sustainably balance the multiple objectives of food water and energy security in developing countries van der zaag and gupta 2008 decentralized approaches have been shown to provide greater access to energy and water for food production amongst smallholder farmers who produce most of low income country s food supply ifad 2013 stevens and gallagher 2015 furthermore the stronger coupling between local stakeholders and water infrastructure may provide additional few synergies such as applying dredged nutrient rich river sediments to cropland to boost food production which simultaneously extends the life of the dam lembke et al 1983 moving forward water resource system analysts must increasingly account for interconnected few processes and systems when evaluating technology and infrastructure the growing capabilities of technologies such as remote sensing geographic information systems gis low cost sensors and smart phone applications can provide critical data concerning few systems and may help water researchers accomplish this more integrated analysis for example data collected from aging water infrastructure retrofitted with smart sensors can inform more flexible operating procedures and improved decision support visualization ultimately leading to more efficient use of few resources and environmentally friendlier operation while developing these advanced data tools some fundamental questions must be addressed how can the resource use of heterogeneous and fragmented users be monitored and measured how can information describing human processes institutions and stakeholder behaviors in different sectors be paired with physical and ecosystem data in a meaningful way what data are needed to understand the spatial and temporal evolution of few systems as answers to these questions are developed and more data sensing capabilities are harnessed water and few system analysts will be empowered to more fully understand few system complexity and thus guide future technological and infrastructural investments 5 2 systems design the few nexus will also allow water engineers new freedom to combine existing technologies and infrastructures in new ways for an improved overall few system garcia and you 2016 especially traditional water uses technology and infrastructure can be reimagined i e system re design to exploit synergies within the broader few system the incorporation of interdependent food energy and water processes in design opens opportunities to improve resource use efficiency and achieve synergistic societal benefits one case is to reduce the energy required to supply clean water by integrating engineered water treatment and natural watershed management for example biofuel production from herbaceous perennial crops in marginal agricultural land can reduce sediment and nutrient runoff nelson et al 2006 thereby improving water quality and reducing the need for energy intensive water treatment before human consumption another case is to couple the production of multiple energy sources given different weather conditions and the timing of energy demands wind solar and hydropower can be coupled to increase energy supply reliability for example general electric recently began an initiative to use massive wind turbines to pump water for storage at the top of a hill when electricity is needed water is released downhill and run through a hydropower generator in essence water is used as a battery to store excess power from wind turbines this is an extension of pump and hydropower generation where water is pumped to elevated reservoirs at night when energy demand is reduced and the water is released and its energy captured during the day when the electricity and water demand are higher grumet 2016 in addition viewing issues traditionally thought of as water problems e g floods through the lens of a few system will reframe how we manage design and set policies to handle water issues for instance coastal flooding and erosion are typically mitigated by structural e g dykes groins or policy measures e g flood insurance yet what would flood resilience look like within the context of few one example can be seen in small island nations where the rehabilitation of mangrove habitats not only better protects local populations from coastal flooding and erosion but also improves water quality and produces food with minimal disruption to water and energy supplies biggs et al 2015 many important synergies such as in the examples above are only accessible to system designers if food energy and water systems are analyzed and managed collectively water researchers and practitioners must design unorthodox solutions such as this in the face of increasingly limited few resources 5 3 externalities of technology development new technologies and systems often require tremendous investment to develop and implement and such investments may be wasted or even cause additional problems if they are not guided by an adequate understanding of few system complexities webber 2015 therefore systems analysts in water and other sectors have a tremendous responsibility to guide technology development and infrastructure design with deepening understanding of few system complexities instances of misapplied technology leading to unintended consequences and surprises are abundant for water scientists a classical example is the increase of water consumption in response to improved irrigation technologies this phenomenon known as jevon s paradox indeed occurs in the energy and food sectors as well ceddia et al 2013 dumont et al 2013 freeman et al 2016 ward and pulido velazquez 2008 as another example water recycling or reuse projects can improve water use efficiencies but also have unintended consequences across the nexus in egypt continual recycling and reuse of irrigation runoff had negative effects on water quality throughout the country s irrigation network the water became more saline and polluted as it was recycled reducing crop yield in addition the upstream downstream dynamics of water recycling created issues of unequal access for egyptian farmers barnes 2014 thus two intuitive solutions to water resource scarcity improved efficiency and resource reuse must not be pursued hastily but through careful consideration of their broader impacts across the few system and society at large these examples also provide impetus for developing adaptive water management techniques even the most carefully considered plans may yield surprising outcomes given the complexity of few systems and adaptive management techniques could enable water managers to change plans as new knowledge is gained pahl wostl 2007 for example when the northwest power act was passed in 1980 mandating the sustainable balancing of hydropower development and fish conservation the columbia river basin fish and wildlife program crbfwp initiated an adaptive management strategy the crbfwp immediately began taking mitigation measures but also created systems to measure the impact of habitat enhancements on salmon spawning rates as they were employed thus the crbfwp was able to continuously learn and adapt its management strategies lee 1989 lee and lawrence 1986 in general infrastructure design and the application of technology based on understanding only input output relations or other individual processes may be misguided regarding certain overall system characteristics kumar 2015 as understanding of few system complexity improves unintended outcomes of technology and design can be avoided more successfully 6 governance and institutions from water to few system over the past several decades different institutional frameworks and governance regimes have been proposed to improve water management particularly through integrated and multi sectoral coordination meinzen dick 2007 pahl wostl et al 2010 considering iwrm as one of the latest examples the introduction of iwrm was recognized as an attempt for policy integration across sectors embracing the inherent complexity of the managed system grigg 2008 pahl wostl et al 2012 in fact iwrm was developed based on the premise that governing water land and other related resources in an integrated manner is essential to effectively address problems such as equity economic efficiency and ecosystem sustainability global water partnership 2000 hagemann and kirschke 2017 similarly in terms of the few nexus the overarching governance issue is that policies are fragmented across food energy and water sectors hanlon et al 2013 and a political process requiring negotiations among the different actors representing different sectors is needed to improve cross sectoral policy integration weitz et al 2017 failing to consider the connections among sectors in few governance either in policy analysis or in implementation therefore could result in unintended consequences and worsen the overall resource security bizikova et al 2013 while some researchers cast doubt about the effectiveness of iwrm in its implementation biswas 2008 hering and ingold 2012 pahl wostl et al 2012 we would argue that the progresses made in water institutions governance and science policy interfaces especially the lessons learnt from iwrm implementations could in fact benefit addressing the rising institutional challenges with few systems however it also should be noted that with a paradigm shift from water governance to few governance new challenges and opportunities will emerge this section reviews and discusses how water management institutions can contribute to and be reshaped for efficient and sustainable management of few systems 6 1 relevance of outstanding water policy issues to the few nexus over the years water researchers have identified different policy issues and proposed corresponding technical and institutional mechanisms to address the issues among them social equity has been a great concern appearing in the various water governance frameworks in fact social equity is one of the main pillars of iwrm along with economic efficiency and environmental sustainability grigg 2008 peña 2011 peña 2011 argued that assessing social equity in water management should go beyond the water sector and be addressed in the context of equity for all relevant groups in the society by considering all the possible ways in which water impacts the welfare of people directly or indirectly in few nexus governance it is also suggested that policy integration can be facilitated if the issues are framed around strong political motivators such as quality and access bazilian et al 2011 middleton et al 2015 however while it is expected that a full functioning few nexus framework could provide a more reasonable and pragmatic approach to address issues such as equity it should be noted that adding more dimensions to this messy problem would likely create more challenges due to increases in tradeoffs not only between multiple objectives i e resource efficiency and equity of access but also across the sectors for example investment in hydropower to secure energy generation occasionally has had negative impacts on access to water for local usually under represented stakeholders bhaduri et al 2015 hensengerth 2015 large scale water diversion and hydropower projects in developing regions could lead to out migration of smallholder farmers thus influencing agricultural production and nearby urban settlements foran 2015 to advance equity studies in the context of few systems researchers need to develop more generalizable descriptions of equitable water energy and food access and identify criteria for equitable management another critical policy issue in water management which is likely to be magnified in the context of the few nexus is the so called the ripple effect or the cascading effect currently the decision landscapes in few sectors are highly compartmentalized and there are still artificial divides between the individual sectors energy food and water management and policy making are usually conducted independently without considering the cross sectoral interactions and externalities hanlon et al 2013 vora et al 2017 this single minded approach in management and governance especially when there is power imbalance between sectors can create sub optimal solutions and lead to unintended and detrimental consequences hensengerth 2015 hoff 2011 moreover while cross sectoral policy making may provide opportunities to mitigate tradeoffs and conflicts it may aggravate negative impacts on the environment and society if decisions are not well aligned with environmental and socioeconomic objectives examples of ripple effects and unintended outcomes due to the ignorance of few nexus abound bhaduri et al 2015 davis et al 2016 to name a few china s change to its soy trade policy in 2000 2001 led to global water savings associated with soy trade in 2007 because brazil argentina and the united states the three main soy exporters to china produce soy with less water than china however deforestation of amazon rainforests accompanied brazilian expansion of soybean production and is likely to have significant impacts on local and regional water cycles dalin et al 2012 rapid biofuel expansion and its impact on food prices in the mid 2000s stands out as another important example because biofuel feedstocks compete for agricultural land supplies of certain food commodities struggled to meet demand naylor et al 2007 and caused international food prices to skyrocket ultimately contributing to a global food crisis in 2008 in this instance an energy policy had a negative impact on food production with pronounced impacts on the world s poor whose food access was reduced rosegrant 2008 there are also many cases where national food policies had detrimental impacts within the water sector for example in india a policy of unmetered power supply for the agricultural sector provided to increase agricultural output and reduce rural poverty has led to significant decline in groundwater levels gulati and pahuja 2015 shah et al 2012 or in china agricultural policies aiming to improve food security and food self sufficiency have been related to ongoing irreversible damages to local groundwater resources ghose 2014 the issues discussed above and others require institutional reform as well as the support of process based scientific research and technology development cross sector organization and comprehensive policy incentives considering all major objectives relevant to food energy and water security must be developed 6 2 challenges in policy integration integrating and operationalizing policies in the nexus framework is and will continue to be a difficult task bizikova et al 2013 leck et al 2015 scott et al 2011 although the few approach may provide a clearer scope and path for policy integration than iwrm does here we highlight several essential elements of successful policy implementation first it is critical to identify where food energy or water policies overlap with or contradict policies in the other sectors at different spatial and temporal scales bazilian et al 2011 leck et al 2015 for instance qin et al 2015 found that china s plans to meet growing energy demand while reducing ghg emissions could conflict with the country s so called 3 red lines water policies introduced in 2011 to address regional imbalance in water availability cross sectoral analysis would help identify how current policies in each of the sectors constrain or accelerate implementation of integrated few system management such efforts constitute a daunting task complicated by multi tiered institutional arrangements and the involvement of stakeholders who hold conflicting perspectives and objectives gerlak 2005 leck et al 2015 scott et al 2011 second governance innovations at both local and national levels are needed to facilitate policy making in the context of the few nexus bhaduri et al 2015 doe 2014 similar to iwrm although few nexus research is likely to improve the scientific basis for decision making karthe et al 2015 it is difficult to integrate specific technical solutions into an institutional framework due to the lack of a comprehensive science policy interface and a lack of understanding of the institutional structures hagemann and kirschke 2017 to improve effective implementation of solutions conditions possibilities and limitations of institutional change should be identified hagemann and kirschke 2017 kurian 2004 two examples are provided below for illustration of the complexity in policy reforms in the u s operation and storage allocation for many dams remains essentially unchanged since their construction despite changes in societal preferences water demand for food and energy production and hydrologic conditions and supply capacities that affect water availability implementation of storage reallocation for large reservoirs would require the coordination of federal and state institutions on water uses for food and energy production as well as other purposes designed for the reservoirs marston and cai 2016 as another example water availability in some areas could restrict the expansion of biofuel crop production and the use of water intensive oil and gas extraction technologies nicot and scanlon 2012 scanlon et al 2014 since most water rights are for irrigated agriculture tradeoffs and synergies associated with reallocating water from food production to these new energy sources should be explored to avoid water use conflicts between food and energy sectors as occurred in texas where the water need for hydraulic fracturing by natural gas producers competed with irrigation water use by farmers during drought cooley and donnelly 2012 third weather and climate extremes or climate shocks have always presented major challenges for water food and energy supply and demand management policy approaches to climate shocks in most cases have focused on short term solutions ignoring factors that significantly affect the resilience of water food and energy systems in the long term adger et al 2011 fulton and cooley 2015 thus a transition to a risk management paradigm is required to enhance the adaptive capacity of the system not only through economic development and technological solutions but also through improved pro active policies wilhite et al 2000 adger et al 2011 while this transition has proved to be challenging some progress has been made to characterize the resilience of a system to better inform policy makers for example rushforth and ruddell 2016 adopted and extended a conceptual definition of ecological resilience to address hydro economic vulnerability and resilience of water resources in an urban area efforts have also been made to track the resilience in global food systems béné et al 2016 suweis et al 2015 seekell et al 2017 however building resilience to climate shocks in few systems can be even more challenging due to the complexity and interconnectedness of the system and the lack of holistic policy making channels conway et al 2015 scott et al 2015 california s central valley for example has experienced a chronic drought event recently and caused many complicating issues such as the decline of hydropower generation the increase of electricity use for deep groundwater pumping and the cut of water use permits for irrigation and municipal and industrial sectors famiglietti 2014 gleick 2016 to better cope with future climate shocks in few systems holistic policy integration among the various sectors will be a critical need fulton and cooley 2015 fourth economic instruments must be coordinated and well aligned in each of the sectors to mitigate tradeoffs bird 2016 fishman et al 2015 showed that without appropriate economic incentives adoption of groundwater conservation technologies in india would probably fail to reach their large potential as mentioned before while solar irrigation pumping is potentially a sustainable technology subsidized solar irrigation pumps might lead to over pumping if there is no incentive for farmers to redirect surplus power into the grid bird 2016 on the other hand if economic incentives are implemented appropriately they can motivate farmers to conserve water and use water more efficiently rosegrant et al 2009 for example ward 2014 showed that public subsidies to convert flood irrigation to drip irrigation in the southwestern united states could raise the value of food production and reduce the amount of water applied to crops in general economic instruments are needed to reconcile dissonance between natural resource values and their prices as commonly occurs with water bhaduri et al 2015 oecd 2014 rosegrant et al 2009 unescap 2013 fifth it is important to target different entities and stakeholders from the various involved communities in the united states for example there is little policy effort by the federal government to address the few nexus hanlon et al 2013 while local governments tend to respond to emerging challenges in the context of few by picking up the slack legislations and policies at the national level should also target few nexus management by improving data monitoring programs and encouraging integrated resource management hanlon et al 2013 likewise quantifying energy and water footprints associated with food and energy production and trade can help policy makers develop more effective and holistic policies vora et al 2017 finally organization is needed to bring together stakeholders from different sectors so that they may understand the issues such as tradeoffs synergies and uncertainties and identify optimal solutions bhaduri et al 2015 lele et al 2013 positive change can only happen if policy makers business owners and consumers alike better understand these interconnections hanlon et al 2013 experiences in participatory water management during the past decades will fit the campaign of policy innovations for few systems for instance integrating and managing the few nexus in transboundary river basins is likely to be impeded by frictions and conflicts in interest among riparian countries as stated by belinskij 2015 the nexus approach to transboundary cooperation requires a long term capacity and trust building between riparian states to create new opportunities through cooperation it is important to recognize that it is not possible to entirely eliminate the tradeoffs across sectors and across stakeholders however framing policies within the nexus approach can help reduce the tensions among stakeholders by maximizing the potential synergies kim et al 2015 scott et al 2011 7 conclusions in this perspective paper we provide our vision of the few nexus giving special attention to how it pertains to the water resources community our vision is characterized by interconnected few processes input output relationships and overlapping institutions and infrastructures we discuss the relevance of existing and ongoing scholarship within the water community and explore current research needs in few processes systems technologies and infrastructures and policies we identify the paths for water researchers to extend our disciplinary strengths within the broader few communities while informing scientists in the food and energy domains about our unique skillset the few nexus paradigm has a clear scope of integration over the interacting areas of food energy and water sectors which may allow interdisciplinary research to progress and research outcomes to be implemented where iwrm has had limited success analysts must be aware that due to the few nexus relationships technology and policy changes can end with either co benefits or unintended tradeoffs and environmental impacts depending on how the changes are guided furthermore few resource use efficiency should be approached by mitigating multiple dimension tradeoffs and enhancing existing or creating new positive synergies all of these advancements will have to be supported by fundamental research pertaining complexities in processes and systems to build on traditional empirical knowledge and methods in water resources systems researchers need to establish new relationships of water and food and water and energy processes using the various sources of existing and newly observed data synthesis of real world nexus issues across the various few systems can be especially helpful in discovering generic knowledge to complement the continuation of work with traditional systems by sector i e water energy and food exploratory research in system of systems or complex system theories and methods will be needed to test and develop innovative few system models decision making mechanisms technologies and institutions in particular knowledge of generic few system mechanisms must be gleaned from new interdisciplinary studies to augment the existing numerous case studies in the current literature for management purposes there is an urgent need to reform the current institutions whose focus are on individual sectors and explore coordinated management of food energy and water wherever needed early warning based on scientific prediction and monitoring should be provided to possible externalities and unintended consequences resulting from few system implementations especially to the environment and underrepresented groups as those occurring with water resources development at many places around the world following the historical efforts in iwrm the water community is provided opportunities for interdisciplinary studies amongst themselves and for collaborations with energy and food communities united by a common path to achieve the sustainable development goals considering the various efforts required to advance few nexus understanding and management every traditional water study group i e hydrologists water resources engineers economists and policy analysts can have a role but it is critical for all groups to integrate our work both within the water sector and across the food and energy sectors acknowledgements senior authorship is shared for this paper this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors edwin cho conducted the art design of figs 2 and 3 supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2017 11 014 appendix supplementary materials image application 1 
891,studies on the food energy and water few nexus lay a shared foundation for researchers policy makers practitioners and stakeholders to understand and manage linked production utilization and security of few systems the few nexus paradigm provides the water community specific channels to move forward in interdisciplinary research where integrated water resources management iwrm has fallen short here we help water researchers identify articulate utilize and extend our disciplinary strengths within the broader few communities while informing scientists in the food and energy domains about our unique skillset this paper explores the relevance of existing and ongoing scholarship within the water community as well as current research needs for understanding few processes and systems and implementing few solutions through innovations in technologies infrastructures and policies following the historical efforts in iwrm hydrologists water resources engineers economists and policy analysts are provided opportunities for interdisciplinary studies among themselves and in collaboration with energy and food communities united by a common path to achieve sustainability development goals keywords few nexus process system technology policy water resources 1 introduction the production utilization and security of food energy and water few are inextricably linked as global demand for few resources continues to increase supplies of these interconnected resources are becoming less secure hence in a timely manner the global research communities have united their efforts to study the few nexus in a holistic framework with an aim to address sustainable development goals sdgs recently proposed by the united nations bhaduri et al 2015 leck et al 2015 ringler et al 2013 it has been argued that the sdgs are not well integrated especially with respect to the few nexus weitz et al 2014 the few nexus paradigm is building up a common podium for researchers policy makers practitioners and stakeholders from energy food and water sectors to understand and resolve various complex issues linking the three sectors bizikova et al 2013 hoff 2011 these issues include resources allocation infrastructure investment socioeconomic development and environmental conservation as water researchers come together with food and energy research communities we share a working context that is broader than ever before and our community faces many research questions how can water researchers contribute to few system understanding and management based on our existing experiences and skills in what ways can we extend methodologies traditionally used to analyze water systems to now evaluate few systems on what specific issues can water researchers collaborate with those from energy and food sectors for hydrologists how will fundamental hydrologic processes influence or be influenced by processes of other sectors for water engineers and policy makers what will be the new directions for technology infrastructure and policy development as few understanding improves these questions motivate this perspective paper as we attempt to elucidate how water researchers and practitioners can uniquely contribute to emerging transdisciplinary few nexus literature the idea of integrated resources management is not new to water researchers dating back to the harvard water program maass et al 1962 there has been a call for researchers to study water within an interdisciplinary framework to understand water s multifaceted connections with human society and the environment since then advocacy for interdisciplinary water research has been pervasive actually the aim of few nexus studies which is to improve system efficiency pursue sustainability and increase system performance through holistic understanding and management of resources mirrors the objectives of integrated water resources management iwrm biswas 2004 iwrm is defined as a process which promotes the coordinated development and management of water land and related resources in order to maximize the resultant economic and social welfare in an equitable manner without compromising the sustainability of vital ecosystems global water partnership 2000 iwrm has been recognized as a key tenant of sustainable development by the united nations united nations 2012 and has been promoted by many leading international agencies hering and ingold 2012 nonetheless iwrm has not been implemented as widely as expected and has been criticized as a recipe for paralysis merrey 2008 and having the desire to do too much at one time schreiner and hassan 2011 hering and ingold 2012 proposed that moving forward requires setting bounds for integration and that transsectoral integration may nonetheless be required if the identified deficits are derived from activities based outside the water sector in fact iwrm has highlighted the linkage between water food and energy security hoff 2011 in contrast to iwrm we argue that the few nexus approach has a clearer scope of integration since it explicitly sets the sectoral bounds i e food energy and water resources of integration whereas iwrm attempts to integrate seemingly all resources and objectives related to water which is often subject to institutional barriers grigg 2008 mohtar and lawford 2016 moreover the three pronged emphasis of few may engage government agencies and other important stakeholders that have been reluctant to fully adopt iwrm since water related issues are not their chief concern or mandate and thus present a broader solution space not necessary centered around water which allows the cross pollination of ideas and integration of solutions across disciplines the nexus approach can also make the objectives of iwrm more palatable to stakeholders across political boundaries as is necessary in transboundary river basins since few does not require all solutions align with water management grigg 2008 thus under the scope of few iwrm s broader goals of efficient resource management synergistic thinking and equitable tradeoffs may seem more tenable to a wider set of stakeholders particularly those whose primary interest lie in the agriculture and energy sectors in addition iwrm achievements in solving a country s key water related development problems are limited due to the lack of innovative approaches biswas 2008 on the other hand few has inspired numerous research interests and efforts from both academic and practical communities in developing novel approaches and methods including models decision making theories and methods and technologies e g via the innovation in food energy and water systems infews program a research program initialized at the u s national science foundation nsf eventually we expect that the few nexus paradigm will refine and focus the scope of iwrm and provide water communities specific channels to move forward and collaborate with food and energy communities on many shared iwrm issues there are already a number of review and perspective papers on the few nexus in the literature a few are named here because of their close relevance to the background of this paper hoff 2011 presented the background paper for the bonn2011 conference the water energy and food security nexus which provides a comprehensive perspective on the few nexus for the first time including a discussion on the necessities and opportunities in few nexus studies and knowledge gaps in relevant science technology and policy areas the paper extends traditional food security perspectives to the nexus of security of food energy and water sectors to improve resource use efficiency mitigate tradeoffs build synergies and improve governance across sectors webber 2015 contended that the few nexus perspective is especially critical in regard to large infrastructure investments which are difficult to adapt should they prove counter productive across sectors webber also illustrated the connectedness of few systems through key examples of cascading failures in few systems highlighted synergistic technical solutions and acknowledged the lack of integrated policy implementation more recently scanlon et al 2017 called for extending the power of the scientific community to develop innovative prescriptive recommendations and adaptation pathways to deal with resources scarcity the authors highlighted the need for local and global nexus measurement and monitoring resource conservation technology to enhance supplies decision making techniques to deal with tradeoffs and more efficient storage transport and trade of few resources to satisfy the demands at the global scale the purpose of this perspective paper is to help water communities identify articulate utilize and extend our disciplinary strengths within the broader few communities while also informing scientists in the food and energy domains about the unique skill set we bring to address the few nexus we identify few relevant issues that water scientists face and discuss the existing and new methods to address those issues organizing our insights as pertaining to processes systems technologies or policies as displayed in fig 1 we illustrate that research on the few nexus must progress our understanding of the interactions of connected water and food and water and energy processes and systems and promote innovative water centric technologies infrastructures and policies toward the co benefits of few systems first however we present our vision of the few nexus in the following 2 vision of few nexus many review and perspective papers e g biggs et al 2015 keairns et al 2016 perrone and hornberger 2014 have provided varying definitions of the few nexus since a consensus has yet to be established we share our perspective of the form and scope of interconnected few systems illustrated in figs 2 and 3 the few nexus can be characterized by the following three forms of interactions i physical biophysical and chemical ii resource input output and iii via institutions markets and infrastructure first food energy and water are governed by separate but interconnected physical biophysical and chemical processes as displayed in the outermost linkages of fig 2 the processes that connect food energy and water drive the dynamics and performance of not only the individual systems but also the integrated system via mass and energy heat exchanges between the boundaries of each resource it should be noted that among the three sectors water is most directly subject to major natural variability which then drives much of the variability in other sectors ray et al 2015 scott and sugg 2015 additionally water is largely controlled by a physical boundary i e aquifers river basins while food and energy sectors have a stronger human influence shaping their spatial boundaries e g people decide where to grow food and build electricity transmission lines second food energy and water are critical inputs of production to the other resources as illustrated by the input output relations in fig 2 the inner interactions between the three sectors of the circle besides the input output interdependence these sectors also compete for few resources at local and regional scales e g energy and food production compete for water supplies water treatment and food production storage and shipment compete for energy supplies in particular water often acts as the limiting resource that dictates system outcomes especially in arid and semi arid regions and regions with extraordinary water demand falkenmark and molden 2008 gleick and palaniappan 2010 in fact two thirds of the world s population faces severe water scarcity at least one month of the year mekonnen and hoekstra 2016 third food energy and water are regulated by separate administrations markets and engineering infrastructure which often overlap and interact but do not fully integrate their efforts due to differing approaches objectives and institutional settings the effectiveness of any solution for a specific few nexus problem depends on how these independent entities coordinate with each other furthermore each of these three characteristic interactions the interconnected processes resources supply and demand and institutions markets and infrastructure can be influenced by technological innovations environmental changes and socioeconomic conditions system analysis starts with defining the system and specifying the spatial and temporal dimensions the few nexus exists at various spatial and temporal scales depending on the problem spatial scales can vary from microscopic to field farm or household to regional and global levels the mesoscale is shown in fig 3 likewise temporal scales can vary from seconds e g flow rate to daily e g systems operations to mid and long term horizons e g resource and infrastructure planning and development policy development and socio economic and environmental ramifications following iwrm we argue that the river basin or watershed can be used as a fundamental scale because food and energy can easily be transferred from distant locations to bolster regionally scarce resources or temporal variability of these resources while the spatial incongruence between water supplies and water demand cannot be as easily resolved davis et al 2016 in fact water is largely restricted within its natural boundaries although limited inter basin water transfers occur while the bounds of food and energy systems are chiefly delineated by humans and are thus more suitable for change nonetheless we must acknowledge that basin approaches often do not align with economic or social boundaries in many countries or regions especially where there is no river basin management authority and thus the suggested basin actions may be difficult to implement grigg 2008 hagemann and kirsche 2017 argued that a basin or sub basin scale that was used for the iwrm approach might not be an appropriate scale for the few approach therefore an appropriate scale or spatial unit for few nexus analysis and management may need to adhere to a particular society s needs of water energy and food as critical supplies for both human and natural systems moreover cross scale issues are a challenge for few system analysis because few processes system design and assessment prevail at different spatial and temporal scales it is particularly difficult for researchers to integrate information across the few nexus watkins et al 2015a to create tiered temporal and spatial interventions that account for and manage feedbacks across the few sectors hill and engle 2013 to mitigate environmental impacts over appropriate scales of time and space adger et al 2005 and to assess tradeoffs and synergies crossing scales davis et al 2016 kauneckis and andersson 2009 oates and portney 2003 given our few vision as described above the rest of this paper discusses knowledge gaps and research potentials for water resources researchers and the opportunities for collaboration with food and energy communities with respect to processes systems technologies and policies 3 interconnected processes considering the above vision of the few nexus a critical element of few system understanding is knowledge of the underlying individual processes and their connectedness some issues that have traditionally been addressed as water resources development and management problems are truly part of a larger interconnected few system and should be addressed as such the analyses of those issues such as irrigation water and wastewater treatment water supply hydropower or thermoelectric cooling have been largely based on hydrologic science and engineering principles yet these issues are pertinent to the food and energy sectors as well furthermore recent progress in eco hydrology and ecosystem restoration practices have provided deeper understanding of interactions between water and ecosystem services bakker 2012 especially those for food and energy production e g flow regime and water quality for aquatic fish habitats and water requirement for biomass production christian smith and merenlender 2010 palmer 2009 richardson et al 2011 to integrate understanding of the hydrologic cycle and its processes with understanding of few systems many outstanding issues connecting hydrologic processes to those in agriculture and energy areas must still be addressed in the following we identify knowledge gaps from a water perspective between water and food and between water and energy although the few nexus approach emphasizes the interactions of the three sectors we argue that there are still many knowledge gaps and research challenges in understanding the one to one process interactions and gaps which prevent the characterization and quantification of the nexus relationships 3 1 processes connecting water and food sectors 3 1 1 water to food hydrologic processes of precipitation evapotranspiration and flow in porous medium are all integral to agriculture production in particular despite extensive study by ecologists and hydrologists understanding crop evapotranspiration a fundamental process dictating crop water requirement allen et al 1998 has remained a research need particularly under climate change and environmental change e g variations in soil salinity droogers and van de giesen 2010 nistor et al 2017 in order to improve various stages of crop growth irrigation and drainage engineering measures are widely applied for manipulating soil moisture yet these practices are now challenged by more frequent and intense extreme weather events droughts heat waves and floods due to climate change numerous recent studies have revealed complex temporal and spatial variability in precipitation for example in the corn belt the shifting seasonality of rainfall pal et al 2013 wuebbles and hayhoe 2004 a tendency for a greater percentage of rainfall to occur during extreme events kunkel et al 2012 alternating periods of excessive wetness and dryness orlowsky and seneviratne 2012 and the impact of land use and land cover change on soil moisture across the region collectively make agriculture decisions more complex e g the crop land traditionally facilitated by drainage infrastructure in the late spring now often requires irrigation in the late summer how to make crops more capable of adapting to frequent and abrupt soil moisture changes via biological and hydrological engineering measures and how such conditions evolve in the future are pertinent research questions for the provision of adequate water for food production although irrigated agriculture often comes to mind when discussing water for food water is also essential for aquaculture an important source of food around the world especially in coastal regions nevertheless relatively little research has been published regarding the connections between hydrology and fisheries gephart et al 2017 though numerous studies have contributed to relating streamflow regime to aquatic habitats e g hydrologic alteration index iha poff et al 2010 collaboration between hydrologists and fishery ecologists is still under the call to develop more ecologically based hydrological indices and more explicit linkages between terrestrial and marine systems endo et al 2017 given the wide and intensive impacts of land and water use activities e g deforestation damming for hydropower etc studies are needed to develop guidelines for watershed management and water storage system operations which consider the interactions between hydrology and aquatic habitats schnier et al 2016 yang et al 2008 3 1 2 food to water agriculture production often uses large amounts of land water fertilizer and pesticide inputs causing major environmental changes in many regions around the world in particular non point source pollution due to extraordinary fertilizer and pesticide use in agricultural production has been a long standing yet unresolved problem for environmental protection and water supply quality for example in the u s midwest grain production and subsequent utilization for animal foodstuffs food processing and ethanol production have pervasive effects on water quantity and quality in downstream environments both locally 95 of waters have elevated nitrogen and phosphorus and nationally e g hypoxia zone in the gulf of mexico epa 2015 nutrient loading in waterways accelerates aquatic vegetative growth disrupts ecosystems and increases water treatment costs in the past society s major concern was water quality in the ecosystems but recently the concern has also been aggravated by the situation of water supply the des moines water works argued in a recent lawsuit that their water supply was adversely impacted by nitrate runoff from three grain producing counties in northwest iowa illuminating how food to water processes can exacerbate tensions between local stakeholders eller 2015 nutrient load problems within the united states have sparked a significant increase in federal natural resource and environment expenditures however there is no conclusive evidence that problems of sedimentation nutrient pollution and biodiversity loss in agriculturally dominated basins have been ameliorated through governmental efforts david et al 2015 2013 research is still needed for monitoring and simulating nutrient stocks and flows in soil woo and kumar 2016 nutrient loading and transport across scales from field to watershed and basin and water quality response to nutrient dynamics under both climatic variability and human interferences e g irrigation and land drainage research is also needed to develop technologies policies and best management practices to reduce fertilizer and pesticide use retain nutrients in soil and extract nutrients from wastewater i e resource recovery cai et al 2013 jarvie et al 2015 as detailed later in this paper agricultural activities also affect natural flow regimes yet the mechanism of the effects has not been well understood return flow from irrigation systems non consumptive portion of water withdrawals complicates flow balance and water use accounting at a basin scale cai et al 2003c and affects water quality de moraes et al 2010 determining return flow especially the utilizable return flow volume is important for not only understanding water balance in streams and aquifers but also determining water availability for the development of more reasonable and sustainable water rights at the river basin scale grafton et al 2012 the usefulness of return flow depends on the path of the flow i e via natural systems such as aquifers and interflow or man made pathways such as drainage systems the time lag occurring in the flow process and its quality all of which are very difficult to monitor and simulate hydrologic heterogeneity and a dearth of data have encumbered the development of inexpensive and widely acceptable methods for quantifying return flow at the river basin level 3 2 processes connecting water and energy sectors 3 2 1 water to energy energy production and supply both from traditional and emerging energy sources is often highly dependent on water supplies it is well known that considerable amounts of water are used for hydro energy generation and cooling within thermoelectric and nuclear power plants yet recently energy generation has been shifting toward unconventional and renewable energy technologies some of which have even larger water requirements compared to traditional thermal power mekonnen et al 2015 notably concentrated solar power requires significant cooling with water use rates often exceeding that of similarly sized coal and nuclear power plants bracken et al 2015 cultivation of biomass and processing to produce biofuels incurs significant water consumption housh et al 2015b song et al 2016 hydraulic fracturing of unconventional hydrocarbons requires 1 4 to 4 times as much water over its life cycle as conventional natural gas clark et al 2013 thus energy production and supply including both the traditional and emerging energy sources can be highly dependent on water supplies furthermore hydroclimatic variability propagates to the interlinked energy system and leads to diminished energy output many power plants or stations must adjust operations in response to extreme water conditions such as droughts and heat waves due to severe water availability and temperature limitations webber 2015 this emphasizes the role of hydroclimatic forecasts especially seasonal forecasts in water energy nexus studies conway et al 2015 perrone and hornberger 2016 3 2 2 energy to water on one hand water supply and delivery depend on energy for example energy use for moving and treating water and wastewater represents over 12 of total u s primary energy consumption sanders and webber 2012 on the other hand water withdrawal for and water discharge from energy generation have caused problems in water quantity and water quality especially for local ecosystems recent development of bioenergy and natural gas facilitated by hydraulic fracturing has brought new threats to water quality and riparian health for example in the u s midwest recent increases in corn based ethanol production have further constrained existing resource allocation i e competing land and water with corn as food and feed crops and threatened the regional environment simpson et al 2008 for many mid sized corn belt cities ethanol plants are the largest water user and discharge the largest quantities of wastewater to local sanitary districts phosphorus concentration in grain processing wastewater is several times greater than that of typical domestic wastewater illinois epa 2015 kim and dale 2005 watkins et al 2015b natural gas extraction creates substantial risk for water degradation with the lingering threat of pollution from transportation spills well casing leaks leaks through fractured rock drilling site discharge and wastewater disposal rozell and reaven 2012 for example vengosh et al 2014 analyzed the published data in the u s through january 2014 and found evidence for stray gas contamination surface water impacts in areas of intensive shale gas development and the accumulation of radium isotopes in natural gas disposal and spill sites thus increasing pollutant loads from new energy generation and distribution pathways have made water quality and environmental problems more complex than before this has stimulated both basic scientific research and technology development for example plant biologists have been exploring the second generation of bioenergy feedstocks that are both efficient in energy production and friendly to the environment mcisaac et al 2010 smith et al 2013 hydrologists can join the effort to assess the water requirement and impacts on water quantity and quality of these second generation feedstocks housh et al 2015b le et al 2011 ng et al 2010 the utility of hydropower remains a longstanding global debate within water resources development wcd 2000 while often proposed for energy provision purposes hydropower dams cause numerous incidental benefits and damages including the benefits for water storage for drought mitigation flood regulation and recreation and damages from disrupted sediment transport and inhibited fish migration also the timing of hydropower demand and other water demands namely irrigation can cause competition between benefits as zeng et al 2017 demonstrated to be the case for over half of globally installed hydropower moreover the green energy label attributed to hydropower may be misguided according to emerging research regarding the greenhouse gas emissions resulting from decomposition in reservoirs gunkel 2009 in light of these findings hydropower research should consider the full scope of few system impacts within dam design and operation in particular balancing the often conflicting requirements of aquatic habitats energy demand water supply and other water uses remains a challenge for the joint work of ecologists hydrologists and water resources engineers especially under hydrologic inflow uncertainty and variability suen et al 2009 yang and cai 2011 mitigating the tradeoffs among a dam s various purposes will require understanding of relevant physical processes such as flow states sediment transport wild and loucks 2014 and hydrodynamic conditions for fish within and downstream of reservoirs xu et al 2017 3 3 highlights of relevance to hydrologic research the few nexus adds new dimensions to classic hydrologic problems as demonstrated in the preceding section also see smajgl et al 2016 however it is not surprising that some classic problems for water scientists will remain and become even more complex in the context of the few nexus in particular quantifying and managing uncertainty is a long standing issue within in the hydrology community rajaram et al 2015 especially that of extreme events such as droughts heat waves and floods hydroclimatic uncertainty propagates to all sectors relying on water as a resource or being affected by water processes e g flooding additional complexity arises from the correlation of the various uncertainty sources from food energy and water sectors and their joint impacts on the performance of the few system leck et al 2015 watkins et al 2015a yang et al 2016b research on hydroclimatic forecasts characterized by forecast horizon and accuracy should consider the specific needs to secure the stability of food and energy production and markets hamlet et al 2002 koch and vögele 2013 exploration of outstanding scale and scaling up issues with few analysis and management as discussed earlier can be based on and extend the knowledge of hydrologic communities blöschl 2001 sivapalan 2003 soulsby et al 2006 advances in hydrologic modeling at large scales such as national continental or global rajaram et al 2015 provide scientific support for few nexus understanding at those scales by providing water availability assessment e g watergap global model döll and schmied 2012 streamflow and flood forecasts e g national water model maidment 2016 and demand and trade modeling of food rosegrant et al 2002 and energy hejazi et al 2015 engineering measures such as long distance water transfer and food and energy markets enhance the few nexus interconnectedness at large scales these expanded nexus relationships at a regional or national scale can impact local water resources development and the hydrologic cycle and thus increase the relevant scale of the local water system e g via inter basin water transfer pumping and lifting or food market that drives virtual water flow in turn regional or national outcomes are impacted by local outcomes that trickle up through interconnections these feedback loops that cross scales offer an exciting avenue for exploration among hydrologists watkins et al 2015a on the other hand some few nexus cases may indeed be confined to a local scale for example treatment of brackish water in coastal areas to irrigate crops and vegetables with high salt tolerance does not interact with a surrounding watershed or sub watershed another research direction arising from the few nexus paradigm and coinciding with the current concern of the hydrologic community is the human dimension of the hydrologic cycle including anthropogenic alterations and hydrologic co evolution with human systems rajaram et al 2015 vogel et al 2015 the inter sectoral connectedness of the few nexus extends the human dimension by involving stakeholders from multiple sectors and introduces more complex tradeoffs and synergies or co benefits among the stakeholders this broader human dimension interferes with the various physical processes and thematically complicates the interactions of human and natural system dynamics recent studies on coupled nature human systems cnhs reemphasize the need to integrate work among researchers in social and physical communities lund 2015 scanlon et al 2017 sivapalan et al 2012 and to link ecosystem services critical to food and energy production with various stakeholder outcomes de groot et al 2010 hein et al 2006 from a water perspective we are concerned with water supply of sufficient quantity and quality for food and energy production and the feedbacks of those water uses to hydrologic processes which reemphasizes the role of hydrology highlighting the interdisciplinary science of water in the context of cnhs as proposed by vogel et al 2015 the above processes and connections make up the complex system discussed hereafter we highlight these processes because they are particularly impactful within few systems and they represent current knowledge gaps as with any complex system few system understanding requires sound knowledge of the underlying processes and connections before the system can be effectively managed through infrastructure technology institutions and policy 4 the unique role of water in few system analysis managing integrated few systems represents a fundamental shift from the traditional but narrow goal of solely increasing benefits derived from either food energy or water resources with limited regard for the other few components instead a system of systems approach targets overall efficiency of few resources utilization and produces synergistic societal and environmental benefits water s foundational role in so many facets of human society as well as natural processes has necessitated systems thinking amongst water researchers for decades brown et al 2015 rogers and fiering 1986 maass et al 1962 as water scientists our long history of system thinking may act as springboard to understanding and managing the complex interdependencies within the few nexus following the discussion on interconnected processes in the preceding section here we address the interactions between food energy and water within a systems context we give special attention to the features and issues within water sub systems that will propagate up to the broader few system and may act as the key driver of few system outcomes broadly we identify sources of system complexity that challenge water resource system analysis and hence few system analysis and demonstrate how water resources systems analysis can be extended to address the complexities with few systems 4 1 interconnectedness circular demands and feedback loops complex few systems are diagnosed and described by their inherent interdependent linkages and feedbacks these system properties may lead to emergent characteristics which arise from the web of interconnections in a complex system kumar 2015 water systems are complex by themselves but many traditional water centric problems may need to be addressed in the context of few systems to avoid unexpected consequences for instance during a severe drought in 2012 kolkata india suffered a major blackout due to the linkages among the regional water and energy sectors webber 2015 in response to the drought farmers increased groundwater pumping in turn increased groundwater pumping placed increased demands on the regional electrical grid meanwhile low streamflow reduced hydropower production ultimately the drought event caused 690 million people to lose power webber 2015 this example illustrates how shocks to the water system can propagate through the food and energy sectors and circulate back to the water system itself identifying and understanding the interconnections that initiate circular demands or feedback loops is foundational to designing and managing overall few system behaviors water scientists have long studied the coupling between water and human systems noting the complicated nonlinear response of water systems to both natural němec and schaake 1982 and human thomas et al 2013 van der zaag and gupta 2008 wang and cai 2010 perturbations the couplings between few components society and ecosystems with nonlinear feedbacks and circular demands may create even more complex patterns of system performance across multiple spatial and temporal scales in particular instances of small gradual changes to either food energy or water resources can emerge as large and even disastrous changes in the overall few system or broader environment this is evident in the aral sea basin where steady increases in irrigated area and hydropower capacity over multiple decades led to a precipitous drop in the aral sea s surface area once a critical threshold of upstream irrigation was reached cai et al 2003b agriculture intensification which was seen in the aral sea basin and typically requires additional water and energy inputs is essential to feed the growing global population godfray et al 2010 yet will agriculture and energy intensification insidiously lead to similar environmental catastrophes in basins around the world will additional demand for water to irrigate food and biofuel crops lead to circular demands for few resources to answer these questions water scientists need to work with food and energy scientists to better understand local interconnected few processes and institutions see section 6 which determine water availability for food and energy production as well as the environmental impacts associated with these water uses additionally we need to understand the telecouplings between local resource use and the distant consumers that are remotely driving the system through the invisible hand of the global market marston and konar 2017 after all in the aral sea basin besides irrigated grains for local consumption irrigated cotton as both a major income source for people in central asia and a mandate for 95 percent of cotton used in the former soviet union was one of the primary water users in the aral sea basin the short term policies and profit driven decision making exhibited in the case of the aral sea basin did not account for externalities associated with extensive irrigation which eventually caused the environmental disaster in the region cai et al 2003b no study within the water resources literature has fully explained the tipping point leading to the sharp drop of inflow to the aral sea and corresponding recession of its surface area beginning in the 1970s and continuing today the aral sea represents a complex few system and highlights a specific instance where joint efforts from water agriculture and energy hydropower in the upstream of the basin communities are needed to explain the nonlinear phenomena and propose solutions to reverse an environmental and socioeconomic disaster 4 2 tradeoffs synergies and system efficiency nexus thinking requires a shift from a singular focus on production maximization to improving system efficiencies capturing synergies and managing tradeoffs the entangled and diverse uses of water have necessitated nexus thinking well before the few nexus came to the forefront of scientific discourse while water scientists past and ongoing work can inform few nexus research the few framework may offer a means for wider implementation of our work through the inclusion and engagement of those that have previously evaded a water centric approach within water systems researchers practitioners and decision makers have long considered tradeoffs of water quality versus water quantity upstream beneficiaries versus downstream beneficiaries and environmental health versus economic production among others in the context of few these tradeoffs become increasingly complicated as more sectors and stakeholders become involved our understanding of water resources is not complete without nexus thinking for example housh et al 2015b showed how adopting a second generation biofuel crop miscanthus in a central illinois watershed will improve biofuel production efficiency and reduce nutrient discharge but increase cost and volume of freshwater consumption compared to the current use of corn as feedstock the few nexus approach allows us to view this issue beyond tradeoffs of water quality vs water quantity and understand the underlying mechanisms that drive system outcomes food and energy markets transportation infrastructure farm management feedstock conversion rates and emerging energy technologies are among the drivers of this system extending our boundaries of analysis will make evident previously hidden and poorly understood tradeoffs dealing with such complicated tradeoffs needs stronger scientific support for the understanding of processes interventions and outcomes and stronger institutional support to balance the benefits of multiple groups of stakeholders in addition positive synergies in integrated few systems can be leveraged to overcome issues that have persistently plagued the water community for example in arid or semi arid areas with marginal water resources e g saline groundwater and wastewater and plentiful renewable energy sources e g solar and or wind power the energy sources can be used for desalination of saline groundwater and treatment of wastewater which can be applied to irrigating high value crops via vertical agriculture vertically stacked layers of farmed land in a building such coupling of water and energy resources for food production and storage purposes can generate synergies by 1 making more effective use of renewable energies given that wind mill and solar panel capacities are not fully used in many regions 2 increasing food production or reducing food waste 3 making marginal water saline water and wastewater useful the potential synergies rising from few systems are informative to water food and energy scientists and to engineers who design particular few systems that fit local resources and socioeconomic conditions issues such as cost effectiveness environmental impact and social impact see section 6 for more discussion must be addressed via few system analysis however the expected synergies in few systems can be weakened or even replaced by tradeoffs under changing environmental and social conditions within water resources multi purpose reservoirs provide one such example dams are often designed to serve multiple purposes including hydropower fishing irrigation public water supply among others during design objectives such as energy production and crop irrigation are balanced so as to meet the immediate needs of those reliant on the dam s water releases however years of continued damming of upstream waters land use change and climate change have altered hydrologic regimes as well as the timing of water requirement for hydropower and food production zeng et al 2017 thereby impacting the dam s operational synergies moreover changes in societal values regarding the environment and fish habitat have called into question previous water allocations marston and cai 2016 natural and societal change is unavoidable and seemingly happening more rapidly working together few researchers can make the food energy and water sectors more resilient to future changes by designing adaptable infrastructure and utilizing excess resources from each sector an example of this is conjunctive water use cu and managed aquifer recharge mar which stores excess water in depleted aquifers that can be extracted later to irrigate food or biofuel crops during drought scanlon et al 2016 further technological innovations paired with forward looking policy can lead to additional few synergies and make each sector more resilient to variability in natural and humans systems see section 5 for more discussion increasing water use efficiency amongst the energy and food sectors the two largest water users globally has been a long term effort in water science and technology communities however improving water use efficiency does not necessarily lead to better system performance when considering broader or different few objectives within the few nexus even the conceptual basis of efficiency must be reevaluated for instance closed loop thermoelectric cooling is considered more efficient than open loop cooling because it withdraws approximately 95 less water however closed loop cooling can consume nearly 60 more water than open loop cooling denooyer et al 2016 improving irrigation efficiencies may reduce water applied to crops but additional energy inputs are needed to pressurize more water efficient irrigation systems moreover measures of efficiency are highly dependent on the boundaries of analysis water efficiency improvements at the site scale may have little effect on basin efficiency defined as the ratio of beneficial water consumption over total water consumption within a basin since return flows from inefficient water users can be utilized downstream for food production hydro energy generation and other purposes cai et al 2003c 4 3 systems analysis techniques there is no singular method or clear best practice for understanding highly complex systems shalizi 2006 indeed several system analysis techniques that have been developed in the water sector can be extended for even more sophisticated analysis of few systems first water researchers have employed several approaches to evaluate water related tradeoffs in a holistic manner for instance mathematical programming yang et al 2016a including multi objective optimization hurford and harou 2014 and water management simulation models perrone and hornberger 2016 have been employed to create tradeoff frontiers between water supply and quality food production power generation social outcomes and environmental health this permits decisions makers and other stakeholders to visualize nexus outcomes and consider non economic goals alongside profits from water supply food production and power generation jägerskog et al 2013 embedded resource accounting approaches such as life cycle assessment and footprint assessment methods can also reveal the hidden linkages between few resources and the tradeoffs and synergies throughout the value chain gerbens leenes et al 2012 marston et al 2015 computable general equilibrium cge models with an ecological sector have been used to establish tradeoffs between economic benefits and the environment llop and ponce alifonso 2012 finally stochastic optimization techniques that have been developed for hydropower operation under hydroclimatic variability and uncertainty labadie 2004 yeh 1985 can be extended to a larger system of multiple complementary energy sources and water users under changing and uncertain environmental and socioeconomic conditions cai et al 2009 few systems interact not only in the physical environment but also the socio economic environment which requires appropriate modeling tools to analyze the interactions between natural and social systems hydro economic models cai 2008 harou et al 2009 integrate essential hydrologic and economic relationships in a consistent model to analyze the interactions between water supply water demand and economic policies such an approach can be naturally extended to few systems by adding physical economic relations of food and energy e g cai et al 2003a more recently water resource researchers have applied system of systems models to analyze the multi dimensional tradeoffs and synergies among the water food and energy sub systems housh et al 2015a agent based modeling abm is gaining traction within the water resources research community as it can be particularly useful in representing diverse human actors hu et al 2017 likewise abms are promising for few systems analysis due to the ability to represent heterogeneous behaviors among multiple stakeholders furthermore abms are often coupled with natural process models to address the interactions between human and natural dynamics for instance ng et al 2011 studied land allocation between food and biofuel crops and its impact on hydrologic flows and water quality in general the framework of coupled natural human system cnhs is well suited to few analysis to simulate the dynamic feedbacks between natural system mainly with water and human systems with stakeholders from all sectors elshafei et al 2015 finally networks depicting connections among processes state variables and fluxes known as process networks can provide a highly informative snapshot of the state of a complex system kumar 2015 which has been illustrated in water systems but have not yet been applied specifically to few system analysis to the authors knowledge for example the work of ruddell and kumar 2009a 2009b demonstrate the ability to produce process networks from time series data for a complex eco hydrologic network and should serve as proof of concept worth pursuing further in the few context another systems modeling method system dynamics has been used to study the behavior of complex non linear systems in water resources but it has not yet been utilized in few system analysis to its full potential halbe et al 2015 mirchi et al 2012 each of the above methods has proven valuable in a small sample of hydrologic and water resource systems applications and warrant further extension by water scientists in collaboration with food and energy scientists to diagnose and describe linkages feedbacks and emergent characteristics in few systems thereby advancing few understanding 5 technology development in the context of few systems few relevant water technologies and infrastructure design are rapidly advancing enabling new synergies and improved overall system efficiency water infrastructure is inherently relevant to the few nexus since it is often purposed to meet the water demands of the energy and food sectors yet water technologies and infrastructure design often do not consider few interdependencies bazilian et al 2011 webber 2015 currently there are 3700 large dams planned or under construction globally zarfl et al 2015 constituting a critical opportunity to incorporate broader few system outcomes when planning constructing and operating these new dams new water infrastructure and technologies should aim to increase total few benefits not just those derived from water amongst a wide range of stakeholders including the environment here we review a few key advancements in water technology and infrastructure highlight the ability of system designers to reimagine existing technology and warn of the surprises which may arise if implementation does not fully account for few system complexity 5 1 technology innovations many water technologies and infrastructure designs offer avenues to reduce tradeoffs enhance efficiencies or improve reliability within the few system for instance advancements in both multi stage flash distillation and reverse osmosis technologies have increased the energy efficiency of desalination plants thereby reducing the energy versus water tradeoff khawaji et al 2008 development of drought tolerant crops tester and langridge 2010 can mitigate water shortage vulnerability and also save energy for irrigation systems other examples include the use of saline water to irrigate some salt tolerant crops rozema and flowers 2008 reuse of wastewater after cost effective treatment becerra castro et al 2015 haruvy 1997 use of food waste for bioenergy production using low environmental impact technologies lin et al 2013 uçkun kiran et al 2014 another pathway to few savings has been the shift toward utilizing waste as a resource recently spearheaded by wastewater engineers in particular water reclaimed at treatment plants is used for thermoelectric power generation or to irrigate food and biofuel crops dong et al 2016 wastewater treatment systems have demonstrated the economic feasibility of recovering thermal energy for heating organic compounds which are incinerated for energy production and nutrients used to fertilize crops hering et al 2013 with innovative resource recovery technologies the environment and downstream water users benefit from improved water quality while farmers who apply captured phosphorus and nitrogen from wastewater to their fields can benefit from increased crop yields and reduced fertilizer cost however water scientists must beware of the few example investigated by rajagopal 2008 for example where societal benefits unexpectedly decreased as wasteland was converted into agricultural land for biofuel development as it turned out what planners had viewed as wasteland was actually a valuable resource for an overlooked community serving as a source of fuel and food for local impoverished peoples rajagopal 2008 as food energy and water operations are further integrated new opportunities may emerge for water scientists to utilize food and energy system waste or to redirect water system waste to systems where it may serve as a resource though limited some studies and projects have extended the evaluation of water technology and infrastructure to include the cascading effects throughout a few system villarroel walker et al 2014 evaluated the effects of four water sector technologies on the metabolism of the city of london the city s intake and output of nutrients energy and water through multi sectoral systems analysis they show which combinations of technologies are preferred for various resource conservation priorities villarroel walker et al 2014 there is also evidence that decentralized small scale water storage and hydropower schemes may sustainably balance the multiple objectives of food water and energy security in developing countries van der zaag and gupta 2008 decentralized approaches have been shown to provide greater access to energy and water for food production amongst smallholder farmers who produce most of low income country s food supply ifad 2013 stevens and gallagher 2015 furthermore the stronger coupling between local stakeholders and water infrastructure may provide additional few synergies such as applying dredged nutrient rich river sediments to cropland to boost food production which simultaneously extends the life of the dam lembke et al 1983 moving forward water resource system analysts must increasingly account for interconnected few processes and systems when evaluating technology and infrastructure the growing capabilities of technologies such as remote sensing geographic information systems gis low cost sensors and smart phone applications can provide critical data concerning few systems and may help water researchers accomplish this more integrated analysis for example data collected from aging water infrastructure retrofitted with smart sensors can inform more flexible operating procedures and improved decision support visualization ultimately leading to more efficient use of few resources and environmentally friendlier operation while developing these advanced data tools some fundamental questions must be addressed how can the resource use of heterogeneous and fragmented users be monitored and measured how can information describing human processes institutions and stakeholder behaviors in different sectors be paired with physical and ecosystem data in a meaningful way what data are needed to understand the spatial and temporal evolution of few systems as answers to these questions are developed and more data sensing capabilities are harnessed water and few system analysts will be empowered to more fully understand few system complexity and thus guide future technological and infrastructural investments 5 2 systems design the few nexus will also allow water engineers new freedom to combine existing technologies and infrastructures in new ways for an improved overall few system garcia and you 2016 especially traditional water uses technology and infrastructure can be reimagined i e system re design to exploit synergies within the broader few system the incorporation of interdependent food energy and water processes in design opens opportunities to improve resource use efficiency and achieve synergistic societal benefits one case is to reduce the energy required to supply clean water by integrating engineered water treatment and natural watershed management for example biofuel production from herbaceous perennial crops in marginal agricultural land can reduce sediment and nutrient runoff nelson et al 2006 thereby improving water quality and reducing the need for energy intensive water treatment before human consumption another case is to couple the production of multiple energy sources given different weather conditions and the timing of energy demands wind solar and hydropower can be coupled to increase energy supply reliability for example general electric recently began an initiative to use massive wind turbines to pump water for storage at the top of a hill when electricity is needed water is released downhill and run through a hydropower generator in essence water is used as a battery to store excess power from wind turbines this is an extension of pump and hydropower generation where water is pumped to elevated reservoirs at night when energy demand is reduced and the water is released and its energy captured during the day when the electricity and water demand are higher grumet 2016 in addition viewing issues traditionally thought of as water problems e g floods through the lens of a few system will reframe how we manage design and set policies to handle water issues for instance coastal flooding and erosion are typically mitigated by structural e g dykes groins or policy measures e g flood insurance yet what would flood resilience look like within the context of few one example can be seen in small island nations where the rehabilitation of mangrove habitats not only better protects local populations from coastal flooding and erosion but also improves water quality and produces food with minimal disruption to water and energy supplies biggs et al 2015 many important synergies such as in the examples above are only accessible to system designers if food energy and water systems are analyzed and managed collectively water researchers and practitioners must design unorthodox solutions such as this in the face of increasingly limited few resources 5 3 externalities of technology development new technologies and systems often require tremendous investment to develop and implement and such investments may be wasted or even cause additional problems if they are not guided by an adequate understanding of few system complexities webber 2015 therefore systems analysts in water and other sectors have a tremendous responsibility to guide technology development and infrastructure design with deepening understanding of few system complexities instances of misapplied technology leading to unintended consequences and surprises are abundant for water scientists a classical example is the increase of water consumption in response to improved irrigation technologies this phenomenon known as jevon s paradox indeed occurs in the energy and food sectors as well ceddia et al 2013 dumont et al 2013 freeman et al 2016 ward and pulido velazquez 2008 as another example water recycling or reuse projects can improve water use efficiencies but also have unintended consequences across the nexus in egypt continual recycling and reuse of irrigation runoff had negative effects on water quality throughout the country s irrigation network the water became more saline and polluted as it was recycled reducing crop yield in addition the upstream downstream dynamics of water recycling created issues of unequal access for egyptian farmers barnes 2014 thus two intuitive solutions to water resource scarcity improved efficiency and resource reuse must not be pursued hastily but through careful consideration of their broader impacts across the few system and society at large these examples also provide impetus for developing adaptive water management techniques even the most carefully considered plans may yield surprising outcomes given the complexity of few systems and adaptive management techniques could enable water managers to change plans as new knowledge is gained pahl wostl 2007 for example when the northwest power act was passed in 1980 mandating the sustainable balancing of hydropower development and fish conservation the columbia river basin fish and wildlife program crbfwp initiated an adaptive management strategy the crbfwp immediately began taking mitigation measures but also created systems to measure the impact of habitat enhancements on salmon spawning rates as they were employed thus the crbfwp was able to continuously learn and adapt its management strategies lee 1989 lee and lawrence 1986 in general infrastructure design and the application of technology based on understanding only input output relations or other individual processes may be misguided regarding certain overall system characteristics kumar 2015 as understanding of few system complexity improves unintended outcomes of technology and design can be avoided more successfully 6 governance and institutions from water to few system over the past several decades different institutional frameworks and governance regimes have been proposed to improve water management particularly through integrated and multi sectoral coordination meinzen dick 2007 pahl wostl et al 2010 considering iwrm as one of the latest examples the introduction of iwrm was recognized as an attempt for policy integration across sectors embracing the inherent complexity of the managed system grigg 2008 pahl wostl et al 2012 in fact iwrm was developed based on the premise that governing water land and other related resources in an integrated manner is essential to effectively address problems such as equity economic efficiency and ecosystem sustainability global water partnership 2000 hagemann and kirschke 2017 similarly in terms of the few nexus the overarching governance issue is that policies are fragmented across food energy and water sectors hanlon et al 2013 and a political process requiring negotiations among the different actors representing different sectors is needed to improve cross sectoral policy integration weitz et al 2017 failing to consider the connections among sectors in few governance either in policy analysis or in implementation therefore could result in unintended consequences and worsen the overall resource security bizikova et al 2013 while some researchers cast doubt about the effectiveness of iwrm in its implementation biswas 2008 hering and ingold 2012 pahl wostl et al 2012 we would argue that the progresses made in water institutions governance and science policy interfaces especially the lessons learnt from iwrm implementations could in fact benefit addressing the rising institutional challenges with few systems however it also should be noted that with a paradigm shift from water governance to few governance new challenges and opportunities will emerge this section reviews and discusses how water management institutions can contribute to and be reshaped for efficient and sustainable management of few systems 6 1 relevance of outstanding water policy issues to the few nexus over the years water researchers have identified different policy issues and proposed corresponding technical and institutional mechanisms to address the issues among them social equity has been a great concern appearing in the various water governance frameworks in fact social equity is one of the main pillars of iwrm along with economic efficiency and environmental sustainability grigg 2008 peña 2011 peña 2011 argued that assessing social equity in water management should go beyond the water sector and be addressed in the context of equity for all relevant groups in the society by considering all the possible ways in which water impacts the welfare of people directly or indirectly in few nexus governance it is also suggested that policy integration can be facilitated if the issues are framed around strong political motivators such as quality and access bazilian et al 2011 middleton et al 2015 however while it is expected that a full functioning few nexus framework could provide a more reasonable and pragmatic approach to address issues such as equity it should be noted that adding more dimensions to this messy problem would likely create more challenges due to increases in tradeoffs not only between multiple objectives i e resource efficiency and equity of access but also across the sectors for example investment in hydropower to secure energy generation occasionally has had negative impacts on access to water for local usually under represented stakeholders bhaduri et al 2015 hensengerth 2015 large scale water diversion and hydropower projects in developing regions could lead to out migration of smallholder farmers thus influencing agricultural production and nearby urban settlements foran 2015 to advance equity studies in the context of few systems researchers need to develop more generalizable descriptions of equitable water energy and food access and identify criteria for equitable management another critical policy issue in water management which is likely to be magnified in the context of the few nexus is the so called the ripple effect or the cascading effect currently the decision landscapes in few sectors are highly compartmentalized and there are still artificial divides between the individual sectors energy food and water management and policy making are usually conducted independently without considering the cross sectoral interactions and externalities hanlon et al 2013 vora et al 2017 this single minded approach in management and governance especially when there is power imbalance between sectors can create sub optimal solutions and lead to unintended and detrimental consequences hensengerth 2015 hoff 2011 moreover while cross sectoral policy making may provide opportunities to mitigate tradeoffs and conflicts it may aggravate negative impacts on the environment and society if decisions are not well aligned with environmental and socioeconomic objectives examples of ripple effects and unintended outcomes due to the ignorance of few nexus abound bhaduri et al 2015 davis et al 2016 to name a few china s change to its soy trade policy in 2000 2001 led to global water savings associated with soy trade in 2007 because brazil argentina and the united states the three main soy exporters to china produce soy with less water than china however deforestation of amazon rainforests accompanied brazilian expansion of soybean production and is likely to have significant impacts on local and regional water cycles dalin et al 2012 rapid biofuel expansion and its impact on food prices in the mid 2000s stands out as another important example because biofuel feedstocks compete for agricultural land supplies of certain food commodities struggled to meet demand naylor et al 2007 and caused international food prices to skyrocket ultimately contributing to a global food crisis in 2008 in this instance an energy policy had a negative impact on food production with pronounced impacts on the world s poor whose food access was reduced rosegrant 2008 there are also many cases where national food policies had detrimental impacts within the water sector for example in india a policy of unmetered power supply for the agricultural sector provided to increase agricultural output and reduce rural poverty has led to significant decline in groundwater levels gulati and pahuja 2015 shah et al 2012 or in china agricultural policies aiming to improve food security and food self sufficiency have been related to ongoing irreversible damages to local groundwater resources ghose 2014 the issues discussed above and others require institutional reform as well as the support of process based scientific research and technology development cross sector organization and comprehensive policy incentives considering all major objectives relevant to food energy and water security must be developed 6 2 challenges in policy integration integrating and operationalizing policies in the nexus framework is and will continue to be a difficult task bizikova et al 2013 leck et al 2015 scott et al 2011 although the few approach may provide a clearer scope and path for policy integration than iwrm does here we highlight several essential elements of successful policy implementation first it is critical to identify where food energy or water policies overlap with or contradict policies in the other sectors at different spatial and temporal scales bazilian et al 2011 leck et al 2015 for instance qin et al 2015 found that china s plans to meet growing energy demand while reducing ghg emissions could conflict with the country s so called 3 red lines water policies introduced in 2011 to address regional imbalance in water availability cross sectoral analysis would help identify how current policies in each of the sectors constrain or accelerate implementation of integrated few system management such efforts constitute a daunting task complicated by multi tiered institutional arrangements and the involvement of stakeholders who hold conflicting perspectives and objectives gerlak 2005 leck et al 2015 scott et al 2011 second governance innovations at both local and national levels are needed to facilitate policy making in the context of the few nexus bhaduri et al 2015 doe 2014 similar to iwrm although few nexus research is likely to improve the scientific basis for decision making karthe et al 2015 it is difficult to integrate specific technical solutions into an institutional framework due to the lack of a comprehensive science policy interface and a lack of understanding of the institutional structures hagemann and kirschke 2017 to improve effective implementation of solutions conditions possibilities and limitations of institutional change should be identified hagemann and kirschke 2017 kurian 2004 two examples are provided below for illustration of the complexity in policy reforms in the u s operation and storage allocation for many dams remains essentially unchanged since their construction despite changes in societal preferences water demand for food and energy production and hydrologic conditions and supply capacities that affect water availability implementation of storage reallocation for large reservoirs would require the coordination of federal and state institutions on water uses for food and energy production as well as other purposes designed for the reservoirs marston and cai 2016 as another example water availability in some areas could restrict the expansion of biofuel crop production and the use of water intensive oil and gas extraction technologies nicot and scanlon 2012 scanlon et al 2014 since most water rights are for irrigated agriculture tradeoffs and synergies associated with reallocating water from food production to these new energy sources should be explored to avoid water use conflicts between food and energy sectors as occurred in texas where the water need for hydraulic fracturing by natural gas producers competed with irrigation water use by farmers during drought cooley and donnelly 2012 third weather and climate extremes or climate shocks have always presented major challenges for water food and energy supply and demand management policy approaches to climate shocks in most cases have focused on short term solutions ignoring factors that significantly affect the resilience of water food and energy systems in the long term adger et al 2011 fulton and cooley 2015 thus a transition to a risk management paradigm is required to enhance the adaptive capacity of the system not only through economic development and technological solutions but also through improved pro active policies wilhite et al 2000 adger et al 2011 while this transition has proved to be challenging some progress has been made to characterize the resilience of a system to better inform policy makers for example rushforth and ruddell 2016 adopted and extended a conceptual definition of ecological resilience to address hydro economic vulnerability and resilience of water resources in an urban area efforts have also been made to track the resilience in global food systems béné et al 2016 suweis et al 2015 seekell et al 2017 however building resilience to climate shocks in few systems can be even more challenging due to the complexity and interconnectedness of the system and the lack of holistic policy making channels conway et al 2015 scott et al 2015 california s central valley for example has experienced a chronic drought event recently and caused many complicating issues such as the decline of hydropower generation the increase of electricity use for deep groundwater pumping and the cut of water use permits for irrigation and municipal and industrial sectors famiglietti 2014 gleick 2016 to better cope with future climate shocks in few systems holistic policy integration among the various sectors will be a critical need fulton and cooley 2015 fourth economic instruments must be coordinated and well aligned in each of the sectors to mitigate tradeoffs bird 2016 fishman et al 2015 showed that without appropriate economic incentives adoption of groundwater conservation technologies in india would probably fail to reach their large potential as mentioned before while solar irrigation pumping is potentially a sustainable technology subsidized solar irrigation pumps might lead to over pumping if there is no incentive for farmers to redirect surplus power into the grid bird 2016 on the other hand if economic incentives are implemented appropriately they can motivate farmers to conserve water and use water more efficiently rosegrant et al 2009 for example ward 2014 showed that public subsidies to convert flood irrigation to drip irrigation in the southwestern united states could raise the value of food production and reduce the amount of water applied to crops in general economic instruments are needed to reconcile dissonance between natural resource values and their prices as commonly occurs with water bhaduri et al 2015 oecd 2014 rosegrant et al 2009 unescap 2013 fifth it is important to target different entities and stakeholders from the various involved communities in the united states for example there is little policy effort by the federal government to address the few nexus hanlon et al 2013 while local governments tend to respond to emerging challenges in the context of few by picking up the slack legislations and policies at the national level should also target few nexus management by improving data monitoring programs and encouraging integrated resource management hanlon et al 2013 likewise quantifying energy and water footprints associated with food and energy production and trade can help policy makers develop more effective and holistic policies vora et al 2017 finally organization is needed to bring together stakeholders from different sectors so that they may understand the issues such as tradeoffs synergies and uncertainties and identify optimal solutions bhaduri et al 2015 lele et al 2013 positive change can only happen if policy makers business owners and consumers alike better understand these interconnections hanlon et al 2013 experiences in participatory water management during the past decades will fit the campaign of policy innovations for few systems for instance integrating and managing the few nexus in transboundary river basins is likely to be impeded by frictions and conflicts in interest among riparian countries as stated by belinskij 2015 the nexus approach to transboundary cooperation requires a long term capacity and trust building between riparian states to create new opportunities through cooperation it is important to recognize that it is not possible to entirely eliminate the tradeoffs across sectors and across stakeholders however framing policies within the nexus approach can help reduce the tensions among stakeholders by maximizing the potential synergies kim et al 2015 scott et al 2011 7 conclusions in this perspective paper we provide our vision of the few nexus giving special attention to how it pertains to the water resources community our vision is characterized by interconnected few processes input output relationships and overlapping institutions and infrastructures we discuss the relevance of existing and ongoing scholarship within the water community and explore current research needs in few processes systems technologies and infrastructures and policies we identify the paths for water researchers to extend our disciplinary strengths within the broader few communities while informing scientists in the food and energy domains about our unique skillset the few nexus paradigm has a clear scope of integration over the interacting areas of food energy and water sectors which may allow interdisciplinary research to progress and research outcomes to be implemented where iwrm has had limited success analysts must be aware that due to the few nexus relationships technology and policy changes can end with either co benefits or unintended tradeoffs and environmental impacts depending on how the changes are guided furthermore few resource use efficiency should be approached by mitigating multiple dimension tradeoffs and enhancing existing or creating new positive synergies all of these advancements will have to be supported by fundamental research pertaining complexities in processes and systems to build on traditional empirical knowledge and methods in water resources systems researchers need to establish new relationships of water and food and water and energy processes using the various sources of existing and newly observed data synthesis of real world nexus issues across the various few systems can be especially helpful in discovering generic knowledge to complement the continuation of work with traditional systems by sector i e water energy and food exploratory research in system of systems or complex system theories and methods will be needed to test and develop innovative few system models decision making mechanisms technologies and institutions in particular knowledge of generic few system mechanisms must be gleaned from new interdisciplinary studies to augment the existing numerous case studies in the current literature for management purposes there is an urgent need to reform the current institutions whose focus are on individual sectors and explore coordinated management of food energy and water wherever needed early warning based on scientific prediction and monitoring should be provided to possible externalities and unintended consequences resulting from few system implementations especially to the environment and underrepresented groups as those occurring with water resources development at many places around the world following the historical efforts in iwrm the water community is provided opportunities for interdisciplinary studies amongst themselves and for collaborations with energy and food communities united by a common path to achieve the sustainable development goals considering the various efforts required to advance few nexus understanding and management every traditional water study group i e hydrologists water resources engineers economists and policy analysts can have a role but it is critical for all groups to integrate our work both within the water sector and across the food and energy sectors acknowledgements senior authorship is shared for this paper this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors edwin cho conducted the art design of figs 2 and 3 supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2017 11 014 appendix supplementary materials image application 1 
892,laboratory experiments have shown that oil production from sandstone and carbonate reservoirs by waterflooding could be significantly increased by manipulating the composition of the injected water e g by lowering the ionic strength recent studies suggest that a change of wettability induced by a change in surface charge is likely to be one of the driving mechanism of the so called low salinity effect in this case the potential increase of oil recovery during waterflooding at low ionic strength would be strongly impacted by the inter relations between flow transport and chemical reaction at the pore scale hence a new numerical model that includes two phase flow solute reactive transport and wettability alteration is implemented based on the direct numerical simulation of the navier stokes equations and surface complexation modelling our model is first used to match experimental results of oil droplet detachment from clay patches we then study the effect of wettability change on the pore scale displacement for simple 2d calcite micro models and evaluate the impact of several parameters such as water composition and injected velocity finally we repeat the simulation experiments on a larger and more complex pore geometry representing a carbonate rock our simulations highlight two different effects of low salinity on oil production from carbonate rocks a smaller number of oil clusters left in the pores after invasion and a greater number of pores invaded keywords pore scale modelling wettability change volume of fluid reactive transport nomenclature variables c concentration mol l d molecular diffusivity m2 s f interior force n m3 h henry constant i ionic strength mol l j molecular diffusion flux mol m2 s k stability constant l characteristic length m m surface concentration mol m2 p pressure pa r bulk chemical reaction molar rate mol m3 s s surface chemical reaction molar rate mol m2 s t temperature k t time s u characteristic velocity m s u velocity m s v surface complex charge z ionic charge α phase volume fraction γ surface sites density mol m2 γ interfacial tension n m κ interface curvature m 1 μ viscosity pa s ψ surface potential v ρ mass density kg m 3 σ surface charge density c m2 θ contact angle constants f faraday constant 96490 c mol g gravity constant 9 81 m s2 r universal gas constant 8 314 j mol k ϵ dielectric constant of pure water 78 41 at 25 c ϵ0 vacuum permittivity 8 854 10 12 c v m subscripts i component index j phase index s surface si surface component index st surface tension abbreviations 25dsw 25 diluted sea water adre advection diffusion reaction equation csf continuous surface force cst continuous species transfer eor enhanced oil recovery fw formation water hs high salinity ihp inner helmholtz plane lbm lattice boltzmann method lse low salinity effect lsf low salinity flooding nse navier stokes equations ohp outer helmholtz plane pdi potential determining ions pnm pore network modelling pv pore volume scm surface complexation modelling ssf sharp surface force sw sea water vof volume of fluid 1 introduction reactive transport in porous media is an essential field of study in a broad range of applications including oil and gas production carbon dioxide co2 sequestration nuclear waste storage and transport of pollutant in the subsurface steefel et al 2005 porosity and wettability changes induced by chemical reactions is relevant to a range of production related applications for oil and gas reservoirs including diagenesis well stimulation and enhanced oil recovery eor these processes are particularly important in the case of carbonate reservoirs for which recovery factors generally do not exceed 30 eor processes such as co2 flooding han and gu 2014 and low salinity flooding lsf mahani et al 2015b have the potential to significantly increase the recovery factors by changing flow properties such as viscosity and wettability and increase the overall sweep efficiency in the reservoir the coupling between chemical reactions and transport is traditionally described at the macro scale by an advection dispersion reaction equation adre however at the macro scale the adre has been shown to give inaccurate predictions of experimental results gramling et al 2002 this discrepancy has been linked with incomplete mixing of the injected and resident fluids alhashmi et al 2015 karadimitriou et al 2017 therefore modelling the reactive transport at the pore scale where the mixing can be resolved on a pore by pore level is a crucial tool to better constrain macroscopic reactions zaretskiy et al 2010 although pore scale non reactive bijeljic et al 2013 hosa et al 2016 kallel et al 2016 and reactive transport alhashmi et al 2015 soulaine and tchelepi 2016 zaretskiy et al 2012 have been studied extensively in recent years only a few studies have included wettability alteration kallel et al 2017 developed a model for wettability alteration during primary drainage based on polar compound adsorption watson et al 2017 included wettability alteration with increasing tracer concentration following a heaviside function for the contact angle none of these studies included the geochemical reactions that are taking place at the water mineral interface and can influence wettability one of the reasons for this is that wettability change induced by manipulating the injected water composition e g lowering the ionic strength is a mechanism that is not fully understood yet mahani et al 2015b tang and morrow 1997 this effect has been associated in the past with a reduction of the salt content of water the so called low salinity effect or lse tang and morrow 1997 however recent advances in experimental work in particular in the domain of fluid visualisation greatly improved the understanding of this phenomenon for sandstones tang and morrow 1997 observed that lse is linked to the presence of clay minerals and also depends on a number of factors such as oil composition formation water composition and salinity of the injected water a number of potential low salinity mechanisms have been proposed in the literature such as fines migration tang and morrow 1999 interfacial tension reduction and emulsification mcguire et al 2005 selective plugging via clay swelling zhang and morrow 2006 and wettability alteration by multicomponent ionic exchange tang and morrow 2002 and or electrical double layer expansion austad et al 2010 berg et al 2010 directly visualised detachment of crude oil from clay minerals they observed a release of crude oil when changing the brine from high to low salinity even when the amount of clay swelling was insignificant for carbonate rocks the effect cannot be related to the presence of clay as most of these rocks do not contain any and if they do they occur only at very low levels moreover the exact chemical composition of the injected water seems to play a more important role than just salinity and ionic strength zhang et al 2007 mahani et al 2015b observed a lse on calcite patches in the absence of dissolution and with an increase of interfacial tension they could link the change of contact angle to a change of ζ potential defined as the local electrical potential at the slipping plane shear plane that separates the stationary and mobile phases in tangential flow of the liquid with respect to the surface hunter 1981 more recently jackson et al 2016a 2016b observed that the increase of oil recovery from carbonate core plugs obtained by manipulating the injected water composition depends greatly on the sign of the ζ potential at both water mineral and water oil interfaces both these studies suggest that lse in carbonate rocks is driven by a wettability change induced by a change of surface charge and the double layer expansion to analyse this effect further surface complexation models scm goldberg 2013 can provide a link between the water composition and the change of potential scm are chemical models that provide a molecular description of adsorption phenomena using an equilibrium approach one of the major advancements of scm is that it considers the charges on both the adsorbing ion and the solid adsorbent surface goldberg 2013 hence scm can provide the link between water composition and change of surface potential scm for clay minerals bradbury and baeyens 1997 calcite and dolomite pokrovsky et al 2000 have been proposed in the context of eor brady and krumhansl 2012 and brady et al 2012 have used such models to investigate reactions at the water oil and water mineral interfaces that lead to oil adhesion on mineral surfaces more recently mahani et al 2016 developed a calcite scm adapted from pokrovsky et al 2000 and modified so that it can explain the impact of sulphate concentration on the ζ potential at the water calcite interface the objective of this work is to develop an internally consistent pore scale numerical model that 1 captures the effect of surface complexation on the surface potential and wettability of carbonate rocks 2 can explain experimental observations at the micro scale and 3 can be easily parameterized to study the impact of different water mineral and oil compositions for this we use direct numerical simulation of the navier stokes equations nse patankar and spalding 1972 to simulate the flow the phase distribution is solved using the volume of fluid vof method hirt and nichols 1981 the transport of chemical species is given by a pore scale adre and the concentration discontinuity at the fluid fluid interface due to thermodynamic dissolution equilibrium is treated using the continuous species transfer cst method deising et al 2016 haroun et al 2010 scm is used to relate the adsorption of the potential determining ions pdi to the change of surface potential mahani et al 2016 two simplified models that can be fitted with experimental data are proposed to relate surface potential to a change of contact angle we then present several applications that 1 show convergence of our numerical method and concordance with experimental results 2 allow us to perform a sensitivity analysis with respect to several parameters and production scenarios on 2d micro models and 3 offer new physical insights into lse 2 flow and reactive transport solvers three different approaches have been previously applied to solve multiphase flow problems at the pore scale pore network models pnm blunt and king 1991 lattice boltzmann method lbm pan et al 2004 and direct numerical simulation dns patankar and spalding 1972 of the nse pnm are computationally efficient but are based on simplified idealised geometries of the pore surface which may impact modelling dynamic wettability changes moreover standard pnm are quasi static which limits their predictive capability especially for complex recovery processes where wettability changes dynamically dynamic pore network models have appeared recently joekar niasar et al 2010 nordhaug et al 2003 but are generally based on adding a notional time dependency to the invasion percolation mechanism determined by flow rates obtained from solving the quasi static problem moreover reactive transport models based on pnm usually assume full mixing in pore bodies and throats lbm is based on the discrete boltzmann equations which describes the fluids in terms of the movement and collisions of a set of particles lbm does not require solving an implicit pressure equation and therefore can be easily parallelized however lbm cannot accommodate additional physical effects such as wall slip and dynamic contact angles easily and has difficulties handling large viscosity and density ratios meakin and tartakovsky 2009 dns methods can either be mesh free like the smoothed particle hydrodynamics method tartakovsky and meakin 2006 or grid based like the finite volume method mesh free methods represent sharp interface accurately and are easily parallelized however they are difficult to extend to reactive transport as they do no solve for concentration of species in the domain in this work we hence choose to use grid based dns with the vof method hirt and nichols 1981 2 1 the volume of fluid method in the vof method the interface between two fluids is tracked using an indicator function α which represents the volume fraction of one of the fluid in each grid cell if the cell is completely filled with the first fluid then α 1 and if it is filled with the second fluid then α 0 for cells which are crossed by the interface α lies between 0 and 1 the density and viscosity of the fluid are deduced by linear interpolation from the indicator function 1 ρ α ρ 1 1 α ρ 2 μ α μ 1 1 α μ 2 where ρi and μi are the density and viscosity of phase i respectively the single field velocity u is defined as 2 u α u 1 1 α u 2 where u i is the velocity of phase i the nse can be written with the single field formalism hirt and nichols 1981 3 u 0 ρ u t u u p τ ρ g f s t where p is the pressure g is the gravity vector τ is the viscous stress tensor and f st is the surface tension force the viscous stress tensor can be expresses as 4 τ μ u u t the reynolds number is defined as the ratio of inertial to viscous forces 5 r e ρ l u μ where l and u are the reference length and velocity in the domain and ρ and μ are the density and viscosity of the invading phase the reynolds number is used to characterise different flow regimes such as laminar flow where viscous forces are dominant and turbulent flow where inertial forces are dominant in this work we only consider cases where re 1 so that we are in the so called creeping flow regime lenormand et al 1988 the indicator function α is evolved with the advection equation 6 α t α u 0 vof methods can be algebraic or geometric algebraic methods resolve the interface by solving a discretized form of the phase advection equation eq 6 on a computational mesh ubbink and issa 1999 while the geometric methods explicitly reconstruct the interface so that the solution of the advection equation conserves the volume fraction exactly gerlach et al 2006 geometric methods do not create numerical diffusion and can achieve better precision with accurate interface reconstruction popinet 2009 but the calculations can be complicated especially for unstructured grids algebraic methods can be easily applied to unstructured grids as no explicit interface reconstruction is needed but numerical diffusion can smear the interface over a large number of cells here we use compression of the interface to reduce this problem ubbink and issa 1999 the surface tension force can be modelled using the continuum surface force csf formulation introduced by brackbill et al 1992 7 f s t γ κ α where γ is the interfacial tension between the two fluids and κ the mean interface curvature which can be computed as 8 κ n 12 where n 12 is the interface normal vector defined as 9 n 12 α α at the fluid fluid solid contact line the interface forms with the normal to the solid surface a micro scale contact angle θ so that 10 n 12 cos θ n s sin θ t s where n s and t s are the normal and tangent vectors to the solid surface respectively brackbill et al 1992 the capillary number ca is defined as the ratio of viscous to surface tension forces 11 c a μ u γ and describes if the system is in the viscous dominated regime ca 1 or in the capillary dominated regime ca 1 the vof csf method is attractive because of its simplicity however scardovelli and zaleski 1999 reported the presence of spurious currents in the capillary dominated regime which originate from errors in calculating the normal vector and the curvature of the interface to limit the spurious currents one can apply the sharp surface force ssf method introduced by francois et al 2006 where the indicator function is smoothed by a laplacian smoother for the computation of the curvature and sharpened by a curtail function for the computation of the surface tension force alternatively the filtered surface force fsf introduced by raeini et al 2012 filters the components of the capillary force that are parallel to the interface ssf and fsf reduce spurious currents considerably raeini et al 2012 especially for static test cases however pavuluri et al 2017 show that spurious currents appear when simulating spontaneous imbibition in a 2d straight micro channel with vof ssf and vof fsf at c a 10 3 but they also show that these spurious currents do not affect the global dynamic of the system for c a 10 4 in this work we use ssf and a minimum capillary number c a 10 5 spurious currents may be present but we assume that they do not affect the global dynamic of the system 2 2 continuous species transfer during a reactive transport process the mass of each species in the fluid changes due to transport by advection and diffusion and due to reactions the conservation equation satisfied by the concentration c j i of a chemical species j in phase i reads 12 c j i t c j i u i j j i r j i where j j i is the molecular diffusion flux of j in phase i and r j i is the molar rate of creation of j in phase i by chemical reactions in the pore space in mol m3 s we assume that the molecular diffusion follows fick s law 13 j j i d j i c j i where d j i is the molecular diffusivity of j in phase i reactions that take place at the solid fluid boundaries such as surface adsorptions are not included in r j i instead they are expressed as boundary conditions on reactive surfaces steefel et al 2013 14 d j i c j i n s s j i where s j i is the molar rate of creation of j in phase i by surface adsorption desorption reactions in mol m2 s and n s is the normal to the surface of the mineral in the absence of phase change and chemical reactions at the fluid fluid interface the jump conditions are given by the continuity of fluxes and chemical potentials the latter described here by henry s law danckwerts 1970 15 j j 1 j j 2 n 12 0 and 16 c j 1 h j c j 2 where hj is the henry s coefficient for species j haroun et al 2010 and marschall et al 2012 developed the cst method to model the interface species transfer within the vof method by defining the global variable 17 c j α c j 1 1 α c j 2 the global concentration adre is given by 18 c j t c j u j j r j where 19 j j α 1 d j 1 c j 1 α 2 d j 2 c j 2 r j α 1 r j 1 α 2 r j 2 haroun et al 2010 shows that the diffusion flux j j can be written as 20 j j d j c j φ j where 21 d j 1 α 1 d j 1 α 2 d j 2 φ j d j 1 h j α 1 h j α 2 c j α 1 here d j is the harmonic interpolation of the phase diffusion coefficient haroun et al 2010 and deising et al 2016 have demonstrated that this formulation is more robust than a simple mixing rule the additional flux φj is the cst flux which results from the concentration jump at the interface finally graveleau 2016 derived the boundary conditions for the global concentration at the solid walls in case of a moving contact line in the absence of surface reaction this can be adapted to include surface reactions 22 d j c j φ j n s s j where the global surface reactions rate sj writes 23 s j α 1 s j 1 α 2 s j 2 the flow regime is described by the péclet number which is equal to the ratio of convection to diffusion rate 24 p e j l u d j where l and u are the reference length and velocity respectively and dj is the diffusion coefficient of species j in the invading phase the system is in the convection dominated regime for species j when pej 1 and in the diffusion dominated regime when pej 1 2 3 surface complexation in this work we consider two different types of minerals calcite and clay for calcite we use the scm developed by mahani et al 2016 the rock surface presents two hydrolysis species co3h0 and caoh0 where represents the mineral surface the following species are assumed to form on the calcium and carbonate sites exposed to an aqueous solution co 3 co3ca co3mg cao caco 3 cahco 3 0 and caso 4 we assume that the surface density γ of ca sites and co3 sites are both equal to 8 27 µmol m2 pokrovsky et al 2000 the surface complexation reactions are summarised in table 1 for clay patches we use the na montmorillonite scm proposed by bradbury and baeyens 1997 summarised in table 2 the surface density γ of adsorption sites s is equal to 2 4 µmol m2 for simplification we assume that all reactions occur only on the calcite mineral surface often termed 0 plane and that charge and potential can be determined using a simple double layer model goldberg 2013 the total surface charge σs can be obtained by adding up the charge of all surface complex 25 σ s f i m s i v s i where msi and vsi are the surface concentration and the charge of the complex si respectively and f is the faraday constant the double layer surface potential ψs is related to the surface charge by the grahame equation israelachivili 1985 26 σ s 2 8000 ϵ ϵ 0 rti sinh f ψ s 2 rt 2 where ϵ is the dielectric constant of pure water ϵ0 is the vacuum permittivity i is the ionic strength of the electrolyte solution r is the ideal gas constant and t is the temperature since charged ions are attracted to or repelled from the solid surface due to coulomb interactions the apparent stability constant k is different from the intrinsic one kint the relationship between the two is given by israelachivili 1985 27 k k i n t exp z c f ψ s r t where zc is the net change of surface charge induced by the reaction for example 1 for reaction 1 in table 1 the reaction rates r j i eq 12 and s j i eq 14 are obtained by equilibrating the chemical model table 1 or 2 with the double layer model eqs 25 27 2 4 contact angle alteration it has been observed in experimental work mahani et al 2015a 2015b 2017 that the surface of a sandstone or a carbonate rock becomes less oil wet when switching from high salinity to low salinity water for example mahani et al 2015a found a change of contact angle δ θ 10 40 for an oil droplet on a clay patch when switching from a high salinity brine to a low salinity brine obtained by diluting the initial brine 4 8 or 16 times mahani et al 2015b also found a change of contact angle δ θ 5 20 on limestone patches and δ θ 0 45 on dolomite patches when switching from a high salinity formation water fw to sea water sw or 25 times diluted sea water 25dsw these water compositions are given in table 3 in the study of mahani et al 2015b ζ potentials at the water oil and at the water rock interfaces were also measured the water oil ζ potential was observed to be negative and decreasing from fw to sw and 25dsw for limestone particles the water rock ζ potential was observed to be positive for fw but negative for sw and 25dsw a contact angle reduction was also observed for dolomite particles the ζ potential remained positive for all three water compositions contact angle reduction was observed for sw but not for 25dsw to explain these changes of contact angle it was proposed that the change of ζ potential from positive to negative modifies the electrostatic forces between the oil molecule and the water rock interface from adhesive to repulsive brady and krumhansl 2012 buckley et al 1989 this would explain why no contact angle reduction was observed on dolomite particles for 25dsw the change of contact angle for sw on dolomite patches could be further explained by an increase of the separation distance between oil and dolomite due to the large concentration of so 4 2 mahani et al 2015b in our simplified scm we assume that all surface reactions occur on the 0 plane fig 1 this implies that the ζ potential and the potential at the surface of the calcite are equal in reality only protonation and deprotonation reactions e g reactions 1 and 4 in table 1 occur on the 0 plane for example in a basic stern model fig 1 a layer of constant capacitance the stern layer separates the mineral surface from the diffuse layer and reactions other than protonation and deprotonation e g reactions 2 3 5 6 and 7 in table 1 occur on the inner or outer planes of the stern layer also called inner helmholtz plane ihp and outer helmholtz plane ohp al mahrouqi et al 2017 therefore the ζ potential and the 0 plane potential can differ greatly since the reactions involving divalent ions occur on the ihp and ohp planes the ζ potential would be more accurately approximated by the ohp potential unfortunately the geochemical simulator used in our numerical model phreeqc see section 2 5 does not include basic stern model hence we are using instead a simple double layer model fig 1a fig 2 shows a comparison between the ζ potential at a water calcite interface experimentally obtained by heberling et al 2011 and mahani et al 2016 and the surface potential computed using the scm table 1 with a simple double layer model the different water compositions are represented in term of the concentration of potential determining ions ca 2 mg 2 and so 4 2 we observe that the double layer surface potential ψs only matches the trend of the ζ potential nevertheless a simple model that describes the variation of contact angle change with ψs can be used to study the link between flow and wettability change induced by surface complexation and provide new insights into the process of wettability change by surface complexation in the absence of robust quantitative experimental data that links surface potential to contact angle variation two simple models are considered in this work in the first model we assume that the contact angle changes linearly with the surface potential 28 θ f l ψ s θ 0 ψ s ψ 0 θ 1 θ 0 ψ 1 ψ 0 this model can be easily fitted to contact angle measurements and can be easily extended to piecewise linear functions so that the function can be fitted with a large number of experimental measurements however this model cannot explain why 25dsw does not always induce more contact angle changes that sw the second model considered here used a heaviside function watson et al 2017 with a critical surface potential assumed to be equal to 0 for simplification 29 θ f h ψ s θ 0 ψ s 0 θ 0 δ θ ψ s 0 the first model eq 28 is used in all applications in this study the second model eq 29 is used in section 3 4 to conducting a sensitivity analysis with respect to the contact angle model 2 5 numerical implementation the mathematical model given by the nse eq 3 and the phase advection equation eq 6 is implemented in the open source computational fluids dynamics software openfoam www openfoam org as an internal vof solver so called interfoam interfoam solves the nse on a collocated eulerian grid with a predictor corrector strategy based on the pressure implicit splitting operator piso algorithm issa et al 1985 an explicit formulation is used to treat the coupling between the phase distribution equation eq 6 and the nse this imposes a limit on the time step size by introducing a capillary wave time scale described by the brackbill conditions brackbill et al 1992 in all simulations we use a constant time step that satisfies this condition time discretization is performed using the crank nicolson scheme and space discretization is performed using the second order van leer scheme van leer 1974 for the purpose of this work we extended the interfoam solver to perform two phase reactive transport simulations the concentration equation eq 18 is solved sequentially after the phase conservation equation eq 6 time discretization is again based on the crank nicolson scheme the advection term cu and the cst flux φ space discretization is again based on the second order van leer scheme van leer 1974 the diffusion term dj cj is discretized using the gauss linear limited corrected scheme which is second order and conservative all of these discretization schemes are available in the standard openfoam distribution the surface complexation model eqs 25 27 is solved using the us geological survey chemical package phreeqc www usgs gov software phreeqc the coupling between transport and reactions is handled by a sequential split operator method carrayrou et al 2004 first the transport step solves the system of equations in the absence of chemical reactions using openfoam then the reaction step solves the system in the absence of flow using phreeqc for this the concentration boundary condition on a reactive surface eq 22 is integrated over a control volume and gives an additional source term in the adre eq 18 our numerical model was validated by comparison with analytical solutions for spontaneous imbibition in a 2d rectangular channel pavuluri et al 2017 for steady state interface mass transfer in a 2d tube graveleau 2016 and for linear retardation in a 1d semi infinite column ogata and banks 1961 for each case the numerical solution was shown to converge toward the analytical solution and a relative error below to 1 was obtained for sufficient resolution additional convergence tests are shown in section 3 3 3 applications we present five applications of our numerical model first we consider a batch experiment investigating the equilibrium between calcite and water for different water compositions and the corresponding change of surface potential secondly we simulate the detachment of an oil droplet from a clay patch and compare 3d simulations with experimental results mahani et al 2015a thirdly we study the convergence of the numerical model and the final residual oil saturation for the invasion of an idealised 2d square shaped pore by different types of water fourthly we consider a simple 3 3 heterogeneous calcite micro model in order to perform a sensitivity analysis with respect to several parameters of the model finally we simulate water invasion in a complex 2d porous media and study different production scenarios for all 2d applications gravity is ignored the fluids used are water and oil we used four different water compositions table 3 that have been used previously in experimental studies high salinity hs brine obtained by dissolving pure salts nacl kcl cacl2 h2o and cacl2 h2o into pure water mahani et al 2015a formation water fw from a middle eastern carbonate field sea water sw and 25 times diluted sea water 25dsw mahani et al 2016 the diffusion coefficients of ions in water are obtained from li and gregory 1973 and are summarised in table 4 the initial concentration of ions in the oil phase is zero and the henry constant of every ions is assumed to be 0 too so that there is no ion transfer between the phases the oil density and viscosity are equal to 840 kg m3 and 6 5 mpa s north sea crude oil from mahani et al 2015a respectively the interfacial tension is equal to 10 mn m 3 1 decomposition of low salinity effect on calcite as mentioned previously lse is a mechanism that is still not well understood and more studies are necessary to capture the driving factors and predict an increase in oil recovery in this example we use scm to decompose the lse on calcite mahani et al 2016 studied the effect of ph on the surface potential however as it has been noted by alroudhan et al 2016 and jackson et al 2016a a modification of the ph would change the dissolution equilibrium between calcite and water and can greatly affect the concentration of ca 2 in the water instead these studies analysed the evolution of surface potential with the concentration of pdis using the scm defined in table 1 we identify three mechanisms responsible for lowering the surface potential of the calcite when switching from fw to 25dsw a desorption of ca 2 and mg 2 these ions are in competition with h for a co3 surface site lower concentration of the divalent ions generates more sorption of the monovalent ion therefore lowering the positive part of the surface charge b sorption of so 4 2 and desorption of hco 3 these ions are in competition with oh for a ca surface site lower concentration of the monovalent ions generates more sorption of the divalent ion therefore increasing the negative part of the surface charge c lowering the concentration of surface inert ions na k sr 2 and cl in solution this affects the surface potential by lowering the ionic strength of the solution we perform three simulations in phreeqc which represents batch experiments to study the effect of each mechanism first we lower the concentration of ca 2 and mg 2 in solution while keeping the other concentrations constant then we lower the concentration of so 4 2 and hco 3 finally we lower the concentration of na k sr 2 and cl a b c then we change the order of the steps b c a and c a b fig 3 shows the evolution of surface potential with ionic strength during each step for each simulation we observe that in each case step a has the most impact on the surface potential the average change of surface potential is 40 mv this is because fw has a very high initial concentration of ca 2 and mg 2 initially every co3 site is occupied by a divalent ion lowering the concentration of these ions has therefore a major impact on the surface charge step b has a smaller impact on the surface potential the average change of surface potential is 8 mv note that here we lower the concentration of the divalent ion so 4 2 which by itself should increase the surface charge but we also lower the concentration of hco 3 so that the relative concentration of divalent ions actually increases and the surface charge decreases the effect is less important than step a since the initial concentration of so 4 2 is large enough so that most of ca sites are initially occupied by a divalent ion finally we observe that step c can have either a positive or a negative impact on the surface potential indeed step c only marginally changes the surface adsorption as it only affects the ionic strength therefore it does not change the sign of the surface potential only the magnitude indeed when we perform step c first the surface potential actually increases from 7 to 8 5 mv this analysis shows that the surface potential is more affected by the chemical composition of the water than by its salinity it also suggests that the driving mechanism of the lse on calcite is the desorption of ca 2 and mg 2 ions the effect of other ions in particular sulphate and bicarbonate depends strongly on the composition of the formation water this confirms the trends observed in fig 2 mineralogy could also have a large impact e g presence of dolomite 3 2 oil droplet detachment from a clay patch in this section we consider an oil droplet on a clay patch the system is equilibrated first under high salinity brine hs table 3 before switching to a low salinity brine obtained by diluted hs 4 times the hs equilibration lasted 72 h and we focused here on the second part of the experiment the volume of the droplet is equal to 3 1 mm3 at equilibrium with hs the contact angle θ is equal to 55 o and the initial contact area is equal to 1 1 mm2 the surface potentials computed with phreeqc are equal to 7 3 mv when equilibrated with hs and 15 6 mv with the 4 times diluted brine the contact angle variation is modelled using a linear function eq 28 fitted to experimental data from mahani et al 2015a for the initial contact angle and the contact angle at detachment fig 4 we use a uniform 3d cartesian grid with δ x δ y δ z 0 05 mm the surface of the clay patch reacts with the low salinity brine and calcium ions are desorbed from the surface eq 14 the excess of calcium and magnesium diffuses away from the surface of the patch and more reaction occurs the electric potential of the solid surface decreases and as a result the contact angle changes and the oil droplet recedes from the surface until it detaches by buoyancy fig 7 however mahani et al 2015a observed a time scale of detachment two order of magnitude longer than expected by diffusion only they proposed that this discrepancy could be explained by electrostatic effects in the thin film than forms near the charged clay surface fig 5 shows a schematic representation of these electrostatic effects the variation of surface potential induces a gradient of electrostatic potential inside the thin film opposed to the gradient of cation concentration therefore the electrostatic force generates a flux opposed to the diffusion flux this can be modelled using the nernst planck equation in the thin film 30 j j d j c j z f c j r t ψ however this cannot be simply implemented in our model at the micro scale because the thin film is of a few nano meters in thickness instead we include these effects by modifying the molecular diffusion near the surface the boundary condition for the phase concentrations on a reactive surface eq 14 is replaced by 31 d j i n s c j i n s s j i where dns is the near surface diffusion fig 6 shows the evolution of the contact angle during the simulation for different values of dns and a comparison with experimental data presented in mahani et al 2015a first we use d n s d where d represents the values presented in table 4 we obtain a time of detachment of 250 s then we use d n s d 10 d n s d 100 and d n s d 150 we observe that for d n s d 150 the numerical simulation matches qualitatively the experiment fig 7 shows the evolution of the droplet shape with time during the simulation we conclude that our numerical model is able to match experimental results obtained in mahani et al 2015a however there are two drawbacks of not including the thin film in the model explicitly first the parameters dns cannot be evaluated a priori and need to be matched by comparison with experimental results in test cases 3 3 and 3 5 the electrostatic effects are ignored while in test case 3 4 the sensitivity of the recovery factor with respect to dns is explored secondly bartels et al 2017 show that the low salinity effect can induce oil remobilisation without buoyancy joekar niasar and mahani 2017 show that the pressure dynamic inside the thin film can lead to expansion of the film and deformation of the fluid fluid interface potentially resulting in oil remobilisation in test cases 3 3 and 3 4 the initial saturation of water is ignored so that no oil is trapped and the effect of pressure in the thin film can be ignored in test case 3 5 we show that our model can simulate the increase of pore scale sweep efficiency in response of low salinity flooding but not the oil remobilisation effect in the absence of buoyancy 3 3 2d square shaped pore in this application we consider a single idealised and two dimensional idealised pore constituting of one square connected to two throats we explore the convergence of the numerical model fig 8 presents the geometry of the domain and the inlet and outlet boundary conditions the pore surfaces are assumed to be calcite table 1 the pore space is initially filled with oil but the surface of the pore is at equilibrium with a nano scale thin film of fw table 3 the surface potential calculated with phreeqc is equal to 7 mv but the effect of the thin film on the hydrodynamics of the system is ignored α 0 and d n s d at t 0 s we inject fw sw or 25dsw at the inlet with a velocity of 1 mm s which corresponds to a capillary number c a 10 4 the surface potential of the calcite equilibrated with sw respectively 25dsw computed with phreeqc is equal to 9 mv respectively 40 mv to explore convergence and sensitivity for different values of contact angles we assume θ fw 120 θ sw 110 o and θ sw 90 o this corresponds to θ ψ 0 64 mv eq 28 to study grid convergence for each case fw sw and 25dsw we use a fine grid solution δ x δ y 0 5 µm as a reference solution all cells containing solids are removed and replaced by rectangular and triangular cells that match the solid boundaries we then compare the final residual oil saturation in the domain obtained at different grid resolutions fig 9 shows the evolution of the relative error for the three cases we observe that the simulations have converged for a resolution of 1 µm fig 10 shows the corresponding evolution of the indicator function α and the water ph during invasion with fw sw and 25dsw blue corresponds to water and red to oil the water ph during fw invasion remains constant equal to 6 9 during the simulation since calcite has been previously equilibrated with fw at the end of the simulation a significant fraction of oil remains at the top and bottom corner of the pore this corresponds to a residual oil saturation s or fw 0 07 during invasion with sw the contact angle changes from 120 to 110 as calcite equilibrates with water we observed that the ph increases from 8 to approximately 9 near the pore surface where the reactions take place at first glance this observation could be surprising as the calcite has been previously equilibrated with fw which has a ph of 6 9 however we show in section 3 1 that the most important mechanism of surface potential reduction during the replacement of fw by 25dsw is the desorption of calcium and magnesium on the pore surface this is described by reactions 2 and 3 in table 1 during these reactions h ions are adsorbed onto the surface effectively increasing the ph of the solution at the end of the simulation oil still remains at the top and bottom of the pore but the residual oil saturation s or sw is 0 03 which corresponds to an increase of oil recovery of 4 during invasion with 25dsw the contact angle changes from 120 to 90 as the calcite equilibrates with water more ca 2 and mg 2 are desorbed from the calcite and more h is adsorbed the effect of surface reactions on the ph is stronger especially near the inlet where 25dsw is in contact with calcite for the first time at the end of the simulation almost no oil remains at the top and bottom of the pore and the residual oil saturation s or sw is 0 0025 which corresponds to an increase of oil recovery of 6 75 our simulations show that flooding by a low salinity water leaves a smaller amount of residual oil inside a pore as observed experimentally by berg et al 2010 and chen et al 2010 our numerical model can then complement such experiments by providing additional information such as ph evolution 3 4 3 3 heterogeneous micro model in this section we consider a 2d micro model formed by subtracting four rectangles in a 2d square of calcite table 1 the resulting micro model includes 3 3 nodes and is presented in fig 11 similarly to the previous test case the domain is initially filled by oil α 0 but the pore surfaces are at equilibrium with a nano scale fw thin film table 3 so that the surface potential computed with phreeqc is equal to 7 mv the aim of this test case is to analyse how recovery factors vary with water composition contact angle change injection velocity and near surface diffusion for this we assume θ f w 120 θ s w 110 and θ s w 90 first we assume that the contact angle is a linear function of the surface potential eq 28 that the injection velocity u is equal to 1 mm s c a 10 4 and that d n s d we perform a convergence study similar to the one conducted in the previous application section 3 3 and we obtain convergence for a grid with a resolution of 1 µm fig 12 shows the evolution of the indicator function α during invasion with fw sw and 25dsw blue corresponds to water and red to oil we observe that sw invades more throats than fw and that 25dsw invades the entire domain this indicates an increase of pore scale sweep efficiency with reduction of water salinity this can also be observed in a more complex 2d pore structure as discussed in section 3 5 below the residual oil saturation are s or fw 0 177 s or sw 0 077 and s or 25dsw 0 001 these correspond to an increase of oil recovery of 10 and 17 6 for sw and 25dsw respectively we then perform a sensitivity analysis considering four different parameters water composition described here by ionic strength i 0 87 for sw and i 0 035 for 25dsw contact angle model eq 28 or eq 29 injection velocity 1 or 0 1 mm s and near surface diffusion d n s d or d n s d 10 to perform the sensitivity analysis and compare the results we use a two level factorial design myers et al 2009 and a measure of performance equal to the increase of recovery factor by comparison with fw injection table 5 shows the full summary of the sensitivity analysis the response is then analysed using a first order model with interactions myers et al 2009 fig 13 shows the corresponding pareto chart myers et al 2009 showing the eight most important effects we observe that the most important factors are the injection velocity the near surface diffusion and the water composition described here by the ionic strength i the impact of the contact angle model is small in comparison and can be ignored as a first order approximation we also note that an important part of the impact of u and dns is due to their interaction this can be expressed in term of the near surface diffusion péclet number 32 p e j n s l u d j n s we use the average pore throat radius l 5 21 µm as a reference length this gives péclet numbers between 0 53 and 7 45 for test cases 1 to 4 so that we are in the transitional regime where advection and diffusion have similar time scales for test cases 5 to 8 p e n s ranges from 0 053 to 0 745 so that we are now in the diffusion dominated regime here the recovery factors slightly increase however for test cases 9 to 12 p e n s number ranges from 5 3 to 74 5 in these cases we are in the advection dominated regime and the increase of recovery factor is almost zero finally for test cases 13 to 16 p e n s ranges again from 0 53 to 7 45 here the recovery factors are identical to the ones for test cases 1 to 4 this suggests that the most important factor for the low salinity effect is the flow regime advection needs to be sufficiently slow to cause a diffusion induced change in contact angle near the water solid interface 3 5 complex 2d porous medium in this test case we consider a complex 2d porous medium representing a thin section of a real carbonate grainstone zaretskiy et al 2010 the pore surfaces are assumed to be calcite table 1 the geometry and boundary conditions are summarised in fig 14 the porosity and permeability of the sample have been numerically estimated to 0 4 and 0 71 10 12 m2 respectively the aim of this test case is to study three different production scenarios fw injection sw injection and fw injection followed by sw injection we assume that the domain is initially filled by oil α 0 but the pore surfaces are at equilibrium with a nano scale fw thin film table 3 so that the surface potential computed with phreeqc is equal to 7 mv the surface potential of the calcite equilibrated with sw computed with phreeqc is equal to 9 mv the contact angle is assumed to be a linear function of the surface potential eq 28 fitted with experimental data for an oil droplet on a limestone plate from mahani et al 2015b fig 15 the domain is represented by a 2d uniform cartesian grid comprising 1000 500 grid blocks all cells containing solid are removed and replaced by rectangular and triangular cells that match the solid boundaries the final grid contains 204 728 cells fig 16 shows the evolution of the indicator function α during fw and sw injection at different times corresponding to 0 25 0 5 1 and 2 pore volume pv injected we observe that the overall residual oil saturation is impacted by the change of wettability in two ways first the water phase remains more connected during sw flooding compared to fw flooding as a consequence fw leaves a larger number of small clusters of oil in the pore space after invasion this is particularly visible in the solid rectangle shown on fig 16 secondly the invasion pattern changes and more pores are being invaded during sw flooding compared to fw flooding this is particularly visible in the dashed rectangle shown on fig 16 both these effects contribute to an increase of pore scale sweep efficiency induced by wettability change after 3 pv injected the oil saturation has reached an equilibrium in both cases we then consider the production scenario where we inject 2 pv of fw followed by 2 pv of sw fig 17 compares the final phase distributions for fw flooding only and fw flooding followed by sw flooding we observe that the amount and form of oil clusters left in the pore space after invasion solid rectangle on fig 17 remain mostly unchanged this suggests that even though our numerical model can simulate droplet detachment by buoyancy under lse section 3 2 it is not able to simulate oil remobilisation due to lse in the absence of buoyancy bartels et al 2017 observed oil remobilisation in the absence of buoyancy in a 2d micro model and showed that the mechanism was driven by thin film dynamics which we do not include in our model however we do observe an increase in the number of invaded pores dashed rectangle on fig 17 the change of wettability reduces the capillary resistance in the domain and unlocks additional pores for the water invasion fig 18 shows the evolution of the oil saturation in the domain during fw flooding sw flooding and fw flooding followed by sw flooding the final oil saturations are s or fw 0 402 s or sw 0 341 and s or fw sw 0 318 these correspond to an increase of oil recovery of 15 2 for sw and 20 9 for fw sw our investigation shows that wettability change induced by surface complexation during low salinity flooding can result in an improvement of pore scale sweep efficiency this has been previously observed in experimental studies on sandstone core plug kumar and mohanty 2011 zhang and morrow 2006 zhang et al 2007 but was associated with selective plugging via clay swelling bernard 2011 zhang and morrow 2006 our study suggests that this improvement of sweep efficiency could also applied to carbonate reservoir and be induced by the temporal evolution of the contact angle this changes during lsf the set of pores and throats that become accessible to the invaded phase 4 concluding remarks a novel pore scale reactive transport model has been developed and validate with the aim of providing new insights into wettability alteration by surface complexation as a mechanism of lsf using 3d and 2d simulations based on the five applications considered here we propose the following key conclusions the change of surface potential at the calcite water interface is not driven by the ph of the injected water but by the concentration of pdi such as ca 2 and mg 2 for the water compositions considered here the concentration of so 4 2 has only a small impact our numerical model is able to reproduce the evolution of the oil droplet shape with time during detachment from a clay patch for this the molecular diffusion near the surface of the solid need to be fitted to take into account electrostatic effect on simple 2d models e g a square pore and a 3 3 micro models we show that our numerical model is convergent a sensitivity analysis carried out for the 3 3 micro model show that the most important parameters controlling the residual oil saturation are the velocity at which water is injected and the near surface diffusion we further show that the lse is only observed if the transport regime is such that diffusion has a smaller or similar time scale as advection so that the low salinity water has time to diffuse into the thin water film separating the oil and mineral surfaces and can induce a change in contact angle by performing simulation on a complex 2d porous medium we show that our numerical model is able to explain an increase of pore scale sweep efficiency with lsf more generally the results of our simulations highlight two effects of wettability alteration due to surface complexation during lsf namely a decrease in the amount of residual oil left in the pore space after invasion and an increase of the number of pores that are invaded the former is simply a consequence of calcite being more water wet but the latter is induced by the temporal evolution of contact angle and cannot be captured readily in static or quasi dynamic pore network models this dynamic effect changes the set of pores and throats that become accessible to the invading brine during lsf however our model was not able to simulate the remobilisation mechanism observed when injecting low salinity water after formation water bartels et al 2017 including thin film hydrodynamics abu al saud et al 2017 and electrostatic effect inside the thin film joekar niasar and mahani 2017 could potentially solve this issue our numerical modelling gives new insights into several mechanisms inducing an increase in oil recovery during low salinity flooding we have focused on the impact of several parameters namely the water composition the injected velocity the contact angle model and the diffusivity in the thin film since our model can be parameterized easily it can be used to study the impact of other factors such as oil and mineral compositions for example the evolution functions of contact angle with surface potential that we used in our examples were only calibrated with two data points if more data points are made available the evolution function can be obtained by interpolation and the contact angle model can be replaced with a more sophisticated approximation future work could focus on comparison with experimental observation on micro models bartels et al 2017 then our numerical model could be fully deployed to perform detailed sensitivity analysis on 3d micro ct images for example to develop quantitative and semi quantitative rules that guide invasion by low salinity water for pore network modelling studies watson et al 2017 acknowledgement we would like to thank petrobras and shell for their sponsorship of the iccr program and the permission to publish this work from the reactcarb project sebastian geiger further thanks the energi simulation foundation for supporting his chair programme 
892,laboratory experiments have shown that oil production from sandstone and carbonate reservoirs by waterflooding could be significantly increased by manipulating the composition of the injected water e g by lowering the ionic strength recent studies suggest that a change of wettability induced by a change in surface charge is likely to be one of the driving mechanism of the so called low salinity effect in this case the potential increase of oil recovery during waterflooding at low ionic strength would be strongly impacted by the inter relations between flow transport and chemical reaction at the pore scale hence a new numerical model that includes two phase flow solute reactive transport and wettability alteration is implemented based on the direct numerical simulation of the navier stokes equations and surface complexation modelling our model is first used to match experimental results of oil droplet detachment from clay patches we then study the effect of wettability change on the pore scale displacement for simple 2d calcite micro models and evaluate the impact of several parameters such as water composition and injected velocity finally we repeat the simulation experiments on a larger and more complex pore geometry representing a carbonate rock our simulations highlight two different effects of low salinity on oil production from carbonate rocks a smaller number of oil clusters left in the pores after invasion and a greater number of pores invaded keywords pore scale modelling wettability change volume of fluid reactive transport nomenclature variables c concentration mol l d molecular diffusivity m2 s f interior force n m3 h henry constant i ionic strength mol l j molecular diffusion flux mol m2 s k stability constant l characteristic length m m surface concentration mol m2 p pressure pa r bulk chemical reaction molar rate mol m3 s s surface chemical reaction molar rate mol m2 s t temperature k t time s u characteristic velocity m s u velocity m s v surface complex charge z ionic charge α phase volume fraction γ surface sites density mol m2 γ interfacial tension n m κ interface curvature m 1 μ viscosity pa s ψ surface potential v ρ mass density kg m 3 σ surface charge density c m2 θ contact angle constants f faraday constant 96490 c mol g gravity constant 9 81 m s2 r universal gas constant 8 314 j mol k ϵ dielectric constant of pure water 78 41 at 25 c ϵ0 vacuum permittivity 8 854 10 12 c v m subscripts i component index j phase index s surface si surface component index st surface tension abbreviations 25dsw 25 diluted sea water adre advection diffusion reaction equation csf continuous surface force cst continuous species transfer eor enhanced oil recovery fw formation water hs high salinity ihp inner helmholtz plane lbm lattice boltzmann method lse low salinity effect lsf low salinity flooding nse navier stokes equations ohp outer helmholtz plane pdi potential determining ions pnm pore network modelling pv pore volume scm surface complexation modelling ssf sharp surface force sw sea water vof volume of fluid 1 introduction reactive transport in porous media is an essential field of study in a broad range of applications including oil and gas production carbon dioxide co2 sequestration nuclear waste storage and transport of pollutant in the subsurface steefel et al 2005 porosity and wettability changes induced by chemical reactions is relevant to a range of production related applications for oil and gas reservoirs including diagenesis well stimulation and enhanced oil recovery eor these processes are particularly important in the case of carbonate reservoirs for which recovery factors generally do not exceed 30 eor processes such as co2 flooding han and gu 2014 and low salinity flooding lsf mahani et al 2015b have the potential to significantly increase the recovery factors by changing flow properties such as viscosity and wettability and increase the overall sweep efficiency in the reservoir the coupling between chemical reactions and transport is traditionally described at the macro scale by an advection dispersion reaction equation adre however at the macro scale the adre has been shown to give inaccurate predictions of experimental results gramling et al 2002 this discrepancy has been linked with incomplete mixing of the injected and resident fluids alhashmi et al 2015 karadimitriou et al 2017 therefore modelling the reactive transport at the pore scale where the mixing can be resolved on a pore by pore level is a crucial tool to better constrain macroscopic reactions zaretskiy et al 2010 although pore scale non reactive bijeljic et al 2013 hosa et al 2016 kallel et al 2016 and reactive transport alhashmi et al 2015 soulaine and tchelepi 2016 zaretskiy et al 2012 have been studied extensively in recent years only a few studies have included wettability alteration kallel et al 2017 developed a model for wettability alteration during primary drainage based on polar compound adsorption watson et al 2017 included wettability alteration with increasing tracer concentration following a heaviside function for the contact angle none of these studies included the geochemical reactions that are taking place at the water mineral interface and can influence wettability one of the reasons for this is that wettability change induced by manipulating the injected water composition e g lowering the ionic strength is a mechanism that is not fully understood yet mahani et al 2015b tang and morrow 1997 this effect has been associated in the past with a reduction of the salt content of water the so called low salinity effect or lse tang and morrow 1997 however recent advances in experimental work in particular in the domain of fluid visualisation greatly improved the understanding of this phenomenon for sandstones tang and morrow 1997 observed that lse is linked to the presence of clay minerals and also depends on a number of factors such as oil composition formation water composition and salinity of the injected water a number of potential low salinity mechanisms have been proposed in the literature such as fines migration tang and morrow 1999 interfacial tension reduction and emulsification mcguire et al 2005 selective plugging via clay swelling zhang and morrow 2006 and wettability alteration by multicomponent ionic exchange tang and morrow 2002 and or electrical double layer expansion austad et al 2010 berg et al 2010 directly visualised detachment of crude oil from clay minerals they observed a release of crude oil when changing the brine from high to low salinity even when the amount of clay swelling was insignificant for carbonate rocks the effect cannot be related to the presence of clay as most of these rocks do not contain any and if they do they occur only at very low levels moreover the exact chemical composition of the injected water seems to play a more important role than just salinity and ionic strength zhang et al 2007 mahani et al 2015b observed a lse on calcite patches in the absence of dissolution and with an increase of interfacial tension they could link the change of contact angle to a change of ζ potential defined as the local electrical potential at the slipping plane shear plane that separates the stationary and mobile phases in tangential flow of the liquid with respect to the surface hunter 1981 more recently jackson et al 2016a 2016b observed that the increase of oil recovery from carbonate core plugs obtained by manipulating the injected water composition depends greatly on the sign of the ζ potential at both water mineral and water oil interfaces both these studies suggest that lse in carbonate rocks is driven by a wettability change induced by a change of surface charge and the double layer expansion to analyse this effect further surface complexation models scm goldberg 2013 can provide a link between the water composition and the change of potential scm are chemical models that provide a molecular description of adsorption phenomena using an equilibrium approach one of the major advancements of scm is that it considers the charges on both the adsorbing ion and the solid adsorbent surface goldberg 2013 hence scm can provide the link between water composition and change of surface potential scm for clay minerals bradbury and baeyens 1997 calcite and dolomite pokrovsky et al 2000 have been proposed in the context of eor brady and krumhansl 2012 and brady et al 2012 have used such models to investigate reactions at the water oil and water mineral interfaces that lead to oil adhesion on mineral surfaces more recently mahani et al 2016 developed a calcite scm adapted from pokrovsky et al 2000 and modified so that it can explain the impact of sulphate concentration on the ζ potential at the water calcite interface the objective of this work is to develop an internally consistent pore scale numerical model that 1 captures the effect of surface complexation on the surface potential and wettability of carbonate rocks 2 can explain experimental observations at the micro scale and 3 can be easily parameterized to study the impact of different water mineral and oil compositions for this we use direct numerical simulation of the navier stokes equations nse patankar and spalding 1972 to simulate the flow the phase distribution is solved using the volume of fluid vof method hirt and nichols 1981 the transport of chemical species is given by a pore scale adre and the concentration discontinuity at the fluid fluid interface due to thermodynamic dissolution equilibrium is treated using the continuous species transfer cst method deising et al 2016 haroun et al 2010 scm is used to relate the adsorption of the potential determining ions pdi to the change of surface potential mahani et al 2016 two simplified models that can be fitted with experimental data are proposed to relate surface potential to a change of contact angle we then present several applications that 1 show convergence of our numerical method and concordance with experimental results 2 allow us to perform a sensitivity analysis with respect to several parameters and production scenarios on 2d micro models and 3 offer new physical insights into lse 2 flow and reactive transport solvers three different approaches have been previously applied to solve multiphase flow problems at the pore scale pore network models pnm blunt and king 1991 lattice boltzmann method lbm pan et al 2004 and direct numerical simulation dns patankar and spalding 1972 of the nse pnm are computationally efficient but are based on simplified idealised geometries of the pore surface which may impact modelling dynamic wettability changes moreover standard pnm are quasi static which limits their predictive capability especially for complex recovery processes where wettability changes dynamically dynamic pore network models have appeared recently joekar niasar et al 2010 nordhaug et al 2003 but are generally based on adding a notional time dependency to the invasion percolation mechanism determined by flow rates obtained from solving the quasi static problem moreover reactive transport models based on pnm usually assume full mixing in pore bodies and throats lbm is based on the discrete boltzmann equations which describes the fluids in terms of the movement and collisions of a set of particles lbm does not require solving an implicit pressure equation and therefore can be easily parallelized however lbm cannot accommodate additional physical effects such as wall slip and dynamic contact angles easily and has difficulties handling large viscosity and density ratios meakin and tartakovsky 2009 dns methods can either be mesh free like the smoothed particle hydrodynamics method tartakovsky and meakin 2006 or grid based like the finite volume method mesh free methods represent sharp interface accurately and are easily parallelized however they are difficult to extend to reactive transport as they do no solve for concentration of species in the domain in this work we hence choose to use grid based dns with the vof method hirt and nichols 1981 2 1 the volume of fluid method in the vof method the interface between two fluids is tracked using an indicator function α which represents the volume fraction of one of the fluid in each grid cell if the cell is completely filled with the first fluid then α 1 and if it is filled with the second fluid then α 0 for cells which are crossed by the interface α lies between 0 and 1 the density and viscosity of the fluid are deduced by linear interpolation from the indicator function 1 ρ α ρ 1 1 α ρ 2 μ α μ 1 1 α μ 2 where ρi and μi are the density and viscosity of phase i respectively the single field velocity u is defined as 2 u α u 1 1 α u 2 where u i is the velocity of phase i the nse can be written with the single field formalism hirt and nichols 1981 3 u 0 ρ u t u u p τ ρ g f s t where p is the pressure g is the gravity vector τ is the viscous stress tensor and f st is the surface tension force the viscous stress tensor can be expresses as 4 τ μ u u t the reynolds number is defined as the ratio of inertial to viscous forces 5 r e ρ l u μ where l and u are the reference length and velocity in the domain and ρ and μ are the density and viscosity of the invading phase the reynolds number is used to characterise different flow regimes such as laminar flow where viscous forces are dominant and turbulent flow where inertial forces are dominant in this work we only consider cases where re 1 so that we are in the so called creeping flow regime lenormand et al 1988 the indicator function α is evolved with the advection equation 6 α t α u 0 vof methods can be algebraic or geometric algebraic methods resolve the interface by solving a discretized form of the phase advection equation eq 6 on a computational mesh ubbink and issa 1999 while the geometric methods explicitly reconstruct the interface so that the solution of the advection equation conserves the volume fraction exactly gerlach et al 2006 geometric methods do not create numerical diffusion and can achieve better precision with accurate interface reconstruction popinet 2009 but the calculations can be complicated especially for unstructured grids algebraic methods can be easily applied to unstructured grids as no explicit interface reconstruction is needed but numerical diffusion can smear the interface over a large number of cells here we use compression of the interface to reduce this problem ubbink and issa 1999 the surface tension force can be modelled using the continuum surface force csf formulation introduced by brackbill et al 1992 7 f s t γ κ α where γ is the interfacial tension between the two fluids and κ the mean interface curvature which can be computed as 8 κ n 12 where n 12 is the interface normal vector defined as 9 n 12 α α at the fluid fluid solid contact line the interface forms with the normal to the solid surface a micro scale contact angle θ so that 10 n 12 cos θ n s sin θ t s where n s and t s are the normal and tangent vectors to the solid surface respectively brackbill et al 1992 the capillary number ca is defined as the ratio of viscous to surface tension forces 11 c a μ u γ and describes if the system is in the viscous dominated regime ca 1 or in the capillary dominated regime ca 1 the vof csf method is attractive because of its simplicity however scardovelli and zaleski 1999 reported the presence of spurious currents in the capillary dominated regime which originate from errors in calculating the normal vector and the curvature of the interface to limit the spurious currents one can apply the sharp surface force ssf method introduced by francois et al 2006 where the indicator function is smoothed by a laplacian smoother for the computation of the curvature and sharpened by a curtail function for the computation of the surface tension force alternatively the filtered surface force fsf introduced by raeini et al 2012 filters the components of the capillary force that are parallel to the interface ssf and fsf reduce spurious currents considerably raeini et al 2012 especially for static test cases however pavuluri et al 2017 show that spurious currents appear when simulating spontaneous imbibition in a 2d straight micro channel with vof ssf and vof fsf at c a 10 3 but they also show that these spurious currents do not affect the global dynamic of the system for c a 10 4 in this work we use ssf and a minimum capillary number c a 10 5 spurious currents may be present but we assume that they do not affect the global dynamic of the system 2 2 continuous species transfer during a reactive transport process the mass of each species in the fluid changes due to transport by advection and diffusion and due to reactions the conservation equation satisfied by the concentration c j i of a chemical species j in phase i reads 12 c j i t c j i u i j j i r j i where j j i is the molecular diffusion flux of j in phase i and r j i is the molar rate of creation of j in phase i by chemical reactions in the pore space in mol m3 s we assume that the molecular diffusion follows fick s law 13 j j i d j i c j i where d j i is the molecular diffusivity of j in phase i reactions that take place at the solid fluid boundaries such as surface adsorptions are not included in r j i instead they are expressed as boundary conditions on reactive surfaces steefel et al 2013 14 d j i c j i n s s j i where s j i is the molar rate of creation of j in phase i by surface adsorption desorption reactions in mol m2 s and n s is the normal to the surface of the mineral in the absence of phase change and chemical reactions at the fluid fluid interface the jump conditions are given by the continuity of fluxes and chemical potentials the latter described here by henry s law danckwerts 1970 15 j j 1 j j 2 n 12 0 and 16 c j 1 h j c j 2 where hj is the henry s coefficient for species j haroun et al 2010 and marschall et al 2012 developed the cst method to model the interface species transfer within the vof method by defining the global variable 17 c j α c j 1 1 α c j 2 the global concentration adre is given by 18 c j t c j u j j r j where 19 j j α 1 d j 1 c j 1 α 2 d j 2 c j 2 r j α 1 r j 1 α 2 r j 2 haroun et al 2010 shows that the diffusion flux j j can be written as 20 j j d j c j φ j where 21 d j 1 α 1 d j 1 α 2 d j 2 φ j d j 1 h j α 1 h j α 2 c j α 1 here d j is the harmonic interpolation of the phase diffusion coefficient haroun et al 2010 and deising et al 2016 have demonstrated that this formulation is more robust than a simple mixing rule the additional flux φj is the cst flux which results from the concentration jump at the interface finally graveleau 2016 derived the boundary conditions for the global concentration at the solid walls in case of a moving contact line in the absence of surface reaction this can be adapted to include surface reactions 22 d j c j φ j n s s j where the global surface reactions rate sj writes 23 s j α 1 s j 1 α 2 s j 2 the flow regime is described by the péclet number which is equal to the ratio of convection to diffusion rate 24 p e j l u d j where l and u are the reference length and velocity respectively and dj is the diffusion coefficient of species j in the invading phase the system is in the convection dominated regime for species j when pej 1 and in the diffusion dominated regime when pej 1 2 3 surface complexation in this work we consider two different types of minerals calcite and clay for calcite we use the scm developed by mahani et al 2016 the rock surface presents two hydrolysis species co3h0 and caoh0 where represents the mineral surface the following species are assumed to form on the calcium and carbonate sites exposed to an aqueous solution co 3 co3ca co3mg cao caco 3 cahco 3 0 and caso 4 we assume that the surface density γ of ca sites and co3 sites are both equal to 8 27 µmol m2 pokrovsky et al 2000 the surface complexation reactions are summarised in table 1 for clay patches we use the na montmorillonite scm proposed by bradbury and baeyens 1997 summarised in table 2 the surface density γ of adsorption sites s is equal to 2 4 µmol m2 for simplification we assume that all reactions occur only on the calcite mineral surface often termed 0 plane and that charge and potential can be determined using a simple double layer model goldberg 2013 the total surface charge σs can be obtained by adding up the charge of all surface complex 25 σ s f i m s i v s i where msi and vsi are the surface concentration and the charge of the complex si respectively and f is the faraday constant the double layer surface potential ψs is related to the surface charge by the grahame equation israelachivili 1985 26 σ s 2 8000 ϵ ϵ 0 rti sinh f ψ s 2 rt 2 where ϵ is the dielectric constant of pure water ϵ0 is the vacuum permittivity i is the ionic strength of the electrolyte solution r is the ideal gas constant and t is the temperature since charged ions are attracted to or repelled from the solid surface due to coulomb interactions the apparent stability constant k is different from the intrinsic one kint the relationship between the two is given by israelachivili 1985 27 k k i n t exp z c f ψ s r t where zc is the net change of surface charge induced by the reaction for example 1 for reaction 1 in table 1 the reaction rates r j i eq 12 and s j i eq 14 are obtained by equilibrating the chemical model table 1 or 2 with the double layer model eqs 25 27 2 4 contact angle alteration it has been observed in experimental work mahani et al 2015a 2015b 2017 that the surface of a sandstone or a carbonate rock becomes less oil wet when switching from high salinity to low salinity water for example mahani et al 2015a found a change of contact angle δ θ 10 40 for an oil droplet on a clay patch when switching from a high salinity brine to a low salinity brine obtained by diluting the initial brine 4 8 or 16 times mahani et al 2015b also found a change of contact angle δ θ 5 20 on limestone patches and δ θ 0 45 on dolomite patches when switching from a high salinity formation water fw to sea water sw or 25 times diluted sea water 25dsw these water compositions are given in table 3 in the study of mahani et al 2015b ζ potentials at the water oil and at the water rock interfaces were also measured the water oil ζ potential was observed to be negative and decreasing from fw to sw and 25dsw for limestone particles the water rock ζ potential was observed to be positive for fw but negative for sw and 25dsw a contact angle reduction was also observed for dolomite particles the ζ potential remained positive for all three water compositions contact angle reduction was observed for sw but not for 25dsw to explain these changes of contact angle it was proposed that the change of ζ potential from positive to negative modifies the electrostatic forces between the oil molecule and the water rock interface from adhesive to repulsive brady and krumhansl 2012 buckley et al 1989 this would explain why no contact angle reduction was observed on dolomite particles for 25dsw the change of contact angle for sw on dolomite patches could be further explained by an increase of the separation distance between oil and dolomite due to the large concentration of so 4 2 mahani et al 2015b in our simplified scm we assume that all surface reactions occur on the 0 plane fig 1 this implies that the ζ potential and the potential at the surface of the calcite are equal in reality only protonation and deprotonation reactions e g reactions 1 and 4 in table 1 occur on the 0 plane for example in a basic stern model fig 1 a layer of constant capacitance the stern layer separates the mineral surface from the diffuse layer and reactions other than protonation and deprotonation e g reactions 2 3 5 6 and 7 in table 1 occur on the inner or outer planes of the stern layer also called inner helmholtz plane ihp and outer helmholtz plane ohp al mahrouqi et al 2017 therefore the ζ potential and the 0 plane potential can differ greatly since the reactions involving divalent ions occur on the ihp and ohp planes the ζ potential would be more accurately approximated by the ohp potential unfortunately the geochemical simulator used in our numerical model phreeqc see section 2 5 does not include basic stern model hence we are using instead a simple double layer model fig 1a fig 2 shows a comparison between the ζ potential at a water calcite interface experimentally obtained by heberling et al 2011 and mahani et al 2016 and the surface potential computed using the scm table 1 with a simple double layer model the different water compositions are represented in term of the concentration of potential determining ions ca 2 mg 2 and so 4 2 we observe that the double layer surface potential ψs only matches the trend of the ζ potential nevertheless a simple model that describes the variation of contact angle change with ψs can be used to study the link between flow and wettability change induced by surface complexation and provide new insights into the process of wettability change by surface complexation in the absence of robust quantitative experimental data that links surface potential to contact angle variation two simple models are considered in this work in the first model we assume that the contact angle changes linearly with the surface potential 28 θ f l ψ s θ 0 ψ s ψ 0 θ 1 θ 0 ψ 1 ψ 0 this model can be easily fitted to contact angle measurements and can be easily extended to piecewise linear functions so that the function can be fitted with a large number of experimental measurements however this model cannot explain why 25dsw does not always induce more contact angle changes that sw the second model considered here used a heaviside function watson et al 2017 with a critical surface potential assumed to be equal to 0 for simplification 29 θ f h ψ s θ 0 ψ s 0 θ 0 δ θ ψ s 0 the first model eq 28 is used in all applications in this study the second model eq 29 is used in section 3 4 to conducting a sensitivity analysis with respect to the contact angle model 2 5 numerical implementation the mathematical model given by the nse eq 3 and the phase advection equation eq 6 is implemented in the open source computational fluids dynamics software openfoam www openfoam org as an internal vof solver so called interfoam interfoam solves the nse on a collocated eulerian grid with a predictor corrector strategy based on the pressure implicit splitting operator piso algorithm issa et al 1985 an explicit formulation is used to treat the coupling between the phase distribution equation eq 6 and the nse this imposes a limit on the time step size by introducing a capillary wave time scale described by the brackbill conditions brackbill et al 1992 in all simulations we use a constant time step that satisfies this condition time discretization is performed using the crank nicolson scheme and space discretization is performed using the second order van leer scheme van leer 1974 for the purpose of this work we extended the interfoam solver to perform two phase reactive transport simulations the concentration equation eq 18 is solved sequentially after the phase conservation equation eq 6 time discretization is again based on the crank nicolson scheme the advection term cu and the cst flux φ space discretization is again based on the second order van leer scheme van leer 1974 the diffusion term dj cj is discretized using the gauss linear limited corrected scheme which is second order and conservative all of these discretization schemes are available in the standard openfoam distribution the surface complexation model eqs 25 27 is solved using the us geological survey chemical package phreeqc www usgs gov software phreeqc the coupling between transport and reactions is handled by a sequential split operator method carrayrou et al 2004 first the transport step solves the system of equations in the absence of chemical reactions using openfoam then the reaction step solves the system in the absence of flow using phreeqc for this the concentration boundary condition on a reactive surface eq 22 is integrated over a control volume and gives an additional source term in the adre eq 18 our numerical model was validated by comparison with analytical solutions for spontaneous imbibition in a 2d rectangular channel pavuluri et al 2017 for steady state interface mass transfer in a 2d tube graveleau 2016 and for linear retardation in a 1d semi infinite column ogata and banks 1961 for each case the numerical solution was shown to converge toward the analytical solution and a relative error below to 1 was obtained for sufficient resolution additional convergence tests are shown in section 3 3 3 applications we present five applications of our numerical model first we consider a batch experiment investigating the equilibrium between calcite and water for different water compositions and the corresponding change of surface potential secondly we simulate the detachment of an oil droplet from a clay patch and compare 3d simulations with experimental results mahani et al 2015a thirdly we study the convergence of the numerical model and the final residual oil saturation for the invasion of an idealised 2d square shaped pore by different types of water fourthly we consider a simple 3 3 heterogeneous calcite micro model in order to perform a sensitivity analysis with respect to several parameters of the model finally we simulate water invasion in a complex 2d porous media and study different production scenarios for all 2d applications gravity is ignored the fluids used are water and oil we used four different water compositions table 3 that have been used previously in experimental studies high salinity hs brine obtained by dissolving pure salts nacl kcl cacl2 h2o and cacl2 h2o into pure water mahani et al 2015a formation water fw from a middle eastern carbonate field sea water sw and 25 times diluted sea water 25dsw mahani et al 2016 the diffusion coefficients of ions in water are obtained from li and gregory 1973 and are summarised in table 4 the initial concentration of ions in the oil phase is zero and the henry constant of every ions is assumed to be 0 too so that there is no ion transfer between the phases the oil density and viscosity are equal to 840 kg m3 and 6 5 mpa s north sea crude oil from mahani et al 2015a respectively the interfacial tension is equal to 10 mn m 3 1 decomposition of low salinity effect on calcite as mentioned previously lse is a mechanism that is still not well understood and more studies are necessary to capture the driving factors and predict an increase in oil recovery in this example we use scm to decompose the lse on calcite mahani et al 2016 studied the effect of ph on the surface potential however as it has been noted by alroudhan et al 2016 and jackson et al 2016a a modification of the ph would change the dissolution equilibrium between calcite and water and can greatly affect the concentration of ca 2 in the water instead these studies analysed the evolution of surface potential with the concentration of pdis using the scm defined in table 1 we identify three mechanisms responsible for lowering the surface potential of the calcite when switching from fw to 25dsw a desorption of ca 2 and mg 2 these ions are in competition with h for a co3 surface site lower concentration of the divalent ions generates more sorption of the monovalent ion therefore lowering the positive part of the surface charge b sorption of so 4 2 and desorption of hco 3 these ions are in competition with oh for a ca surface site lower concentration of the monovalent ions generates more sorption of the divalent ion therefore increasing the negative part of the surface charge c lowering the concentration of surface inert ions na k sr 2 and cl in solution this affects the surface potential by lowering the ionic strength of the solution we perform three simulations in phreeqc which represents batch experiments to study the effect of each mechanism first we lower the concentration of ca 2 and mg 2 in solution while keeping the other concentrations constant then we lower the concentration of so 4 2 and hco 3 finally we lower the concentration of na k sr 2 and cl a b c then we change the order of the steps b c a and c a b fig 3 shows the evolution of surface potential with ionic strength during each step for each simulation we observe that in each case step a has the most impact on the surface potential the average change of surface potential is 40 mv this is because fw has a very high initial concentration of ca 2 and mg 2 initially every co3 site is occupied by a divalent ion lowering the concentration of these ions has therefore a major impact on the surface charge step b has a smaller impact on the surface potential the average change of surface potential is 8 mv note that here we lower the concentration of the divalent ion so 4 2 which by itself should increase the surface charge but we also lower the concentration of hco 3 so that the relative concentration of divalent ions actually increases and the surface charge decreases the effect is less important than step a since the initial concentration of so 4 2 is large enough so that most of ca sites are initially occupied by a divalent ion finally we observe that step c can have either a positive or a negative impact on the surface potential indeed step c only marginally changes the surface adsorption as it only affects the ionic strength therefore it does not change the sign of the surface potential only the magnitude indeed when we perform step c first the surface potential actually increases from 7 to 8 5 mv this analysis shows that the surface potential is more affected by the chemical composition of the water than by its salinity it also suggests that the driving mechanism of the lse on calcite is the desorption of ca 2 and mg 2 ions the effect of other ions in particular sulphate and bicarbonate depends strongly on the composition of the formation water this confirms the trends observed in fig 2 mineralogy could also have a large impact e g presence of dolomite 3 2 oil droplet detachment from a clay patch in this section we consider an oil droplet on a clay patch the system is equilibrated first under high salinity brine hs table 3 before switching to a low salinity brine obtained by diluted hs 4 times the hs equilibration lasted 72 h and we focused here on the second part of the experiment the volume of the droplet is equal to 3 1 mm3 at equilibrium with hs the contact angle θ is equal to 55 o and the initial contact area is equal to 1 1 mm2 the surface potentials computed with phreeqc are equal to 7 3 mv when equilibrated with hs and 15 6 mv with the 4 times diluted brine the contact angle variation is modelled using a linear function eq 28 fitted to experimental data from mahani et al 2015a for the initial contact angle and the contact angle at detachment fig 4 we use a uniform 3d cartesian grid with δ x δ y δ z 0 05 mm the surface of the clay patch reacts with the low salinity brine and calcium ions are desorbed from the surface eq 14 the excess of calcium and magnesium diffuses away from the surface of the patch and more reaction occurs the electric potential of the solid surface decreases and as a result the contact angle changes and the oil droplet recedes from the surface until it detaches by buoyancy fig 7 however mahani et al 2015a observed a time scale of detachment two order of magnitude longer than expected by diffusion only they proposed that this discrepancy could be explained by electrostatic effects in the thin film than forms near the charged clay surface fig 5 shows a schematic representation of these electrostatic effects the variation of surface potential induces a gradient of electrostatic potential inside the thin film opposed to the gradient of cation concentration therefore the electrostatic force generates a flux opposed to the diffusion flux this can be modelled using the nernst planck equation in the thin film 30 j j d j c j z f c j r t ψ however this cannot be simply implemented in our model at the micro scale because the thin film is of a few nano meters in thickness instead we include these effects by modifying the molecular diffusion near the surface the boundary condition for the phase concentrations on a reactive surface eq 14 is replaced by 31 d j i n s c j i n s s j i where dns is the near surface diffusion fig 6 shows the evolution of the contact angle during the simulation for different values of dns and a comparison with experimental data presented in mahani et al 2015a first we use d n s d where d represents the values presented in table 4 we obtain a time of detachment of 250 s then we use d n s d 10 d n s d 100 and d n s d 150 we observe that for d n s d 150 the numerical simulation matches qualitatively the experiment fig 7 shows the evolution of the droplet shape with time during the simulation we conclude that our numerical model is able to match experimental results obtained in mahani et al 2015a however there are two drawbacks of not including the thin film in the model explicitly first the parameters dns cannot be evaluated a priori and need to be matched by comparison with experimental results in test cases 3 3 and 3 5 the electrostatic effects are ignored while in test case 3 4 the sensitivity of the recovery factor with respect to dns is explored secondly bartels et al 2017 show that the low salinity effect can induce oil remobilisation without buoyancy joekar niasar and mahani 2017 show that the pressure dynamic inside the thin film can lead to expansion of the film and deformation of the fluid fluid interface potentially resulting in oil remobilisation in test cases 3 3 and 3 4 the initial saturation of water is ignored so that no oil is trapped and the effect of pressure in the thin film can be ignored in test case 3 5 we show that our model can simulate the increase of pore scale sweep efficiency in response of low salinity flooding but not the oil remobilisation effect in the absence of buoyancy 3 3 2d square shaped pore in this application we consider a single idealised and two dimensional idealised pore constituting of one square connected to two throats we explore the convergence of the numerical model fig 8 presents the geometry of the domain and the inlet and outlet boundary conditions the pore surfaces are assumed to be calcite table 1 the pore space is initially filled with oil but the surface of the pore is at equilibrium with a nano scale thin film of fw table 3 the surface potential calculated with phreeqc is equal to 7 mv but the effect of the thin film on the hydrodynamics of the system is ignored α 0 and d n s d at t 0 s we inject fw sw or 25dsw at the inlet with a velocity of 1 mm s which corresponds to a capillary number c a 10 4 the surface potential of the calcite equilibrated with sw respectively 25dsw computed with phreeqc is equal to 9 mv respectively 40 mv to explore convergence and sensitivity for different values of contact angles we assume θ fw 120 θ sw 110 o and θ sw 90 o this corresponds to θ ψ 0 64 mv eq 28 to study grid convergence for each case fw sw and 25dsw we use a fine grid solution δ x δ y 0 5 µm as a reference solution all cells containing solids are removed and replaced by rectangular and triangular cells that match the solid boundaries we then compare the final residual oil saturation in the domain obtained at different grid resolutions fig 9 shows the evolution of the relative error for the three cases we observe that the simulations have converged for a resolution of 1 µm fig 10 shows the corresponding evolution of the indicator function α and the water ph during invasion with fw sw and 25dsw blue corresponds to water and red to oil the water ph during fw invasion remains constant equal to 6 9 during the simulation since calcite has been previously equilibrated with fw at the end of the simulation a significant fraction of oil remains at the top and bottom corner of the pore this corresponds to a residual oil saturation s or fw 0 07 during invasion with sw the contact angle changes from 120 to 110 as calcite equilibrates with water we observed that the ph increases from 8 to approximately 9 near the pore surface where the reactions take place at first glance this observation could be surprising as the calcite has been previously equilibrated with fw which has a ph of 6 9 however we show in section 3 1 that the most important mechanism of surface potential reduction during the replacement of fw by 25dsw is the desorption of calcium and magnesium on the pore surface this is described by reactions 2 and 3 in table 1 during these reactions h ions are adsorbed onto the surface effectively increasing the ph of the solution at the end of the simulation oil still remains at the top and bottom of the pore but the residual oil saturation s or sw is 0 03 which corresponds to an increase of oil recovery of 4 during invasion with 25dsw the contact angle changes from 120 to 90 as the calcite equilibrates with water more ca 2 and mg 2 are desorbed from the calcite and more h is adsorbed the effect of surface reactions on the ph is stronger especially near the inlet where 25dsw is in contact with calcite for the first time at the end of the simulation almost no oil remains at the top and bottom of the pore and the residual oil saturation s or sw is 0 0025 which corresponds to an increase of oil recovery of 6 75 our simulations show that flooding by a low salinity water leaves a smaller amount of residual oil inside a pore as observed experimentally by berg et al 2010 and chen et al 2010 our numerical model can then complement such experiments by providing additional information such as ph evolution 3 4 3 3 heterogeneous micro model in this section we consider a 2d micro model formed by subtracting four rectangles in a 2d square of calcite table 1 the resulting micro model includes 3 3 nodes and is presented in fig 11 similarly to the previous test case the domain is initially filled by oil α 0 but the pore surfaces are at equilibrium with a nano scale fw thin film table 3 so that the surface potential computed with phreeqc is equal to 7 mv the aim of this test case is to analyse how recovery factors vary with water composition contact angle change injection velocity and near surface diffusion for this we assume θ f w 120 θ s w 110 and θ s w 90 first we assume that the contact angle is a linear function of the surface potential eq 28 that the injection velocity u is equal to 1 mm s c a 10 4 and that d n s d we perform a convergence study similar to the one conducted in the previous application section 3 3 and we obtain convergence for a grid with a resolution of 1 µm fig 12 shows the evolution of the indicator function α during invasion with fw sw and 25dsw blue corresponds to water and red to oil we observe that sw invades more throats than fw and that 25dsw invades the entire domain this indicates an increase of pore scale sweep efficiency with reduction of water salinity this can also be observed in a more complex 2d pore structure as discussed in section 3 5 below the residual oil saturation are s or fw 0 177 s or sw 0 077 and s or 25dsw 0 001 these correspond to an increase of oil recovery of 10 and 17 6 for sw and 25dsw respectively we then perform a sensitivity analysis considering four different parameters water composition described here by ionic strength i 0 87 for sw and i 0 035 for 25dsw contact angle model eq 28 or eq 29 injection velocity 1 or 0 1 mm s and near surface diffusion d n s d or d n s d 10 to perform the sensitivity analysis and compare the results we use a two level factorial design myers et al 2009 and a measure of performance equal to the increase of recovery factor by comparison with fw injection table 5 shows the full summary of the sensitivity analysis the response is then analysed using a first order model with interactions myers et al 2009 fig 13 shows the corresponding pareto chart myers et al 2009 showing the eight most important effects we observe that the most important factors are the injection velocity the near surface diffusion and the water composition described here by the ionic strength i the impact of the contact angle model is small in comparison and can be ignored as a first order approximation we also note that an important part of the impact of u and dns is due to their interaction this can be expressed in term of the near surface diffusion péclet number 32 p e j n s l u d j n s we use the average pore throat radius l 5 21 µm as a reference length this gives péclet numbers between 0 53 and 7 45 for test cases 1 to 4 so that we are in the transitional regime where advection and diffusion have similar time scales for test cases 5 to 8 p e n s ranges from 0 053 to 0 745 so that we are now in the diffusion dominated regime here the recovery factors slightly increase however for test cases 9 to 12 p e n s number ranges from 5 3 to 74 5 in these cases we are in the advection dominated regime and the increase of recovery factor is almost zero finally for test cases 13 to 16 p e n s ranges again from 0 53 to 7 45 here the recovery factors are identical to the ones for test cases 1 to 4 this suggests that the most important factor for the low salinity effect is the flow regime advection needs to be sufficiently slow to cause a diffusion induced change in contact angle near the water solid interface 3 5 complex 2d porous medium in this test case we consider a complex 2d porous medium representing a thin section of a real carbonate grainstone zaretskiy et al 2010 the pore surfaces are assumed to be calcite table 1 the geometry and boundary conditions are summarised in fig 14 the porosity and permeability of the sample have been numerically estimated to 0 4 and 0 71 10 12 m2 respectively the aim of this test case is to study three different production scenarios fw injection sw injection and fw injection followed by sw injection we assume that the domain is initially filled by oil α 0 but the pore surfaces are at equilibrium with a nano scale fw thin film table 3 so that the surface potential computed with phreeqc is equal to 7 mv the surface potential of the calcite equilibrated with sw computed with phreeqc is equal to 9 mv the contact angle is assumed to be a linear function of the surface potential eq 28 fitted with experimental data for an oil droplet on a limestone plate from mahani et al 2015b fig 15 the domain is represented by a 2d uniform cartesian grid comprising 1000 500 grid blocks all cells containing solid are removed and replaced by rectangular and triangular cells that match the solid boundaries the final grid contains 204 728 cells fig 16 shows the evolution of the indicator function α during fw and sw injection at different times corresponding to 0 25 0 5 1 and 2 pore volume pv injected we observe that the overall residual oil saturation is impacted by the change of wettability in two ways first the water phase remains more connected during sw flooding compared to fw flooding as a consequence fw leaves a larger number of small clusters of oil in the pore space after invasion this is particularly visible in the solid rectangle shown on fig 16 secondly the invasion pattern changes and more pores are being invaded during sw flooding compared to fw flooding this is particularly visible in the dashed rectangle shown on fig 16 both these effects contribute to an increase of pore scale sweep efficiency induced by wettability change after 3 pv injected the oil saturation has reached an equilibrium in both cases we then consider the production scenario where we inject 2 pv of fw followed by 2 pv of sw fig 17 compares the final phase distributions for fw flooding only and fw flooding followed by sw flooding we observe that the amount and form of oil clusters left in the pore space after invasion solid rectangle on fig 17 remain mostly unchanged this suggests that even though our numerical model can simulate droplet detachment by buoyancy under lse section 3 2 it is not able to simulate oil remobilisation due to lse in the absence of buoyancy bartels et al 2017 observed oil remobilisation in the absence of buoyancy in a 2d micro model and showed that the mechanism was driven by thin film dynamics which we do not include in our model however we do observe an increase in the number of invaded pores dashed rectangle on fig 17 the change of wettability reduces the capillary resistance in the domain and unlocks additional pores for the water invasion fig 18 shows the evolution of the oil saturation in the domain during fw flooding sw flooding and fw flooding followed by sw flooding the final oil saturations are s or fw 0 402 s or sw 0 341 and s or fw sw 0 318 these correspond to an increase of oil recovery of 15 2 for sw and 20 9 for fw sw our investigation shows that wettability change induced by surface complexation during low salinity flooding can result in an improvement of pore scale sweep efficiency this has been previously observed in experimental studies on sandstone core plug kumar and mohanty 2011 zhang and morrow 2006 zhang et al 2007 but was associated with selective plugging via clay swelling bernard 2011 zhang and morrow 2006 our study suggests that this improvement of sweep efficiency could also applied to carbonate reservoir and be induced by the temporal evolution of the contact angle this changes during lsf the set of pores and throats that become accessible to the invaded phase 4 concluding remarks a novel pore scale reactive transport model has been developed and validate with the aim of providing new insights into wettability alteration by surface complexation as a mechanism of lsf using 3d and 2d simulations based on the five applications considered here we propose the following key conclusions the change of surface potential at the calcite water interface is not driven by the ph of the injected water but by the concentration of pdi such as ca 2 and mg 2 for the water compositions considered here the concentration of so 4 2 has only a small impact our numerical model is able to reproduce the evolution of the oil droplet shape with time during detachment from a clay patch for this the molecular diffusion near the surface of the solid need to be fitted to take into account electrostatic effect on simple 2d models e g a square pore and a 3 3 micro models we show that our numerical model is convergent a sensitivity analysis carried out for the 3 3 micro model show that the most important parameters controlling the residual oil saturation are the velocity at which water is injected and the near surface diffusion we further show that the lse is only observed if the transport regime is such that diffusion has a smaller or similar time scale as advection so that the low salinity water has time to diffuse into the thin water film separating the oil and mineral surfaces and can induce a change in contact angle by performing simulation on a complex 2d porous medium we show that our numerical model is able to explain an increase of pore scale sweep efficiency with lsf more generally the results of our simulations highlight two effects of wettability alteration due to surface complexation during lsf namely a decrease in the amount of residual oil left in the pore space after invasion and an increase of the number of pores that are invaded the former is simply a consequence of calcite being more water wet but the latter is induced by the temporal evolution of contact angle and cannot be captured readily in static or quasi dynamic pore network models this dynamic effect changes the set of pores and throats that become accessible to the invading brine during lsf however our model was not able to simulate the remobilisation mechanism observed when injecting low salinity water after formation water bartels et al 2017 including thin film hydrodynamics abu al saud et al 2017 and electrostatic effect inside the thin film joekar niasar and mahani 2017 could potentially solve this issue our numerical modelling gives new insights into several mechanisms inducing an increase in oil recovery during low salinity flooding we have focused on the impact of several parameters namely the water composition the injected velocity the contact angle model and the diffusivity in the thin film since our model can be parameterized easily it can be used to study the impact of other factors such as oil and mineral compositions for example the evolution functions of contact angle with surface potential that we used in our examples were only calibrated with two data points if more data points are made available the evolution function can be obtained by interpolation and the contact angle model can be replaced with a more sophisticated approximation future work could focus on comparison with experimental observation on micro models bartels et al 2017 then our numerical model could be fully deployed to perform detailed sensitivity analysis on 3d micro ct images for example to develop quantitative and semi quantitative rules that guide invasion by low salinity water for pore network modelling studies watson et al 2017 acknowledgement we would like to thank petrobras and shell for their sponsorship of the iccr program and the permission to publish this work from the reactcarb project sebastian geiger further thanks the energi simulation foundation for supporting his chair programme 
893,concentration time series are provided by simulated concentrations of a nonreactive solute transported in groundwater integrated over the transverse direction of a two dimensional computational domain and recorded at the plume center of mass the analysis of a statistical ensemble of time series reveals subtle features that are not captured by the first two moments which characterize the approximate gaussian distribution of the two dimensional concentration fields the concentration time series exhibit a complex preasymptotic behavior driven by a nonstationary trend and correlated fluctuations with time variable amplitude time series with almost the same statistics are generated by successively adding to a time dependent trend a sum of linear regression terms accounting for correlations between fluctuations around the trend and their increments in time and terms of an amplitude modulated autoregressive noise of order one with time varying parameter the algorithm generalizes mixing models used in probability density function approaches the well known interaction by exchange with the mean mixing model is a special case consisting of a linear regression with constant coefficients keywords time series analysis monte carlo simulations global random walk groundwater msc 37m10 65c05 60g50 86a05 1 introduction time series are ubiquitous in all fields of hydrology monitoring strategies and sampling procedures in various water management contexts as for example in monitoring of nutrients geer et al 2016 or of nitrate transport in groundwater turkeltaub et al 2016 are based on analyses of concentration time series obtained from geophysical observations the most common examples of groundwater concentration time series are the breakthrough curves obtained from concentration measurements at reference planes in aquifers also often used in subsurface hydrology literature are series indexed instead of time by a one dimensional spatial variable see e g meerschaert et al 2013 examples of such series are among others measured data on porosity permeability hydraulic conductivity electrical resistivity see riva et al 2015 and references therein the complexity of the hydrological time series drew the attention of the scientific community long time ago the analysis of long run hydrological and other geophysical time series mandelbrot and wallis 1968 1969 lead to new concepts extending the classical gaussian models such as gaussian fractional noise and fractional brownian motion mandelbrot and van ness 1968 during the last two decades such mathematical objects were used in subsurface hydrology notably to model the complex structure of the hydraulic conductivity liu et al 2009 meerschaert et al 2013 molz et al 1997 these modeling approaches are based on both measured and synthetic time series synthetic time series obtained from numerical simulations can be used to investigate the behavior of some quantities which are not accessible to direct measurements for instance it was shown by using an automatic algorithm to decompose time series into intrinsic components that in some conditions the transverse component of the trajectory of the classical advection dispersion model of transport in heterogeneous aquifers with randomly distributed hydraulic conductivity behaves as a fractional brownian motion or even as a multifractal vamoş et al 2015 concentration time series recorded at regular time intervals at given points of the aquifer system supply observational data for monitoring and risk assessments of groundwater quality in the context of stochastic subsurface hydrology the heterogeneity of the groundwater flow domain is modeled as a random environment consequently predictions on the behavior of the contaminant concentration are uncertain and have to be modeled as random functions in discrete representations a random function is equivalent to an ensemble of random time series recorded at different points in the domain risk assessments are based on the probability density function pdf of the random concentration concentration pdfs can be inferred in case of moderate heterogeneity if one assumes a gaussian shape of the concentration with random spatial moments estimated from the statistics of the random hydraulic conductivity dentz and tartakovsky 2010 or by assuming the shape of the concentration pdf itself pope 1985 in recent years there were several attempts to apply the pdf approach from turbulence modeling pope 1985 2000 to problems of stochastic subsurface hydrology meyer et al 2010 sanchez vila et al 2009 suciu et al 2015 2016 the pdf approach consists of solving a pdf evolution equation which can be derived from the advection dispersion reaction equation verified by the random concentration pope 1985 evolution equations with the same structure are obtained in the filtered density function fdf approach where instead of ensemble averages spatial filtering procedures are used to infer statistical quantities suciu et al 2016 such equations have to be parameterized by using closure hypotheses and models while the transport of the concentration pdf in the physical space can be modeled by known upscaling procedures building a mixing model which describes the transport of the pdf in the concentration space is still a challenging issue suciu et al 2016 a possible way to search for appropriate mixing models is to use the numerical approach based on the fokker planck equation describing the evolution of a suitably weighted concentration pdf suciu et al 2015 in this approach the mixing model for nonreactive transport is given by an ordinary stochastic differential equation describing the evolution of the concentration on trajectories of an advection dispersion process in case of reactive transport with species independent diffusion coefficients chemical reactions are modeled by including in the stochastic differential equation drift terms given by reaction rates suciu et al 2016 eq 5 in this study we investigate the structure of an ensemble of synthetic random time series of concentration values recorded on the trajectory of the center of mass of the solute plume and we derive a stochastic process which generates time series with almost the same statistics this process reveals the structure and provides the parameters of the mixing model which closes the pdf equation for the concentration at the plume center of mass time series associated to the classical model of nonreactive transport were recently constructed by integrating over the transverse direction of a two dimensional domain the concentration fields computed with the global random walk grw algorithm vamoş et al 2003 at successive longitudinal coordinates of the plume center of mass an ensemble of such time series was computed with independent realizations of the random velocity field and a pdf approach was developed to simulate the pdf of the random concentration suciu et al 2015 2016 the mechanism responsible for the transport of the concentration pdf in concentration space is in this case the stochastic process which generates the ensemble of concentration time series a simple mixing model inferred from the ensemble of simulated time series generates time series by summing up increments of a time dependent trend and gaussian white noise terms with decaying amplitude suciu et al 2016 though this pdf approach provides results close to reference monte carlo mc simulations at early times its performance deteriorates at larger times this can be attributed to the inability of the mixing model to reduce the spreading of the realizations of the process generating the time series around their ensemble average necessary to produce the asymptotical narrowing of the concentration pdf shown by mc simulations keeping in mind the utility of the concentration time series in designing mixing models for pdf approaches we look for a stochastic model for the concentration time series that can be used to generate statistical ensembles having similar features with the initial ensemble of time series obtained from grw mc simulations in this paper the simple model previously used in suciu et al 2016 is refined and modified by considering more complex time series increments the correct asymptotic behavior is ensured by a linear dependence between distances of time series realizations to their ensemble average and their increments in time in this way the larger the distances from the ensemble average the stronger the increments tend to reduce them the residuals obtained after removing the linear regression are correlated and as a first approximation we model them with an amplitude modulated autoregressive process of order one ar 1 with time varying parameter our modeling approach uses methods of time series theory brockwell and davis 1987 hamilton 1994 where statistical inferences are obtained from individual time series as well as methods of statistical physics based on statistical ensembles landau and lifshitz 1984 the paper is organized as follows in section 2 the statistical ensemble obtained by grw mc simulations is described section 3 is dedicated to the analysis and modeling of the ensemble average of the time series and of the increments of the centered time series obtained by subtracting the ensemble average from each time series in section 4 we introduce the linear regression between the centered time series and their increments and we infer the regression coefficients the demodulated regression residuals are further modeled as an ar 1 process with time varying parameter in section 5 in the last section we present some conclusions and discuss the implications of the new time series model for mixing models in pdf methods the influence of sampling time spatial sampling domain and hydraulic conductivity on the structure of the time series model is analyzed in appendix a 2 statistical ensemble of concentration time series we consider the two dimensional problem for nonreactive transport in saturated aquifers previously used in numerical investigations based on grw simulations suciu 2014 suciu et al 2006 2009 and pdf approaches suciu et al 2015 2016 the nonreactive transport was modeled as an advection dispersion process with a constant isotropic local dispersion coefficient d 0 01 m2 d and advection velocity fields given by realizations of a random space function for a log normally distributed hydraulic conductivity field k with small variance σ l n k 2 0 1 and isotropic gaussian correlation with correlation length set to λ 1 m the velocity realizations were generated numerically as superpositions of n p 6400 random periodic modes with the kraichnan routine kraichnan 1970 by the usual approximation for small variances of ln k see details in suciu et al 2016 appendix a the mean velocity field with an amplitude u 1 m d was aligned with the x axis the simulations were conducted over 4000 time steps δ t 0 5 d which correspond to 2000 days or equivalently to 2000 advection time scales λ u the computational domain was a rectangle with dimensions of 750 m in the longitudinal direction and 300 m in the transversal direction a constant spatial step of 0 1 m was considered in both directions so that the grw lattice contained 22 5 millions of nodes the computational domain was larger than the maximum extension of the plume and every time when groups of particles reached the outflow boundary the domain was displaced in the direction of the mean flow so that it contained the entire plume at all times therefore with this numerical setting no boundary conditions were necessary the initial condition consisted of an instantaneous injection of n 10 24 particles uniformly distributed in a transverse slab of 1 m 100 m details on the numerical implementation of the grw algorithm can be found in suciu et al 2006 the cross section concentration recorded at the x coordinate of the expected center of mass of the solute plume x u t was obtained by summing the number of particles n x y t over transverse slabs δx ly where δ x 1 m and ly is the transverse dimension of the two dimensional domain for each simulation one obtains in this way a time series 1 c t c u t t 1 n δ x l y 0 l y u t δ x 2 u t δ x 2 n x y t d x d y the concentrations were sampled at intervals 2δt which correspond to 1 day a statistical ensemble c s t t 1 2 t s 1 2 s of time series of length t 2000 was obtained by repeating the simulations for s 1000 independent realizations of the velocity field see fig 1 a in suciu et al 2006 appendix b2 it has been shown that the large values of the parameters s n and np used in our grw mc simulations ensure the reliability of the statistical inferences obtained by averaging over the ensemble c s t the simplified advection dispersion model constant isotropic local dispersion coefficient and isotropic hydraulic conductivity with small variance considered in this study is the same as that used to develop the pdf fdf approach for groundwater systems suciu et al 2016 despite its simplicity this model can be used to illustrate essential features of transport in groundwater such as influence of local dispersion and sampling volume on concentration fluctuations andričević 1998 caroni and fiorotto 2005 ergodicity suciu et al 2006 memory effects suciu et al 2009 or anomalous behavior vamoş et al 2015 on the other hand the transport of the cross section spatially averaged concentration 1 is well approximated by a one dimensional process parameterized by longitudinal components of the velocity and dispersion coefficients as shown by the numerical results presented in suciu et al 2016 section 5 hence the behavior of the time series 1 is not affected by the anisotropy of the transport parameters as long as the longitudinal dispersion coefficient does not depend on transverse dispersion for instance when the anisotropic dispersion coefficients are proportional to velocity or constant andričević 1998 the choice of a small variance σ l n k 2 of the log hydraulic conductivity facilitates the computation of large ensembles of time series with thousands of terms because it allows fast transport simulations with kraichnan generated velocity fields instead of numerical solutions of the flow equations which would require huge computing resources it has been shown both theoretically andričević 1998 fiori and dagan 2000 schüler et al 2016 and numerically caroni and fiorotto 2005 suciu et al 2006 that for dispersion processes in random velocity fields with short range correlation non vanishing mean and small fluctuations the concentration is approximately normally distributed with time decaying maximum concentration and concentration variance at the center of the plume moreover in the long time limit the process approaches a gaussian diffusion with constant coefficients sometimes called macrodispersion process suciu et al 2006 2009 the behavior of the ensemble average c x t of the concentration sampled across the transverse dimension of the computational domain is accurately approximated by a one dimensional diffusion process with drift velocity u and a time variable ensemble dispersion coefficient d t suciu et al 2016 in the long time limit the normalized mean concentration is then given by the gaussian probability density of the diffusion process with mean ut and constant macrodispersion coefficient d lim t d t 2 c x t 4 π d t 1 2 exp x u t 2 4 d t the mean concentration at the expected center of mass x u t behaves in time as 1 t and because of the approach to the macrodispersion process it is an attractor for the time series c s t investigated in this paper the transport in the concentration space of the concentration pdf investigated in suciu et al 2016 is governed by a mixing model describing the behavior of the increments d c t c t 1 c t of the time series process a statistical analysis of 500 time series has been used to build a simple model for the increments dc t consisting of a deterministic trend given by the ensemble average dc t and a heteroskedastic process approximated by a white noise with time decaying amplitude suciu et al 2016 numerical simulations using this mixing model gave good results at early and intermediate times but failed to predict the true concentration pdf at large times suciu 2014 suciu et al 2015 2016 the observation that this simple mixing model does not describe the approach to the macrodispersive attractor was the starting point and the motivation for deeper investigations presented in this paper 3 statistical time series analysis and modeling each time series c s t for fixed s can be analyzed with methods of time series theory using statistical inferences obtained by time sampling and averaging see for example brockwell and davis 1987 hamilton 1994 but if the time series have regions with strong nonstationarity like the concentration series investigated here these methods fail to reveal some important features in such cases one can use the statistics of the ensemble c s t for fixed t and all values of s for example the ensemble average c t of the concentration see fig 1 is given by the arithmetic mean of the s concentration values c s t at given t fig 1 b presents the log log plot of the ensemble average of concentration as function of time its variation is almost linear except a few values at the beginning of the time series these values may be associated with the numerical transition from the discontinuous initial condition see section 2 to a gaussian shape of the two dimensional concentration field in our grw simulations therefore we consider t t 0 30 and fit the average c t with a power law function 3 μ t a μ t b μ a μ 1 0084 b μ 0 5053 t t 0 plotted with straight line in fig 1 b the fit is consistent with the 1 t long time behavior of the concentration sampled at the plume s center implied by 2 even though the fit is already very good for t 10 the restriction t 30 is necessary to obtain simple power law models for the amplitude of the increments of the time series which are analyzed in the following the centered time series are obtained by subtracting the ensemble average from each time series 4 x s t c s t c t and their increments are defined by 5 δ x s t x s t 1 x s t the increments 5 shown in fig 2 a are heteroscedastic that is their amplitudes vary with time we denote by v t δ x t the ensemble average of the absolute values of the increment time series δx s t at given t by analogy to the theory of financial time series see for example taylor 2007 we refer to the mean amplitude v t as the volatility of the increment time series its values are plotted in log log coordinates in fig 2 b the logarithm of the volatility has a region with nonlinear variation at the beginning and for t t 0 two distinct regions where its variation is almost linear with respect to log10 t i e v t has a power law decay with respect to t in these regions log10 v t has two different slopes the absolute value of the first one being larger to determine more precisely the time value for which log10 v t changes its slope we consider a fixed initial time t 0 30 a fixed end point t 2000 and a variable intermediate time t 0 tv t for each value of tv we fit log10 v t with linear functions for t t 0 t v and for t t v 1 t we compute the square norm error for every value tv e t v t t 0 t v log 10 v t log 10 a ϑ 1 b ϑ 1 log 10 t 2 t t v 1 t log 10 v t log 10 a ϑ 2 b ϑ 2 log 10 t 2 1 2 which has a minimum at t v 288 this minimum separates the two regions with different slopes so we can divide the length t of the time series into three distinct regions with different behavior of the volatility v t a region with numerical variability from t 1 to t t 0 1 a transient region where the volatility decreases rapidly and can be modeled by the power law function ϑ t a ϑ 1 t b ϑ 1 b ϑ 1 0 9209 a ϑ 1 0 0379 between t t 0 and t v 288 a region which corresponds to the approach to the asymptotic behavior with a slow decrease of the volatility modeled by the power law function ϑ t a ϑ 2 t b ϑ 2 b ϑ 2 0 5880 a ϑ 2 0 0057 between t v 1 289 and t 2000 in the following we analyze the residuals obtained after dividing every increment time series δ x s t s 1 s of the statistical ensemble by the volatility v t 6 z s t δ x s t v t the residuals z s t plotted in fig 3 a seem to be realizations of an uncorrelated noise using a common approach in time series theory we check whether the distribution of the residuals z s t for fixed s and t 1 t is normal by the kolmogorov smirnov test the statistics dks of this test is defined as the maximum of the absolute value of the difference between the empirical cumulative distribution function of the individual standardized residual series and the theoretical cumulative distribution function of the normal distribution see for e g bohm and zech 2010 fig 3 b shows that all dks values are smaller than the critical value d k s 0 03028 which corresponds to a 5 significance level the values of the autocorrelation functions estimated through time averages on individual realizations are already negligible from the first time lag together these tests indicate that the residual process z s t defined by 6 is a gaussian white noise based on the above analysis the concentration time series can be modeled as a combination of a deterministic variation of power law type and a sum of terms generated by a gaussian white noise n 0 σ z 2 modulated in amplitude the relations 4 6 and the model ϑ t of the volatility v t presented above provide a relatively simple model of the concentration time series for t t 0 30 7 c t μ t x t 0 τ t 0 t 1 ϑ τ z τ with average concentration and volatility modeled by 8 μ t a μ t b μ a μ 1 0084 b μ 0 5053 ϑ t a ϑ t b ϑ a ϑ 0 0379 t t 0 t v 0 0057 t t v 1 t b ϑ 0 9209 t t 0 t v 0 5880 t t v 1 t t v 288 z n 0 σ z 2 σ z 2 1 5768 this model needs initial values for x t 0 the analysis of the ensemble x s t 0 s 1 1000 shows that the initial values are almost normally distributed with zero mean and variance σ x t 0 2 1 8822 10 4 in order to verify this model we used 7 and 8 to generate 1000 concentration time series plotted in fig 4 b one observes that the time series generated with this model are much more scattered than the initial time series fig 4 a moreover instead of approaching to zero for large values of t some generated time series take negative values in conclusion the model 7 and 8 fails to reproduce the behavior of the initial time series 4 modeling the asymptotic behavior of the concentration to account for the asymptotic behavior of the concentration time series in fig 4 a the simple model defined by relations 7 and 8 has to be completed with a mechanism which prevents the scattering of the time series realizations shown in fig 4 b that means when the distance x s t between a realization s of the concentration time series and the ensemble average increases it should be decreased at the next time steps by increments δx s in the opposite direction therefore we investigate the relation between x s t and its increments at the next time steps by computing pearson correlation coefficients through averages over the ensemble of s time series realizations the relevant non zero correlation is that between x s t and the increments δ x s t 1 the corresponding coefficient starts from negative values followed by a rapid increase in time and an approach to zero through small fluctuations the processes x s t and δ x s t 1 are thus anticorrelated in the mean the relation between the anticorrelated δ x s t 1 and x s t s 1 s is given by a linear regression with coefficients p 1 and p 0 with ξ s t 1 being the fluctuating part of δ x s t 1 about the linear regression the increments δx s are advanced in time according to the model 9 δ x s t 1 p 1 t 1 x s t p 0 t 1 ξ s t 1 t t 0 fig 5 presents the values of p 1 t one observes that they have high variability and most of the values are negative their dependence on time is well fitted with the power law function 10 p 1 t a p t b p c p a p 1 3733 b p 1 0127 c p 5 5460 10 4 the values of this function are used in the following as coefficients describing the dependence between δ x s t 1 and x s t in the model of c t the values of p 0 t not presented here are very small all being below 10 15 so they will be neglected the fluctuations ξ s t obtained after removing the values p 1 t x s t 1 from δx s t for t t 0 1 are still heteroscedastic similar to the increments δx s t shown in fig 2 a the corresponding volatility is given by the ensemble average u t ξ t and the residuals are defined similarly to 6 by 11 z s t ξ s t u t the log log plot of the volatility u t has two linear parts with different slopes they are fitted with power law functions denoted by υ t using the method described in the previous section 12 υ t a υ t b υ a υ 0 0326 t t 0 t u 0 0056 t t u 1 t b υ 0 8936 t t 0 t u 0 5850 t t u 1 t t u 298 we note that all the values of the coefficients in 12 are very close to those given in 8 thus removing the linear regression from δx s does not change the volatility in a significant way the kolmogorov smirnov test and the autocorrelation functions indicate again that the residual process z s t defined in 11 is a gaussian white noise taking into account the analysis from this section we modify the model 7 for the ensemble of concentration time series for t t 0 1 as follows 13 c t μ t x t 0 1 τ t 0 1 t 1 p 1 τ x τ 1 υ τ z τ with μ t defined in 8 p 1 t given by eq 10 υ t given by eq 12 initial values x t 0 1 almost normally distributed with zero mean and variance σ x t 0 1 2 1 8083 10 4 and z n 0 σ z 2 where σ z 2 1 5759 the regression between δx t and x t 1 introduced in 13 is the mechanism we were looking for which ensures the convergence of the concentration time series toward the true asymptotic behavior an ensemble of 1000 concentration time series generated with the model 13 is presented in fig 4 c they now have a convergent behavior similar to that of the original ensemble compare fig 4 a and c the minimum and maximum concentration values for the initial ensemble and of the generated one are also similar see fig 6 a but the standard deviation σ c t estimated by averaging over the ensemble of generated time series is a bit smaller for t 500 while for t 500 it is larger than for the initial ensemble see fig 6 c 5 nonstationarity of the residual time series the residuals z t from relation 13 seem to be realizations of a gaussian white noise however as seen in section 3 statistical inferences based on time averages computed on individual time series could be misleading therefore a deeper investigation on the statistical structure of the residuals time series should be carried out to proceed we apply a symmetric moving average filter see for example vamoş and crăciun 2012 with the semi length of the window equal to 10 to every z s t for fixed s e g fig 7 a the resulted time series z s t are inhomogeneous with large amplitudes at early times which slowly decay at large times fig 7 b the inhomogeneity might be attributed to a nonstationary autocorrelation of the stochastic process z s t to investigate this possibility we computed correlations between the residuals z s t and z s t τ through averages over the ensemble of s realizations at time lags τ 1 2 3 for all t t 0 τ 1 t the ensemble pearson correlation coefficients for τ 1 denoted by γ 1 t are plotted in fig 8 over the first several hundreds time steps γ 1 t takes positive values then it decreases toward negative values and reaches an almost stationary regime at large times the correlation coefficients for τ 2 and 3 are significantly smaller than γ 1 t and can be neglected hence the process z s t is a nonstationary correlated noise with correlation coefficient decreasing in time this analysis suggests that the residuals z s t can be modeled in a first approximation as an ar 1 process with time varying correlation coefficient see e g kitagawa and gersch 1985 mehta et al 2012 moulines et al 2005 14 z s t γ 1 t z s t 1 ɛ t ɛ n 0 σ ɛ 2 where σ ɛ 2 1 5451 the variable correlation coefficients γ 1 t can be fitted with an exponential function with a constant added plotted with continuous line in fig 8 15 γ 1 t a γ e b γ t c γ a γ 0 7021 b γ 0 0047 c γ 0 1321 we also find that the initial values z s t 0 1 s 1 2 s can be well approximated by a normal distribution with zero mean and σ z t 0 1 2 1 5621 considering the ar 1 model for the residuals z t in 13 we obtain a complete model that can be used to generate concentration time series specified by relations 13 15 an ensemble of 1000 time series generated with this model is presented in fig 4 d the corresponding minimum and maximum values of cs t are shown in fig 6 b and the standard deviations in fig 6 d fig 6 a and b shows that the extreme values of the concentration can be reproduced with either the white noise or the ar 1 models for residuals instead the standard deviation of the concentration time series generated by using the ar 1 model fig 6 d is much more accurate than that obtained with the white noise model fig 6 c to conclude the validation of the model 13 15 we also estimated the probability densities of the values of c t generated with the ar 1 noise model for residuals z t and compared them with those inferred from the initial ensemble mc grw simulations the pdfs are close to each other at all times those for t 32 100 300 500 1000 and 1995 are compared in fig 9 as already expected from the good results for extreme concentration values and standard deviations shown in fig 6 as the time increases the pdfs get narrower and narrower indicating that the values of c t fluctuate close to the average concentration and reach the correct asymptotic behavior thus the time series generating process 13 15 has the desired features of an appropriate mixing model for the pdf approach proposed in suciu et al 2016 a similar mixing model for fdf evolution equations can be derived from an ensemble of time series obtained from grw mc simulations based on spatially filtered kraichnan velocity fields generated with the algorithm described in suciu et al 2016 appendix a the practical advantage of the fdf approach is that the effect of sampling volume can be investigated without solving volume averaged transport equations because their solutions e g volume averaged concentration and variance can be readily obtained by computing the moments of the fdf solution 6 discussion and conclusions the analysis of a statistical ensemble of 1000 time series of concentration allowed us to reveal their complex structure the main structure is similar to a brownian motion but modified by four types of nonstationarity according to 3 the average concentration decreases as a power law in agreement with the theoretical model 2 this being the first nonstationarity of deterministic trend type on this deterministic variation a random component expressed as a sum of increments is superposed see 13 if the increment time series were a gaussian white noise then the random component would be a brownian motion but the increment time series contains three nonstationarities the increments are anticorrelated with the distance between the concentration and its average value over the statistical ensemble anticorrelation described by the linear regression coefficient 10 which is varying in time the amplitude of the residuals of the regression varies in time according to the volatility 12 moreover the demodulated regression residuals have a variable correlation in time and are modeled by an ar 1 process with a time varying parameter 14 the complexity of the structure of these time series also manifests itself in their convergence in time to the asymptotic self similar evolution for t t 0 30 the simulated concentrations undergo a numerical transition as the discontinuous initial concentration is smoothed out after this initial period of time there is a transition period of about 300 time steps with a strong nonstationarity where the volatility has a rapid decrease fig 2 the linear regression coefficient is much larger in absolute value than at later times fig 5 and the autoregressive correlation coefficient takes large positive values fig 8 for larger values of t as the evolution of the concentration approaches the asymptotic behavior all these parameters have small variations and tend to a stationary value fig 4 b illustrates the inability of the simple model 7 and 8 which is a precise mathematical formulation of the mixing model used in suciu et al 2016 to avoid the spreading of the ensemble of time series around the mean as the time increases the behavior of the original ensemble fig 4 a is reproduced with the new model 13 by considering the linear regression term while keeping the noise term unchanged fig 4 c by considering the ar 1 noise 14 and 15 the model 13 improves the overall convergent behavior of the ensemble of generated time series as well as the estimation of the standard deviation a mixing model moves the pdf in concentration spaces by increments of concentration time series pope 1985 suciu 2014 suciu et al 2015 2016 using 4 the increments d c t c t 1 c t of the time series model 13 can be written in a form closer to that used in pdf approaches 16 d c t d c t p 1 t c t 1 c t 1 υ t z t the first and last terms in the right hand side correspond to the simple stochastic model 7 and to its empirical formulation in suciu et al 2016 the linear regression middle term has the structure of interaction by exchange with the mean iem model used in pdf methods for turbulent flows pope 1985 the only difference is that instead of the variable coefficient p 1 t the factor in the iem model is a constant proportional to the mixing frequency inverse of the characteristic time scale the iem model is an exact mixing model rigorously derived for homogeneous and isotropic turbulence pope 2000 however in pdf problems for transport in groundwater flows the iem model underestimates the drift in concentration space which moves the pdf toward small concentration values suciu et al 2015 2016 a time dependent coefficient of the iem model heuristically inferred from the parameters of the transport problem has been also proposed schüler et al 2016 it improves the pdf simulation but only for small to intermediate times it seems that the drawback of the iem model is the absence of the trend increment d c t and that of the noise term in case of the simple stochastic model 7 the drawback is the absence of the regression term both models are generalized by the complete time series model 13 the model 13 reveals the structure of the mixing model which governs the transport in concentration space of the pdf of c t defined by eq 1 the transport of the concentration pdf in concentration space presented in fig 9 shows that the mixing model 16 is practically exact in this case similarly to the classical iem model which is appropriate for modeling a large variety of scenarios of turbulent transport one expects that mixing models for more complex problems of transport in groundwater will have the same structure as 16 consisting of a deterministic trend a noise and a regression term generalizing the classical iem model since the variable regression coefficient p 1 t in eq 10 is negative the regression term describes the time dependent relaxation of the fluctuations c c as the concentration approaches a spatially uniform distribution comparing fig 4 b to c and d we can see that the presence of this term in 13 prevents the occurrence of negative concentrations which is a major drawback of diffusion like mixing models pope 1985 the large number of parameters of the model 13 is required to generate time series with approximately the same statistics as the initial ensemble see figs 6 and 9 on the other hand we found that using instead of ar 1 autoregressive and moving average models of higher order with larger number of parameters to model the noise z t in 13 does not significantly improve the results the need to fit a large number of parameters could be however a cumbersome task in practical applications to pdf fdf problems moreover these parameters are not directly related to the physical parameters of the transport problem to parameterize a model with the same structure as in 16 but for different transport conditions and physical parameters one needs another set of real data i e an ensemble of time series realizations for practical purposes of estimating pdfs of maximum concentration by the approach proposed in suciu et al 2016 the mixing model 16 can be parameterized for the beginning as follows a trend given by the average concentration 2 at the plume center of mass completely specified by the macrodispersion coefficient d or a similar expression for the average concentration at finite times depending on the ensemble dispersion coefficient d t a white noise with variable amplitude inferred from analyses of individual synthetical or measured time series for instance by using the automatic detrending algorithm presented in vamoş and crăciun 2012 the iem model with variable coefficients introduced in schüler et al 2016 specified by the local dispersion coefficient d and the longitudinal component of the effective dispersion tensor or equivalently by the longitudinal effective dispersion coefficient the correlation length λ of the log hydraulic conductivity field and the dispersion time scale λ 2 d the time series mixing model 16 has been inferred from mc simulations for initial conditions which correspond to an instantaneous injection of the resident concentration in an experimental setup we did not consider the in flux injection mode and continuous injections over finite intervals in time or in the longitudinal spatial direction demmy et al 1999 in such situations we only can expect that a stationary regime is reached more rapidly and the regression coefficient p 1 t in eq 16 approaches a constant value in shorter times we investigated instead the influence of the sampling time and spatial sampling domain as well as the effect of large variance of the log hydraulic conductivity field in all cases we found that the time series process has the general structure of eq 16 but with more or less important changes of the parameters as shown in appendix a 1 the effect of reducing the sampling interval from 1 d to 0 5 d is the strengthening of the correlation of the noisy z t in eq 13 by replacing the transverse slab in eq 1 with square sampling domains of edge equal to 1 m and 2 m respectively we found that the regression coefficient p1 t is no longer a power law being better approximated by a polynomial fitting and the numerical transition at the beginning of the time series takes longer the model being valid for t 100 appendix a 2 increasing the variance of the log hydraulic conductivity field to σ l n k 2 6 0 the time series model reproduces the statistics of the initial ensemble with a lower accuracy but still keeps the structure of 16 as well as the structure of the parameter functions with modified numerical constants moreover since larger velocity fluctuations result in enhanced mixing the smoothing of the discontinuous initial condition is faster than for small variability and the model is already valid for t 10 appendix a 3 as a general conclusion we note that the time series model has a general structure consisting of a deterministic trend a linear regression and a noise but for accurate assessments of the parameters separate analyzes for different experimental scenarios are required acknowledgments the computation of the ensemble of concentration time series was supported by the jülich supercomputing centre germany as part of the project jicg41 the work of n s was partially supported by the deutsche forschungsgemeinschaft germany under grants at 102 7 1 kn 229 15 1 su 415 2 1 appendix a influence of sampling time spatial sampling domain and variance of the ln k field a1 influence of sampling time repeating the analysis presented above for an ensemble of time series obtained from the same grw mc simulations but with cross section concentration 1 sampled at 0 5 d instead of 1 d we found that the time series model preserves the structure 13 with modified parameters as shown in table a 1 the model 3 of the mean concentration remains practically unchanged the difference between the coefficients aμ being a consequence of time scaling from t to t 2 in case δ t 0 5 d where the time series with t 4000 terms corresponds to the same physical time of 2000 d the other parameters are more or less close to each other with the exception of the parameters of the ar 1 noise the decrease of bγ and the increase of cγ in 15 correspond to a strengthening of the correlation of the noisy part of the increments from 13 since this correlation is strictly positive in case δ t 0 5 according to 13 the correlation of the centered time series 4 increases as well these effects are somewhat similar to that observed in a recent study on the influence of the lag on the statistics of the increments of a subordinated gaussian process riva et al 2015 a2 influence of spatial sampling domain to investigate the dependence of the time series model on the sampling domain we repeated the analysis from sections 3 5 for concentration time series sampled similarly to eq 1 at the expected center of mass of the plume at time intervals of 1 day in spatial domains of 2 m 2 m and 1 m 1 m the corresponding ensembles of grw mc simulations were obtained for the same numerical setup and initial condition of the two dimensional transport problem as for the ensemble of concentration time series sampled in cross section transverse slabs described in section 2 the new time series are more irregular than those sampled in the cross section of the domain this process is no longer an exact mixing model but can be used as a starting approximation for three dimensional pdf problems two spatial dimensions and a concentration axis the new time series models for small sampling domains keep the general structure of 13 but now the regression coefficient p 1 t is no longer a power law function being better approximated by a polynomial fitting for the purpose of illustrations presented in figs a 1 and a 2 we did not refine the polynomial fitting using instead the regression coefficients computed from initial ensembles of time series smoothed with a moving average since the numerical transition zone at the beginning of the time series takes longer the model parameters can be determined only for times larger than t 0 100 fig a 1 shows that the extreme values and the standard deviations obtained from the time series models approximate the values obtained from the mc ensembles with lower accuracy than in case of cross section sampling domain see fig 6 in case of the smaller sampling domain of 1 m 1 m the approximation is better because the fluctuations of the number of particles are smaller than when sampled in the larger domain of 2 m 2 m domain the estimations of the concentration pdf shown in fig a 2 are still acceptable being more accurate in case of the 1 m 1 m domain a3 influence of σ l n k 2 to get a hint on the influence of increasing the variance of the ln k field we use an ensemble of s 200 time series obtained from mc grw simulations of non reactive transport in kraichnan velocity fields generated with σ l n k 2 6 0 for the same initial condition sampling time and sampling domain as in case σ l n k 2 0 1 suciu et al 2011 though these fields are no longer acceptable first order approximations of the darcy flow velocity they can be used to illustrate the effect of high velocity heterogeneity on the structure of the time series process to avoid the effect of particle trapping which occurs at large times in two dimensional simulations with particles in case of large velocity fluctuations suciu et al 2006 the length of the time series has been limited to t 100 days repeating the analysis from sections 3 5 we found that the time series process has the same structure as in case of small variability of the velocity field with modified numerical parameters the regression coefficient p 1 t can be approximated by a power low similarly to the case with small variance σ l n k 2 0 1 since larger velocity fluctuations enhance mixing the smoothing of the discontinuous initial condition is faster than for small variability and the model is already valid for t t 0 1 where t 0 10 the extreme values and the standard deviation of the ensemble of time series are reproduced with lower accuracy than in case σ l n k 2 0 1 fig a 3 a and b but the estimation of the concentration pdf is still satisfactory fig a 3 c 
893,concentration time series are provided by simulated concentrations of a nonreactive solute transported in groundwater integrated over the transverse direction of a two dimensional computational domain and recorded at the plume center of mass the analysis of a statistical ensemble of time series reveals subtle features that are not captured by the first two moments which characterize the approximate gaussian distribution of the two dimensional concentration fields the concentration time series exhibit a complex preasymptotic behavior driven by a nonstationary trend and correlated fluctuations with time variable amplitude time series with almost the same statistics are generated by successively adding to a time dependent trend a sum of linear regression terms accounting for correlations between fluctuations around the trend and their increments in time and terms of an amplitude modulated autoregressive noise of order one with time varying parameter the algorithm generalizes mixing models used in probability density function approaches the well known interaction by exchange with the mean mixing model is a special case consisting of a linear regression with constant coefficients keywords time series analysis monte carlo simulations global random walk groundwater msc 37m10 65c05 60g50 86a05 1 introduction time series are ubiquitous in all fields of hydrology monitoring strategies and sampling procedures in various water management contexts as for example in monitoring of nutrients geer et al 2016 or of nitrate transport in groundwater turkeltaub et al 2016 are based on analyses of concentration time series obtained from geophysical observations the most common examples of groundwater concentration time series are the breakthrough curves obtained from concentration measurements at reference planes in aquifers also often used in subsurface hydrology literature are series indexed instead of time by a one dimensional spatial variable see e g meerschaert et al 2013 examples of such series are among others measured data on porosity permeability hydraulic conductivity electrical resistivity see riva et al 2015 and references therein the complexity of the hydrological time series drew the attention of the scientific community long time ago the analysis of long run hydrological and other geophysical time series mandelbrot and wallis 1968 1969 lead to new concepts extending the classical gaussian models such as gaussian fractional noise and fractional brownian motion mandelbrot and van ness 1968 during the last two decades such mathematical objects were used in subsurface hydrology notably to model the complex structure of the hydraulic conductivity liu et al 2009 meerschaert et al 2013 molz et al 1997 these modeling approaches are based on both measured and synthetic time series synthetic time series obtained from numerical simulations can be used to investigate the behavior of some quantities which are not accessible to direct measurements for instance it was shown by using an automatic algorithm to decompose time series into intrinsic components that in some conditions the transverse component of the trajectory of the classical advection dispersion model of transport in heterogeneous aquifers with randomly distributed hydraulic conductivity behaves as a fractional brownian motion or even as a multifractal vamoş et al 2015 concentration time series recorded at regular time intervals at given points of the aquifer system supply observational data for monitoring and risk assessments of groundwater quality in the context of stochastic subsurface hydrology the heterogeneity of the groundwater flow domain is modeled as a random environment consequently predictions on the behavior of the contaminant concentration are uncertain and have to be modeled as random functions in discrete representations a random function is equivalent to an ensemble of random time series recorded at different points in the domain risk assessments are based on the probability density function pdf of the random concentration concentration pdfs can be inferred in case of moderate heterogeneity if one assumes a gaussian shape of the concentration with random spatial moments estimated from the statistics of the random hydraulic conductivity dentz and tartakovsky 2010 or by assuming the shape of the concentration pdf itself pope 1985 in recent years there were several attempts to apply the pdf approach from turbulence modeling pope 1985 2000 to problems of stochastic subsurface hydrology meyer et al 2010 sanchez vila et al 2009 suciu et al 2015 2016 the pdf approach consists of solving a pdf evolution equation which can be derived from the advection dispersion reaction equation verified by the random concentration pope 1985 evolution equations with the same structure are obtained in the filtered density function fdf approach where instead of ensemble averages spatial filtering procedures are used to infer statistical quantities suciu et al 2016 such equations have to be parameterized by using closure hypotheses and models while the transport of the concentration pdf in the physical space can be modeled by known upscaling procedures building a mixing model which describes the transport of the pdf in the concentration space is still a challenging issue suciu et al 2016 a possible way to search for appropriate mixing models is to use the numerical approach based on the fokker planck equation describing the evolution of a suitably weighted concentration pdf suciu et al 2015 in this approach the mixing model for nonreactive transport is given by an ordinary stochastic differential equation describing the evolution of the concentration on trajectories of an advection dispersion process in case of reactive transport with species independent diffusion coefficients chemical reactions are modeled by including in the stochastic differential equation drift terms given by reaction rates suciu et al 2016 eq 5 in this study we investigate the structure of an ensemble of synthetic random time series of concentration values recorded on the trajectory of the center of mass of the solute plume and we derive a stochastic process which generates time series with almost the same statistics this process reveals the structure and provides the parameters of the mixing model which closes the pdf equation for the concentration at the plume center of mass time series associated to the classical model of nonreactive transport were recently constructed by integrating over the transverse direction of a two dimensional domain the concentration fields computed with the global random walk grw algorithm vamoş et al 2003 at successive longitudinal coordinates of the plume center of mass an ensemble of such time series was computed with independent realizations of the random velocity field and a pdf approach was developed to simulate the pdf of the random concentration suciu et al 2015 2016 the mechanism responsible for the transport of the concentration pdf in concentration space is in this case the stochastic process which generates the ensemble of concentration time series a simple mixing model inferred from the ensemble of simulated time series generates time series by summing up increments of a time dependent trend and gaussian white noise terms with decaying amplitude suciu et al 2016 though this pdf approach provides results close to reference monte carlo mc simulations at early times its performance deteriorates at larger times this can be attributed to the inability of the mixing model to reduce the spreading of the realizations of the process generating the time series around their ensemble average necessary to produce the asymptotical narrowing of the concentration pdf shown by mc simulations keeping in mind the utility of the concentration time series in designing mixing models for pdf approaches we look for a stochastic model for the concentration time series that can be used to generate statistical ensembles having similar features with the initial ensemble of time series obtained from grw mc simulations in this paper the simple model previously used in suciu et al 2016 is refined and modified by considering more complex time series increments the correct asymptotic behavior is ensured by a linear dependence between distances of time series realizations to their ensemble average and their increments in time in this way the larger the distances from the ensemble average the stronger the increments tend to reduce them the residuals obtained after removing the linear regression are correlated and as a first approximation we model them with an amplitude modulated autoregressive process of order one ar 1 with time varying parameter our modeling approach uses methods of time series theory brockwell and davis 1987 hamilton 1994 where statistical inferences are obtained from individual time series as well as methods of statistical physics based on statistical ensembles landau and lifshitz 1984 the paper is organized as follows in section 2 the statistical ensemble obtained by grw mc simulations is described section 3 is dedicated to the analysis and modeling of the ensemble average of the time series and of the increments of the centered time series obtained by subtracting the ensemble average from each time series in section 4 we introduce the linear regression between the centered time series and their increments and we infer the regression coefficients the demodulated regression residuals are further modeled as an ar 1 process with time varying parameter in section 5 in the last section we present some conclusions and discuss the implications of the new time series model for mixing models in pdf methods the influence of sampling time spatial sampling domain and hydraulic conductivity on the structure of the time series model is analyzed in appendix a 2 statistical ensemble of concentration time series we consider the two dimensional problem for nonreactive transport in saturated aquifers previously used in numerical investigations based on grw simulations suciu 2014 suciu et al 2006 2009 and pdf approaches suciu et al 2015 2016 the nonreactive transport was modeled as an advection dispersion process with a constant isotropic local dispersion coefficient d 0 01 m2 d and advection velocity fields given by realizations of a random space function for a log normally distributed hydraulic conductivity field k with small variance σ l n k 2 0 1 and isotropic gaussian correlation with correlation length set to λ 1 m the velocity realizations were generated numerically as superpositions of n p 6400 random periodic modes with the kraichnan routine kraichnan 1970 by the usual approximation for small variances of ln k see details in suciu et al 2016 appendix a the mean velocity field with an amplitude u 1 m d was aligned with the x axis the simulations were conducted over 4000 time steps δ t 0 5 d which correspond to 2000 days or equivalently to 2000 advection time scales λ u the computational domain was a rectangle with dimensions of 750 m in the longitudinal direction and 300 m in the transversal direction a constant spatial step of 0 1 m was considered in both directions so that the grw lattice contained 22 5 millions of nodes the computational domain was larger than the maximum extension of the plume and every time when groups of particles reached the outflow boundary the domain was displaced in the direction of the mean flow so that it contained the entire plume at all times therefore with this numerical setting no boundary conditions were necessary the initial condition consisted of an instantaneous injection of n 10 24 particles uniformly distributed in a transverse slab of 1 m 100 m details on the numerical implementation of the grw algorithm can be found in suciu et al 2006 the cross section concentration recorded at the x coordinate of the expected center of mass of the solute plume x u t was obtained by summing the number of particles n x y t over transverse slabs δx ly where δ x 1 m and ly is the transverse dimension of the two dimensional domain for each simulation one obtains in this way a time series 1 c t c u t t 1 n δ x l y 0 l y u t δ x 2 u t δ x 2 n x y t d x d y the concentrations were sampled at intervals 2δt which correspond to 1 day a statistical ensemble c s t t 1 2 t s 1 2 s of time series of length t 2000 was obtained by repeating the simulations for s 1000 independent realizations of the velocity field see fig 1 a in suciu et al 2006 appendix b2 it has been shown that the large values of the parameters s n and np used in our grw mc simulations ensure the reliability of the statistical inferences obtained by averaging over the ensemble c s t the simplified advection dispersion model constant isotropic local dispersion coefficient and isotropic hydraulic conductivity with small variance considered in this study is the same as that used to develop the pdf fdf approach for groundwater systems suciu et al 2016 despite its simplicity this model can be used to illustrate essential features of transport in groundwater such as influence of local dispersion and sampling volume on concentration fluctuations andričević 1998 caroni and fiorotto 2005 ergodicity suciu et al 2006 memory effects suciu et al 2009 or anomalous behavior vamoş et al 2015 on the other hand the transport of the cross section spatially averaged concentration 1 is well approximated by a one dimensional process parameterized by longitudinal components of the velocity and dispersion coefficients as shown by the numerical results presented in suciu et al 2016 section 5 hence the behavior of the time series 1 is not affected by the anisotropy of the transport parameters as long as the longitudinal dispersion coefficient does not depend on transverse dispersion for instance when the anisotropic dispersion coefficients are proportional to velocity or constant andričević 1998 the choice of a small variance σ l n k 2 of the log hydraulic conductivity facilitates the computation of large ensembles of time series with thousands of terms because it allows fast transport simulations with kraichnan generated velocity fields instead of numerical solutions of the flow equations which would require huge computing resources it has been shown both theoretically andričević 1998 fiori and dagan 2000 schüler et al 2016 and numerically caroni and fiorotto 2005 suciu et al 2006 that for dispersion processes in random velocity fields with short range correlation non vanishing mean and small fluctuations the concentration is approximately normally distributed with time decaying maximum concentration and concentration variance at the center of the plume moreover in the long time limit the process approaches a gaussian diffusion with constant coefficients sometimes called macrodispersion process suciu et al 2006 2009 the behavior of the ensemble average c x t of the concentration sampled across the transverse dimension of the computational domain is accurately approximated by a one dimensional diffusion process with drift velocity u and a time variable ensemble dispersion coefficient d t suciu et al 2016 in the long time limit the normalized mean concentration is then given by the gaussian probability density of the diffusion process with mean ut and constant macrodispersion coefficient d lim t d t 2 c x t 4 π d t 1 2 exp x u t 2 4 d t the mean concentration at the expected center of mass x u t behaves in time as 1 t and because of the approach to the macrodispersion process it is an attractor for the time series c s t investigated in this paper the transport in the concentration space of the concentration pdf investigated in suciu et al 2016 is governed by a mixing model describing the behavior of the increments d c t c t 1 c t of the time series process a statistical analysis of 500 time series has been used to build a simple model for the increments dc t consisting of a deterministic trend given by the ensemble average dc t and a heteroskedastic process approximated by a white noise with time decaying amplitude suciu et al 2016 numerical simulations using this mixing model gave good results at early and intermediate times but failed to predict the true concentration pdf at large times suciu 2014 suciu et al 2015 2016 the observation that this simple mixing model does not describe the approach to the macrodispersive attractor was the starting point and the motivation for deeper investigations presented in this paper 3 statistical time series analysis and modeling each time series c s t for fixed s can be analyzed with methods of time series theory using statistical inferences obtained by time sampling and averaging see for example brockwell and davis 1987 hamilton 1994 but if the time series have regions with strong nonstationarity like the concentration series investigated here these methods fail to reveal some important features in such cases one can use the statistics of the ensemble c s t for fixed t and all values of s for example the ensemble average c t of the concentration see fig 1 is given by the arithmetic mean of the s concentration values c s t at given t fig 1 b presents the log log plot of the ensemble average of concentration as function of time its variation is almost linear except a few values at the beginning of the time series these values may be associated with the numerical transition from the discontinuous initial condition see section 2 to a gaussian shape of the two dimensional concentration field in our grw simulations therefore we consider t t 0 30 and fit the average c t with a power law function 3 μ t a μ t b μ a μ 1 0084 b μ 0 5053 t t 0 plotted with straight line in fig 1 b the fit is consistent with the 1 t long time behavior of the concentration sampled at the plume s center implied by 2 even though the fit is already very good for t 10 the restriction t 30 is necessary to obtain simple power law models for the amplitude of the increments of the time series which are analyzed in the following the centered time series are obtained by subtracting the ensemble average from each time series 4 x s t c s t c t and their increments are defined by 5 δ x s t x s t 1 x s t the increments 5 shown in fig 2 a are heteroscedastic that is their amplitudes vary with time we denote by v t δ x t the ensemble average of the absolute values of the increment time series δx s t at given t by analogy to the theory of financial time series see for example taylor 2007 we refer to the mean amplitude v t as the volatility of the increment time series its values are plotted in log log coordinates in fig 2 b the logarithm of the volatility has a region with nonlinear variation at the beginning and for t t 0 two distinct regions where its variation is almost linear with respect to log10 t i e v t has a power law decay with respect to t in these regions log10 v t has two different slopes the absolute value of the first one being larger to determine more precisely the time value for which log10 v t changes its slope we consider a fixed initial time t 0 30 a fixed end point t 2000 and a variable intermediate time t 0 tv t for each value of tv we fit log10 v t with linear functions for t t 0 t v and for t t v 1 t we compute the square norm error for every value tv e t v t t 0 t v log 10 v t log 10 a ϑ 1 b ϑ 1 log 10 t 2 t t v 1 t log 10 v t log 10 a ϑ 2 b ϑ 2 log 10 t 2 1 2 which has a minimum at t v 288 this minimum separates the two regions with different slopes so we can divide the length t of the time series into three distinct regions with different behavior of the volatility v t a region with numerical variability from t 1 to t t 0 1 a transient region where the volatility decreases rapidly and can be modeled by the power law function ϑ t a ϑ 1 t b ϑ 1 b ϑ 1 0 9209 a ϑ 1 0 0379 between t t 0 and t v 288 a region which corresponds to the approach to the asymptotic behavior with a slow decrease of the volatility modeled by the power law function ϑ t a ϑ 2 t b ϑ 2 b ϑ 2 0 5880 a ϑ 2 0 0057 between t v 1 289 and t 2000 in the following we analyze the residuals obtained after dividing every increment time series δ x s t s 1 s of the statistical ensemble by the volatility v t 6 z s t δ x s t v t the residuals z s t plotted in fig 3 a seem to be realizations of an uncorrelated noise using a common approach in time series theory we check whether the distribution of the residuals z s t for fixed s and t 1 t is normal by the kolmogorov smirnov test the statistics dks of this test is defined as the maximum of the absolute value of the difference between the empirical cumulative distribution function of the individual standardized residual series and the theoretical cumulative distribution function of the normal distribution see for e g bohm and zech 2010 fig 3 b shows that all dks values are smaller than the critical value d k s 0 03028 which corresponds to a 5 significance level the values of the autocorrelation functions estimated through time averages on individual realizations are already negligible from the first time lag together these tests indicate that the residual process z s t defined by 6 is a gaussian white noise based on the above analysis the concentration time series can be modeled as a combination of a deterministic variation of power law type and a sum of terms generated by a gaussian white noise n 0 σ z 2 modulated in amplitude the relations 4 6 and the model ϑ t of the volatility v t presented above provide a relatively simple model of the concentration time series for t t 0 30 7 c t μ t x t 0 τ t 0 t 1 ϑ τ z τ with average concentration and volatility modeled by 8 μ t a μ t b μ a μ 1 0084 b μ 0 5053 ϑ t a ϑ t b ϑ a ϑ 0 0379 t t 0 t v 0 0057 t t v 1 t b ϑ 0 9209 t t 0 t v 0 5880 t t v 1 t t v 288 z n 0 σ z 2 σ z 2 1 5768 this model needs initial values for x t 0 the analysis of the ensemble x s t 0 s 1 1000 shows that the initial values are almost normally distributed with zero mean and variance σ x t 0 2 1 8822 10 4 in order to verify this model we used 7 and 8 to generate 1000 concentration time series plotted in fig 4 b one observes that the time series generated with this model are much more scattered than the initial time series fig 4 a moreover instead of approaching to zero for large values of t some generated time series take negative values in conclusion the model 7 and 8 fails to reproduce the behavior of the initial time series 4 modeling the asymptotic behavior of the concentration to account for the asymptotic behavior of the concentration time series in fig 4 a the simple model defined by relations 7 and 8 has to be completed with a mechanism which prevents the scattering of the time series realizations shown in fig 4 b that means when the distance x s t between a realization s of the concentration time series and the ensemble average increases it should be decreased at the next time steps by increments δx s in the opposite direction therefore we investigate the relation between x s t and its increments at the next time steps by computing pearson correlation coefficients through averages over the ensemble of s time series realizations the relevant non zero correlation is that between x s t and the increments δ x s t 1 the corresponding coefficient starts from negative values followed by a rapid increase in time and an approach to zero through small fluctuations the processes x s t and δ x s t 1 are thus anticorrelated in the mean the relation between the anticorrelated δ x s t 1 and x s t s 1 s is given by a linear regression with coefficients p 1 and p 0 with ξ s t 1 being the fluctuating part of δ x s t 1 about the linear regression the increments δx s are advanced in time according to the model 9 δ x s t 1 p 1 t 1 x s t p 0 t 1 ξ s t 1 t t 0 fig 5 presents the values of p 1 t one observes that they have high variability and most of the values are negative their dependence on time is well fitted with the power law function 10 p 1 t a p t b p c p a p 1 3733 b p 1 0127 c p 5 5460 10 4 the values of this function are used in the following as coefficients describing the dependence between δ x s t 1 and x s t in the model of c t the values of p 0 t not presented here are very small all being below 10 15 so they will be neglected the fluctuations ξ s t obtained after removing the values p 1 t x s t 1 from δx s t for t t 0 1 are still heteroscedastic similar to the increments δx s t shown in fig 2 a the corresponding volatility is given by the ensemble average u t ξ t and the residuals are defined similarly to 6 by 11 z s t ξ s t u t the log log plot of the volatility u t has two linear parts with different slopes they are fitted with power law functions denoted by υ t using the method described in the previous section 12 υ t a υ t b υ a υ 0 0326 t t 0 t u 0 0056 t t u 1 t b υ 0 8936 t t 0 t u 0 5850 t t u 1 t t u 298 we note that all the values of the coefficients in 12 are very close to those given in 8 thus removing the linear regression from δx s does not change the volatility in a significant way the kolmogorov smirnov test and the autocorrelation functions indicate again that the residual process z s t defined in 11 is a gaussian white noise taking into account the analysis from this section we modify the model 7 for the ensemble of concentration time series for t t 0 1 as follows 13 c t μ t x t 0 1 τ t 0 1 t 1 p 1 τ x τ 1 υ τ z τ with μ t defined in 8 p 1 t given by eq 10 υ t given by eq 12 initial values x t 0 1 almost normally distributed with zero mean and variance σ x t 0 1 2 1 8083 10 4 and z n 0 σ z 2 where σ z 2 1 5759 the regression between δx t and x t 1 introduced in 13 is the mechanism we were looking for which ensures the convergence of the concentration time series toward the true asymptotic behavior an ensemble of 1000 concentration time series generated with the model 13 is presented in fig 4 c they now have a convergent behavior similar to that of the original ensemble compare fig 4 a and c the minimum and maximum concentration values for the initial ensemble and of the generated one are also similar see fig 6 a but the standard deviation σ c t estimated by averaging over the ensemble of generated time series is a bit smaller for t 500 while for t 500 it is larger than for the initial ensemble see fig 6 c 5 nonstationarity of the residual time series the residuals z t from relation 13 seem to be realizations of a gaussian white noise however as seen in section 3 statistical inferences based on time averages computed on individual time series could be misleading therefore a deeper investigation on the statistical structure of the residuals time series should be carried out to proceed we apply a symmetric moving average filter see for example vamoş and crăciun 2012 with the semi length of the window equal to 10 to every z s t for fixed s e g fig 7 a the resulted time series z s t are inhomogeneous with large amplitudes at early times which slowly decay at large times fig 7 b the inhomogeneity might be attributed to a nonstationary autocorrelation of the stochastic process z s t to investigate this possibility we computed correlations between the residuals z s t and z s t τ through averages over the ensemble of s realizations at time lags τ 1 2 3 for all t t 0 τ 1 t the ensemble pearson correlation coefficients for τ 1 denoted by γ 1 t are plotted in fig 8 over the first several hundreds time steps γ 1 t takes positive values then it decreases toward negative values and reaches an almost stationary regime at large times the correlation coefficients for τ 2 and 3 are significantly smaller than γ 1 t and can be neglected hence the process z s t is a nonstationary correlated noise with correlation coefficient decreasing in time this analysis suggests that the residuals z s t can be modeled in a first approximation as an ar 1 process with time varying correlation coefficient see e g kitagawa and gersch 1985 mehta et al 2012 moulines et al 2005 14 z s t γ 1 t z s t 1 ɛ t ɛ n 0 σ ɛ 2 where σ ɛ 2 1 5451 the variable correlation coefficients γ 1 t can be fitted with an exponential function with a constant added plotted with continuous line in fig 8 15 γ 1 t a γ e b γ t c γ a γ 0 7021 b γ 0 0047 c γ 0 1321 we also find that the initial values z s t 0 1 s 1 2 s can be well approximated by a normal distribution with zero mean and σ z t 0 1 2 1 5621 considering the ar 1 model for the residuals z t in 13 we obtain a complete model that can be used to generate concentration time series specified by relations 13 15 an ensemble of 1000 time series generated with this model is presented in fig 4 d the corresponding minimum and maximum values of cs t are shown in fig 6 b and the standard deviations in fig 6 d fig 6 a and b shows that the extreme values of the concentration can be reproduced with either the white noise or the ar 1 models for residuals instead the standard deviation of the concentration time series generated by using the ar 1 model fig 6 d is much more accurate than that obtained with the white noise model fig 6 c to conclude the validation of the model 13 15 we also estimated the probability densities of the values of c t generated with the ar 1 noise model for residuals z t and compared them with those inferred from the initial ensemble mc grw simulations the pdfs are close to each other at all times those for t 32 100 300 500 1000 and 1995 are compared in fig 9 as already expected from the good results for extreme concentration values and standard deviations shown in fig 6 as the time increases the pdfs get narrower and narrower indicating that the values of c t fluctuate close to the average concentration and reach the correct asymptotic behavior thus the time series generating process 13 15 has the desired features of an appropriate mixing model for the pdf approach proposed in suciu et al 2016 a similar mixing model for fdf evolution equations can be derived from an ensemble of time series obtained from grw mc simulations based on spatially filtered kraichnan velocity fields generated with the algorithm described in suciu et al 2016 appendix a the practical advantage of the fdf approach is that the effect of sampling volume can be investigated without solving volume averaged transport equations because their solutions e g volume averaged concentration and variance can be readily obtained by computing the moments of the fdf solution 6 discussion and conclusions the analysis of a statistical ensemble of 1000 time series of concentration allowed us to reveal their complex structure the main structure is similar to a brownian motion but modified by four types of nonstationarity according to 3 the average concentration decreases as a power law in agreement with the theoretical model 2 this being the first nonstationarity of deterministic trend type on this deterministic variation a random component expressed as a sum of increments is superposed see 13 if the increment time series were a gaussian white noise then the random component would be a brownian motion but the increment time series contains three nonstationarities the increments are anticorrelated with the distance between the concentration and its average value over the statistical ensemble anticorrelation described by the linear regression coefficient 10 which is varying in time the amplitude of the residuals of the regression varies in time according to the volatility 12 moreover the demodulated regression residuals have a variable correlation in time and are modeled by an ar 1 process with a time varying parameter 14 the complexity of the structure of these time series also manifests itself in their convergence in time to the asymptotic self similar evolution for t t 0 30 the simulated concentrations undergo a numerical transition as the discontinuous initial concentration is smoothed out after this initial period of time there is a transition period of about 300 time steps with a strong nonstationarity where the volatility has a rapid decrease fig 2 the linear regression coefficient is much larger in absolute value than at later times fig 5 and the autoregressive correlation coefficient takes large positive values fig 8 for larger values of t as the evolution of the concentration approaches the asymptotic behavior all these parameters have small variations and tend to a stationary value fig 4 b illustrates the inability of the simple model 7 and 8 which is a precise mathematical formulation of the mixing model used in suciu et al 2016 to avoid the spreading of the ensemble of time series around the mean as the time increases the behavior of the original ensemble fig 4 a is reproduced with the new model 13 by considering the linear regression term while keeping the noise term unchanged fig 4 c by considering the ar 1 noise 14 and 15 the model 13 improves the overall convergent behavior of the ensemble of generated time series as well as the estimation of the standard deviation a mixing model moves the pdf in concentration spaces by increments of concentration time series pope 1985 suciu 2014 suciu et al 2015 2016 using 4 the increments d c t c t 1 c t of the time series model 13 can be written in a form closer to that used in pdf approaches 16 d c t d c t p 1 t c t 1 c t 1 υ t z t the first and last terms in the right hand side correspond to the simple stochastic model 7 and to its empirical formulation in suciu et al 2016 the linear regression middle term has the structure of interaction by exchange with the mean iem model used in pdf methods for turbulent flows pope 1985 the only difference is that instead of the variable coefficient p 1 t the factor in the iem model is a constant proportional to the mixing frequency inverse of the characteristic time scale the iem model is an exact mixing model rigorously derived for homogeneous and isotropic turbulence pope 2000 however in pdf problems for transport in groundwater flows the iem model underestimates the drift in concentration space which moves the pdf toward small concentration values suciu et al 2015 2016 a time dependent coefficient of the iem model heuristically inferred from the parameters of the transport problem has been also proposed schüler et al 2016 it improves the pdf simulation but only for small to intermediate times it seems that the drawback of the iem model is the absence of the trend increment d c t and that of the noise term in case of the simple stochastic model 7 the drawback is the absence of the regression term both models are generalized by the complete time series model 13 the model 13 reveals the structure of the mixing model which governs the transport in concentration space of the pdf of c t defined by eq 1 the transport of the concentration pdf in concentration space presented in fig 9 shows that the mixing model 16 is practically exact in this case similarly to the classical iem model which is appropriate for modeling a large variety of scenarios of turbulent transport one expects that mixing models for more complex problems of transport in groundwater will have the same structure as 16 consisting of a deterministic trend a noise and a regression term generalizing the classical iem model since the variable regression coefficient p 1 t in eq 10 is negative the regression term describes the time dependent relaxation of the fluctuations c c as the concentration approaches a spatially uniform distribution comparing fig 4 b to c and d we can see that the presence of this term in 13 prevents the occurrence of negative concentrations which is a major drawback of diffusion like mixing models pope 1985 the large number of parameters of the model 13 is required to generate time series with approximately the same statistics as the initial ensemble see figs 6 and 9 on the other hand we found that using instead of ar 1 autoregressive and moving average models of higher order with larger number of parameters to model the noise z t in 13 does not significantly improve the results the need to fit a large number of parameters could be however a cumbersome task in practical applications to pdf fdf problems moreover these parameters are not directly related to the physical parameters of the transport problem to parameterize a model with the same structure as in 16 but for different transport conditions and physical parameters one needs another set of real data i e an ensemble of time series realizations for practical purposes of estimating pdfs of maximum concentration by the approach proposed in suciu et al 2016 the mixing model 16 can be parameterized for the beginning as follows a trend given by the average concentration 2 at the plume center of mass completely specified by the macrodispersion coefficient d or a similar expression for the average concentration at finite times depending on the ensemble dispersion coefficient d t a white noise with variable amplitude inferred from analyses of individual synthetical or measured time series for instance by using the automatic detrending algorithm presented in vamoş and crăciun 2012 the iem model with variable coefficients introduced in schüler et al 2016 specified by the local dispersion coefficient d and the longitudinal component of the effective dispersion tensor or equivalently by the longitudinal effective dispersion coefficient the correlation length λ of the log hydraulic conductivity field and the dispersion time scale λ 2 d the time series mixing model 16 has been inferred from mc simulations for initial conditions which correspond to an instantaneous injection of the resident concentration in an experimental setup we did not consider the in flux injection mode and continuous injections over finite intervals in time or in the longitudinal spatial direction demmy et al 1999 in such situations we only can expect that a stationary regime is reached more rapidly and the regression coefficient p 1 t in eq 16 approaches a constant value in shorter times we investigated instead the influence of the sampling time and spatial sampling domain as well as the effect of large variance of the log hydraulic conductivity field in all cases we found that the time series process has the general structure of eq 16 but with more or less important changes of the parameters as shown in appendix a 1 the effect of reducing the sampling interval from 1 d to 0 5 d is the strengthening of the correlation of the noisy z t in eq 13 by replacing the transverse slab in eq 1 with square sampling domains of edge equal to 1 m and 2 m respectively we found that the regression coefficient p1 t is no longer a power law being better approximated by a polynomial fitting and the numerical transition at the beginning of the time series takes longer the model being valid for t 100 appendix a 2 increasing the variance of the log hydraulic conductivity field to σ l n k 2 6 0 the time series model reproduces the statistics of the initial ensemble with a lower accuracy but still keeps the structure of 16 as well as the structure of the parameter functions with modified numerical constants moreover since larger velocity fluctuations result in enhanced mixing the smoothing of the discontinuous initial condition is faster than for small variability and the model is already valid for t 10 appendix a 3 as a general conclusion we note that the time series model has a general structure consisting of a deterministic trend a linear regression and a noise but for accurate assessments of the parameters separate analyzes for different experimental scenarios are required acknowledgments the computation of the ensemble of concentration time series was supported by the jülich supercomputing centre germany as part of the project jicg41 the work of n s was partially supported by the deutsche forschungsgemeinschaft germany under grants at 102 7 1 kn 229 15 1 su 415 2 1 appendix a influence of sampling time spatial sampling domain and variance of the ln k field a1 influence of sampling time repeating the analysis presented above for an ensemble of time series obtained from the same grw mc simulations but with cross section concentration 1 sampled at 0 5 d instead of 1 d we found that the time series model preserves the structure 13 with modified parameters as shown in table a 1 the model 3 of the mean concentration remains practically unchanged the difference between the coefficients aμ being a consequence of time scaling from t to t 2 in case δ t 0 5 d where the time series with t 4000 terms corresponds to the same physical time of 2000 d the other parameters are more or less close to each other with the exception of the parameters of the ar 1 noise the decrease of bγ and the increase of cγ in 15 correspond to a strengthening of the correlation of the noisy part of the increments from 13 since this correlation is strictly positive in case δ t 0 5 according to 13 the correlation of the centered time series 4 increases as well these effects are somewhat similar to that observed in a recent study on the influence of the lag on the statistics of the increments of a subordinated gaussian process riva et al 2015 a2 influence of spatial sampling domain to investigate the dependence of the time series model on the sampling domain we repeated the analysis from sections 3 5 for concentration time series sampled similarly to eq 1 at the expected center of mass of the plume at time intervals of 1 day in spatial domains of 2 m 2 m and 1 m 1 m the corresponding ensembles of grw mc simulations were obtained for the same numerical setup and initial condition of the two dimensional transport problem as for the ensemble of concentration time series sampled in cross section transverse slabs described in section 2 the new time series are more irregular than those sampled in the cross section of the domain this process is no longer an exact mixing model but can be used as a starting approximation for three dimensional pdf problems two spatial dimensions and a concentration axis the new time series models for small sampling domains keep the general structure of 13 but now the regression coefficient p 1 t is no longer a power law function being better approximated by a polynomial fitting for the purpose of illustrations presented in figs a 1 and a 2 we did not refine the polynomial fitting using instead the regression coefficients computed from initial ensembles of time series smoothed with a moving average since the numerical transition zone at the beginning of the time series takes longer the model parameters can be determined only for times larger than t 0 100 fig a 1 shows that the extreme values and the standard deviations obtained from the time series models approximate the values obtained from the mc ensembles with lower accuracy than in case of cross section sampling domain see fig 6 in case of the smaller sampling domain of 1 m 1 m the approximation is better because the fluctuations of the number of particles are smaller than when sampled in the larger domain of 2 m 2 m domain the estimations of the concentration pdf shown in fig a 2 are still acceptable being more accurate in case of the 1 m 1 m domain a3 influence of σ l n k 2 to get a hint on the influence of increasing the variance of the ln k field we use an ensemble of s 200 time series obtained from mc grw simulations of non reactive transport in kraichnan velocity fields generated with σ l n k 2 6 0 for the same initial condition sampling time and sampling domain as in case σ l n k 2 0 1 suciu et al 2011 though these fields are no longer acceptable first order approximations of the darcy flow velocity they can be used to illustrate the effect of high velocity heterogeneity on the structure of the time series process to avoid the effect of particle trapping which occurs at large times in two dimensional simulations with particles in case of large velocity fluctuations suciu et al 2006 the length of the time series has been limited to t 100 days repeating the analysis from sections 3 5 we found that the time series process has the same structure as in case of small variability of the velocity field with modified numerical parameters the regression coefficient p 1 t can be approximated by a power low similarly to the case with small variance σ l n k 2 0 1 since larger velocity fluctuations enhance mixing the smoothing of the discontinuous initial condition is faster than for small variability and the model is already valid for t t 0 1 where t 0 10 the extreme values and the standard deviation of the ensemble of time series are reproduced with lower accuracy than in case σ l n k 2 0 1 fig a 3 a and b but the estimation of the concentration pdf is still satisfactory fig a 3 c 
894,the area of investigation in this study is designed around an improved understanding of fundamentals of the diffusive leakage of brine from a storage aquifer into overlying and underlying low permeability layers during geosequestration of carbon dioxide co2 through development of a theoretical model here we consider a two dimensional domain in cylindrical coordinates comprised of an aquifer and an overburden where the interaction between the two media is handled by imposing the continuities of pressures and fluid fluxes at the aquifer overburden interface this coupled problem is solved by successive implementation of the laplace and finite hankel transforms the developed solutions can be used to analyze diffusive leakage of brine from the aquifer into overburden and generate type curves for average pressures in the aquifer and overburden during injection and post injection periods the results show that the leakage rate at early times is scaled with t 1 2 while it remains constant at late times it is also shown that the average pressure in the aquifer is scaled with t for short and long times moreover the average pressure in the overburden is scaled with t at late times while it is scaled with t 3 2 at early times in addition the results reveal that factors affecting diffusive leakage rate through intact overburden during co2 storage are in decreasing order of significance thickness of overburden thickness of aquifer aquifer to overburden permeability ratio and aquifer to overburden porosity ratio however thickness of aquifer has minimal effect on diffusive leakage of brine within post injection period to evaluate the theoretical model case studies for two potential sites in united kingdom one in lincolnshire and the other one in the firth of forth are conducted the field studies show that the diffusive leakage from the aquifer into the overburden diminishes 40 years after the injection has ceased for lincolnshire while it stops after 12 years for firth of forth the average amount of the brine leaked from the aquifers per standard cubic meter sm3 of the injected co2 through diffusive leakage was found to be 6 28 10 4 m3 of brine or 0 330 kg of brine kg of co2 over 70 years for lincolnshire and 4 59 10 4 m3 of brine or 0 242 kg of brine kg of co2 over 42 years for firth of forth graphical abstract image graphical abstract keywords diffusivity equation injection post injection diffusive leakage leakage rate average pressure type curve nomenclature b formation volume factor c compressibility lt2m 1 e unit vector l h thickness l h dimensionless thickness j diffusive leakage rate of brine l3t 1 j dimensionless diffusive leakage rate of brine k permeability l2 k ratio of aquifer to overburden permeabilities n variable of finite hankel transform p pressure ml 1t 2 p dimensionless pressure q injection rate of co2 l3t 1 r radial coordinate l r dimensionless radius s complex argument of laplace transform s storativity l2t2m 1 t time t ti time for injecting co2 t t temperature k t dimensionless time ti dimensionless time for injecting co2 v darcy velocity vector lt 1 v velocity component lt 1 z compressibility factor z vertical coordinate l z dimensionless height greek letters ρ density ml 3 ϕ porosity fraction φ ratio of aquifer to overburden porosities μ viscosity ml 1t 1 η hydraulic diffusivity l2t 1 ξ ratio of aquifer to overburden hydraulic diffusivities ℓ sign for laplace transform ħ sign for finite hankel transform λ ratio of aquifer to overburden thicknesses ω ratio of aquifer to overburden storativities δt time period for shutting down co2 injection well t δt dimensionless time period for shutting down co2 injection well subscripts 0 early time asymptotic behaviour 1 aquifer 2 overburden late time asymptotic behaviour e external f fluid f firth of forth i initial l lincolnshire p pore post post injection r radial direction r finite hankel transform with respect to r t total t laplace transform with respect to t w well z vertical direction α 1 2 aquifer and overburden superscripts laplace transform finite hankel transform average well pressure average aquifer or overburden pressure 1 introduction leakage of carbon dioxide co2 and brine from deep storage reservoirs is a major risk factor associated with geosequestration metz et al 2005 celia and nordbotten 2009 shaffer 2010 under typical subsurface storage conditions injected co2 is in supercritical state and it is less dense and less viscos than the resident aquifer brines consequently co2 migrates upward and spreads laterally under an overburden which increases the risk of co2 and brine leakage into overlying regions through faults fractures or leaky wells metz et al 2005 damen et al 2005 celia and nordbotten 2009 neufeld et al 2011 sun et al 2013 zeidouni 2014 huang et al 2015 woods et al 2015 shakiba and hosseini 2016 the leakage of co2 and brine may gradually occur however such a leakage can remain undetected for a long time while it has the greatest potential to cause environmental issues in a broad scale metz et al 2005 damen et al 2005 thus it is very important to understand the fundamentals of fluid flow and transport phenomena involved in the co2 and brine leakage associated with geological storage various physical testing techniques can be used for detecting leakage of co2 and brine benson 2006 since the pressure propagation is fast well testing which monitors pressure has been studied as a common potential tool for detection and characterization of co2 and brine leakage from the storage aquifer into overlying layers sun and nicot 2012 jung et al 2013 sun et al 2013 zeidouni 2014 huang et al 2015 shaffer 2010 suggested that leakage of less than 1 of the injected co2 over 1000 years from a storage aquifer allows concentrations of carbon dioxide in atmosphere close to those projected for decreasing emissions by ignoring geomechanical impacts as a result of deformation under controlled field circumstances the pressure differences in the overlying media will be mainly due to the leakage of co2 and brine from the storage aquifer hsieh 1996 kim and hosseini 2013 therefore pressure measurements for the overlying and underlying layers are critical in leakage detection hovorka et al 2013 from the start of efforts for reducing co2 emissions several numerical semi analytical and analytical tools have been developed to study the leakage of co2 and brine from the storage aquifer into the overlying media through faults fractures or well linings and the corresponding pressure changes in these two regions the international energy agency iea published a comprehensive report regarding overburden systems for co2 geological storage ieaghg 2011 all co2 leakage rates discussed in the iea report are in terms of leakage via faults fractures and microfractures within the overburden rather than the overburden itself instead cihan et al 2011 presented a set of analytical solutions for coupled diffuse and focused leakage of groundwater in a multi layered system consisting of any number of aquifers alternating aquitards pumping injection wells and leaky wells their governing equations are one dimensional radial flow in aquifer including the rate of diffuse leakage through the aquifer aquitard interface from aquifer into the overlying or underlying aquitard and one dimensional vertical flow through aquitard in terms of hydraulic head buildup they also used the continuity of hydraulic head buildup as the boundary condition at the aquifer aquitard interface cihan et al 2011 later hou et al 2012 used the stomp subsurface transport over multiple phases simulator to investigate the sensitivity of co2 leakage from a storage aquifer into an intact overburden to different parameters of concern by running an extensive numerical simulation from visual inspection as well as statistical analyses of the fraction of co2 leakage after 200 years hou et al 2012 found that critical factors determining co2 leakage rate through overburden are in decreasing order of significance the overburden thickness overburden permeability reservoir permeability overburden porosity and reservoir porosity subsequently chen et al 2014 investigated the co2 leakage through overburden by a combination of experimental studies and numerical simulation they found that the thickness and permeability of the overburden affect the co2 leakage significantly chen et al 2014 also concluded that the leakage rate has a power relationship with the overburden thickness for certain overburden permeability recently mosaheb and zeidouni 2017 used the analytical solutions developed by zeidouni 2012 for leaky fault in a two layer system and cheng and morohunfola 1993 and cihan et al 2011 for fluid leakage through a low permeability barrier to distinguish between fault and caprock leakage using above zone pressure response however a limited number of semi analytical and analytical works in literature addressed mathematical modeling of the diffusive leakage of brine from the aquifer into the overburden and underburden where the three media interact with each other at the aquifer overburden and aquifer underburden interfaces under these conditions the pressure does not only vary in the aquifer from which brine leakage happens but also in the overburden and underburden into which brine leakage occurs during geological storage in other words this problem is a coupled problem due to the interaction between the aquifer and overburden and the aquifer and underburden at the interfaces thus the area of investigation in this work is designed around an improved understanding of fundamentals of the diffusive leakage of brine from the aquifer into the overburden and underburden through development of a novel theoretical model hou et al 2012 work clearly verifies that there are strong relationships between the co2 leakage rate and the physical properties of the overburden aquifer and underburden therefore addressing the diffusive leakage of brine from the storage aquifer into the overlying and underlying natural intact layers can be of great importance for determining the leakage risk for any given combination of overburden aquifer and underburden properties including thicknesses permeabilities and porosities of the three media we start with a two dimensional coupled aquifer overburden model in which the interaction between the aquifer and overburden is handled by imposing the continuities of pressures and fluid fluxes at the aquifer overburden interface later the laplace and finite hankel transforms are successively implemented to derive the semi analytical solutions for the pressure distributions in the aquifer and overburden then the developed solutions are used to obtain the diffusive leakage of brine and its asymptotic behaviours well pressures in the aquifer and overburden and average aquifer and overburden pressures thereafter all the aforementioned terms are obtained during post injection using the principle of superposition subsequently the fourier inversion algorithms are applied for obtaining the results in the real domain next the new type curves for the problem under study were generated finally field studies are conducted for several coupled aquifer overburden systems to evaluate the presented model in this work this study has three main features first the pressure distributions are presented for a coupled domain composed of an aquifer and an overburden where two media interact with each other at the aquifer overburden interface through diffusive leakage of brine from the aquifer into the overburden during geological storage second the leakage rate from the aquifer into overburden is semi analytically derived which can impact the decisions making with regards to large scale implementation of co2 geosequestration third the new type curves are developed which can be compared with actual field data to qualitatively and quantitatively describe the diffusive leakage of brine from storage aquifers this article is organized as follows first the mathematical modeling is presented then the results are discussed and analyzed followed by different field studies finally conclusions are presented 2 mathematical modeling in this section after assumptions and description of the physical model the governing equations are presented later the semi analytical solutions for the pressure distributions in the domain leakage rate from the aquifer into overburden and its asymptotic behaviours well pressures in the aquifer and overburden and the average aquifer and overburden pressures during injection and post injection periods are derived 2 1 assumptions and description of the physical model the problem is set up by considering a two dimensional cylindrical geometry r z for the domain under study fig 1 the origins of the r and z directions are chosen at the center and bottom of the bounded domain respectively the domain is an element of symmetry composed of an aquifer with thickness of h 1 overlaid by an overburden with thickness of h 2 the external radius of the domain is r e in fact the aquifer and overburden are considered to act as finite reservoirs during co2 geosequestration therefore the developed model in this work is required to assess data from long term well tests in both the aquifer and overburden the well with radius of r w which injects co2 with constant flow rate of q is located at the center of the domain only the aquifer is open to the well this work addresses flow of a single phase fluid in homogenous porous media the fluid is assumed to be slightly compressible the physical properties of the fluid viscosity and isothermal compressibility aquifer and overburden porosities permeabilities and pore compressibilities are supposed to be constant darcy s law is considered applicable to the fluid flow in the aquifer as well as in the overburden initially the aquifer and overburden are saturated with saline water the initial pressure in the domain is equal to pi by injection of co2 into the aquifer it is expected that the domain pressure changes by location and over time here we assume that the length scale of the developed two phase region as a result of injection of supercritical co2 is much smaller than the length scale of the pressure wave propagation such an assumption has been widely used in study of co2 and brine leakage from storage reservoirs farcas and woods 2009 dudfield and woods 2013 huppert and neufeld 2014 bolster 2014 this assumption appears to be reasonable since the pressure diffusion is significantly faster than the dynamics of two phase flow displacement in addition we do not consider the thermal and geomechanical consequences of co2 injection into storage reservoir in our analysis in fact this study is a coupled problem due to the diffusive leakage of brine from the aquifer into the overburden during geological storage therefore the two media interact with each other and the pressure does not only vary in the aquifer but also in the overburden the diffusivity equation can be used as the governing equation for the pressure variation in the domain conceptually the diffusivity equation is derived by combination of equations of continuity state and momentum a mass balance over a control volume of the system aquifer or overburden leads to continuity i e conservation of mass equation 1a ρ v 1 r r ρ v r r ρ v z z ϕ ρ t where ρ is the fluid density v vr vz is the darcy velocity vector where vr and vz are the velocity components in the r and z directions respectively ϕ is the porosity of the porous medium and t is the time the relationship between the fluid compressibility cf pressure p and density is applied as the equation of state for a slightly compressible fluid 1b c f 1 ρ ρ p for the equation of momentum darcy s law is employed 1c v k μ p k μ p r e r p z e z where k is the permeability of the porous medium μ is the fluid viscosity and e r and e z are the unit vectors in the r and z directions respectively the effect of the gravitational force can also be considered in darcy model however the results for darcy equations with and without including gravity will be exactly the same since the formulation for the case of the single phase fluid flow is linear therefore the diffusivity equation is expressed in terms of pressure rather than potential throughout this study accordingly the final form of the diffusivity equation in two dimensional cylindrical coordinates for single phase flow of a slightly compressible fluid though a porous medium can be obtained by combination of eqs 1a 1c 2 2 p 1 r r r p r 2 p z 2 μ c t ϕ k p t 1 η p t where ct is the total compressibility and for a single phase flow is defined as the summation of the fluid compressibility and the pore compressibility of the porous medium cp i e ct cf cp and η k μctϕ is the hydraulic diffusivity 2 2 governing equations the governing equations for the pressure variations in the aquifer and overburden can be developed directly from the two dimensional diffusivity equation see eq 2 in this study the subscripts α 1 2 correspond to the aquifer and overburden respectively the system is nondimensionalized by selecting the well radius r w as the length scale μ 1 ϕ 1 c t 1 r w 2 k 1 r w 2 η 1 as the time scale and qμ1 2πk 1 h 1 to scale the pressure differences in the aquifer and overburden accordingly the dimensionless forms of the diffusivity equations in cylindrical coordinates describing pressure variations for two media can be written as 3 2 p α 1 r r r p α r 2 p α z 2 k φ 1 α 2 k φ p α t α 1 2 where r r rw z z rw p α 2πk 1 h 1 p α pi qμ1 k k 1 k 2 μ2 μ1 φ φ1 c t1 φ2 c t2 and t k 1 μ 1 ϕ 1 c t 1 r w 2 t η 1 r w 2 t in which r is the dimensionless radius z is the dimensionless height p is the dimensionless pressure and t is the dimensionless time in fact k φ in eq 3 is the ratio of the hydraulic diffusivity of the aquifer η 1 k 1 μ 1 ct 1 ϕ 1 to the hydraulic diffusivity of the overburden η 2 k 2 μ 2 ct 2 ϕ 2 and can also be denoted by ξ η 1 η 2 in order to solve governing equations in eq 3 the appropriate initial and boundary conditions for the pressures in the aquifer and overburden can be described as follows the initial pressures inside the aquifer and the overburden are equal to pi 4a p α r z 0 0 as the inner conditions at r rw co2 is injected with constant flow rate of q into the aquifer while there is a no flow boundary for the overburden 4b p α 1 z t r α 2 for the outer conditions at r re no flow boundaries are applied for the aquifer and overburden 4c p α r e z t r 0 where re re rw is the dimensionless external radius there is a no flow boundary condition at the bottom of the element of symmetry z 0 4d p 1 r 0 t z 0 the continuities of the pressures and the fluid fluxes at the interface between the aquifer and overburden z h1 result in 4e p 1 r h 1 t p 2 r h 1 t 4f k p 1 r h 1 t z p 2 r h 1 t z where h 1 h 1 rw is the dimensionless thickness of the aquifer the continuity of the fluid fluxes along the aquifer overburden interface is based on darcy s law a no flow boundary condition is used at the top of the overburden z h1 h2 4g p 2 r h 1 h 2 t z 0 where h 2 h 2 rw is the dimensionless thickness of the overburden the detailed derivations of the semi analytical solutions for the pressure distributions in the domain leakage rate from the aquifer into overburden and its asymptotic behaviours well pressures in the aquifer and overburden and the average aquifer and overburden pressures during injection and post injection periods are presented in appendix a 3 results in the following subsections the developed solutions in this study in combination with practical ranges for the model parameters are used to analyze leakage rate at the aquifer overburden interface later new type curves for average pressures in the aquifer and overburden are generated and described finally the results for the post injection are presented 3 1 practical ranges for the model parameters the ranges of permeability and porosity used for the storage aquifer are provided from properties of sandstone and limestone rocks with a permeability in the range of 9 87 10 18 m2 k 1 6 17 10 13 m2 freeze and cherry 1979 domenico and schwartz 1990 and a porosity within 0 04 ϕ 1 0 30 where the lower bound was reported for the acid gas injection site 8 in the alberta basin hassanzadeh et al 2007 and the upper bound was used by freeze and cherry 1979 and domenico and schwartz 1990 as a maximum value for porosity in reservoir rocks the ranges of permeability and porosity applied for the intact overburden come from typical properties of shale rocks including a permeability in the range of 9 87 10 21 m2 k 2 2 07 10 16 m2 and a porosity within 0 ϕ 2 0 10 freeze and cherry 1979 domenico and schwartz 1990 the range of aquifer thickness is selected as 4 m h 1 330 m where the lower bound was reported for the acid gas injection site 7 in the alberta basin hassanzadeh et al 2007 and the upper bound is the thickness of an aquifer located in lincolnshire in the united kingdom jin et al 2012 the range of overburden thickness is chosen as 1 m h 2 194 m where the lower bound was considered by authors of this study and the upper bound is the thickness of an overburden sited in lincolnshire in the united kingdom jin et al 2012 the range of external radius domain is selected as 102 m re 106 m the parameter ranges used are representative of the full range of properties for potential storage aquifer moreover it is assumed that the well radius is rw 8 89 10 2 m based on the radius of injection wells for field applications as a typical value for the external radius of domain it is supposed to be re 105 m where applied by hassanzadeh et al 2009 for mechanistic and sensitivity studies of accelerating co2 dissolution in aquifers therefore the dimensionless external radius is calculated as re 1 12 106 by choosing ϕ 1 0 25 k 1 2 47 10 13 m2 μ 1 5 10 4 pa s and ct 1 9 10 10 pa 1 the hydraulic diffusivity of the aquifer is calculated as η 1 2 19 m2 s which results in the time scale r w 2 η 1 3 60 10 3 s throughout this study the fluid viscosities and the total compressibilities are supposed to be equal for both the aquifer and overburden i e μ 1 μ 2 and ct 1 ct 2 as a result k and φ become the ratios of aquifer to overburden permeabilities and porosities respectively table 1 summarizes the ranges of dimensionless model parameters used in this section 3 2 leakage rate at the aquifer overburden interface the objective here is to study the potential for diffusive leakage of brine from storage aquifers through the intact overburden for different combinations of rock properties that cover the range of expected variability for natural geosequestration targets the roles of the porosity and permeability ratios and the dimensionless thicknesses of the aquifer and overburden on the dimensionless diffusive leakage rate from the aquifer into the overburden at the interface between them are considered using eq a2 3 fig 2 a illustrates the dimensionless leakage rate j versus the dimensionless time t for a variety of aquifer to overburden porosity ratios in the range of 0 40 φ at h 1 2000 h 2 500 and k 104 for any arbitrary value of the porosity ratio within the previously obtained range see table 1 three different regions are identified early time transition and late time regions the dimensionless diffusive leakage rate at early times is proportional to the square root of the dimensionless time j t which confirms the early time asymptotic behaviour presented in eq a3 1a in other words the leakage of brine is dominated by diffusion mechanism in the early time region after a transition region during middle times the dimensionless diffusive leakage rate reaches to a steady state condition at late times j constant as mathematically proved through eq a3 1b the results in fig 2 a show when the aquifer to overburden porosity ratio increases the dimensionless diffusive leakage rate decreases since the early time and late time solutions are both functions of the porosity ratio as given in eqs a3 1a and a3 1b respectively the early time and late time regions differ from each other for various porosity ratios however the early time duration is shortened while the late time duration is prolonged by increasing the porosity ratio the time expressions and constant values for the early time and late time regions can be determined by using eqs a3 1a and a3 1b respectively the dimensionless leakage rate versus the dimensionless time for different aquifer to overburden permeability ratios in the range of 4 76 10 2 k 6 25 107 at h 1 2000 h 2 500 and φ 10 is demonstrated in fig 2 b the identified three regions are observed for any arbitrary value of the permeability ratio within the formerly provided range in table 1 it is revealed that by increasing the permeability ratio the dimensionless diffusive leakage rate decreases in more details the early time duration is prolonged while the late time duration is decreased as the permeability ratio increases the early time regions vary for different permeability ratios because the early time solution eq a3 1a depends on the permeability ratio whereas the late time regions are stabilized at the same value since the late time solution eq a3 1b is independent of the permeability ratio the time expressions for the early time regions can be obtained by applying eq a3 1a the constant value for the late time region is calculated as j 1 1 φλ 1 1 10 2000 500 2 44 10 2 by using eq a3 1b fig 2 c demonstrates the dimensionless leakage rate versus the dimensionless time for several dimensionless thicknesses of the aquifer 44 99 h 1 3712 04 at h 2 500 φ 10 and k 104 this figure clearly recognizes three regions for an arbitrary value of the dimensionless thickness of the aquifer within the previously obtained range see table 1 it can be found that the dimensionless diffusive leakage rate decreases as the dimensionless thickness of the aquifer increases because the early time and late time solutions are both functions of the dimensionless thickness of the aquifer as provided in eqs a3 1a and a3 1b respectively the early time and late time regions are different from each other for various dimensionless thicknesses of the aquifer it is worth noting that the early time and late time durations remain almost unchanged by varying the dimensionless thicknesses of the aquifer however the time expressions and constant values for the early time and late time regions can be given by applying eqs a3 1a and a3 1b respectively the dimensionless leakage rate versus the dimensionless time for various dimensionless thicknesses of the overburden 11 25 h 2 2182 23 at h 1 2000 φ 10 and k 104 is shown in fig 2 d the recognized three regions are seen for any arbitrary value of the dimensionless thickness of the overburden within the formerly provided range in table 1 it is clear from fig 2 d that by increasing the dimensionless thickness of the overburden the dimensionless diffusive leakage rate increases too in addition the early time duration is prolonged while the late time duration is shortened when the dimensionless thickness of the overburden increases the early time regions are the same for different dimensionless thicknesses of the overburden since the early time solution eq a3 1a is independent of the dimensionless thickness of the overburden whereas the late time regions vary because the late time solution eq a3 1b depends on the dimensionless thickness of the overburden the time expression for the early time region is calculated as j 0 1 π 2 h 1 1 1 k φ t 1 π 2 2000 1 1 10 4 10 t 1 78 10 6 t by using eq a3 1a the constant values for the late time regions can be obtained by applying eq a3 1b 3 3 order of significance of leakage factors it becomes reasonable to compare the performance of the different factors including porosity and permeability ratios and thicknesses of aquifer and overburden for geosequestration purposes with the same amount of co2 injection since the time for injecting co2 is representative of the amount of co2 injection by assuming ti 30 years as co2 injection time comparable to life of a typical power plant cihan et al 2011 and using the previously obtained time scale r w 2 η 1 3 60 10 3 s one can focus on the leakage rate that reached at ti 2 63 1011 by considering this amount of co2 injection the dimensionless leakage rate j versus the aquifer to overburden porosity and permeability ratios φ and k respectively for different scenarios is shown is fig 3 to further investigate the leakage rate after a certain elapsed time since starting co2 injection the asymptotic behaviours of the dimensionless diffusive leakage rate for very small and very large values of the porosity or permeability ratios are also addressed by using combination of eqs a1 13c a1 13e and a2 3 a2 4c for the dimensionless diffusive leakage rate when φ or k approaches 0 or it is possible to arrive at 5a lim j t φ 0 or k ℓ s 1 l i m j s φ 0 or k ℓ s 1 1 h 1 1 k φ coth h 1 s 1 s 3 2 5b lim j t φ or k 0 ℓ s 1 l i m j s φ or k 0 ℓ s 1 1 h 1 1 φ h 2 s coth h 1 s 1 s 3 2 the dimensionless leakage rate versus the aquifer to overburden porosity ratio for different permeability ratios 4 76 10 2 k 6 25 107 at h 1 2000 h 2 500 and ti 2 63 1011 is demonstrated in fig 3 a it is revealed that for each constant value of permeability ratio j 1 φ and j 1 φ at small and large porosity ratios respectively even though for k 106 the j 1 φ relationship breaks down when φ 0 these findings can also be inferred mathematically using eqs 5a and 5b at small values of porosity ratio the diffusive leakage rate decreases as permeability ratio increases although it does not happen for k 105 since the dimensionless diffusive leakage rate is independent of permeability ratio when φ eq 5b j remains unchanged by varying k fig 3 b illustrates the dimensionless leakage rate j versus the aquifer to overburden permeability ratio k for a variety of porosity ratios in the range of 0 40 φ at h 1 2000 h 2 500 and ti 2 63 1011 it is found that for each constant value of porosity ratio j constant and j 1 k at small and large permeability ratios respectively which can also be inferred mathematically using eqs 5a and 5b by increasing porosity ratio the diffusive leakage rate decreases for whole range of permeability ratio this effect on the brine leakage is in agreement with the numerical simulation findings presented by hou et al 2012 for co2 leakage rate through overburden the dimensionless leakage rate versus the aquifer to overburden porosity ratio for several dimensionless thicknesses of the aquifer 44 99 h 1 3712 04 at h 2 500 k 104 and ti 2 63 1011 is demonstrated in fig 3 c as it is expected the diffusive leakage rate decreases by increasing the thicknesses of the aquifer in other words j 1 when h 1 0 and j 0 as h 1 these trends can also be proved through combination of eqs a1 13c a1 13e and a2 3 a2 4c for the dimensionless diffusive leakage rate when h 1 approaches 0 and respectively it is also revealed that for each dimensionless thickness of the aquifer j 1 φ at large porosity ratios by comparison between fig 3 a and c it is possible to mention that the dimensionless thickness of the aquifer plays a relatively more significant role on the diffusive leakage rate than the permeability ratio fig 3 d illustrates the dimensionless leakage rate j versus the aquifer to overburden permeability ratio k for different dimensionless thicknesses of the aquifer in the range of 44 99 h 1 3712 04 at h 2 500 φ 10 and ti 2 63 1011 it is clear that for each dimensionless thickness of the aquifer j constant and j 1 k at small and large permeability ratios respectively the dimensionless leakage rate versus the aquifer to overburden porosity ratio for a variety of dimensionless thicknesses of the overburden 11 25 h 2 2182 23 at h 1 2000 k 104 and ti 2 63 1011 is demonstrated in fig 3 e it is found that for each dimensionless thickness of the overburden j 1 φ at large porosity ratios on the other hand the diffusive leakage rate increases as the thicknesses of the overburden increases in other words j 0 when h 2 0 and j 1 as h 2 which can also be concluded using combination of eqs a1 13c a1 13e and a2 3 a2 4c for the dimensionless diffusive leakage rate when h 2 approaches 0 and respectively a comparison between fig 3 a and e obviously shows that the effect of the dimensionless thickness of the overburden is more pronounced than the effect of the permeability ratio on the diffusive leakage rate this effect on the brine leakage is in agreement with the numerical simulation findings presented by hou et al 2012 for co2 leakage rate through overburden also one can mention that the dimensionless thickness of the overburden plays a more significant role on the diffusive leakage rate than the dimensionless thickness of the aquifer by comparison between fig 3 c and e fig 3 f illustrates the dimensionless leakage rate j versus the aquifer to overburden permeability ratio k for several dimensionless thicknesses of the overburden in the range of 11 25 h 2 2182 23 at h 1 2000 k 104 and ti 2 63 1011 it is revealed that for each dimensionless thickness of the overburden j constant and j 1 k at small and large permeability ratios respectively comparing fig 3 b and f identifies that the dimensionless thickness of the overburden plays a more important role on the diffusive leakage rate than the porosity ratio based on analysis of fig 3 the factors influencing leakage of brine during injection can be ranked in the following decreasing order of significance 1 dimensionless thickness of overburden 2 dimensionless thickness of aquifer 3 aquifer to overburden permeability ratio and 4 aquifer to overburden porosity ratio the presented ranking can also be supported by fig 4 where fig 4 a demonstrates the dimensionless leakage rate j versus the dimensionless time t for four different cases including i h 1 1000 h 2 500 φ 500 k 500 ii h 1 500 h 2 1000 φ 500 k 500 iii h 1 500 h 2 500 φ 1000 k 500 and iv h 1 500 h 2 500 φ 500 k 1000 and fig 4 b shows absolute values of relative change in j for cases i iv respect to base case h 1 500 h 2 500 φ 500 k 500 defined as relative change in j j i iv j base 100 j base versus t the relative change in j for case i is constant and equal to 50 while the relative changes in j for cases ii iv vary with ranges of 0 100 30 50 and 0 30 respectively therefore the previously resulted ranking of the leakage parameters from fig 3 is confirmed since one can generally conclude from fig 4 that the relative change in j for case ii case i case iv case iii 3 4 average aquifer and overburden pressures knowledge of the average pressures in the aquifer and overburden and their changes as functions of time are essential to determine how much co2 are stored in the aquifer and leaked from the aquifer into the overburden respectively fig 5 a illustrates the dimensionless average pressure p α versus the dimensionless time t at h 1 2000 h 2 500 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and aquifer to overburden porosity ratio φ 2 and 1000 including α 1 and φ 2 black solid curve α 1 and φ 1000 blue solid curve α 2 and φ 2 black dashed curve and α 2 and φ 1000 blue dashed curve using eq a5 2 for a special case where pressure in an aquifer with no flow condition along the top boundary is addressed one can reach to the following dimensionless average pressure in the aquifer p 1 by solving governing equation in eq 3 accompanied with initial and boundary conditions in eqs 4a 4d for α 1 and p 1 r h 1 t z 0 using successively implementation of the laplace and finite hankel transforms 6 p 1 t 2 r e 2 1 t the dimensionless pressure in the aquifer with the no flow condition at the top boundary for re 1 12 106 is shown by red solid curve in fig 5 a using eq 6 the results reveal that the average pressures in the aquifer for different porosity ratios and no flow condition at top boundary are almost the same and they are proportional to the dimensionless time p 1 t the results also confirm the early and late time asymptotic behaviours of the dimensionless average pressures presented in eqs a6 1a a6 1b and eq 6 therefore the average pressure in the aquifer remains nearly invariant to the interface condition and the porosity ratio the result for the average pressure in the overburden p 2 is directly proportional to t 3 2 at early times while it varies with t at late times in other words the average pressure in the overburden increases with lower rate at late times p 2 t as compared to the one at early times p 2 t 3 2 during diffusive leakage it is worth mentioning that the average pressure in the overburden at early times increases by increasing the porosity ratio whereas it remains invariant at late times the obtained results also show that all the average pressure in the aquifer and overburden are almost identical at late times regardless of the interface condition and the value of the porosity ratio these outcomes can be mathematically inferred using eqs a6 1a a6 1b and 6 fig 5 b demonstrates the dimensionless average pressure p α versus the dimensionless time t at h 1 2000 h 2 500 φ 10 and re 1 12 106 for different cases according to the medium aquifer α 1 and overburden α 2 and aquifer to overburden permeability ratio k 102 and 108 including α 1 and k 102 black solid curve α 1 and k 108 blue solid curve α 2 and k 102 black dashed curve and α 2 and k 108 blue dashed curve by applying eq a5 2 the dimensionless average pressure in the aquifer with the no flow condition at the top boundary for re 1 12 106 is shown by red solid curve in fig 5 b using eq 6 the similar behaviours as fig 5 a which addressed the effect of the porosity ratio can be observed in fig 5 b for two different permeability ratios and the only difference is that the average pressure in the overburden at early times decreases by increasing the permeability ratio fig 5 c shows the dimensionless average pressure p α versus the dimensionless time t at h 2 500 φ 10 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and dimensionless thickness of the aquifer h 1 500 and 3500 including α 1 and h 1 500 black solid curve α 1 and h 1 3500 blue solid curve α 2 and h 1 500 black dashed curve and α 2 and h 1 3500 blue dashed curve using eq a5 2 the dimensionless average pressure in the aquifer with the no flow condition at the top boundary for re 1 12 106 is shown by red solid curve in fig 5 c using eq 6 the similar trends as fig 5 a which considered the role of the porosity ratio can also be seen in fig 5 c for two different dimensionless thicknesses of the aquifer once can observe that the average pressure in the overburden at early times remains unchanged by increasing the dimensionless thickness of the aquifer fig 5 d illustrates the dimensionless average pressure p α versus the dimensionless time t at h 1 2000 φ 10 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and dimensionless thickness of the overburden h 2 100 and 2000 including α 1 and h 2 100 black solid curve α 1 and h 2 2000 blue solid curve α 2 and h 2 100 black dashed curve and α 2 and h 2 2000 blue dashed curve by applying eq a5 2 the dimensionless pressure in the aquifer with the no flow condition at the top boundary for re 1 12 106 is shown by red solid curve in fig 5 d using eq 6 the similar behaviours as fig 5 b which addressed the influence of the permeability ratio can be observed in fig 5 d for two different dimensionless thicknesses of the overburden fig 5 e demonstrates the dimensionless average pressure p α versus the dimensionless time t at h 1 2000 h 2 500 φ 10 and k 104 for different cases according to the medium aquifer α 1 and overburden α 2 and dimensionless external radius re 103 and 107 including α 1 and re 103 black solid curve α 1 and re 107 blue solid curve α 2 and re 103 black dashed curve and α 2 and re 107 blue dashed curve using eq a5 2 the dimensionless pressures in the aquifer with the no flow condition at the top boundary for re 103 and 107 are shown by red and green solid curves respectively in fig 5 e using eq 6 it is found from fig 5 e that the dimensionless average pressures in the aquifer and overburden decrease by increasing the dimensionless external radius regardless of the interface condition 3 5 post injection thus far the results are presented during co2 injection now the leakage rate from the aquifer into overburden and average aquifer and overburden pressures during post injection period are studied it is assumed that after ti 30 years or ti 2 63 1011 has elapsed since the starting of co2 injection into the storage aquifer overlaid by a natural intact overburden the injection is shut down for δt 70 years cihan et al 2011 by using the previously obtained time scale r w 2 η 1 3 60 10 3 s the dimensionless time period for shutting down the co2 injection becomes δt 6 13 1011 therefore one can analyze the leakage rate and average aquifer and overburden pressures for different scenarios during co2 injection time from 0 to ti 2 63 1011 and for the period of post injection between ti 2 63 1011 and ti δt 8 75 1011 fig 6 a and b illustrate the dimensionless leakage rates versus the dimensionless time t during co2 injection j and post injection jpost periods at h 1 2000 and h 2 500 for different cases based on the aquifer to overburden porosity and permeability ratios including φ 2 and k 104 black solid curve φ 1000 and k 104 blue solid curve φ 10 and k 102 black dashed curve and φ 10 and k 108 blue dashed curve using eqs a2 3 and a7 2 the obtained results for the dimensionless leakage rate versus the dimensionless time during co2 injection in fig 6 a were discussed in section 3 2 it is revealed that the dimensionless leakage rate within post injection period is almost negligible for small φ 2 and large φ 1000 values of the porosity ratios and small permeability ratio k 102 however the dimensionless leakage rate is not negligible and decreases during post injection for large permeability ratio k 108 the dimensionless leakage rates versus the dimensionless time t during co2 injection j and post injection jpost periods at φ 10 and k 104 for different cases based on the dimensionless thicknesses of aquifer and overburden including h 1 500 and h 2 500 black solid curve h 1 3500 and h 2 500 blue solid curve h 1 2000 and h 2 100 black dashed curve and h 1 2000 and h 2 2000 blue dashed curve using eqs a2 3 and a7 2 are demonstrated in fig 6 c and d the presented results for the dimensionless leakage rate versus the dimensionless time during co2 injection in fig 6 c were described in section 3 2 it is found that the dimensionless leakage rate within post injection period is almost insignificant for small h 1 500 and large h 1 3500 values of the dimensionless thicknesses of aquifer and small dimensionless thickness of overburden h 2 100 however the dimensionless leakage rate is significant and decreases sharply during post injection for large dimensionless thickness of overburden h 2 2000 based on analysis of fig 6 the factors affecting leakage of brine within post injection period can be ranked in the following decreasing order of significance 1 dimensionless thickness of overburden 2 aquifer to overburden permeability ratio 3 aquifer to overburden porosity ratio and 4 dimensionless thickness of aquifer it is worth mentioning that dimensionless thickness of aquifer has minimal effect on diffusive leakage of brine during post injection period while it is ranked as the second factor impacting leakage of brine during injection the presented ranking can also be supported by fig 7 where fig 7 a and b demonstrate the dimensionless leakage rates versus the dimensionless time t during co2 injection j and post injection jpost periods for four different cases including i h 1 1000 h 2 500 φ 500 k 500 ii h 1 500 h 2 1000 φ 500 k 500 iii h 1 500 h 2 500 φ 1000 k 500 and iv h 1 500 h 2 500 φ 500 k 1000 and fig 7 c and d show absolute values of relative change in j and relative change in jpost for cases i iv as compared to the base case h 1 500 h 2 500 φ 500 k 500 defined as relative change in j j i iv j base 100 j base and relative change in jpost jpost i iv jpost base 100 jpost base versus t the results for j and absolute value of relative change in j versus t during co2 injection in fig 7 a and c were discussed in section 3 3 during post injection period the relative change in jpost for case i is constant and equal to 50 while the relative changes in jpost for cases ii iv vary with ranges of 6 700 22 75 and 1 100 respectively therefore the previously resulted ranking of the parameters affecting leakage of brine during post injection from fig 6 is confirmed since one can generally conclude from fig 7 that the relative change in jpost for case ii case iv case iii case i fig 8 a and b illustrate the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post injection p α p o s t periods at h 1 2000 h 2 500 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and aquifer to overburden porosity ratio φ 2 and 1000 including α 1 and φ 2 black solid curve α 1 and φ 1000 blue solid curve α 2 and φ 2 black dashed curve and α 2 and φ 1000 blue dashed curve using eqs a5 2 and a7 4 the obtained results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 a were discussed in section 3 4 it is revealed that the dimensionless average pressures in the aquifer and overburden remain constant within post injection period and are equal for small and large porosity ratios which implies p 1 p o s t p 2 p o s t 0 369 for small porosity ratio φ 2 and p 1 p o s t p 2 p o s t 0 415 for large porosity ratio φ 1000 however p α p o s t increases by increasing aquifer to overburden porosity ratio the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post inbjection p α p o s t periods at h 1 2000 h 2 500 φ 10 and re 1 12 106 for different cases according to the medium aquifer α 1 and overburden α 2 and aquifer to overburden permeability ratio k 102 and 108 including α 1 and k 102 black solid curve α 1 and k 108 blue solid curve α 2 and k 102 black dashed curve and α 2 and k 108 blue dashed curve by applying eqs a5 2 and a7 4 are demonstrated in fig 8 c and d the presented results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 c were described in section 3 4 it is found that the dimensionless average pressures in the aquifer and overburden remain unchanged within post injection period and are equal for small permeability ratio which implies p 1 p o s t p 2 p o s t 0 405 for k 102 the dimensionless average pressure in the aquifer is significantly larger than the one in the overburden for large permeability ratio k 108 since the pressure still diffuses from the aquifer into the overburden during post injection although the diffusive leakage of brine decreases the dimensionless average pressure in the overburden increases for large permeability ratio k 108 fig 8 e and f show the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post injection p α p o s t periods at h 2 500 φ 10 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and dimensionless thickness of the aquifer h 1 500 and 3500 including α 1 and h 1 500 black solid curve α 1 and h 1 3500 blue solid curve α 2 and h 1 500 black dashed curve and α 2 and h 1 3500 blue dashed curve using eqs a5 2 and a7 4 the results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 e were explained in section 3 4 it is clear from fig 8 f that the dimensionless average pressures in the aquifer and overburden remain fixed within post injection period and are equal for small and large dimensionless thicknesses of aquifer which implies p 1 p o s t p 2 p o s t 0 378 for small dimensionless thickness of aquifer h 1 500 and p 1 p o s t p 2 p o s t 0 410 for large dimensionless thickness of aquifer h 1 3500 however p α p o s t increases by increasing dimensionless thickness of aquifer the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post injection p α p o s t periods at h 1 2000 φ 10 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and dimensionless thickness of the overburden h 2 100 and 2000 including α 1 and h 2 100 black solid curve α 1 and h 2 2000 blue solid curve α 2 and h 2 100 black dashed curve and α 2 and h 2 2000 blue dashed curve by applying eqs a5 2 and a7 4 are shown in fig 8 g and h the obtained results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 g were addressed in section 3 4 it can be realized that the dimensionless average pressures in the aquifer and overburden remain constant within post injection period and are equal for small and large dimensionless thicknesses of overburden which implies p 1 p o s t p 2 p o s t 0 413 for small dimensionless thickness of overburden h 2 100 and p 1 p o s t p 2 p o s t 0 378 for large dimensionless thickness of overburden h 2 2000 however p α p o s t decreases by increasing dimensionless thickness of overburden fig 8 i and j illustrate the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post injection p α p o s t periods at h 1 2000 h 2 500 φ 10 and k 104 for different cases according to the medium aquifer α 1 and overburden α 2 and dimensionless external radius re 103 and 107 including α 1 and re 103 black solid curve α 1 and re 107 blue solid curve α 2 and re 103 black dashed curve and α 2 and re 107 blue dashed curve using eqs a5 2 and a7 4 the presented results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 i were discussed in section 3 4 it is revealed that the dimensionless average pressures in the aquifer and overburden remain unchanged within post injection period and are equal for small and large dimensionless external radius which implies p 1 p o s t p 2 p o s t 5 13 10 5 for small dimensionless external radius re 103 and p 1 p o s t p 2 p o s t 5 13 10 3 for large dimensionless external radius re 107 note that re 103 is a very small storage medium and thus a high pressure is observed this small dimensionless external radius is used to conduct sensitivity analysis and it is not common in real application however p α p o s t decreases significantly by increasing dimensionless external radius 4 field studies case studies for two potential sites in united kingdom including lincolnshire and firth of forth are conducted to evaluate the presented model in this work the physical rock and fluid properties of the aquifer and overburden in these two sites along with the radius of the co2 well injection which have been used previously by jin et al 2012 for static and dynamic estimations of co2 storage are summarized in table 2 using the defined dimensionless parameters in this study accompanied with table 2 result in the values for the dimensionless model parameters for lincolnshire and firth of forth see table 3 by using the rock and fluid properties of the aquifers in lincolnshire and firth of forth sites see table 2 the hydraulic diffusivities of the aquifers in these sites are calculated as η 1 l 2 74 m2 s and η 1 f 0 55 m2 s respectively which result in the time scales r w 2 η 1 l 8 21 10 3 s and r w 2 η 1 f 4 07 10 2 s respectively therefore by assuming ti 30 years as co2 injection time δt 70 years for post injection period cihan et al 2011 and using these time scales one can focus on the leakage rate from the aquifers into the overburdens and average pressures in the aquifers and overburdens during co2 injection in the aquifer of lincolnshire site from 0 to til 1 15 1011 and in the aquifer of firth of forth site between 0 and tif 2 32 1010 and throughout post injection from til 1 15 1011 to til δtl 3 84 1011 for lincolnshire site and between tif 2 32 1010 and tif δtf 7 74 1010 for firth of forth site fig 9 a illustrates the dimensionless leakage rates versus the dimensionless time tl during co2 injection jl and post injection jpost l periods for lincolnshire site blue solid curve and blue dashed lines using the leakage parameters in table 3 for the period of co2 injection in the aquifer of lincolnshire site the dimensionless leakage rate increases by the dimensionless time jl t at early times and then reaches to 0 22 at til 1 15 1011 within transition region it seems that 30 years of co2 injection is not enough for the leakage rate to arrive at a steady state condition subsequently the dimensionless leakage rate decreases throughout post injection period and becomes zero at til δtl 2 67 1011 or til δt l 70 years in other words the diffusive leakage ceases after δt l 40 years from starting post injection period the average amount of the brine leaked from the aquifer per standard cubic meter sm3 of the injected co2 through diffusive leakage was found to be 6 28 10 4 m3 of brine or 0 330 kg of brine kg of co2 over 70 years for lincolnshire the dimensionless leakage rates versus the dimensionless time tf during co2 injection jf and post injection jpost f periods for firth of forth site red solid curve and red dashed lines using the leakage parameters in table 3 are shown in fig 9 b within the period of co2 injection in the aquifer of firth of forth site the dimensionless leakage rate increases by the dimensionless time jf t at early times and after a transition region reaches to 0 19 at tif 2 32 1010 which recognizes a steady state condition for late times thereafter the dimensionless leakage rate decreases throughout post injection and becomes zero tif δtf 3 23 1010 or tif δt f 42 years in other words the diffusive leakage diminishes δt f 12 years after the start of the post injection period the average amount of the brine leaked from the aquifer per standard cubic meter sm3 of the injected co2 through diffusive leakage was found to be 4 59 10 4 m3 of brine or 0 242 kg of brine kg of co2 over 42 years for firth of forth fig 10 a and b demonstrate the dimensionless average pressures in the aquifer α 1 black solid curve and overburden α 2 black dashed curve of lincolnshire site versus the dimensionless time tl during co2 injection p α l and post injection p α p o s t l periods using the leakage parameters in table 3 for the period of co2 injection in the aquifer of lincolnshire site the average pressure in the overburden increases with larger slope p 2 l t 3 2 compared to the one in the aquifer p 1 l t at early times however p 2 l is lower than p 1 l and reach to 6 64 and 5 14 respectively at til 1 15 1011 it looks that 30 years of co2 injection is not sufficient for the average pressure in the overburden to show the late time behaviour where p 2 l t throughout post injection period the average pressures in the aquifer and overburden vary slightly within 6 30 p 1 p o s t l 6 64 and 5 14 p 2 p o s t l 6 30 respectively however p 1 p o s t l is larger than p 2 p o s t l and both reach to 6 30 at til δtl 3 84 1011 the dimensionless average pressures in the aquifer α 1 black solid curve and overburden α 2 black dashed curve of firth of forth site versus the dimensionless time tf during co2 injection p α f and post injection p α p o s t f periods using the leakage parameters in table 3 are shown in fig 10 c and d for the period of co2 injection in the aquifer of firth of forth site the average pressures in the aquifer p 1 f and overburden p 2 f are proportional to t and t 3 2 respectively at early times the average pressure in the overburden increases with lower slope at late times p 2 f t compared to the one at early times p 2 f t 3 2 however p 1 f is larger than p 2 f at early times while they are the same at late times and both reach to 0 95 at tif 2 32 1010 the average pressures in the aquifer and overburden vary slightly within 0 93 p 1 p o s t f 0 95 and 0 89 p 2 p o s t f 0 93 respectively throughout post injection period however p 2 p o s t f is lower than p 1 s h u t f and both quickly reach to 0 93 at tif δtf 7 74 1010 5 conclusions in this study the diffusive leakage of brine from a storage aquifer into overlying and underlying natural intact layers is modeled the presented model considers a two dimensional domain comprised of an aquifer and an overburden where the interaction between the two media is handled by imposing the continuities of pressures and fluid fluxes at the aquifer overburden interface the laplace transform technique in combination with the finite hankel transform method is adopted to solve this coupled problem and obtain the solutions for the pressure distributions in the aquifer and overburden the diffusive leakage rate from the aquifer into overburden and its asymptotic behaviour well pressures in the aquifer and overburden and average aquifer and overburden pressures and its early and late time behaviours during co2 injection the principle of superposition can be applied to the developed solutions to analyze diffusive leakage of brine from the aquifer into overburden and generate type curves for average pressures in the aquifer and overburden during post injection as well the results reveal that the diffusive leakage rate at early times is proportional to the square root of the time j t while it remains constant at late times it is also shown that the average pressure in the aquifer varies linearly with the time for short and long times p 1 t in addition this study gives this conclusion that the average pressure in the overburden increases with lower slope at late times p 2 t compared to the one at early times p 2 t 3 2 during diffusive leakage of brine from the storage aquifer into the overlying layer based on analysis of the results it is found that factors influencing leakage rate through overburden during co2 injection are in decreasing order of significance thickness of overburden thickness of aquifer aquifer to overburden permeability ratio and aquifer to overburden porosity ratio however thickness of aquifer has minimal effect on diffusive leakage of brine within post injection period finally the presented model through conducting case studies for two potential sites in united kingdom one in lincolnshire and the other one in the firth of forth is evaluated and tested the field studies show that the diffusive leakage from the aquifer into the overburden diminishes 40 years after the injection has ceased for lincolnshire while it stops after 12 years for firth of forth the average amount of the brine leaked from the aquifers per standard cubic meter sm3 of the injected co2 through diffusive leakage was found to be 6 28 10 4 m3 of brine or 0 330 kg of brine kg of co2 over 70 years for lincolnshire and 4 59 10 4 m3 of brine or 0 242 kg of brine kg of co2 over 42 years for firth of forth acknowledgements the first author is gratefully appreciative of the financial support from the department of petroleum engineering in the college of engineering and applied science at the university of wyoming financial support of the natural sciences and engineering research council of canada nserc is also gratefully acknowledged appendix a solutions of the governing equations a 1 semi analytical solutions for pressure distributions in the domain the governing equations in eq 3 subject to the initial and boundary conditions in eqs 4a 4g resemble a coupled problem due to the continuities of the pressures and the fluid fluxes at the interface between the aquifer and overburden the solutions of the two dimensional diffusivity equations in cylindrical coordinates can be obtained by using successive implementation of the laplace and finite hankel transforms combination of these two transform techniques reduces the diffusivity partial differential equations pdes for the aquifer and overburden to second order linear nonhomogeneous ordinary differential equations odes with constant coefficients as a result the odes can be coupled and solved by applying the continuity conditions at the aquifer overburden interface and the no flow boundaries at the bottom of the aquifer and the top of the overburden first the laplace transforms with respect to t for the dimensionless pressures in the aquifer and overburden are defined as a1 1 p α r z s ℓ t p α r z t 0 p α r z t e s t d t where p α is the dimensionless pressures in the aquifer and overburden in the laplace domain s is the complex argument of the laplace transform and ℓt is the sign for the laplace transform with respect to t by taking the laplace transform with respect to t from the governing equations in eq 3 and the boundary conditions in eqs 4b 4g and using the initial conditions in eq 4a one can get a1 2 2 p α k φ 1 α 2 k φ s p α a1 3a p α 1 z s r α 2 s a1 3b p α r e z s r 0 a1 3c p 1 r 0 s z 0 a1 3d p 1 r h 1 s p 2 r h 1 s a1 3e k p 1 r h 1 s z p 2 r h 1 s z a1 3f p 2 r h 1 h 2 s z 0 now an appropriate finite hankel transform is derived for the problem under study the finite hankel transform method gives a systematic efficient and straightforward approach for deriving semi analytical and analytical solutions for fluid flow and transport problems with a radial geometry chen et al 2011 the finite hankel transform expresses any given function u r as the weighted sum of a finite number of the linear combination of bessel functions of the first and second kinds of order ν jν λr and yν λr the bessel functions in the sum are all of the same order ν but differ in a scaling factor λ along the r axis to develop the finite hankel transform of p α r z s the eigenvalues and the corresponding eigenfunctions should be determined from the ordinary differential equation ode d2u dr2 1 r du dr βu using the sturm liouville theory subject to the boundary conditions du 1 dr du re dr 0 as the first step β 0 is considered to see if zero is an eigenvalue therefore one can arrive at 1 r d dr rdu dr 0 which has the general solution u c1 c2 ln r by using the homogeneous boundary conditions it is concluded that c2 0 but c1 can be any constant value without loss of generality one can define c1 1 thus β 0 is an eigenvalue of the ode with the corresponding eigenfunction u0 1 for the next step β λ2 is taken into account thus it is possible to reach to r2d2u dr2 rdu dr λ2r2u 0 which is a homogeneous bessel differential equation that has the general solution u c3j0 λr c4y0 λr by applying the boundary conditions at r 1 and re one can obtain c3j1 λ c4y1 λ 0 and c3j1 λre c4y1 λre 0 respectively solving the first expression for c3 and replacing it in the second expression result in c4 j1 λ y1 λre y1 λ j1 λre j1 λ 0 to avoid a trivial solution c4 0 as a result the eigenvalues λn 0 are determined as the countably infinitely many positive roots of the following equation a1 4 j 1 λ n y 1 λ n r e y 1 λ n j 1 λ n r e 0 also the corresponding eigenfunctions un are obtained as a1 5 u n r y 1 λ n j 0 λ n r j 1 λ n y 0 λ n r consequently the set of u n n 0 form a complete orthogonal family of eigenfunctions on 1 r re with corresponding eigenvalues λ n n 0 accordingly the finite hankel transform with respect to r for the dimensionless pressure in the aquifer and overburden in the laplace domain p α r z s are defined as a1 6 p α n z s ℏ r p α r z s r 1 r r e p α r z s u n r r d r where p α is the finite hankel transform of p α n is the variable of the finite hankel transform and ħr is the sign for the finite hankel transform with respect to r applying the finite hankel transform with respect to r to eq a1 2 which is defined in the laplace domain results in a1 7 ℏ r 1 r r r p α r d 2 p α 0 z s d z 2 k φ 1 α 2 k φ s p α the first term on the left hand side of eq a1 7 is derived for the cases of n 0 with the corresponding eigenvalue λ0 0 and eigenfunction u0 1 and n 1 with the corresponding eigenvalues λn 0 and eigenfunctions un by applying the integration by parts twice the inner r 1 and outer r re boundary conditions of the aquifer and overburden in the laplace domain i e eqs a1 3a and a1 3b the boundary conditions du0 1 dr du0 re dr 0 and dun 1 dr dun re dr 0 and the expressions d d r r d u n d r λ n 2 r u n un 1 2 πλn and un re 2 πλn 1 re j1 λn j1 λnre ziener et al 2015 respectively as follows a1 8 r 1 r r e 1 r r r p α r u 0 r d r 2 α s a1 9 r 1 r r e 1 r r r p α r u n r d r 1 s 2 π λ n 2 α λ n 2 p α n 1 combination of eqs a1 7 a1 9 leads to the governing equations which have been implemented successively by the laplace and finite hankel transforms for the cases of n 0 and n 1 respectively as below a1 10 d 2 p α 0 z s d z 2 k φ 1 α 2 k φ s p α 0 z s α 2 s a1 11 d 2 p α n z s d z 2 k φ 1 α 2 k φ s λ n 2 p α n z s 1 s 2 π λ n α 2 n 1 eqs a1 10 and a1 11 are second order linear nonhomogeneous ordinary differential equations odes with constant coefficients in order to solve these equations the finite hankel transform with respect to r in applied for the boundary conditions at the bottom of the element of symmetry z 0 the aquifer overburden interface z h 1 and the top of the overburden z h 1 h 2 in eqs a1 3c a1 3f which are defined in the laplace domain respectively as follows a1 12a d p 1 n 0 s d z 0 a1 12b p 1 n h 1 s p 2 n h 1 s a1 12c k d p 1 n h 1 s d z d p 2 n h 1 s d z a1 12d d p 2 n h 1 h 2 s d z 0 the ode in eq a1 10 subject to the boundary conditions in eqs a1 12a a1 12d gives the dimensionless aquifer and overburden pressures in the laplace and finite hankel domains for the case of n 0 a1 13a p α 0 z s 1 s 2 2 α a 0 sinh b 0 cosh c 0 d 0 where a1 13b a 0 k k φ α k 2 k φ a1 13c b 0 h 1 s h 2 k φ s α h 1 s 2 h 2 k φ s a1 13d c 0 k φ s z h 1 h 2 s z α k φ s z h 1 h 2 2 s z a1 13e d 0 k sinh h 1 s cosh h 2 k φ s k φ cosh h 1 s sinh h 2 k φ s also the ode in eq a1 11 accompanied with the boundary conditions in eqs a1 12a a1 12d leads to the dimensionless aquifer and overburden pressures in the laplace and finite hankel domains for the case of n 1 a1 14a p α n z s 1 s 2 π λ n 1 s λ n 2 2 α a n sinh b n cosh c n d n n 1 where a1 14b a n k s λ n 2 k φ s λ n 2 α k s λ n 2 2 k φ s λ n 2 a1 14c b n h 1 s λ n 2 h 2 k φ s λ n 2 α h 1 s λ n 2 2 h 2 k φ s λ n 2 a1 14d c n k φ s λ n 2 z h 1 h 2 s λ n 2 z α k φ s λ n 2 z h 1 h 2 2 s λ n 2 z a1 14e d n k s λ n 2 sinh h 1 s λ n 2 cosh h 2 k φ s λ n 2 k φ s λ n 2 cosh h 1 s λ n 2 sinh h 2 k φ s λ n 2 from eqs a1 13a and a1 14a the applications of the inversion theorem for the finite hankel transform with respect to n yield a1 15 p α r z s ℏ n 1 p α n z s p α 0 z s r 1 r r e u 0 2 r r d r u 0 n 1 p α n z s r 1 r r e u n 2 r r d r u n r where ℏ n 1 is the sign for the inverse finite hankel transform with respect to n eq a1 15 along with u0 1 eq a1 5 r 1 r r e u 0 2 r d r r e 2 1 2 and r 1 r r e u n 2 r r d r 2 π 2 λ n 2 j 1 2 λ n j 1 2 λ n r e 1 ziener et al 2015 results in a1 16 p α r z s 2 r e 2 1 p α 0 z s π 2 2 n 1 λ n 2 j 1 2 λ n r e p α n z s y 1 λ n j 0 λ n r j 1 λ n y 0 λ n r j 1 2 λ n j 1 2 λ n r e combination of eqs a1 13a a1 14e and a1 16 gives the dimensionless pressures in the aquifer and overburden in the laplace domain therefore it is possible to obtain the semi analytical solutions for the dimensionless aquifer and overburden pressures in the real domain by applying the stehfest inversion method hassanzadeh and pooladi darvish 2007 dejam et al 2011a mashayekhizadeh et al 2011 dejam et al 2013 for eq a1 16 p α r z t ℓ s 1 p α r z s a 2 diffusive leakage rate from the aquifer into overburden in order to gain insight into the leakage of brine from the aquifer into the overburden during geological storage the leakage rate at the aquifer overburden interface is now investigated the dimensionless diffusive leakage rate from the aquifer into the overburden j j q at the interface between them z h 1 can be defined as a2 1 j t 1 h 1 1 k 1 α 2 1 k r 1 r r e p α r z h 1 t z r d r where the injection rate of co2 q and the diffusive leakage rate of brine j are at aquifer conditions aquifer temperature and pressure therefore the dimensionless diffusive leakage rate of brine j is presented in terms of volume of brine divided by volume of injected co2 both at aquifer conditions if the dimensionless diffusive leakage rate of brine j is multiplied by the co2 formation volume factor b c o 2 one can present the dimensionless diffusive leakage rate of brine in terms of volume of brine divided by volume of injected co2 both at standard conditions it is noted that the brine formation volume factor bbrine is taken as unity and the standard conditions correspond to pressure and temperature of 101 325 kpa and 288 71 k respectively by applying the laplace transform with respect to t for eq a2 1 it is possible to obtain the dimensionless diffusive leakage rate at the aquifer overburden interface in the laplace domain j a2 2 j s 1 h 1 1 k 1 α 2 1 k r 1 r r e p α r z h 1 s z r d r eq a2 2 accompanied with eq a1 16 r 1 r r e r d r r e 2 1 2 and r 1 r r e y 1 λ n j 0 λ n r j 1 λ n y 0 λ n r r d r 0 ziener et al 2015 leads to a2 3 j s 1 h 1 1 k 1 α 2 1 k p α 0 z h 1 s z by taking the first derivative with respect to z from eq a1 13a and assigning z h 1 one can derive the term p α 0 z h 1 s z in eq a2 3 as a2 4a p α 0 z h 1 s z 1 s 3 2 e 0 sinh b 0 sinh f 0 d 0 where a2 4b e 0 k φ k 1 α k φ 2 k a2 4c f 0 h 1 s h 2 k φ s α 2 h 1 s h 2 k φ s in fact combination of eqs a1 13c a1 13e and a2 3 a2 4c yields the dimensionless diffusive leakage rate in the laplace domain thus the semi analytical solution for the dimensionless leakage rate in the real domain can be obtained by implementing the fourier inversion technique hassanzadeh and pooladi darvish 2007 dejam et al 2011a b 2014 2016 2017 dejam 2016 for eq a2 3 j t ℓ s 1 j s a 3 early time and late time asymptotic behaviours of the leakage rate for further investigation about the leakage of brine during co2 geosequestration the early time and late time asymptotic behaviours of the dimensionless diffusive leakage rate at the interface between the aquifer and overburden j 0 and j respectively are also studied by using a combination of eqs a1 13c a1 13e and a2 3 a2 4c for the dimensionless diffusive leakage rate and considering the initial s is large for an early time period where t is small and final s is small for a late time period where t is large value theories one can arrive at a3 1a j 0 lim t 0 j t ℓ s 1 lim s j s ℓ s 1 1 h 1 1 1 k φ 1 s 3 2 2 h 1 1 1 k φ t π a3 1b j lim t j t ℓ s 1 lim s 0 j s ℓ s 1 1 1 φ λ 1 s 1 1 φ λ 1 1 ω where λ is the aspect ratio of the aquifer thickness to the overburden thickness h 1 h 2 h 1 h 2 and ω φλ is the storativity ratio and defined as the ratio of the aquifer storativity s 1 ϕ 1 ct 1 h 1 to the overburden storativity s 2 ϕ 2 ct 2 h 2 i e ω s 1 s 2 equations a3 1a and a3 1b suggest that the leakage rates at early and late times can be estimated for a system comprised of an aquifer and an overburden a 4 well pressures in the aquifer and overburden now the semi analytical solutions for development of new type curves during geological storage of co2 in an aquifer overlaid by an overburden associated with diffusive leakage of brine at the aquifer overburden interface are presented by writing eq a1 16 at r 1 and using un 1 2 πλn ziener et al 2015 it is possible to obtain the dimensionless well pressures in the aquifer and overburden in the laplace domain p α w a4 1 p α w z s p α r 1 z s 2 r e 2 1 p α 0 z s π n 1 λ n j 1 2 λ n r e p α n z s j 1 2 λ n j 1 2 λ n r e eq a4 1 is a function of z to obtain the dimensionless average well pressures in the aquifer and overburden in the laplace domain along the dimensionless intervals of the aquifer and overburden p α w eq a4 1 must be integrated with respect to z over the limits of the dimensionless intervals of the aquifer and overburden 0 z h 1 and h 1 z h1 h2 respectively divided by the dimensionless intervals of the aquifer and overburden h1 and h2 respectively therefore by using this approach it is possible to reach at a4 2 p α w s 1 h 1 2 α h 2 α 1 z h 1 α 1 z h 1 h 2 α 1 p α w z s d z 2 r e 2 1 p α 0 s π n 1 λ n j 1 2 λ n r e p α n s j 1 2 λ n j 1 2 λ n r e where p α 0 s and p α n s are the dimensionless average well pressures in the aquifer and overburden in the laplace and finite hankel domains for the cases of n 1 and n 1 respectively p α 0 s can be derived using eq a1 13a as a4 3a p α 0 s 1 h 1 2 α h 2 α 1 z h 1 α 1 z h 1 h 2 α 1 p α 0 z s d z 1 s 2 2 α 1 h 1 2 α h 2 α 1 1 s g 0 sinh h 1 s sinh h 2 k φ s d 0 where a4 3b g 0 k φ k φ α 2 k φ k φ also p α n s can be obtained by applying eq a1 14a as a4 4a p α n s 1 h 1 2 α h 2 α 1 z h 1 α 1 z h 1 h 2 α 1 p α n z s d z 1 s 2 π λ n 1 s λ n 2 2 α 1 h 1 2 α h 2 α 1 g n sinh h 1 s λ n 2 sinh h 2 k φ s λ n 2 d n where a4 4b g n k φ s λ n 2 s λ n 2 k s λ n 2 k φ s λ n 2 α 2 k φ s λ n 2 s λ n 2 k s λ n 2 k φ s λ n 2 combining eqs a1 13e a1 14e and a4 2 a4 4b gives the dimensionless average well pressures in the aquifer and overburden in the laplace domain hence the semi analytical solutions for the dimensionless average well pressures in the aquifer and overburden in the real domain p α w can be obtained by implementing the stehfest inversion algorithm hassanzadeh and pooladi darvish 2007 dejam et al 2011a mashayekhizadeh et al 2011 dejam et al 2013 for eq a4 2 p α w t ℓ s 1 p α w s a 5 average aquifer and overburden pressures the volumetric average aquifer pressure at a given time refers to an indication of how much co2 is stored in the aquifer while the average overburden pressure at a certain time indicates how much co2 is diffusively leaked from the aquifer into the overburden the dimensionless average aquifer and overburden pressures in the laplace domain p α s can be defined as a5 1 p α s 2 r e 2 1 1 h 1 2 α h 2 α 1 r 1 r r e z h 1 α 1 z h 1 h 2 α 1 p α r z s d z r d r eq a5 1 along with eq a1 16 r 1 r r e r d r r e 2 1 2 and r 1 r r e y 1 λ n j 0 λ n r j 1 λ n y 0 λ n r r d r 0 ziener et al 2015 results in a5 2 p α s 2 r e 2 1 1 h 1 2 α h 2 α 1 z h 1 α 1 z h 1 h 2 α 1 p α 0 z s d z 2 r e 2 1 p α 0 s by combination of eqs a1 13e a4 3a a4 3b and a5 2 on can reach to the dimensionless average aquifer and overburden pressures in the laplace domain therefore the semi analytical solutions for the dimensionless average pressures in the aquifer and overburden in the real domain p α can be obtained by using the fourier inversion method hassanzadeh and pooladi darvish 2007 dejam et al 2011a b 2014 2016 2017 dejam 2016 for eq a5 2 p α t ℓ s 1 p α s a 6 early time and late time asymptotic behaviours of the average pressures in order to further investigate about the average aquifer and overburden pressures the early time and late time asymptotic behaviours of the dimensionless average aquifer and overburden pressures p α 0 and p α respectively are also addressed by applying combination of eqs a1 13e a4 3a a4 3b and a5 2 for the dimensionless average aquifer and overburden pressures and considering the initial s is large for an early time period where t is small and final s is small for a late time period where t is large value theories one can reach to a6 1a p α 0 lim t 0 p α t ℓ s 1 lim s p α s ℓ s 1 2 r e 2 1 2 α s 1 h 2 1 k φ 1 φ α 1 s 5 2 2 r e 2 1 t 2 α 1 h 2 1 k φ 1 φ 4 3 π t 3 2 α 1 a6 1b p α lim t p α t ℓ s 1 lim s 0 p α s ℓ s 1 2 r e 2 1 1 1 1 φ λ 1 s 2 2 r e 2 1 1 1 1 φ λ t 2 r e 2 1 1 1 1 ω t a 7 post injection the injection history for a well which is kept injecting co2 at constant flow rate of q for a time ti and then shut down for a period δt is considered this kind of well test is called post injection in order to obtain well pressures in the domain during post injection period the principle of superposition is used since the differential equations and boundary conditions are linear in this study the principle of superposition can be applied to implement the principle of superposition the problem can be treated as the combination of two flow rates q for a time ti δt and q for a period δt where ti is the injection period and δt is the post injection time the result of the combination of these two flow rates is the same as the well being kept injecting co2 at constant flow rate of q for a time ti and then shut down for a period δt horne 1995 the semi analytical solutions for the pressure distributions in the domain p α post leakage rate from the aquifer into overburden jpost well pressures in the aquifer and overburden p α w p o s t and average aquifer and overburden pressures p α p o s t within post injection duration can be obtained using the principle of superposition for eqs a1 16 a2 3 a4 2 and a5 2 respectively as follows a7 1 p α p o s t r z t p α r z t i δ t p α r z δ t t i t t i δ t a7 2 j p o s t t j t i δ t j δ t t i t t i δ t a7 3 p α w p o s t t p α w t i δ t p α w δ t t i t t i δ t a7 4 p α p o s t t p α t i δ t p α δ t t i t t i δ t where ti is the dimensionless time for injecting co2 and δt is the dimensionless time period for shutting down the co2 injection well 
894,the area of investigation in this study is designed around an improved understanding of fundamentals of the diffusive leakage of brine from a storage aquifer into overlying and underlying low permeability layers during geosequestration of carbon dioxide co2 through development of a theoretical model here we consider a two dimensional domain in cylindrical coordinates comprised of an aquifer and an overburden where the interaction between the two media is handled by imposing the continuities of pressures and fluid fluxes at the aquifer overburden interface this coupled problem is solved by successive implementation of the laplace and finite hankel transforms the developed solutions can be used to analyze diffusive leakage of brine from the aquifer into overburden and generate type curves for average pressures in the aquifer and overburden during injection and post injection periods the results show that the leakage rate at early times is scaled with t 1 2 while it remains constant at late times it is also shown that the average pressure in the aquifer is scaled with t for short and long times moreover the average pressure in the overburden is scaled with t at late times while it is scaled with t 3 2 at early times in addition the results reveal that factors affecting diffusive leakage rate through intact overburden during co2 storage are in decreasing order of significance thickness of overburden thickness of aquifer aquifer to overburden permeability ratio and aquifer to overburden porosity ratio however thickness of aquifer has minimal effect on diffusive leakage of brine within post injection period to evaluate the theoretical model case studies for two potential sites in united kingdom one in lincolnshire and the other one in the firth of forth are conducted the field studies show that the diffusive leakage from the aquifer into the overburden diminishes 40 years after the injection has ceased for lincolnshire while it stops after 12 years for firth of forth the average amount of the brine leaked from the aquifers per standard cubic meter sm3 of the injected co2 through diffusive leakage was found to be 6 28 10 4 m3 of brine or 0 330 kg of brine kg of co2 over 70 years for lincolnshire and 4 59 10 4 m3 of brine or 0 242 kg of brine kg of co2 over 42 years for firth of forth graphical abstract image graphical abstract keywords diffusivity equation injection post injection diffusive leakage leakage rate average pressure type curve nomenclature b formation volume factor c compressibility lt2m 1 e unit vector l h thickness l h dimensionless thickness j diffusive leakage rate of brine l3t 1 j dimensionless diffusive leakage rate of brine k permeability l2 k ratio of aquifer to overburden permeabilities n variable of finite hankel transform p pressure ml 1t 2 p dimensionless pressure q injection rate of co2 l3t 1 r radial coordinate l r dimensionless radius s complex argument of laplace transform s storativity l2t2m 1 t time t ti time for injecting co2 t t temperature k t dimensionless time ti dimensionless time for injecting co2 v darcy velocity vector lt 1 v velocity component lt 1 z compressibility factor z vertical coordinate l z dimensionless height greek letters ρ density ml 3 ϕ porosity fraction φ ratio of aquifer to overburden porosities μ viscosity ml 1t 1 η hydraulic diffusivity l2t 1 ξ ratio of aquifer to overburden hydraulic diffusivities ℓ sign for laplace transform ħ sign for finite hankel transform λ ratio of aquifer to overburden thicknesses ω ratio of aquifer to overburden storativities δt time period for shutting down co2 injection well t δt dimensionless time period for shutting down co2 injection well subscripts 0 early time asymptotic behaviour 1 aquifer 2 overburden late time asymptotic behaviour e external f fluid f firth of forth i initial l lincolnshire p pore post post injection r radial direction r finite hankel transform with respect to r t total t laplace transform with respect to t w well z vertical direction α 1 2 aquifer and overburden superscripts laplace transform finite hankel transform average well pressure average aquifer or overburden pressure 1 introduction leakage of carbon dioxide co2 and brine from deep storage reservoirs is a major risk factor associated with geosequestration metz et al 2005 celia and nordbotten 2009 shaffer 2010 under typical subsurface storage conditions injected co2 is in supercritical state and it is less dense and less viscos than the resident aquifer brines consequently co2 migrates upward and spreads laterally under an overburden which increases the risk of co2 and brine leakage into overlying regions through faults fractures or leaky wells metz et al 2005 damen et al 2005 celia and nordbotten 2009 neufeld et al 2011 sun et al 2013 zeidouni 2014 huang et al 2015 woods et al 2015 shakiba and hosseini 2016 the leakage of co2 and brine may gradually occur however such a leakage can remain undetected for a long time while it has the greatest potential to cause environmental issues in a broad scale metz et al 2005 damen et al 2005 thus it is very important to understand the fundamentals of fluid flow and transport phenomena involved in the co2 and brine leakage associated with geological storage various physical testing techniques can be used for detecting leakage of co2 and brine benson 2006 since the pressure propagation is fast well testing which monitors pressure has been studied as a common potential tool for detection and characterization of co2 and brine leakage from the storage aquifer into overlying layers sun and nicot 2012 jung et al 2013 sun et al 2013 zeidouni 2014 huang et al 2015 shaffer 2010 suggested that leakage of less than 1 of the injected co2 over 1000 years from a storage aquifer allows concentrations of carbon dioxide in atmosphere close to those projected for decreasing emissions by ignoring geomechanical impacts as a result of deformation under controlled field circumstances the pressure differences in the overlying media will be mainly due to the leakage of co2 and brine from the storage aquifer hsieh 1996 kim and hosseini 2013 therefore pressure measurements for the overlying and underlying layers are critical in leakage detection hovorka et al 2013 from the start of efforts for reducing co2 emissions several numerical semi analytical and analytical tools have been developed to study the leakage of co2 and brine from the storage aquifer into the overlying media through faults fractures or well linings and the corresponding pressure changes in these two regions the international energy agency iea published a comprehensive report regarding overburden systems for co2 geological storage ieaghg 2011 all co2 leakage rates discussed in the iea report are in terms of leakage via faults fractures and microfractures within the overburden rather than the overburden itself instead cihan et al 2011 presented a set of analytical solutions for coupled diffuse and focused leakage of groundwater in a multi layered system consisting of any number of aquifers alternating aquitards pumping injection wells and leaky wells their governing equations are one dimensional radial flow in aquifer including the rate of diffuse leakage through the aquifer aquitard interface from aquifer into the overlying or underlying aquitard and one dimensional vertical flow through aquitard in terms of hydraulic head buildup they also used the continuity of hydraulic head buildup as the boundary condition at the aquifer aquitard interface cihan et al 2011 later hou et al 2012 used the stomp subsurface transport over multiple phases simulator to investigate the sensitivity of co2 leakage from a storage aquifer into an intact overburden to different parameters of concern by running an extensive numerical simulation from visual inspection as well as statistical analyses of the fraction of co2 leakage after 200 years hou et al 2012 found that critical factors determining co2 leakage rate through overburden are in decreasing order of significance the overburden thickness overburden permeability reservoir permeability overburden porosity and reservoir porosity subsequently chen et al 2014 investigated the co2 leakage through overburden by a combination of experimental studies and numerical simulation they found that the thickness and permeability of the overburden affect the co2 leakage significantly chen et al 2014 also concluded that the leakage rate has a power relationship with the overburden thickness for certain overburden permeability recently mosaheb and zeidouni 2017 used the analytical solutions developed by zeidouni 2012 for leaky fault in a two layer system and cheng and morohunfola 1993 and cihan et al 2011 for fluid leakage through a low permeability barrier to distinguish between fault and caprock leakage using above zone pressure response however a limited number of semi analytical and analytical works in literature addressed mathematical modeling of the diffusive leakage of brine from the aquifer into the overburden and underburden where the three media interact with each other at the aquifer overburden and aquifer underburden interfaces under these conditions the pressure does not only vary in the aquifer from which brine leakage happens but also in the overburden and underburden into which brine leakage occurs during geological storage in other words this problem is a coupled problem due to the interaction between the aquifer and overburden and the aquifer and underburden at the interfaces thus the area of investigation in this work is designed around an improved understanding of fundamentals of the diffusive leakage of brine from the aquifer into the overburden and underburden through development of a novel theoretical model hou et al 2012 work clearly verifies that there are strong relationships between the co2 leakage rate and the physical properties of the overburden aquifer and underburden therefore addressing the diffusive leakage of brine from the storage aquifer into the overlying and underlying natural intact layers can be of great importance for determining the leakage risk for any given combination of overburden aquifer and underburden properties including thicknesses permeabilities and porosities of the three media we start with a two dimensional coupled aquifer overburden model in which the interaction between the aquifer and overburden is handled by imposing the continuities of pressures and fluid fluxes at the aquifer overburden interface later the laplace and finite hankel transforms are successively implemented to derive the semi analytical solutions for the pressure distributions in the aquifer and overburden then the developed solutions are used to obtain the diffusive leakage of brine and its asymptotic behaviours well pressures in the aquifer and overburden and average aquifer and overburden pressures thereafter all the aforementioned terms are obtained during post injection using the principle of superposition subsequently the fourier inversion algorithms are applied for obtaining the results in the real domain next the new type curves for the problem under study were generated finally field studies are conducted for several coupled aquifer overburden systems to evaluate the presented model in this work this study has three main features first the pressure distributions are presented for a coupled domain composed of an aquifer and an overburden where two media interact with each other at the aquifer overburden interface through diffusive leakage of brine from the aquifer into the overburden during geological storage second the leakage rate from the aquifer into overburden is semi analytically derived which can impact the decisions making with regards to large scale implementation of co2 geosequestration third the new type curves are developed which can be compared with actual field data to qualitatively and quantitatively describe the diffusive leakage of brine from storage aquifers this article is organized as follows first the mathematical modeling is presented then the results are discussed and analyzed followed by different field studies finally conclusions are presented 2 mathematical modeling in this section after assumptions and description of the physical model the governing equations are presented later the semi analytical solutions for the pressure distributions in the domain leakage rate from the aquifer into overburden and its asymptotic behaviours well pressures in the aquifer and overburden and the average aquifer and overburden pressures during injection and post injection periods are derived 2 1 assumptions and description of the physical model the problem is set up by considering a two dimensional cylindrical geometry r z for the domain under study fig 1 the origins of the r and z directions are chosen at the center and bottom of the bounded domain respectively the domain is an element of symmetry composed of an aquifer with thickness of h 1 overlaid by an overburden with thickness of h 2 the external radius of the domain is r e in fact the aquifer and overburden are considered to act as finite reservoirs during co2 geosequestration therefore the developed model in this work is required to assess data from long term well tests in both the aquifer and overburden the well with radius of r w which injects co2 with constant flow rate of q is located at the center of the domain only the aquifer is open to the well this work addresses flow of a single phase fluid in homogenous porous media the fluid is assumed to be slightly compressible the physical properties of the fluid viscosity and isothermal compressibility aquifer and overburden porosities permeabilities and pore compressibilities are supposed to be constant darcy s law is considered applicable to the fluid flow in the aquifer as well as in the overburden initially the aquifer and overburden are saturated with saline water the initial pressure in the domain is equal to pi by injection of co2 into the aquifer it is expected that the domain pressure changes by location and over time here we assume that the length scale of the developed two phase region as a result of injection of supercritical co2 is much smaller than the length scale of the pressure wave propagation such an assumption has been widely used in study of co2 and brine leakage from storage reservoirs farcas and woods 2009 dudfield and woods 2013 huppert and neufeld 2014 bolster 2014 this assumption appears to be reasonable since the pressure diffusion is significantly faster than the dynamics of two phase flow displacement in addition we do not consider the thermal and geomechanical consequences of co2 injection into storage reservoir in our analysis in fact this study is a coupled problem due to the diffusive leakage of brine from the aquifer into the overburden during geological storage therefore the two media interact with each other and the pressure does not only vary in the aquifer but also in the overburden the diffusivity equation can be used as the governing equation for the pressure variation in the domain conceptually the diffusivity equation is derived by combination of equations of continuity state and momentum a mass balance over a control volume of the system aquifer or overburden leads to continuity i e conservation of mass equation 1a ρ v 1 r r ρ v r r ρ v z z ϕ ρ t where ρ is the fluid density v vr vz is the darcy velocity vector where vr and vz are the velocity components in the r and z directions respectively ϕ is the porosity of the porous medium and t is the time the relationship between the fluid compressibility cf pressure p and density is applied as the equation of state for a slightly compressible fluid 1b c f 1 ρ ρ p for the equation of momentum darcy s law is employed 1c v k μ p k μ p r e r p z e z where k is the permeability of the porous medium μ is the fluid viscosity and e r and e z are the unit vectors in the r and z directions respectively the effect of the gravitational force can also be considered in darcy model however the results for darcy equations with and without including gravity will be exactly the same since the formulation for the case of the single phase fluid flow is linear therefore the diffusivity equation is expressed in terms of pressure rather than potential throughout this study accordingly the final form of the diffusivity equation in two dimensional cylindrical coordinates for single phase flow of a slightly compressible fluid though a porous medium can be obtained by combination of eqs 1a 1c 2 2 p 1 r r r p r 2 p z 2 μ c t ϕ k p t 1 η p t where ct is the total compressibility and for a single phase flow is defined as the summation of the fluid compressibility and the pore compressibility of the porous medium cp i e ct cf cp and η k μctϕ is the hydraulic diffusivity 2 2 governing equations the governing equations for the pressure variations in the aquifer and overburden can be developed directly from the two dimensional diffusivity equation see eq 2 in this study the subscripts α 1 2 correspond to the aquifer and overburden respectively the system is nondimensionalized by selecting the well radius r w as the length scale μ 1 ϕ 1 c t 1 r w 2 k 1 r w 2 η 1 as the time scale and qμ1 2πk 1 h 1 to scale the pressure differences in the aquifer and overburden accordingly the dimensionless forms of the diffusivity equations in cylindrical coordinates describing pressure variations for two media can be written as 3 2 p α 1 r r r p α r 2 p α z 2 k φ 1 α 2 k φ p α t α 1 2 where r r rw z z rw p α 2πk 1 h 1 p α pi qμ1 k k 1 k 2 μ2 μ1 φ φ1 c t1 φ2 c t2 and t k 1 μ 1 ϕ 1 c t 1 r w 2 t η 1 r w 2 t in which r is the dimensionless radius z is the dimensionless height p is the dimensionless pressure and t is the dimensionless time in fact k φ in eq 3 is the ratio of the hydraulic diffusivity of the aquifer η 1 k 1 μ 1 ct 1 ϕ 1 to the hydraulic diffusivity of the overburden η 2 k 2 μ 2 ct 2 ϕ 2 and can also be denoted by ξ η 1 η 2 in order to solve governing equations in eq 3 the appropriate initial and boundary conditions for the pressures in the aquifer and overburden can be described as follows the initial pressures inside the aquifer and the overburden are equal to pi 4a p α r z 0 0 as the inner conditions at r rw co2 is injected with constant flow rate of q into the aquifer while there is a no flow boundary for the overburden 4b p α 1 z t r α 2 for the outer conditions at r re no flow boundaries are applied for the aquifer and overburden 4c p α r e z t r 0 where re re rw is the dimensionless external radius there is a no flow boundary condition at the bottom of the element of symmetry z 0 4d p 1 r 0 t z 0 the continuities of the pressures and the fluid fluxes at the interface between the aquifer and overburden z h1 result in 4e p 1 r h 1 t p 2 r h 1 t 4f k p 1 r h 1 t z p 2 r h 1 t z where h 1 h 1 rw is the dimensionless thickness of the aquifer the continuity of the fluid fluxes along the aquifer overburden interface is based on darcy s law a no flow boundary condition is used at the top of the overburden z h1 h2 4g p 2 r h 1 h 2 t z 0 where h 2 h 2 rw is the dimensionless thickness of the overburden the detailed derivations of the semi analytical solutions for the pressure distributions in the domain leakage rate from the aquifer into overburden and its asymptotic behaviours well pressures in the aquifer and overburden and the average aquifer and overburden pressures during injection and post injection periods are presented in appendix a 3 results in the following subsections the developed solutions in this study in combination with practical ranges for the model parameters are used to analyze leakage rate at the aquifer overburden interface later new type curves for average pressures in the aquifer and overburden are generated and described finally the results for the post injection are presented 3 1 practical ranges for the model parameters the ranges of permeability and porosity used for the storage aquifer are provided from properties of sandstone and limestone rocks with a permeability in the range of 9 87 10 18 m2 k 1 6 17 10 13 m2 freeze and cherry 1979 domenico and schwartz 1990 and a porosity within 0 04 ϕ 1 0 30 where the lower bound was reported for the acid gas injection site 8 in the alberta basin hassanzadeh et al 2007 and the upper bound was used by freeze and cherry 1979 and domenico and schwartz 1990 as a maximum value for porosity in reservoir rocks the ranges of permeability and porosity applied for the intact overburden come from typical properties of shale rocks including a permeability in the range of 9 87 10 21 m2 k 2 2 07 10 16 m2 and a porosity within 0 ϕ 2 0 10 freeze and cherry 1979 domenico and schwartz 1990 the range of aquifer thickness is selected as 4 m h 1 330 m where the lower bound was reported for the acid gas injection site 7 in the alberta basin hassanzadeh et al 2007 and the upper bound is the thickness of an aquifer located in lincolnshire in the united kingdom jin et al 2012 the range of overburden thickness is chosen as 1 m h 2 194 m where the lower bound was considered by authors of this study and the upper bound is the thickness of an overburden sited in lincolnshire in the united kingdom jin et al 2012 the range of external radius domain is selected as 102 m re 106 m the parameter ranges used are representative of the full range of properties for potential storage aquifer moreover it is assumed that the well radius is rw 8 89 10 2 m based on the radius of injection wells for field applications as a typical value for the external radius of domain it is supposed to be re 105 m where applied by hassanzadeh et al 2009 for mechanistic and sensitivity studies of accelerating co2 dissolution in aquifers therefore the dimensionless external radius is calculated as re 1 12 106 by choosing ϕ 1 0 25 k 1 2 47 10 13 m2 μ 1 5 10 4 pa s and ct 1 9 10 10 pa 1 the hydraulic diffusivity of the aquifer is calculated as η 1 2 19 m2 s which results in the time scale r w 2 η 1 3 60 10 3 s throughout this study the fluid viscosities and the total compressibilities are supposed to be equal for both the aquifer and overburden i e μ 1 μ 2 and ct 1 ct 2 as a result k and φ become the ratios of aquifer to overburden permeabilities and porosities respectively table 1 summarizes the ranges of dimensionless model parameters used in this section 3 2 leakage rate at the aquifer overburden interface the objective here is to study the potential for diffusive leakage of brine from storage aquifers through the intact overburden for different combinations of rock properties that cover the range of expected variability for natural geosequestration targets the roles of the porosity and permeability ratios and the dimensionless thicknesses of the aquifer and overburden on the dimensionless diffusive leakage rate from the aquifer into the overburden at the interface between them are considered using eq a2 3 fig 2 a illustrates the dimensionless leakage rate j versus the dimensionless time t for a variety of aquifer to overburden porosity ratios in the range of 0 40 φ at h 1 2000 h 2 500 and k 104 for any arbitrary value of the porosity ratio within the previously obtained range see table 1 three different regions are identified early time transition and late time regions the dimensionless diffusive leakage rate at early times is proportional to the square root of the dimensionless time j t which confirms the early time asymptotic behaviour presented in eq a3 1a in other words the leakage of brine is dominated by diffusion mechanism in the early time region after a transition region during middle times the dimensionless diffusive leakage rate reaches to a steady state condition at late times j constant as mathematically proved through eq a3 1b the results in fig 2 a show when the aquifer to overburden porosity ratio increases the dimensionless diffusive leakage rate decreases since the early time and late time solutions are both functions of the porosity ratio as given in eqs a3 1a and a3 1b respectively the early time and late time regions differ from each other for various porosity ratios however the early time duration is shortened while the late time duration is prolonged by increasing the porosity ratio the time expressions and constant values for the early time and late time regions can be determined by using eqs a3 1a and a3 1b respectively the dimensionless leakage rate versus the dimensionless time for different aquifer to overburden permeability ratios in the range of 4 76 10 2 k 6 25 107 at h 1 2000 h 2 500 and φ 10 is demonstrated in fig 2 b the identified three regions are observed for any arbitrary value of the permeability ratio within the formerly provided range in table 1 it is revealed that by increasing the permeability ratio the dimensionless diffusive leakage rate decreases in more details the early time duration is prolonged while the late time duration is decreased as the permeability ratio increases the early time regions vary for different permeability ratios because the early time solution eq a3 1a depends on the permeability ratio whereas the late time regions are stabilized at the same value since the late time solution eq a3 1b is independent of the permeability ratio the time expressions for the early time regions can be obtained by applying eq a3 1a the constant value for the late time region is calculated as j 1 1 φλ 1 1 10 2000 500 2 44 10 2 by using eq a3 1b fig 2 c demonstrates the dimensionless leakage rate versus the dimensionless time for several dimensionless thicknesses of the aquifer 44 99 h 1 3712 04 at h 2 500 φ 10 and k 104 this figure clearly recognizes three regions for an arbitrary value of the dimensionless thickness of the aquifer within the previously obtained range see table 1 it can be found that the dimensionless diffusive leakage rate decreases as the dimensionless thickness of the aquifer increases because the early time and late time solutions are both functions of the dimensionless thickness of the aquifer as provided in eqs a3 1a and a3 1b respectively the early time and late time regions are different from each other for various dimensionless thicknesses of the aquifer it is worth noting that the early time and late time durations remain almost unchanged by varying the dimensionless thicknesses of the aquifer however the time expressions and constant values for the early time and late time regions can be given by applying eqs a3 1a and a3 1b respectively the dimensionless leakage rate versus the dimensionless time for various dimensionless thicknesses of the overburden 11 25 h 2 2182 23 at h 1 2000 φ 10 and k 104 is shown in fig 2 d the recognized three regions are seen for any arbitrary value of the dimensionless thickness of the overburden within the formerly provided range in table 1 it is clear from fig 2 d that by increasing the dimensionless thickness of the overburden the dimensionless diffusive leakage rate increases too in addition the early time duration is prolonged while the late time duration is shortened when the dimensionless thickness of the overburden increases the early time regions are the same for different dimensionless thicknesses of the overburden since the early time solution eq a3 1a is independent of the dimensionless thickness of the overburden whereas the late time regions vary because the late time solution eq a3 1b depends on the dimensionless thickness of the overburden the time expression for the early time region is calculated as j 0 1 π 2 h 1 1 1 k φ t 1 π 2 2000 1 1 10 4 10 t 1 78 10 6 t by using eq a3 1a the constant values for the late time regions can be obtained by applying eq a3 1b 3 3 order of significance of leakage factors it becomes reasonable to compare the performance of the different factors including porosity and permeability ratios and thicknesses of aquifer and overburden for geosequestration purposes with the same amount of co2 injection since the time for injecting co2 is representative of the amount of co2 injection by assuming ti 30 years as co2 injection time comparable to life of a typical power plant cihan et al 2011 and using the previously obtained time scale r w 2 η 1 3 60 10 3 s one can focus on the leakage rate that reached at ti 2 63 1011 by considering this amount of co2 injection the dimensionless leakage rate j versus the aquifer to overburden porosity and permeability ratios φ and k respectively for different scenarios is shown is fig 3 to further investigate the leakage rate after a certain elapsed time since starting co2 injection the asymptotic behaviours of the dimensionless diffusive leakage rate for very small and very large values of the porosity or permeability ratios are also addressed by using combination of eqs a1 13c a1 13e and a2 3 a2 4c for the dimensionless diffusive leakage rate when φ or k approaches 0 or it is possible to arrive at 5a lim j t φ 0 or k ℓ s 1 l i m j s φ 0 or k ℓ s 1 1 h 1 1 k φ coth h 1 s 1 s 3 2 5b lim j t φ or k 0 ℓ s 1 l i m j s φ or k 0 ℓ s 1 1 h 1 1 φ h 2 s coth h 1 s 1 s 3 2 the dimensionless leakage rate versus the aquifer to overburden porosity ratio for different permeability ratios 4 76 10 2 k 6 25 107 at h 1 2000 h 2 500 and ti 2 63 1011 is demonstrated in fig 3 a it is revealed that for each constant value of permeability ratio j 1 φ and j 1 φ at small and large porosity ratios respectively even though for k 106 the j 1 φ relationship breaks down when φ 0 these findings can also be inferred mathematically using eqs 5a and 5b at small values of porosity ratio the diffusive leakage rate decreases as permeability ratio increases although it does not happen for k 105 since the dimensionless diffusive leakage rate is independent of permeability ratio when φ eq 5b j remains unchanged by varying k fig 3 b illustrates the dimensionless leakage rate j versus the aquifer to overburden permeability ratio k for a variety of porosity ratios in the range of 0 40 φ at h 1 2000 h 2 500 and ti 2 63 1011 it is found that for each constant value of porosity ratio j constant and j 1 k at small and large permeability ratios respectively which can also be inferred mathematically using eqs 5a and 5b by increasing porosity ratio the diffusive leakage rate decreases for whole range of permeability ratio this effect on the brine leakage is in agreement with the numerical simulation findings presented by hou et al 2012 for co2 leakage rate through overburden the dimensionless leakage rate versus the aquifer to overburden porosity ratio for several dimensionless thicknesses of the aquifer 44 99 h 1 3712 04 at h 2 500 k 104 and ti 2 63 1011 is demonstrated in fig 3 c as it is expected the diffusive leakage rate decreases by increasing the thicknesses of the aquifer in other words j 1 when h 1 0 and j 0 as h 1 these trends can also be proved through combination of eqs a1 13c a1 13e and a2 3 a2 4c for the dimensionless diffusive leakage rate when h 1 approaches 0 and respectively it is also revealed that for each dimensionless thickness of the aquifer j 1 φ at large porosity ratios by comparison between fig 3 a and c it is possible to mention that the dimensionless thickness of the aquifer plays a relatively more significant role on the diffusive leakage rate than the permeability ratio fig 3 d illustrates the dimensionless leakage rate j versus the aquifer to overburden permeability ratio k for different dimensionless thicknesses of the aquifer in the range of 44 99 h 1 3712 04 at h 2 500 φ 10 and ti 2 63 1011 it is clear that for each dimensionless thickness of the aquifer j constant and j 1 k at small and large permeability ratios respectively the dimensionless leakage rate versus the aquifer to overburden porosity ratio for a variety of dimensionless thicknesses of the overburden 11 25 h 2 2182 23 at h 1 2000 k 104 and ti 2 63 1011 is demonstrated in fig 3 e it is found that for each dimensionless thickness of the overburden j 1 φ at large porosity ratios on the other hand the diffusive leakage rate increases as the thicknesses of the overburden increases in other words j 0 when h 2 0 and j 1 as h 2 which can also be concluded using combination of eqs a1 13c a1 13e and a2 3 a2 4c for the dimensionless diffusive leakage rate when h 2 approaches 0 and respectively a comparison between fig 3 a and e obviously shows that the effect of the dimensionless thickness of the overburden is more pronounced than the effect of the permeability ratio on the diffusive leakage rate this effect on the brine leakage is in agreement with the numerical simulation findings presented by hou et al 2012 for co2 leakage rate through overburden also one can mention that the dimensionless thickness of the overburden plays a more significant role on the diffusive leakage rate than the dimensionless thickness of the aquifer by comparison between fig 3 c and e fig 3 f illustrates the dimensionless leakage rate j versus the aquifer to overburden permeability ratio k for several dimensionless thicknesses of the overburden in the range of 11 25 h 2 2182 23 at h 1 2000 k 104 and ti 2 63 1011 it is revealed that for each dimensionless thickness of the overburden j constant and j 1 k at small and large permeability ratios respectively comparing fig 3 b and f identifies that the dimensionless thickness of the overburden plays a more important role on the diffusive leakage rate than the porosity ratio based on analysis of fig 3 the factors influencing leakage of brine during injection can be ranked in the following decreasing order of significance 1 dimensionless thickness of overburden 2 dimensionless thickness of aquifer 3 aquifer to overburden permeability ratio and 4 aquifer to overburden porosity ratio the presented ranking can also be supported by fig 4 where fig 4 a demonstrates the dimensionless leakage rate j versus the dimensionless time t for four different cases including i h 1 1000 h 2 500 φ 500 k 500 ii h 1 500 h 2 1000 φ 500 k 500 iii h 1 500 h 2 500 φ 1000 k 500 and iv h 1 500 h 2 500 φ 500 k 1000 and fig 4 b shows absolute values of relative change in j for cases i iv respect to base case h 1 500 h 2 500 φ 500 k 500 defined as relative change in j j i iv j base 100 j base versus t the relative change in j for case i is constant and equal to 50 while the relative changes in j for cases ii iv vary with ranges of 0 100 30 50 and 0 30 respectively therefore the previously resulted ranking of the leakage parameters from fig 3 is confirmed since one can generally conclude from fig 4 that the relative change in j for case ii case i case iv case iii 3 4 average aquifer and overburden pressures knowledge of the average pressures in the aquifer and overburden and their changes as functions of time are essential to determine how much co2 are stored in the aquifer and leaked from the aquifer into the overburden respectively fig 5 a illustrates the dimensionless average pressure p α versus the dimensionless time t at h 1 2000 h 2 500 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and aquifer to overburden porosity ratio φ 2 and 1000 including α 1 and φ 2 black solid curve α 1 and φ 1000 blue solid curve α 2 and φ 2 black dashed curve and α 2 and φ 1000 blue dashed curve using eq a5 2 for a special case where pressure in an aquifer with no flow condition along the top boundary is addressed one can reach to the following dimensionless average pressure in the aquifer p 1 by solving governing equation in eq 3 accompanied with initial and boundary conditions in eqs 4a 4d for α 1 and p 1 r h 1 t z 0 using successively implementation of the laplace and finite hankel transforms 6 p 1 t 2 r e 2 1 t the dimensionless pressure in the aquifer with the no flow condition at the top boundary for re 1 12 106 is shown by red solid curve in fig 5 a using eq 6 the results reveal that the average pressures in the aquifer for different porosity ratios and no flow condition at top boundary are almost the same and they are proportional to the dimensionless time p 1 t the results also confirm the early and late time asymptotic behaviours of the dimensionless average pressures presented in eqs a6 1a a6 1b and eq 6 therefore the average pressure in the aquifer remains nearly invariant to the interface condition and the porosity ratio the result for the average pressure in the overburden p 2 is directly proportional to t 3 2 at early times while it varies with t at late times in other words the average pressure in the overburden increases with lower rate at late times p 2 t as compared to the one at early times p 2 t 3 2 during diffusive leakage it is worth mentioning that the average pressure in the overburden at early times increases by increasing the porosity ratio whereas it remains invariant at late times the obtained results also show that all the average pressure in the aquifer and overburden are almost identical at late times regardless of the interface condition and the value of the porosity ratio these outcomes can be mathematically inferred using eqs a6 1a a6 1b and 6 fig 5 b demonstrates the dimensionless average pressure p α versus the dimensionless time t at h 1 2000 h 2 500 φ 10 and re 1 12 106 for different cases according to the medium aquifer α 1 and overburden α 2 and aquifer to overburden permeability ratio k 102 and 108 including α 1 and k 102 black solid curve α 1 and k 108 blue solid curve α 2 and k 102 black dashed curve and α 2 and k 108 blue dashed curve by applying eq a5 2 the dimensionless average pressure in the aquifer with the no flow condition at the top boundary for re 1 12 106 is shown by red solid curve in fig 5 b using eq 6 the similar behaviours as fig 5 a which addressed the effect of the porosity ratio can be observed in fig 5 b for two different permeability ratios and the only difference is that the average pressure in the overburden at early times decreases by increasing the permeability ratio fig 5 c shows the dimensionless average pressure p α versus the dimensionless time t at h 2 500 φ 10 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and dimensionless thickness of the aquifer h 1 500 and 3500 including α 1 and h 1 500 black solid curve α 1 and h 1 3500 blue solid curve α 2 and h 1 500 black dashed curve and α 2 and h 1 3500 blue dashed curve using eq a5 2 the dimensionless average pressure in the aquifer with the no flow condition at the top boundary for re 1 12 106 is shown by red solid curve in fig 5 c using eq 6 the similar trends as fig 5 a which considered the role of the porosity ratio can also be seen in fig 5 c for two different dimensionless thicknesses of the aquifer once can observe that the average pressure in the overburden at early times remains unchanged by increasing the dimensionless thickness of the aquifer fig 5 d illustrates the dimensionless average pressure p α versus the dimensionless time t at h 1 2000 φ 10 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and dimensionless thickness of the overburden h 2 100 and 2000 including α 1 and h 2 100 black solid curve α 1 and h 2 2000 blue solid curve α 2 and h 2 100 black dashed curve and α 2 and h 2 2000 blue dashed curve by applying eq a5 2 the dimensionless pressure in the aquifer with the no flow condition at the top boundary for re 1 12 106 is shown by red solid curve in fig 5 d using eq 6 the similar behaviours as fig 5 b which addressed the influence of the permeability ratio can be observed in fig 5 d for two different dimensionless thicknesses of the overburden fig 5 e demonstrates the dimensionless average pressure p α versus the dimensionless time t at h 1 2000 h 2 500 φ 10 and k 104 for different cases according to the medium aquifer α 1 and overburden α 2 and dimensionless external radius re 103 and 107 including α 1 and re 103 black solid curve α 1 and re 107 blue solid curve α 2 and re 103 black dashed curve and α 2 and re 107 blue dashed curve using eq a5 2 the dimensionless pressures in the aquifer with the no flow condition at the top boundary for re 103 and 107 are shown by red and green solid curves respectively in fig 5 e using eq 6 it is found from fig 5 e that the dimensionless average pressures in the aquifer and overburden decrease by increasing the dimensionless external radius regardless of the interface condition 3 5 post injection thus far the results are presented during co2 injection now the leakage rate from the aquifer into overburden and average aquifer and overburden pressures during post injection period are studied it is assumed that after ti 30 years or ti 2 63 1011 has elapsed since the starting of co2 injection into the storage aquifer overlaid by a natural intact overburden the injection is shut down for δt 70 years cihan et al 2011 by using the previously obtained time scale r w 2 η 1 3 60 10 3 s the dimensionless time period for shutting down the co2 injection becomes δt 6 13 1011 therefore one can analyze the leakage rate and average aquifer and overburden pressures for different scenarios during co2 injection time from 0 to ti 2 63 1011 and for the period of post injection between ti 2 63 1011 and ti δt 8 75 1011 fig 6 a and b illustrate the dimensionless leakage rates versus the dimensionless time t during co2 injection j and post injection jpost periods at h 1 2000 and h 2 500 for different cases based on the aquifer to overburden porosity and permeability ratios including φ 2 and k 104 black solid curve φ 1000 and k 104 blue solid curve φ 10 and k 102 black dashed curve and φ 10 and k 108 blue dashed curve using eqs a2 3 and a7 2 the obtained results for the dimensionless leakage rate versus the dimensionless time during co2 injection in fig 6 a were discussed in section 3 2 it is revealed that the dimensionless leakage rate within post injection period is almost negligible for small φ 2 and large φ 1000 values of the porosity ratios and small permeability ratio k 102 however the dimensionless leakage rate is not negligible and decreases during post injection for large permeability ratio k 108 the dimensionless leakage rates versus the dimensionless time t during co2 injection j and post injection jpost periods at φ 10 and k 104 for different cases based on the dimensionless thicknesses of aquifer and overburden including h 1 500 and h 2 500 black solid curve h 1 3500 and h 2 500 blue solid curve h 1 2000 and h 2 100 black dashed curve and h 1 2000 and h 2 2000 blue dashed curve using eqs a2 3 and a7 2 are demonstrated in fig 6 c and d the presented results for the dimensionless leakage rate versus the dimensionless time during co2 injection in fig 6 c were described in section 3 2 it is found that the dimensionless leakage rate within post injection period is almost insignificant for small h 1 500 and large h 1 3500 values of the dimensionless thicknesses of aquifer and small dimensionless thickness of overburden h 2 100 however the dimensionless leakage rate is significant and decreases sharply during post injection for large dimensionless thickness of overburden h 2 2000 based on analysis of fig 6 the factors affecting leakage of brine within post injection period can be ranked in the following decreasing order of significance 1 dimensionless thickness of overburden 2 aquifer to overburden permeability ratio 3 aquifer to overburden porosity ratio and 4 dimensionless thickness of aquifer it is worth mentioning that dimensionless thickness of aquifer has minimal effect on diffusive leakage of brine during post injection period while it is ranked as the second factor impacting leakage of brine during injection the presented ranking can also be supported by fig 7 where fig 7 a and b demonstrate the dimensionless leakage rates versus the dimensionless time t during co2 injection j and post injection jpost periods for four different cases including i h 1 1000 h 2 500 φ 500 k 500 ii h 1 500 h 2 1000 φ 500 k 500 iii h 1 500 h 2 500 φ 1000 k 500 and iv h 1 500 h 2 500 φ 500 k 1000 and fig 7 c and d show absolute values of relative change in j and relative change in jpost for cases i iv as compared to the base case h 1 500 h 2 500 φ 500 k 500 defined as relative change in j j i iv j base 100 j base and relative change in jpost jpost i iv jpost base 100 jpost base versus t the results for j and absolute value of relative change in j versus t during co2 injection in fig 7 a and c were discussed in section 3 3 during post injection period the relative change in jpost for case i is constant and equal to 50 while the relative changes in jpost for cases ii iv vary with ranges of 6 700 22 75 and 1 100 respectively therefore the previously resulted ranking of the parameters affecting leakage of brine during post injection from fig 6 is confirmed since one can generally conclude from fig 7 that the relative change in jpost for case ii case iv case iii case i fig 8 a and b illustrate the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post injection p α p o s t periods at h 1 2000 h 2 500 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and aquifer to overburden porosity ratio φ 2 and 1000 including α 1 and φ 2 black solid curve α 1 and φ 1000 blue solid curve α 2 and φ 2 black dashed curve and α 2 and φ 1000 blue dashed curve using eqs a5 2 and a7 4 the obtained results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 a were discussed in section 3 4 it is revealed that the dimensionless average pressures in the aquifer and overburden remain constant within post injection period and are equal for small and large porosity ratios which implies p 1 p o s t p 2 p o s t 0 369 for small porosity ratio φ 2 and p 1 p o s t p 2 p o s t 0 415 for large porosity ratio φ 1000 however p α p o s t increases by increasing aquifer to overburden porosity ratio the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post inbjection p α p o s t periods at h 1 2000 h 2 500 φ 10 and re 1 12 106 for different cases according to the medium aquifer α 1 and overburden α 2 and aquifer to overburden permeability ratio k 102 and 108 including α 1 and k 102 black solid curve α 1 and k 108 blue solid curve α 2 and k 102 black dashed curve and α 2 and k 108 blue dashed curve by applying eqs a5 2 and a7 4 are demonstrated in fig 8 c and d the presented results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 c were described in section 3 4 it is found that the dimensionless average pressures in the aquifer and overburden remain unchanged within post injection period and are equal for small permeability ratio which implies p 1 p o s t p 2 p o s t 0 405 for k 102 the dimensionless average pressure in the aquifer is significantly larger than the one in the overburden for large permeability ratio k 108 since the pressure still diffuses from the aquifer into the overburden during post injection although the diffusive leakage of brine decreases the dimensionless average pressure in the overburden increases for large permeability ratio k 108 fig 8 e and f show the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post injection p α p o s t periods at h 2 500 φ 10 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and dimensionless thickness of the aquifer h 1 500 and 3500 including α 1 and h 1 500 black solid curve α 1 and h 1 3500 blue solid curve α 2 and h 1 500 black dashed curve and α 2 and h 1 3500 blue dashed curve using eqs a5 2 and a7 4 the results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 e were explained in section 3 4 it is clear from fig 8 f that the dimensionless average pressures in the aquifer and overburden remain fixed within post injection period and are equal for small and large dimensionless thicknesses of aquifer which implies p 1 p o s t p 2 p o s t 0 378 for small dimensionless thickness of aquifer h 1 500 and p 1 p o s t p 2 p o s t 0 410 for large dimensionless thickness of aquifer h 1 3500 however p α p o s t increases by increasing dimensionless thickness of aquifer the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post injection p α p o s t periods at h 1 2000 φ 10 k 104 and re 1 12 106 for different cases based on the medium aquifer α 1 and overburden α 2 and dimensionless thickness of the overburden h 2 100 and 2000 including α 1 and h 2 100 black solid curve α 1 and h 2 2000 blue solid curve α 2 and h 2 100 black dashed curve and α 2 and h 2 2000 blue dashed curve by applying eqs a5 2 and a7 4 are shown in fig 8 g and h the obtained results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 g were addressed in section 3 4 it can be realized that the dimensionless average pressures in the aquifer and overburden remain constant within post injection period and are equal for small and large dimensionless thicknesses of overburden which implies p 1 p o s t p 2 p o s t 0 413 for small dimensionless thickness of overburden h 2 100 and p 1 p o s t p 2 p o s t 0 378 for large dimensionless thickness of overburden h 2 2000 however p α p o s t decreases by increasing dimensionless thickness of overburden fig 8 i and j illustrate the dimensionless average pressures in the aquifer and overburden versus the dimensionless time t during co2 injection p α and post injection p α p o s t periods at h 1 2000 h 2 500 φ 10 and k 104 for different cases according to the medium aquifer α 1 and overburden α 2 and dimensionless external radius re 103 and 107 including α 1 and re 103 black solid curve α 1 and re 107 blue solid curve α 2 and re 103 black dashed curve and α 2 and re 107 blue dashed curve using eqs a5 2 and a7 4 the presented results for the dimensionless average pressures in the aquifer and overburden versus the dimensionless time during co2 injection in fig 8 i were discussed in section 3 4 it is revealed that the dimensionless average pressures in the aquifer and overburden remain unchanged within post injection period and are equal for small and large dimensionless external radius which implies p 1 p o s t p 2 p o s t 5 13 10 5 for small dimensionless external radius re 103 and p 1 p o s t p 2 p o s t 5 13 10 3 for large dimensionless external radius re 107 note that re 103 is a very small storage medium and thus a high pressure is observed this small dimensionless external radius is used to conduct sensitivity analysis and it is not common in real application however p α p o s t decreases significantly by increasing dimensionless external radius 4 field studies case studies for two potential sites in united kingdom including lincolnshire and firth of forth are conducted to evaluate the presented model in this work the physical rock and fluid properties of the aquifer and overburden in these two sites along with the radius of the co2 well injection which have been used previously by jin et al 2012 for static and dynamic estimations of co2 storage are summarized in table 2 using the defined dimensionless parameters in this study accompanied with table 2 result in the values for the dimensionless model parameters for lincolnshire and firth of forth see table 3 by using the rock and fluid properties of the aquifers in lincolnshire and firth of forth sites see table 2 the hydraulic diffusivities of the aquifers in these sites are calculated as η 1 l 2 74 m2 s and η 1 f 0 55 m2 s respectively which result in the time scales r w 2 η 1 l 8 21 10 3 s and r w 2 η 1 f 4 07 10 2 s respectively therefore by assuming ti 30 years as co2 injection time δt 70 years for post injection period cihan et al 2011 and using these time scales one can focus on the leakage rate from the aquifers into the overburdens and average pressures in the aquifers and overburdens during co2 injection in the aquifer of lincolnshire site from 0 to til 1 15 1011 and in the aquifer of firth of forth site between 0 and tif 2 32 1010 and throughout post injection from til 1 15 1011 to til δtl 3 84 1011 for lincolnshire site and between tif 2 32 1010 and tif δtf 7 74 1010 for firth of forth site fig 9 a illustrates the dimensionless leakage rates versus the dimensionless time tl during co2 injection jl and post injection jpost l periods for lincolnshire site blue solid curve and blue dashed lines using the leakage parameters in table 3 for the period of co2 injection in the aquifer of lincolnshire site the dimensionless leakage rate increases by the dimensionless time jl t at early times and then reaches to 0 22 at til 1 15 1011 within transition region it seems that 30 years of co2 injection is not enough for the leakage rate to arrive at a steady state condition subsequently the dimensionless leakage rate decreases throughout post injection period and becomes zero at til δtl 2 67 1011 or til δt l 70 years in other words the diffusive leakage ceases after δt l 40 years from starting post injection period the average amount of the brine leaked from the aquifer per standard cubic meter sm3 of the injected co2 through diffusive leakage was found to be 6 28 10 4 m3 of brine or 0 330 kg of brine kg of co2 over 70 years for lincolnshire the dimensionless leakage rates versus the dimensionless time tf during co2 injection jf and post injection jpost f periods for firth of forth site red solid curve and red dashed lines using the leakage parameters in table 3 are shown in fig 9 b within the period of co2 injection in the aquifer of firth of forth site the dimensionless leakage rate increases by the dimensionless time jf t at early times and after a transition region reaches to 0 19 at tif 2 32 1010 which recognizes a steady state condition for late times thereafter the dimensionless leakage rate decreases throughout post injection and becomes zero tif δtf 3 23 1010 or tif δt f 42 years in other words the diffusive leakage diminishes δt f 12 years after the start of the post injection period the average amount of the brine leaked from the aquifer per standard cubic meter sm3 of the injected co2 through diffusive leakage was found to be 4 59 10 4 m3 of brine or 0 242 kg of brine kg of co2 over 42 years for firth of forth fig 10 a and b demonstrate the dimensionless average pressures in the aquifer α 1 black solid curve and overburden α 2 black dashed curve of lincolnshire site versus the dimensionless time tl during co2 injection p α l and post injection p α p o s t l periods using the leakage parameters in table 3 for the period of co2 injection in the aquifer of lincolnshire site the average pressure in the overburden increases with larger slope p 2 l t 3 2 compared to the one in the aquifer p 1 l t at early times however p 2 l is lower than p 1 l and reach to 6 64 and 5 14 respectively at til 1 15 1011 it looks that 30 years of co2 injection is not sufficient for the average pressure in the overburden to show the late time behaviour where p 2 l t throughout post injection period the average pressures in the aquifer and overburden vary slightly within 6 30 p 1 p o s t l 6 64 and 5 14 p 2 p o s t l 6 30 respectively however p 1 p o s t l is larger than p 2 p o s t l and both reach to 6 30 at til δtl 3 84 1011 the dimensionless average pressures in the aquifer α 1 black solid curve and overburden α 2 black dashed curve of firth of forth site versus the dimensionless time tf during co2 injection p α f and post injection p α p o s t f periods using the leakage parameters in table 3 are shown in fig 10 c and d for the period of co2 injection in the aquifer of firth of forth site the average pressures in the aquifer p 1 f and overburden p 2 f are proportional to t and t 3 2 respectively at early times the average pressure in the overburden increases with lower slope at late times p 2 f t compared to the one at early times p 2 f t 3 2 however p 1 f is larger than p 2 f at early times while they are the same at late times and both reach to 0 95 at tif 2 32 1010 the average pressures in the aquifer and overburden vary slightly within 0 93 p 1 p o s t f 0 95 and 0 89 p 2 p o s t f 0 93 respectively throughout post injection period however p 2 p o s t f is lower than p 1 s h u t f and both quickly reach to 0 93 at tif δtf 7 74 1010 5 conclusions in this study the diffusive leakage of brine from a storage aquifer into overlying and underlying natural intact layers is modeled the presented model considers a two dimensional domain comprised of an aquifer and an overburden where the interaction between the two media is handled by imposing the continuities of pressures and fluid fluxes at the aquifer overburden interface the laplace transform technique in combination with the finite hankel transform method is adopted to solve this coupled problem and obtain the solutions for the pressure distributions in the aquifer and overburden the diffusive leakage rate from the aquifer into overburden and its asymptotic behaviour well pressures in the aquifer and overburden and average aquifer and overburden pressures and its early and late time behaviours during co2 injection the principle of superposition can be applied to the developed solutions to analyze diffusive leakage of brine from the aquifer into overburden and generate type curves for average pressures in the aquifer and overburden during post injection as well the results reveal that the diffusive leakage rate at early times is proportional to the square root of the time j t while it remains constant at late times it is also shown that the average pressure in the aquifer varies linearly with the time for short and long times p 1 t in addition this study gives this conclusion that the average pressure in the overburden increases with lower slope at late times p 2 t compared to the one at early times p 2 t 3 2 during diffusive leakage of brine from the storage aquifer into the overlying layer based on analysis of the results it is found that factors influencing leakage rate through overburden during co2 injection are in decreasing order of significance thickness of overburden thickness of aquifer aquifer to overburden permeability ratio and aquifer to overburden porosity ratio however thickness of aquifer has minimal effect on diffusive leakage of brine within post injection period finally the presented model through conducting case studies for two potential sites in united kingdom one in lincolnshire and the other one in the firth of forth is evaluated and tested the field studies show that the diffusive leakage from the aquifer into the overburden diminishes 40 years after the injection has ceased for lincolnshire while it stops after 12 years for firth of forth the average amount of the brine leaked from the aquifers per standard cubic meter sm3 of the injected co2 through diffusive leakage was found to be 6 28 10 4 m3 of brine or 0 330 kg of brine kg of co2 over 70 years for lincolnshire and 4 59 10 4 m3 of brine or 0 242 kg of brine kg of co2 over 42 years for firth of forth acknowledgements the first author is gratefully appreciative of the financial support from the department of petroleum engineering in the college of engineering and applied science at the university of wyoming financial support of the natural sciences and engineering research council of canada nserc is also gratefully acknowledged appendix a solutions of the governing equations a 1 semi analytical solutions for pressure distributions in the domain the governing equations in eq 3 subject to the initial and boundary conditions in eqs 4a 4g resemble a coupled problem due to the continuities of the pressures and the fluid fluxes at the interface between the aquifer and overburden the solutions of the two dimensional diffusivity equations in cylindrical coordinates can be obtained by using successive implementation of the laplace and finite hankel transforms combination of these two transform techniques reduces the diffusivity partial differential equations pdes for the aquifer and overburden to second order linear nonhomogeneous ordinary differential equations odes with constant coefficients as a result the odes can be coupled and solved by applying the continuity conditions at the aquifer overburden interface and the no flow boundaries at the bottom of the aquifer and the top of the overburden first the laplace transforms with respect to t for the dimensionless pressures in the aquifer and overburden are defined as a1 1 p α r z s ℓ t p α r z t 0 p α r z t e s t d t where p α is the dimensionless pressures in the aquifer and overburden in the laplace domain s is the complex argument of the laplace transform and ℓt is the sign for the laplace transform with respect to t by taking the laplace transform with respect to t from the governing equations in eq 3 and the boundary conditions in eqs 4b 4g and using the initial conditions in eq 4a one can get a1 2 2 p α k φ 1 α 2 k φ s p α a1 3a p α 1 z s r α 2 s a1 3b p α r e z s r 0 a1 3c p 1 r 0 s z 0 a1 3d p 1 r h 1 s p 2 r h 1 s a1 3e k p 1 r h 1 s z p 2 r h 1 s z a1 3f p 2 r h 1 h 2 s z 0 now an appropriate finite hankel transform is derived for the problem under study the finite hankel transform method gives a systematic efficient and straightforward approach for deriving semi analytical and analytical solutions for fluid flow and transport problems with a radial geometry chen et al 2011 the finite hankel transform expresses any given function u r as the weighted sum of a finite number of the linear combination of bessel functions of the first and second kinds of order ν jν λr and yν λr the bessel functions in the sum are all of the same order ν but differ in a scaling factor λ along the r axis to develop the finite hankel transform of p α r z s the eigenvalues and the corresponding eigenfunctions should be determined from the ordinary differential equation ode d2u dr2 1 r du dr βu using the sturm liouville theory subject to the boundary conditions du 1 dr du re dr 0 as the first step β 0 is considered to see if zero is an eigenvalue therefore one can arrive at 1 r d dr rdu dr 0 which has the general solution u c1 c2 ln r by using the homogeneous boundary conditions it is concluded that c2 0 but c1 can be any constant value without loss of generality one can define c1 1 thus β 0 is an eigenvalue of the ode with the corresponding eigenfunction u0 1 for the next step β λ2 is taken into account thus it is possible to reach to r2d2u dr2 rdu dr λ2r2u 0 which is a homogeneous bessel differential equation that has the general solution u c3j0 λr c4y0 λr by applying the boundary conditions at r 1 and re one can obtain c3j1 λ c4y1 λ 0 and c3j1 λre c4y1 λre 0 respectively solving the first expression for c3 and replacing it in the second expression result in c4 j1 λ y1 λre y1 λ j1 λre j1 λ 0 to avoid a trivial solution c4 0 as a result the eigenvalues λn 0 are determined as the countably infinitely many positive roots of the following equation a1 4 j 1 λ n y 1 λ n r e y 1 λ n j 1 λ n r e 0 also the corresponding eigenfunctions un are obtained as a1 5 u n r y 1 λ n j 0 λ n r j 1 λ n y 0 λ n r consequently the set of u n n 0 form a complete orthogonal family of eigenfunctions on 1 r re with corresponding eigenvalues λ n n 0 accordingly the finite hankel transform with respect to r for the dimensionless pressure in the aquifer and overburden in the laplace domain p α r z s are defined as a1 6 p α n z s ℏ r p α r z s r 1 r r e p α r z s u n r r d r where p α is the finite hankel transform of p α n is the variable of the finite hankel transform and ħr is the sign for the finite hankel transform with respect to r applying the finite hankel transform with respect to r to eq a1 2 which is defined in the laplace domain results in a1 7 ℏ r 1 r r r p α r d 2 p α 0 z s d z 2 k φ 1 α 2 k φ s p α the first term on the left hand side of eq a1 7 is derived for the cases of n 0 with the corresponding eigenvalue λ0 0 and eigenfunction u0 1 and n 1 with the corresponding eigenvalues λn 0 and eigenfunctions un by applying the integration by parts twice the inner r 1 and outer r re boundary conditions of the aquifer and overburden in the laplace domain i e eqs a1 3a and a1 3b the boundary conditions du0 1 dr du0 re dr 0 and dun 1 dr dun re dr 0 and the expressions d d r r d u n d r λ n 2 r u n un 1 2 πλn and un re 2 πλn 1 re j1 λn j1 λnre ziener et al 2015 respectively as follows a1 8 r 1 r r e 1 r r r p α r u 0 r d r 2 α s a1 9 r 1 r r e 1 r r r p α r u n r d r 1 s 2 π λ n 2 α λ n 2 p α n 1 combination of eqs a1 7 a1 9 leads to the governing equations which have been implemented successively by the laplace and finite hankel transforms for the cases of n 0 and n 1 respectively as below a1 10 d 2 p α 0 z s d z 2 k φ 1 α 2 k φ s p α 0 z s α 2 s a1 11 d 2 p α n z s d z 2 k φ 1 α 2 k φ s λ n 2 p α n z s 1 s 2 π λ n α 2 n 1 eqs a1 10 and a1 11 are second order linear nonhomogeneous ordinary differential equations odes with constant coefficients in order to solve these equations the finite hankel transform with respect to r in applied for the boundary conditions at the bottom of the element of symmetry z 0 the aquifer overburden interface z h 1 and the top of the overburden z h 1 h 2 in eqs a1 3c a1 3f which are defined in the laplace domain respectively as follows a1 12a d p 1 n 0 s d z 0 a1 12b p 1 n h 1 s p 2 n h 1 s a1 12c k d p 1 n h 1 s d z d p 2 n h 1 s d z a1 12d d p 2 n h 1 h 2 s d z 0 the ode in eq a1 10 subject to the boundary conditions in eqs a1 12a a1 12d gives the dimensionless aquifer and overburden pressures in the laplace and finite hankel domains for the case of n 0 a1 13a p α 0 z s 1 s 2 2 α a 0 sinh b 0 cosh c 0 d 0 where a1 13b a 0 k k φ α k 2 k φ a1 13c b 0 h 1 s h 2 k φ s α h 1 s 2 h 2 k φ s a1 13d c 0 k φ s z h 1 h 2 s z α k φ s z h 1 h 2 2 s z a1 13e d 0 k sinh h 1 s cosh h 2 k φ s k φ cosh h 1 s sinh h 2 k φ s also the ode in eq a1 11 accompanied with the boundary conditions in eqs a1 12a a1 12d leads to the dimensionless aquifer and overburden pressures in the laplace and finite hankel domains for the case of n 1 a1 14a p α n z s 1 s 2 π λ n 1 s λ n 2 2 α a n sinh b n cosh c n d n n 1 where a1 14b a n k s λ n 2 k φ s λ n 2 α k s λ n 2 2 k φ s λ n 2 a1 14c b n h 1 s λ n 2 h 2 k φ s λ n 2 α h 1 s λ n 2 2 h 2 k φ s λ n 2 a1 14d c n k φ s λ n 2 z h 1 h 2 s λ n 2 z α k φ s λ n 2 z h 1 h 2 2 s λ n 2 z a1 14e d n k s λ n 2 sinh h 1 s λ n 2 cosh h 2 k φ s λ n 2 k φ s λ n 2 cosh h 1 s λ n 2 sinh h 2 k φ s λ n 2 from eqs a1 13a and a1 14a the applications of the inversion theorem for the finite hankel transform with respect to n yield a1 15 p α r z s ℏ n 1 p α n z s p α 0 z s r 1 r r e u 0 2 r r d r u 0 n 1 p α n z s r 1 r r e u n 2 r r d r u n r where ℏ n 1 is the sign for the inverse finite hankel transform with respect to n eq a1 15 along with u0 1 eq a1 5 r 1 r r e u 0 2 r d r r e 2 1 2 and r 1 r r e u n 2 r r d r 2 π 2 λ n 2 j 1 2 λ n j 1 2 λ n r e 1 ziener et al 2015 results in a1 16 p α r z s 2 r e 2 1 p α 0 z s π 2 2 n 1 λ n 2 j 1 2 λ n r e p α n z s y 1 λ n j 0 λ n r j 1 λ n y 0 λ n r j 1 2 λ n j 1 2 λ n r e combination of eqs a1 13a a1 14e and a1 16 gives the dimensionless pressures in the aquifer and overburden in the laplace domain therefore it is possible to obtain the semi analytical solutions for the dimensionless aquifer and overburden pressures in the real domain by applying the stehfest inversion method hassanzadeh and pooladi darvish 2007 dejam et al 2011a mashayekhizadeh et al 2011 dejam et al 2013 for eq a1 16 p α r z t ℓ s 1 p α r z s a 2 diffusive leakage rate from the aquifer into overburden in order to gain insight into the leakage of brine from the aquifer into the overburden during geological storage the leakage rate at the aquifer overburden interface is now investigated the dimensionless diffusive leakage rate from the aquifer into the overburden j j q at the interface between them z h 1 can be defined as a2 1 j t 1 h 1 1 k 1 α 2 1 k r 1 r r e p α r z h 1 t z r d r where the injection rate of co2 q and the diffusive leakage rate of brine j are at aquifer conditions aquifer temperature and pressure therefore the dimensionless diffusive leakage rate of brine j is presented in terms of volume of brine divided by volume of injected co2 both at aquifer conditions if the dimensionless diffusive leakage rate of brine j is multiplied by the co2 formation volume factor b c o 2 one can present the dimensionless diffusive leakage rate of brine in terms of volume of brine divided by volume of injected co2 both at standard conditions it is noted that the brine formation volume factor bbrine is taken as unity and the standard conditions correspond to pressure and temperature of 101 325 kpa and 288 71 k respectively by applying the laplace transform with respect to t for eq a2 1 it is possible to obtain the dimensionless diffusive leakage rate at the aquifer overburden interface in the laplace domain j a2 2 j s 1 h 1 1 k 1 α 2 1 k r 1 r r e p α r z h 1 s z r d r eq a2 2 accompanied with eq a1 16 r 1 r r e r d r r e 2 1 2 and r 1 r r e y 1 λ n j 0 λ n r j 1 λ n y 0 λ n r r d r 0 ziener et al 2015 leads to a2 3 j s 1 h 1 1 k 1 α 2 1 k p α 0 z h 1 s z by taking the first derivative with respect to z from eq a1 13a and assigning z h 1 one can derive the term p α 0 z h 1 s z in eq a2 3 as a2 4a p α 0 z h 1 s z 1 s 3 2 e 0 sinh b 0 sinh f 0 d 0 where a2 4b e 0 k φ k 1 α k φ 2 k a2 4c f 0 h 1 s h 2 k φ s α 2 h 1 s h 2 k φ s in fact combination of eqs a1 13c a1 13e and a2 3 a2 4c yields the dimensionless diffusive leakage rate in the laplace domain thus the semi analytical solution for the dimensionless leakage rate in the real domain can be obtained by implementing the fourier inversion technique hassanzadeh and pooladi darvish 2007 dejam et al 2011a b 2014 2016 2017 dejam 2016 for eq a2 3 j t ℓ s 1 j s a 3 early time and late time asymptotic behaviours of the leakage rate for further investigation about the leakage of brine during co2 geosequestration the early time and late time asymptotic behaviours of the dimensionless diffusive leakage rate at the interface between the aquifer and overburden j 0 and j respectively are also studied by using a combination of eqs a1 13c a1 13e and a2 3 a2 4c for the dimensionless diffusive leakage rate and considering the initial s is large for an early time period where t is small and final s is small for a late time period where t is large value theories one can arrive at a3 1a j 0 lim t 0 j t ℓ s 1 lim s j s ℓ s 1 1 h 1 1 1 k φ 1 s 3 2 2 h 1 1 1 k φ t π a3 1b j lim t j t ℓ s 1 lim s 0 j s ℓ s 1 1 1 φ λ 1 s 1 1 φ λ 1 1 ω where λ is the aspect ratio of the aquifer thickness to the overburden thickness h 1 h 2 h 1 h 2 and ω φλ is the storativity ratio and defined as the ratio of the aquifer storativity s 1 ϕ 1 ct 1 h 1 to the overburden storativity s 2 ϕ 2 ct 2 h 2 i e ω s 1 s 2 equations a3 1a and a3 1b suggest that the leakage rates at early and late times can be estimated for a system comprised of an aquifer and an overburden a 4 well pressures in the aquifer and overburden now the semi analytical solutions for development of new type curves during geological storage of co2 in an aquifer overlaid by an overburden associated with diffusive leakage of brine at the aquifer overburden interface are presented by writing eq a1 16 at r 1 and using un 1 2 πλn ziener et al 2015 it is possible to obtain the dimensionless well pressures in the aquifer and overburden in the laplace domain p α w a4 1 p α w z s p α r 1 z s 2 r e 2 1 p α 0 z s π n 1 λ n j 1 2 λ n r e p α n z s j 1 2 λ n j 1 2 λ n r e eq a4 1 is a function of z to obtain the dimensionless average well pressures in the aquifer and overburden in the laplace domain along the dimensionless intervals of the aquifer and overburden p α w eq a4 1 must be integrated with respect to z over the limits of the dimensionless intervals of the aquifer and overburden 0 z h 1 and h 1 z h1 h2 respectively divided by the dimensionless intervals of the aquifer and overburden h1 and h2 respectively therefore by using this approach it is possible to reach at a4 2 p α w s 1 h 1 2 α h 2 α 1 z h 1 α 1 z h 1 h 2 α 1 p α w z s d z 2 r e 2 1 p α 0 s π n 1 λ n j 1 2 λ n r e p α n s j 1 2 λ n j 1 2 λ n r e where p α 0 s and p α n s are the dimensionless average well pressures in the aquifer and overburden in the laplace and finite hankel domains for the cases of n 1 and n 1 respectively p α 0 s can be derived using eq a1 13a as a4 3a p α 0 s 1 h 1 2 α h 2 α 1 z h 1 α 1 z h 1 h 2 α 1 p α 0 z s d z 1 s 2 2 α 1 h 1 2 α h 2 α 1 1 s g 0 sinh h 1 s sinh h 2 k φ s d 0 where a4 3b g 0 k φ k φ α 2 k φ k φ also p α n s can be obtained by applying eq a1 14a as a4 4a p α n s 1 h 1 2 α h 2 α 1 z h 1 α 1 z h 1 h 2 α 1 p α n z s d z 1 s 2 π λ n 1 s λ n 2 2 α 1 h 1 2 α h 2 α 1 g n sinh h 1 s λ n 2 sinh h 2 k φ s λ n 2 d n where a4 4b g n k φ s λ n 2 s λ n 2 k s λ n 2 k φ s λ n 2 α 2 k φ s λ n 2 s λ n 2 k s λ n 2 k φ s λ n 2 combining eqs a1 13e a1 14e and a4 2 a4 4b gives the dimensionless average well pressures in the aquifer and overburden in the laplace domain hence the semi analytical solutions for the dimensionless average well pressures in the aquifer and overburden in the real domain p α w can be obtained by implementing the stehfest inversion algorithm hassanzadeh and pooladi darvish 2007 dejam et al 2011a mashayekhizadeh et al 2011 dejam et al 2013 for eq a4 2 p α w t ℓ s 1 p α w s a 5 average aquifer and overburden pressures the volumetric average aquifer pressure at a given time refers to an indication of how much co2 is stored in the aquifer while the average overburden pressure at a certain time indicates how much co2 is diffusively leaked from the aquifer into the overburden the dimensionless average aquifer and overburden pressures in the laplace domain p α s can be defined as a5 1 p α s 2 r e 2 1 1 h 1 2 α h 2 α 1 r 1 r r e z h 1 α 1 z h 1 h 2 α 1 p α r z s d z r d r eq a5 1 along with eq a1 16 r 1 r r e r d r r e 2 1 2 and r 1 r r e y 1 λ n j 0 λ n r j 1 λ n y 0 λ n r r d r 0 ziener et al 2015 results in a5 2 p α s 2 r e 2 1 1 h 1 2 α h 2 α 1 z h 1 α 1 z h 1 h 2 α 1 p α 0 z s d z 2 r e 2 1 p α 0 s by combination of eqs a1 13e a4 3a a4 3b and a5 2 on can reach to the dimensionless average aquifer and overburden pressures in the laplace domain therefore the semi analytical solutions for the dimensionless average pressures in the aquifer and overburden in the real domain p α can be obtained by using the fourier inversion method hassanzadeh and pooladi darvish 2007 dejam et al 2011a b 2014 2016 2017 dejam 2016 for eq a5 2 p α t ℓ s 1 p α s a 6 early time and late time asymptotic behaviours of the average pressures in order to further investigate about the average aquifer and overburden pressures the early time and late time asymptotic behaviours of the dimensionless average aquifer and overburden pressures p α 0 and p α respectively are also addressed by applying combination of eqs a1 13e a4 3a a4 3b and a5 2 for the dimensionless average aquifer and overburden pressures and considering the initial s is large for an early time period where t is small and final s is small for a late time period where t is large value theories one can reach to a6 1a p α 0 lim t 0 p α t ℓ s 1 lim s p α s ℓ s 1 2 r e 2 1 2 α s 1 h 2 1 k φ 1 φ α 1 s 5 2 2 r e 2 1 t 2 α 1 h 2 1 k φ 1 φ 4 3 π t 3 2 α 1 a6 1b p α lim t p α t ℓ s 1 lim s 0 p α s ℓ s 1 2 r e 2 1 1 1 1 φ λ 1 s 2 2 r e 2 1 1 1 1 φ λ t 2 r e 2 1 1 1 1 ω t a 7 post injection the injection history for a well which is kept injecting co2 at constant flow rate of q for a time ti and then shut down for a period δt is considered this kind of well test is called post injection in order to obtain well pressures in the domain during post injection period the principle of superposition is used since the differential equations and boundary conditions are linear in this study the principle of superposition can be applied to implement the principle of superposition the problem can be treated as the combination of two flow rates q for a time ti δt and q for a period δt where ti is the injection period and δt is the post injection time the result of the combination of these two flow rates is the same as the well being kept injecting co2 at constant flow rate of q for a time ti and then shut down for a period δt horne 1995 the semi analytical solutions for the pressure distributions in the domain p α post leakage rate from the aquifer into overburden jpost well pressures in the aquifer and overburden p α w p o s t and average aquifer and overburden pressures p α p o s t within post injection duration can be obtained using the principle of superposition for eqs a1 16 a2 3 a4 2 and a5 2 respectively as follows a7 1 p α p o s t r z t p α r z t i δ t p α r z δ t t i t t i δ t a7 2 j p o s t t j t i δ t j δ t t i t t i δ t a7 3 p α w p o s t t p α w t i δ t p α w δ t t i t t i δ t a7 4 p α p o s t t p α t i δ t p α δ t t i t t i δ t where ti is the dimensionless time for injecting co2 and δt is the dimensionless time period for shutting down the co2 injection well 
