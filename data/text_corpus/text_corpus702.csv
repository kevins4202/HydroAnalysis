index,text
3510,the exact solution for the concentration breakthrough curves resulting from a solute injection in radially converging flow in an aquifer obtained using laplace transforms has a complex form difficult to compute and cannot be given in closed form expression this makes it difficult to use for tracer tests analysis in radial flow to overcome this difficulty new simple approximate but accurate closed form expressions are derived in the present paper for slug and continuous injections the improvement of accuracy of these new closed form expressions is demonstrated the paper establishes also that the breakthrough curves resulting from slug injections into a radially diverging or radially converging flow are exactly identical at the sampling well in domains having the same spatial extension solutions were also derived for tracers or solutes subject to degradation the new closed form expressions were used for the analysis of 12 field tracer tests to highlight the difference in transport parameters determination compared to previous approximate expressions keywords radial flow tracer tests closed form approximation dimensional expression field test applications nomenclature notation definition unit relation a intermediate variable l2t 1 a q 2πhω c concentration ml 3 cd dimensionless concentration cd c cref or c c0 cref reference concentration ml 3 c r e f m π r l 2 h ω c0 injected concentration ml 3 c 0 q m q dl longitudinal dispersion coefficient l2t 1 dl αl u erfc complementary error function f slug injection f 0 continuous injection f 1 fp correcting factors for péclet number ft correcting factors for dimensionless time h aquifer thickness l k normalization constant m injected mass m p péclet number p r l α l q injected or pumped flow rate l3t 1 qm mass flux mt 1 r retardation coefficient r radial distance l rd dimensionless radial distance r d r r l rl radial distance to outer well l t time t ta advection time from outer to center t t a π r l 2 h ω q td dimensionless time t d t t a tg first order decay time constant t t g 1 λ tgd dimensionless decay time constant t gd t g t a u pore velocity lt 1 αl longitudinal dispersivity l αt transverse dispersivity l ε diverging flow 1 converging flow 1 θ angular coordinate λ first order decay constant t 1 ω kinematic porosity 1 introduction tracer tests are widely used to determine non reactive parameters governing transport in porous media such as the effective porosity the retardation factor and the dispersivities tracer tests may be performed from an injection well to a pumping well if the flow rates in the wells are small the flow is nearly 1d cartesian and represents the background flow under natural conditions in the aquifer there are then simple exact expressions to describe the time evolution of the concentration at the pumping well corresponding to an instantaneous injection of tracer slug injection or to a constant rate mass flux injection continuous injection analyzing the monitored breakthrough curve btc with a software such as cxtfit toride et al 1999 traci95 käss 1998 qtracer2 field 2002 trac gutierrez et al 2013 using these 1d expressions enables to determine the transport parameters tracer tests under natural conditions are however difficult to manage because of difficulty in determining the exact direction of flow and the long duration of the tests resulting from the generally low velocities tracer tests in radially converging flow are widely used to overcome these difficulties and tests in radially diverging flows can also be used for some applications fig 1 in both cases there are two wells the first well located at the center of the radial flow and the second well located laterally at the radial distance rl from the center called the outer well in a diverging flow the central well is an injection well where the tracer is introduced and the sampling well is located at the distance rl in a converging flow it is the opposite the tracer is introduced in the outer well and the central well is a pumping well where the tracer is sampled the domain extension may be of two types a semi infinite domain extending from the central well to infinity referred in this paper as an unbounded domain or a bounded domain extending only from the central well to the outer well an unbounded domain would seem a priori to be closer to the field reality but as will be discussed later the solution of the convection dispersion equation in converging flow generates a non physical upstream dispersion that is reduced when considering a bounded domain interpretation of tracer tests in radial flow is difficult because there are no exact closed form solutions available for diverging flows and the solutions available for converging flow using laplace transform or airy functions are difficult to include in an interpretation software the purpose of this paper is to establish easy to use approximate closed form expressions describing the evolution of the concentration of a tracer or solute in a radially converging or diverging flow field in bounded or unbounded domain closed form expressions will be also established for solutes subject to degradation 2 previous work numerous papers addressed with different approaches the solution of radial flow tracer tests in diverging or converging flow in bounded or unbounded domain 2 1 solutions for diverging flow only ogata 1958 presented the exact solution for a continuous injection in diverging flow but its expression requires the integration of a rational fraction of bessel functions of the first and second kind hence the numerical calculation of this function is very complex 2 2 solutions for converging and diverging flow sauty 1980 used a numerical finite differences model to compute the btcs and presented approximations by analytical functions and type curves for the concentration normalized by the maximum concentration c cmax however the results which do not compare well to exact solutions are only for péclet numbers greater than 5 or 10 depending on the selected function and for a slug injection refer only to the c cmax ratio welty and gelhar 1994 gave an approximate solution for high péclet numbers wang and crampon 1995 used a numerical model with an outer boundary located far from the outer well to fit analytical functions after applying correction factors to them their results which use a great number of correcting factors are approximate as will be seen apply only to péclet numbers greater than 3 and also refer only to the c cmax ratio 2 3 solutions for converging flow only moench 1989 using laplace transform presented the exact closed form analytical solution for converging flow in a bounded domain i e without dispersion upstream of the injection well as pointed out by zlotnik and logan 1996 moench 1995 gave solutions for converging flow with double porosity chen et al 1996 presented the exact solution for converging flow in an unbounded domain their analytical solution involving airy functions of complex arguments and laplace inversion are however quite difficult to compute due to the numerical back transformation of the solutions in the laplace domain to the time domain becker and charbeneau 2000 presented also a solution for converging flow using airy functions and laplace transform chen et al 2002 presented a new exact solution in bounded domain somewhat simpler with laplace transform but without airy functions chen et al 2003a analyzed the effect of the well bore mixing volume chen et al 2003b derived semi analytical solutions with a scale dependent dispersivity 2 4 special configurations wang and zhan 2013 developed semi analytical solutions of radial reactive solute transport in an aquifer aquitard system in diverging flow via laplace transform and finite fourier transform techniques and numerical inversion csanady 1973 pérez guerrero and skaggs 2010 natarajan 2016 proposed various schemes where the longitudinal dispersivity is not constant but increases with transport distance irvine et al 2020 described a method to reduce unwanted upstream dispersion in 2d discretized numerical models akanji and falade 2018 derived a solution to the radial transport of tracer under the influence of linear drift their solution which uses tricomi kummer functions and requires a numerical laplace inversion shows that the effect of the drift becomes progressively more pronounced at later times van genuchten 1981 1985 presented solutions in cartesian coordinate system for solutes involved in sequential first order decay reactions 3 mathematical formulation a homogeneous and isotropic aquifer of infinite horizontal extent and constant thickness h and effective porosity ω is considered a well of negligible radius located in this aquifer with a constant injection or pumping rate creates a steady state diverging or converging radial flow field tracer transport in the aquifer occurs by radial advection and by mechanical dispersion the effects of molecular diffusion and also the effects of both extraction and injection well mixing volumes are considered as negligible tracer degradation is not considered in this section however closed form expressions including degradation will be presented in section 7 5 two mass injection regimes are studied a slug or dirac injection where a mass m of tracer is injected instantaneously or a continuous injection where a constant mass flux qm is injected the continuous injection corresponds to the integration over time of slug injections 3 1 diverging flow the well injects a constant positive flow rate q at the initial time a mass m of tracer or a constant mass flux qm of tracer is injected instantaneously into the well the concentration is monitored in a sampling well situated at a distance rl the system is perfectly axisymmetric and the mass transport equation sauty 1980 is 1 r c t d l 2 c r 2 u c r where r is the radial distance from the well t is the time from the start of the tracer injection c is the tracer concentration u is the pore velocity dl is the longitudinal dispersion coefficient and r is the tracer retardation factor resulting from a partition coefficient kd between the liquid phase and a solid phase the geometry being axisymmetric the transverse dispersion coefficient has no influence and doesn t appear in the equation assuming that dl αl u neglecting the molecular diffusion and expressing the velocity as u q 2πrhω a r where a q 2πhω into eq 1 results in 2 r c t α l a r 2 c r 2 a r c r 3 2 converging flow the well is pumped at a constant positive flow rate q at the initial time a mass m of tracer or a constant mass flux qm of tracer is injected in a nearby borehole at a distance rl without disturbing the flow field in the aquifer the concentration is monitored in the pumped well the system is not axisymmetric and the mass transport equation sauty 1980 is 3 r c t α l u 2 c r 2 α t u r 2 2 c θ 2 u c r where αt is the transverse dispersivity θ the angular coordinate and u a r is negative because the concentration in the pumped well is the average over the negligible well radius sauty 1977a 1980 shows that it is possible to consider the average concentration at a radius r 4 c r t 1 2 π 0 2 π c r θ t d θ applying this transformation to eq 3 the second term depending on θ and αt disappears the average concentration does not depend any more on the transverse dispersivity and eq 5 similar to eq 2 for diverging flow is obtained with only a change of sign in the last term 5 r c t α l a r 2 c r 2 a r c r 3 3 equation for both diverging and converging flow the equations for diverging and converging flow may be combined as 6 r c t α l a r 2 c r 2 ε a r c r where ε 1 for diverging flow and ε 1 for converging flow to obtain a dimensionless equation let the following variables t a π r l 2 h ω q r l 2 2 a advection time from the injection point to the observation point located at distance rl c r e f m π r l 2 h ω injected mass divided by the water volume within the distance rl for a slug injection c 0 q m q equivalent injected concentration for a continuous mass flux injection p r l α l péclet number using the dimensionless variables r d r r l t d t t a c d c c r e f or c d c c 0 the mass transport equation eq 6 for diverging or converging flow becomes 7 2 r c d t d 1 p r d 2 c d r d 2 ε 1 r d c d r d where ε 1 for diverging flow and ε 1 for converging flow the only parameter of this eq 7 is the péclet number p not mentioning the retardation factor r which can be included in td transport boundary conditions the transport boundary condition at the central well rd 0 is 8a c d 1 p c d r d f i n d i v e r g i n g f l o w 8b c d r d 0 i n c o n v e r g i n g f l o w with f 0 for a slug injection and f 1 for a continuous injection in an unbounded domain the outer boundary condition rd is 8c c d r d 0 o r c d 0 in a bounded domain the outer boundary condition rd 1 is 8d c d r d 0 i n d i v e r g i n g f l o w 8e c d 1 p c d r d f i n c o n v e r g i n g f l o w 4 unbounded domain versus bounded domain the dispersion term in eq 6 is a fickian diffusion process which generates dispersion in all directions downstream but also upstream in a converging flow the upstream dispersion generates mass transport upstream of the injection well which is non physical because mechanical dispersion is due to the heterogeneity of the velocity field caused by the heterogeneity of the medium however the velocity field heterogeneity cannot lead to counter flow velocity in fact the upstream dispersion is essentially due to the assumption that dispersion dl is equal to αl u with αl independent of distance yet it has been observed that the average value of αl between two points is clearly increasing with their distance sauty 1980 pérez guerrero and skaggs 2010 chen et al 2003b natarajan 2016 a method to reduce or cancel the upstream dispersion is to assume according to csanady 1973 and chen et al 2003b that the longitudinal dispersivity is not constant but increases with transport distance thus with travel time from a small or nil initial value to a large final value however this method requires the dispersivity distance relationship which is seldom available irvine et al 2020 describe a method to reduce unwanted upstream dispersion in 2d discretized numerical models by setting a lower dispersivity in areas upstream of the injection wells another classic however somewhat artificial way to reduce the upstream dispersion is to limit the modeled domain to the outer injection well which corresponds to a bounded domain in fact this cancels the dispersivity upstream of the injection well but not all the upstream dispersion that results from the symmetric dispersion term in eq 5 to deal with this issue of bounded or unbounded domain it has been decided in this paper for the sake of completeness to establish closed form expressions for both the unbounded and the bounded domain a comparison of the transport parameters obtained in a tracer test analysis using expressions for a bounded or unbounded domain will be presented in appendix c although the bounded domain applies only to converging flow the closed form expressions have also been established in diverging flow for comparison and for possible use in particular configurations 5 method for obtaining approximate closed form expressions to obtain closed form expressions easy to use and to integrate into a computer code without airy functions or laplace inversion which is the main goal of this paper an approach somewhat similar to that of wang and crampon 1995 was used starting from simple approximate closed form expressions for a slug injection or a continuous injection in 1d cartesian coordinate two correction coefficients applied to the péclet number p and the dimensionless time td were introduced into the expression to obtain a simple expressions that most accurately reproduce the exact solutions since the exact solutions that involve airy functions or laplace inversions were difficult to determine another method was used to calculate them a finite volume groundwater flow and transport numerical model was used to obtain numerically exact btcs resulting from slug or continuous injections for a wide range of péclet numbers from 0 1 to 1000 that will be used later to determine the simple approximate closed form expressions the accuracy of the model simulations was checked by comparing them to the available exact solutions of a limited number of btcs in converging flow as presented in figures from the literature mainly in moench 1989 chen et al 1996 2002 the numerical model was also used to generate the exact solutions in diverging flow that are not available in the literature and to take into account the tracer degradation as will be shown in section 7 5 6 numerical solutions in converging and diverging flow the numerical calculations were performed with marthe code thiéry 2010 2015b vanderborght et al 2005 thiéry and picot colbeaux 2020 in the numerical code the mass transport equation is solved numerically using a total variation diminishing tvd method implemented with a flux limiter leonard 1988 which produces very little numerical dispersion due to the axisymmetric geometry the calculations were performed with a 1d radial grid following sauty 1977a a non uniform spatial discretization was implemented to ensure a constant numerical courant number as the pore velocity decreases with the distance from the central well the grid size also decreases with distance four sets of btcs were generated with the model in converging flow and in diverging flow and both of them in bounded or unbounded domain 6 1 discretization outer boundary condition and initial conditions in the model a fine 1d radial grid is used and the steady state radial flow field is computed first to obtain the radial flow field a source term injection or pumping is set in the cell located at the origin of the grid and a constant hydraulic head is prescribed a dirichlet condition in the model outer limit located very far from the wells this prescribed hydraulic head automatically generates the desired radial flow mass transport is then computed in transient state starting from an initial concentration equal to zero in the whole domain for an unbounded domain the outer boundary for transport was located far enough away from the central well to have no influence usually at a dimensionless radial distance rd equal to 3 for péclet numbers as low as 0 1 or for continuous injections the transport outer boundary was located farther at a dimensionless radial distance equal to 7 the concentration was prescribed at this outer boundary but it was verified that this boundary being located far enough away the results obtained with a no flow boundary were identical for a bounded domain the grid extension hence the outer boundary for transport was limited to the outer well i e at a dimensionless distance rd equal to 1 at this outer boundary a constant hydraulic head is prescribed as was done for the unbounded domain to generate the desired radial flow and a no flow boundary condition was set for the mass transport without prescribing the concentration however exactly the same results were obtained keeping the former quasi infinite grid and setting a nil dispersivity in all cells located at a dimensionless distance larger than 1 the dimensionless radial distance rd equal to 3 or equal to 7 was discretized in 3000 cells and the dimensionless time td up to 5 was divided in 10 500 time steps 6 2 verification of the numerical scheme and discretization in converging flow the 1d radial numerical scheme and discretization was checked by comparison with available solutions in converging flow in unbounded and bounded domains a first verification was done in unbounded domain for péclet numbers ranging from 0 1 to 300 fig 2 illustrates that even for péclet numbers as small as 0 1 the numerical solutions are identical to chen et al 1996 analytical solution as depicted in their fig 2 a second verification was done in bounded domain by comparison to moench 1989 and to chen et al 2002 analytical solution for péclet numbers ranging from 0 1 to 200 it is shown in appendix a that the numerical solutions are also identical to the exact analytical solution figs a1 and a2 it was also verified numerically that as demonstrated by sauty 1977a 1980 the transverse dispersion has no influence a simulation was performed with the same numerical code in 2d radial coordinates in an unbounded domain for a péclet number equal to 5 with a transverse dispersivity equal to 0 2 αl fig 3 confirms that the simulated average concentration along the production well radius is identical to the concentration obtained with a 1d simulation without transverse dispersivity which is a further verification of the numerical code accuracy the accuracy of the solutions obtained with the numerical model having been carefully verified these numerical solutions will be called exact solutions from here on in the paper 6 3 numerical solution for a slug injection or a continuous injection in a diverging flow in unbounded domain the exact solutions for diverging flow being not available in the literature they are also generated with the numerical model the accuracy of the numerical modeling being verified in converging flow it is assumed that the numerical scheme and the spatial and time discretization can also be used for diverging flow using a different boundary condition for this calculation the outer boundary is set at a distance sufficient to obtain there a negligible concentration less than 1 1000 of maximum concentration because the flow field is axisymmetric the transverse dispersivity having no influence is not included in the calculation fig 4 compares the btcs resulting from a slug injection in diverging flow and in converging flow in an unbounded domain for péclet numbers ranging from 0 1 to 100 it appears though it has not been demonstrated that the btcs are absolutely identical fig 5 compares the concentrations profiles at td 0 25 td 0 5 for a slug injection in diverging flow and in converging flow in an unbounded domain for a péclet number equal to 3 although the profiles are essentially different the concentrations at the sampling well are identical this result is quite different from the results obtained by wang and crampon 1995 who used the same outer boundary condition probably because the radial extent of their grid was too small especially for small péclet numbers since the continuous injection corresponds to the integration over time of slug injections the computed btcs in converging and in diverging flow should also be identical which was verified by our simulations the numerical solution for btcs from continuous injection in diverging flow not displayed in the paper are exactly identical to the corresponding btcs in converging flow 6 4 numerical solution for a slug injection or a continuous injection in bounded domain the btcs resulting from a slug injection in bounded domain in diverging and in converging flow have been computed for péclet numbers ranging from 0 1 to 200 fig 6 compares the btcs obtained in diverging flow and in converging flow in a bounded domain similar to what was obtained in unbounded domain it appears though it has not been demonstrated that in bounded domain also the btcs are absolutely identical in diverging and in converging flow fig 7 displays the concentrations profiles at td 0 25 td 0 4 for a slug injection in diverging flow and in converging flow in bounded domain for a péclet number equal to 3 it illustrates that as in unbounded domain although the profiles are different the concentrations at the sampling well are identical 7 approximate closed form expressions as explained in section 5 the exact solutions needed to obtain the approximate closed form expressions were obtained by numerical modeling the exact solutions for slug injections and continuous injections were successively computed with the numerical model for 20 values of péclet numbers ranging from 1 to 1000 or from 0 8 to 1000 for dimensionless time td ranging from 0 to6 the solutions were calculated only in converging flow as it has been shown that they were identical in diverging flow for each solution slug injection or continuous injection a simple closed form expression approximation f of the exact solution in the form of eq 9 is selected 9 c d t d f p t d as in wang and crampon 1995 approach two correction factors were introduced a correction factor ft on the dimensionless time and a correction factor fp on the péclet number to obtain a simple closed form expression that most accurately reproduces the exact solutions the following formulation for these correction factors depending only of the péclet number was chosen 10 f t a b p c a n d f p d e p f in the equations the dimensionless time td is multiplied by ft and the péclet number p is divided by fp the reason why p is divided by fp rather than multiplied by fp is that fp was introduced as a multiplying factor on the dispersivity hence a dividing factor on the péclet number introducing the two correction factors of eq 10 into eq 9 it becomes 11 c d t d f p f p f t t d the unique set of 6 constants a b c d e and f is determined by optimization using the rosenbrock 1960 algorithm to simultaneously reproduce as accurately as possible with eq 11 a large set of around 20 btcs corresponding to 20 values of the péclet number the optimization process maximizes the average nash criterion nash and sutcliffe 1970 of the 20 btcs obtained by eq 11 with respect to the corresponding exact solutions approximate expressions are established both for an unbounded domain section 7 1 and for a bounded domain section 7 2 the improvement of the new closed form expression compared to available approximate expressions is demonstrated in section 7 3 the application of the expressions for a solute subject to interactions resulting in a retardation coefficient is described in section 7 4 the adaption of the closed form expressions to solutes or tracers subject to degradation is presented in section 7 5 a comparison of the transport parameters obtained in a tracer test analysis using expressions for a bounded or unbounded domain is given in appendix c it highlights the large variations in dispersivity values but also in porosity obtained according to the choice of geometry 7 1 approximate closed form expressions in unbounded domain closed form expressions were derived in unbounded domain for a continuous injection and for a slug injection 7 1 1 approximate closed form expression for a continuous injection in unbounded domain two 1d closed form expressions were tried to determine which one would produce the best results the first expression eq 12 is the solution for a constant rate mass injection in cartesian coordinate it was derived by sauty 1977a by integration of the solution reported by bear 1972 for a slug injection into an infinite column 12 c x t q m 2 q e r f c x u t 4 d l t e x p x α l e r f c x u t 4 d l t the second expression considered eq 13 is a simplification of eq 12 obtained by dropping its second term 13 c x t q m 2 q e r f c x u t 4 d l t the results obtained with this expression turned out to be significantly closer to the exact solution especially for péclet numbers smaller than 3 in radial flow at a distance r rl considering the average pore velocity u a defined as u a r l t a q π h ω r l d l α l u a the equivalent formulation of eq 13 in radial coordinate in dimensionless form is 14 c d t d 0 5 e r f c p 4 t d 1 t d this formulation is only a crude approximation of the exact solution introducing the two correction factors ft and fp eq 14 becomes 15 c d 0 5 e r f c p f p 4 f t t d 1 f t t d as explained before the optimal set of 6 constants a b c d e and f is determined by optimization to simultaneously reproduce as accurately as possible with eq 15 the 20 btcs corresponding to 20 values of the péclet number with this unique set of 6 constants a very good match was obtained for péclet numbers ranging from 0 8 to 1000 and td ranging from 0 to6 see fig 8 the lowest nash criterion of all curves is 0 9994 the equations obtained for the correcting factors for a continuous injection in converging or diverging flow in unbounded domain are 16a f t 1 00627 0 44829 p 0 73712 16b f p 1 44488 0 21574 p 0 78005 7 1 2 approximate closed form expression for a slug injection in unbounded domain bear 1972 shows that the analytical solution for a slug injection into an infinite column is 17 c x t m ω h w 4 π d l t e x p x u t 2 4 d l t where w is the width of the horizontal column in radial flow at a distance x rl and using ua the equivalent formulation in radial coordinate is 18 c r l t m u a q 4 π α l u a t e x p r l u a t 2 4 α l u a t and in dimensionless variables 19 c d t d p 4 π t d e x p p 4 t d 1 t d 2 however the derivative with respect to dimensionless time td of eq 14 which gave a very good match for a continuous injection is 20 c d t d 0 5 p 4 π t d t d 1 t d e x p p 4 t d 1 t d 2 introducing the correction factors fp and ft eq 20 becomes 21 c d t d 0 5 f t p f p 4 π f t t d f t t d 1 f t t d e x p p f p 4 f t t d 1 f t t d 2 the leading factor ft introduced into the first term is necessary to have an integral from td 0 to equal to 1 i e to conserve mass as for the continuous injection another unique set of 6 constants a b c d e and f was determined by optimization to obtain the closest approximation of the 20 exact solutions for slug injections again a very good match is obtained for péclet numbers ranging from 1 to 1000 and td ranging from 0 to6 see fig 9 the fit obtained with eq 21 is significantly better than that obtained when fitting eq 19 that could have seemed more natural the lowest nash criterion of all curves is 0 9922 the equations obtained for the correcting factors for a slug injection in converging or diverging flow in unbounded domain are 22a f t 1 00092 0 45272 p 0 87334 22b f p 1 51016 0 3189 p 0 09496 7 2 approximate closed form expressions in bounded domain in the same manner as for an unbounded domain closed form expressions have been determined for a continuous injection and for a slug injection in bounded domain 7 2 1 approximate closed form expression for a continuous injection in bounded domain among the 1d closed form expressions that were tried it is the solution for a step injection at fixed concentration in 1d cartesian coordinate system that produces the best results it is ogata and banks 1961 equation 23 c d t d 0 5 e r f c p 4 t d 1 t d e x p p e r f c p 4 t d 1 t d this equation differs from equation 12 by a plus sign in front of the term exp erfc instead of a minus sign introducing the correction factors fp and ft eq 23 becomes 24 c d t d 0 5 e r f c p f p 4 f t t d 1 f t t d e x p p f p e r f c p f p 4 f t t d 1 f t t d after determination of the optimal set of 6 constants a b c d e and f a very good match is obtained for péclet numbers ranging from 2 to 1000 see fig 10 however the fit is not quite as good for péclet numbers lower than 2 the average nash criterion for the 20 curves is 0 9998 and the lowest criterion is 0 9988 the equations obtained for the correcting factors for a continuous injection in converging flow in bounded domain are 25a f t 1 17097 0 20663 p 1 87515 25b f p 1 43094 0 96565 p 0 47269 7 2 2 approximate closed form expression for a slug injection in bounded domain several classic closed form expressions were tried the derivative versus time of ogata and banks 1961 equation for a step injection in 1d cartesian coordinate lenda and zuber 1970 that was used by sauty 1980 26 c d t d p 4 π t d 3 2 e x p p 4 t d 1 t d 2 did not result in a close match for all péclet numbers after optimization of the set of 6 constants the curves for low péclet numbers were not modeled accurately the selected closed form expression is equation 18 for a slug injection in 1d cartesian coordinate bear 1972 after determination of the optimal set of 6 constants a b c d e and f a very good match is obtained for péclet numbers ranging from 1 to 1000 see fig 11 for the sake of readability the curves for péclet numbers from 200 to 1000 do not appear in fig 11 but they are also very accurately reproduced the average nash criterion for the 20 curves is 0 9993 and the lowest nash criterion is 0 9984 27 c d t d f t p f p 4 π f t t d e x p p f p 4 f t t d 1 f t t d 2 the equations obtained for the correcting factors for a slug injection in converging flow in bounded domain are 28a f t 0 99003 1 29039 p 0 72566 28b f p 1 51514 0 89053 p 0 29830 7 3 improvement of the new closed form expressions compared to available expressions the improvement of the new closed form expressions developed in the present paper has been demonstrated by comparison to two approximate closed form available in radial flow the closed form described by sauty 1980 for a slug injection in converging flow and the closed form described by wang and crampon 1995 for the whole btc duration the comparison is detailed in appendix b figs b1 and b2 show that the new closed form expressions are significantly closer to the exact solutions 7 4 expressions for a solute with a retardation factor the closed form expressions applies also to solutes or tracers having a retardation factor r resulting from a partition coefficient kd between the liquid phase and a solid phase in equation 6 setting r 1 and ω r ω which corresponds to a a r leaves the equation unchanged it is then possible to use all the derived expressions replacing ω by r ω to obtain the concentration for a solute with a known retardation factor equal to r on the other hand using the original dimensionless expressions to determine the unknown transport parameters ω and αl from a tracer test would yield the right value for αl but a value of ω multiplied by r it would then be impossible to determine the value of the retardation factor 7 5 expressions for a solute subject to degradation the closed form expressions may be adapted easily for solutes or tracers subject to an exponential decay during transport as c 0 e t t g tg being the first order decay time constant for the mobile phase assuming the same decay time constant in the solid phase eq 6 becomes 29 r c t α l a r 2 c r 2 ε a r c r r c t g using the dimensionless decay time constant t g d t g t a the dimensionless equivalent of eq 7 is 30 2 r c d t d 1 p r d 2 c d r d 2 ε 1 r d c d r d 2 r c d t g d it can be verified that if c d r d t d is solution of eq 7 then c d r d t d c d r d t d e t d t g d is solution of eq 30 31a c d c d e t d t g d 31b c d t d c d t d e t d t g d c d t g d e t d t g d 31c c d r d c d r d e t d t g d 31d 2 c d r d 2 2 c d r d 2 e t d t g d introducing eqs 31a 31d into eq 7 and dividing by e t d t g d results in eq 30 this proves that using the new closed form expressions derived in this paper that are very close to solution of eq 7 and multiplying them by e t d t g d gives approximate closed form expressions integrating degradation provided that the boundary conditions are also multiplied by e t d t g d this applies to the slug injections however for continuous injections it would apply only if the solute is degraded with the same decay rate before being injected which is usually not verified as bacterial degradation occurs only in the aquifer fig 12 refers to the btcs resulting from a slug injection in converging or diverging flow in an unbounded domain for two péclet numbers and various decay time constants it shows that the closed form expression applies accurately to solutes subject to exponential decay it has also been verified that for a bounded domain the equivalent expression applies also with the same accuracy 8 application to field tracer tests the new closed form expression established in this paper for a slug injection has been applied for the interpretation of a set of tracer tests i e for determining their dispersivity and kinematic porosity by calibration it was thus possible to quantify the improvement obtained by using this expression rather than other approximate expressions the set consists of twelve tracer tests mostly performed in alluvial formations tracer tests 1 through 8 come from gutierrez et al 2012 the btcs data relative to these tracer tests are provided as supplementary material the main characteristics of the tests distance to well formation thickness pumping rate test duration are gathered in table 1 the distance from the injection point to the pumping well is most of the time quite small median value is 14 m with only one exception the formations thickness are also small median thickness is 9 3 m and the total duration of the tests usually ranges from 1 day to 2 days with the exception of two much longer tests unfortunately the injected masses were not known using the rosenbrock optimization method for determining the optimal kinematic porosity and dispersivity the btcs of these twelve tracer tests were reproduced successfully with the new closed form formulation in unbounded domain eq 21 22a 22b the median nash and sutcliffe criterion is 0 977 with only one value below 0 9 the calibrated kinetic porosity dispersivity and injected mass values are given in table 2 the péclet numbers obtained are rather small median value is 4 3 and only one value is above 10 two approximate expressions for a slug injection in converging flow were used for comparison the expressions described by sauty 1980 and by wang and crampon 1995 sauty s 1980 expression is eq 26 the derivative versus time of ogata and banks 1961 equation for a step injection in 1d cartesian coordinate lenda and zuber 1970 without correction factors the wang and crampon 1995 equation for a radially convergent slug injection for the whole btc is based on eq 19 i e the solution of a slug injection in 1d cartesian coordinate with correction factors it is valid only for péclet numbers greater than 3 c d t d k p f p 4 πt d f t e xp p f p 4 t d f t 1 t d f t 2 with k normalization constant f t 2 0 503 0 33 p if p 100 else f t 1 f p 1 32 1 116 p the twelve btcs were also reproduced successfully using both these approximate expressions with comparable nash coefficients however the calibrated values of the kinetic porosity and of the dispersivity given in table 3 for the wang and crampon 1995 equation differ significantly from those obtained using the new closed form expression of this paper which is extremely close to the exact solution using the formulation of wang and crampon 1995 both of these parameters are overestimated the median value of the overestimation is 19 9 for dispersivity and only 4 4 for kinematic porosity fig 13 shows that as expected it is for small péclet numbers that the new closed form expression provides more accuracy where the overestimation of the dispersivity was the largest sauty s 1980 approximation heavily overestimates the dispersivity and kinematic porosity the median value of these two parameters overestimation is 69 and 67 respectively however sauty s 1980 approximate formulation was selected after comparison to a numerical modeling using an outer boundary condition not clearly documented but apparently corresponding to a bounded domain therefore another comparison was made with the kinematic porosity and dispersivity obtained with the new closed form expression of this paper in a bounded domain eq 27 28a 28b the deviations are then smaller the median value of the overestimation is reduced to 15 4 for dispersivity and to 23 2 for kinematic porosity 9 summary and conclusions this paper derived simple accurate approximate closed form expressions for tracer injection in aquifer with a radially converging or diverging flow in a bounded or unbounded domain starting from approximate closed form expressions for a slug injection or a continuous injection in 1d cartesian coordinate two correction coefficients depending only on the péclet number were introduced into this expression to obtain new closed form expressions that most accurately reproduce the exact solutions in radial coordinate the conditions of application of these expressions are that the aquifer must have homogeneous properties and a uniform thickness and the central pumping or injection well must have a negligible radius longitudinal dispersion is taken into account but the molecular diffusion is neglected transverse dispersion does not appear in the expressions because it has no influence the closed form expressions may be used for a tracer having a retardation factor and subject to exponential degradation an interesting result obtained by the numerical simulations is that for a given set of parameters a btc at the sampling well is identical in diverging or in converging flow this applies in unbounded domain and also in bounded domain using the 4 following dimensionless numbers t d t q π r l 2 h ω dimensionless time p r l α l péclet number c d c q q m dimensionless concentration for a continuous injection or c d c π r l 2 h ω m dimensionless concentration for a slug injection the approximate closed form for péclet number ranging from 1 to 1000 and dimensionless time ranging from 0 to 5 are unbounded domain slug injection c d t d 0 5 f t p f p 4 π f t t d f t t d 1 f t t d e x p p f p 4 f t t d 1 f t t d 2 e t d t g d f t 1 00092 0 45272 p 0 87334 f p 1 51016 0 3189 p 0 09496 when there is no degradation t g d and the last term is dropped continuous injection c d 0 5 e r f c p f p 4 f t t d 1 f t t d f t 1 00627 0 44829 p 0 73712 f p 1 44488 0 21574 p 0 78005 bounded domain these expressions in a bounded domain can be used for tracer tests in converging flow they would not be appropriate in diverging flow slug injection c d t d f t p f p 4 π f t t d e x p p f p 4 f t t d 1 f t t d 2 e t d t g d f t 0 99003 1 29039 p 0 72566 f p 1 51514 0 89053 p 0 29830 continuous injection c d t d 0 5 e r f c p f p 4 f t t d 1 f t t d e x p p f p e r f c p f p 4 f t t d 1 f t t d f t 1 17097 0 20663 p 1 87515 f p 1 43094 0 96565 p 0 47269 the new closed form formulation for a slug injection in unbounded domain has been applied to twelve radially convergent tracer tests the mass transfer parameters obtained were compared to those obtained by two approximate methods sauty s 1980 formulation and the formulation of wang and crampon 1995 it appeared that sauty s 1980 approximate formulation results in overestimations of both the kinematic porosity and the dispersivity using the approximate formulation of wang and crampon 1995 also overestimates dispersivity but to a lesser extent it has been shown that by choosing a bounded domain to reduce the spurious upstream dispersion instead of an unbounded domain corresponding to the real geometry significantly different values are obtained for the dispersivity but also for the porosity these differences however decrease for large péclet numbers it has also been shown that both schemes can reproduce the btc equally well therefore the analysis of the btc alone does not allow the selection of the most appropriate scheme funding information this research was conducted by the french geological survey brgm and was funded by internal research projects declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors are grateful to t klinka from brgm for providing field tracer tests data to apply the developed solutions they are also grateful to the two anonymous reviewers for their helpful suggestions appendix a validation of our 1d radial numerical scheme discretization and outer boundary conditions in bounded domain our 1d radial numerical scheme and discretization was validated in bounded domain in converging flow by comparison to chen et al 2002 analytical solution as depicted in their fig 2 and fig 4 fig a1 and fig a2 show that the numerical calculations with the selected spatial and temporal discretization and outer boundary condition reproduce accurately the exact analytical solution of chen et al 2002 for péclet numbers ranging from 0 1 to 200 appendix b evaluating the improvement of the new closed form expressions the improvement of the new closed form expressions developed in this paper is demonstrated by comparison to the two approximate closed form available for the btc resulting from a slug injection in radial flow sauty s 1980 closed form for a slug injection in converging flow and the closed form described by wang and crampon 1995 for the whole btc duration the equations corresponding to these approximate expressions are given in section 8 sauty s 1980 approximation for a slug injection in converging flow in the numerical model used by sauty 1980 to select its approximate expression the outer boundary condition although not clearly documented corresponds apparently to a bounded domain for this reason their approximation was compared to the solution in a bounded domain and the closeness to their solution was compared the new closed form in a bounded domain fig b1 shows that the new closed form expression in bounded domain eq 27 28a 28b is significantly closer to the exact solution than sauty s 1980 expression this is true as well for small péclet numbers not exceeding 3 as for large values exceeding 30 wang and crampon 1995 approximation wang and crampon 1995 used a numerical model in unbounded domain to fit their expressions among the four expressions ascending part of btc or whole btc converging or diverging only the two expressions for the whole btc were selected and compared to the single exact solution the closeness of their expressions valid for péclet number greater than or equal to 3 were compared to the single new closed form in unbounded domain in unbounded domain also fig b2 shows that the new closed form expression eq 21 22a 22b is much closer to the exact solution than wang and crampon 1995 expression the difference is considerable for small péclet numbers not exceeding 3 which are below the limit of validity of their expression but is also significant for larger values the difference decreases however for large values exceeding 30 appendix c comparison of the transport parameters obtained in a tracer test analysis using expressions for a bounded or unbounded domain the transport parameters kinematic porosity and dispersivity obtained from the analysis of a tracer test depend on the assumption chosen for the domain bounded or unbounded to analyze the sensitivity to this assumption the dimensionless btcs for slug injections were calculated with the exact bounded domain solution for 20 values of péclet numbers corresponding to given values of kinematic porosity and dispersivity these 20 btcs are assumed to represent actual tracer tests using the exact solution corresponding to the alternative assumption of an unbounded domain the 20 btcs are analyzed to determine the corresponding kinematic porosity and dispersivity it can be seen from fig c1 that all btcs corresponding to péclet numbers greater than or equal to 1 5 could be reproduced very accurately with the unbounded domain solution but with transport parameters different from the original parameters this shows that the sole analysis of a btc cannot help to determine which geometry bounded or not should be selected fig c2 shows the changes in the initial parameters required to reproduce the btcs it appears that in the unbounded domain the corresponding calibrated dispersivity is decreased by 50 20 and 8 respectively for péclet numbers equal to 1 5 10 and 30 the corresponding calibrated kinematic porosity is decreased by 38 15 and 7 for these same péclet numbers the reason for the decrease in dispersivity is that without upstream dispersion the btcs are less dispersed especially for small péclet numbers the decrease in kinematic porosity is also explained by the fact that without upstream dispersion the bulk advection velocity is increased resulting in a decrease in porosity appendix d supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127661 appendix d supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 
3510,the exact solution for the concentration breakthrough curves resulting from a solute injection in radially converging flow in an aquifer obtained using laplace transforms has a complex form difficult to compute and cannot be given in closed form expression this makes it difficult to use for tracer tests analysis in radial flow to overcome this difficulty new simple approximate but accurate closed form expressions are derived in the present paper for slug and continuous injections the improvement of accuracy of these new closed form expressions is demonstrated the paper establishes also that the breakthrough curves resulting from slug injections into a radially diverging or radially converging flow are exactly identical at the sampling well in domains having the same spatial extension solutions were also derived for tracers or solutes subject to degradation the new closed form expressions were used for the analysis of 12 field tracer tests to highlight the difference in transport parameters determination compared to previous approximate expressions keywords radial flow tracer tests closed form approximation dimensional expression field test applications nomenclature notation definition unit relation a intermediate variable l2t 1 a q 2πhω c concentration ml 3 cd dimensionless concentration cd c cref or c c0 cref reference concentration ml 3 c r e f m π r l 2 h ω c0 injected concentration ml 3 c 0 q m q dl longitudinal dispersion coefficient l2t 1 dl αl u erfc complementary error function f slug injection f 0 continuous injection f 1 fp correcting factors for péclet number ft correcting factors for dimensionless time h aquifer thickness l k normalization constant m injected mass m p péclet number p r l α l q injected or pumped flow rate l3t 1 qm mass flux mt 1 r retardation coefficient r radial distance l rd dimensionless radial distance r d r r l rl radial distance to outer well l t time t ta advection time from outer to center t t a π r l 2 h ω q td dimensionless time t d t t a tg first order decay time constant t t g 1 λ tgd dimensionless decay time constant t gd t g t a u pore velocity lt 1 αl longitudinal dispersivity l αt transverse dispersivity l ε diverging flow 1 converging flow 1 θ angular coordinate λ first order decay constant t 1 ω kinematic porosity 1 introduction tracer tests are widely used to determine non reactive parameters governing transport in porous media such as the effective porosity the retardation factor and the dispersivities tracer tests may be performed from an injection well to a pumping well if the flow rates in the wells are small the flow is nearly 1d cartesian and represents the background flow under natural conditions in the aquifer there are then simple exact expressions to describe the time evolution of the concentration at the pumping well corresponding to an instantaneous injection of tracer slug injection or to a constant rate mass flux injection continuous injection analyzing the monitored breakthrough curve btc with a software such as cxtfit toride et al 1999 traci95 käss 1998 qtracer2 field 2002 trac gutierrez et al 2013 using these 1d expressions enables to determine the transport parameters tracer tests under natural conditions are however difficult to manage because of difficulty in determining the exact direction of flow and the long duration of the tests resulting from the generally low velocities tracer tests in radially converging flow are widely used to overcome these difficulties and tests in radially diverging flows can also be used for some applications fig 1 in both cases there are two wells the first well located at the center of the radial flow and the second well located laterally at the radial distance rl from the center called the outer well in a diverging flow the central well is an injection well where the tracer is introduced and the sampling well is located at the distance rl in a converging flow it is the opposite the tracer is introduced in the outer well and the central well is a pumping well where the tracer is sampled the domain extension may be of two types a semi infinite domain extending from the central well to infinity referred in this paper as an unbounded domain or a bounded domain extending only from the central well to the outer well an unbounded domain would seem a priori to be closer to the field reality but as will be discussed later the solution of the convection dispersion equation in converging flow generates a non physical upstream dispersion that is reduced when considering a bounded domain interpretation of tracer tests in radial flow is difficult because there are no exact closed form solutions available for diverging flows and the solutions available for converging flow using laplace transform or airy functions are difficult to include in an interpretation software the purpose of this paper is to establish easy to use approximate closed form expressions describing the evolution of the concentration of a tracer or solute in a radially converging or diverging flow field in bounded or unbounded domain closed form expressions will be also established for solutes subject to degradation 2 previous work numerous papers addressed with different approaches the solution of radial flow tracer tests in diverging or converging flow in bounded or unbounded domain 2 1 solutions for diverging flow only ogata 1958 presented the exact solution for a continuous injection in diverging flow but its expression requires the integration of a rational fraction of bessel functions of the first and second kind hence the numerical calculation of this function is very complex 2 2 solutions for converging and diverging flow sauty 1980 used a numerical finite differences model to compute the btcs and presented approximations by analytical functions and type curves for the concentration normalized by the maximum concentration c cmax however the results which do not compare well to exact solutions are only for péclet numbers greater than 5 or 10 depending on the selected function and for a slug injection refer only to the c cmax ratio welty and gelhar 1994 gave an approximate solution for high péclet numbers wang and crampon 1995 used a numerical model with an outer boundary located far from the outer well to fit analytical functions after applying correction factors to them their results which use a great number of correcting factors are approximate as will be seen apply only to péclet numbers greater than 3 and also refer only to the c cmax ratio 2 3 solutions for converging flow only moench 1989 using laplace transform presented the exact closed form analytical solution for converging flow in a bounded domain i e without dispersion upstream of the injection well as pointed out by zlotnik and logan 1996 moench 1995 gave solutions for converging flow with double porosity chen et al 1996 presented the exact solution for converging flow in an unbounded domain their analytical solution involving airy functions of complex arguments and laplace inversion are however quite difficult to compute due to the numerical back transformation of the solutions in the laplace domain to the time domain becker and charbeneau 2000 presented also a solution for converging flow using airy functions and laplace transform chen et al 2002 presented a new exact solution in bounded domain somewhat simpler with laplace transform but without airy functions chen et al 2003a analyzed the effect of the well bore mixing volume chen et al 2003b derived semi analytical solutions with a scale dependent dispersivity 2 4 special configurations wang and zhan 2013 developed semi analytical solutions of radial reactive solute transport in an aquifer aquitard system in diverging flow via laplace transform and finite fourier transform techniques and numerical inversion csanady 1973 pérez guerrero and skaggs 2010 natarajan 2016 proposed various schemes where the longitudinal dispersivity is not constant but increases with transport distance irvine et al 2020 described a method to reduce unwanted upstream dispersion in 2d discretized numerical models akanji and falade 2018 derived a solution to the radial transport of tracer under the influence of linear drift their solution which uses tricomi kummer functions and requires a numerical laplace inversion shows that the effect of the drift becomes progressively more pronounced at later times van genuchten 1981 1985 presented solutions in cartesian coordinate system for solutes involved in sequential first order decay reactions 3 mathematical formulation a homogeneous and isotropic aquifer of infinite horizontal extent and constant thickness h and effective porosity ω is considered a well of negligible radius located in this aquifer with a constant injection or pumping rate creates a steady state diverging or converging radial flow field tracer transport in the aquifer occurs by radial advection and by mechanical dispersion the effects of molecular diffusion and also the effects of both extraction and injection well mixing volumes are considered as negligible tracer degradation is not considered in this section however closed form expressions including degradation will be presented in section 7 5 two mass injection regimes are studied a slug or dirac injection where a mass m of tracer is injected instantaneously or a continuous injection where a constant mass flux qm is injected the continuous injection corresponds to the integration over time of slug injections 3 1 diverging flow the well injects a constant positive flow rate q at the initial time a mass m of tracer or a constant mass flux qm of tracer is injected instantaneously into the well the concentration is monitored in a sampling well situated at a distance rl the system is perfectly axisymmetric and the mass transport equation sauty 1980 is 1 r c t d l 2 c r 2 u c r where r is the radial distance from the well t is the time from the start of the tracer injection c is the tracer concentration u is the pore velocity dl is the longitudinal dispersion coefficient and r is the tracer retardation factor resulting from a partition coefficient kd between the liquid phase and a solid phase the geometry being axisymmetric the transverse dispersion coefficient has no influence and doesn t appear in the equation assuming that dl αl u neglecting the molecular diffusion and expressing the velocity as u q 2πrhω a r where a q 2πhω into eq 1 results in 2 r c t α l a r 2 c r 2 a r c r 3 2 converging flow the well is pumped at a constant positive flow rate q at the initial time a mass m of tracer or a constant mass flux qm of tracer is injected in a nearby borehole at a distance rl without disturbing the flow field in the aquifer the concentration is monitored in the pumped well the system is not axisymmetric and the mass transport equation sauty 1980 is 3 r c t α l u 2 c r 2 α t u r 2 2 c θ 2 u c r where αt is the transverse dispersivity θ the angular coordinate and u a r is negative because the concentration in the pumped well is the average over the negligible well radius sauty 1977a 1980 shows that it is possible to consider the average concentration at a radius r 4 c r t 1 2 π 0 2 π c r θ t d θ applying this transformation to eq 3 the second term depending on θ and αt disappears the average concentration does not depend any more on the transverse dispersivity and eq 5 similar to eq 2 for diverging flow is obtained with only a change of sign in the last term 5 r c t α l a r 2 c r 2 a r c r 3 3 equation for both diverging and converging flow the equations for diverging and converging flow may be combined as 6 r c t α l a r 2 c r 2 ε a r c r where ε 1 for diverging flow and ε 1 for converging flow to obtain a dimensionless equation let the following variables t a π r l 2 h ω q r l 2 2 a advection time from the injection point to the observation point located at distance rl c r e f m π r l 2 h ω injected mass divided by the water volume within the distance rl for a slug injection c 0 q m q equivalent injected concentration for a continuous mass flux injection p r l α l péclet number using the dimensionless variables r d r r l t d t t a c d c c r e f or c d c c 0 the mass transport equation eq 6 for diverging or converging flow becomes 7 2 r c d t d 1 p r d 2 c d r d 2 ε 1 r d c d r d where ε 1 for diverging flow and ε 1 for converging flow the only parameter of this eq 7 is the péclet number p not mentioning the retardation factor r which can be included in td transport boundary conditions the transport boundary condition at the central well rd 0 is 8a c d 1 p c d r d f i n d i v e r g i n g f l o w 8b c d r d 0 i n c o n v e r g i n g f l o w with f 0 for a slug injection and f 1 for a continuous injection in an unbounded domain the outer boundary condition rd is 8c c d r d 0 o r c d 0 in a bounded domain the outer boundary condition rd 1 is 8d c d r d 0 i n d i v e r g i n g f l o w 8e c d 1 p c d r d f i n c o n v e r g i n g f l o w 4 unbounded domain versus bounded domain the dispersion term in eq 6 is a fickian diffusion process which generates dispersion in all directions downstream but also upstream in a converging flow the upstream dispersion generates mass transport upstream of the injection well which is non physical because mechanical dispersion is due to the heterogeneity of the velocity field caused by the heterogeneity of the medium however the velocity field heterogeneity cannot lead to counter flow velocity in fact the upstream dispersion is essentially due to the assumption that dispersion dl is equal to αl u with αl independent of distance yet it has been observed that the average value of αl between two points is clearly increasing with their distance sauty 1980 pérez guerrero and skaggs 2010 chen et al 2003b natarajan 2016 a method to reduce or cancel the upstream dispersion is to assume according to csanady 1973 and chen et al 2003b that the longitudinal dispersivity is not constant but increases with transport distance thus with travel time from a small or nil initial value to a large final value however this method requires the dispersivity distance relationship which is seldom available irvine et al 2020 describe a method to reduce unwanted upstream dispersion in 2d discretized numerical models by setting a lower dispersivity in areas upstream of the injection wells another classic however somewhat artificial way to reduce the upstream dispersion is to limit the modeled domain to the outer injection well which corresponds to a bounded domain in fact this cancels the dispersivity upstream of the injection well but not all the upstream dispersion that results from the symmetric dispersion term in eq 5 to deal with this issue of bounded or unbounded domain it has been decided in this paper for the sake of completeness to establish closed form expressions for both the unbounded and the bounded domain a comparison of the transport parameters obtained in a tracer test analysis using expressions for a bounded or unbounded domain will be presented in appendix c although the bounded domain applies only to converging flow the closed form expressions have also been established in diverging flow for comparison and for possible use in particular configurations 5 method for obtaining approximate closed form expressions to obtain closed form expressions easy to use and to integrate into a computer code without airy functions or laplace inversion which is the main goal of this paper an approach somewhat similar to that of wang and crampon 1995 was used starting from simple approximate closed form expressions for a slug injection or a continuous injection in 1d cartesian coordinate two correction coefficients applied to the péclet number p and the dimensionless time td were introduced into the expression to obtain a simple expressions that most accurately reproduce the exact solutions since the exact solutions that involve airy functions or laplace inversions were difficult to determine another method was used to calculate them a finite volume groundwater flow and transport numerical model was used to obtain numerically exact btcs resulting from slug or continuous injections for a wide range of péclet numbers from 0 1 to 1000 that will be used later to determine the simple approximate closed form expressions the accuracy of the model simulations was checked by comparing them to the available exact solutions of a limited number of btcs in converging flow as presented in figures from the literature mainly in moench 1989 chen et al 1996 2002 the numerical model was also used to generate the exact solutions in diverging flow that are not available in the literature and to take into account the tracer degradation as will be shown in section 7 5 6 numerical solutions in converging and diverging flow the numerical calculations were performed with marthe code thiéry 2010 2015b vanderborght et al 2005 thiéry and picot colbeaux 2020 in the numerical code the mass transport equation is solved numerically using a total variation diminishing tvd method implemented with a flux limiter leonard 1988 which produces very little numerical dispersion due to the axisymmetric geometry the calculations were performed with a 1d radial grid following sauty 1977a a non uniform spatial discretization was implemented to ensure a constant numerical courant number as the pore velocity decreases with the distance from the central well the grid size also decreases with distance four sets of btcs were generated with the model in converging flow and in diverging flow and both of them in bounded or unbounded domain 6 1 discretization outer boundary condition and initial conditions in the model a fine 1d radial grid is used and the steady state radial flow field is computed first to obtain the radial flow field a source term injection or pumping is set in the cell located at the origin of the grid and a constant hydraulic head is prescribed a dirichlet condition in the model outer limit located very far from the wells this prescribed hydraulic head automatically generates the desired radial flow mass transport is then computed in transient state starting from an initial concentration equal to zero in the whole domain for an unbounded domain the outer boundary for transport was located far enough away from the central well to have no influence usually at a dimensionless radial distance rd equal to 3 for péclet numbers as low as 0 1 or for continuous injections the transport outer boundary was located farther at a dimensionless radial distance equal to 7 the concentration was prescribed at this outer boundary but it was verified that this boundary being located far enough away the results obtained with a no flow boundary were identical for a bounded domain the grid extension hence the outer boundary for transport was limited to the outer well i e at a dimensionless distance rd equal to 1 at this outer boundary a constant hydraulic head is prescribed as was done for the unbounded domain to generate the desired radial flow and a no flow boundary condition was set for the mass transport without prescribing the concentration however exactly the same results were obtained keeping the former quasi infinite grid and setting a nil dispersivity in all cells located at a dimensionless distance larger than 1 the dimensionless radial distance rd equal to 3 or equal to 7 was discretized in 3000 cells and the dimensionless time td up to 5 was divided in 10 500 time steps 6 2 verification of the numerical scheme and discretization in converging flow the 1d radial numerical scheme and discretization was checked by comparison with available solutions in converging flow in unbounded and bounded domains a first verification was done in unbounded domain for péclet numbers ranging from 0 1 to 300 fig 2 illustrates that even for péclet numbers as small as 0 1 the numerical solutions are identical to chen et al 1996 analytical solution as depicted in their fig 2 a second verification was done in bounded domain by comparison to moench 1989 and to chen et al 2002 analytical solution for péclet numbers ranging from 0 1 to 200 it is shown in appendix a that the numerical solutions are also identical to the exact analytical solution figs a1 and a2 it was also verified numerically that as demonstrated by sauty 1977a 1980 the transverse dispersion has no influence a simulation was performed with the same numerical code in 2d radial coordinates in an unbounded domain for a péclet number equal to 5 with a transverse dispersivity equal to 0 2 αl fig 3 confirms that the simulated average concentration along the production well radius is identical to the concentration obtained with a 1d simulation without transverse dispersivity which is a further verification of the numerical code accuracy the accuracy of the solutions obtained with the numerical model having been carefully verified these numerical solutions will be called exact solutions from here on in the paper 6 3 numerical solution for a slug injection or a continuous injection in a diverging flow in unbounded domain the exact solutions for diverging flow being not available in the literature they are also generated with the numerical model the accuracy of the numerical modeling being verified in converging flow it is assumed that the numerical scheme and the spatial and time discretization can also be used for diverging flow using a different boundary condition for this calculation the outer boundary is set at a distance sufficient to obtain there a negligible concentration less than 1 1000 of maximum concentration because the flow field is axisymmetric the transverse dispersivity having no influence is not included in the calculation fig 4 compares the btcs resulting from a slug injection in diverging flow and in converging flow in an unbounded domain for péclet numbers ranging from 0 1 to 100 it appears though it has not been demonstrated that the btcs are absolutely identical fig 5 compares the concentrations profiles at td 0 25 td 0 5 for a slug injection in diverging flow and in converging flow in an unbounded domain for a péclet number equal to 3 although the profiles are essentially different the concentrations at the sampling well are identical this result is quite different from the results obtained by wang and crampon 1995 who used the same outer boundary condition probably because the radial extent of their grid was too small especially for small péclet numbers since the continuous injection corresponds to the integration over time of slug injections the computed btcs in converging and in diverging flow should also be identical which was verified by our simulations the numerical solution for btcs from continuous injection in diverging flow not displayed in the paper are exactly identical to the corresponding btcs in converging flow 6 4 numerical solution for a slug injection or a continuous injection in bounded domain the btcs resulting from a slug injection in bounded domain in diverging and in converging flow have been computed for péclet numbers ranging from 0 1 to 200 fig 6 compares the btcs obtained in diverging flow and in converging flow in a bounded domain similar to what was obtained in unbounded domain it appears though it has not been demonstrated that in bounded domain also the btcs are absolutely identical in diverging and in converging flow fig 7 displays the concentrations profiles at td 0 25 td 0 4 for a slug injection in diverging flow and in converging flow in bounded domain for a péclet number equal to 3 it illustrates that as in unbounded domain although the profiles are different the concentrations at the sampling well are identical 7 approximate closed form expressions as explained in section 5 the exact solutions needed to obtain the approximate closed form expressions were obtained by numerical modeling the exact solutions for slug injections and continuous injections were successively computed with the numerical model for 20 values of péclet numbers ranging from 1 to 1000 or from 0 8 to 1000 for dimensionless time td ranging from 0 to6 the solutions were calculated only in converging flow as it has been shown that they were identical in diverging flow for each solution slug injection or continuous injection a simple closed form expression approximation f of the exact solution in the form of eq 9 is selected 9 c d t d f p t d as in wang and crampon 1995 approach two correction factors were introduced a correction factor ft on the dimensionless time and a correction factor fp on the péclet number to obtain a simple closed form expression that most accurately reproduces the exact solutions the following formulation for these correction factors depending only of the péclet number was chosen 10 f t a b p c a n d f p d e p f in the equations the dimensionless time td is multiplied by ft and the péclet number p is divided by fp the reason why p is divided by fp rather than multiplied by fp is that fp was introduced as a multiplying factor on the dispersivity hence a dividing factor on the péclet number introducing the two correction factors of eq 10 into eq 9 it becomes 11 c d t d f p f p f t t d the unique set of 6 constants a b c d e and f is determined by optimization using the rosenbrock 1960 algorithm to simultaneously reproduce as accurately as possible with eq 11 a large set of around 20 btcs corresponding to 20 values of the péclet number the optimization process maximizes the average nash criterion nash and sutcliffe 1970 of the 20 btcs obtained by eq 11 with respect to the corresponding exact solutions approximate expressions are established both for an unbounded domain section 7 1 and for a bounded domain section 7 2 the improvement of the new closed form expression compared to available approximate expressions is demonstrated in section 7 3 the application of the expressions for a solute subject to interactions resulting in a retardation coefficient is described in section 7 4 the adaption of the closed form expressions to solutes or tracers subject to degradation is presented in section 7 5 a comparison of the transport parameters obtained in a tracer test analysis using expressions for a bounded or unbounded domain is given in appendix c it highlights the large variations in dispersivity values but also in porosity obtained according to the choice of geometry 7 1 approximate closed form expressions in unbounded domain closed form expressions were derived in unbounded domain for a continuous injection and for a slug injection 7 1 1 approximate closed form expression for a continuous injection in unbounded domain two 1d closed form expressions were tried to determine which one would produce the best results the first expression eq 12 is the solution for a constant rate mass injection in cartesian coordinate it was derived by sauty 1977a by integration of the solution reported by bear 1972 for a slug injection into an infinite column 12 c x t q m 2 q e r f c x u t 4 d l t e x p x α l e r f c x u t 4 d l t the second expression considered eq 13 is a simplification of eq 12 obtained by dropping its second term 13 c x t q m 2 q e r f c x u t 4 d l t the results obtained with this expression turned out to be significantly closer to the exact solution especially for péclet numbers smaller than 3 in radial flow at a distance r rl considering the average pore velocity u a defined as u a r l t a q π h ω r l d l α l u a the equivalent formulation of eq 13 in radial coordinate in dimensionless form is 14 c d t d 0 5 e r f c p 4 t d 1 t d this formulation is only a crude approximation of the exact solution introducing the two correction factors ft and fp eq 14 becomes 15 c d 0 5 e r f c p f p 4 f t t d 1 f t t d as explained before the optimal set of 6 constants a b c d e and f is determined by optimization to simultaneously reproduce as accurately as possible with eq 15 the 20 btcs corresponding to 20 values of the péclet number with this unique set of 6 constants a very good match was obtained for péclet numbers ranging from 0 8 to 1000 and td ranging from 0 to6 see fig 8 the lowest nash criterion of all curves is 0 9994 the equations obtained for the correcting factors for a continuous injection in converging or diverging flow in unbounded domain are 16a f t 1 00627 0 44829 p 0 73712 16b f p 1 44488 0 21574 p 0 78005 7 1 2 approximate closed form expression for a slug injection in unbounded domain bear 1972 shows that the analytical solution for a slug injection into an infinite column is 17 c x t m ω h w 4 π d l t e x p x u t 2 4 d l t where w is the width of the horizontal column in radial flow at a distance x rl and using ua the equivalent formulation in radial coordinate is 18 c r l t m u a q 4 π α l u a t e x p r l u a t 2 4 α l u a t and in dimensionless variables 19 c d t d p 4 π t d e x p p 4 t d 1 t d 2 however the derivative with respect to dimensionless time td of eq 14 which gave a very good match for a continuous injection is 20 c d t d 0 5 p 4 π t d t d 1 t d e x p p 4 t d 1 t d 2 introducing the correction factors fp and ft eq 20 becomes 21 c d t d 0 5 f t p f p 4 π f t t d f t t d 1 f t t d e x p p f p 4 f t t d 1 f t t d 2 the leading factor ft introduced into the first term is necessary to have an integral from td 0 to equal to 1 i e to conserve mass as for the continuous injection another unique set of 6 constants a b c d e and f was determined by optimization to obtain the closest approximation of the 20 exact solutions for slug injections again a very good match is obtained for péclet numbers ranging from 1 to 1000 and td ranging from 0 to6 see fig 9 the fit obtained with eq 21 is significantly better than that obtained when fitting eq 19 that could have seemed more natural the lowest nash criterion of all curves is 0 9922 the equations obtained for the correcting factors for a slug injection in converging or diverging flow in unbounded domain are 22a f t 1 00092 0 45272 p 0 87334 22b f p 1 51016 0 3189 p 0 09496 7 2 approximate closed form expressions in bounded domain in the same manner as for an unbounded domain closed form expressions have been determined for a continuous injection and for a slug injection in bounded domain 7 2 1 approximate closed form expression for a continuous injection in bounded domain among the 1d closed form expressions that were tried it is the solution for a step injection at fixed concentration in 1d cartesian coordinate system that produces the best results it is ogata and banks 1961 equation 23 c d t d 0 5 e r f c p 4 t d 1 t d e x p p e r f c p 4 t d 1 t d this equation differs from equation 12 by a plus sign in front of the term exp erfc instead of a minus sign introducing the correction factors fp and ft eq 23 becomes 24 c d t d 0 5 e r f c p f p 4 f t t d 1 f t t d e x p p f p e r f c p f p 4 f t t d 1 f t t d after determination of the optimal set of 6 constants a b c d e and f a very good match is obtained for péclet numbers ranging from 2 to 1000 see fig 10 however the fit is not quite as good for péclet numbers lower than 2 the average nash criterion for the 20 curves is 0 9998 and the lowest criterion is 0 9988 the equations obtained for the correcting factors for a continuous injection in converging flow in bounded domain are 25a f t 1 17097 0 20663 p 1 87515 25b f p 1 43094 0 96565 p 0 47269 7 2 2 approximate closed form expression for a slug injection in bounded domain several classic closed form expressions were tried the derivative versus time of ogata and banks 1961 equation for a step injection in 1d cartesian coordinate lenda and zuber 1970 that was used by sauty 1980 26 c d t d p 4 π t d 3 2 e x p p 4 t d 1 t d 2 did not result in a close match for all péclet numbers after optimization of the set of 6 constants the curves for low péclet numbers were not modeled accurately the selected closed form expression is equation 18 for a slug injection in 1d cartesian coordinate bear 1972 after determination of the optimal set of 6 constants a b c d e and f a very good match is obtained for péclet numbers ranging from 1 to 1000 see fig 11 for the sake of readability the curves for péclet numbers from 200 to 1000 do not appear in fig 11 but they are also very accurately reproduced the average nash criterion for the 20 curves is 0 9993 and the lowest nash criterion is 0 9984 27 c d t d f t p f p 4 π f t t d e x p p f p 4 f t t d 1 f t t d 2 the equations obtained for the correcting factors for a slug injection in converging flow in bounded domain are 28a f t 0 99003 1 29039 p 0 72566 28b f p 1 51514 0 89053 p 0 29830 7 3 improvement of the new closed form expressions compared to available expressions the improvement of the new closed form expressions developed in the present paper has been demonstrated by comparison to two approximate closed form available in radial flow the closed form described by sauty 1980 for a slug injection in converging flow and the closed form described by wang and crampon 1995 for the whole btc duration the comparison is detailed in appendix b figs b1 and b2 show that the new closed form expressions are significantly closer to the exact solutions 7 4 expressions for a solute with a retardation factor the closed form expressions applies also to solutes or tracers having a retardation factor r resulting from a partition coefficient kd between the liquid phase and a solid phase in equation 6 setting r 1 and ω r ω which corresponds to a a r leaves the equation unchanged it is then possible to use all the derived expressions replacing ω by r ω to obtain the concentration for a solute with a known retardation factor equal to r on the other hand using the original dimensionless expressions to determine the unknown transport parameters ω and αl from a tracer test would yield the right value for αl but a value of ω multiplied by r it would then be impossible to determine the value of the retardation factor 7 5 expressions for a solute subject to degradation the closed form expressions may be adapted easily for solutes or tracers subject to an exponential decay during transport as c 0 e t t g tg being the first order decay time constant for the mobile phase assuming the same decay time constant in the solid phase eq 6 becomes 29 r c t α l a r 2 c r 2 ε a r c r r c t g using the dimensionless decay time constant t g d t g t a the dimensionless equivalent of eq 7 is 30 2 r c d t d 1 p r d 2 c d r d 2 ε 1 r d c d r d 2 r c d t g d it can be verified that if c d r d t d is solution of eq 7 then c d r d t d c d r d t d e t d t g d is solution of eq 30 31a c d c d e t d t g d 31b c d t d c d t d e t d t g d c d t g d e t d t g d 31c c d r d c d r d e t d t g d 31d 2 c d r d 2 2 c d r d 2 e t d t g d introducing eqs 31a 31d into eq 7 and dividing by e t d t g d results in eq 30 this proves that using the new closed form expressions derived in this paper that are very close to solution of eq 7 and multiplying them by e t d t g d gives approximate closed form expressions integrating degradation provided that the boundary conditions are also multiplied by e t d t g d this applies to the slug injections however for continuous injections it would apply only if the solute is degraded with the same decay rate before being injected which is usually not verified as bacterial degradation occurs only in the aquifer fig 12 refers to the btcs resulting from a slug injection in converging or diverging flow in an unbounded domain for two péclet numbers and various decay time constants it shows that the closed form expression applies accurately to solutes subject to exponential decay it has also been verified that for a bounded domain the equivalent expression applies also with the same accuracy 8 application to field tracer tests the new closed form expression established in this paper for a slug injection has been applied for the interpretation of a set of tracer tests i e for determining their dispersivity and kinematic porosity by calibration it was thus possible to quantify the improvement obtained by using this expression rather than other approximate expressions the set consists of twelve tracer tests mostly performed in alluvial formations tracer tests 1 through 8 come from gutierrez et al 2012 the btcs data relative to these tracer tests are provided as supplementary material the main characteristics of the tests distance to well formation thickness pumping rate test duration are gathered in table 1 the distance from the injection point to the pumping well is most of the time quite small median value is 14 m with only one exception the formations thickness are also small median thickness is 9 3 m and the total duration of the tests usually ranges from 1 day to 2 days with the exception of two much longer tests unfortunately the injected masses were not known using the rosenbrock optimization method for determining the optimal kinematic porosity and dispersivity the btcs of these twelve tracer tests were reproduced successfully with the new closed form formulation in unbounded domain eq 21 22a 22b the median nash and sutcliffe criterion is 0 977 with only one value below 0 9 the calibrated kinetic porosity dispersivity and injected mass values are given in table 2 the péclet numbers obtained are rather small median value is 4 3 and only one value is above 10 two approximate expressions for a slug injection in converging flow were used for comparison the expressions described by sauty 1980 and by wang and crampon 1995 sauty s 1980 expression is eq 26 the derivative versus time of ogata and banks 1961 equation for a step injection in 1d cartesian coordinate lenda and zuber 1970 without correction factors the wang and crampon 1995 equation for a radially convergent slug injection for the whole btc is based on eq 19 i e the solution of a slug injection in 1d cartesian coordinate with correction factors it is valid only for péclet numbers greater than 3 c d t d k p f p 4 πt d f t e xp p f p 4 t d f t 1 t d f t 2 with k normalization constant f t 2 0 503 0 33 p if p 100 else f t 1 f p 1 32 1 116 p the twelve btcs were also reproduced successfully using both these approximate expressions with comparable nash coefficients however the calibrated values of the kinetic porosity and of the dispersivity given in table 3 for the wang and crampon 1995 equation differ significantly from those obtained using the new closed form expression of this paper which is extremely close to the exact solution using the formulation of wang and crampon 1995 both of these parameters are overestimated the median value of the overestimation is 19 9 for dispersivity and only 4 4 for kinematic porosity fig 13 shows that as expected it is for small péclet numbers that the new closed form expression provides more accuracy where the overestimation of the dispersivity was the largest sauty s 1980 approximation heavily overestimates the dispersivity and kinematic porosity the median value of these two parameters overestimation is 69 and 67 respectively however sauty s 1980 approximate formulation was selected after comparison to a numerical modeling using an outer boundary condition not clearly documented but apparently corresponding to a bounded domain therefore another comparison was made with the kinematic porosity and dispersivity obtained with the new closed form expression of this paper in a bounded domain eq 27 28a 28b the deviations are then smaller the median value of the overestimation is reduced to 15 4 for dispersivity and to 23 2 for kinematic porosity 9 summary and conclusions this paper derived simple accurate approximate closed form expressions for tracer injection in aquifer with a radially converging or diverging flow in a bounded or unbounded domain starting from approximate closed form expressions for a slug injection or a continuous injection in 1d cartesian coordinate two correction coefficients depending only on the péclet number were introduced into this expression to obtain new closed form expressions that most accurately reproduce the exact solutions in radial coordinate the conditions of application of these expressions are that the aquifer must have homogeneous properties and a uniform thickness and the central pumping or injection well must have a negligible radius longitudinal dispersion is taken into account but the molecular diffusion is neglected transverse dispersion does not appear in the expressions because it has no influence the closed form expressions may be used for a tracer having a retardation factor and subject to exponential degradation an interesting result obtained by the numerical simulations is that for a given set of parameters a btc at the sampling well is identical in diverging or in converging flow this applies in unbounded domain and also in bounded domain using the 4 following dimensionless numbers t d t q π r l 2 h ω dimensionless time p r l α l péclet number c d c q q m dimensionless concentration for a continuous injection or c d c π r l 2 h ω m dimensionless concentration for a slug injection the approximate closed form for péclet number ranging from 1 to 1000 and dimensionless time ranging from 0 to 5 are unbounded domain slug injection c d t d 0 5 f t p f p 4 π f t t d f t t d 1 f t t d e x p p f p 4 f t t d 1 f t t d 2 e t d t g d f t 1 00092 0 45272 p 0 87334 f p 1 51016 0 3189 p 0 09496 when there is no degradation t g d and the last term is dropped continuous injection c d 0 5 e r f c p f p 4 f t t d 1 f t t d f t 1 00627 0 44829 p 0 73712 f p 1 44488 0 21574 p 0 78005 bounded domain these expressions in a bounded domain can be used for tracer tests in converging flow they would not be appropriate in diverging flow slug injection c d t d f t p f p 4 π f t t d e x p p f p 4 f t t d 1 f t t d 2 e t d t g d f t 0 99003 1 29039 p 0 72566 f p 1 51514 0 89053 p 0 29830 continuous injection c d t d 0 5 e r f c p f p 4 f t t d 1 f t t d e x p p f p e r f c p f p 4 f t t d 1 f t t d f t 1 17097 0 20663 p 1 87515 f p 1 43094 0 96565 p 0 47269 the new closed form formulation for a slug injection in unbounded domain has been applied to twelve radially convergent tracer tests the mass transfer parameters obtained were compared to those obtained by two approximate methods sauty s 1980 formulation and the formulation of wang and crampon 1995 it appeared that sauty s 1980 approximate formulation results in overestimations of both the kinematic porosity and the dispersivity using the approximate formulation of wang and crampon 1995 also overestimates dispersivity but to a lesser extent it has been shown that by choosing a bounded domain to reduce the spurious upstream dispersion instead of an unbounded domain corresponding to the real geometry significantly different values are obtained for the dispersivity but also for the porosity these differences however decrease for large péclet numbers it has also been shown that both schemes can reproduce the btc equally well therefore the analysis of the btc alone does not allow the selection of the most appropriate scheme funding information this research was conducted by the french geological survey brgm and was funded by internal research projects declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors are grateful to t klinka from brgm for providing field tracer tests data to apply the developed solutions they are also grateful to the two anonymous reviewers for their helpful suggestions appendix a validation of our 1d radial numerical scheme discretization and outer boundary conditions in bounded domain our 1d radial numerical scheme and discretization was validated in bounded domain in converging flow by comparison to chen et al 2002 analytical solution as depicted in their fig 2 and fig 4 fig a1 and fig a2 show that the numerical calculations with the selected spatial and temporal discretization and outer boundary condition reproduce accurately the exact analytical solution of chen et al 2002 for péclet numbers ranging from 0 1 to 200 appendix b evaluating the improvement of the new closed form expressions the improvement of the new closed form expressions developed in this paper is demonstrated by comparison to the two approximate closed form available for the btc resulting from a slug injection in radial flow sauty s 1980 closed form for a slug injection in converging flow and the closed form described by wang and crampon 1995 for the whole btc duration the equations corresponding to these approximate expressions are given in section 8 sauty s 1980 approximation for a slug injection in converging flow in the numerical model used by sauty 1980 to select its approximate expression the outer boundary condition although not clearly documented corresponds apparently to a bounded domain for this reason their approximation was compared to the solution in a bounded domain and the closeness to their solution was compared the new closed form in a bounded domain fig b1 shows that the new closed form expression in bounded domain eq 27 28a 28b is significantly closer to the exact solution than sauty s 1980 expression this is true as well for small péclet numbers not exceeding 3 as for large values exceeding 30 wang and crampon 1995 approximation wang and crampon 1995 used a numerical model in unbounded domain to fit their expressions among the four expressions ascending part of btc or whole btc converging or diverging only the two expressions for the whole btc were selected and compared to the single exact solution the closeness of their expressions valid for péclet number greater than or equal to 3 were compared to the single new closed form in unbounded domain in unbounded domain also fig b2 shows that the new closed form expression eq 21 22a 22b is much closer to the exact solution than wang and crampon 1995 expression the difference is considerable for small péclet numbers not exceeding 3 which are below the limit of validity of their expression but is also significant for larger values the difference decreases however for large values exceeding 30 appendix c comparison of the transport parameters obtained in a tracer test analysis using expressions for a bounded or unbounded domain the transport parameters kinematic porosity and dispersivity obtained from the analysis of a tracer test depend on the assumption chosen for the domain bounded or unbounded to analyze the sensitivity to this assumption the dimensionless btcs for slug injections were calculated with the exact bounded domain solution for 20 values of péclet numbers corresponding to given values of kinematic porosity and dispersivity these 20 btcs are assumed to represent actual tracer tests using the exact solution corresponding to the alternative assumption of an unbounded domain the 20 btcs are analyzed to determine the corresponding kinematic porosity and dispersivity it can be seen from fig c1 that all btcs corresponding to péclet numbers greater than or equal to 1 5 could be reproduced very accurately with the unbounded domain solution but with transport parameters different from the original parameters this shows that the sole analysis of a btc cannot help to determine which geometry bounded or not should be selected fig c2 shows the changes in the initial parameters required to reproduce the btcs it appears that in the unbounded domain the corresponding calibrated dispersivity is decreased by 50 20 and 8 respectively for péclet numbers equal to 1 5 10 and 30 the corresponding calibrated kinematic porosity is decreased by 38 15 and 7 for these same péclet numbers the reason for the decrease in dispersivity is that without upstream dispersion the btcs are less dispersed especially for small péclet numbers the decrease in kinematic porosity is also explained by the fact that without upstream dispersion the bulk advection velocity is increased resulting in a decrease in porosity appendix d supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127661 appendix d supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 
3511,streamflow prediction plays a crucial role in water resources systems planning and the mitigation of hydrological extremes such as floods and droughts since a variety of uncertainties exist in streamflow prediction it is necessary to enhance our efforts to robustly address uncertainties and their interactions for improving the reliability of streamflow prediction this paper presents a stochastic hydrological modeling system shms for improving daily streamflow prediction by explicitly addressing uncertainties in error and model parameters as well as in forcing data and model outputs specifically the shms merges the strengths of the ensemble kalman filter and the particle filter algorithms for improving the effectiveness and robustness of daily streamflow assimilation factorial analysis of variance and variance based global sensitivity analysis are performed to reveal parameter interactions affecting predictive performance and temporal dynamics of parameter sensitivities maximizing the accuracy of streamflow prediction the shms has been applied to the guadalupe river basin located in texas of the united states to demonstrate feasibility and applicability our findings indicate that the shms improves upon the well known ensemble kalman filter for sequential estimation of hydrological model parameters through a more rapid and accurate convergence of model parameters in streamflow simulation the shms also demonstrates a higher level of skill in streamflow prediction compared to the conditional vine copula model the proposed shms can be applied straightforwardly to other river basins for probabilistic hydrological prediction keywords hydrological prediction streamflow uncertainty parameter sensitivity 1 introduction hydrological models have been widely used to advance our understanding of the hydrological cycle in a changing environment as models are conceptual representations of spatially and temporally varying hydrological processes uncertainty is inevitable in predicting the behavior of catchments uncertainty arises from various sources including the errors in model structures and parameters boundary and initial conditions and hydrometeorological forcing ajami et al 2007 kavetski et al 2011 mockler et al 2016 thus uncertainty assessment plays a crucial role in providing reliable hydrological prediction for sound water resources planning and management uncertainty quantification techniques have been extensively used to explicitly address uncertainties in hydrological prediction vrugt et al 2005 moradkhani et al 2005 dechant and moradkhani 2012 khan and valeo 2016 wang et al 2018 huang and qin 2018 abbaszadeh et al 2019 ghaith and li 2020 gou et al 2020 tran et al 2020 ghaith et al 2021 over the past decade the ensemble kalman filter enkf which is a data assimilation method introduced by evensen 1994 has been widely used for diagnostic evaluation and uncertainty quantification of hydrological models cammalleri and ciraolo 2012 thiboult and anctil 2015 liu et al 2016 pathiraja et al 2016 zhang et al 2017 zou et al 2017 tran and kim 2021 previous studies have demonstrated that hydrological data assimilating using the enkf is able to tackle uncertainties in model parameters inputs and outputs as an alternative to the enkf the particle filter pf technique has been receiving increasing attention in recent years due to its capability to properly estimate the state of nonlinear and non gaussian systems moradkhani et al 2012 vrugt et al 2013 wang et al 2017 abbaszadeh et al 2018 compared with the enkf the pf removes the gaussian assumption of the enkf that often fails to hold for nonlinear systems however the pf may suffer from the issue of filter degeneracy where only a few particles have a significant weight while all the others have small weights which deteriorates the performance of the pf as a result a large number of particles are often required to resolve the degeneracy problem but the ensemble size increases exponentially with the number of state variables making the pf impractical for high dimensional models great efforts have been made to the advances in data assimilation techniques over the past decade nevertheless little attention has been paid to the assessment and identification of error parameters and their interactions that have a significant influence on the performance of data assimilation systems to address uncertainties in model inputs and outputs through data assimilation an ensemble of model parameters and state variables can be generated through stochastic perturbations of forcing data and observations the specification of perturbation parameters i e error parameters is thus the key feature of data assimilation schemes which plays a crucial role in improving model performance since error parameters interact with each other and their interactions have a considerable influence on the behavior of nonlinear dynamic systems failure to address potential interactions among error parameters can significantly degrade the performance of data assimilation systems it is thus necessary to identify the best settings of error parameters through examining the contributions of error parameters and their interactions to the performance of data assimilation algorithms in addition to the assessment of error parameters influencing data assimilation sensitivities and interactions of model parameters should also be investigated to improve our understanding of dominant model components and their joint behavior in this work we develop a stochastic hydrological modeling system shms based on sequential data assimilation for improving daily streamflow prediction under uncertainty error parameters and their interactions will be examined to identify the best settings of the data assimilation system model parameter sensitivities and their temporal dynamics will also be revealed to advance our understanding of the dominant hydrological processes that contribute to the catchment response under time varying hydroclimatic characteristics both synthetic and real data assimilation experiments will be carried out to demonstrate applicability of the proposed methodology in the guadalupe river basin texas the proposed shms will also be compared against the well known ensemble kalman filter and the conditional vine copula model to demonstrate superiority this paper is organized as follows section 2 introduces the proposed methodology for improving daily streamflow prediction section 3 provides details on the design and setup of data assimilation experiments section 4 presents an in depth analysis and discussion based on model results and comparison finally conclusions are drawn in section 5 2 methodology 2 1 sequential data assimilation algorithms the basic idea of data assimilation is to produce the best possible estimate of the state of a system through combining different sources of information these sources include observations and models that inevitably contain errors the enkf is a sophisticated data assimilation technique that makes use of monte carlo integration methods to approximate the error covariance matrix through a stochastic ensemble of model realizations evensen 2003 the enkf is particularly useful for nonlinear dynamic models and can thus be used for the recursive estimation of hydrological model states and parameters by using the enkf the ensemble of model states is integrated forward in time to predict error statistics and the model forecast can be made as follows 1 x i t 1 f x i t u i t 1 θ i t 1 ε i t 1 where x i t represent posterior model states at the previous time step x i t 1 represent the predicted model states at the current time step f represents the hydrological model with model inputs u i t 1 and parameters θ i t 1 ε i t 1 represent model errors and i and t denote the ensemble number and the time step respectively as for the recursive parameter estimation using the enkf it is assumed that model parameters are perturbed by a small random noise 2 θ i t 1 θ i t τ s θ i t where τ is a small tuning parameter of 0 01 and s θ i t is the standard deviation of the prior parameter distribution at the previous time step dechant and moradkhani 2012 the ensemble members of model states and parameters can then be updated as follows 3 x i t 1 x i t 1 k t 1 x y t 1 h x i t 1 4 θ i t 1 θ i t 1 k t 1 θ y t 1 h x i t 1 where y t 1 is the observation vector h is the observation operator that converts model states to observation space and k t 1 is the kalman gain matrix that can be written by 5 k t 1 x p t 1 x h t 1 t h t 1 p t 1 x h t 1 t r t 1 1 6 k t 1 θ p t 1 θ h t 1 t h t 1 p t 1 θ h t 1 t r t 1 1 where p t 1 is the forecast error covariance r t 1 is the observation error covariance and superscript t denotes the matrix transpose the pf is a promising alternative to the enkf which can be used to derive the posterior distributions of model states by a set of weighted particles the evolving posterior state distribution can be derived by 7 p x t 1 y t 1 l y i t 1 x i t 1 p x t 1 y t p y t 1 y t where p x t 1 y t is the prior state distribution p y t 1 y t is a normalization constant and l y i t 1 x i t 1 is the likelihood function that can be defined as follows 8 l y i t 1 x i t 1 1 2 π m 2 r 1 2 exp 1 2 y i t 1 h x x i t 1 t r 1 y i t 1 h x x i t 1 where r is the observation error covariance matrix m denotes the length of the observation vector y i t 1 and denotes the determinant operator to address nonlinear and non gaussian problems the sequential monte carlo smc method can be used to approximate the posterior state distribution doucet et al 2001 9 p x t 1 y t 1 i 1 n w i t 1 δ x t 1 x i t 1 where y t 1 is the observed value at time t 1 δ denotes the dirac delta function gordon et al 1993 n is the number of particles and w i t 1 is the normalized importance weight for particle i at time t 1 since the posterior density is unknown and difficult to sample directly from p x t 1 y t 1 the particles are usually generated from a known importance density denoted by q x t 1 y t 1 the unnormalized importance weights of particles can be updated in a recursive form as follows 10 w i t 1 w i t f x i t 1 x i t l y t 1 x i t 1 q x i t 1 x i t y t 1 where f x i t 1 x i t l y t 1 x i t 1 q x i t 1 x i t y t 1 is the incremental importance weights doucet et al 2001 f x i t 1 x i t is the transition probability density of model states model operator and l y t 1 x i t 1 is the likelihood function which is the probability density of observations given state variables vrugt et al 2013 the normalized importance weights of particles can then be calculated by 11 w i t 1 w i t 1 i 1 n w i t 1 the pf algorithm generates a weighted sample of model realizations by updating the particle weights sequentially most particles often carry negligible weights after a few iterations resulting in severe particle degeneracy the sampling importance resampling sir algorithm can thus be used to address the problem of particle degeneracy gilks and berzuini 2001 liu and chen 1998 in the sir algorithm the update of particles is followed by a resampling step at each time step and all weights become equal after resampling the resampling step within the pf removes particles with small importance weights and then replaces them by particles with large weights which is useful to deal with the degeneracy problem 2 2 stochastic hydrological modeling system as introduced above the enkf and pf algorithms approximate the probability density function pdf of the state variable in different ways the enkf uses the observed values of state variables to update the forecasted states of each ensemble member and approximates the state pdf by a set of equally weighted ensemble members in comparison the pf does not use a state analysis step instead the pf constructs the state pdf by calculating the likelihood the weight of each particle which measures in a probabilistic sense the distance between the observed and forecasted state variables as a result the pf requires a resampling step to rejuvenate the ensemble since the forecasted states of particles may be systematically biased from a theoretical point of view the enkf estimates the posterior distribution of a state variable at the current observation in comparison the pf infers the posterior distribution of the entire state trajectory which imposes much stronger constraints on the resampling step of a pf as any resampling of the states must be statistically adequate in other words the enkf can simply reset the states close to the measured states however this cannot be achieved by a pf because the resampled state would create a state trajectory that is statistically impossible given the model operator and model error thus a stochastic hydrological modeling system shms is proposed to merge the strengths of the enkf and pf algorithms for improving the effectiveness of hydrological prediction through data assimilation the steps to implement the shms are shown in fig 1 in the shms the ensemble of model trajectories is produced by stochastically perturbing the precipitation and potential evapotranspiration data as well as streamflow observations and these perturbations account for uncertainties in model inputs and outputs as a result the proper specification of error parameters i e magnitude of perturbations plays a crucial role in the assimilation accuracy factorial anova is an effective statistical technique for examining the effects of independent variables and their interactions on dependent variables through experimental design and data analysis montgomery and runger 2013 thus factorial anova is used in this study to identify the best settings of error parameters with each having specified scenarios through investigating their contributions to model performance including the precipitation error the potential evapotranspiration error and the observation error the factorial anova model can be expressed as 12 y ijkl μ τ i β j γ k τ β ij τ γ ik β γ jk τ β γ ijk ε ijkl i 1 2 a j 1 2 b k 1 2 c l 1 2 n where μ is the overall mean effect τ i is the effect of the ith scenario of precipitation error a β i is the effect of the jth scenario of potential evapotranspiration error b γ k is the effect of the kth scenario of observation error c τβ ij is the effect of the interaction between error parameters a and b τγ ik is the effect of the interaction between error parameters a and c βγ jk is the effect of the interaction between error parameters b and c τβγ ijk is the effect of the interaction among error parameters a b and c and ε ijkl is the random error component the factorial anova model contains three main effects three two factor interaction effects a three factor interaction effect and an error term these effects can be defined as deviations from the overall mean so i 1 a τ i 0 j 1 b β i 0 k 1 c γ k 0 i 1 a τ β ij j 1 b τ β ij 0 i 1 a τ γ ik k 1 c τ γ ik 0 j 1 b β γ jk k 1 c β γ jk 0 and i 1 a τ β γ ijk j 1 b τ β γ ijk k 1 c τ β γ ijk 0 montgomery 2000 to examine the contributions of error parameters and their interactions to model performance the f statistic can be used as follows 13 f a s s a a 1 s s e a b c n 1 f b s s b b 1 s s e a b c n 1 f c s s c c 1 s s e a b c n 1 14 f ab s s ab a 1 b 1 s s e a b c n 1 f ac s s ac a 1 c 1 s s e a b c n 1 f bc s s bc b 1 c 1 s s e a b c n 1 15 f abc s s abc a 1 b 1 c 1 s s e a b c n 1 where ssa ssb ssc ssab ssac ssbc ssabc and sse are the sum of squares for error parameters a b c and the a b a c b c a b c interactions as well as the random error component respectively sst represents the total sum of squares these statistics are useful for decomposing the total variance into its contributing components revealing the statistical significance of investigated parameters affecting model performance wu and hamada 2009 the best settings of error parameters can be identified with maximized performance accordingly in addition to factorial anova used to examine the influence of error parameters on model performance variance based global sensitivity analysis is also performed in this study to quantify the importance of model parameters the global sensitivity analysis uses the variance decomposition technique to attribute the total variance in the model output to individual parameters and their interactions the first and total order sensitivity indices are used to reveal the effects of a single parameter and its interactions with other parameters respectively these sensitivity indices are calculated using numerical integration with a sample size of 3 000 in a monte carlo framework furthermore time varying sensitivity analysis is performed to explore the temporal dynamics of parameter sensitivities which is useful for not only improving our understanding of dominant model components under changing hydroclimatic conditions but also providing meaningful insights time varying parameter sensitivities into uncertainty propagation in hydrological prediction 2 3 benchmark approach to demonstrate the superiority of the proposed shms it is necessary to perform a quantitative comparison with existing approaches the conditional vine copula model was selected as a comparative benchmark since it has been extensively applied to hydrological prediction by constructing a multivariate conditional distribution of hydroclimatic variables manning et al 2018 the conditional vine copula model graphically decomposes a high dimensional joint distribution into a cascade of bivariate copulas and univariate margins thereby allowing for flexible hydrological simulations assume that x x 1 xn 1 xn signifies n hydroclimate variables that affect the streamflow regimes and y signifies the streamflow observation the joint pdf between x and y can be expressed as 16 p x 1 x n y p 1 x 1 p n x n p y y c u 1 u n v y where p represents the marginal pdf ui and v represent the marginal cumulative probability of xi and y respectively i 1 n c represents the copula density since c u 1 un vy are inflexible in high dimensions and the high dimensional copula families are limited vine copula also known as pair copula construction pcc has been proposed to graphically represent equation 16 as vines comprising a nested set of trees with nodes that are joined by edges bedford cooke 2002 for example if two hydroclimate variables x 1 x 2 are used the joint density between x 1 x 2 and observation y can be decomposed through a 3 dimensional vine copula as 17 p x 1 x 2 y p x 1 p x 2 p y c u 1 u 2 α 1 2 c u 1 v α 1 y c h u 2 u 1 α 1 2 h v u 1 α 1 y α 2 y 1 where α represents the parameter set of bivariate copulas the h function is the conditional distribution function expressed as 18 f x v h x v α c x v f x f v α f v since there are multiple vine copula structures to decompose p x 1 x 2 y we use the sequential maximal spanning tree algorithm proposed by dißmann et al 2013 along with the akaike information criterion aic to identify an appropriate structure when the vine structure is determined a conditional cumulative distribution function cdf of y can be constructed by recursively applying the h function 19 p y x 1 x 2 c y 2 1 p y x 1 p x 2 x 1 p x 2 x 1 h h v u 1 α 1 y h u 2 u 1 α 1 2 α 2 y 1 thus the inverse form of equation 19 can be used to generate probabilistic hydrologic predictions 20 y f x 1 x 2 τ p y 1 h 1 h 1 τ h p 2 x 2 p 1 x 1 α 1 2 α 2 y 1 p 1 x 1 α 1 y τ 0 1 where τ represents random probability levels e g τ 0 01 0 1 0 99 p represents marginal cdfs to achieve reliable model results mc simulations were used to generate multiple e g 500 samples of τ from the uniform distribution u 0 1 leading to multiple realizations of y the median values of these realizations are obtained as hydrological predictions and uncertainty intervals can also be derived 3 experimental setups 3 1 study area the proposed shms was applied to predict daily streamflow in the guadalupe river basin texas as shown in fig 2 the guadalupe river with a drainage area of about 15 500 km2 originates in kerr county and flows into the guadalupe estuary with a mean daily discharge of 53 m3 s the guadalupe river basin is characterized by a significant difference in elevation the river originates at an elevation of 2 400 feet near its headwaters while it reaches an elevation as low as 5 feet at the outlet of the basin where the guadalupe river discharges into the gulf of mexico the guadalupe river and its tributaries are a vital source of water for a number of populous cities including kerrville new braunfels san marcos seguin lockhart gonzales cuero luling and victoria streamflow conditions in the guadalupe river basin are mainly influenced by spring discharge rainfall runoff processes evapotranspiration withdrawals for water supply reservoir operations and losses to aquifer recharge ockerman and slattery 2008 the study area has a subtropical subhumid climate characterized by hot summers and dry winters annual precipitation ranges from 770 mm near the headwaters to 1 000 mm near the gulf of mexico the heaviest rainfall tends to occur in spring and early summer thus periods with large or small amounts of rainfall are common resulting in recurring floods and droughts 3 2 data and model in this study the meteorological and hydrological data for the guadalupe river basin were collected from the model parameter estimation experiment mopex dataset duan et al 2006 a total of three years of data from january 1981 to december 1983 were used to assimilate daily streamflow such that the first year was used as a spin up period to reduce sensitivity to state value initialization data assimilation experiments were conducted by using the hymod which is a widely used rainfall runoff model for probabilistic hydrological prediction bulygina and gupta 2011 sadegh and vrugt 2013 young 2013 zhang et al 2021 in the rainfall runoff model the runoff production is characterized as a rainfall excess process and the runoff is determined according to a probability distributed storage capacity model that partitions excess rainfall into surface and subsurface storage through a partitioning factor moore 2007 the surface storage is characterized by three quick flow tanks and the subsurface storage is represented by a single slow flow tank thus the generated streamflow is the addition of discharges from slow and quick flow tanks the model has five parameters including the maximum soil moisture storage capacity c max the degree of spatial variability in the storage capacity b exp the factor used to distribute flow between the quick and slow flow routing β the residence time of the slow flow tank r s and the residence time of quick flow tanks r q the initial ranges of model parameters and their true values are given in table 1 in addition daily precipitation and potential evapotranspiration are the forcing input data used to drive the model 3 3 experimental design both synthetic and real data assimilation experiments were conducted to demonstrate the proposed methodology the synthetic experiment was designed to examine the ability of the assimilation system to estimate hydrological model parameters which has been widely used to validate the performance of data assimilation systems first the synthetic experiment with predefined model parameters was carried out to generate the true model states and streamflow time series as synthetic observations second the assimilation experiment was conducted based on the generated synthetic streamflow time series such that the convergence of model parameters towards the predefined parameter values can be evaluated third the assimilation experiment with real streamflow data was conducted when the performance of the assimilation system was validated through the synthetic experiment to address various sources of uncertainty in data assimilation random perturbations were adopted by adding noise errors to the precipitation and potential evapotranspiration data and streamflow observations leading to an ensemble of state variables as a result the specification of error parameters is a key feature of assimilation systems which plays an important role in the performance of hydrological prediction a statistical hypothesis test was conducted in this study to identify the best settings of error parameters including the precipitation error the potential evapotranspiration error and the streamflow observation error three scenarios were given on the strength of perturbations including 10 30 and 50 a three way factorial anova was thus performed to explicitly examine the sensitivities of error parameters and their interactions affecting the predictive accuracy which provided meaningful information for achieving the best performance of hydrological prediction when the posterior distributions of error parameters were identified through data assimilation the sensitivities of model parameters and their interactions were then investigated through variance based global sensitivity analysis advancing our understanding of dominant hydrological components and their temporal evolution 4 results and discussion 4 1 evaluation of the shms for parameter estimation a synthetic data assimilation experiment was performed to demonstrate the ability of shms to estimate the predefined model parameters fig 3 shows the convergence of model parameters through assimilating streamflow observations all parameters are identifiable as they rapidly converge to the posterior target distributions and the estimated mean values of all parameters converge toward the true values which are predefined as c max 610 mm b exp 2 05 β 0 50 r s 0 15 days 1 and r q 0 30 days 1 it can be seen that the first two parameters c max and b exp related to soil moisture storage capacity can be better estimated compared to the others as new observations become available the shms recursively correct and update parameter samples thus the uncertainty degree i e difference between maximum and minimum values of model parameters is relatively high at the early stage of filtering and diminishes gradually along the assimilation trajectory results verify the ability of shms to achieve convergence to the target distributions and can thus be used for uncertainty assessment of hydrological model parameters and predictions to further demonstrate the advantage of the proposed approach the data assimilation results obtained from the shms are compared against those obtained with the well known enkf fig 4 depicts the evolution of model parameters estimated using the enkf in comparison the proposed shms largely improves upon the enkf through the more rapid and accurate convergence of model parameters towards the posterior target distributions with reduced uncertainty especially for estimating the factor used to distribute flow between the quick and slow flow routing β the residence time of the slow flow tank r s and the residence time of quick flow tanks r q 4 2 identification of error and model parameters in streamflow assimilation when the performance of the shms was validated through the synthetic experiment a real data assimilation experiment was also conducted to predict daily streamflow in the guadalupe river basin texas a three way factorial anova was performed to examine the impacts of model and observation error parameters as well as their interactions in streamflow assimilation so as to identify the best settings of the shms with maximized performance fig 5 presents the normal probability plot of residuals for checking the normality of the residual distribution in the three way anova since this plot is approximately linear it verifies that the residuals are normally distributed as shown in table 2 the precipitation error is identified as the most statistically significant parameter according to the p value thus the precipitation error parameter has the largest first order effect on the predictive accuracy this indicates that any change in the settings of precipitation error parameter could lead to the largest variation of the root mean square error rmse value in addition the potential evapotranspiration and the streamflow observation error parameters as well as their interactions have considerable contributions to model performance based on the interaction analysis through factorial anova the minimum value of rmse can be obtained when the settings of precipitation potential evapotranspiration and observation error parameters are 50 10 and 50 respectively identification of the best settings of error parameters provides meaningful information for advancing our understanding of the data assimilation system and for maximizing model performance in previous studies error parameters were often randomly selected without a systematic assessment resulting in unreliable conclusions due to the oversimplified settings of error parameters for instance a single scenario of error parameters was often used previously to carry out hydrological data assimilation however sensitivities of error parameters and their interactions play a crucial role in the performance of data assimilation it is thus necessary to examine various scenarios of error parameters and to explore potential interactions between error parameters affecting the predictive accuracy leading to more robust and reliable hydrological prediction with the best parameter settings fig 6 shows the temporal evolution of model parameters derived through the daily streamflow assimilation using the shms with the best settings of error parameters it is indicated that all parameters are identifiable and they converge rapidly to the target distributions the derived posterior parameter distributions vary greatly from the synthetic experiment to the real data experiment due to the assimilation of different streamflow time series fig 7 presents a comparison of simulated and observed daily streamflow time series the daily streamflow distributions were evaluated using the probabilistic performance measure of reliability introduced by renard et al 2010 and breinholt et al 2012 reliability represents the percentage of observations falling within the uncertainty bounds of simulated streamflow time series which varies between 0 lowest reliability and 1 highest reliability in this study the reliability of streamflow distribution is 0 75 which is acceptable although far from perfect but the shms may underpredict the streamflow regimes furthermore hypothesis testing with a significance level of 0 05 was conducted to measure the significance of the difference between observed and simulated streamflow time series the p value derived by the hypothesis testing is less than 0 05 which indicates that the accuracy of streamflow prediction is statistically acceptable this verifies the ability of the shms to recursively assimilate streamflow observations and can thus be used for probabilistic streamflow prediction in the guadalupe river basin 4 3 comparison with probabilistic prediction approach to demonstrate the superiority of the proposed shms the conditional vine copula model was selected as a comparative benchmark to construct a conditional vine copula model the marginal distributions of hydrological variables i e streamflow precipitation potential evapotranspiration and temperature were selected from a total of 8 types of probability distributions including gamma weibull log normal gumbel generalized extreme value gev log logistic generalized pareto gp and generalized gamma the marginal distribution of hydrological variables was selected using the akaike information criterion aic see table 3 results show that the gev distribution was optimal for all hydrological variables including streamflow precipitation potential evapotranspiration and temperature for example fig 8 presents the fitted gev cumulative distribution function of daily streamflow and the q q plot indicating that the gev distribution provides a good representation of daily streamflow the hydrological variables were transformed to uniform margins on 0 1 based on their optimal parametric probability distributions and then were used to construct the conditional vine copula model the one with the lowest aic value was selected as the optimal vine structure fig 9 presents a comparison of daily streamflow time series generated from the observation and the constructed conditional vine copula model results show that the reliability is 0 71 which is lower than 0 75 generated from the proposed shms the shms also outperforms the conditional vine copula model in terms of capturing extreme flows specifically the shms captures 81 and 83 of high i e higher than the 90th percentile and low i e lower than the 10th percentile flows respectively whereas the conditional vine copula model captures only 71 and 36 of high and low flows respectively this indicates that the proposed shms can improve the reliability of daily streamflow simulations by robustly addressing various uncertainties and their interactions 4 4 sensitivities of model parameters and their interactions variance based global sensitivity analysis was also carried out to examine the sensitivities of model parameters and their interactions as shown in fig 10 the residence time of the quick flow tank r q has the largest individual and interaction effects on model performance this indicates that the simulated daily streamflow is highly sensitive to the variation of the residence time of the quick flow tank thus the quick flow tank parameter plays a crucial role in streamflow predictions in the guadalupe river basin in addition the quick flow tank parameter is closely correlated with other parameters and their interactions make a considerable contribution to model performance in comparison the residence time of the slow flow tank r s and its interactions with other parameters make little contribution to model performance results indicate that the surface runoff routing plays a dominant role in minimizing the overall error while the subsurface runoff process has little influence on streamflow predictions in the guadalupe river basin consequently sensitivity analysis for model parameters and their interactions is useful for providing meaningful insights into model components dominating the overall accuracy as the parameter sensitivity varies over time due to the changing hydrological conditions the temporal dynamics of parameter sensitivity were examined using the time varying sensitivity analysis method introduced by pianosi and wagener 2016 as shown in fig 11 sensitivities of five model parameters vary in response to changes in daily streamflow the accuracy is highly sensitive to the degree of spatial variability of soil moisture capacity b exp and the residence time of the quick flow tank r q especially for the days with heavy rainfall our findings reveal that the soil moisture capacity and the surface runoff routing parameters as well as precipitation play a key role in simulating daily streamflow in the dry guadalupe river basin in addition minimizing errors in heavy rainy days would greatly improve the overall accuracy of daily streamflow predictions analysis of the temporal dynamics of parameter sensitivity advances our understanding of dominant hydrologic processes that contribute to the catchment response under time varying hydroclimatic conditions 5 conclusions in this study we proposed a shms for improving daily streamflow prediction through sequential data assimilation the shms greatly improves upon the well known enkf through the more rapid and accurate convergence of model parameters in streamflow assimilation factorial anova was performed to explicitly reveal the impacts of model and observation error parameters as well as their interactions on streamflow assimilation variance based sensitivity analysis was also conducted to examine the sensitivities of hydrological model parameters and their interactions as well as to reveal the temporal dynamics of parameter sensitivity such a computational framework is capable of explicitly identifying underlying interactions between error parameters in streamflow assimilation and robustly predicting daily streamflow time series in a probabilistic manner the proposed framework was also compared with the existing well known approach used for streamflow prediction both synthetic and real data assimilation experiments were conducted to demonstrate applicability of the proposed methodology in the guadalupe river basin texas results obtained from factorial anova reveal that the precipitation error parameter has the largest first order effect on the assimilation accuracy potential evapotranspiration and streamflow observation error parameters as well as their interactions have considerable contributions to model performance factorial anova provides insights into model and observation error parameters that affect the performance of the hydrological data assimilation system maximizing the accuracy of streamflow assimilation by comparing the time series of observed and simulated daily streamflow using deterministic and probabilistic measures the results verify the ability of the shms to properly assimilate streamflow observations in the guadalupe river basin the shms also shows better performance than the conditional vine copula model in terms of the reliability of streamflow prediction on the other hand the soil moisture capacity and the surface runoff routing parameters as well as precipitation play a crucial role in simulating daily streamflow in the dry guadalupe river basin moreover sensitivities of model parameters vary over time due to the changing hydroclimatic conditions the model response is more sensitive to the variation of model parameters for the days with heavy rainfall thus minimizing errors in heavy rainy days would greatly improve the overall accuracy these findings provide meaningful insights into the dynamics of model components dominating the overall performance the shms has significant potential for performing hydrological predictions and will be applied to the physically based distributed hydrological models for better addressing the spatial heterogeneity of watershed characteristics in future studies nevertheless the computational cost will increase exponentially with the increasing number of hydrological model parameters due to the computationally extensive factorial anova and the variance based global sensitivity analysis it is thus necessary to further improve the factorial design and the variance based sensitivity analysis method for increasing the computational efficiency of hydrological prediction using the shms moreover a total of three years of data collected from the mopex dataset are used in this study to predict daily streamflow which may not adequately reflect the hydrological characteristics the longer time series data is thus desired in future studies to further improve the robustness of hydrological prediction credit authorship contribution statement y shen methodology validation formal analysis investigation writing original draft s wang conceptualization formal analysis writing review editing supervision project administration funding acquisition b zhang validation formal analysis writing original draft j zhu writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the national natural science foundation of china grant no 51809223 and the hong kong research grants council early career scheme grant no 25222319 the daily meteorological and hydrological data for the guadalupe river basin were collected from the u s mopex dataset 
3511,streamflow prediction plays a crucial role in water resources systems planning and the mitigation of hydrological extremes such as floods and droughts since a variety of uncertainties exist in streamflow prediction it is necessary to enhance our efforts to robustly address uncertainties and their interactions for improving the reliability of streamflow prediction this paper presents a stochastic hydrological modeling system shms for improving daily streamflow prediction by explicitly addressing uncertainties in error and model parameters as well as in forcing data and model outputs specifically the shms merges the strengths of the ensemble kalman filter and the particle filter algorithms for improving the effectiveness and robustness of daily streamflow assimilation factorial analysis of variance and variance based global sensitivity analysis are performed to reveal parameter interactions affecting predictive performance and temporal dynamics of parameter sensitivities maximizing the accuracy of streamflow prediction the shms has been applied to the guadalupe river basin located in texas of the united states to demonstrate feasibility and applicability our findings indicate that the shms improves upon the well known ensemble kalman filter for sequential estimation of hydrological model parameters through a more rapid and accurate convergence of model parameters in streamflow simulation the shms also demonstrates a higher level of skill in streamflow prediction compared to the conditional vine copula model the proposed shms can be applied straightforwardly to other river basins for probabilistic hydrological prediction keywords hydrological prediction streamflow uncertainty parameter sensitivity 1 introduction hydrological models have been widely used to advance our understanding of the hydrological cycle in a changing environment as models are conceptual representations of spatially and temporally varying hydrological processes uncertainty is inevitable in predicting the behavior of catchments uncertainty arises from various sources including the errors in model structures and parameters boundary and initial conditions and hydrometeorological forcing ajami et al 2007 kavetski et al 2011 mockler et al 2016 thus uncertainty assessment plays a crucial role in providing reliable hydrological prediction for sound water resources planning and management uncertainty quantification techniques have been extensively used to explicitly address uncertainties in hydrological prediction vrugt et al 2005 moradkhani et al 2005 dechant and moradkhani 2012 khan and valeo 2016 wang et al 2018 huang and qin 2018 abbaszadeh et al 2019 ghaith and li 2020 gou et al 2020 tran et al 2020 ghaith et al 2021 over the past decade the ensemble kalman filter enkf which is a data assimilation method introduced by evensen 1994 has been widely used for diagnostic evaluation and uncertainty quantification of hydrological models cammalleri and ciraolo 2012 thiboult and anctil 2015 liu et al 2016 pathiraja et al 2016 zhang et al 2017 zou et al 2017 tran and kim 2021 previous studies have demonstrated that hydrological data assimilating using the enkf is able to tackle uncertainties in model parameters inputs and outputs as an alternative to the enkf the particle filter pf technique has been receiving increasing attention in recent years due to its capability to properly estimate the state of nonlinear and non gaussian systems moradkhani et al 2012 vrugt et al 2013 wang et al 2017 abbaszadeh et al 2018 compared with the enkf the pf removes the gaussian assumption of the enkf that often fails to hold for nonlinear systems however the pf may suffer from the issue of filter degeneracy where only a few particles have a significant weight while all the others have small weights which deteriorates the performance of the pf as a result a large number of particles are often required to resolve the degeneracy problem but the ensemble size increases exponentially with the number of state variables making the pf impractical for high dimensional models great efforts have been made to the advances in data assimilation techniques over the past decade nevertheless little attention has been paid to the assessment and identification of error parameters and their interactions that have a significant influence on the performance of data assimilation systems to address uncertainties in model inputs and outputs through data assimilation an ensemble of model parameters and state variables can be generated through stochastic perturbations of forcing data and observations the specification of perturbation parameters i e error parameters is thus the key feature of data assimilation schemes which plays a crucial role in improving model performance since error parameters interact with each other and their interactions have a considerable influence on the behavior of nonlinear dynamic systems failure to address potential interactions among error parameters can significantly degrade the performance of data assimilation systems it is thus necessary to identify the best settings of error parameters through examining the contributions of error parameters and their interactions to the performance of data assimilation algorithms in addition to the assessment of error parameters influencing data assimilation sensitivities and interactions of model parameters should also be investigated to improve our understanding of dominant model components and their joint behavior in this work we develop a stochastic hydrological modeling system shms based on sequential data assimilation for improving daily streamflow prediction under uncertainty error parameters and their interactions will be examined to identify the best settings of the data assimilation system model parameter sensitivities and their temporal dynamics will also be revealed to advance our understanding of the dominant hydrological processes that contribute to the catchment response under time varying hydroclimatic characteristics both synthetic and real data assimilation experiments will be carried out to demonstrate applicability of the proposed methodology in the guadalupe river basin texas the proposed shms will also be compared against the well known ensemble kalman filter and the conditional vine copula model to demonstrate superiority this paper is organized as follows section 2 introduces the proposed methodology for improving daily streamflow prediction section 3 provides details on the design and setup of data assimilation experiments section 4 presents an in depth analysis and discussion based on model results and comparison finally conclusions are drawn in section 5 2 methodology 2 1 sequential data assimilation algorithms the basic idea of data assimilation is to produce the best possible estimate of the state of a system through combining different sources of information these sources include observations and models that inevitably contain errors the enkf is a sophisticated data assimilation technique that makes use of monte carlo integration methods to approximate the error covariance matrix through a stochastic ensemble of model realizations evensen 2003 the enkf is particularly useful for nonlinear dynamic models and can thus be used for the recursive estimation of hydrological model states and parameters by using the enkf the ensemble of model states is integrated forward in time to predict error statistics and the model forecast can be made as follows 1 x i t 1 f x i t u i t 1 θ i t 1 ε i t 1 where x i t represent posterior model states at the previous time step x i t 1 represent the predicted model states at the current time step f represents the hydrological model with model inputs u i t 1 and parameters θ i t 1 ε i t 1 represent model errors and i and t denote the ensemble number and the time step respectively as for the recursive parameter estimation using the enkf it is assumed that model parameters are perturbed by a small random noise 2 θ i t 1 θ i t τ s θ i t where τ is a small tuning parameter of 0 01 and s θ i t is the standard deviation of the prior parameter distribution at the previous time step dechant and moradkhani 2012 the ensemble members of model states and parameters can then be updated as follows 3 x i t 1 x i t 1 k t 1 x y t 1 h x i t 1 4 θ i t 1 θ i t 1 k t 1 θ y t 1 h x i t 1 where y t 1 is the observation vector h is the observation operator that converts model states to observation space and k t 1 is the kalman gain matrix that can be written by 5 k t 1 x p t 1 x h t 1 t h t 1 p t 1 x h t 1 t r t 1 1 6 k t 1 θ p t 1 θ h t 1 t h t 1 p t 1 θ h t 1 t r t 1 1 where p t 1 is the forecast error covariance r t 1 is the observation error covariance and superscript t denotes the matrix transpose the pf is a promising alternative to the enkf which can be used to derive the posterior distributions of model states by a set of weighted particles the evolving posterior state distribution can be derived by 7 p x t 1 y t 1 l y i t 1 x i t 1 p x t 1 y t p y t 1 y t where p x t 1 y t is the prior state distribution p y t 1 y t is a normalization constant and l y i t 1 x i t 1 is the likelihood function that can be defined as follows 8 l y i t 1 x i t 1 1 2 π m 2 r 1 2 exp 1 2 y i t 1 h x x i t 1 t r 1 y i t 1 h x x i t 1 where r is the observation error covariance matrix m denotes the length of the observation vector y i t 1 and denotes the determinant operator to address nonlinear and non gaussian problems the sequential monte carlo smc method can be used to approximate the posterior state distribution doucet et al 2001 9 p x t 1 y t 1 i 1 n w i t 1 δ x t 1 x i t 1 where y t 1 is the observed value at time t 1 δ denotes the dirac delta function gordon et al 1993 n is the number of particles and w i t 1 is the normalized importance weight for particle i at time t 1 since the posterior density is unknown and difficult to sample directly from p x t 1 y t 1 the particles are usually generated from a known importance density denoted by q x t 1 y t 1 the unnormalized importance weights of particles can be updated in a recursive form as follows 10 w i t 1 w i t f x i t 1 x i t l y t 1 x i t 1 q x i t 1 x i t y t 1 where f x i t 1 x i t l y t 1 x i t 1 q x i t 1 x i t y t 1 is the incremental importance weights doucet et al 2001 f x i t 1 x i t is the transition probability density of model states model operator and l y t 1 x i t 1 is the likelihood function which is the probability density of observations given state variables vrugt et al 2013 the normalized importance weights of particles can then be calculated by 11 w i t 1 w i t 1 i 1 n w i t 1 the pf algorithm generates a weighted sample of model realizations by updating the particle weights sequentially most particles often carry negligible weights after a few iterations resulting in severe particle degeneracy the sampling importance resampling sir algorithm can thus be used to address the problem of particle degeneracy gilks and berzuini 2001 liu and chen 1998 in the sir algorithm the update of particles is followed by a resampling step at each time step and all weights become equal after resampling the resampling step within the pf removes particles with small importance weights and then replaces them by particles with large weights which is useful to deal with the degeneracy problem 2 2 stochastic hydrological modeling system as introduced above the enkf and pf algorithms approximate the probability density function pdf of the state variable in different ways the enkf uses the observed values of state variables to update the forecasted states of each ensemble member and approximates the state pdf by a set of equally weighted ensemble members in comparison the pf does not use a state analysis step instead the pf constructs the state pdf by calculating the likelihood the weight of each particle which measures in a probabilistic sense the distance between the observed and forecasted state variables as a result the pf requires a resampling step to rejuvenate the ensemble since the forecasted states of particles may be systematically biased from a theoretical point of view the enkf estimates the posterior distribution of a state variable at the current observation in comparison the pf infers the posterior distribution of the entire state trajectory which imposes much stronger constraints on the resampling step of a pf as any resampling of the states must be statistically adequate in other words the enkf can simply reset the states close to the measured states however this cannot be achieved by a pf because the resampled state would create a state trajectory that is statistically impossible given the model operator and model error thus a stochastic hydrological modeling system shms is proposed to merge the strengths of the enkf and pf algorithms for improving the effectiveness of hydrological prediction through data assimilation the steps to implement the shms are shown in fig 1 in the shms the ensemble of model trajectories is produced by stochastically perturbing the precipitation and potential evapotranspiration data as well as streamflow observations and these perturbations account for uncertainties in model inputs and outputs as a result the proper specification of error parameters i e magnitude of perturbations plays a crucial role in the assimilation accuracy factorial anova is an effective statistical technique for examining the effects of independent variables and their interactions on dependent variables through experimental design and data analysis montgomery and runger 2013 thus factorial anova is used in this study to identify the best settings of error parameters with each having specified scenarios through investigating their contributions to model performance including the precipitation error the potential evapotranspiration error and the observation error the factorial anova model can be expressed as 12 y ijkl μ τ i β j γ k τ β ij τ γ ik β γ jk τ β γ ijk ε ijkl i 1 2 a j 1 2 b k 1 2 c l 1 2 n where μ is the overall mean effect τ i is the effect of the ith scenario of precipitation error a β i is the effect of the jth scenario of potential evapotranspiration error b γ k is the effect of the kth scenario of observation error c τβ ij is the effect of the interaction between error parameters a and b τγ ik is the effect of the interaction between error parameters a and c βγ jk is the effect of the interaction between error parameters b and c τβγ ijk is the effect of the interaction among error parameters a b and c and ε ijkl is the random error component the factorial anova model contains three main effects three two factor interaction effects a three factor interaction effect and an error term these effects can be defined as deviations from the overall mean so i 1 a τ i 0 j 1 b β i 0 k 1 c γ k 0 i 1 a τ β ij j 1 b τ β ij 0 i 1 a τ γ ik k 1 c τ γ ik 0 j 1 b β γ jk k 1 c β γ jk 0 and i 1 a τ β γ ijk j 1 b τ β γ ijk k 1 c τ β γ ijk 0 montgomery 2000 to examine the contributions of error parameters and their interactions to model performance the f statistic can be used as follows 13 f a s s a a 1 s s e a b c n 1 f b s s b b 1 s s e a b c n 1 f c s s c c 1 s s e a b c n 1 14 f ab s s ab a 1 b 1 s s e a b c n 1 f ac s s ac a 1 c 1 s s e a b c n 1 f bc s s bc b 1 c 1 s s e a b c n 1 15 f abc s s abc a 1 b 1 c 1 s s e a b c n 1 where ssa ssb ssc ssab ssac ssbc ssabc and sse are the sum of squares for error parameters a b c and the a b a c b c a b c interactions as well as the random error component respectively sst represents the total sum of squares these statistics are useful for decomposing the total variance into its contributing components revealing the statistical significance of investigated parameters affecting model performance wu and hamada 2009 the best settings of error parameters can be identified with maximized performance accordingly in addition to factorial anova used to examine the influence of error parameters on model performance variance based global sensitivity analysis is also performed in this study to quantify the importance of model parameters the global sensitivity analysis uses the variance decomposition technique to attribute the total variance in the model output to individual parameters and their interactions the first and total order sensitivity indices are used to reveal the effects of a single parameter and its interactions with other parameters respectively these sensitivity indices are calculated using numerical integration with a sample size of 3 000 in a monte carlo framework furthermore time varying sensitivity analysis is performed to explore the temporal dynamics of parameter sensitivities which is useful for not only improving our understanding of dominant model components under changing hydroclimatic conditions but also providing meaningful insights time varying parameter sensitivities into uncertainty propagation in hydrological prediction 2 3 benchmark approach to demonstrate the superiority of the proposed shms it is necessary to perform a quantitative comparison with existing approaches the conditional vine copula model was selected as a comparative benchmark since it has been extensively applied to hydrological prediction by constructing a multivariate conditional distribution of hydroclimatic variables manning et al 2018 the conditional vine copula model graphically decomposes a high dimensional joint distribution into a cascade of bivariate copulas and univariate margins thereby allowing for flexible hydrological simulations assume that x x 1 xn 1 xn signifies n hydroclimate variables that affect the streamflow regimes and y signifies the streamflow observation the joint pdf between x and y can be expressed as 16 p x 1 x n y p 1 x 1 p n x n p y y c u 1 u n v y where p represents the marginal pdf ui and v represent the marginal cumulative probability of xi and y respectively i 1 n c represents the copula density since c u 1 un vy are inflexible in high dimensions and the high dimensional copula families are limited vine copula also known as pair copula construction pcc has been proposed to graphically represent equation 16 as vines comprising a nested set of trees with nodes that are joined by edges bedford cooke 2002 for example if two hydroclimate variables x 1 x 2 are used the joint density between x 1 x 2 and observation y can be decomposed through a 3 dimensional vine copula as 17 p x 1 x 2 y p x 1 p x 2 p y c u 1 u 2 α 1 2 c u 1 v α 1 y c h u 2 u 1 α 1 2 h v u 1 α 1 y α 2 y 1 where α represents the parameter set of bivariate copulas the h function is the conditional distribution function expressed as 18 f x v h x v α c x v f x f v α f v since there are multiple vine copula structures to decompose p x 1 x 2 y we use the sequential maximal spanning tree algorithm proposed by dißmann et al 2013 along with the akaike information criterion aic to identify an appropriate structure when the vine structure is determined a conditional cumulative distribution function cdf of y can be constructed by recursively applying the h function 19 p y x 1 x 2 c y 2 1 p y x 1 p x 2 x 1 p x 2 x 1 h h v u 1 α 1 y h u 2 u 1 α 1 2 α 2 y 1 thus the inverse form of equation 19 can be used to generate probabilistic hydrologic predictions 20 y f x 1 x 2 τ p y 1 h 1 h 1 τ h p 2 x 2 p 1 x 1 α 1 2 α 2 y 1 p 1 x 1 α 1 y τ 0 1 where τ represents random probability levels e g τ 0 01 0 1 0 99 p represents marginal cdfs to achieve reliable model results mc simulations were used to generate multiple e g 500 samples of τ from the uniform distribution u 0 1 leading to multiple realizations of y the median values of these realizations are obtained as hydrological predictions and uncertainty intervals can also be derived 3 experimental setups 3 1 study area the proposed shms was applied to predict daily streamflow in the guadalupe river basin texas as shown in fig 2 the guadalupe river with a drainage area of about 15 500 km2 originates in kerr county and flows into the guadalupe estuary with a mean daily discharge of 53 m3 s the guadalupe river basin is characterized by a significant difference in elevation the river originates at an elevation of 2 400 feet near its headwaters while it reaches an elevation as low as 5 feet at the outlet of the basin where the guadalupe river discharges into the gulf of mexico the guadalupe river and its tributaries are a vital source of water for a number of populous cities including kerrville new braunfels san marcos seguin lockhart gonzales cuero luling and victoria streamflow conditions in the guadalupe river basin are mainly influenced by spring discharge rainfall runoff processes evapotranspiration withdrawals for water supply reservoir operations and losses to aquifer recharge ockerman and slattery 2008 the study area has a subtropical subhumid climate characterized by hot summers and dry winters annual precipitation ranges from 770 mm near the headwaters to 1 000 mm near the gulf of mexico the heaviest rainfall tends to occur in spring and early summer thus periods with large or small amounts of rainfall are common resulting in recurring floods and droughts 3 2 data and model in this study the meteorological and hydrological data for the guadalupe river basin were collected from the model parameter estimation experiment mopex dataset duan et al 2006 a total of three years of data from january 1981 to december 1983 were used to assimilate daily streamflow such that the first year was used as a spin up period to reduce sensitivity to state value initialization data assimilation experiments were conducted by using the hymod which is a widely used rainfall runoff model for probabilistic hydrological prediction bulygina and gupta 2011 sadegh and vrugt 2013 young 2013 zhang et al 2021 in the rainfall runoff model the runoff production is characterized as a rainfall excess process and the runoff is determined according to a probability distributed storage capacity model that partitions excess rainfall into surface and subsurface storage through a partitioning factor moore 2007 the surface storage is characterized by three quick flow tanks and the subsurface storage is represented by a single slow flow tank thus the generated streamflow is the addition of discharges from slow and quick flow tanks the model has five parameters including the maximum soil moisture storage capacity c max the degree of spatial variability in the storage capacity b exp the factor used to distribute flow between the quick and slow flow routing β the residence time of the slow flow tank r s and the residence time of quick flow tanks r q the initial ranges of model parameters and their true values are given in table 1 in addition daily precipitation and potential evapotranspiration are the forcing input data used to drive the model 3 3 experimental design both synthetic and real data assimilation experiments were conducted to demonstrate the proposed methodology the synthetic experiment was designed to examine the ability of the assimilation system to estimate hydrological model parameters which has been widely used to validate the performance of data assimilation systems first the synthetic experiment with predefined model parameters was carried out to generate the true model states and streamflow time series as synthetic observations second the assimilation experiment was conducted based on the generated synthetic streamflow time series such that the convergence of model parameters towards the predefined parameter values can be evaluated third the assimilation experiment with real streamflow data was conducted when the performance of the assimilation system was validated through the synthetic experiment to address various sources of uncertainty in data assimilation random perturbations were adopted by adding noise errors to the precipitation and potential evapotranspiration data and streamflow observations leading to an ensemble of state variables as a result the specification of error parameters is a key feature of assimilation systems which plays an important role in the performance of hydrological prediction a statistical hypothesis test was conducted in this study to identify the best settings of error parameters including the precipitation error the potential evapotranspiration error and the streamflow observation error three scenarios were given on the strength of perturbations including 10 30 and 50 a three way factorial anova was thus performed to explicitly examine the sensitivities of error parameters and their interactions affecting the predictive accuracy which provided meaningful information for achieving the best performance of hydrological prediction when the posterior distributions of error parameters were identified through data assimilation the sensitivities of model parameters and their interactions were then investigated through variance based global sensitivity analysis advancing our understanding of dominant hydrological components and their temporal evolution 4 results and discussion 4 1 evaluation of the shms for parameter estimation a synthetic data assimilation experiment was performed to demonstrate the ability of shms to estimate the predefined model parameters fig 3 shows the convergence of model parameters through assimilating streamflow observations all parameters are identifiable as they rapidly converge to the posterior target distributions and the estimated mean values of all parameters converge toward the true values which are predefined as c max 610 mm b exp 2 05 β 0 50 r s 0 15 days 1 and r q 0 30 days 1 it can be seen that the first two parameters c max and b exp related to soil moisture storage capacity can be better estimated compared to the others as new observations become available the shms recursively correct and update parameter samples thus the uncertainty degree i e difference between maximum and minimum values of model parameters is relatively high at the early stage of filtering and diminishes gradually along the assimilation trajectory results verify the ability of shms to achieve convergence to the target distributions and can thus be used for uncertainty assessment of hydrological model parameters and predictions to further demonstrate the advantage of the proposed approach the data assimilation results obtained from the shms are compared against those obtained with the well known enkf fig 4 depicts the evolution of model parameters estimated using the enkf in comparison the proposed shms largely improves upon the enkf through the more rapid and accurate convergence of model parameters towards the posterior target distributions with reduced uncertainty especially for estimating the factor used to distribute flow between the quick and slow flow routing β the residence time of the slow flow tank r s and the residence time of quick flow tanks r q 4 2 identification of error and model parameters in streamflow assimilation when the performance of the shms was validated through the synthetic experiment a real data assimilation experiment was also conducted to predict daily streamflow in the guadalupe river basin texas a three way factorial anova was performed to examine the impacts of model and observation error parameters as well as their interactions in streamflow assimilation so as to identify the best settings of the shms with maximized performance fig 5 presents the normal probability plot of residuals for checking the normality of the residual distribution in the three way anova since this plot is approximately linear it verifies that the residuals are normally distributed as shown in table 2 the precipitation error is identified as the most statistically significant parameter according to the p value thus the precipitation error parameter has the largest first order effect on the predictive accuracy this indicates that any change in the settings of precipitation error parameter could lead to the largest variation of the root mean square error rmse value in addition the potential evapotranspiration and the streamflow observation error parameters as well as their interactions have considerable contributions to model performance based on the interaction analysis through factorial anova the minimum value of rmse can be obtained when the settings of precipitation potential evapotranspiration and observation error parameters are 50 10 and 50 respectively identification of the best settings of error parameters provides meaningful information for advancing our understanding of the data assimilation system and for maximizing model performance in previous studies error parameters were often randomly selected without a systematic assessment resulting in unreliable conclusions due to the oversimplified settings of error parameters for instance a single scenario of error parameters was often used previously to carry out hydrological data assimilation however sensitivities of error parameters and their interactions play a crucial role in the performance of data assimilation it is thus necessary to examine various scenarios of error parameters and to explore potential interactions between error parameters affecting the predictive accuracy leading to more robust and reliable hydrological prediction with the best parameter settings fig 6 shows the temporal evolution of model parameters derived through the daily streamflow assimilation using the shms with the best settings of error parameters it is indicated that all parameters are identifiable and they converge rapidly to the target distributions the derived posterior parameter distributions vary greatly from the synthetic experiment to the real data experiment due to the assimilation of different streamflow time series fig 7 presents a comparison of simulated and observed daily streamflow time series the daily streamflow distributions were evaluated using the probabilistic performance measure of reliability introduced by renard et al 2010 and breinholt et al 2012 reliability represents the percentage of observations falling within the uncertainty bounds of simulated streamflow time series which varies between 0 lowest reliability and 1 highest reliability in this study the reliability of streamflow distribution is 0 75 which is acceptable although far from perfect but the shms may underpredict the streamflow regimes furthermore hypothesis testing with a significance level of 0 05 was conducted to measure the significance of the difference between observed and simulated streamflow time series the p value derived by the hypothesis testing is less than 0 05 which indicates that the accuracy of streamflow prediction is statistically acceptable this verifies the ability of the shms to recursively assimilate streamflow observations and can thus be used for probabilistic streamflow prediction in the guadalupe river basin 4 3 comparison with probabilistic prediction approach to demonstrate the superiority of the proposed shms the conditional vine copula model was selected as a comparative benchmark to construct a conditional vine copula model the marginal distributions of hydrological variables i e streamflow precipitation potential evapotranspiration and temperature were selected from a total of 8 types of probability distributions including gamma weibull log normal gumbel generalized extreme value gev log logistic generalized pareto gp and generalized gamma the marginal distribution of hydrological variables was selected using the akaike information criterion aic see table 3 results show that the gev distribution was optimal for all hydrological variables including streamflow precipitation potential evapotranspiration and temperature for example fig 8 presents the fitted gev cumulative distribution function of daily streamflow and the q q plot indicating that the gev distribution provides a good representation of daily streamflow the hydrological variables were transformed to uniform margins on 0 1 based on their optimal parametric probability distributions and then were used to construct the conditional vine copula model the one with the lowest aic value was selected as the optimal vine structure fig 9 presents a comparison of daily streamflow time series generated from the observation and the constructed conditional vine copula model results show that the reliability is 0 71 which is lower than 0 75 generated from the proposed shms the shms also outperforms the conditional vine copula model in terms of capturing extreme flows specifically the shms captures 81 and 83 of high i e higher than the 90th percentile and low i e lower than the 10th percentile flows respectively whereas the conditional vine copula model captures only 71 and 36 of high and low flows respectively this indicates that the proposed shms can improve the reliability of daily streamflow simulations by robustly addressing various uncertainties and their interactions 4 4 sensitivities of model parameters and their interactions variance based global sensitivity analysis was also carried out to examine the sensitivities of model parameters and their interactions as shown in fig 10 the residence time of the quick flow tank r q has the largest individual and interaction effects on model performance this indicates that the simulated daily streamflow is highly sensitive to the variation of the residence time of the quick flow tank thus the quick flow tank parameter plays a crucial role in streamflow predictions in the guadalupe river basin in addition the quick flow tank parameter is closely correlated with other parameters and their interactions make a considerable contribution to model performance in comparison the residence time of the slow flow tank r s and its interactions with other parameters make little contribution to model performance results indicate that the surface runoff routing plays a dominant role in minimizing the overall error while the subsurface runoff process has little influence on streamflow predictions in the guadalupe river basin consequently sensitivity analysis for model parameters and their interactions is useful for providing meaningful insights into model components dominating the overall accuracy as the parameter sensitivity varies over time due to the changing hydrological conditions the temporal dynamics of parameter sensitivity were examined using the time varying sensitivity analysis method introduced by pianosi and wagener 2016 as shown in fig 11 sensitivities of five model parameters vary in response to changes in daily streamflow the accuracy is highly sensitive to the degree of spatial variability of soil moisture capacity b exp and the residence time of the quick flow tank r q especially for the days with heavy rainfall our findings reveal that the soil moisture capacity and the surface runoff routing parameters as well as precipitation play a key role in simulating daily streamflow in the dry guadalupe river basin in addition minimizing errors in heavy rainy days would greatly improve the overall accuracy of daily streamflow predictions analysis of the temporal dynamics of parameter sensitivity advances our understanding of dominant hydrologic processes that contribute to the catchment response under time varying hydroclimatic conditions 5 conclusions in this study we proposed a shms for improving daily streamflow prediction through sequential data assimilation the shms greatly improves upon the well known enkf through the more rapid and accurate convergence of model parameters in streamflow assimilation factorial anova was performed to explicitly reveal the impacts of model and observation error parameters as well as their interactions on streamflow assimilation variance based sensitivity analysis was also conducted to examine the sensitivities of hydrological model parameters and their interactions as well as to reveal the temporal dynamics of parameter sensitivity such a computational framework is capable of explicitly identifying underlying interactions between error parameters in streamflow assimilation and robustly predicting daily streamflow time series in a probabilistic manner the proposed framework was also compared with the existing well known approach used for streamflow prediction both synthetic and real data assimilation experiments were conducted to demonstrate applicability of the proposed methodology in the guadalupe river basin texas results obtained from factorial anova reveal that the precipitation error parameter has the largest first order effect on the assimilation accuracy potential evapotranspiration and streamflow observation error parameters as well as their interactions have considerable contributions to model performance factorial anova provides insights into model and observation error parameters that affect the performance of the hydrological data assimilation system maximizing the accuracy of streamflow assimilation by comparing the time series of observed and simulated daily streamflow using deterministic and probabilistic measures the results verify the ability of the shms to properly assimilate streamflow observations in the guadalupe river basin the shms also shows better performance than the conditional vine copula model in terms of the reliability of streamflow prediction on the other hand the soil moisture capacity and the surface runoff routing parameters as well as precipitation play a crucial role in simulating daily streamflow in the dry guadalupe river basin moreover sensitivities of model parameters vary over time due to the changing hydroclimatic conditions the model response is more sensitive to the variation of model parameters for the days with heavy rainfall thus minimizing errors in heavy rainy days would greatly improve the overall accuracy these findings provide meaningful insights into the dynamics of model components dominating the overall performance the shms has significant potential for performing hydrological predictions and will be applied to the physically based distributed hydrological models for better addressing the spatial heterogeneity of watershed characteristics in future studies nevertheless the computational cost will increase exponentially with the increasing number of hydrological model parameters due to the computationally extensive factorial anova and the variance based global sensitivity analysis it is thus necessary to further improve the factorial design and the variance based sensitivity analysis method for increasing the computational efficiency of hydrological prediction using the shms moreover a total of three years of data collected from the mopex dataset are used in this study to predict daily streamflow which may not adequately reflect the hydrological characteristics the longer time series data is thus desired in future studies to further improve the robustness of hydrological prediction credit authorship contribution statement y shen methodology validation formal analysis investigation writing original draft s wang conceptualization formal analysis writing review editing supervision project administration funding acquisition b zhang validation formal analysis writing original draft j zhu writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the national natural science foundation of china grant no 51809223 and the hong kong research grants council early career scheme grant no 25222319 the daily meteorological and hydrological data for the guadalupe river basin were collected from the u s mopex dataset 
3512,the optimization for surfactant enhanced aquifer remediation sear of dense non aqueous phase liquid dnapl contaminated aquifers is usually accompanied by uncertainties which may arise from the characterization of complex aquifer heterogeneity and dnapl source zone architecture sza due to measurement sparsity optimization under uncertainty is computationally expensive as it involves an enormous number of model runs the huge computational burden can be alleviated by utilizing a surrogate model for repeated model evaluations however most of the developed surrogates are often limited to low dimensional optimization problems that only consider simplified aquifer heterogeneity in this study we developed a multi objective simulation optimization framework to optimize the sear schemes considering the characterization uncertainties from both highly heterogeneous aquifer permeability and complex sza a fast to run convolutional neural network cnn based surrogate model was developed to approximate the high dimensional and highly complex input output mapping of the dnapl multiphase flow simulation model we first used the rejection sampling strategy to generate random realizations of permeability and sza conditioning on their limited measurements and then formulated a multi objective optimization under uncertainty problem based on these realizations the developed 3 d cnn was trained and used as the surrogate for repeated model runs in optimization to identify the optimal sear schemes under uncertainty a 3 d numerical experiment was used to test the performance of the cnn based simulation optimization framework comprehensive analysis on the obtained pareto fronts demonstrates that the proposed framework can efficiently identify reliable pareto optimal solutions with a 99 8 speedup compared to the traditional optimization coupled with the forward model moreover the optimization considering multiple realizations enables us to perform the risk assessment to locate the risk zone where the napl phase possibly exists after remediation which provides useful information for decision making keywords dnapl remediation strategy design optimization under uncertainty deep learning heterogeneous permeability risk assessment abbreviations dnapl dense non aqueous phase liquid 1 introduction dense non aqueous phase liquids dnapls are common contaminants detected in groundwater and difficult to remediate due to their low solubility high interfacial tension and high tendency to sink below the water table delshad et al 1996 national research council 2013 the surfactant enhanced aquifer remediation sear technique has been shown to be an effective remediation method for dnapl contaminated aquifers brown 2004 fountain et al 1996 in sear surfactant solution is injected into the aquifers to enhance the transport and solubility of dnapls so as to make them easier to be removed through extraction wells delshad et al 1996 fountain et al 1991 huo et al 2020 to obtain a good trade off between maximizing the contaminants removal effects and minimizing the economic costs a multi objective optimization simulation framework is generally employed to optimize remediation scheme under such contradictory objectives dokou and karatzas 2013 jiang and na 2020 schaerlaekens et al 2005 schaerlaekens et al 2006 singh and minsker 2008 a well designed sear scheme relies heavily on a high resolution characterization of the complex aquifer heterogeneity usually the heterogeneous permeability and dnapl source zone architecture sza otherwise it will lead to an inaccurate simulation of the transport of dnapl and surfactant and consequently mislead the design of remediation schemes brusseau et al 2007 dekker and abriola 2000 huo et al 2020 saenton et al 2002 however our characterizations for the aquifer heterogeneity and dnapl sza are inevitably associated with uncertainties due to measurement sparsity abriola et al 2012 therefore it is necessary to account for these uncertainties when designing the sear scheme which results in an optimization under uncertainty problem such a problem is usually solved by considering multiple possible realizations to assess the influence of their uncertainties on the optimization results aly and peralta 1999 ampomah et al 2017 kourakos and mantoglou 2008 singh and minsker 2008 wagner and gorelick 1989 in the simulation optimization under uncertainty framework a great challenge is to deal with the high dimensional uncertain parameter space arising from the consideration of uncertainties associated with highly heterogeneous aquifer and sza this is because the number of forward model runs during the simulation optimization process increases as the number of parameter values considered increases one of the widely used strategies to alleviate the computational burden is to substitute the time consuming forward model with a comparably accurate but much faster surrogate model for repeated model runs aly and peralta 1999 ampomah et al 2017 fan et al 2020 he et al 2008 yan and minsker 2010 yin and tsai 2020 for the sear remediated dnapl multiphase flow system considered here two major challenges arise associated with the development of surrogate model first the uncertain heterogeneous permeability field and complex dnapl sza cause the well known curse of dimensionality for most existing surrogate techniques lin and tartakovsky 2009 liao et al 2017 asher et al 2015 mo et al 2017 mo et al 2019b as a result to make the surrogate methods applicable to problems with multiple realizations in most previous groundwater remediation studies the homogenization or zoning strategy was generally employed to represent the heterogeneous permeability field by one or several uncertain parameters e g fan et al 2020 he et al 2008 yan and minsker 2010 however considering that the multiphase flow transport is sensitive to the permeability and sza variability the simplified permeability heterogeneity in the numerical models may mislead the sear scheme design therefore the surrogate modeling task of learning the high dimensional input output mapping of dnapl multiphase flow systems under sear remains to be effectively addressed and calls for innovative solutions second the surrogates in previous studies on surrogate based sear simulation are generally designed to approximate one or several target variables e g the removal rate and or the dnapl concentrations at monitoring wells e g he et al 2008 jiang and na 2020 luo et al 2020 as they are not able to provide predictions for the spatial distribution of the remaining napl phase after remediation since the remaining napl may be a long term contaminant source and pose threats to groundwater quality a global surrogate that can comparably accurately approximate its distribution is thus desired such a global surrogate model will further allow for a post remediation risk assessment which is of crucial significance for decision making on groundwater management recently deep convolutional neural network cnn has shown an impressive performance in surrogate modeling of systems involving high dimensional and highly complex input output mappings e g mo et al 2019a mo et al 2019b mo et al 2020 mo et al 2022 zhong et al 2019 zhu and zabaras 2018 for example cnn was applied in zhong et al 2019 and mo et al 2019b for surrogate modeling of geological carbon sequestration in andersson et al 2021 and ravuri et al 2021 for sea ice forecasting from hydroclimatic inputs and for precipitation nowcasting from radar images respectively the convolution operation with sparse connectivity and parameter sharing properties and the flexibility in designing network architecture by incorporating new advances of deep learning make cnn very promising for addressing many long standing challenges faced in previous studies lecun et al 2015 reichstein et al 2019 shen 2018 and our problem in optimizing dnapl remediation strategy under uncertainty in this work we are concerned with identifying the optimal sear scheme for dnapl contaminated aquifers under uncertainties associated with characterizing the highly heterogeneous permeability field and dnapl sza the aforementioned two challenges regarding considering the uncertainties will be addressed by developing a cnn based surrogate method to approximate the high dimensional and highly complex input output mapping of the time consuming dnapl multiphase flow model under different remediation schemes the cnn surrogate is then combined with the non dominated sorting genetic algorithm ii nsga ii deb et al 2002 to finally formulate a cnn nsgaii bi objective optimization under uncertain framework the characterization uncertainties associated with the permeability and dnapl sza are considered in the optimization through generating multiple realizations where the objective function value for a specific remediation scheme is defined based on the results of all realizations see section 2 3 2 the proposed framework is demonstrated using a 3d numerical experiment the risk analysis is performed based on the multiple realizations to quantify the probability of the spatial distribution of remaining napl phase after sear 2 methodology 2 1 governing equations and problem formulation the sear process of the dnapl contaminated aquifer is modeled using the university of texas at austin developed chemical flooding simulator utchem which is a multicomponent multiphase 3 d chemical compositional reservoir simulation model and can be applied to simulate various subsurface processes including advection dispersion and the mass transfer of species surfactant water organics delshad et al 1996 the governing mass conservation equation is as follows 1 t ϕ c κ ρ κ l 1 n p ρ κ c κ l u l d κ l r κ 2 u l k rl k μ l p l γ l h where ϕ is the porosity c κ l 3 l 3 is the overall volume of component κ per unit pore volume over all phases ρ κ m l 3 is the density of component κ i e water oil and surfactant n p is the number of phases c κ l l 3 l 3 is the concentration of component κ in phase l i e water phase oil phase and microemulsion phase u l l t is the darcy flux in phase l d κ l l t is the dispersive flux of component κ in phase l r κ m l 3 t is the source terms of component κ k rl is the relative permeability in phase l k l 2 is the intrinsic permeability μ l m lt is the viscosity of phase l p l m lt 2 is the pressure of phase l and γ l m l 2 t 2 is the specific weight for phase l h l is the vertical depth our focus is the development of a surrogate based method for efficiently identifying the optimal sear scheme under uncertainties associated with the highly heterogeneous permeability field and dnapl sza the surrogate model is tasked with approximating the underlying input output relationship of the dnapl multiphase flow system under sear so that one can efficiently obtain the predictions for quantity of interest without solving the governing equation with the time demanding utchem 2 2 deep convolutional neural network cnn for surrogate modeling to effectively learn the high dimensional and highly complex input output mapping of the sear system the 3 d input and output distributions are treated as 3 d images matrices and the learning task becomes an image to image regression problem it has been extensively shown that cnn is very suitable for tackling an image regression task due to its sparse connectivity and parameter sharing properties lecun et al 2015 mo et al 2019a reichstein et al 2019 ravuri et al 2021 zhong et al 2019 zhu and zabaras 2018 formally denoting d h w as the spatial discretization resolution of a 3 d domain the regression function between n x input distributions images x r n x d h w and n y output distributions images y r n y d h w is described as 3 f r n x d h w r n y d h w where n x and n y are the number of the input and output images respectively cnn s deep architecture which contains multiple processing layers and nonlinear transformations further enhances its performance in learning complex mappings our cnn architecture is illustrated in fig 1 more specifically the cnn architecture is u shaped in the sense that the size of feature maps is first sequentially halved to extract multi scale features with strided convolutional layers stride 2 then the size is sequentially doubled with strided transposed convolutional layers stride 2 the residual in residual dense block rrdb modules which introduce connections between non adjacent layers to enhance information flow through networks and employ the residual learning strategy to ease the training of deep networks avoid the problem of vanishing gradients wang et al 2018 are employed in our cnn and placed between two strided convolution conv transposed convolution deconv layers for higher performance the cascaded strided conv deconv layers and rrdbs contain multiple processing layers and nonlinear transformations enabling cnn to learn complex mappings more details regarding the network architecture and hyperparameters are given in the supplementary material 2 3 bi objective optimization under uncertainty for remediation design 2 3 1 generating realizations of the permeability field and dnapl sza it is often the case that in practice only limited measurements of permeability k and dnapl saturation s n 0 at boreholes are available to make better use of the available measurements we perform inverse modeling with the rejection sampling rs algorithm peters 2008 to achieve an improved characterization of the k field and dnapl sza s n 0 field more specifically a large ensemble of k realizations conditioning on the available k measurements are first generated using the conditional sequential gaussian simulator sgsim deutsch and journel 1998 the corresponding s n 0 realizations for all k realizations are then generated using the stochastic invasion percolation sip algorithm koch and nowak 2015 koch and nowak 2016 here we use the sip algorithm instead of the utchem mainly because the sip is much faster than utchem to generate a large ensemble of s n 0 realizations finally the rs algorithm is designed to accept the realizations having smaller deviations from the s n 0 observations with higher probabilities let s n 0 obs denote the s n 0 measurements that contain measurement errors with standard deviations σ i i 1 n obs n obs is the number of measurements s n 0 sip denote the sip realizations of s n 0 at observation locations the difference between the observed and simulated s n 0 is measured using the sum of the squared weighted residuals sswr metric as written by 4 sswr i 1 n obs s n 0 obs i s n 0 sip i σ i 2 for an s n 0 sip realization the acceptance rate α in the rs algorithm is defined as 5 α min 1 exp 0 5 γ sswr sswr ref where sswr ref is the reference sswr value considering that our characterization for the k and s n 0 distributions are usually associated with large uncertainties here we multiply the acceptance rate of the original rs algorithm by a modification factor γ γ 0 1 which will lead to accepting k and s n 0 with larger variability and make the surrogate modeling task more challenging 2 3 2 objective functions we consider two conflicting objective functions f 1 and f 2 in the simulation optimization framework for optimal design of the sear scheme 1 one f 1 quantifies the economic costs of remediation and 2 the other f 2 quantifies the dnapl removal efficiency they are conflicting in the sense that the increase of removal efficiency comes at the expense of more economic costs more specifically f 1 is defined as 6 minimize f 1 c 1 m n c 2 t i 1 n q i ex c 3 t i 1 m q i in where c 1 m n denotes the installation cost of m injection wells and n extraction wells rmb c 2 denotes the operation cost coefficient rmb m3 of extraction wells and c 3 denotes the combined operation cost coefficient rmb m3 of injection wells for water and surfactant schaerlaekens et al 2005 jiang et al 2018 for the f 2 function instead of directly treating it as the removal rate of dnapl as in many previous studies we define it as the total distribution area of the remaining napl after sear this is mainly because the remaining napl may be a long term contaminant source and minimizing its distribution area can to some extent reduce the contamination risk formally f 2 is defined as 7 minimize f 2 i 1 n m s n i m 1 s n 0 s n where s n i denotes the remaining dnapl saturation in the i th grid m is a indicator function to indicate if a grid contains napl phase or not n is the number of the total grids is a threshold that equals the residual dnapl saturation the f 1 and f 2 objective functions are subject to 8 q min in q i in q max in q min ex q j ex q max ex i 1 m q i in j 1 n q j ex where q min and q max are the allowed minimum and maximum injection in extraction ex rates respectively since the characterization uncertainty leads to multiple realizations of the k and s n 0 fields a specific remediation scheme will produce different f 2 values for different realizations of k and s n 0 fields to integrate these uncertainties into the optimization framework we adopt a similar strategy as in previous study ampomah et al 2017 that the final objective function f 2 is defined based on the mean and standard deviation of the f 2 values for all realizations 9 minimize f 2 μ f 2 λ σ f 2 where μ f 2 and σ f 2 are the mean and standard deviation respectively λ is the risk aversion factor it is assumed that the values of f 2 follow a normal distribution we set λ 2 to obtain a confidence probability p c 97 73 that an arbitrary realization satisfies f 2 i f 2 i 1 n r with a probability of 97 73 since p c μ f 2 2 σ f 2 f 2 μ f 2 2 σ f 2 0 9545 p c f 2 μ f 2 2 σ f 2 0 9773 according to the symmetry of normal distribution a higher confidence probability p c can be obtained by setting a higher risk aversion factor λ for example when λ 3 p c 99 87 the above bi objective optimization problem is solved using the well known non dominated sorting genetic algorithm ii nsga ii deb et al 2002 the nsga ii provides a set of non dominated solutions known as the pareto front which represents the trade off solutions between conflicting objectives 2 4 the integrated cnn nsgaii optimization under uncertainty framework in the integrated cnn nsgaii framework the cheap to run cnn surrogate is used to replace the time demanding utchem for repeated model evaluations in the nsga ii optimization algorithm the nsga ii randomly generates the sear wells schemes v from a given range the wells schemes are then transformed into images matrices which are fed into the well trained cnn together with the previously stored high dimensional inputs including n r realizations of the k and s n 0 fields cnn then outputs predictions of the post remediation s n fields which are used to calculate the objective f 2 and returned to the nsga ii to update the candidate v and run the next iteration the flowchart of applying this integrated framework is illustrated in fig 2 and detailed as follows step 1 generate n train realizations of the k and s n 0 fields using the rs algorithm section 2 3 1 and randomly generate n train sear schemes v for surrogate training step 2 run the utchem with n train k s n 0 v realizations to obtain the resulting s n fields step 3 train the cnn surrogate model with the n train k s n 0 v s n training samples step 4 generate another n r realizations of the k and s n 0 fields distinct from the training realizations for optimization under uncertainty step 5 run the nsga ii based optimization with the f 1 eq 6 and f 2 eq 9 objective functions evaluated on the cnn surrogate predictions to identify the pareto front of optimal sear schemes step 6 risk assessment for each identified remediation scheme in the pareto front based on the n r realizations of s n field 3 numerical experiments 3 1 synthetic aquifer system the performance of the proposed cnn nsgaii surrogate based simulation optimization under uncertainty framework is demonstrated using a synthetic study of an sear remediated dnapl contaminated 3 d confined aquifer 45 m 25 m 10 m see fig 3 since the denser than water dnapls have a high tendency to sink below the water table the domain is uniformly discretized into 45 rows 25 columns and 10 layers the left and right boundaries are constant hydraulic head boundaries with a gradient of 0 001 left to right and water is the only phase entering the lateral boundaries the other boundaries are all set as no flow boundaries the dnapl is released from the top layer of the domain at location x y 23 m 13 m with a total mass of 4 395 tons the solubility of dnapl in water is 0 505 g l in the absence of surfactant more details regarding the experimental settings are listed in table 1 it is assumed that the permeability k field is log normally distributed but uncertain with its statistics being listed in table 1 therefore the spatial distribution of the dnapl sza s n 0 field is also uncertain the measurements of k and s n 0 are collected from 15 synthetic boreholes at 10 depths resulting in 150 k observations and 150 s n 0 observations random realizations of the k and s n 0 fields conditioning on these observations are generated by following the procedure presented in section 2 3 1 during the sear we adopt a similar scheme of wells locations as in the previous study qin et al 2007 the surfactant is injected into the aquifer through six injection wells and the contaminated water is extracted through three extraction wells as shown in fig 3 for simplicity the cation exchange reactions gel reactions tracer reactions biodegradation reactions and adsorptions are not considered the remediation lasts for 30 days depending on parameters setting one utchem simulation of the sear process takes about 6 40 min on an intel xeon gold 6248 2 5 ghz cpu 3 2 parameter settings of the nsga ii optimization we set the wells installation cost coefficient c 1 to 5 000 rmb the operation cost coefficient c 2 to 0 5 rmb m3 for the extraction wells the operation cost coefficient c 3 to 201 5 rmb m3 for the injection wells refer to the cost of surfactant and injection in liu et al 2021 and ouyang et al 2017 and the capacity ranges for injection and extraction wells are q min in q max in 0 75 m3 d and q min ex q max ex 150 0 m3 d respectively to determine the number n r of k and s n 0 realizations required to properly represent the uncertainties associated with them the convergence lines of the mean and standard deviation of f 2 eq 7 values with respect to the number of realizations are depicted in fig 4 it is observed that the two lines stabilize after about 450 realizations thus we set n r 500 to ensure more stable statistics we run the nsga ii optimization with a randomly selected set of k and s n 0 realizations to determine the number of generations n g required for convergence which is measured by the commonly used hypervolume hv indicator bader and zitzler 2011 song et al 2018 the hypervolume indicator is evaluated by a pareto compliant evaluation method which means the hv value increases monotonically as the pareto front converges towards the optimal direction and the optimal pareto front will reach the maximum hv value fig 5 indicates that the nsga ii converges after about 90 generations thus we set n g 100 more details regarding the nsga ii parameters are listed in table 2 3 3 cnn network training the inputs to the cnn model include the log permeability ln k field the dnapl sza s n 0 field and the sear related parameters i e wells locations s l s lx s ly s lz injection extraction rates s r the cnn output is the prediction for the remaining dnapl saturation distribution s n after sear the ln k s n 0 and s n fields are organized as images with a resolution of d h w based directly on the spatial grids for the sear related parameters they are organized within a single image according to the following definition 10 s d h w s rj d h w s lx s ly s lz 0 d h w s lx s ly s lz where d 1 d h 1 h w 1 w and j 1 9 denotes the well index with s rj 0 and 0 representing injection and extraction wells respectively that is the input image for the sear related parameters has pixel values at the well locations being the injection extraction rate and 0 elsewhere we generate n train 5 000 input output samples following the procedure presented in section 2 3 1 to train the cnn surrogate model the network is trained using the l 2 loss function and the adam optimizer kingma and ba 2014 implemented in the pytorch deep learning framework https pytorch org with an initial learning rate of 0 005 and a batch size of 24 the training of cnn on an nvidia tesla v100 gpu for 200 epochs requires about 5 5 h we generate another n test 1 000 testing samples to evaluate the cnn s surrogate modeling performance based on the structural similarity index ssim wang et al 2004 the ssim metric quantifies the structural similarity between two 2 d images fields and is calculated over local windows of the images for the 3 d image with size d h w considered here it is treated as d images with size h w when computing the ssim metric wang et al 2004 as follows 11 ssim u v 2 μ u μ v c 1 2 σ uv c 2 μ u 2 μ v 2 c 1 σ u 2 σ v 2 c 2 where u and v are two windows with size 11 11 in the real and predicted images respectively μ u μ v and σ u 2 σ v 2 are the mean and variance values of window u v respectively σ uv denotes the covariance between u and v c 1 0 01 and c 2 0 03 are two constants a ssim value closer to 1 0 means a better performance of the cnn surrogate 4 results and discussion 4 1 surrogate accuracy analysis the cnn s training and testing approximation accuracy for the 3 d multiphase transport model is described in fig 6 it can be seen that the cnn surrogate achieves a median ssim value of 0 995 on the 5 000 training samples which have been seen by cnn during training the median of ssim values evaluated on the 1 000 cnn unseen testing samples is 0 991 indicating a good prediction for the spatial distribution of the dnapl saturation after sear the cnn s performance in accurately approximating the dnapl saturation s n field after remediation is further illustrated in fig 7 which depicts a comparison of the utchem simulated and cnn predicted s n fields of three randomly selected realizations in the testing set the input ln k and s n 0 fields and the difference between the simulated and predicted s n fields are also shown it is observed that on the one hand the three realizations have similar s n 0 values at observation wells vertical cylinders but their spatial s n 0 distributions differ largely from each other the results again suggest the necessity of considering the uncertainties associated with characterizing k and s n 0 fields when designing sear schemes on the other hand although the s n fields are spatially complex and discontinuous cnn is able to successfully reproduce the discontinuity and provide very close predictions to the simulated s n fields in all three realizations with the predicted errors less than 0 05 in most regions it is also noteworthy that the ln k field is highly heterogeneous and the s n 0 field is highly irregular with discontinuity and their distributions differ largely in different realizations these together lead to a high dimensional and highly complex mapping between ln k s n 0 v v denotes the remediation scheme and s n we attribute the success of cnn in accurately learning such a complex mapping to its outstanding capability of extracting informative features from spatially correlated images with multiple processing layers and nonlinear transformations therefore in the following sections we will use the comparably accurate but much faster to run cnn surrogate as the substitution of the time consuming utchem for repeated model runs in the simulation optimization process 4 2 optimization results under uncertainty 4 2 1 pareto optimal front analysis the pareto fronts at the final generation for all 500 f 1 f 2 realizations and the ensemble front f 1 f 2 see eq 9 obtained by cnn nsgaii are shown in fig 8 it can be seen that the pareto front is nonlinear and the less dnapl remained comes at the expense of higher remediation costs as expected to illustrate that the pareto solutions obtained by the cnn nsgaii optimization framework are reliable we compared the f 2 values predicted by the cnn surrogate with their simulation results by utchem the scatters of the f 2 values are close to the 1 1 perfect line with a coefficient of determination r 2 0 9939 fig 9 a and the absolute errors within 40 m2 20 m2 fig 9 b which means the cnn predictions of the pareto solutions are in good agreement with utchem simulation results to further validate that the pareto fronts achieved by our cnn nsgaii framework are reliable we randomly selected two realizations denoted as realizations i and ii from the 500 realizations and performed nsga ii optimization respectively with the cnn surrogate model cnn nsgaii and utchem forward model utchem nsgaii the hv curves of the two frameworks exhibit similar convergence rates and stabilize at close hv values in both realizations fig 10 a indicating a similar search process note the convergence rates of cnn nsgaii and utchem nsgaii in the early period may be different mainly due to the random crossover and mutation operations in the nsga ii fig 10 b shows the final pareto fronts achieved by the two frameworks it is observed the pareto fronts achieved by cnn nsgaii are very close to those by utchem nsgaii in both realizations suggesting that the cnn nsgaii framework is able to provide similar optimum solutions as the traditional frameworks based on time demanding forward models notably that the pareto front searched by cnn nsgaii lacks few solutions with large f 2 values which can be explained by cnn s slight underestimation of the f 2 values when the remaining dnapl distribution areas i e f 2 are large fig 9 a 4 2 2 evaluation of computational efficiency the fundamental intention of employing a surrogate to solve the optimization problem is to alleviate the computational burden see table 3 in the optimization of sear schemes under uncertainty task considered here the number of forward model runs required can be as least 4 000 000 for each of the 500 realizations 8 000 model runs in at least 80 generations of the nsga ii optimization fig 11 leading to a total running time of 800 000 h a single utchem run takes 12 min on the contrary with the very fast to run cnn for repeated model evaluations during the optimization process 129 5 h for 4 000 000 surrogate model evaluations 1 240 h for generation of 6 000 training samples and 5 5 h for cnn training we can obtain as high as 99 8 computational savings compared to the traditional utchem nsgaii simulation optimization framework more details regarding the computational savings of our cnn nsgaii framework relative to utchem nsgaii are summarized in table 3 4 3 decision making for remediation 4 3 1 optimal remediation schemes analysis we analysed three typical remediation schemes s 1 s 2 s 3 representing different best compromises between the objectives f 1 f 2 to further assess the effectiveness of pareto optimal solutions and provide suggestions on decision making the scheme s 1 s 2 and s 3 locate at the upper middle and bottom of the pareto front respectively see from fig 8 with the objective f 2 from the largest to the smallest by comparing the simulated results of the surrogate model s n with the forward model in these schemes as shown in fig 12 we further validate the cnn almost accurately predicts the discontinuous and irregular distribution as the absolute errors between them are mostly between 0 05 0 05 besides s 1 has the largest and concentrated distribution area while the remaining napl distributes the smallest and disseminates in s 3 depicted in fig 12 the predicted scattered napl phase in s 3 might be ignored as the monitoring wells are usually too sparse to find some scattered dnapl therefore it s necessary to predict the distribution of the remaining napl another three typical remediation schemes s 2 s 4 s 5 corresponding to different realizations of ln k and dnapl s n 0 with the same optimized solutions marked in fig 8 are analyzed to illustrate the influence of the characterization uncertainty on remediation schemes these three schemes share the same sear designs for all wells but the resulting napl phase distributions are very different shown in fig 13 with the difference between any two schemes being 270 at most the scheme s 5 and s 4 shown in fig 8 if only scheme s 5 is used to produce the optimal solution the result will be sub optimal for the others while using the results from scheme s 4 might be too conservative to find most potential effective remediation strategies therefore comprehensively considering all the realizations contributes to finding an effective and reliable remediation strategy 4 3 2 risk assessment as multiple realizations are considered in the cnn surrogate based simulation optimization under uncertainty framework we can further perform risk assessment to quantify the possible distribution of dnapl after remediation based on cnn s predictions for the s n fields in 500 realizations fig 14 depicts the risk maps to show the probability of the remaining dnapl saturation in every grid exceeds a threshold value of 0 1 for three typical schemes s 1 s 2 and s 3 it is observed that the scheme s 1 has a higher risk than s 3 with more remaining dnapl after remediation as s 1 focuses more on minimizing the economic costs with these risk maps reflecting various risk levels in all zones one can locate the specific zone where napl phase highly possibly exists contributing to adjusting the remediation strategy for example for scheme s 1 more than 80 of the 500 realizations have a large area in the bottom layer that the remaining dnapl saturation is larger than 0 1 the subsequent remediation can mainly focus on the bottom layer in scheme s 3 the remaining dnapl is likely to sparsely distribute only in the bottom layer suggesting a low contamination risk after remediation 5 conclusions in this study we are concerned with optimizing the sear schemes for dnapl contaminated aquifers under uncertainties associated with characterizing the highly heterogeneous permeability ln k field and complex dnapl source zone architecture s n 0 field solving such an optimization under uncertainty problem with two contradictory objectives of minimizing the distribution area of remaining dnapl saturation while minimizing the economic cost is computationally expensive or even infeasible as an enormous amount of time consuming dnapl multiphase flow model runs are usually required to alleviate the huge computational burden we developed a cnn surrogate model to approximate the high dimensional and highly complex mapping between the inputs ln k s n 0 and sear scheme v and outputs dnapl saturation s n after remediation of the forward model the fast to run cnn surrogate was then used as the substitution of time consuming forward model for repeated model evaluations our main conclusions are as follows 1 the proposed cnn deep learning method effectively overcomes the well known curse of dimensionality asher et al 2015 razavi et al 2012 for surrogate modeling it is therefore able to accurately r 2 0 9939 and median ssim 0 9910 and efficiently approximate the high dimensional r 3 45 25 10 r 1 45 25 10 and highly complex input output mapping ln k s n 0 v s n of the time consuming dnapl multiphase flow model 2 the cnn surrogate based simulation optimization under uncertainty framework can efficiently identify the optimal sear schemes with 99 8 fewer computational costs than the original framework without using surrogate model 3 for a specific remediation scheme the post remediation dnapl saturation distribution s n is uncertain due to the uncertainties associated with the characterization of ln k and s n 0 fields the cnn surrogate based simulation optimization under uncertainty framework allows for a comprehensive consideration of these uncertainties and more importantly enables us to perform a risk assessment for the remediated aquifers under different feasible remediation schemes i e the risk map of the post optimization dnapl saturation distribution providing useful information for management of the remediated aquifers credit authorship contribution statement jianwen du conceptualization methodology software validation investigation formal analysis visualization data curation writing original draft xiaoqing shi conceptualization writing review editing resources supervision funding acquisition shaoxing mo conceptualization methodology software validation writing review editing supervision xueyuan kang methodology writing review editing jichun wu funding acquisition writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we are grateful to the high performance computing center hpcc of nanjing university for doing the numerical calculations in this paper on its blade cluster system the work was supported by the key science and technology project for revitalization of inner mongolia of china 2021eedscxsfqzd010 national key research and development program of china 2018yfc1800600 national natural science foundation of china 41977157 and 42002248 china postdoctoral science foundation 2020m681550 jiangsu planned projects for postdoctoral research funds 2020z133 the authors would like to thank dr jonas koch and prof wolfgang nowak universität stuttgart for the sip codes which significantly promote the progress of this work we are also grateful to the editor associate editor and four anonymous reviewers for their constructive comments appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2022 127639 supplementary data the following are the supplementary data to this article supplementary data 1 
3512,the optimization for surfactant enhanced aquifer remediation sear of dense non aqueous phase liquid dnapl contaminated aquifers is usually accompanied by uncertainties which may arise from the characterization of complex aquifer heterogeneity and dnapl source zone architecture sza due to measurement sparsity optimization under uncertainty is computationally expensive as it involves an enormous number of model runs the huge computational burden can be alleviated by utilizing a surrogate model for repeated model evaluations however most of the developed surrogates are often limited to low dimensional optimization problems that only consider simplified aquifer heterogeneity in this study we developed a multi objective simulation optimization framework to optimize the sear schemes considering the characterization uncertainties from both highly heterogeneous aquifer permeability and complex sza a fast to run convolutional neural network cnn based surrogate model was developed to approximate the high dimensional and highly complex input output mapping of the dnapl multiphase flow simulation model we first used the rejection sampling strategy to generate random realizations of permeability and sza conditioning on their limited measurements and then formulated a multi objective optimization under uncertainty problem based on these realizations the developed 3 d cnn was trained and used as the surrogate for repeated model runs in optimization to identify the optimal sear schemes under uncertainty a 3 d numerical experiment was used to test the performance of the cnn based simulation optimization framework comprehensive analysis on the obtained pareto fronts demonstrates that the proposed framework can efficiently identify reliable pareto optimal solutions with a 99 8 speedup compared to the traditional optimization coupled with the forward model moreover the optimization considering multiple realizations enables us to perform the risk assessment to locate the risk zone where the napl phase possibly exists after remediation which provides useful information for decision making keywords dnapl remediation strategy design optimization under uncertainty deep learning heterogeneous permeability risk assessment abbreviations dnapl dense non aqueous phase liquid 1 introduction dense non aqueous phase liquids dnapls are common contaminants detected in groundwater and difficult to remediate due to their low solubility high interfacial tension and high tendency to sink below the water table delshad et al 1996 national research council 2013 the surfactant enhanced aquifer remediation sear technique has been shown to be an effective remediation method for dnapl contaminated aquifers brown 2004 fountain et al 1996 in sear surfactant solution is injected into the aquifers to enhance the transport and solubility of dnapls so as to make them easier to be removed through extraction wells delshad et al 1996 fountain et al 1991 huo et al 2020 to obtain a good trade off between maximizing the contaminants removal effects and minimizing the economic costs a multi objective optimization simulation framework is generally employed to optimize remediation scheme under such contradictory objectives dokou and karatzas 2013 jiang and na 2020 schaerlaekens et al 2005 schaerlaekens et al 2006 singh and minsker 2008 a well designed sear scheme relies heavily on a high resolution characterization of the complex aquifer heterogeneity usually the heterogeneous permeability and dnapl source zone architecture sza otherwise it will lead to an inaccurate simulation of the transport of dnapl and surfactant and consequently mislead the design of remediation schemes brusseau et al 2007 dekker and abriola 2000 huo et al 2020 saenton et al 2002 however our characterizations for the aquifer heterogeneity and dnapl sza are inevitably associated with uncertainties due to measurement sparsity abriola et al 2012 therefore it is necessary to account for these uncertainties when designing the sear scheme which results in an optimization under uncertainty problem such a problem is usually solved by considering multiple possible realizations to assess the influence of their uncertainties on the optimization results aly and peralta 1999 ampomah et al 2017 kourakos and mantoglou 2008 singh and minsker 2008 wagner and gorelick 1989 in the simulation optimization under uncertainty framework a great challenge is to deal with the high dimensional uncertain parameter space arising from the consideration of uncertainties associated with highly heterogeneous aquifer and sza this is because the number of forward model runs during the simulation optimization process increases as the number of parameter values considered increases one of the widely used strategies to alleviate the computational burden is to substitute the time consuming forward model with a comparably accurate but much faster surrogate model for repeated model runs aly and peralta 1999 ampomah et al 2017 fan et al 2020 he et al 2008 yan and minsker 2010 yin and tsai 2020 for the sear remediated dnapl multiphase flow system considered here two major challenges arise associated with the development of surrogate model first the uncertain heterogeneous permeability field and complex dnapl sza cause the well known curse of dimensionality for most existing surrogate techniques lin and tartakovsky 2009 liao et al 2017 asher et al 2015 mo et al 2017 mo et al 2019b as a result to make the surrogate methods applicable to problems with multiple realizations in most previous groundwater remediation studies the homogenization or zoning strategy was generally employed to represent the heterogeneous permeability field by one or several uncertain parameters e g fan et al 2020 he et al 2008 yan and minsker 2010 however considering that the multiphase flow transport is sensitive to the permeability and sza variability the simplified permeability heterogeneity in the numerical models may mislead the sear scheme design therefore the surrogate modeling task of learning the high dimensional input output mapping of dnapl multiphase flow systems under sear remains to be effectively addressed and calls for innovative solutions second the surrogates in previous studies on surrogate based sear simulation are generally designed to approximate one or several target variables e g the removal rate and or the dnapl concentrations at monitoring wells e g he et al 2008 jiang and na 2020 luo et al 2020 as they are not able to provide predictions for the spatial distribution of the remaining napl phase after remediation since the remaining napl may be a long term contaminant source and pose threats to groundwater quality a global surrogate that can comparably accurately approximate its distribution is thus desired such a global surrogate model will further allow for a post remediation risk assessment which is of crucial significance for decision making on groundwater management recently deep convolutional neural network cnn has shown an impressive performance in surrogate modeling of systems involving high dimensional and highly complex input output mappings e g mo et al 2019a mo et al 2019b mo et al 2020 mo et al 2022 zhong et al 2019 zhu and zabaras 2018 for example cnn was applied in zhong et al 2019 and mo et al 2019b for surrogate modeling of geological carbon sequestration in andersson et al 2021 and ravuri et al 2021 for sea ice forecasting from hydroclimatic inputs and for precipitation nowcasting from radar images respectively the convolution operation with sparse connectivity and parameter sharing properties and the flexibility in designing network architecture by incorporating new advances of deep learning make cnn very promising for addressing many long standing challenges faced in previous studies lecun et al 2015 reichstein et al 2019 shen 2018 and our problem in optimizing dnapl remediation strategy under uncertainty in this work we are concerned with identifying the optimal sear scheme for dnapl contaminated aquifers under uncertainties associated with characterizing the highly heterogeneous permeability field and dnapl sza the aforementioned two challenges regarding considering the uncertainties will be addressed by developing a cnn based surrogate method to approximate the high dimensional and highly complex input output mapping of the time consuming dnapl multiphase flow model under different remediation schemes the cnn surrogate is then combined with the non dominated sorting genetic algorithm ii nsga ii deb et al 2002 to finally formulate a cnn nsgaii bi objective optimization under uncertain framework the characterization uncertainties associated with the permeability and dnapl sza are considered in the optimization through generating multiple realizations where the objective function value for a specific remediation scheme is defined based on the results of all realizations see section 2 3 2 the proposed framework is demonstrated using a 3d numerical experiment the risk analysis is performed based on the multiple realizations to quantify the probability of the spatial distribution of remaining napl phase after sear 2 methodology 2 1 governing equations and problem formulation the sear process of the dnapl contaminated aquifer is modeled using the university of texas at austin developed chemical flooding simulator utchem which is a multicomponent multiphase 3 d chemical compositional reservoir simulation model and can be applied to simulate various subsurface processes including advection dispersion and the mass transfer of species surfactant water organics delshad et al 1996 the governing mass conservation equation is as follows 1 t ϕ c κ ρ κ l 1 n p ρ κ c κ l u l d κ l r κ 2 u l k rl k μ l p l γ l h where ϕ is the porosity c κ l 3 l 3 is the overall volume of component κ per unit pore volume over all phases ρ κ m l 3 is the density of component κ i e water oil and surfactant n p is the number of phases c κ l l 3 l 3 is the concentration of component κ in phase l i e water phase oil phase and microemulsion phase u l l t is the darcy flux in phase l d κ l l t is the dispersive flux of component κ in phase l r κ m l 3 t is the source terms of component κ k rl is the relative permeability in phase l k l 2 is the intrinsic permeability μ l m lt is the viscosity of phase l p l m lt 2 is the pressure of phase l and γ l m l 2 t 2 is the specific weight for phase l h l is the vertical depth our focus is the development of a surrogate based method for efficiently identifying the optimal sear scheme under uncertainties associated with the highly heterogeneous permeability field and dnapl sza the surrogate model is tasked with approximating the underlying input output relationship of the dnapl multiphase flow system under sear so that one can efficiently obtain the predictions for quantity of interest without solving the governing equation with the time demanding utchem 2 2 deep convolutional neural network cnn for surrogate modeling to effectively learn the high dimensional and highly complex input output mapping of the sear system the 3 d input and output distributions are treated as 3 d images matrices and the learning task becomes an image to image regression problem it has been extensively shown that cnn is very suitable for tackling an image regression task due to its sparse connectivity and parameter sharing properties lecun et al 2015 mo et al 2019a reichstein et al 2019 ravuri et al 2021 zhong et al 2019 zhu and zabaras 2018 formally denoting d h w as the spatial discretization resolution of a 3 d domain the regression function between n x input distributions images x r n x d h w and n y output distributions images y r n y d h w is described as 3 f r n x d h w r n y d h w where n x and n y are the number of the input and output images respectively cnn s deep architecture which contains multiple processing layers and nonlinear transformations further enhances its performance in learning complex mappings our cnn architecture is illustrated in fig 1 more specifically the cnn architecture is u shaped in the sense that the size of feature maps is first sequentially halved to extract multi scale features with strided convolutional layers stride 2 then the size is sequentially doubled with strided transposed convolutional layers stride 2 the residual in residual dense block rrdb modules which introduce connections between non adjacent layers to enhance information flow through networks and employ the residual learning strategy to ease the training of deep networks avoid the problem of vanishing gradients wang et al 2018 are employed in our cnn and placed between two strided convolution conv transposed convolution deconv layers for higher performance the cascaded strided conv deconv layers and rrdbs contain multiple processing layers and nonlinear transformations enabling cnn to learn complex mappings more details regarding the network architecture and hyperparameters are given in the supplementary material 2 3 bi objective optimization under uncertainty for remediation design 2 3 1 generating realizations of the permeability field and dnapl sza it is often the case that in practice only limited measurements of permeability k and dnapl saturation s n 0 at boreholes are available to make better use of the available measurements we perform inverse modeling with the rejection sampling rs algorithm peters 2008 to achieve an improved characterization of the k field and dnapl sza s n 0 field more specifically a large ensemble of k realizations conditioning on the available k measurements are first generated using the conditional sequential gaussian simulator sgsim deutsch and journel 1998 the corresponding s n 0 realizations for all k realizations are then generated using the stochastic invasion percolation sip algorithm koch and nowak 2015 koch and nowak 2016 here we use the sip algorithm instead of the utchem mainly because the sip is much faster than utchem to generate a large ensemble of s n 0 realizations finally the rs algorithm is designed to accept the realizations having smaller deviations from the s n 0 observations with higher probabilities let s n 0 obs denote the s n 0 measurements that contain measurement errors with standard deviations σ i i 1 n obs n obs is the number of measurements s n 0 sip denote the sip realizations of s n 0 at observation locations the difference between the observed and simulated s n 0 is measured using the sum of the squared weighted residuals sswr metric as written by 4 sswr i 1 n obs s n 0 obs i s n 0 sip i σ i 2 for an s n 0 sip realization the acceptance rate α in the rs algorithm is defined as 5 α min 1 exp 0 5 γ sswr sswr ref where sswr ref is the reference sswr value considering that our characterization for the k and s n 0 distributions are usually associated with large uncertainties here we multiply the acceptance rate of the original rs algorithm by a modification factor γ γ 0 1 which will lead to accepting k and s n 0 with larger variability and make the surrogate modeling task more challenging 2 3 2 objective functions we consider two conflicting objective functions f 1 and f 2 in the simulation optimization framework for optimal design of the sear scheme 1 one f 1 quantifies the economic costs of remediation and 2 the other f 2 quantifies the dnapl removal efficiency they are conflicting in the sense that the increase of removal efficiency comes at the expense of more economic costs more specifically f 1 is defined as 6 minimize f 1 c 1 m n c 2 t i 1 n q i ex c 3 t i 1 m q i in where c 1 m n denotes the installation cost of m injection wells and n extraction wells rmb c 2 denotes the operation cost coefficient rmb m3 of extraction wells and c 3 denotes the combined operation cost coefficient rmb m3 of injection wells for water and surfactant schaerlaekens et al 2005 jiang et al 2018 for the f 2 function instead of directly treating it as the removal rate of dnapl as in many previous studies we define it as the total distribution area of the remaining napl after sear this is mainly because the remaining napl may be a long term contaminant source and minimizing its distribution area can to some extent reduce the contamination risk formally f 2 is defined as 7 minimize f 2 i 1 n m s n i m 1 s n 0 s n where s n i denotes the remaining dnapl saturation in the i th grid m is a indicator function to indicate if a grid contains napl phase or not n is the number of the total grids is a threshold that equals the residual dnapl saturation the f 1 and f 2 objective functions are subject to 8 q min in q i in q max in q min ex q j ex q max ex i 1 m q i in j 1 n q j ex where q min and q max are the allowed minimum and maximum injection in extraction ex rates respectively since the characterization uncertainty leads to multiple realizations of the k and s n 0 fields a specific remediation scheme will produce different f 2 values for different realizations of k and s n 0 fields to integrate these uncertainties into the optimization framework we adopt a similar strategy as in previous study ampomah et al 2017 that the final objective function f 2 is defined based on the mean and standard deviation of the f 2 values for all realizations 9 minimize f 2 μ f 2 λ σ f 2 where μ f 2 and σ f 2 are the mean and standard deviation respectively λ is the risk aversion factor it is assumed that the values of f 2 follow a normal distribution we set λ 2 to obtain a confidence probability p c 97 73 that an arbitrary realization satisfies f 2 i f 2 i 1 n r with a probability of 97 73 since p c μ f 2 2 σ f 2 f 2 μ f 2 2 σ f 2 0 9545 p c f 2 μ f 2 2 σ f 2 0 9773 according to the symmetry of normal distribution a higher confidence probability p c can be obtained by setting a higher risk aversion factor λ for example when λ 3 p c 99 87 the above bi objective optimization problem is solved using the well known non dominated sorting genetic algorithm ii nsga ii deb et al 2002 the nsga ii provides a set of non dominated solutions known as the pareto front which represents the trade off solutions between conflicting objectives 2 4 the integrated cnn nsgaii optimization under uncertainty framework in the integrated cnn nsgaii framework the cheap to run cnn surrogate is used to replace the time demanding utchem for repeated model evaluations in the nsga ii optimization algorithm the nsga ii randomly generates the sear wells schemes v from a given range the wells schemes are then transformed into images matrices which are fed into the well trained cnn together with the previously stored high dimensional inputs including n r realizations of the k and s n 0 fields cnn then outputs predictions of the post remediation s n fields which are used to calculate the objective f 2 and returned to the nsga ii to update the candidate v and run the next iteration the flowchart of applying this integrated framework is illustrated in fig 2 and detailed as follows step 1 generate n train realizations of the k and s n 0 fields using the rs algorithm section 2 3 1 and randomly generate n train sear schemes v for surrogate training step 2 run the utchem with n train k s n 0 v realizations to obtain the resulting s n fields step 3 train the cnn surrogate model with the n train k s n 0 v s n training samples step 4 generate another n r realizations of the k and s n 0 fields distinct from the training realizations for optimization under uncertainty step 5 run the nsga ii based optimization with the f 1 eq 6 and f 2 eq 9 objective functions evaluated on the cnn surrogate predictions to identify the pareto front of optimal sear schemes step 6 risk assessment for each identified remediation scheme in the pareto front based on the n r realizations of s n field 3 numerical experiments 3 1 synthetic aquifer system the performance of the proposed cnn nsgaii surrogate based simulation optimization under uncertainty framework is demonstrated using a synthetic study of an sear remediated dnapl contaminated 3 d confined aquifer 45 m 25 m 10 m see fig 3 since the denser than water dnapls have a high tendency to sink below the water table the domain is uniformly discretized into 45 rows 25 columns and 10 layers the left and right boundaries are constant hydraulic head boundaries with a gradient of 0 001 left to right and water is the only phase entering the lateral boundaries the other boundaries are all set as no flow boundaries the dnapl is released from the top layer of the domain at location x y 23 m 13 m with a total mass of 4 395 tons the solubility of dnapl in water is 0 505 g l in the absence of surfactant more details regarding the experimental settings are listed in table 1 it is assumed that the permeability k field is log normally distributed but uncertain with its statistics being listed in table 1 therefore the spatial distribution of the dnapl sza s n 0 field is also uncertain the measurements of k and s n 0 are collected from 15 synthetic boreholes at 10 depths resulting in 150 k observations and 150 s n 0 observations random realizations of the k and s n 0 fields conditioning on these observations are generated by following the procedure presented in section 2 3 1 during the sear we adopt a similar scheme of wells locations as in the previous study qin et al 2007 the surfactant is injected into the aquifer through six injection wells and the contaminated water is extracted through three extraction wells as shown in fig 3 for simplicity the cation exchange reactions gel reactions tracer reactions biodegradation reactions and adsorptions are not considered the remediation lasts for 30 days depending on parameters setting one utchem simulation of the sear process takes about 6 40 min on an intel xeon gold 6248 2 5 ghz cpu 3 2 parameter settings of the nsga ii optimization we set the wells installation cost coefficient c 1 to 5 000 rmb the operation cost coefficient c 2 to 0 5 rmb m3 for the extraction wells the operation cost coefficient c 3 to 201 5 rmb m3 for the injection wells refer to the cost of surfactant and injection in liu et al 2021 and ouyang et al 2017 and the capacity ranges for injection and extraction wells are q min in q max in 0 75 m3 d and q min ex q max ex 150 0 m3 d respectively to determine the number n r of k and s n 0 realizations required to properly represent the uncertainties associated with them the convergence lines of the mean and standard deviation of f 2 eq 7 values with respect to the number of realizations are depicted in fig 4 it is observed that the two lines stabilize after about 450 realizations thus we set n r 500 to ensure more stable statistics we run the nsga ii optimization with a randomly selected set of k and s n 0 realizations to determine the number of generations n g required for convergence which is measured by the commonly used hypervolume hv indicator bader and zitzler 2011 song et al 2018 the hypervolume indicator is evaluated by a pareto compliant evaluation method which means the hv value increases monotonically as the pareto front converges towards the optimal direction and the optimal pareto front will reach the maximum hv value fig 5 indicates that the nsga ii converges after about 90 generations thus we set n g 100 more details regarding the nsga ii parameters are listed in table 2 3 3 cnn network training the inputs to the cnn model include the log permeability ln k field the dnapl sza s n 0 field and the sear related parameters i e wells locations s l s lx s ly s lz injection extraction rates s r the cnn output is the prediction for the remaining dnapl saturation distribution s n after sear the ln k s n 0 and s n fields are organized as images with a resolution of d h w based directly on the spatial grids for the sear related parameters they are organized within a single image according to the following definition 10 s d h w s rj d h w s lx s ly s lz 0 d h w s lx s ly s lz where d 1 d h 1 h w 1 w and j 1 9 denotes the well index with s rj 0 and 0 representing injection and extraction wells respectively that is the input image for the sear related parameters has pixel values at the well locations being the injection extraction rate and 0 elsewhere we generate n train 5 000 input output samples following the procedure presented in section 2 3 1 to train the cnn surrogate model the network is trained using the l 2 loss function and the adam optimizer kingma and ba 2014 implemented in the pytorch deep learning framework https pytorch org with an initial learning rate of 0 005 and a batch size of 24 the training of cnn on an nvidia tesla v100 gpu for 200 epochs requires about 5 5 h we generate another n test 1 000 testing samples to evaluate the cnn s surrogate modeling performance based on the structural similarity index ssim wang et al 2004 the ssim metric quantifies the structural similarity between two 2 d images fields and is calculated over local windows of the images for the 3 d image with size d h w considered here it is treated as d images with size h w when computing the ssim metric wang et al 2004 as follows 11 ssim u v 2 μ u μ v c 1 2 σ uv c 2 μ u 2 μ v 2 c 1 σ u 2 σ v 2 c 2 where u and v are two windows with size 11 11 in the real and predicted images respectively μ u μ v and σ u 2 σ v 2 are the mean and variance values of window u v respectively σ uv denotes the covariance between u and v c 1 0 01 and c 2 0 03 are two constants a ssim value closer to 1 0 means a better performance of the cnn surrogate 4 results and discussion 4 1 surrogate accuracy analysis the cnn s training and testing approximation accuracy for the 3 d multiphase transport model is described in fig 6 it can be seen that the cnn surrogate achieves a median ssim value of 0 995 on the 5 000 training samples which have been seen by cnn during training the median of ssim values evaluated on the 1 000 cnn unseen testing samples is 0 991 indicating a good prediction for the spatial distribution of the dnapl saturation after sear the cnn s performance in accurately approximating the dnapl saturation s n field after remediation is further illustrated in fig 7 which depicts a comparison of the utchem simulated and cnn predicted s n fields of three randomly selected realizations in the testing set the input ln k and s n 0 fields and the difference between the simulated and predicted s n fields are also shown it is observed that on the one hand the three realizations have similar s n 0 values at observation wells vertical cylinders but their spatial s n 0 distributions differ largely from each other the results again suggest the necessity of considering the uncertainties associated with characterizing k and s n 0 fields when designing sear schemes on the other hand although the s n fields are spatially complex and discontinuous cnn is able to successfully reproduce the discontinuity and provide very close predictions to the simulated s n fields in all three realizations with the predicted errors less than 0 05 in most regions it is also noteworthy that the ln k field is highly heterogeneous and the s n 0 field is highly irregular with discontinuity and their distributions differ largely in different realizations these together lead to a high dimensional and highly complex mapping between ln k s n 0 v v denotes the remediation scheme and s n we attribute the success of cnn in accurately learning such a complex mapping to its outstanding capability of extracting informative features from spatially correlated images with multiple processing layers and nonlinear transformations therefore in the following sections we will use the comparably accurate but much faster to run cnn surrogate as the substitution of the time consuming utchem for repeated model runs in the simulation optimization process 4 2 optimization results under uncertainty 4 2 1 pareto optimal front analysis the pareto fronts at the final generation for all 500 f 1 f 2 realizations and the ensemble front f 1 f 2 see eq 9 obtained by cnn nsgaii are shown in fig 8 it can be seen that the pareto front is nonlinear and the less dnapl remained comes at the expense of higher remediation costs as expected to illustrate that the pareto solutions obtained by the cnn nsgaii optimization framework are reliable we compared the f 2 values predicted by the cnn surrogate with their simulation results by utchem the scatters of the f 2 values are close to the 1 1 perfect line with a coefficient of determination r 2 0 9939 fig 9 a and the absolute errors within 40 m2 20 m2 fig 9 b which means the cnn predictions of the pareto solutions are in good agreement with utchem simulation results to further validate that the pareto fronts achieved by our cnn nsgaii framework are reliable we randomly selected two realizations denoted as realizations i and ii from the 500 realizations and performed nsga ii optimization respectively with the cnn surrogate model cnn nsgaii and utchem forward model utchem nsgaii the hv curves of the two frameworks exhibit similar convergence rates and stabilize at close hv values in both realizations fig 10 a indicating a similar search process note the convergence rates of cnn nsgaii and utchem nsgaii in the early period may be different mainly due to the random crossover and mutation operations in the nsga ii fig 10 b shows the final pareto fronts achieved by the two frameworks it is observed the pareto fronts achieved by cnn nsgaii are very close to those by utchem nsgaii in both realizations suggesting that the cnn nsgaii framework is able to provide similar optimum solutions as the traditional frameworks based on time demanding forward models notably that the pareto front searched by cnn nsgaii lacks few solutions with large f 2 values which can be explained by cnn s slight underestimation of the f 2 values when the remaining dnapl distribution areas i e f 2 are large fig 9 a 4 2 2 evaluation of computational efficiency the fundamental intention of employing a surrogate to solve the optimization problem is to alleviate the computational burden see table 3 in the optimization of sear schemes under uncertainty task considered here the number of forward model runs required can be as least 4 000 000 for each of the 500 realizations 8 000 model runs in at least 80 generations of the nsga ii optimization fig 11 leading to a total running time of 800 000 h a single utchem run takes 12 min on the contrary with the very fast to run cnn for repeated model evaluations during the optimization process 129 5 h for 4 000 000 surrogate model evaluations 1 240 h for generation of 6 000 training samples and 5 5 h for cnn training we can obtain as high as 99 8 computational savings compared to the traditional utchem nsgaii simulation optimization framework more details regarding the computational savings of our cnn nsgaii framework relative to utchem nsgaii are summarized in table 3 4 3 decision making for remediation 4 3 1 optimal remediation schemes analysis we analysed three typical remediation schemes s 1 s 2 s 3 representing different best compromises between the objectives f 1 f 2 to further assess the effectiveness of pareto optimal solutions and provide suggestions on decision making the scheme s 1 s 2 and s 3 locate at the upper middle and bottom of the pareto front respectively see from fig 8 with the objective f 2 from the largest to the smallest by comparing the simulated results of the surrogate model s n with the forward model in these schemes as shown in fig 12 we further validate the cnn almost accurately predicts the discontinuous and irregular distribution as the absolute errors between them are mostly between 0 05 0 05 besides s 1 has the largest and concentrated distribution area while the remaining napl distributes the smallest and disseminates in s 3 depicted in fig 12 the predicted scattered napl phase in s 3 might be ignored as the monitoring wells are usually too sparse to find some scattered dnapl therefore it s necessary to predict the distribution of the remaining napl another three typical remediation schemes s 2 s 4 s 5 corresponding to different realizations of ln k and dnapl s n 0 with the same optimized solutions marked in fig 8 are analyzed to illustrate the influence of the characterization uncertainty on remediation schemes these three schemes share the same sear designs for all wells but the resulting napl phase distributions are very different shown in fig 13 with the difference between any two schemes being 270 at most the scheme s 5 and s 4 shown in fig 8 if only scheme s 5 is used to produce the optimal solution the result will be sub optimal for the others while using the results from scheme s 4 might be too conservative to find most potential effective remediation strategies therefore comprehensively considering all the realizations contributes to finding an effective and reliable remediation strategy 4 3 2 risk assessment as multiple realizations are considered in the cnn surrogate based simulation optimization under uncertainty framework we can further perform risk assessment to quantify the possible distribution of dnapl after remediation based on cnn s predictions for the s n fields in 500 realizations fig 14 depicts the risk maps to show the probability of the remaining dnapl saturation in every grid exceeds a threshold value of 0 1 for three typical schemes s 1 s 2 and s 3 it is observed that the scheme s 1 has a higher risk than s 3 with more remaining dnapl after remediation as s 1 focuses more on minimizing the economic costs with these risk maps reflecting various risk levels in all zones one can locate the specific zone where napl phase highly possibly exists contributing to adjusting the remediation strategy for example for scheme s 1 more than 80 of the 500 realizations have a large area in the bottom layer that the remaining dnapl saturation is larger than 0 1 the subsequent remediation can mainly focus on the bottom layer in scheme s 3 the remaining dnapl is likely to sparsely distribute only in the bottom layer suggesting a low contamination risk after remediation 5 conclusions in this study we are concerned with optimizing the sear schemes for dnapl contaminated aquifers under uncertainties associated with characterizing the highly heterogeneous permeability ln k field and complex dnapl source zone architecture s n 0 field solving such an optimization under uncertainty problem with two contradictory objectives of minimizing the distribution area of remaining dnapl saturation while minimizing the economic cost is computationally expensive or even infeasible as an enormous amount of time consuming dnapl multiphase flow model runs are usually required to alleviate the huge computational burden we developed a cnn surrogate model to approximate the high dimensional and highly complex mapping between the inputs ln k s n 0 and sear scheme v and outputs dnapl saturation s n after remediation of the forward model the fast to run cnn surrogate was then used as the substitution of time consuming forward model for repeated model evaluations our main conclusions are as follows 1 the proposed cnn deep learning method effectively overcomes the well known curse of dimensionality asher et al 2015 razavi et al 2012 for surrogate modeling it is therefore able to accurately r 2 0 9939 and median ssim 0 9910 and efficiently approximate the high dimensional r 3 45 25 10 r 1 45 25 10 and highly complex input output mapping ln k s n 0 v s n of the time consuming dnapl multiphase flow model 2 the cnn surrogate based simulation optimization under uncertainty framework can efficiently identify the optimal sear schemes with 99 8 fewer computational costs than the original framework without using surrogate model 3 for a specific remediation scheme the post remediation dnapl saturation distribution s n is uncertain due to the uncertainties associated with the characterization of ln k and s n 0 fields the cnn surrogate based simulation optimization under uncertainty framework allows for a comprehensive consideration of these uncertainties and more importantly enables us to perform a risk assessment for the remediated aquifers under different feasible remediation schemes i e the risk map of the post optimization dnapl saturation distribution providing useful information for management of the remediated aquifers credit authorship contribution statement jianwen du conceptualization methodology software validation investigation formal analysis visualization data curation writing original draft xiaoqing shi conceptualization writing review editing resources supervision funding acquisition shaoxing mo conceptualization methodology software validation writing review editing supervision xueyuan kang methodology writing review editing jichun wu funding acquisition writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we are grateful to the high performance computing center hpcc of nanjing university for doing the numerical calculations in this paper on its blade cluster system the work was supported by the key science and technology project for revitalization of inner mongolia of china 2021eedscxsfqzd010 national key research and development program of china 2018yfc1800600 national natural science foundation of china 41977157 and 42002248 china postdoctoral science foundation 2020m681550 jiangsu planned projects for postdoctoral research funds 2020z133 the authors would like to thank dr jonas koch and prof wolfgang nowak universität stuttgart for the sip codes which significantly promote the progress of this work we are also grateful to the editor associate editor and four anonymous reviewers for their constructive comments appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2022 127639 supplementary data the following are the supplementary data to this article supplementary data 1 
3513,the standard exponential and logarithmic laws for flow velocity evaluation cannot be applied for gravel bed streams due to the effect of large scale roughness an analytical model based on a two layer subdivision approach was developed to predict flow velocity over a gravel array with different densities the velocity distribution in the gravel layer was derived by solving the darcy forchheimer brinkman dfb differential equation based on the concept of porous medium flows the velocity in the surface layer was modeled by the mixing length theory with the length scale modified by taking into account the porous effect of the gravel ball arrays to assess the model flow velocities over gravel beds simulated by ping pong ball arrays with different densities or porosities were measured in a laboratory flume the results show that the predicted velocities by this subdivision model agree well with experimental data reflecting that the porosity of the gravel array essentially impacts the flows both in the gravel layer and surface layer in comparison with the existing models not considering the porous effect of the gravel bed this model can effectively predict vertical velocity distributions and thereby flow resistances in gravel streams the permeable interface velocity atop the gravel layer as the boundary condition for the two layer model is sensitive to the bed context effect rather than the hydraulic effect suggesting that the inflection point of the full velocity profile might be vital in determining the accuracy of the model moreover with other data sources over dense gravel bed our model is suitable for data pre dealt with the spatially averaging where the spatial non uniformity effect is great keywords gravel bed streams gravel array spatial density two layer subdivision approach velocity distribution analytical model 1 introduction gravel bed streams with a wide distribution of sediment particles are commonly found in the piedmont and mountainous regions lateral landslides debris flows and flash floods bring boulders onto stream beds to generate various bedforms such as cascades or clusters of various kinds bathurst 1985 rickenmann 2001 yager et al 2007 nitsche et al 2011 piton and recking 2019 because of intensive sediment movement and river platforms flash floods in the mountainous regions usually lead to more severe disasters compared with lowland floods under the same flood discharge wilcox et al 2006 schneider et al 2015 lamb et al 2017a zhang et al 2020 therefore the quantitative prediction of bedload transport rate and bedform evolution in gravel bed streams is desired comiti et al 2007 ferguson 2007 powell 2014 schneider et al 2016 lamb et al 2017b as reported by ferro and pecoraro 2000 nikora et al 2001 bathurst 2002 katul et al 2002 rickenmann and recking 2011 lamb et al 2017a ferro and porto 2018 and luo et al 2020 the vertical velocity distribution in gravel streams is characterized by an inflection point atop the gravel layer which substantially deviates from the exponential or logarithmic law due to the resistance of the gravel layer the velocity below the gravel top is far lower than that in the surface layer canovaro et al 2007 the velocity distribution in the gravel layer is assumed constant exponential linear or a hybrid pattern nikora et al 2004 the velocity prediction methods over large scale roughness can be classified into two categories powell 2014 the first type is to explore physically based models of flow velocity for instance katul et al 2002 developed a mixing flow model for the deflected velocity distribution across the roughness bed luo et al 2020 recently proposed a multivariable mixing flow analogy to achieve high accuracy the second however adopts a subdivision concept for flow through large scale sediment obstacles and submerged canopies providing more physics of the flow roughness interaction nikora et al 2001 nikora et al 2007 introduced the space time averaging of the ns equations to the spatially non uniform velocity distribution over a gravel layer lamb et al 2017a derived an exact solution of the gravel layer velocity with the integration of the seepage equation for flow motion somehow the velocity distribution in a gravel stream is analogous to that in a vegetated stream since the roughness layer for both is porous the concept of flow layer subdivision has also been applied in vegetated flows nepf 2012a for instance a single layer model was proposed to search for the prediction equation of the mean velocity by revising the hydraulic radius or applying genetic programing cheng 2015 tinoco et al 2015 two layer models were developed to describe flow velocity in the surface and vegetation layers respectively stone and shen 2002 huthoff et al 2007 cheng 2011 shi et al 2019 moreover vegetation density is shown to have a significant impact on velocity distribution nepf et al 2007 yan et al 2016 with similar regard the gravel spatial density is expected to have a substantial impact on velocity distribution in gravel streams the knowledge of gravel bed flows under the impact of varying gravel array spatial density defined as the volume fraction of gravel particle to total space is reported by only few flume experiments canovaro et al 2007 conducting flume experiments with different immobile particles spacing showed that gravel array spatial density substantially affected flow resistance yager et al 2007 studied the bedload transport rate over a steep boulder bed with immobile particles in varying spatially distributed patterns and demonstrated that with a small gravel array spatial density the shear stress derived from mobile particles tended to decrease and the error of bedload transport equation tended to increase luo et al 2020 found that the ratios between the standard deviation of instantaneous velocity and shear velocity in gravel bed with a varying gravel array spatial density were closer to typical values in mixing layer flows manes et al 2009 and papanicolaou et al 2012 investigated the spatially nonuniform velocity distribution within a gravel array but did not present the impact of varying array spatial density the prediction method of the vertical velocity distribution for gravel streams taking into account the effect of varying gravel array spatial density has not been proposed and the velocity profile inside the gravel layer has been rarely solved this study contains two perspectives of novelties as below a two layer subdivision model is developed to simulate flow velocity distribution and averaged velocity in both the gravel and surface layers with the aim of considering varying gravel array spatial density to simulate the vertical velocity distribution in the gravel layer a solution of the darcy forchheimer brinkman dfb differential equation is derived with the linear approximation by the taylor expansion for the surface layer the velocity distribution is modeled by a logarithmic law with modified mixing length theory taking into account the effect of gravel array spatial density flume experiments of flow over gravel bed with different spatial densities mimicked by a ping pong ball array with different arrangements are conducted flow velocity data from this study and published literature are used to verify and assess the proposed model 2 analytical model of velocity in gravel bed streams in a stream with a permeable gravel bed the flow is divided into two layers namely the gravel layer and surface layer fig 1 a compared with a standard logarithmic type flow velocity distribution in the surface layer has a significant distortion affected by the gravel layer the flow behavior in the gravel layer is similar to the flow through a large scale porosity medium note that the porosity of the gravel layer is assumed homogeneous fig 1b 2 1 gravel layer model flow velocity within the porous medium can be modeled by the darcy s equation however the darcy s equation only simply characterizes linear seepage processes in porous mediums with the increase of fluctuations in the porous medium the seepage process might be nonlinear nield and bejan 2017 thus the forchheimer term is used to model nonlinear flow regime caused by turbulent momentum exchange which is profound with a large reynolds number lamb et al 2017a tortuosity in the large porous medium increases extra viscous shear stress which is integrated as the brinkman term for flow through the porous medium therefore the gravel layer flow can be modeled using the darcy forchheimer brinkman equation dfb equation as follows nield and bejan 2017 1 p μ k u ρ f ϕ sub u 2 k μ m 2 u z 2 where u is the flow velocity f is the dimensionless form drag forchheimer constant coefficient k is the intrinsic permeability coefficient of the medium depending on the geometry rather than fluid motion ϕ sub is the porosity of the porous medium μ is the dynamic viscosity of the fluid and μ m is the effective viscosity constant depending on the tortuosity of the medium ρ is the fluid density and z is the distance above the bed in the direction perpendicular to the bed p ρ g s is the pressure gradient in the flow direction in which g is the gravitational acceleration 9 81 m s2 and s is the channel slope on the right hand side the first term is the darcy term the second term is the forchheimer term associating with the nonlinear regime and the third term is the brinkman term accounting for porosity in the gravel layer eq 1 can be rewritten as a second order non homogeneous linear differential equation with constant coefficients but it is challenging to find the exact solution due to the existence of u 2 what s more eq 1 is applicable for steady uniform and unconfined fluids and the boundaries of porous medium are assumed impermeable however flow in gravel layer would be accelerated by the surface layer flow with high velocity across the gravel water interface similar to the mixing flow layer this feature in gravel streams shall be considered in the dfb equation before applying the equation to gravel layer flow here a simple analytical approximation of eq 1 is proposed the purpose of introducing the forchheimer term in darcy s equation is to solve the turbulent flow with a large reynolds number the solution depends on how to solve the forchheimer term for avoiding calculating u 2 the flow velocity u z is assumed to be differentiable vertically thus u 2 z can be approximated by the value for a fixed position with the taylor s theorem as shown in the following equation 2 u 2 z u 2 z 0 2 u z 0 u z 0 z z 0 r k z where u z 0 denotes the derivative of u z at z z 0 r k z denotes the truncation error term of taylor s theorem describing the asymptotic behavior which can be omitted the magnitude of r k z as a high order term is much smaller than other terms for a thin gravel layer porous media the same treatment was used for gaseous slip flow in a long microchannel dongari et al 2007 for submerged shrub like vegetation flow liu et al 2012 and for incompressible flow in porous media antohe and lage 1997 besides for a permeable medium gravel layer vegetation layer exchange layer the effects of the bed topography become larger than that of the viscous force and inertial force so that u 2 z has been reported by previous studies in gravel bed flow bathurst 2002 smart et al 2002 if the interface boundary is impermeable the boundary can be set as the no slip condition for velocity distribution for the permeable interface boundary conditions however the velocity at the permeable interface should be different from zero and only decays to zero in the gravel layer numerous studies adopt the beavers and joseph condition to describe the boundary condition between a saturated porous medium and an outer free fluid auriault 2009 an empirical formula proposed by beavers and joseph 1967 verified by the homogenization theory based on the systematic use of the notion of separation of scales in jäger and mikelić 2009 is given as u z z 0 u 0 u z z 0 α b k u 0 u r where α b μ m μ is the beavers and joseph s phenomenological parameter and depends on hydraulic conductivity which is greater than that of different porous materials experimental observation koplik 1983 ur is the mean velocity normal to the boundary and can be associated with vertical fluctuation caused by local eddies due to the roughness elements based on the concept of homogeneous isotropic turbulence ur is assumed to be equal to the tangential instantaneous velocities monin and yaglom 2013 hence ur is assumed linearly associated with bed shear stress parallel to the bed ur eu in which e is an empirical relaxation coefficient to attain the influence of bed surface and u τ 0 ρ is the bed shear velocity in which τ 0 is the bed shear stress z 0 0 is set as the location of permeable interface boundary which connects with the surface layer flow then substituting eq 2 into eq 1 the standard second order nonlinear inhomogeneous differential equation could be simplified with the reduction of the order of u yielding 4 s f u 0 2 2 u 0 u z 0 0 z μ m ρ g 2 u z 2 u k where k ρ g k μ is the hydraulic conductivity and f f ϕ sub g k is a dimensionless forchheimer coefficient using the boundary condition given by eq 3 the exact solution for the velocity u in the gravel layer is obtained the detailed derivations are shown in appendix 1 the final expression of u is 5 u z α b 1 5 u 0 u r b c b sinh d z u 0 a 1 α b 1 5 b cosh d z c z a where a k s f u 0 2 b k f u 0 2 c 2 k f u 0 u r and d d a μ m and the range of z is from h g to zero in the gravel layer these terms of eq 5 account for the effects of large reynolds number and large porosity in the gravel layer which are utilized to modify the nonlinear velocity distribution then the depth averaged velocity u g for the gravel layer can be obtained by integrating eq 5 from z h g to zero and dividing by h g yielding u g 1 h g h g 0 udz 1 d h g α b 1 5 u 0 u r b c b 1 d h g α b 1 5 u 0 u r b c b cosh h g d 6 1 d h g u 0 a 1 α b 1 5 b sinh d h g c h g 2 a 2 2 surface layer model the velocity distribution in the surface layer is derived by a mixing length approach which is improved from lamb et al 2017a in our model the improvement is made by incorporating the effect of gravel array spatial density in the definition of mixing length with the boussinesq eddy viscosity hypothesis the reynolds stress τ quantifying the vertical momentum exchange yields 7 τ ρ u 2 1 z h s ρ l 2 d u dz 2 μ t d u dz where l is the mixing length scale μ t is the eddy viscosity u is the local mean velocity and h s is the depth of the surface layer following prandtl s hypothesis the eddy viscosity μ t yields 8 μ t ρ u 1 z h s l to take into account the impact of the roughness layer on the surface layer the mixing length l is treated as a sum of two components given as a hybrid mixing length model 9 l κ z r where κ 0 41 is the von karman constant coefficient r is the length scale of coherent structures near bed for the near bed surface region turbulent mixing is dominated by wakes shedding from rough gravel surface which controls the momentum exchange across the gravel water interface on determining the value of r different studies have proposed empirical equations correlated with the roughness height regarding terrestrial tree canopy raupach et al 1996 aquatic vegetation nepf 2012b and gravel bed katul et al 2002 lamb et al 2017a large scale eddies near the porous gravel bed surface somehow tend to penetrate into the porous layer which influences the velocity distribution to our knowledge there are no theories or data exploring the relationship between coherent structures and gravel bed configuration a qualitative description based on the physics of vortex boundary interactions is given as follows so that the r established to modify the mixing length can be mathematically formulated randomly firstly we know that near bed large scale eddies are caused by the flow instability arising from rough topography such structures on one hand act as an agent of eddies between the large and small scales and on the other hand promote the momentum exchange between different velocity layers effectively nepf 2012b nikora et al 2019 secondly the coherent structures tend to permeate the deeper position due to the decrease in gravel array spatial density which is similar to vegetation flow interfaces e g flows through submerged vegetation therefore it is rational to take into account the effect of gravel array spatial density when defining the mixing length the effect of gravel array spatial density should diminish when the gravel layer is either infinitely sparse or dense as a result the mixing length l is only associated with the vertical location and r 0 when the bed topography gradually becomes sparser from dense condition or denser from sparse condition however the coherent structures induced by varying bed topography permeate deeper water depth to enhance the mixing length increasing the value of r therefore a maximum value might exist for r herein a modified r simply assumed to be formulated by a quadratic function is given by 10 r m k s α λ 2 α λ where k s is the roughness height and m has been derived by lamb for z k s i e m κ 30 exp κ u 0 u α is a negative fitting coefficient and λ is the gravel array spatial density defined as the fraction of the total solid volume occupied by the gravel elements and the total volume compared with the model of lamb et al 2017a λ is a new parameter taken into account for the solution in this study for a solid wall or empty space λ approaching 1 or 0 the mixing length l in eq 9 reduces to kz by manipulating an integration from z k s 30 to z z the standard velocity logarithmic equation can be achieved 11 u z u 1 κ ln 30 z k s similarly substituting eq 8 9 and 10 into eq 7 by integrating gives 12 u z u 1 κ ln 1 κ m a λ 2 a λ z k s u 0 u where z ranges from 0 to h s in the surface layer the depth averaged surface velocity u s 1 h s 0 h s u z d z in the surface layer can be obtained by integrating from z 0 to h s and dividing by h s 13 u s u 1 κ 1 m a λ 2 a λ κ k s h s ln 1 κ m a λ 2 a λ h s k s 1 u 0 u 2 3 model performance evaluation the nash sutcliffe efficiency index nsei root mean square error rmse and mean relative error mre are reliable statistical parameters widely used to assess the fitting goodness of hydrological and hydrodynamic models expressed as 14 1 nsei 1 i 1 i n y i y i 2 i 1 i n y i y 2 14 2 rmse i 1 i n y i y i 2 n 14 3 mre 1 n i 1 i n y i y i y i where y i and y i are the predicted and measured values of the dependent variable y respectively y denotes the mean measured values of y n is the sample size in particular it noted that the nsei indicates how well the plot of measured versus predicted data fits the 1 1 line nsei 1 when the model accounts for all the variation in the measurements while 0 when the model predictions are as accurate as the mean of the measured values a negative nsei indicates that the predicted results are not reliable the rmse indicates the dispersion degree between model predictions and measured values the mre indicates the averaged relative error of all data 3 flume experiments to test the model experiments were conducted in a rectangular flume with 16 0 m in length 0 5 m in width 0 4 m in height and a slope of 0 25 in the state key lab of hydraulics and mountain river engineering in sichuan university see fig 2 a the flow was regulated by a rectangular weir with a wide top at the inlet generating a steady uniform flow regime the rough gravel bed reach with a length of 4 0 m was located in the middle of the flume two segment rough beds made of one meter long uniform rubbles were placed in the inlet and outlet of the rough gravel reach to eliminate large scale disturbances the coordinate system followed that x 0 was located at the front of the model rough gravel bed y 0 was in the center of the cross section and z 0 was at the permeable interface and also the top of spheres in this study the gravel layer was simulated by periodic span wise arrays of spherical ping pong balls of diameter d p 0 04 m gravel elements were densely placed transversely and uniformly distributed longitudinally in equal spacing fig 2b the gravel spatial spacing ds varying from 0 0 to 0 28 m was equal to integral times of ping pong ball diameter fig 2c the gravel array spatial density λ in planimetric arrangements of this study is defined as the fraction of the solid volume occupied by the gravel elements modeled by spheres v g π n k s 3 6 and the total volume v 0 b l k s where n is the number of gravel elements arranged on the rough gravel bed reach and b and l are the width and length of the rough gravel bed reach respectively hence the gravel array spatial density λ in planimetric arrangements of this study could be calculated as 15 λ v g v 0 π n k s 2 6 b l π π b k s k s 2 6 b π d s k s π k s 6 d s k s where π is the transverse alignment number of gravel array arranged on the rough gravel bed reach the height of the gravel layer is assumed as h g d p ks 0 04 m therefore the gravel array spatial density λ 0 07 0 52 by varying flow depth hs flow discharge q and gravel array spatial density λ 12 scenarios of experiments were obtained summarized in table 1 the cross section average velocity is u q b h the froude number is fr u g h 0 5 in which b 0 5 m is the flume width and water depth h is the sum of h s and h g and the reynolds number is re uh ν in which υ is the kinematic coefficient of viscosity equaling 1 01 10 6 m2 s under the current gravel bed configuration flow velocity was measured in the region of 6 m downstream from the flow inlet where the flow was fully developed following the approach of lamb et al 2017a measurements were conducted near the center of the cross section that can represent the region of the average velocity of the cross section with a mean relative error of 16 31 the specific middle measurement line along water depth was arranged in the middle of two adjacent gravel arrays as indicated by the red dashed line in fig 2c in other words the middle position of the measurement line was measured for instantaneous velocities i e the valley between ping pong balls the measurement interval in the vertical direction was 1 0 cm to obtain the detailed velocity distribution instantaneous velocities were sampled within 45 s using a side looking three dimensional sontek acoustic doppler velocimeter adv 50 hz those instantaneous velocities with the lower signal noise ratio lower than 15 db and with the correlation coefficient lower limit of 70 were removed to improve data quality goring and nikora 2002 the remaining instantaneous velocities were decomposed into time averaged and fluctuating components using a matlab code figures s1 s6 in the supporting file run c and d q 0 036 and 0 048 m3 s show that in the fully developed region the variability in velocity in the different cross sections between two gravel array rows is minor the measured averaged velocities u g and u s are obtained by integration of the profile u z note that linear extrapolation of adv velocity is used to estimate missing near bed incomplete velocity in the gravel layer lamb et al 2017a 4 results 4 1 velocity at the permeable interface in the derivation of the theoretical model the critical parameter u 0 representing velocity at the permeable interface appears both in eq 6 and 13 as shown in fig 3 a u 0 and u calculated by gravel beds simulated by ping pong ball arrays from our data run a d with different λ and natural cobbles from lamb et al s data with different slopes l1 s 0 004 l2 s 0 02 l3 s 0 08 l4 s 0 15 cannot be directly described by a simple linear relation in particular for those small values the reason might be that the developed large scale turbulence under different λ increases the non linearity of flow across the permeable interface when λ increases more turbulent momentum is transported into the gravel layer through the large scale interface turbulence therefore more factors need to be considered to establish the mathematical description of u 0 clearly u 0 can be enhanced by the generation of large scale vortices near the gravel layer interface due to vertical momentum exchange hence u 0 can be assumed as a function of the shear velocity u and the length scale of coherent structures r e g u 0 γ u r in which γ is a function symbol considering the relationship between r and bedform features in eq 10 and u g h s 0 5 in a two dimensional flow u 0 can be written as u 0 γ h s k s λ due to h h s h g in which h g is usually assumed as k s u 0 can be rewritten as u 0 γ h s s k s λ hence u 0 is expressed in an empirical form i e 16 u 0 m 0 h s a s b k s c λ d where m 0 a b c and d are constants estimated by experimental data which are 25 gravel bed flume data including ping pong ball arrays data and natural cobbles lamb et al 2017a we achieved the result of estimating empirical coefficients m 0 13 13 for lamb and 37 82 for our data a 0 5 b 0 7 c 0 5 and d 1 5 are attained λ of lamb et al s data is 0 6 in case of the overlap of natural river cobbles with ds k s 0 1 the fitting results with a mean relative error of 12 5 are illustrated in fig 3 b therefore eq 16 can be replaced by u 0 u m 0 λ 1 5 s 0 2 k s 0 5 g 0 5 in which the term m 0 s 0 2 λ 1 5 k s 0 5 g 0 5 is an experimental constant under a certain flow condition and u is dependent on flow conditions in the following eq 16 is used to estimate u 0 which is a key parameter adopted in eqs 6 and 13 4 2 gravel layer velocity for empirical coefficients appearing in the gravel layer model eq 5 the forchheimer constant f 5 10 3 the permeability k 1 10 10 m 2 the relaxation coefficient e 1 10 3 and the beavers and joseph s phenomenological parameter α b 1 23 fig 4 a and 4 b show the measured gravel layer velocity u g against the gravel array spatial density λ and measured u 0 with the results by data fitting the measured u g in the gravel layer is larger for larger λ and u 0 from the positive relationship between shear stress length scale and gravel array spatial density luo et al 2020 the large scale turbulence near bed can be restricted to the upper 50 gravel layer height for a dense gravel bed the turbulence can easily penetrate to the lower 50 for a sparse gravel bed even to the substrate bottom hence the decrease in velocity attenuation near bed is stronger as gravel array spatial density decreases besides it is interestingly noted that the increase in bed slope and gravel array spatial density can promote the value of u 0 with the same discharge the data is listed in table s1 in the supporting file which can explain the reasonability of eq 16 fig 4 c shows the comparison of ug between the measured data and predicted results with colored solid circles for eq 6 and colored solid triangles for lamb s model with an assumption of linear distribution of the gravel layer velocity eq a11 1 of lamb et al 2017a in appendix 2 the mean relative errors in the estimate of u g by eq 6 is 27 for all data and results for run c and d with smaller λ have smaller relative errors of u g the coefficients of eq 5 fitted to lamb flume data with natural gravel and cobber particles f 1 10 4 and k 6 10 11 m2 are smaller than those based on our experimental data the reasons are probably owing to the denser arrangement of gravels and faster flow employed in lamb s flume the integral linear hypothesis adopted by lamb et al 2017a and the taylor s expansion theorem for differential equation simplification in this study are two ways to derive the analytical solution of the dfb equation for the gravel layer flow the differential based method proposed in this study can show the velocity profile along with the height of the gravel layer which has not been reported by previous studies fig 5 illustrates the predicted velocity distribution predicted by eq 5 in the gravel layer z h g 2 0 it is shown that the rate of velocity decay for a denser gravel bed is larger than that for a sparser gravel bed in addition the decay rate of gravel layer velocity of the upper part is far higher than the lower part suggesting a higher shear effect of the surface layer on the gravel layer flow to our knowledge this is the first attempt to describe the velocity distribution in the gravel layer with an analytical model the comparison between the measured and predicted results at the same vertical position in the gravel layer as illustrated in fig s7 in the supporting file indicates a mean relative error of u 25 4 3 surface layer velocity fig 6 a shows the comparison of surface layer velocity profiles between the predicted results by eq 11 and the measured data with k s 0 04 m the characteristics of velocity distribution affected by λ cannot be described by the standard logarithmic law besides the velocities atop the gravel layer are significantly affected by λ fig 6a for a lower λ the surface layer velocities are less affected by the gravel layer and their distributions are closer to the standard logarithmic curve i e run c and d the performance of the surface layer velocity model eq 12 developed by this study is compared with the model of lamb et al 2017a eq a12 as illustrated in fig 6 b with solid lines and dashed lines respectively the surface layer velocity distribution under the varying λ can be described well by eq 12 indicated by generally small errors the lamb s model eq a12 however does not show the fact that the velocity distribution changes as λ varies fig 7 shows the plot of α in eqs 12 and 13 against λ for different experimental it is noted that a grows with the increase of λ and approaches to zero the depth averaged velocities in the surface layer predicted by eq 13 under the impact of varying λ are shown in fig 8 with good accuracy the permeable interface velocity u 0 also determines the overall behavior of the surface layer velocity distribution eq 12 u 0 for 12 runs ranges from 0 29 to 0 79 m s corresponding to the surface averaged velocity in a range of us 0 26 0 89 m s two positive relationships between u 0 and us and between u 0 and λ are presented in fig 9 a and 9 b respectively which show that u 0 is not only affected by the flow velocity but also the planimetric arrangements of gravel array 4 4 flow resistance calculation performance in engineering practices flow resistance affects average velocity water level and turbulent properties and essentially controls fluvial geomorphology in man made channels and natural streams the ratio of depth averaged velocity to bed shear velocity u u can be used to describe flow resistance powell 2014 with the gravel layer averaged velocity calculated by eq 6 and the surface layer averaged velocity calculated by eq 13 the averaged velocity of the cross section can be weighted by the velocity of the gravel layer and surface flow layer lamb et al 2017a combining eq 6 and eq 13 flow resistance for a gravel bed flow takes a form 17 u u u g h g u s h s h g h s u to evaluate the performance of eq 17 five classical flow resistance equations incorporating k s d p d 84 are put here for comparison in which d 84 is the particle size of 84 percent of the material is finer hey 1979 proposed a relationship in gravel streams for hs d 84 0 3 18 u u 6 25 5 75 log h s 3 5 d 84 a simple manning stricker equation is used widely 19 u u 6 5 h s k s 1 6 smart et al 2002 showed the h s d 84 exponent of the power law flow resistance equation is enlarged from 1 6 to 1 2 with the increase in relative submergence 20 u u 1 1 h s 0 1 d 84 0 5 ferguson 2007 used a variable power equation with roughness layer relation and manning strickler relation as asymptotes expressed as 21 u u 7 5 2 36 h s d 84 7 5 2 2 36 2 h s d 84 5 3 the six flow resistance equations including those obtained by the weighted mean of flow velocities from eq a11 1 and a11 2 are applied to calculate u u fig 10 generally eqs 19 and 20 tend to overestimate u u for cases of lower velocities while others tend to underestimate u u especially eq 21 the accuracy of the results is quantitatively indicated by nsei rmse and mre see table 2 the results show that the approaches from this study perform better than other flow resistance equations which is suggested by the smallest rmse and mre and highest nsei values this is probably partially because the approach from eq 17 are calibrated by experimental data while other equations are not calibrated however the essence for the good performance is that the analytical models both take into account the physics of hydrodynamics over permeable beds 5 discussion 5 1 sensitivity analysis of u 0 the permeable interface velocity atop the gravel layer u 0 as a key role in this proposed model is associated with many factors from two perspectives i e bed context and hydraulics eq 16 is that u 0 shows a function of factors associated with bed context in this part we further explore which type have the priority in affecting u 0 based on quantitative analyses which can support the reasonability of eq 16 for bed context the gravel array spatial density λ relative submergence hs k s the relative roughness and the channel slope s are evaluated to fulfill the above objective the well known shannon s entropy weight method li et al 2011 can be applied to determine the weights of all factors for a multiple attribute decision making problem the calculation procedures are elaborated in appendix 3 the standardized index matrix as r λ hs k s s fr re is established first the entropy e and weight w of the index matrix r are calculated as e 0 951 0 966 0 674 0 835 0 895 and w 0 002 0 001 0 014 0 007 0 005 respectively it confirms our analysis that the permeable interface velocity u 0 is more sensitive to the bed context effects than hydraulic effects in particular in terms of bed slope 5 2 importance of velocity inflection point to derive the two layer subdivision model the gravel interface is simply assumed as the boundaries of the two layers gravel layer and surface layer however this assumption might be invalid for some scenarios that gravel or boulder layer is in motion due to sediment transport resulting in the varying boundary in this scene the bound of the two layers where the velocity inflection point is located might not always be fixed the concept of inflection point has been broadly used in terrestrial or aquatic vegetation canopy flows to characterize vertical velocity profiles nepf 2012b yan et al 2016 such concept can be also found in some studies in granular bed flows nikora et al 2013 wang et al 2016 to be noted the velocity inflection point essentially differs from the concept of the zero plane displacement point which is used to decide the onset of logarithmic velocity profile kim et al 2019 the velocity inflection point occurs due to the generation of large scale vortices at the roughness interface therefore the inflection point on the velocity profile can reveal more the real physics of flow in large scale gravel or boulder streams this explains that many multiple layer scaling models incorporating an inflection point were developed to predict the velocity profile through vegetation canopies ghisalberti 2002 huthoff et al 2007 shi et al 2019 in aquatic canopy flows it is reported that the inflection point does not occur or is not apparent when canopy density decreases significantly nepf 2012b an expectation works here that such similar behavior is applies for gravel bed flows because flow and turbulence physics under the two porous boundaries inherently should be the same therefore applying the current proposed subdivision model across a wide range of gravel streams with different porosities might be limited to the cases of inflection points being formed understanding how the inflection point behaves in gravel bed flows in a generalized way is critical in affecting the accuracy of the analytical model further experiments are demanded for the investigate of the behavior of inflection points in gravel bed flows 5 3 spatial effects of flow in gravel array the spatial effect exists in flows through large scale obstacles such as gravel ball arrays some experimental studies across different λ addressed this issue manes et al 2009 compared surface flow velocity statistics over gravel beds between two sets of experiments one set with one layer of spheres d p 12 mm and another with five layers of spheres these spheres are placed the same way as run a our experiments with λ 0 52 a high resolution flow measurement technology 3dpiv was applied for flow measurement the spatially averaging flow velocity can be spatially averaged by the time averaged velocities around spheres more detail can be found in nikora et al 2001 nikora et al 2004 papanicolaou et al 2012 used a very sparse gravel arrangement λ 0 05 to explore the bedload transport process four cases of manes and one case of papanicolaou are employed here to evaluate the spatial effects of gravel elements on the surface layer flow velocity the surface layer velocity distributions of these spatially averaged data are evaluated by eq 12 with the results fig 11 the case under a low λ run p1 is close to the standard logarithmic curve which is similar to our case fig 6 for a high λ our model eq 12 can make a good prediction of the spatially averaged velocity for λ 0 52 rather than the standard logarithmic model eq 11 this performance is much better than that for our dense case run a λ 0 52 see fig 6 the rooted cause is that ours are not manipulated with spatial averaging and for the dense gravel configuration velocity profile is very sensitive to the spatial effect of flow therefore this model is substantially effective in predicting the velocity distribution in gravel streams after eliminating the spatial effect the similar spatial effects may also be expected to be more significant in the gravel layer however the adv used in this study cannot measure velocity near the impermeable bed or near the bounds of the balls which only allowed the measurement of the velocities with the upper apart of the profile in the gravel layer therefore a more advanced measurement technique e g an ultrasonic velocity profiler upv system should be used for velocity measurement in the gravel layer and the spatially averaging of velocities in the gravel layer particularly for dense gravel bed is needed to improve prediction accuracy 6 conclusions a two layer subdivision approach to derive the velocity distribution in gravel bed streams considering the effect of gravel array spatial density was developed in this study the flow motion in the gravel layer following the porous medium theory was governed by the darcy forchheimer brinkman dbf equation and the taylor s expansion theorem was introduced to simplify the differential equation for attaining velocity distribution in the gravel layer which to our knowledge has been reported for the first time the velocity in the surface layer was derived by a modified mixing length approach by considering the effect of gravel array spatial density to test our model and the effects of gravel array spatial density velocity distributions over a gravel bed simulated by ping pong ball arrays with varying spacing were measured by a series of flume experiments the results showed that the gravel layer model and the surface layer model could describe the velocity and can be integrated to obtain accurate averaged depth velocities of significance was that the surface layer model could predict with different gravel spatial densities which has not drawn attention previously the flow resistance established by our model was compared with other models which showed our model performed well as indicated by better statistics parameters nsei rmse and mre with an objective analysis based on shannon s entropy weight method the permeable interface velocity u 0 was slightly more sensitive to the bed context in particular the bed slope rather than the hydraulic effects a sensitivity analysis of u 0 plausibly also explained the reasonability of adding gravel array spatial density to modify the mixing length moreover with other data sources over dense gravel beds our model was suitable for the data pre dealt with the spatially averaging where the spatial non uniformity effect was great in conclusion the presented two layer subdivision approach is promising to reveal the more detailed physical mechanism of flows in gravel streams many problems related to more complex and natural gravel bed streams however need to be considered and studied such as flow form resistance induced by micromorphology and sediment transport credit authorship contribution statement ming luo conceptualization methodology formal analysis writing original draft writing review editing chen ye data curation xiekang wang supervision funding acquisition er huang supervision funding acquisition project administration xufeng yan conceptualization methodology validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is supported by the second tibetan plateau scientific expedition and research program grant no 2019qzkk020402 and the national natural science foundation of china grant no 51639007 and no 51909178 and the fundamental research funds for the central universities 2020scu12064 thanks to francesco comiti and all the anonymous reviewers for their feedback that have helped us improve this research appendix 1 the exact solution setup for u in the gravel layer eq 4 is a typical second order inhomogeneous linear equation with constant coefficients whose solution is the sum of the general solution of the homogeneous equation and a particular solution of the inhomogeneous equation itself eq 4 can be rewritten as a1 ρ g μ m s f u 0 2 2 u 0 u z 0 z 2 u z 2 d a 2 μ m u where da 2 is defined as ρ g k 1 the first part general solution homogeneous equation a2 2 u z 2 d a 2 μ m u 0 the characteristic equation of eq a2 a3 η 2 d a 2 μ m 0 the characteristic roots are a4 η 1 2 d a μ m hence the general solution of eq a2 is a5 u c 1 e d a μ m z c 2 e d a μ m z where c 1 and c 2 are two unknown coefficients 2 the second part specific solution the left hand side of eq a1 can be expressed as a6 ρ g μ m s f u 0 2 2 u 0 u z 0 z p m z e β z where p m z is a function of z and β is an exponent coefficient according to eq a6 β 0 is not characteristic roots of eq a3 so the specific solution u s can be assumed as a7 u s b 0 z b 1 submitting eq a7 into eq a1 the coefficients are b 0 2 f u z 0 u 0 b 1 k s f u 0 2 therefore the general solution of eq a1 is combined with the sum of eq a5 and a8 expressed as a9 u c 1 e d a μ m z c 2 e d a μ m z 2 f u z 0 u 0 z k s f u 0 2 adding the boundary conditions given by eq 3 into equation a9 the coefficients c 1 and c 2 of eq a5 are solved as c 1 1 α b 1 5 u 0 2 α b 1 5 u r 2 ks 2 1 2 α b 1 5 k f u 0 2 2 α b 1 5 k f u 0 u r c 2 1 α b 1 5 u 0 2 α b 1 5 u r 2 ks 2 1 2 α b 1 5 k f u 0 2 2 α b 1 5 k f u 0 u r letting a k s f u 0 2 b k f u 0 2 c 2 k f u 0 u r and d d a μ m submitting eq a10 and definition of function cosh and sinh into eq a9 can be used to simplify to yield eq 5 appendix 2 the depth averaged velocity by lamb et al 2017a based on eq 1 lamb et al approximated the square of the depth averaged velocity within the gravel layer as 1 h g h g 0 u 2 d z c 3 u g 2 in which c 3 depends on the velocity distribution then eq 1 could be solved using the quadratic formula u g 1 2 1 c 3 k f 2 4 s c 3 k f h s h g 1 1 2 1 c 3 k f where c 3 2 due to the linearity of velocity distribution and the negligible deep groundwater flow the surface averaged velocity is u s u 1 κ 1 m κ k s h s ln 1 κ m h s k s 1 u 0 u which is obtained by integrating the following velocity distribution u z u 1 κ ln 1 κ m z k s u 0 u appendix 3 the shannon s entropy weight method assuming there are m s sample data with ns pieces of indexes x ij is the jth index s value in the ith sample data the whole calculation procedures are expressed as s1 normalization of indexes r ij x ij min x i max x i min x j the standardized index matrix r can be accomplished after normalization s2 calculation of the index s entropy following the definition of entropy the entropy of the jth index can be determined by e j ln n s 1 i 1 n s p ij ln p ij where p ij r ij i 1 n s r ij and the entropy matrix is shown as e note that p ij ln p ij can be set to equal to zero if r ij 0 s3 calculation of the index s entropy weight the weight of importance of the jth index can be determined by w j 1 e j m s i 1 n s e i and the entropy weight matrix is shown as w if the entropy of the x ij index is smaller it indicates that the variation degree of the index value is higher and more useful information is attained more information can play a key role in the comprehensive evaluation and increase the index s entropy weight w j appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127581 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3513,the standard exponential and logarithmic laws for flow velocity evaluation cannot be applied for gravel bed streams due to the effect of large scale roughness an analytical model based on a two layer subdivision approach was developed to predict flow velocity over a gravel array with different densities the velocity distribution in the gravel layer was derived by solving the darcy forchheimer brinkman dfb differential equation based on the concept of porous medium flows the velocity in the surface layer was modeled by the mixing length theory with the length scale modified by taking into account the porous effect of the gravel ball arrays to assess the model flow velocities over gravel beds simulated by ping pong ball arrays with different densities or porosities were measured in a laboratory flume the results show that the predicted velocities by this subdivision model agree well with experimental data reflecting that the porosity of the gravel array essentially impacts the flows both in the gravel layer and surface layer in comparison with the existing models not considering the porous effect of the gravel bed this model can effectively predict vertical velocity distributions and thereby flow resistances in gravel streams the permeable interface velocity atop the gravel layer as the boundary condition for the two layer model is sensitive to the bed context effect rather than the hydraulic effect suggesting that the inflection point of the full velocity profile might be vital in determining the accuracy of the model moreover with other data sources over dense gravel bed our model is suitable for data pre dealt with the spatially averaging where the spatial non uniformity effect is great keywords gravel bed streams gravel array spatial density two layer subdivision approach velocity distribution analytical model 1 introduction gravel bed streams with a wide distribution of sediment particles are commonly found in the piedmont and mountainous regions lateral landslides debris flows and flash floods bring boulders onto stream beds to generate various bedforms such as cascades or clusters of various kinds bathurst 1985 rickenmann 2001 yager et al 2007 nitsche et al 2011 piton and recking 2019 because of intensive sediment movement and river platforms flash floods in the mountainous regions usually lead to more severe disasters compared with lowland floods under the same flood discharge wilcox et al 2006 schneider et al 2015 lamb et al 2017a zhang et al 2020 therefore the quantitative prediction of bedload transport rate and bedform evolution in gravel bed streams is desired comiti et al 2007 ferguson 2007 powell 2014 schneider et al 2016 lamb et al 2017b as reported by ferro and pecoraro 2000 nikora et al 2001 bathurst 2002 katul et al 2002 rickenmann and recking 2011 lamb et al 2017a ferro and porto 2018 and luo et al 2020 the vertical velocity distribution in gravel streams is characterized by an inflection point atop the gravel layer which substantially deviates from the exponential or logarithmic law due to the resistance of the gravel layer the velocity below the gravel top is far lower than that in the surface layer canovaro et al 2007 the velocity distribution in the gravel layer is assumed constant exponential linear or a hybrid pattern nikora et al 2004 the velocity prediction methods over large scale roughness can be classified into two categories powell 2014 the first type is to explore physically based models of flow velocity for instance katul et al 2002 developed a mixing flow model for the deflected velocity distribution across the roughness bed luo et al 2020 recently proposed a multivariable mixing flow analogy to achieve high accuracy the second however adopts a subdivision concept for flow through large scale sediment obstacles and submerged canopies providing more physics of the flow roughness interaction nikora et al 2001 nikora et al 2007 introduced the space time averaging of the ns equations to the spatially non uniform velocity distribution over a gravel layer lamb et al 2017a derived an exact solution of the gravel layer velocity with the integration of the seepage equation for flow motion somehow the velocity distribution in a gravel stream is analogous to that in a vegetated stream since the roughness layer for both is porous the concept of flow layer subdivision has also been applied in vegetated flows nepf 2012a for instance a single layer model was proposed to search for the prediction equation of the mean velocity by revising the hydraulic radius or applying genetic programing cheng 2015 tinoco et al 2015 two layer models were developed to describe flow velocity in the surface and vegetation layers respectively stone and shen 2002 huthoff et al 2007 cheng 2011 shi et al 2019 moreover vegetation density is shown to have a significant impact on velocity distribution nepf et al 2007 yan et al 2016 with similar regard the gravel spatial density is expected to have a substantial impact on velocity distribution in gravel streams the knowledge of gravel bed flows under the impact of varying gravel array spatial density defined as the volume fraction of gravel particle to total space is reported by only few flume experiments canovaro et al 2007 conducting flume experiments with different immobile particles spacing showed that gravel array spatial density substantially affected flow resistance yager et al 2007 studied the bedload transport rate over a steep boulder bed with immobile particles in varying spatially distributed patterns and demonstrated that with a small gravel array spatial density the shear stress derived from mobile particles tended to decrease and the error of bedload transport equation tended to increase luo et al 2020 found that the ratios between the standard deviation of instantaneous velocity and shear velocity in gravel bed with a varying gravel array spatial density were closer to typical values in mixing layer flows manes et al 2009 and papanicolaou et al 2012 investigated the spatially nonuniform velocity distribution within a gravel array but did not present the impact of varying array spatial density the prediction method of the vertical velocity distribution for gravel streams taking into account the effect of varying gravel array spatial density has not been proposed and the velocity profile inside the gravel layer has been rarely solved this study contains two perspectives of novelties as below a two layer subdivision model is developed to simulate flow velocity distribution and averaged velocity in both the gravel and surface layers with the aim of considering varying gravel array spatial density to simulate the vertical velocity distribution in the gravel layer a solution of the darcy forchheimer brinkman dfb differential equation is derived with the linear approximation by the taylor expansion for the surface layer the velocity distribution is modeled by a logarithmic law with modified mixing length theory taking into account the effect of gravel array spatial density flume experiments of flow over gravel bed with different spatial densities mimicked by a ping pong ball array with different arrangements are conducted flow velocity data from this study and published literature are used to verify and assess the proposed model 2 analytical model of velocity in gravel bed streams in a stream with a permeable gravel bed the flow is divided into two layers namely the gravel layer and surface layer fig 1 a compared with a standard logarithmic type flow velocity distribution in the surface layer has a significant distortion affected by the gravel layer the flow behavior in the gravel layer is similar to the flow through a large scale porosity medium note that the porosity of the gravel layer is assumed homogeneous fig 1b 2 1 gravel layer model flow velocity within the porous medium can be modeled by the darcy s equation however the darcy s equation only simply characterizes linear seepage processes in porous mediums with the increase of fluctuations in the porous medium the seepage process might be nonlinear nield and bejan 2017 thus the forchheimer term is used to model nonlinear flow regime caused by turbulent momentum exchange which is profound with a large reynolds number lamb et al 2017a tortuosity in the large porous medium increases extra viscous shear stress which is integrated as the brinkman term for flow through the porous medium therefore the gravel layer flow can be modeled using the darcy forchheimer brinkman equation dfb equation as follows nield and bejan 2017 1 p μ k u ρ f ϕ sub u 2 k μ m 2 u z 2 where u is the flow velocity f is the dimensionless form drag forchheimer constant coefficient k is the intrinsic permeability coefficient of the medium depending on the geometry rather than fluid motion ϕ sub is the porosity of the porous medium μ is the dynamic viscosity of the fluid and μ m is the effective viscosity constant depending on the tortuosity of the medium ρ is the fluid density and z is the distance above the bed in the direction perpendicular to the bed p ρ g s is the pressure gradient in the flow direction in which g is the gravitational acceleration 9 81 m s2 and s is the channel slope on the right hand side the first term is the darcy term the second term is the forchheimer term associating with the nonlinear regime and the third term is the brinkman term accounting for porosity in the gravel layer eq 1 can be rewritten as a second order non homogeneous linear differential equation with constant coefficients but it is challenging to find the exact solution due to the existence of u 2 what s more eq 1 is applicable for steady uniform and unconfined fluids and the boundaries of porous medium are assumed impermeable however flow in gravel layer would be accelerated by the surface layer flow with high velocity across the gravel water interface similar to the mixing flow layer this feature in gravel streams shall be considered in the dfb equation before applying the equation to gravel layer flow here a simple analytical approximation of eq 1 is proposed the purpose of introducing the forchheimer term in darcy s equation is to solve the turbulent flow with a large reynolds number the solution depends on how to solve the forchheimer term for avoiding calculating u 2 the flow velocity u z is assumed to be differentiable vertically thus u 2 z can be approximated by the value for a fixed position with the taylor s theorem as shown in the following equation 2 u 2 z u 2 z 0 2 u z 0 u z 0 z z 0 r k z where u z 0 denotes the derivative of u z at z z 0 r k z denotes the truncation error term of taylor s theorem describing the asymptotic behavior which can be omitted the magnitude of r k z as a high order term is much smaller than other terms for a thin gravel layer porous media the same treatment was used for gaseous slip flow in a long microchannel dongari et al 2007 for submerged shrub like vegetation flow liu et al 2012 and for incompressible flow in porous media antohe and lage 1997 besides for a permeable medium gravel layer vegetation layer exchange layer the effects of the bed topography become larger than that of the viscous force and inertial force so that u 2 z has been reported by previous studies in gravel bed flow bathurst 2002 smart et al 2002 if the interface boundary is impermeable the boundary can be set as the no slip condition for velocity distribution for the permeable interface boundary conditions however the velocity at the permeable interface should be different from zero and only decays to zero in the gravel layer numerous studies adopt the beavers and joseph condition to describe the boundary condition between a saturated porous medium and an outer free fluid auriault 2009 an empirical formula proposed by beavers and joseph 1967 verified by the homogenization theory based on the systematic use of the notion of separation of scales in jäger and mikelić 2009 is given as u z z 0 u 0 u z z 0 α b k u 0 u r where α b μ m μ is the beavers and joseph s phenomenological parameter and depends on hydraulic conductivity which is greater than that of different porous materials experimental observation koplik 1983 ur is the mean velocity normal to the boundary and can be associated with vertical fluctuation caused by local eddies due to the roughness elements based on the concept of homogeneous isotropic turbulence ur is assumed to be equal to the tangential instantaneous velocities monin and yaglom 2013 hence ur is assumed linearly associated with bed shear stress parallel to the bed ur eu in which e is an empirical relaxation coefficient to attain the influence of bed surface and u τ 0 ρ is the bed shear velocity in which τ 0 is the bed shear stress z 0 0 is set as the location of permeable interface boundary which connects with the surface layer flow then substituting eq 2 into eq 1 the standard second order nonlinear inhomogeneous differential equation could be simplified with the reduction of the order of u yielding 4 s f u 0 2 2 u 0 u z 0 0 z μ m ρ g 2 u z 2 u k where k ρ g k μ is the hydraulic conductivity and f f ϕ sub g k is a dimensionless forchheimer coefficient using the boundary condition given by eq 3 the exact solution for the velocity u in the gravel layer is obtained the detailed derivations are shown in appendix 1 the final expression of u is 5 u z α b 1 5 u 0 u r b c b sinh d z u 0 a 1 α b 1 5 b cosh d z c z a where a k s f u 0 2 b k f u 0 2 c 2 k f u 0 u r and d d a μ m and the range of z is from h g to zero in the gravel layer these terms of eq 5 account for the effects of large reynolds number and large porosity in the gravel layer which are utilized to modify the nonlinear velocity distribution then the depth averaged velocity u g for the gravel layer can be obtained by integrating eq 5 from z h g to zero and dividing by h g yielding u g 1 h g h g 0 udz 1 d h g α b 1 5 u 0 u r b c b 1 d h g α b 1 5 u 0 u r b c b cosh h g d 6 1 d h g u 0 a 1 α b 1 5 b sinh d h g c h g 2 a 2 2 surface layer model the velocity distribution in the surface layer is derived by a mixing length approach which is improved from lamb et al 2017a in our model the improvement is made by incorporating the effect of gravel array spatial density in the definition of mixing length with the boussinesq eddy viscosity hypothesis the reynolds stress τ quantifying the vertical momentum exchange yields 7 τ ρ u 2 1 z h s ρ l 2 d u dz 2 μ t d u dz where l is the mixing length scale μ t is the eddy viscosity u is the local mean velocity and h s is the depth of the surface layer following prandtl s hypothesis the eddy viscosity μ t yields 8 μ t ρ u 1 z h s l to take into account the impact of the roughness layer on the surface layer the mixing length l is treated as a sum of two components given as a hybrid mixing length model 9 l κ z r where κ 0 41 is the von karman constant coefficient r is the length scale of coherent structures near bed for the near bed surface region turbulent mixing is dominated by wakes shedding from rough gravel surface which controls the momentum exchange across the gravel water interface on determining the value of r different studies have proposed empirical equations correlated with the roughness height regarding terrestrial tree canopy raupach et al 1996 aquatic vegetation nepf 2012b and gravel bed katul et al 2002 lamb et al 2017a large scale eddies near the porous gravel bed surface somehow tend to penetrate into the porous layer which influences the velocity distribution to our knowledge there are no theories or data exploring the relationship between coherent structures and gravel bed configuration a qualitative description based on the physics of vortex boundary interactions is given as follows so that the r established to modify the mixing length can be mathematically formulated randomly firstly we know that near bed large scale eddies are caused by the flow instability arising from rough topography such structures on one hand act as an agent of eddies between the large and small scales and on the other hand promote the momentum exchange between different velocity layers effectively nepf 2012b nikora et al 2019 secondly the coherent structures tend to permeate the deeper position due to the decrease in gravel array spatial density which is similar to vegetation flow interfaces e g flows through submerged vegetation therefore it is rational to take into account the effect of gravel array spatial density when defining the mixing length the effect of gravel array spatial density should diminish when the gravel layer is either infinitely sparse or dense as a result the mixing length l is only associated with the vertical location and r 0 when the bed topography gradually becomes sparser from dense condition or denser from sparse condition however the coherent structures induced by varying bed topography permeate deeper water depth to enhance the mixing length increasing the value of r therefore a maximum value might exist for r herein a modified r simply assumed to be formulated by a quadratic function is given by 10 r m k s α λ 2 α λ where k s is the roughness height and m has been derived by lamb for z k s i e m κ 30 exp κ u 0 u α is a negative fitting coefficient and λ is the gravel array spatial density defined as the fraction of the total solid volume occupied by the gravel elements and the total volume compared with the model of lamb et al 2017a λ is a new parameter taken into account for the solution in this study for a solid wall or empty space λ approaching 1 or 0 the mixing length l in eq 9 reduces to kz by manipulating an integration from z k s 30 to z z the standard velocity logarithmic equation can be achieved 11 u z u 1 κ ln 30 z k s similarly substituting eq 8 9 and 10 into eq 7 by integrating gives 12 u z u 1 κ ln 1 κ m a λ 2 a λ z k s u 0 u where z ranges from 0 to h s in the surface layer the depth averaged surface velocity u s 1 h s 0 h s u z d z in the surface layer can be obtained by integrating from z 0 to h s and dividing by h s 13 u s u 1 κ 1 m a λ 2 a λ κ k s h s ln 1 κ m a λ 2 a λ h s k s 1 u 0 u 2 3 model performance evaluation the nash sutcliffe efficiency index nsei root mean square error rmse and mean relative error mre are reliable statistical parameters widely used to assess the fitting goodness of hydrological and hydrodynamic models expressed as 14 1 nsei 1 i 1 i n y i y i 2 i 1 i n y i y 2 14 2 rmse i 1 i n y i y i 2 n 14 3 mre 1 n i 1 i n y i y i y i where y i and y i are the predicted and measured values of the dependent variable y respectively y denotes the mean measured values of y n is the sample size in particular it noted that the nsei indicates how well the plot of measured versus predicted data fits the 1 1 line nsei 1 when the model accounts for all the variation in the measurements while 0 when the model predictions are as accurate as the mean of the measured values a negative nsei indicates that the predicted results are not reliable the rmse indicates the dispersion degree between model predictions and measured values the mre indicates the averaged relative error of all data 3 flume experiments to test the model experiments were conducted in a rectangular flume with 16 0 m in length 0 5 m in width 0 4 m in height and a slope of 0 25 in the state key lab of hydraulics and mountain river engineering in sichuan university see fig 2 a the flow was regulated by a rectangular weir with a wide top at the inlet generating a steady uniform flow regime the rough gravel bed reach with a length of 4 0 m was located in the middle of the flume two segment rough beds made of one meter long uniform rubbles were placed in the inlet and outlet of the rough gravel reach to eliminate large scale disturbances the coordinate system followed that x 0 was located at the front of the model rough gravel bed y 0 was in the center of the cross section and z 0 was at the permeable interface and also the top of spheres in this study the gravel layer was simulated by periodic span wise arrays of spherical ping pong balls of diameter d p 0 04 m gravel elements were densely placed transversely and uniformly distributed longitudinally in equal spacing fig 2b the gravel spatial spacing ds varying from 0 0 to 0 28 m was equal to integral times of ping pong ball diameter fig 2c the gravel array spatial density λ in planimetric arrangements of this study is defined as the fraction of the solid volume occupied by the gravel elements modeled by spheres v g π n k s 3 6 and the total volume v 0 b l k s where n is the number of gravel elements arranged on the rough gravel bed reach and b and l are the width and length of the rough gravel bed reach respectively hence the gravel array spatial density λ in planimetric arrangements of this study could be calculated as 15 λ v g v 0 π n k s 2 6 b l π π b k s k s 2 6 b π d s k s π k s 6 d s k s where π is the transverse alignment number of gravel array arranged on the rough gravel bed reach the height of the gravel layer is assumed as h g d p ks 0 04 m therefore the gravel array spatial density λ 0 07 0 52 by varying flow depth hs flow discharge q and gravel array spatial density λ 12 scenarios of experiments were obtained summarized in table 1 the cross section average velocity is u q b h the froude number is fr u g h 0 5 in which b 0 5 m is the flume width and water depth h is the sum of h s and h g and the reynolds number is re uh ν in which υ is the kinematic coefficient of viscosity equaling 1 01 10 6 m2 s under the current gravel bed configuration flow velocity was measured in the region of 6 m downstream from the flow inlet where the flow was fully developed following the approach of lamb et al 2017a measurements were conducted near the center of the cross section that can represent the region of the average velocity of the cross section with a mean relative error of 16 31 the specific middle measurement line along water depth was arranged in the middle of two adjacent gravel arrays as indicated by the red dashed line in fig 2c in other words the middle position of the measurement line was measured for instantaneous velocities i e the valley between ping pong balls the measurement interval in the vertical direction was 1 0 cm to obtain the detailed velocity distribution instantaneous velocities were sampled within 45 s using a side looking three dimensional sontek acoustic doppler velocimeter adv 50 hz those instantaneous velocities with the lower signal noise ratio lower than 15 db and with the correlation coefficient lower limit of 70 were removed to improve data quality goring and nikora 2002 the remaining instantaneous velocities were decomposed into time averaged and fluctuating components using a matlab code figures s1 s6 in the supporting file run c and d q 0 036 and 0 048 m3 s show that in the fully developed region the variability in velocity in the different cross sections between two gravel array rows is minor the measured averaged velocities u g and u s are obtained by integration of the profile u z note that linear extrapolation of adv velocity is used to estimate missing near bed incomplete velocity in the gravel layer lamb et al 2017a 4 results 4 1 velocity at the permeable interface in the derivation of the theoretical model the critical parameter u 0 representing velocity at the permeable interface appears both in eq 6 and 13 as shown in fig 3 a u 0 and u calculated by gravel beds simulated by ping pong ball arrays from our data run a d with different λ and natural cobbles from lamb et al s data with different slopes l1 s 0 004 l2 s 0 02 l3 s 0 08 l4 s 0 15 cannot be directly described by a simple linear relation in particular for those small values the reason might be that the developed large scale turbulence under different λ increases the non linearity of flow across the permeable interface when λ increases more turbulent momentum is transported into the gravel layer through the large scale interface turbulence therefore more factors need to be considered to establish the mathematical description of u 0 clearly u 0 can be enhanced by the generation of large scale vortices near the gravel layer interface due to vertical momentum exchange hence u 0 can be assumed as a function of the shear velocity u and the length scale of coherent structures r e g u 0 γ u r in which γ is a function symbol considering the relationship between r and bedform features in eq 10 and u g h s 0 5 in a two dimensional flow u 0 can be written as u 0 γ h s k s λ due to h h s h g in which h g is usually assumed as k s u 0 can be rewritten as u 0 γ h s s k s λ hence u 0 is expressed in an empirical form i e 16 u 0 m 0 h s a s b k s c λ d where m 0 a b c and d are constants estimated by experimental data which are 25 gravel bed flume data including ping pong ball arrays data and natural cobbles lamb et al 2017a we achieved the result of estimating empirical coefficients m 0 13 13 for lamb and 37 82 for our data a 0 5 b 0 7 c 0 5 and d 1 5 are attained λ of lamb et al s data is 0 6 in case of the overlap of natural river cobbles with ds k s 0 1 the fitting results with a mean relative error of 12 5 are illustrated in fig 3 b therefore eq 16 can be replaced by u 0 u m 0 λ 1 5 s 0 2 k s 0 5 g 0 5 in which the term m 0 s 0 2 λ 1 5 k s 0 5 g 0 5 is an experimental constant under a certain flow condition and u is dependent on flow conditions in the following eq 16 is used to estimate u 0 which is a key parameter adopted in eqs 6 and 13 4 2 gravel layer velocity for empirical coefficients appearing in the gravel layer model eq 5 the forchheimer constant f 5 10 3 the permeability k 1 10 10 m 2 the relaxation coefficient e 1 10 3 and the beavers and joseph s phenomenological parameter α b 1 23 fig 4 a and 4 b show the measured gravel layer velocity u g against the gravel array spatial density λ and measured u 0 with the results by data fitting the measured u g in the gravel layer is larger for larger λ and u 0 from the positive relationship between shear stress length scale and gravel array spatial density luo et al 2020 the large scale turbulence near bed can be restricted to the upper 50 gravel layer height for a dense gravel bed the turbulence can easily penetrate to the lower 50 for a sparse gravel bed even to the substrate bottom hence the decrease in velocity attenuation near bed is stronger as gravel array spatial density decreases besides it is interestingly noted that the increase in bed slope and gravel array spatial density can promote the value of u 0 with the same discharge the data is listed in table s1 in the supporting file which can explain the reasonability of eq 16 fig 4 c shows the comparison of ug between the measured data and predicted results with colored solid circles for eq 6 and colored solid triangles for lamb s model with an assumption of linear distribution of the gravel layer velocity eq a11 1 of lamb et al 2017a in appendix 2 the mean relative errors in the estimate of u g by eq 6 is 27 for all data and results for run c and d with smaller λ have smaller relative errors of u g the coefficients of eq 5 fitted to lamb flume data with natural gravel and cobber particles f 1 10 4 and k 6 10 11 m2 are smaller than those based on our experimental data the reasons are probably owing to the denser arrangement of gravels and faster flow employed in lamb s flume the integral linear hypothesis adopted by lamb et al 2017a and the taylor s expansion theorem for differential equation simplification in this study are two ways to derive the analytical solution of the dfb equation for the gravel layer flow the differential based method proposed in this study can show the velocity profile along with the height of the gravel layer which has not been reported by previous studies fig 5 illustrates the predicted velocity distribution predicted by eq 5 in the gravel layer z h g 2 0 it is shown that the rate of velocity decay for a denser gravel bed is larger than that for a sparser gravel bed in addition the decay rate of gravel layer velocity of the upper part is far higher than the lower part suggesting a higher shear effect of the surface layer on the gravel layer flow to our knowledge this is the first attempt to describe the velocity distribution in the gravel layer with an analytical model the comparison between the measured and predicted results at the same vertical position in the gravel layer as illustrated in fig s7 in the supporting file indicates a mean relative error of u 25 4 3 surface layer velocity fig 6 a shows the comparison of surface layer velocity profiles between the predicted results by eq 11 and the measured data with k s 0 04 m the characteristics of velocity distribution affected by λ cannot be described by the standard logarithmic law besides the velocities atop the gravel layer are significantly affected by λ fig 6a for a lower λ the surface layer velocities are less affected by the gravel layer and their distributions are closer to the standard logarithmic curve i e run c and d the performance of the surface layer velocity model eq 12 developed by this study is compared with the model of lamb et al 2017a eq a12 as illustrated in fig 6 b with solid lines and dashed lines respectively the surface layer velocity distribution under the varying λ can be described well by eq 12 indicated by generally small errors the lamb s model eq a12 however does not show the fact that the velocity distribution changes as λ varies fig 7 shows the plot of α in eqs 12 and 13 against λ for different experimental it is noted that a grows with the increase of λ and approaches to zero the depth averaged velocities in the surface layer predicted by eq 13 under the impact of varying λ are shown in fig 8 with good accuracy the permeable interface velocity u 0 also determines the overall behavior of the surface layer velocity distribution eq 12 u 0 for 12 runs ranges from 0 29 to 0 79 m s corresponding to the surface averaged velocity in a range of us 0 26 0 89 m s two positive relationships between u 0 and us and between u 0 and λ are presented in fig 9 a and 9 b respectively which show that u 0 is not only affected by the flow velocity but also the planimetric arrangements of gravel array 4 4 flow resistance calculation performance in engineering practices flow resistance affects average velocity water level and turbulent properties and essentially controls fluvial geomorphology in man made channels and natural streams the ratio of depth averaged velocity to bed shear velocity u u can be used to describe flow resistance powell 2014 with the gravel layer averaged velocity calculated by eq 6 and the surface layer averaged velocity calculated by eq 13 the averaged velocity of the cross section can be weighted by the velocity of the gravel layer and surface flow layer lamb et al 2017a combining eq 6 and eq 13 flow resistance for a gravel bed flow takes a form 17 u u u g h g u s h s h g h s u to evaluate the performance of eq 17 five classical flow resistance equations incorporating k s d p d 84 are put here for comparison in which d 84 is the particle size of 84 percent of the material is finer hey 1979 proposed a relationship in gravel streams for hs d 84 0 3 18 u u 6 25 5 75 log h s 3 5 d 84 a simple manning stricker equation is used widely 19 u u 6 5 h s k s 1 6 smart et al 2002 showed the h s d 84 exponent of the power law flow resistance equation is enlarged from 1 6 to 1 2 with the increase in relative submergence 20 u u 1 1 h s 0 1 d 84 0 5 ferguson 2007 used a variable power equation with roughness layer relation and manning strickler relation as asymptotes expressed as 21 u u 7 5 2 36 h s d 84 7 5 2 2 36 2 h s d 84 5 3 the six flow resistance equations including those obtained by the weighted mean of flow velocities from eq a11 1 and a11 2 are applied to calculate u u fig 10 generally eqs 19 and 20 tend to overestimate u u for cases of lower velocities while others tend to underestimate u u especially eq 21 the accuracy of the results is quantitatively indicated by nsei rmse and mre see table 2 the results show that the approaches from this study perform better than other flow resistance equations which is suggested by the smallest rmse and mre and highest nsei values this is probably partially because the approach from eq 17 are calibrated by experimental data while other equations are not calibrated however the essence for the good performance is that the analytical models both take into account the physics of hydrodynamics over permeable beds 5 discussion 5 1 sensitivity analysis of u 0 the permeable interface velocity atop the gravel layer u 0 as a key role in this proposed model is associated with many factors from two perspectives i e bed context and hydraulics eq 16 is that u 0 shows a function of factors associated with bed context in this part we further explore which type have the priority in affecting u 0 based on quantitative analyses which can support the reasonability of eq 16 for bed context the gravel array spatial density λ relative submergence hs k s the relative roughness and the channel slope s are evaluated to fulfill the above objective the well known shannon s entropy weight method li et al 2011 can be applied to determine the weights of all factors for a multiple attribute decision making problem the calculation procedures are elaborated in appendix 3 the standardized index matrix as r λ hs k s s fr re is established first the entropy e and weight w of the index matrix r are calculated as e 0 951 0 966 0 674 0 835 0 895 and w 0 002 0 001 0 014 0 007 0 005 respectively it confirms our analysis that the permeable interface velocity u 0 is more sensitive to the bed context effects than hydraulic effects in particular in terms of bed slope 5 2 importance of velocity inflection point to derive the two layer subdivision model the gravel interface is simply assumed as the boundaries of the two layers gravel layer and surface layer however this assumption might be invalid for some scenarios that gravel or boulder layer is in motion due to sediment transport resulting in the varying boundary in this scene the bound of the two layers where the velocity inflection point is located might not always be fixed the concept of inflection point has been broadly used in terrestrial or aquatic vegetation canopy flows to characterize vertical velocity profiles nepf 2012b yan et al 2016 such concept can be also found in some studies in granular bed flows nikora et al 2013 wang et al 2016 to be noted the velocity inflection point essentially differs from the concept of the zero plane displacement point which is used to decide the onset of logarithmic velocity profile kim et al 2019 the velocity inflection point occurs due to the generation of large scale vortices at the roughness interface therefore the inflection point on the velocity profile can reveal more the real physics of flow in large scale gravel or boulder streams this explains that many multiple layer scaling models incorporating an inflection point were developed to predict the velocity profile through vegetation canopies ghisalberti 2002 huthoff et al 2007 shi et al 2019 in aquatic canopy flows it is reported that the inflection point does not occur or is not apparent when canopy density decreases significantly nepf 2012b an expectation works here that such similar behavior is applies for gravel bed flows because flow and turbulence physics under the two porous boundaries inherently should be the same therefore applying the current proposed subdivision model across a wide range of gravel streams with different porosities might be limited to the cases of inflection points being formed understanding how the inflection point behaves in gravel bed flows in a generalized way is critical in affecting the accuracy of the analytical model further experiments are demanded for the investigate of the behavior of inflection points in gravel bed flows 5 3 spatial effects of flow in gravel array the spatial effect exists in flows through large scale obstacles such as gravel ball arrays some experimental studies across different λ addressed this issue manes et al 2009 compared surface flow velocity statistics over gravel beds between two sets of experiments one set with one layer of spheres d p 12 mm and another with five layers of spheres these spheres are placed the same way as run a our experiments with λ 0 52 a high resolution flow measurement technology 3dpiv was applied for flow measurement the spatially averaging flow velocity can be spatially averaged by the time averaged velocities around spheres more detail can be found in nikora et al 2001 nikora et al 2004 papanicolaou et al 2012 used a very sparse gravel arrangement λ 0 05 to explore the bedload transport process four cases of manes and one case of papanicolaou are employed here to evaluate the spatial effects of gravel elements on the surface layer flow velocity the surface layer velocity distributions of these spatially averaged data are evaluated by eq 12 with the results fig 11 the case under a low λ run p1 is close to the standard logarithmic curve which is similar to our case fig 6 for a high λ our model eq 12 can make a good prediction of the spatially averaged velocity for λ 0 52 rather than the standard logarithmic model eq 11 this performance is much better than that for our dense case run a λ 0 52 see fig 6 the rooted cause is that ours are not manipulated with spatial averaging and for the dense gravel configuration velocity profile is very sensitive to the spatial effect of flow therefore this model is substantially effective in predicting the velocity distribution in gravel streams after eliminating the spatial effect the similar spatial effects may also be expected to be more significant in the gravel layer however the adv used in this study cannot measure velocity near the impermeable bed or near the bounds of the balls which only allowed the measurement of the velocities with the upper apart of the profile in the gravel layer therefore a more advanced measurement technique e g an ultrasonic velocity profiler upv system should be used for velocity measurement in the gravel layer and the spatially averaging of velocities in the gravel layer particularly for dense gravel bed is needed to improve prediction accuracy 6 conclusions a two layer subdivision approach to derive the velocity distribution in gravel bed streams considering the effect of gravel array spatial density was developed in this study the flow motion in the gravel layer following the porous medium theory was governed by the darcy forchheimer brinkman dbf equation and the taylor s expansion theorem was introduced to simplify the differential equation for attaining velocity distribution in the gravel layer which to our knowledge has been reported for the first time the velocity in the surface layer was derived by a modified mixing length approach by considering the effect of gravel array spatial density to test our model and the effects of gravel array spatial density velocity distributions over a gravel bed simulated by ping pong ball arrays with varying spacing were measured by a series of flume experiments the results showed that the gravel layer model and the surface layer model could describe the velocity and can be integrated to obtain accurate averaged depth velocities of significance was that the surface layer model could predict with different gravel spatial densities which has not drawn attention previously the flow resistance established by our model was compared with other models which showed our model performed well as indicated by better statistics parameters nsei rmse and mre with an objective analysis based on shannon s entropy weight method the permeable interface velocity u 0 was slightly more sensitive to the bed context in particular the bed slope rather than the hydraulic effects a sensitivity analysis of u 0 plausibly also explained the reasonability of adding gravel array spatial density to modify the mixing length moreover with other data sources over dense gravel beds our model was suitable for the data pre dealt with the spatially averaging where the spatial non uniformity effect was great in conclusion the presented two layer subdivision approach is promising to reveal the more detailed physical mechanism of flows in gravel streams many problems related to more complex and natural gravel bed streams however need to be considered and studied such as flow form resistance induced by micromorphology and sediment transport credit authorship contribution statement ming luo conceptualization methodology formal analysis writing original draft writing review editing chen ye data curation xiekang wang supervision funding acquisition er huang supervision funding acquisition project administration xufeng yan conceptualization methodology validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is supported by the second tibetan plateau scientific expedition and research program grant no 2019qzkk020402 and the national natural science foundation of china grant no 51639007 and no 51909178 and the fundamental research funds for the central universities 2020scu12064 thanks to francesco comiti and all the anonymous reviewers for their feedback that have helped us improve this research appendix 1 the exact solution setup for u in the gravel layer eq 4 is a typical second order inhomogeneous linear equation with constant coefficients whose solution is the sum of the general solution of the homogeneous equation and a particular solution of the inhomogeneous equation itself eq 4 can be rewritten as a1 ρ g μ m s f u 0 2 2 u 0 u z 0 z 2 u z 2 d a 2 μ m u where da 2 is defined as ρ g k 1 the first part general solution homogeneous equation a2 2 u z 2 d a 2 μ m u 0 the characteristic equation of eq a2 a3 η 2 d a 2 μ m 0 the characteristic roots are a4 η 1 2 d a μ m hence the general solution of eq a2 is a5 u c 1 e d a μ m z c 2 e d a μ m z where c 1 and c 2 are two unknown coefficients 2 the second part specific solution the left hand side of eq a1 can be expressed as a6 ρ g μ m s f u 0 2 2 u 0 u z 0 z p m z e β z where p m z is a function of z and β is an exponent coefficient according to eq a6 β 0 is not characteristic roots of eq a3 so the specific solution u s can be assumed as a7 u s b 0 z b 1 submitting eq a7 into eq a1 the coefficients are b 0 2 f u z 0 u 0 b 1 k s f u 0 2 therefore the general solution of eq a1 is combined with the sum of eq a5 and a8 expressed as a9 u c 1 e d a μ m z c 2 e d a μ m z 2 f u z 0 u 0 z k s f u 0 2 adding the boundary conditions given by eq 3 into equation a9 the coefficients c 1 and c 2 of eq a5 are solved as c 1 1 α b 1 5 u 0 2 α b 1 5 u r 2 ks 2 1 2 α b 1 5 k f u 0 2 2 α b 1 5 k f u 0 u r c 2 1 α b 1 5 u 0 2 α b 1 5 u r 2 ks 2 1 2 α b 1 5 k f u 0 2 2 α b 1 5 k f u 0 u r letting a k s f u 0 2 b k f u 0 2 c 2 k f u 0 u r and d d a μ m submitting eq a10 and definition of function cosh and sinh into eq a9 can be used to simplify to yield eq 5 appendix 2 the depth averaged velocity by lamb et al 2017a based on eq 1 lamb et al approximated the square of the depth averaged velocity within the gravel layer as 1 h g h g 0 u 2 d z c 3 u g 2 in which c 3 depends on the velocity distribution then eq 1 could be solved using the quadratic formula u g 1 2 1 c 3 k f 2 4 s c 3 k f h s h g 1 1 2 1 c 3 k f where c 3 2 due to the linearity of velocity distribution and the negligible deep groundwater flow the surface averaged velocity is u s u 1 κ 1 m κ k s h s ln 1 κ m h s k s 1 u 0 u which is obtained by integrating the following velocity distribution u z u 1 κ ln 1 κ m z k s u 0 u appendix 3 the shannon s entropy weight method assuming there are m s sample data with ns pieces of indexes x ij is the jth index s value in the ith sample data the whole calculation procedures are expressed as s1 normalization of indexes r ij x ij min x i max x i min x j the standardized index matrix r can be accomplished after normalization s2 calculation of the index s entropy following the definition of entropy the entropy of the jth index can be determined by e j ln n s 1 i 1 n s p ij ln p ij where p ij r ij i 1 n s r ij and the entropy matrix is shown as e note that p ij ln p ij can be set to equal to zero if r ij 0 s3 calculation of the index s entropy weight the weight of importance of the jth index can be determined by w j 1 e j m s i 1 n s e i and the entropy weight matrix is shown as w if the entropy of the x ij index is smaller it indicates that the variation degree of the index value is higher and more useful information is attained more information can play a key role in the comprehensive evaluation and increase the index s entropy weight w j appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127581 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3514,resource user participation in decision making through local collective action likely contributes to effective groundwater management and protection despite efforts to construct generalized theoretical frameworks explaining factors influencing successful collective action in groundwater management this is a highly complex process that remains challenging this paper analyzes factors facilitating and impeding collective action in groundwater management using the rare and successful collective action example of the angas bremer irrigation district south australia drawing on data gathered through semi structured interviews this paper further explores the context under which collective action arose and changed over time the findings show a dynamic transient interaction between the following factors responsible for the rise and fall of collective action i perceived crisis ii small homogenous community iii strong leadership from respected community members iv shared norms and values v shared goals and vi trustworthy two way relationship between resource users and formal institution although it is difficult to generalize from one case study collective action and groundwater management are highly contextual these findings are useful i for other communities with similar characteristics ii to explore conditions for achieving successful groundwater governance including efficient and effective reforms iii to highlight the importance of participatory management processes iv to help government agencies understand what motivates communities to engage in collective action and how that leads to successful groundwater co management and v to expand on a very small body of literature documenting stakeholders narratives on collective action and groundwater management keywords collective action groundwater management success factors socio hydrogeology murray darling basin australia 1 introduction common pool resources cpr are those where several users are entitled to the resource and include surface and groundwater fisheries pastures and forests cpr are often degraded over time because resource use is not effectively managed meinzen dick et al 1999 groundwater management is especially challenging because of its invisible nature slow recharge rates large spatial distribution and open access closas and villholth 2019 jakeman et al 2016 barthel et al 2017 resulting in nearly a third of aquifers around the world being depleted faster than they are replenished molle and closas 2019 the global degradation of this vital resource has led to many negative social economic and environmental impacts jakeman et al 2016 brouwer et al 2018 which are likely to be accelerated by climate change green 2016 increased reliance on groundwater during droughts has also led to aquifer depletion and highlights the need for action by resource owners and governments pradhan and ranjan 2016 dramatic recent examples of such water crises include cape town south africa lavanchy et al 2019 and the murray darling basin australia grafton 2020 despite the need for action groundwater management remains reactive and in most contexts unlikely to prevent future crises wilhite 2011 water crises are mostly crises in governance more so than in management mukherji and shah 2005 re 2015 curtis et al 2016 according to mukherji and shah 2005 groundwater management refers to expert driven processes derived from mathematical model building exercises of hydrologists and the formulation and implementation of groundwater laws by water managers natural resources governance is defined as the interactions among structures processes and traditions that determine how power and responsibilities are exercised how decisions are taken and how citizens or other stakeholders have their say graham et al 2003 more specifically groundwater governance embodies a shift to a more integrated approach that considers the interests concerns of hydrologists policy makers groundwater users and other stakeholders mitchell et al 2011 poor governance is at least in part attributed to the failure of decision makers to fully incorporate the human dimensions of natural resource management including consideration of users values goals social and personal norms and local practices and the distributional impacts of interventions e g equity impacts barthel et al 2017 good governance is supported by the core principles defined by lockwood et al 2010 of legitimacy transparency accountability inclusivity fairness integration capability and adaptability it is more likely to occur when decision makers respond to specific social contexts engage stakeholders and evaluate the appropriateness of different policy instruments curtis et al 2016 closas and villholth 2019 this is because groundwater systems are part of large complex socio ecological systems comprising of many biophysical socio economic and human components all interacting with each other barreteau et al 2016 therefore a single actor is not capable of addressing all issues and all stakeholders should be involved in decision making mitchell et al 2012 success of groundwater governance ultimately depends on the users behavior wegmann and mußhoff 2019 although it is clear sustainable groundwater management requires an integrated approach by incorporating social aspects jakeman et al 2016 hydrogeologists and groundwater managers are still debating how to do this in practice curtis et al 2016 re 2015 barthel et al 2017 state centered groundwater governance has largely been ineffective molle and closas 2020b on the other hand there is evidence that participatory approaches such as co management regimes i e shared management between formal institutions and resource users can lead to effective groundwater management fao 2015 molle and closas 2020b however examples of successful co management are rare molle and closas 2019 one explanation is that once a co management regime is put in place governments assume the users will automatically take on the roles that were previously conducted by the government katon et al 1999 in places where collective action does not voluntarily emerge the withdrawal of the state could leave a management vacuum because the users would have to coordinate their activities develop rules to monitor compliance and mobilize the required financial and human resources katon et al 1999 a recent example of such lack of success is offered by ratna reddy et al 2020 who state lack of local collective action as the reason for co management not to arise groundwater management participatory approaches are likely to be more successful if underpinned by local collective action e g lopez gunn 2003 lopez gunn and cortina 2006 esteban et al 2012 shalsi et al 2019 defined by ostrom 2000 as the action taken by a group either directly or on its behalf through an organization in pursuit of members perceived shared interests there is a large body of literature that examines the factors that facilitate collective action in natural resources management nrm e g wade 1987 ostrom 1990 tang 1992 baland and platteau 1996 meinzen dick et al 1999 agrawal 2001 etc molle and closas 2020a reviewed factors affecting collective action in groundwater management presenting 12 different case studies with varying levels of success concluding that successful cases of collective action are rare it remains unclear what governance framework i e the level of co management or the level of shared responsibility between states and users is most effective to support collective action and under which conditions milman and kiparsky 2020 molle and closas 2020a an extensive literature review of almost 300 publications on the social dimensions of groundwater management shows factors affecting collective action in groundwater in australia are understudied mitchell et al 2011 thus it is essential to identify the drivers behind collective action and understand the conditions under which it arises in order to design appropriate institutional frameworks contributing to better groundwater management molle and closas 2020a this paper draws on an australian case study to identify the impediments and factors facilitating collective action in groundwater management the angas bremer ab irrigation district in south australia sa the so called driest state in australia dew 2017 is the case study the ab is at the lower end of a very complex and sensitive socio ecological system ses the murray darling basin mdb the mdb 14 of australia s land area is australia s food bowl producing 39 of the country s agricultural products by value mdba 2017 the ab community faces unique water management challenges being at the end of the basin and not having control over upstream water management decisions the ab is considered a rare example of successful co management which started in the late 1970s cuadrado quesada 2014 and a rich and unique case study as documented by shalsi et al 2019 and detailed in the case study section below shalsi et al 2019 studied the history of water management in the ab exploring the links between the level of collective action co management and water management outcomes they concluded that successful groundwater co management in this system rose from collective action this paper goes further to analyze the factors that influenced collective action to understand the drivers behind it it draws on the analysis of data collected in 14 interviews of stakeholders directly involved in ab s groundwater management history the aim is to identify lessons for managers or researchers interested in exploring participatory models for better groundwater governance in australia and internationally which can enable decision makers to adapt institutional frameworks to local social economic and environmental contexts to the best of our knowledge this work is part of very limited number of scientific papers e g cuadrado quesada 2014 incorporating stakeholders quotes and narratives therefore documenting examining and preserving key knowledge on groundwater management on social dimensions of groundwater management especially in what relates to collective action and co management 2 factors affecting collective action formal frameworks such as ostrom s 1990 institutional design principles followed by ostrom s institutional analysis and development iad have been developed to improve the design of institutional arrangements to facilitate collective action and in turn provide the basis for successful co management ostrom s 1990 design principles have been supported empirically a vast amount of literature has focused on understanding their application for the improvement of groundwater governance and management e g seward and xu 2019 robertson 2020 and they are useful in providing a framework for evaluating water governance arrangements robertson 2020 however such formal approaches have been critiqued for focusing on institutional designs in isolation and often forgetting the social historical and ecological context in which those institutions were created afroz et al 2016 resource users are strongly influenced by the community s norms and values and power dynamics which are often not accounted for in such approaches baldwin 2008 wang and ching 2013 afroz et al 2016 ratna reddy et al 2020 molle and closas 2020a there is a need for nrm approaches that incorporate the specific historical and social context of resource users armitage 2005 afroz et al 2016 as well as informal collective action local networks and motivations behind the users actions vanni 2014 agrawal 2001 analyzed the three most comprehensive nrm studies that seek to construct theoretical generalizations on collective action baland and platteau 1996 ostrom 1990 and wade 1988 and created a comprehensive list of 25 factors and conditions that enable resource users to engage in collective action the author grouped these factors in a set of four basic categories i resource system characteristics ii group characteristics iii institutional arrangements and iv external environment from a resource system perspective the scarcity of the resource and the salience to the users are key factors that influence collective action ostrom 1992 other important factors are size and productivity of the resource very large territories make defining boundaries and monitoring the system too costly while small territories do not generate enough funds ostrom 2009 considering productivity if the users think their resource is exhausted or abundant they will not have a motivation to act collectively ostrom 2009 however if the users perceive a credible threat on a resource they are dependent on they consider the benefits of collective action to exceed the costs ostrom 2009 the eastern la mancha aquifer spain lopez gunn and cortina 2006 and the saint louis valley california usa molle and closas 2020a are examples where a groundwater crisis encouraged users to organize to face the threat to their groundwater sustained livelihoods when it comes to group characteristics smaller homogenous communities that engage in face to face communication and regular community meetings are more likely to act collectively ostrom 2010 in a smaller community costs of negotiation are lower the outcomes are observable and the likelihood of compliance to the rules is higher which in turn allow for information exchange and for the creation of social relationships ostrom 2010 naghar et al 2016 vanni 2014 molle and closas 2020a argue small communities of up to 1000 groundwater users engage more easily than those of tens of thousands of users however a small homogenous community with well defined boundaries will not necessarily lead to collective action as users also need to have the capacity and commitment to sustainably manage their resource clark and brake 2008 thus sustainable nrm can be promoted by building human and social capital mitchell et al 2012 human capital denotes the individuals skills and capabilities i e leadership personality attributes social skills communication skills intelligence etc whereas social capital represents the networks social relations and trust that arise between people when interacting as well as their norms and values ostrom and ahn 2001 community leadership is a key ingredient in successful collective action ostrom 2010 the presence of a dedicated and well respected individual who is willing to commit and has the ability to convince the community to voluntarily contribute to their common issue is a key requirement for successful collective action sutton and rudd 2015 social capital is generated through networks and positive interaction between individuals and government agencies these networks build the capacity for user communities to effectively manage resources and facilitate social learning kewit and kewit 2004 informal institutions that is traditions customs moral values religious beliefs and all other norms of behavior that have passed the test of time pejovich 1999 p 166 and networks amongst users are equally as important as formal institutions that is rules and laws enforced through official channels north 1991 lopez gunn and cortina 2006 conclude it is the successful relationship between the regulator and regulated that leads to positive collective action and the creation of successful relationships is facilitated by open honest and regular communication between stakeholders which ultimately leads to trust ostrom 2000 trust and reciprocity are important components of social capital collective action is not only a matter of constructing strong institutions but also a matter of building trust between the government and users as well as trust amongst users de vos and van tatenhove 2011 trust is essential for public participation as it determines the acceptability of management policies and there is evidence that where trust is present litigations and delays in policy implementations are less likely to occur sharp and curtis 2014 jamieson et al 2020 additionally trust reduces conflict and removes the fear of free riding which is one of the main social dilemmas that impedes collective action ostrom 1999 naghar et al 2016 institutional arrangements can contribute to collective action by providing support funding to monitoring of the resource and technical advice and stakeholder engagement in monitoring and decision making katton 1999 ostrom 1992 ostrom 2009 ostrom 2001 molle and closas 2020a involving users in monitoring provides them with more information on the gravity of the issue and allows for both local users and government departments to create a shared picture of the condition of the resource lopez gunn and cortina 2006 re 2015 jamieson 2020 according to ross et al 2008 this motivates users to organise and act collectively leading to more successful outcomes in comparison to government legislation alone the lockyer valley australia sarker et al 2009 and lerma chapala basin mexico wester et al 2007 are examples where the lack of shared knowledge about the resource has negatively impacted collective action engaging stakeholders in decision making encourages mutual learning curtis et al 2016 incorporates the community s values and local knowledge in policies enabling trust to be built between policy makers and those affected by policies and improves the government s accountability clark and brake 2008 through regular and honest communication policies can be legitimized by public acceptance and so they are more likely to be effectively implemented and maintained clark and brake 2008 stakeholder participation not only increases compliance but also motivates resource users to voluntarily contribute to management initiatives curtis et al 2016 lopez gunn 2003 and esteban and albiac 2012 concluded that water user associations were imposed to the community in the western la mancha aquifer spain resulting in unsuccessful groundwater management they found that in the neighbouring eastern la mancha aquifer where collective action arose from the users aquifer recovery was achieved further allowing resource users to devise their own rules is what enables local collective action to contribute to the success of management policies ostrom 1990 2009 lutz and caldecott 1996 curtis et al 2014 research regarding factors that affect collective action in groundwater management in australia is limited to baldwin 2008 skurray 2015 cuadrado quesada and gupta 2019 molle and closas 2020a and robertson 2020 it is worth re noting that collective action is highly contextual from a ses perspective and as such it is important to analyze its specificities in an australian context skurray 2015 analyzes ostrom s situational variables in the gnangara aquifer in western australia and identifies components of the current institutions that should be modified to facilitate collective action baldwin 2008 also analyses ostrom s design principles by taking the lockyer valley in queensland australia as a case study concluding that ostrom s principles and the community s values should be reflected in groundwater management however without explaining how the community s values should be reflected into policy molle and closas 2020a summarise the factors why co management in the lockyer valley was unsuccessful both skurray 2015 and baldwin 2008 suggested collective action as means of better groundwater management in australian case studies although without giving guidance on how to achieve it in practice robertson 2020 uses ostrom s 1990 design principles to analyze queensland s current water governance framework and highlights how the absence of some of those principles may have contributed to unsustainable outcomes in the surat basin cuadrado quesada and gupta 2019 discuss how legal frameworks that include participation can mitigate local groundwater issues in australia and costa rica although without specifically mentioning factors that impact collective action the above mentioned research focuses on formal institutions and there is a clear gap in addressing collective action in groundwater management from an informal institutional context in australia which is important as pointed out by shalsi et al 2019 3 methods this paper uses the case study and data collection process described in shalsi et al 2019 here we only provide the elements that are critical for the analyses of this paper s research questions 3 1 case study the ab irrigation district is located 60 km to the southeast of adelaide state capital and 30 km inland from the murray river mouth abrwm 2021 fig 1 it is home to 160 irrigators and is delineated by a prescribed well area pwa 250 km2 for groundwater management purposes as of 2008 ab farmers irrigated 7 100 ha including 5 400 ha of wine grapes 470 ha of lucerne pasture and 430 ha of potatoes thomson 2008 the area is economically supported by a thriving wine industry which largely relies on groundwater for irrigation although surface water has also been used from the mid 1990s langhorne creek is its main town and gives name to this prime wine region the region derives its name from the fresh salinity of 1 000 mg l ephemeral angas and bremer rivers which flow from the mount lofty ranges to the terminal lake of the murray darling system lake alexandrina harris 1993 the regional climate is mediterranean with average rainfall varying from 490 mm year in the northwest to 380 mm year in the south zulfic and barnett 2007 pumping mainly occurs from the deep heterogenous transmissivities of 100to 1 500 m2 day semi confined murray group limestone aquifer mgla of 75 to 100 m thickness zulfic and barnett 2007 it is the preferred aquifer due to i low salinities 1 500 to 3 000 mg l in the central part near the rivers although of up to 10 000 mg l near the basin margins and ii high yields up to 40 l s zulfic and barnett 2007 the mgla is covered by a quaternary shallow unconfined low quality salinity of up to 30 000 mg and low yields 5l s aquifer howels 1994 zulfic and barnett 2007 consider direct rainfall recharge to the mgla insignificant affirming the aquifer is mainly laterally recharged although receiving some vertical recharge from the shallow quaternary aquifer in the river plains fig 2 presents a summary of the findings of shalsi et al 2019 in the form of a timeline of the main management and climatic events the level of collective action and the main management outcomes in the ab region from 1950 to present as of 2017 identified from interviews secondary literature and government reports ab s groundwater management timeline was divided into 5 phases based on historical and temporal evolution of governance structures and or impactful events that occurred at the time this allows for linking the level of collective action with the main management climatic events or changes in governance structures which in turn allows for better understanding the factors that facilitated or impeded collective action over time zulfic and barnett 2007 offer a thorough discussion on the spatio temporal evolution of groundwater levels and pumping phase 1 1950 1979 corresponds to the start of groundwater pumping in the 1950s by the late 1970s irrigators realized their crops were being negatively impacted by the increased salinity and lowered aquifer yields during this phase there was no legislative control over groundwater pumping and the annual groundwater pumping reached 26 600 ml by 1981 which amounts to four times the estimated volume of annual natural recharge thomson 2008 an obvious example of a cpr facing the tragedy of the commons during this phase the collective action levels were low phase 2 1979 1997 started with the creation of the community based advisory committee angas bremer water resource advisory committee abwrac from now on referred to as the ab advisory committee as a response to the aquifer degradation the ab irrigators took the initiative to create the ab advisory committee which was composed of local irrigators as well as hydrogeologists water managers and other specialists from sa government their role was to plan strategies and provide advice to sa government ministers for the development and execution of water management policies to reduce groundwater extraction and maintain sustainable future extractions muller 2002 the ab advisory committee lobbied the state government for the proclamation of the area as a water management zone meaning that all irrigators had to purchase water licenses and comply with the requirements of the water resource act 1976 leading to allocation limits being set and reduced howles 1994 it was a period characterized by high community collective action and a strong co management regime between the government department and ab irrigators after ab s proclamation the ab advisory committee in partnership with the government department developed and executed two water management plans wmp in 1987 and 1992 the main policies included in the two plans that facilitated the reduction of groundwater extractions were i an imposition of a 30 cut on individual groundwater entitlements by allowing irrigators to swap their groundwater licenses for surface water licenses and therefore gain access to a similar volume of surface water from lake alexandrina ii encouragement of privately funded and implemented managed aquifer recharge mar through injection wells such as giving irrigators the right to extract 50 of the their allocated surface water to artificially recharge it into the aquifer and allowing irrigators to carry over for up to 3 years any unused lake water stored in the aquifer thomson 2008 and iii the ability to trade surplus water for profit these policies applied for the duration of the respective wmp phase 3 1997 2005 began with the new water resources act of 1997 which stated that a formal water allocation plan wap had to be developed for the ab irrigation zone substituting the former wmp developed by the ab advisory committee consequently the government agency river murray catchment water management board from now on referred to as the rm catchment board replaced the ab advisory committee muller 2002 the rm catchment board was responsible for the development and the implementation of the wap 1997 2002 encompassing a much larger catchment than just the ab district the ab advisory committee had no longer a clear role in developing the new wap muller 2002 because the community still wanted a voice in policy development it created the voluntary community group angas bremer water management committee from now on referred to as the ab management committee consisting of local irrigators technical staff from the government department and the rm catchment board this new partnership between ab management and rm catchment board ensured that innovative policies were being developed and implemented in a technically robust manner whilst remaining under community ownership muller 2002 the co management regime established in phase 2 remained strong during phase 3 and so did the level of collective action this led to reducing groundwater extractions by 80 harris 1993 to maintain the sustainability of water use the ab management committee developed and implemented a code of practice cop for all irrigators in the area which later became a legal requirement as part of their water license the cop which was funded and managed by the irrigators involved a rigorous water monitoring and reporting system as well as a requirement to plant 2 ha of native vegetation for every 100 ml of surface water from lake alexandrina entitlement to prevent waterlogging phase 4 2005 2009 started with the introduction of the nrm act 2004 which recognized that all natural resources should be managed in an integrated manner nrm boards were established as a state level advisory board responsible for the preparation of the waps emlr wap 2013 this meant that the ab wap was integrated into the eastern mount lofty ranges emlr plan the ab community was much less involved with the development of these new plans that incorporated a much larger area however collective action remained high due to the effects of the millennium drought which led to reduced water levels and increased water salinity of lake alexandrina ab s main source of surface water in phase 2 and 3 consequently the ab committee lobbied for the construction of a government funded 110 km pipeline to bring water directly from the river murray shalsi et al 2019 phase 5 2009 2017 started with the pipeline connecting the river murray to ab which coincided with the end of the millennium drought the pipeline provided 16 000 to 24 000 ml year of water to the region from 2013 to 2020 abrwm 2021 phase 5 goes until the end of the analyzed period this is a period of low co management and low collective action 3 2 data collection 14 face to face semi structured interviews were conducted in adelaide and ab from february to may 2017 with key representatives of all stakeholder groups directly involved in and knowledgeable of ab s water management between the 1950s and 2017 to understand their perspectives and experiences with the local groundwater management history the open ended questions presented in appendix 1 were purely focused on the interviewees experiences with the management history of the region and no personal background questions e g sex gender identity age were asked as they were not considered relevant and in fact never arose as part of the responses the participants were chosen based on the snow ball technique and the sample size was defined based on the theoretical saturation point in which no new concepts arise from the interviews participants in the study signed an informed consent form allowing their quotes to be published anonymously a list with interviewees their respective stakeholder group government department ab advisory committee nrm board and industry and start year of involvement in ab water resources management is provided in shalsi et al 2019 in this paper we analyze the interview passages relating to the factors that affected collective action in each phase aiming to understand how changes in context such as management events policies climatic events and governance structures can influence the level of collective action understanding how context impacts water user behavior could provide insight into keys to successful ground water management policies that could lead to aquifer recovery 3 3 data analyses the interviews were transcribed verbatim and coded thematically using nvivo version 10 the aim of the coding was to systematize the transcripts by identifying the most common themes which were grouped and analyzed based on an adaptation of ostrom s 2009 socio ecological systems ses framework table 1 the ses framework was developed as a response to the criticism that the iad paid insufficient attention to informal institutions and the complexity of interactions between nature and society cole et al 2014 the ses framework incorporates a large set of social and biophysical attributes that could influence management outcomes the main factors that influenced collective action were grouped into three categories a groundwater resource characteristics b groundwater users characteristics and c formal institutions i e government department and nrm boards for the purpose of this paper 4 results the results have been presented based on whether the factors were facilitative or an impediment to collective action and evaluated based on the three categories in table 1 i e groundwater resource characteristics groundwater user characteristics and formal institutions fig 3 presents the most influential factors that dictated the level of collective action for each stage most of the characteristics and events happening during phases 1 2 and 3 facilitated collective action while phases 4 and 5 are mostly characterized by factors impeding collective action phases 1 and 4 are somewhat transition periods between low and high levels of collective action as explained below 4 1 factors facilitating collective action the results of our analysis show that phase 1 s collective action was low as the irrigators were unaware of their unsustainable rates of groundwater extraction collective action was highest during phases 2 and 3 when the irrigators started feeling the impacts of decreased groundwater levels and increased salinities and consequently started working collaboratively with the government department towards solutions high collective action continued in phase 4 during the peak of the millennium drought despite a low co management level due to policy changes as will be explained below a groundwater resource characteristics a1 crisis all 14 interviewees mentioned crisis as a factor that facilitated collective action as stated by an nrm board member it is the pending disaster that motivates people into action a crisis brings people together the resource users perception of being in a crisis is equally important once the irrigators realized that over extraction was negatively impacting their crops the level of collective action started rising and the irrigators decided that they needed to act as stated by a government official one of the reasons things happened so well down there is that they were genuinely scared that the resource was at risk and that s enough to spark them into action whereas when we come in and people are unconvinced that they have a problem it s way harder to get them to engage and get involved and by an irrigator it worked really well for those first 20 years the committee was first formed out of a need everybody knew we had a crisis and we react to the crisis we ve got we were proactive enough to come back to that point of if we do nothing we ll be told what to do let s be on the front foot and have an input into our own destiny b groundwater resource users characteristics b1 small homogenous group one of the conditions that was repeatedly emphasized during the interviews was the size of the group using the resource 160 irrigators in a smaller group it is easier to enforce rules and avoid the free rider problem through peer pressure users can identify anyone who does not have rights to use the resource as stated by an industry member i haven t heard of anyone not complying to the rules it was a very small community they would drive around and look i know what they re doing they know what i m doing so if you re going to do something dodgy people will know about it 10 14 of the interviewees mentioned small size has contributed to the successful collective action in ab because when a group is small members tend to build closer relationships due to frequent and highly personalized interactions as stated by an industry member being small has benefited ab because you all know each other whereas in other regions there s a lot more diversity and a lot more to manage in one way it small number of users helps to form a cohesive group b2 human capital results from the interviews strongly suggest personalities and skills of ab s community members have been key to successful collective action from all the components of human capital 14 14 interviewees singled out leadership from respected members of the community as a key factor an example quote from a government department employee states the key members of the committee were the ones that initiated a lot of change and unfortunately it does come down to some individuals if you re lucky with someone who has the knowledge and the communication skills and the charisma to get the message over otherwise you get someone who s not very competent which makes the relationship more difficult strong leadership not only facilitates the coordination and organization within the community but also helps build trustworthy relationships with formal institutions as stated by an irrigator if we hadn t had that leadership and that guidance from respected community people who could stand up and defend the decision that s been made the community won t buy it communities don t trust governments don t trust nrm and don t trust anything that takes money off them you ve got to build the bridge governments can t build bridges and nrm can t you need the locals to help build the bridge b3 social capital strong social capital within the ab community facilitated collective action shared norms and values heavily influence the ability of users to act collectively ab has a strong history of cooperation between irrigators since early colonization 1800s it is the shared nature of floodplains and the fact that the ab irrigators have been permanent residents in the area for generations with no absentee farmers that has built strong trustworthy relationships between irrigators which can be illustrated by the quoting of a government department employee and an industry member the bremer river flows through the area and for years they managed that themselves they used to trap the water as it came down in flood at the end of winter and diverted on to the paddocks to give the vineyards a big soak which would then pretty much carry them throughout the season people on top of the system got the water first when they d finish they d pass it on to the next person and so forth there were never any rules written down they just did that with a wink and a nod and water was passed down through the system it was shared the makeup of the community has a lot to do with it the families here have been here for 5 6 generations and langhorne creek is one of the few communities that like to run and own everything the whole football complex and sporting ground is community owned and run and this builds relationships between people features of social capital that aids in collective action are also past successful experiences and knowing how to work with government as mentioned by an nrm employee some farmers find it really hard to deal with government they just don t understand how it works and you normally come up against a bit of mistrust but the ab irrigators had that track record of working with government so when they put together a proposal to take it to the government they re well received because they ve already got that government work with them in the past b4 knowledge of ses and dependence on the resource understanding the ses and groundwater dependence was critical for collective action in ab as previously mentioned the irrigators started noticing the aquifer overdraft but they did not know its consequences for the sustainability of the system and for their economic activity this was especially critical because groundwater was the only reliable available water source shalsi et al 2019 the following quote from an irrigator illustrates these two factors so when we were in trouble before we knew we had a problem and there was a lot of concerned irrigators but we didn t know extent of the problem we requested the government to do a study of the water use in the area to give us an indication of how much we were pumping the study indicated we were pumping 29 600 ml which is way over what the basin can sustain c formal institutions c1 funding during phase 2 the government department was providing funding and technical support for the ab advisory committee and both groups worked collaboratively to produce the first two water management plans as well as the annual irrigation reporting scheme in phase 3 the rm catchment board provided funding and technical support to the ab management committee similarly both groups worked collaboratively developing the code of practice and other sustainable management practices this funding allowed the ab management committee to have face to face consultations with on ground hydrogeologists as well as continue their monitoring data collection and reporting scheme additionally with funds from the rm catchment board a fullstop device was implemented by researchers for the ab irrigators to monitor groundwater salinity levels as quoted by an ab advisory committee member the rm catchment board funded certain projects they did some pretty good work at the ab with scientists from csiro who invented the fullstop device they actually educated the people a lot about irrigation and flushing salts through c2 monitoring c2 monitoring and b4 knowledge of ses are closely related because monitoring allows for a better understanding of the system and a better understanding of the system allows for refining monitoring and better interpreting acquired data 10 14 interviewees mentioned that technical knowledge of the system through monitoring the resource was a key factor facilitating collective action because it allowed for all stakeholders to share an understanding of the hydrological issue as affirmed by an irrigator it s very hard to manage anything if there s no information about it the department set up a system of collecting information every year and each irrigator collected that sequence of information for their property and in addition to that you ve got all the wells owned by the farmers that they were reading the water meters and measuring depth so i as a farmer would know exactly what s happening at my place each farmer had a 6 m deep monitoring well and would measure 4 times a year and report their own information which was summarized into the irrigation annual report about the whole community so you ve got real data and if you have got a situation of salinity rising or wells going down everyone agrees that we ve got to do something about it rather than starting at no we don t have to do anything remarkably ab irrigators had the initiative of self conducting monitoring in their property wells simultaneously field government technicians were monitoring groundwater which helped both parties not only to create a shared picture of the resource but also to build trust as referred by an nrm employee and a government department hydrogeologist they irrigators managed their own data with their own community data manager this was really important because they owned their own data they analyzed it and reported it back to the community themselves there was a high level of trust about 95 of irrigators would fill in their annual report even when it was voluntary initially what happened in other south australian areas was that the government would collect the data analyze it and then impose policies on the community which did not bring good results c3 networks within formal and informal institutions a key concern is that policy makers do not accurately portray on ground issues as scientists may be somehow isolated from the real world re 2015 as agreed by a government official a lot of young hydrogeologists here haven t been out of the office they haven t had the opportunity to do field work and it s very hard to form good relationships if we hardly step out of the office 13 14 interviewees stated that the key to ab s successful collective action in phases 2 3 and 4 was because of the partnership between the government department and the irrigators this partnership allowed for irrigators to understand the hydrogeological characteristics of the aquifer by receiving technical advice from on ground scientists it also allowed for policy makers to understand local knowledge and traditions when both parties understand each other s realities and when the community feels like they are contributing to the solutions it leads to better outcomes as stated by an irrigator it started as a proactive movement by the community to try and control our own destiny we worked very cooperatively with the department for the first 10 15 years they invested some good technical advisors hydrologists geologists that sat on the committee with us we d come up with ideas they d go back and explore it and model it and tell us whether it would work or not we wrote 5 wmp through that collaborative atmosphere we got good outcomes from those plans and at least 90 of the community went with it that led on to annual reporting we were one of the first committees in the basin to start that we had success and we started to see aquifer recovery c4 trust another important factor is building relationships between the irrigators and formal institutions because it leads to trust between both parties increasing knowledge on both sides in ab on ground hydrogeologists were very involved with the community as quoted by a government department hydrogeologist i used to go down to all the community meetings and i d stay on an extra night and just go around and visit the farmers and interact with them having a physical presence in the area is what builds relationships these interactions make the irrigators better informed about their issues and therefore they have a much better informed discussion about how to solve it but also they educated us about what s going on there and this two way flow builds a relationship where there s trust c5 collective choice institutions in addition to funding a key contribution from government agencies to collective action is having collective choice institutions that allow community groups to take part in decision making as noted by ostrom 2001 the two main roles of formal institutions are to i provide the resource users with accurate information regarding the physical conditions of the resource and ii to allow resource users to create their own institutional arrangements to manage the specific issue they are facing the institutions governing ab fulfilled both criteria as stated by a government department hydrogeologist the two reason why it worked so well was because they irrigators i used to have technical people every month sitting in their meetings and feeding them scientific information and ii did have a lot of influence over the outcomes of that plan the irrigators were heavily involved with the first two wmp as well as the formal wap of 2001 we sat around the table and they drove the show in ab a key factor mentioned by 10 14 interviewees that motivated the irrigators to act collectively was the autonomy of the committee ability to influence policy and the fact that they felt ownership of the problem the water resource act 1976 provided an institutional framework where all water stakeholders could work together which allowed for the creation of ab advisory committee the autonomy and the ability to influence decisions and policies combined with the understanding of the gravity of the issue gave the ab irrigators a sense of ownership of the problem which then allowed the ab irrigators to push for tough policies as stated by a government department hydrogeologist so then they irrigators accepted the fact that allocations had to get down to a certain level but they had a contribution about how it was done and they accept the cuts because they owned the process they had a say in it whereas if the government just dictated we re going to reduce it by this there s no real ownership it s a bit top down so it s not going to work but again the key is for them irrigators to have the technical understanding which hopefully we can give them so they know what the limits are again definitely a two way thing rather than us dictating which used to happen in the past 4 2 collective action impediments phase 4 marks the transition between strong and weak collective action phase 4 started with a drastic change in governmental water management strategies i e the introduction of the emlr plan and the changes in governance structures that came with it contributing to erode collective action nevertheless the millennium drought was a dramatic problem for the irrigators during this phase which allowed collective action to remain high the impacts the emlr plan had on collective action emerged once the millennium drought was over and the water crisis was perceived to be finished which marked the beginning of phase 5 a groundwater resource characteristic a1 absence of water crisis phase 5 saw a marked decline in collective action sparked by a perceived absence of a water crisis as the millennium drought was over as quoted by an nrm employee so i think the group has struggled a little bit for membership because we ve sort of nailed the salinity problem and we ve got access to better quality water before there was a crisis bringing them together and now there s not a2 size of management zone the emlr plan aims to manage natural resources in a holistic way by incorporating different management zones and conjunctively managing all natural resources however in practice this holistic management negatively impacted collective action from the ab community s point of view besides the drought crisis being over according to the majority of interviewees the two main factors that affected collective action in phases 4 and 5 were i increased size of management zone 10 14 interviewees and ii reduced funding 14 14 interviewees the emlr plan introduced new management issues such as environmental flows vegetation health etc from the ab community s perspective this shifted the focus from groundwater increased the complexity and diversity of the issues and increased the area of the management zones as explained by an irrigator the legislation is driving it not the community needs there was a national water plan nwi written saying that all this has to happen of course we do need a national water plan but the problem with it is that it doesn t have flexibility if the national plan said we are aiming to achieve xyz however work with communities to get there it doesn t say that b groundwater user characteristic b1 social capital the increased size of the management zone a2 led to a loss of social capital manifested in the absence of shared goals this is illustrated by a government department official in the quote the way we manage now trying to make it more holistically doesn t resonate as clearly as if it was purely about water in the early 1990s when the issue was only water we could put up graphs with water levels and salinity and no one in that room could argue that they didn t have a problem they could see it but now with the emlr over the top of that came the problem with the water dependent ecosystems so it was a more complicated discussion and we might argue for years now is there a problem b2 no dependence on groundwater the ab alleviated their dependence on groundwater by building a pipeline from the river murray in 2009 as a response to the same drought the diverse sources of water i e groundwater and surface water from lake alexandrina and the river murray gave the ab community a perceived sense of drought proofing which led to a fall in collective action according to one government official they managed to drought proof themselves this fall in collective action due to the diversification of water supply i e lack of dependence on groundwater and the perception of being drought proof directly relates to the absence of crisis a1 mentioned above nevertheless this idea of drought proofing is not consensual amongst the community and can have negative water management implications and an irrigator stresses the importance of preparing for future crisis we are reactionary we react to the crisis we ve got we don t look forward to the next one we handle that one the drought s finished the water s flowing we ve got our order back and the aquifer is rising beauty what else is going on we tend to move from crisis to crisis c formal institutions c1 reduced funding leading to reduced c 2 monitoring c 3 social networks and c 4 trust 13 14 interviewees agreed that reduced funding from the government department and nrm boards was a key issue that reduced collective action in ab the reduction in funds directly led to a decrease in c2 monitoring c3 networks between formal and informal institutions and c4 trust between community members and government institutions funding towards the ab committee kept decreasing each year with the setting up of the nrm boards which meant less funding to continue ab s monitoring c2 this is illustrated by quotes from a nrm employee and an industry member groups like the ab who traditionally did a lot of monitoring and on ground work that sort of money is no longer available they still do the annual monitoring but the report on the fullstop devices has sort of dropped back importantly reduced funding also meant reductions in human resources such as on ground government hydrogeologists negatively impacting the formal informal networks consequently the level of collective action is lower when compared to phases 2 and 3 as stated by an ab advisory committee member and the main issue was that the department started to cut the money off to support the local committee they started withdrawing their technical people so that left us with none of that interaction with department and that link back to the department all of a sudden we re writing letters instead of talking to the people as previously mentioned in the facilitative factors face to face interaction with the same government officials over a long period of time builds trust between both parties making the implementation of new policies more acceptable when this network is absent trust also diminishes as quoted by an nrm employee some farmers find it really hard to deal with government they just don t understand how it works and you normally come up against a bit of mistrust c2 collective choice institutions although the ab advisory committee never had a regulatory role and always was an advisory committee during phases 2 and 3 the community perceived they had power because they drove the wmp and influenced policies formally nothing changed with regards to the actual power the ab committee had when the nrm boards were introduced however the community s perceptions changed as explained by a government official the group started to wear a different hat the nrm was responsible for developing and amending the emlr plan and water licensing stuff so they went from being an advisory committee that was formed and driven out of the central department to being only reporting to the board in both cases they were only advisory but it certainly felt that they had less power in the new iteration before the nrm they were suggesting the ideas whereas after it was probably that the ideas were being generated out of the nrm board and government department despite the efforts of the nrm board to keep the community engaged this perception of their inability to influence decisions reflected in lowered collective action as stated by an industry member at the moment they are struggling with community engagement and enthusiasm because i think there used to be much more feelings of ownership of it and that s gone it s easy while it s local but now we ve got to think about the emlr the sense of ownership diluted it a fair bit the nrm board staff tried really hard to engage people they are just not as comfortable because they don t feel like they can influence and they feel like there s a lot of stuff there that s not relevant to them and they don t feel like the local flavors come through in the end product so it just doesn t sit with them 5 discussion 5 1 effective collection action in groundwater management a complex interaction between factors the ab example shows that although it is critical to identify and list the factors that affect collective action e g agrawal 2001 it is arguably more important to understand how they interact to nurture collective action or otherwise the discussion below exposes how the factors interacted and consequently influence the levels of collective action some factors are discussed in combination because they are directly interrelated although collective action and groundwater management are highly contextual and it is difficult to generalize from one case study this discussion explores conditions for achieving successful groundwater governance including efficient and effective reforms the importance of participatory management processes and how can government agencies understand what motivates communities to engage in collective action and how that leads to successful groundwater co management 5 2 groundwater crisis a1 and dependence on groundwater b5 as mentioned throughout the results section a key sparker of collective action in ab was the crisis in phases 1 2 and 3 related to groundwater over pumping and consequent depletion and degradation the community was heavily dependent on groundwater for this period although surface water from lake alexandrina became part of the supply mix during phases 2 and 3 which was critical for the reduction of groundwater consumption phase 4 brought a new water crisis related to the millennium drought in which surface water was no longer available and groundwater returned to being the sole source realizing a groundwater crisis unfolding phase 1 led a few irrigators to collectively take action and engage with formal institutions to address the problem phase 4 marked the transition from high to low collective action with the millennium drought keeping collective action high and the integration of the ab wap in the emlr as part of the nrm act making it low collective action became low during phase 5 as combination of the legislative change mentioned above and the absence of a water crisis partially because of access to alternative surface water sources groundwater crisis and dependence acted as first catalysts to facilitate or impede collective action as shown in examples from the eastern la mancha spain lópez gunn 2012 sheridan county kansas usa and san luis valley colorado usa molle and closas 2020a 5 3 group size b1 and management boundaries a2 and a3 crises do not necessarily bring people together ranjan 2014 and are not enough for successful collective action bekkar et al 2009 in addition to the resource physical attributes users characteristics are critical wang and ching 2013 two facilitating factors repeatedly emphasized in literature are i the size of resource user groups and ii clearly defined boundaries ostrom 1990 tang 1992 baland and platteau 1996 schalger 2007 ostrom 2010 size can be a disputed factor while some authors e g ostrom 1990 2009 2010 argue that a small size is conducive to collective action allowing for homogeneity in objectives norms and cultural values others e g agrawal 2001 argue that if a group is small it is much harder to attain the necessary resources to successfully engage in collective action our results show the small and homogeneous group of ab irrigators allowed for successful collective action because i there was a common problem affecting all irrigators ii there was a sociocultural cohesion iii it was easy to discuss and reach an agreement on the problem and solutions and iv it was easy to make sure everyone was complying with the rules this agrees with ostrom 2010 who concludes that collective action is more likely to occur in smaller groups because i they are more cohesive ii it is easier to exchange information leading to shared goals and iii it is easier to enforce rules and prevent free riding problems on the other hand large groups can increase monitoring costs reduce the effect of norms and make communication harder wang and ching 2013 molle and closas 2020a show that in mexico social heterogeneity of a large group contributed to impeding collective action similarly when ab was incorporated into the wider emlr plan in phase 4 collective action diminished because the increased diversity and complexity of the issues diverted the focus away from water resources which led to ab irrigators feeling that the new policies are not locally relevant to them according to ostrom 1990 a critical factor for successful collective action is well defined boundaries however the ab example shows that the size of the management area also plays a role although the emlr plan had a clearly defined management zone the widening of the boundaries decreased collective action and the irrigator s motivation to participate in community meetings 5 4 human b2 and social capital b3 as agreed by all interviewees one of the main factors that facilitated collective action in ab was effective community leaders human capital which agrees with the work of ostrom 2000 lopez gunn and cortina 2006 lópez gunn 2012 lockwood et al 2010 cuadrado quesada 2014 and skurray 2015 phases 2 3 and 4 saw very strong leadership from respected community members who drove the ab management and advisory committees these committees being initiated by trusted community members increased the perceived legitimacy and credibility of the committees by the rest of the community this trust was facilitated from but also increased the strong social capital present in the community numerous authors have stressed the important role social capital e g ranjan 2014 miao et al 2015 plays in the successful co management of groundwater and the ability of resource users to act collectively like katton 1999 our results show that the community s norms and values affect the user s ability to engage in collective action where a strong cooperation tradition increases the likelihood of collective action due to a history of sharing flood waters for irrigation for almost a century ab has always had a very strong sense of community and cooperation which was portrayed in their ability to organize themselves and form committees to collectively solve emerging issues furthermore trust building networks can lead to collective action because they facilitate coordination and cooperation towards mutual goals ranjan 2014 and personal interactions help in building trust between users sharp and curtis 2014 linking back to ab irrigators being a small well defined and homogeneous group our results support those of meinzen dick et al 1999 who states that when groups i are created around a joint goal ii share similar norms and values and iii have established a history of trust and cooperation information and coordination costs are reduced facilitating the emergence of collective action the likelihood of successful collective action is increased when a community has a common issue and a shared goal miao et al 2015 5 5 ses knowledge b4 and formal institutions c1 5 groundwater is managed more effectively through an integrated approach encompassing all aspects that influence a groundwater ses jakeman et al 2016 in the case of ab ses knowledge and connection with formal institutions c1 funding c2 monitoring c3 networks c4 trust and c5 collective choice institutions cannot be decoupled these links are explored below our findings are in accordance with lópez gunn 2012 who concludes that the trustworthy relationships between users is necessary but not sufficient as collective action as a catalyst of successful groundwater co management would not be possible without the support and collaboration from formal institutions a key ingredient for the successful partnership in ab was users knowledge of the groundwater system which was fostered by face to face communication with on ground government hydrogeologists ab had a government supported robust system of monitoring and reporting during phases 2 and 3 which helped both the community and the government department share a common picture of the groundwater issue ostrom 1992 emphasizes the importance of monitoring for understanding the condition of the resource and preventing free riders thus encouraging collective action on ground hydrogeologists facilitate a two way sharing of information while local users have direct knowledge of the resource use and socio economic factors at play in the community e g conflict social structure values and norms hydrogeologists have a better technical understanding of the resource e g sustainable yield aquifer interconnectivity and ecological conditions at a larger scale combining both knowledges creates a fuller picture closas and villholth 2019 direct contact between irrigators and hydrogeologists also facilitated a trust based bridge to be built between the community and the government department the irrigators believed the information the department was providing them with and the department trusted the community s ability to provide sound advice as mentioned by most interviewees it was this successful partnership that allowed the irrigators to be involved in the wmp development and in turn the implementation of widely accepted policies that reduced groundwater extractions by 80 muller 2002 although hydrogeologists often ignore the importance of building relationships with the community re 2015 field hydrogeologists are often the first point of contact with irrigators and they are the ones who can encourage and help to implement bottom up co management approaches by engaging with the community re 2015 lopez gunn and cortina 2006 without these networks there is a risk of disconnection and proposed solutions by policy makers may not accurately reflect on ground issues as scientists are too isolated from the real world according to baland and platteau 1996 who also state what is required for successful collective action is a two way process of information sharing between rural people and the administration this is critical since there is often lack of trust between water users and formal institutions lopez gunn and cortina 2006 according to lockwood et al 2010 confidence and trust in nrm boards and government departments is a key factor in community collaboration and thus effective co management bell and park 2006 explored the effectiveness of developing new water allocation plans in new south wales australia and concluded that according to communities a key issue hindering the successfulness of the new policies was lack of information from governments according to the authors lack of information erodes the water users confidence and trust decreasing their willingness to engage in collective action when users do not understand the issue they do not engage and collaborate on the development of policies thus policy implementation tends to be more difficult clark and brake 2008 funding was a critical factor facilitating the above mentioned monitoring and intra institutional interactions baland and platteau 1996 suggest that governments often fail to allocate sufficient funds to resource conservation because other more urgent priorities hold a heavier political weight ab is a very good example of this during phases 4 and 5 when direct contact with field hydrologists ceased because of bureaucratic changes and decrease in funding the ability to perform robust monitoring and reporting and to have on ground technical advisors building relationships and sharing information was possible because the ab committee was very well resourced by the government over phases 2 and 3 margerum 2007 states in an era of declining management resources it is difficult for agencies to put resources toward long term preventative efforts when there are immediate short term demands during phases 4 and 5 resourcing shifted to managing natural resources holistically securing environmental flows in rivers promoting irrigation efficiencies vegetation health and preserving biodiversity this meant that the nrm board the chief providers for the ab committee started to reduce their funding substantially and continuously towards the group this led to the reduction in monitoring data and regular contact with on ground technicians hindering collective action within ab our research confirms ostrom s 2001 point that autonomy gives users a sense of ownership the capacity of users to create their own rules and establish the means of monitoring and sanctioning the rules constitute a key factor that help individuals to solve their collective action problems when institutions do not allow space for self organization and take over the management of a natural resource it destroys an immense stock of social capital ostrom 2001 baland and platteau 1996 summarize it brilliantly when resource responsibility is taken away from the village so is the concern for the viability of the resource two important factors lead to the decline in collective action in the ab during phases 4 and 5 i the committee s perceived lack of autonomy and ability to make any meaningful contribution to policy change and ii the loss of relevance when incorporated into the larger emlr plans our research adds evidence to the argument that although natural resources should be managed in an integrated manner face to face networks with on ground hydrogeologists and community members should remain for smaller scale problems to be better integrated into larger management areas an ab interviewee clearly stated that government plans should allow more flexibility for local institutions to self organize and create their own rules as put by social researcher brené brown in the context of organizational change we desperately want change but too often we want to engineer the vulnerability humanity and messiness out of change efforts we want to build systems and track accountability without engaging people not only does this kill change it corrodes trust and engagement connection and relationships are the heart of change brown 2021 6 limitations and future work it is difficult to draw generalized conclusions and policy recommendations from one case study especially considering groundwater management is highly contextual bekkar et al 2009 on the other hand the contextual flavor that a case study brings is important to understand the nuances of groundwater management and to provide lessons for managers researchers and uses to apply to their aquifer systems to the best of our knowledge this is one of very few groundwater management social studies including quotes and narratives from local stakeholders a rare example is cuadrado quesada 2014 it is important to document and examine such groundwater management history so that it can be preserved for posterity and available for the management and scientific communities in addition to the above discussed factors some other factors were scarcely mentioned by a few interviewees as potentially collective action influencing such as generational changes adaptability to change personal connections with politicians and time commitment these factors seem to have played a minor role for the involvement of particular people an example is some family farming businesses where the younger generation taking over did not engage in collective action as much as much as the previous one these factors were not explored further as we focused on factors relevant for the area at large future work on the angas bremer case study can include analyzing stakeholders perspectives on effectiveness and efficiency assertions in conjunction with biophysical data 7 conclusion this paper illustrates and discusses a rare example of collective action that led to successful co management and positive groundwater outcomes it answers calls for international successful examples on collective action and co management in groundwater and most importantly on their critical influencing factors e g molle and closas 2019 molle and closas 2020a the ab example confirms collective action is most effective when it starts from a community level and can serve as a catalyst for successful co management in turn leading to successful groundwater management the results show that during the phases when community collective action was high groundwater management was more successful with more and better outcomes as opposed to the phases where collective action was low this is mainly because resource users feel ownership of the problem and are more likely to accept and comply with management policies following the critiques that frameworks on collective action mainly focus on formal institutions rather than the resource users perspective this study used the ab irrigation system as a case study to identify and analyze the main factors that facilitate or impede collective action in groundwater management and how it evolved through time with climatic crises and governance changes 14 qualitative interviews were conducted to take into consideration the community s perspective on the socio cultural context in which ab s collective action arose examining the changes that happened within the ab community from the 1950s until the present day the main factors and conditions that facilitated the emergence of collective action within the ab community are i perceived crisis ii small homogenous community iii presence of strong leadership from respected members of the community iv shared norms and values v shared goals and vi trustworthy relationships between community members a main lesson learnt from the ab experience is that strong social and human capitals act as a catalyst for successful collective action and in turn for successful co management however these are not enough strong support from government departments and agencies is a crucial condition for a shared understanding of the groundwater system through monitoring and data co interpretation the ab committee by working together in a cooperative way with the government department developed and implemented innovative water management policies which led to reduction of groundwater extractions by 80 promoted artificial recharge from excess surface water changed crops for increased profitability and decreased water consumption and constructed pipelines accessing surface water sources although it is not possible to generalize from one case study we can confidently conclude that positive human and social capitals within a resource users community facilitates collective action which combined with support from the government departments and agencies leads to successful co management government departments can support users by providing funds to i monitor the resource and providing timely feedback on the resource and ii having on the ground hydrogeologists to provide the community with the necessary scientific information and technical advice finally on ground hydrogeologists must have the ability to form successful and trust building relationships with the user groups through open honest and regular communication between stakeholders additionally government departments must give users the autonomy required for users to be able to devise their own rules collective action is highly dependent on the specific location and the historical institutional social and economic contexts therefore groundwater management policies should consider local scale allowing for the community s norms and values and local knowledge to be reflected in policies and management approaches the findings from this study recommend against government institutions to change management areas and approaches in systems where effective collective action occurs without properly consulting groundwater users even if the changes may seem technically sound they will only facilitate better management if users understand and accept such changes otherwise government institutions risk eroding or erasing human and social capital and to break trust ties between stakeholders which are critical for managing groundwater systems in all their dimensions credit authorship contribution statement sarah shalsi conceptualization methodology formal analysis writing original draft writing review editing project administration carlos m ordens conceptualization methodology writing original draft supervision writing review editing allan curtis conceptualization methodology resources writing review editing craig t simmons conceptualization resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank ms diane davidson for suggesting us this interesting research project the authors would also like to thank prof christine trenorden ms emily mendham dr constantine seidl and ms leah hunter for insightful discussions that helped in conducting this research work we would like to thank the interviewees for their availability and valuable information provided we would also like to thank the editor and three anonymous reviewers for their contributions to improving the paper appendix 1 no question 1 can you tell me when and how you first became involved in the management of the ab groundwater resource has either the nature e g role or extent of your involvement changed over time if so how and why 2 what is your understanding of how local people have been involved in decisions about the management of the ab groundwater resource has that changed over time if so in your view what have been the main changes if so why do you think those changes occurred 3 how much influence have local people really had on decisions about the management of the ab groundwater resource has their influence changed over that time if so how if so why do you think those changes have occurred 4 what do you see as the main benefits of having local people involved in decision making about the management of the ab groundwater resource 5 have there been any negative outcomes as a result of having local people involved in decision making about the management of the ab groundwater resource 6 what do you think the lessons are for other communities in other places 7 what are some factors that motivated the ab community to engage in collective action 
3514,resource user participation in decision making through local collective action likely contributes to effective groundwater management and protection despite efforts to construct generalized theoretical frameworks explaining factors influencing successful collective action in groundwater management this is a highly complex process that remains challenging this paper analyzes factors facilitating and impeding collective action in groundwater management using the rare and successful collective action example of the angas bremer irrigation district south australia drawing on data gathered through semi structured interviews this paper further explores the context under which collective action arose and changed over time the findings show a dynamic transient interaction between the following factors responsible for the rise and fall of collective action i perceived crisis ii small homogenous community iii strong leadership from respected community members iv shared norms and values v shared goals and vi trustworthy two way relationship between resource users and formal institution although it is difficult to generalize from one case study collective action and groundwater management are highly contextual these findings are useful i for other communities with similar characteristics ii to explore conditions for achieving successful groundwater governance including efficient and effective reforms iii to highlight the importance of participatory management processes iv to help government agencies understand what motivates communities to engage in collective action and how that leads to successful groundwater co management and v to expand on a very small body of literature documenting stakeholders narratives on collective action and groundwater management keywords collective action groundwater management success factors socio hydrogeology murray darling basin australia 1 introduction common pool resources cpr are those where several users are entitled to the resource and include surface and groundwater fisheries pastures and forests cpr are often degraded over time because resource use is not effectively managed meinzen dick et al 1999 groundwater management is especially challenging because of its invisible nature slow recharge rates large spatial distribution and open access closas and villholth 2019 jakeman et al 2016 barthel et al 2017 resulting in nearly a third of aquifers around the world being depleted faster than they are replenished molle and closas 2019 the global degradation of this vital resource has led to many negative social economic and environmental impacts jakeman et al 2016 brouwer et al 2018 which are likely to be accelerated by climate change green 2016 increased reliance on groundwater during droughts has also led to aquifer depletion and highlights the need for action by resource owners and governments pradhan and ranjan 2016 dramatic recent examples of such water crises include cape town south africa lavanchy et al 2019 and the murray darling basin australia grafton 2020 despite the need for action groundwater management remains reactive and in most contexts unlikely to prevent future crises wilhite 2011 water crises are mostly crises in governance more so than in management mukherji and shah 2005 re 2015 curtis et al 2016 according to mukherji and shah 2005 groundwater management refers to expert driven processes derived from mathematical model building exercises of hydrologists and the formulation and implementation of groundwater laws by water managers natural resources governance is defined as the interactions among structures processes and traditions that determine how power and responsibilities are exercised how decisions are taken and how citizens or other stakeholders have their say graham et al 2003 more specifically groundwater governance embodies a shift to a more integrated approach that considers the interests concerns of hydrologists policy makers groundwater users and other stakeholders mitchell et al 2011 poor governance is at least in part attributed to the failure of decision makers to fully incorporate the human dimensions of natural resource management including consideration of users values goals social and personal norms and local practices and the distributional impacts of interventions e g equity impacts barthel et al 2017 good governance is supported by the core principles defined by lockwood et al 2010 of legitimacy transparency accountability inclusivity fairness integration capability and adaptability it is more likely to occur when decision makers respond to specific social contexts engage stakeholders and evaluate the appropriateness of different policy instruments curtis et al 2016 closas and villholth 2019 this is because groundwater systems are part of large complex socio ecological systems comprising of many biophysical socio economic and human components all interacting with each other barreteau et al 2016 therefore a single actor is not capable of addressing all issues and all stakeholders should be involved in decision making mitchell et al 2012 success of groundwater governance ultimately depends on the users behavior wegmann and mußhoff 2019 although it is clear sustainable groundwater management requires an integrated approach by incorporating social aspects jakeman et al 2016 hydrogeologists and groundwater managers are still debating how to do this in practice curtis et al 2016 re 2015 barthel et al 2017 state centered groundwater governance has largely been ineffective molle and closas 2020b on the other hand there is evidence that participatory approaches such as co management regimes i e shared management between formal institutions and resource users can lead to effective groundwater management fao 2015 molle and closas 2020b however examples of successful co management are rare molle and closas 2019 one explanation is that once a co management regime is put in place governments assume the users will automatically take on the roles that were previously conducted by the government katon et al 1999 in places where collective action does not voluntarily emerge the withdrawal of the state could leave a management vacuum because the users would have to coordinate their activities develop rules to monitor compliance and mobilize the required financial and human resources katon et al 1999 a recent example of such lack of success is offered by ratna reddy et al 2020 who state lack of local collective action as the reason for co management not to arise groundwater management participatory approaches are likely to be more successful if underpinned by local collective action e g lopez gunn 2003 lopez gunn and cortina 2006 esteban et al 2012 shalsi et al 2019 defined by ostrom 2000 as the action taken by a group either directly or on its behalf through an organization in pursuit of members perceived shared interests there is a large body of literature that examines the factors that facilitate collective action in natural resources management nrm e g wade 1987 ostrom 1990 tang 1992 baland and platteau 1996 meinzen dick et al 1999 agrawal 2001 etc molle and closas 2020a reviewed factors affecting collective action in groundwater management presenting 12 different case studies with varying levels of success concluding that successful cases of collective action are rare it remains unclear what governance framework i e the level of co management or the level of shared responsibility between states and users is most effective to support collective action and under which conditions milman and kiparsky 2020 molle and closas 2020a an extensive literature review of almost 300 publications on the social dimensions of groundwater management shows factors affecting collective action in groundwater in australia are understudied mitchell et al 2011 thus it is essential to identify the drivers behind collective action and understand the conditions under which it arises in order to design appropriate institutional frameworks contributing to better groundwater management molle and closas 2020a this paper draws on an australian case study to identify the impediments and factors facilitating collective action in groundwater management the angas bremer ab irrigation district in south australia sa the so called driest state in australia dew 2017 is the case study the ab is at the lower end of a very complex and sensitive socio ecological system ses the murray darling basin mdb the mdb 14 of australia s land area is australia s food bowl producing 39 of the country s agricultural products by value mdba 2017 the ab community faces unique water management challenges being at the end of the basin and not having control over upstream water management decisions the ab is considered a rare example of successful co management which started in the late 1970s cuadrado quesada 2014 and a rich and unique case study as documented by shalsi et al 2019 and detailed in the case study section below shalsi et al 2019 studied the history of water management in the ab exploring the links between the level of collective action co management and water management outcomes they concluded that successful groundwater co management in this system rose from collective action this paper goes further to analyze the factors that influenced collective action to understand the drivers behind it it draws on the analysis of data collected in 14 interviews of stakeholders directly involved in ab s groundwater management history the aim is to identify lessons for managers or researchers interested in exploring participatory models for better groundwater governance in australia and internationally which can enable decision makers to adapt institutional frameworks to local social economic and environmental contexts to the best of our knowledge this work is part of very limited number of scientific papers e g cuadrado quesada 2014 incorporating stakeholders quotes and narratives therefore documenting examining and preserving key knowledge on groundwater management on social dimensions of groundwater management especially in what relates to collective action and co management 2 factors affecting collective action formal frameworks such as ostrom s 1990 institutional design principles followed by ostrom s institutional analysis and development iad have been developed to improve the design of institutional arrangements to facilitate collective action and in turn provide the basis for successful co management ostrom s 1990 design principles have been supported empirically a vast amount of literature has focused on understanding their application for the improvement of groundwater governance and management e g seward and xu 2019 robertson 2020 and they are useful in providing a framework for evaluating water governance arrangements robertson 2020 however such formal approaches have been critiqued for focusing on institutional designs in isolation and often forgetting the social historical and ecological context in which those institutions were created afroz et al 2016 resource users are strongly influenced by the community s norms and values and power dynamics which are often not accounted for in such approaches baldwin 2008 wang and ching 2013 afroz et al 2016 ratna reddy et al 2020 molle and closas 2020a there is a need for nrm approaches that incorporate the specific historical and social context of resource users armitage 2005 afroz et al 2016 as well as informal collective action local networks and motivations behind the users actions vanni 2014 agrawal 2001 analyzed the three most comprehensive nrm studies that seek to construct theoretical generalizations on collective action baland and platteau 1996 ostrom 1990 and wade 1988 and created a comprehensive list of 25 factors and conditions that enable resource users to engage in collective action the author grouped these factors in a set of four basic categories i resource system characteristics ii group characteristics iii institutional arrangements and iv external environment from a resource system perspective the scarcity of the resource and the salience to the users are key factors that influence collective action ostrom 1992 other important factors are size and productivity of the resource very large territories make defining boundaries and monitoring the system too costly while small territories do not generate enough funds ostrom 2009 considering productivity if the users think their resource is exhausted or abundant they will not have a motivation to act collectively ostrom 2009 however if the users perceive a credible threat on a resource they are dependent on they consider the benefits of collective action to exceed the costs ostrom 2009 the eastern la mancha aquifer spain lopez gunn and cortina 2006 and the saint louis valley california usa molle and closas 2020a are examples where a groundwater crisis encouraged users to organize to face the threat to their groundwater sustained livelihoods when it comes to group characteristics smaller homogenous communities that engage in face to face communication and regular community meetings are more likely to act collectively ostrom 2010 in a smaller community costs of negotiation are lower the outcomes are observable and the likelihood of compliance to the rules is higher which in turn allow for information exchange and for the creation of social relationships ostrom 2010 naghar et al 2016 vanni 2014 molle and closas 2020a argue small communities of up to 1000 groundwater users engage more easily than those of tens of thousands of users however a small homogenous community with well defined boundaries will not necessarily lead to collective action as users also need to have the capacity and commitment to sustainably manage their resource clark and brake 2008 thus sustainable nrm can be promoted by building human and social capital mitchell et al 2012 human capital denotes the individuals skills and capabilities i e leadership personality attributes social skills communication skills intelligence etc whereas social capital represents the networks social relations and trust that arise between people when interacting as well as their norms and values ostrom and ahn 2001 community leadership is a key ingredient in successful collective action ostrom 2010 the presence of a dedicated and well respected individual who is willing to commit and has the ability to convince the community to voluntarily contribute to their common issue is a key requirement for successful collective action sutton and rudd 2015 social capital is generated through networks and positive interaction between individuals and government agencies these networks build the capacity for user communities to effectively manage resources and facilitate social learning kewit and kewit 2004 informal institutions that is traditions customs moral values religious beliefs and all other norms of behavior that have passed the test of time pejovich 1999 p 166 and networks amongst users are equally as important as formal institutions that is rules and laws enforced through official channels north 1991 lopez gunn and cortina 2006 conclude it is the successful relationship between the regulator and regulated that leads to positive collective action and the creation of successful relationships is facilitated by open honest and regular communication between stakeholders which ultimately leads to trust ostrom 2000 trust and reciprocity are important components of social capital collective action is not only a matter of constructing strong institutions but also a matter of building trust between the government and users as well as trust amongst users de vos and van tatenhove 2011 trust is essential for public participation as it determines the acceptability of management policies and there is evidence that where trust is present litigations and delays in policy implementations are less likely to occur sharp and curtis 2014 jamieson et al 2020 additionally trust reduces conflict and removes the fear of free riding which is one of the main social dilemmas that impedes collective action ostrom 1999 naghar et al 2016 institutional arrangements can contribute to collective action by providing support funding to monitoring of the resource and technical advice and stakeholder engagement in monitoring and decision making katton 1999 ostrom 1992 ostrom 2009 ostrom 2001 molle and closas 2020a involving users in monitoring provides them with more information on the gravity of the issue and allows for both local users and government departments to create a shared picture of the condition of the resource lopez gunn and cortina 2006 re 2015 jamieson 2020 according to ross et al 2008 this motivates users to organise and act collectively leading to more successful outcomes in comparison to government legislation alone the lockyer valley australia sarker et al 2009 and lerma chapala basin mexico wester et al 2007 are examples where the lack of shared knowledge about the resource has negatively impacted collective action engaging stakeholders in decision making encourages mutual learning curtis et al 2016 incorporates the community s values and local knowledge in policies enabling trust to be built between policy makers and those affected by policies and improves the government s accountability clark and brake 2008 through regular and honest communication policies can be legitimized by public acceptance and so they are more likely to be effectively implemented and maintained clark and brake 2008 stakeholder participation not only increases compliance but also motivates resource users to voluntarily contribute to management initiatives curtis et al 2016 lopez gunn 2003 and esteban and albiac 2012 concluded that water user associations were imposed to the community in the western la mancha aquifer spain resulting in unsuccessful groundwater management they found that in the neighbouring eastern la mancha aquifer where collective action arose from the users aquifer recovery was achieved further allowing resource users to devise their own rules is what enables local collective action to contribute to the success of management policies ostrom 1990 2009 lutz and caldecott 1996 curtis et al 2014 research regarding factors that affect collective action in groundwater management in australia is limited to baldwin 2008 skurray 2015 cuadrado quesada and gupta 2019 molle and closas 2020a and robertson 2020 it is worth re noting that collective action is highly contextual from a ses perspective and as such it is important to analyze its specificities in an australian context skurray 2015 analyzes ostrom s situational variables in the gnangara aquifer in western australia and identifies components of the current institutions that should be modified to facilitate collective action baldwin 2008 also analyses ostrom s design principles by taking the lockyer valley in queensland australia as a case study concluding that ostrom s principles and the community s values should be reflected in groundwater management however without explaining how the community s values should be reflected into policy molle and closas 2020a summarise the factors why co management in the lockyer valley was unsuccessful both skurray 2015 and baldwin 2008 suggested collective action as means of better groundwater management in australian case studies although without giving guidance on how to achieve it in practice robertson 2020 uses ostrom s 1990 design principles to analyze queensland s current water governance framework and highlights how the absence of some of those principles may have contributed to unsustainable outcomes in the surat basin cuadrado quesada and gupta 2019 discuss how legal frameworks that include participation can mitigate local groundwater issues in australia and costa rica although without specifically mentioning factors that impact collective action the above mentioned research focuses on formal institutions and there is a clear gap in addressing collective action in groundwater management from an informal institutional context in australia which is important as pointed out by shalsi et al 2019 3 methods this paper uses the case study and data collection process described in shalsi et al 2019 here we only provide the elements that are critical for the analyses of this paper s research questions 3 1 case study the ab irrigation district is located 60 km to the southeast of adelaide state capital and 30 km inland from the murray river mouth abrwm 2021 fig 1 it is home to 160 irrigators and is delineated by a prescribed well area pwa 250 km2 for groundwater management purposes as of 2008 ab farmers irrigated 7 100 ha including 5 400 ha of wine grapes 470 ha of lucerne pasture and 430 ha of potatoes thomson 2008 the area is economically supported by a thriving wine industry which largely relies on groundwater for irrigation although surface water has also been used from the mid 1990s langhorne creek is its main town and gives name to this prime wine region the region derives its name from the fresh salinity of 1 000 mg l ephemeral angas and bremer rivers which flow from the mount lofty ranges to the terminal lake of the murray darling system lake alexandrina harris 1993 the regional climate is mediterranean with average rainfall varying from 490 mm year in the northwest to 380 mm year in the south zulfic and barnett 2007 pumping mainly occurs from the deep heterogenous transmissivities of 100to 1 500 m2 day semi confined murray group limestone aquifer mgla of 75 to 100 m thickness zulfic and barnett 2007 it is the preferred aquifer due to i low salinities 1 500 to 3 000 mg l in the central part near the rivers although of up to 10 000 mg l near the basin margins and ii high yields up to 40 l s zulfic and barnett 2007 the mgla is covered by a quaternary shallow unconfined low quality salinity of up to 30 000 mg and low yields 5l s aquifer howels 1994 zulfic and barnett 2007 consider direct rainfall recharge to the mgla insignificant affirming the aquifer is mainly laterally recharged although receiving some vertical recharge from the shallow quaternary aquifer in the river plains fig 2 presents a summary of the findings of shalsi et al 2019 in the form of a timeline of the main management and climatic events the level of collective action and the main management outcomes in the ab region from 1950 to present as of 2017 identified from interviews secondary literature and government reports ab s groundwater management timeline was divided into 5 phases based on historical and temporal evolution of governance structures and or impactful events that occurred at the time this allows for linking the level of collective action with the main management climatic events or changes in governance structures which in turn allows for better understanding the factors that facilitated or impeded collective action over time zulfic and barnett 2007 offer a thorough discussion on the spatio temporal evolution of groundwater levels and pumping phase 1 1950 1979 corresponds to the start of groundwater pumping in the 1950s by the late 1970s irrigators realized their crops were being negatively impacted by the increased salinity and lowered aquifer yields during this phase there was no legislative control over groundwater pumping and the annual groundwater pumping reached 26 600 ml by 1981 which amounts to four times the estimated volume of annual natural recharge thomson 2008 an obvious example of a cpr facing the tragedy of the commons during this phase the collective action levels were low phase 2 1979 1997 started with the creation of the community based advisory committee angas bremer water resource advisory committee abwrac from now on referred to as the ab advisory committee as a response to the aquifer degradation the ab irrigators took the initiative to create the ab advisory committee which was composed of local irrigators as well as hydrogeologists water managers and other specialists from sa government their role was to plan strategies and provide advice to sa government ministers for the development and execution of water management policies to reduce groundwater extraction and maintain sustainable future extractions muller 2002 the ab advisory committee lobbied the state government for the proclamation of the area as a water management zone meaning that all irrigators had to purchase water licenses and comply with the requirements of the water resource act 1976 leading to allocation limits being set and reduced howles 1994 it was a period characterized by high community collective action and a strong co management regime between the government department and ab irrigators after ab s proclamation the ab advisory committee in partnership with the government department developed and executed two water management plans wmp in 1987 and 1992 the main policies included in the two plans that facilitated the reduction of groundwater extractions were i an imposition of a 30 cut on individual groundwater entitlements by allowing irrigators to swap their groundwater licenses for surface water licenses and therefore gain access to a similar volume of surface water from lake alexandrina ii encouragement of privately funded and implemented managed aquifer recharge mar through injection wells such as giving irrigators the right to extract 50 of the their allocated surface water to artificially recharge it into the aquifer and allowing irrigators to carry over for up to 3 years any unused lake water stored in the aquifer thomson 2008 and iii the ability to trade surplus water for profit these policies applied for the duration of the respective wmp phase 3 1997 2005 began with the new water resources act of 1997 which stated that a formal water allocation plan wap had to be developed for the ab irrigation zone substituting the former wmp developed by the ab advisory committee consequently the government agency river murray catchment water management board from now on referred to as the rm catchment board replaced the ab advisory committee muller 2002 the rm catchment board was responsible for the development and the implementation of the wap 1997 2002 encompassing a much larger catchment than just the ab district the ab advisory committee had no longer a clear role in developing the new wap muller 2002 because the community still wanted a voice in policy development it created the voluntary community group angas bremer water management committee from now on referred to as the ab management committee consisting of local irrigators technical staff from the government department and the rm catchment board this new partnership between ab management and rm catchment board ensured that innovative policies were being developed and implemented in a technically robust manner whilst remaining under community ownership muller 2002 the co management regime established in phase 2 remained strong during phase 3 and so did the level of collective action this led to reducing groundwater extractions by 80 harris 1993 to maintain the sustainability of water use the ab management committee developed and implemented a code of practice cop for all irrigators in the area which later became a legal requirement as part of their water license the cop which was funded and managed by the irrigators involved a rigorous water monitoring and reporting system as well as a requirement to plant 2 ha of native vegetation for every 100 ml of surface water from lake alexandrina entitlement to prevent waterlogging phase 4 2005 2009 started with the introduction of the nrm act 2004 which recognized that all natural resources should be managed in an integrated manner nrm boards were established as a state level advisory board responsible for the preparation of the waps emlr wap 2013 this meant that the ab wap was integrated into the eastern mount lofty ranges emlr plan the ab community was much less involved with the development of these new plans that incorporated a much larger area however collective action remained high due to the effects of the millennium drought which led to reduced water levels and increased water salinity of lake alexandrina ab s main source of surface water in phase 2 and 3 consequently the ab committee lobbied for the construction of a government funded 110 km pipeline to bring water directly from the river murray shalsi et al 2019 phase 5 2009 2017 started with the pipeline connecting the river murray to ab which coincided with the end of the millennium drought the pipeline provided 16 000 to 24 000 ml year of water to the region from 2013 to 2020 abrwm 2021 phase 5 goes until the end of the analyzed period this is a period of low co management and low collective action 3 2 data collection 14 face to face semi structured interviews were conducted in adelaide and ab from february to may 2017 with key representatives of all stakeholder groups directly involved in and knowledgeable of ab s water management between the 1950s and 2017 to understand their perspectives and experiences with the local groundwater management history the open ended questions presented in appendix 1 were purely focused on the interviewees experiences with the management history of the region and no personal background questions e g sex gender identity age were asked as they were not considered relevant and in fact never arose as part of the responses the participants were chosen based on the snow ball technique and the sample size was defined based on the theoretical saturation point in which no new concepts arise from the interviews participants in the study signed an informed consent form allowing their quotes to be published anonymously a list with interviewees their respective stakeholder group government department ab advisory committee nrm board and industry and start year of involvement in ab water resources management is provided in shalsi et al 2019 in this paper we analyze the interview passages relating to the factors that affected collective action in each phase aiming to understand how changes in context such as management events policies climatic events and governance structures can influence the level of collective action understanding how context impacts water user behavior could provide insight into keys to successful ground water management policies that could lead to aquifer recovery 3 3 data analyses the interviews were transcribed verbatim and coded thematically using nvivo version 10 the aim of the coding was to systematize the transcripts by identifying the most common themes which were grouped and analyzed based on an adaptation of ostrom s 2009 socio ecological systems ses framework table 1 the ses framework was developed as a response to the criticism that the iad paid insufficient attention to informal institutions and the complexity of interactions between nature and society cole et al 2014 the ses framework incorporates a large set of social and biophysical attributes that could influence management outcomes the main factors that influenced collective action were grouped into three categories a groundwater resource characteristics b groundwater users characteristics and c formal institutions i e government department and nrm boards for the purpose of this paper 4 results the results have been presented based on whether the factors were facilitative or an impediment to collective action and evaluated based on the three categories in table 1 i e groundwater resource characteristics groundwater user characteristics and formal institutions fig 3 presents the most influential factors that dictated the level of collective action for each stage most of the characteristics and events happening during phases 1 2 and 3 facilitated collective action while phases 4 and 5 are mostly characterized by factors impeding collective action phases 1 and 4 are somewhat transition periods between low and high levels of collective action as explained below 4 1 factors facilitating collective action the results of our analysis show that phase 1 s collective action was low as the irrigators were unaware of their unsustainable rates of groundwater extraction collective action was highest during phases 2 and 3 when the irrigators started feeling the impacts of decreased groundwater levels and increased salinities and consequently started working collaboratively with the government department towards solutions high collective action continued in phase 4 during the peak of the millennium drought despite a low co management level due to policy changes as will be explained below a groundwater resource characteristics a1 crisis all 14 interviewees mentioned crisis as a factor that facilitated collective action as stated by an nrm board member it is the pending disaster that motivates people into action a crisis brings people together the resource users perception of being in a crisis is equally important once the irrigators realized that over extraction was negatively impacting their crops the level of collective action started rising and the irrigators decided that they needed to act as stated by a government official one of the reasons things happened so well down there is that they were genuinely scared that the resource was at risk and that s enough to spark them into action whereas when we come in and people are unconvinced that they have a problem it s way harder to get them to engage and get involved and by an irrigator it worked really well for those first 20 years the committee was first formed out of a need everybody knew we had a crisis and we react to the crisis we ve got we were proactive enough to come back to that point of if we do nothing we ll be told what to do let s be on the front foot and have an input into our own destiny b groundwater resource users characteristics b1 small homogenous group one of the conditions that was repeatedly emphasized during the interviews was the size of the group using the resource 160 irrigators in a smaller group it is easier to enforce rules and avoid the free rider problem through peer pressure users can identify anyone who does not have rights to use the resource as stated by an industry member i haven t heard of anyone not complying to the rules it was a very small community they would drive around and look i know what they re doing they know what i m doing so if you re going to do something dodgy people will know about it 10 14 of the interviewees mentioned small size has contributed to the successful collective action in ab because when a group is small members tend to build closer relationships due to frequent and highly personalized interactions as stated by an industry member being small has benefited ab because you all know each other whereas in other regions there s a lot more diversity and a lot more to manage in one way it small number of users helps to form a cohesive group b2 human capital results from the interviews strongly suggest personalities and skills of ab s community members have been key to successful collective action from all the components of human capital 14 14 interviewees singled out leadership from respected members of the community as a key factor an example quote from a government department employee states the key members of the committee were the ones that initiated a lot of change and unfortunately it does come down to some individuals if you re lucky with someone who has the knowledge and the communication skills and the charisma to get the message over otherwise you get someone who s not very competent which makes the relationship more difficult strong leadership not only facilitates the coordination and organization within the community but also helps build trustworthy relationships with formal institutions as stated by an irrigator if we hadn t had that leadership and that guidance from respected community people who could stand up and defend the decision that s been made the community won t buy it communities don t trust governments don t trust nrm and don t trust anything that takes money off them you ve got to build the bridge governments can t build bridges and nrm can t you need the locals to help build the bridge b3 social capital strong social capital within the ab community facilitated collective action shared norms and values heavily influence the ability of users to act collectively ab has a strong history of cooperation between irrigators since early colonization 1800s it is the shared nature of floodplains and the fact that the ab irrigators have been permanent residents in the area for generations with no absentee farmers that has built strong trustworthy relationships between irrigators which can be illustrated by the quoting of a government department employee and an industry member the bremer river flows through the area and for years they managed that themselves they used to trap the water as it came down in flood at the end of winter and diverted on to the paddocks to give the vineyards a big soak which would then pretty much carry them throughout the season people on top of the system got the water first when they d finish they d pass it on to the next person and so forth there were never any rules written down they just did that with a wink and a nod and water was passed down through the system it was shared the makeup of the community has a lot to do with it the families here have been here for 5 6 generations and langhorne creek is one of the few communities that like to run and own everything the whole football complex and sporting ground is community owned and run and this builds relationships between people features of social capital that aids in collective action are also past successful experiences and knowing how to work with government as mentioned by an nrm employee some farmers find it really hard to deal with government they just don t understand how it works and you normally come up against a bit of mistrust but the ab irrigators had that track record of working with government so when they put together a proposal to take it to the government they re well received because they ve already got that government work with them in the past b4 knowledge of ses and dependence on the resource understanding the ses and groundwater dependence was critical for collective action in ab as previously mentioned the irrigators started noticing the aquifer overdraft but they did not know its consequences for the sustainability of the system and for their economic activity this was especially critical because groundwater was the only reliable available water source shalsi et al 2019 the following quote from an irrigator illustrates these two factors so when we were in trouble before we knew we had a problem and there was a lot of concerned irrigators but we didn t know extent of the problem we requested the government to do a study of the water use in the area to give us an indication of how much we were pumping the study indicated we were pumping 29 600 ml which is way over what the basin can sustain c formal institutions c1 funding during phase 2 the government department was providing funding and technical support for the ab advisory committee and both groups worked collaboratively to produce the first two water management plans as well as the annual irrigation reporting scheme in phase 3 the rm catchment board provided funding and technical support to the ab management committee similarly both groups worked collaboratively developing the code of practice and other sustainable management practices this funding allowed the ab management committee to have face to face consultations with on ground hydrogeologists as well as continue their monitoring data collection and reporting scheme additionally with funds from the rm catchment board a fullstop device was implemented by researchers for the ab irrigators to monitor groundwater salinity levels as quoted by an ab advisory committee member the rm catchment board funded certain projects they did some pretty good work at the ab with scientists from csiro who invented the fullstop device they actually educated the people a lot about irrigation and flushing salts through c2 monitoring c2 monitoring and b4 knowledge of ses are closely related because monitoring allows for a better understanding of the system and a better understanding of the system allows for refining monitoring and better interpreting acquired data 10 14 interviewees mentioned that technical knowledge of the system through monitoring the resource was a key factor facilitating collective action because it allowed for all stakeholders to share an understanding of the hydrological issue as affirmed by an irrigator it s very hard to manage anything if there s no information about it the department set up a system of collecting information every year and each irrigator collected that sequence of information for their property and in addition to that you ve got all the wells owned by the farmers that they were reading the water meters and measuring depth so i as a farmer would know exactly what s happening at my place each farmer had a 6 m deep monitoring well and would measure 4 times a year and report their own information which was summarized into the irrigation annual report about the whole community so you ve got real data and if you have got a situation of salinity rising or wells going down everyone agrees that we ve got to do something about it rather than starting at no we don t have to do anything remarkably ab irrigators had the initiative of self conducting monitoring in their property wells simultaneously field government technicians were monitoring groundwater which helped both parties not only to create a shared picture of the resource but also to build trust as referred by an nrm employee and a government department hydrogeologist they irrigators managed their own data with their own community data manager this was really important because they owned their own data they analyzed it and reported it back to the community themselves there was a high level of trust about 95 of irrigators would fill in their annual report even when it was voluntary initially what happened in other south australian areas was that the government would collect the data analyze it and then impose policies on the community which did not bring good results c3 networks within formal and informal institutions a key concern is that policy makers do not accurately portray on ground issues as scientists may be somehow isolated from the real world re 2015 as agreed by a government official a lot of young hydrogeologists here haven t been out of the office they haven t had the opportunity to do field work and it s very hard to form good relationships if we hardly step out of the office 13 14 interviewees stated that the key to ab s successful collective action in phases 2 3 and 4 was because of the partnership between the government department and the irrigators this partnership allowed for irrigators to understand the hydrogeological characteristics of the aquifer by receiving technical advice from on ground scientists it also allowed for policy makers to understand local knowledge and traditions when both parties understand each other s realities and when the community feels like they are contributing to the solutions it leads to better outcomes as stated by an irrigator it started as a proactive movement by the community to try and control our own destiny we worked very cooperatively with the department for the first 10 15 years they invested some good technical advisors hydrologists geologists that sat on the committee with us we d come up with ideas they d go back and explore it and model it and tell us whether it would work or not we wrote 5 wmp through that collaborative atmosphere we got good outcomes from those plans and at least 90 of the community went with it that led on to annual reporting we were one of the first committees in the basin to start that we had success and we started to see aquifer recovery c4 trust another important factor is building relationships between the irrigators and formal institutions because it leads to trust between both parties increasing knowledge on both sides in ab on ground hydrogeologists were very involved with the community as quoted by a government department hydrogeologist i used to go down to all the community meetings and i d stay on an extra night and just go around and visit the farmers and interact with them having a physical presence in the area is what builds relationships these interactions make the irrigators better informed about their issues and therefore they have a much better informed discussion about how to solve it but also they educated us about what s going on there and this two way flow builds a relationship where there s trust c5 collective choice institutions in addition to funding a key contribution from government agencies to collective action is having collective choice institutions that allow community groups to take part in decision making as noted by ostrom 2001 the two main roles of formal institutions are to i provide the resource users with accurate information regarding the physical conditions of the resource and ii to allow resource users to create their own institutional arrangements to manage the specific issue they are facing the institutions governing ab fulfilled both criteria as stated by a government department hydrogeologist the two reason why it worked so well was because they irrigators i used to have technical people every month sitting in their meetings and feeding them scientific information and ii did have a lot of influence over the outcomes of that plan the irrigators were heavily involved with the first two wmp as well as the formal wap of 2001 we sat around the table and they drove the show in ab a key factor mentioned by 10 14 interviewees that motivated the irrigators to act collectively was the autonomy of the committee ability to influence policy and the fact that they felt ownership of the problem the water resource act 1976 provided an institutional framework where all water stakeholders could work together which allowed for the creation of ab advisory committee the autonomy and the ability to influence decisions and policies combined with the understanding of the gravity of the issue gave the ab irrigators a sense of ownership of the problem which then allowed the ab irrigators to push for tough policies as stated by a government department hydrogeologist so then they irrigators accepted the fact that allocations had to get down to a certain level but they had a contribution about how it was done and they accept the cuts because they owned the process they had a say in it whereas if the government just dictated we re going to reduce it by this there s no real ownership it s a bit top down so it s not going to work but again the key is for them irrigators to have the technical understanding which hopefully we can give them so they know what the limits are again definitely a two way thing rather than us dictating which used to happen in the past 4 2 collective action impediments phase 4 marks the transition between strong and weak collective action phase 4 started with a drastic change in governmental water management strategies i e the introduction of the emlr plan and the changes in governance structures that came with it contributing to erode collective action nevertheless the millennium drought was a dramatic problem for the irrigators during this phase which allowed collective action to remain high the impacts the emlr plan had on collective action emerged once the millennium drought was over and the water crisis was perceived to be finished which marked the beginning of phase 5 a groundwater resource characteristic a1 absence of water crisis phase 5 saw a marked decline in collective action sparked by a perceived absence of a water crisis as the millennium drought was over as quoted by an nrm employee so i think the group has struggled a little bit for membership because we ve sort of nailed the salinity problem and we ve got access to better quality water before there was a crisis bringing them together and now there s not a2 size of management zone the emlr plan aims to manage natural resources in a holistic way by incorporating different management zones and conjunctively managing all natural resources however in practice this holistic management negatively impacted collective action from the ab community s point of view besides the drought crisis being over according to the majority of interviewees the two main factors that affected collective action in phases 4 and 5 were i increased size of management zone 10 14 interviewees and ii reduced funding 14 14 interviewees the emlr plan introduced new management issues such as environmental flows vegetation health etc from the ab community s perspective this shifted the focus from groundwater increased the complexity and diversity of the issues and increased the area of the management zones as explained by an irrigator the legislation is driving it not the community needs there was a national water plan nwi written saying that all this has to happen of course we do need a national water plan but the problem with it is that it doesn t have flexibility if the national plan said we are aiming to achieve xyz however work with communities to get there it doesn t say that b groundwater user characteristic b1 social capital the increased size of the management zone a2 led to a loss of social capital manifested in the absence of shared goals this is illustrated by a government department official in the quote the way we manage now trying to make it more holistically doesn t resonate as clearly as if it was purely about water in the early 1990s when the issue was only water we could put up graphs with water levels and salinity and no one in that room could argue that they didn t have a problem they could see it but now with the emlr over the top of that came the problem with the water dependent ecosystems so it was a more complicated discussion and we might argue for years now is there a problem b2 no dependence on groundwater the ab alleviated their dependence on groundwater by building a pipeline from the river murray in 2009 as a response to the same drought the diverse sources of water i e groundwater and surface water from lake alexandrina and the river murray gave the ab community a perceived sense of drought proofing which led to a fall in collective action according to one government official they managed to drought proof themselves this fall in collective action due to the diversification of water supply i e lack of dependence on groundwater and the perception of being drought proof directly relates to the absence of crisis a1 mentioned above nevertheless this idea of drought proofing is not consensual amongst the community and can have negative water management implications and an irrigator stresses the importance of preparing for future crisis we are reactionary we react to the crisis we ve got we don t look forward to the next one we handle that one the drought s finished the water s flowing we ve got our order back and the aquifer is rising beauty what else is going on we tend to move from crisis to crisis c formal institutions c1 reduced funding leading to reduced c 2 monitoring c 3 social networks and c 4 trust 13 14 interviewees agreed that reduced funding from the government department and nrm boards was a key issue that reduced collective action in ab the reduction in funds directly led to a decrease in c2 monitoring c3 networks between formal and informal institutions and c4 trust between community members and government institutions funding towards the ab committee kept decreasing each year with the setting up of the nrm boards which meant less funding to continue ab s monitoring c2 this is illustrated by quotes from a nrm employee and an industry member groups like the ab who traditionally did a lot of monitoring and on ground work that sort of money is no longer available they still do the annual monitoring but the report on the fullstop devices has sort of dropped back importantly reduced funding also meant reductions in human resources such as on ground government hydrogeologists negatively impacting the formal informal networks consequently the level of collective action is lower when compared to phases 2 and 3 as stated by an ab advisory committee member and the main issue was that the department started to cut the money off to support the local committee they started withdrawing their technical people so that left us with none of that interaction with department and that link back to the department all of a sudden we re writing letters instead of talking to the people as previously mentioned in the facilitative factors face to face interaction with the same government officials over a long period of time builds trust between both parties making the implementation of new policies more acceptable when this network is absent trust also diminishes as quoted by an nrm employee some farmers find it really hard to deal with government they just don t understand how it works and you normally come up against a bit of mistrust c2 collective choice institutions although the ab advisory committee never had a regulatory role and always was an advisory committee during phases 2 and 3 the community perceived they had power because they drove the wmp and influenced policies formally nothing changed with regards to the actual power the ab committee had when the nrm boards were introduced however the community s perceptions changed as explained by a government official the group started to wear a different hat the nrm was responsible for developing and amending the emlr plan and water licensing stuff so they went from being an advisory committee that was formed and driven out of the central department to being only reporting to the board in both cases they were only advisory but it certainly felt that they had less power in the new iteration before the nrm they were suggesting the ideas whereas after it was probably that the ideas were being generated out of the nrm board and government department despite the efforts of the nrm board to keep the community engaged this perception of their inability to influence decisions reflected in lowered collective action as stated by an industry member at the moment they are struggling with community engagement and enthusiasm because i think there used to be much more feelings of ownership of it and that s gone it s easy while it s local but now we ve got to think about the emlr the sense of ownership diluted it a fair bit the nrm board staff tried really hard to engage people they are just not as comfortable because they don t feel like they can influence and they feel like there s a lot of stuff there that s not relevant to them and they don t feel like the local flavors come through in the end product so it just doesn t sit with them 5 discussion 5 1 effective collection action in groundwater management a complex interaction between factors the ab example shows that although it is critical to identify and list the factors that affect collective action e g agrawal 2001 it is arguably more important to understand how they interact to nurture collective action or otherwise the discussion below exposes how the factors interacted and consequently influence the levels of collective action some factors are discussed in combination because they are directly interrelated although collective action and groundwater management are highly contextual and it is difficult to generalize from one case study this discussion explores conditions for achieving successful groundwater governance including efficient and effective reforms the importance of participatory management processes and how can government agencies understand what motivates communities to engage in collective action and how that leads to successful groundwater co management 5 2 groundwater crisis a1 and dependence on groundwater b5 as mentioned throughout the results section a key sparker of collective action in ab was the crisis in phases 1 2 and 3 related to groundwater over pumping and consequent depletion and degradation the community was heavily dependent on groundwater for this period although surface water from lake alexandrina became part of the supply mix during phases 2 and 3 which was critical for the reduction of groundwater consumption phase 4 brought a new water crisis related to the millennium drought in which surface water was no longer available and groundwater returned to being the sole source realizing a groundwater crisis unfolding phase 1 led a few irrigators to collectively take action and engage with formal institutions to address the problem phase 4 marked the transition from high to low collective action with the millennium drought keeping collective action high and the integration of the ab wap in the emlr as part of the nrm act making it low collective action became low during phase 5 as combination of the legislative change mentioned above and the absence of a water crisis partially because of access to alternative surface water sources groundwater crisis and dependence acted as first catalysts to facilitate or impede collective action as shown in examples from the eastern la mancha spain lópez gunn 2012 sheridan county kansas usa and san luis valley colorado usa molle and closas 2020a 5 3 group size b1 and management boundaries a2 and a3 crises do not necessarily bring people together ranjan 2014 and are not enough for successful collective action bekkar et al 2009 in addition to the resource physical attributes users characteristics are critical wang and ching 2013 two facilitating factors repeatedly emphasized in literature are i the size of resource user groups and ii clearly defined boundaries ostrom 1990 tang 1992 baland and platteau 1996 schalger 2007 ostrom 2010 size can be a disputed factor while some authors e g ostrom 1990 2009 2010 argue that a small size is conducive to collective action allowing for homogeneity in objectives norms and cultural values others e g agrawal 2001 argue that if a group is small it is much harder to attain the necessary resources to successfully engage in collective action our results show the small and homogeneous group of ab irrigators allowed for successful collective action because i there was a common problem affecting all irrigators ii there was a sociocultural cohesion iii it was easy to discuss and reach an agreement on the problem and solutions and iv it was easy to make sure everyone was complying with the rules this agrees with ostrom 2010 who concludes that collective action is more likely to occur in smaller groups because i they are more cohesive ii it is easier to exchange information leading to shared goals and iii it is easier to enforce rules and prevent free riding problems on the other hand large groups can increase monitoring costs reduce the effect of norms and make communication harder wang and ching 2013 molle and closas 2020a show that in mexico social heterogeneity of a large group contributed to impeding collective action similarly when ab was incorporated into the wider emlr plan in phase 4 collective action diminished because the increased diversity and complexity of the issues diverted the focus away from water resources which led to ab irrigators feeling that the new policies are not locally relevant to them according to ostrom 1990 a critical factor for successful collective action is well defined boundaries however the ab example shows that the size of the management area also plays a role although the emlr plan had a clearly defined management zone the widening of the boundaries decreased collective action and the irrigator s motivation to participate in community meetings 5 4 human b2 and social capital b3 as agreed by all interviewees one of the main factors that facilitated collective action in ab was effective community leaders human capital which agrees with the work of ostrom 2000 lopez gunn and cortina 2006 lópez gunn 2012 lockwood et al 2010 cuadrado quesada 2014 and skurray 2015 phases 2 3 and 4 saw very strong leadership from respected community members who drove the ab management and advisory committees these committees being initiated by trusted community members increased the perceived legitimacy and credibility of the committees by the rest of the community this trust was facilitated from but also increased the strong social capital present in the community numerous authors have stressed the important role social capital e g ranjan 2014 miao et al 2015 plays in the successful co management of groundwater and the ability of resource users to act collectively like katton 1999 our results show that the community s norms and values affect the user s ability to engage in collective action where a strong cooperation tradition increases the likelihood of collective action due to a history of sharing flood waters for irrigation for almost a century ab has always had a very strong sense of community and cooperation which was portrayed in their ability to organize themselves and form committees to collectively solve emerging issues furthermore trust building networks can lead to collective action because they facilitate coordination and cooperation towards mutual goals ranjan 2014 and personal interactions help in building trust between users sharp and curtis 2014 linking back to ab irrigators being a small well defined and homogeneous group our results support those of meinzen dick et al 1999 who states that when groups i are created around a joint goal ii share similar norms and values and iii have established a history of trust and cooperation information and coordination costs are reduced facilitating the emergence of collective action the likelihood of successful collective action is increased when a community has a common issue and a shared goal miao et al 2015 5 5 ses knowledge b4 and formal institutions c1 5 groundwater is managed more effectively through an integrated approach encompassing all aspects that influence a groundwater ses jakeman et al 2016 in the case of ab ses knowledge and connection with formal institutions c1 funding c2 monitoring c3 networks c4 trust and c5 collective choice institutions cannot be decoupled these links are explored below our findings are in accordance with lópez gunn 2012 who concludes that the trustworthy relationships between users is necessary but not sufficient as collective action as a catalyst of successful groundwater co management would not be possible without the support and collaboration from formal institutions a key ingredient for the successful partnership in ab was users knowledge of the groundwater system which was fostered by face to face communication with on ground government hydrogeologists ab had a government supported robust system of monitoring and reporting during phases 2 and 3 which helped both the community and the government department share a common picture of the groundwater issue ostrom 1992 emphasizes the importance of monitoring for understanding the condition of the resource and preventing free riders thus encouraging collective action on ground hydrogeologists facilitate a two way sharing of information while local users have direct knowledge of the resource use and socio economic factors at play in the community e g conflict social structure values and norms hydrogeologists have a better technical understanding of the resource e g sustainable yield aquifer interconnectivity and ecological conditions at a larger scale combining both knowledges creates a fuller picture closas and villholth 2019 direct contact between irrigators and hydrogeologists also facilitated a trust based bridge to be built between the community and the government department the irrigators believed the information the department was providing them with and the department trusted the community s ability to provide sound advice as mentioned by most interviewees it was this successful partnership that allowed the irrigators to be involved in the wmp development and in turn the implementation of widely accepted policies that reduced groundwater extractions by 80 muller 2002 although hydrogeologists often ignore the importance of building relationships with the community re 2015 field hydrogeologists are often the first point of contact with irrigators and they are the ones who can encourage and help to implement bottom up co management approaches by engaging with the community re 2015 lopez gunn and cortina 2006 without these networks there is a risk of disconnection and proposed solutions by policy makers may not accurately reflect on ground issues as scientists are too isolated from the real world according to baland and platteau 1996 who also state what is required for successful collective action is a two way process of information sharing between rural people and the administration this is critical since there is often lack of trust between water users and formal institutions lopez gunn and cortina 2006 according to lockwood et al 2010 confidence and trust in nrm boards and government departments is a key factor in community collaboration and thus effective co management bell and park 2006 explored the effectiveness of developing new water allocation plans in new south wales australia and concluded that according to communities a key issue hindering the successfulness of the new policies was lack of information from governments according to the authors lack of information erodes the water users confidence and trust decreasing their willingness to engage in collective action when users do not understand the issue they do not engage and collaborate on the development of policies thus policy implementation tends to be more difficult clark and brake 2008 funding was a critical factor facilitating the above mentioned monitoring and intra institutional interactions baland and platteau 1996 suggest that governments often fail to allocate sufficient funds to resource conservation because other more urgent priorities hold a heavier political weight ab is a very good example of this during phases 4 and 5 when direct contact with field hydrologists ceased because of bureaucratic changes and decrease in funding the ability to perform robust monitoring and reporting and to have on ground technical advisors building relationships and sharing information was possible because the ab committee was very well resourced by the government over phases 2 and 3 margerum 2007 states in an era of declining management resources it is difficult for agencies to put resources toward long term preventative efforts when there are immediate short term demands during phases 4 and 5 resourcing shifted to managing natural resources holistically securing environmental flows in rivers promoting irrigation efficiencies vegetation health and preserving biodiversity this meant that the nrm board the chief providers for the ab committee started to reduce their funding substantially and continuously towards the group this led to the reduction in monitoring data and regular contact with on ground technicians hindering collective action within ab our research confirms ostrom s 2001 point that autonomy gives users a sense of ownership the capacity of users to create their own rules and establish the means of monitoring and sanctioning the rules constitute a key factor that help individuals to solve their collective action problems when institutions do not allow space for self organization and take over the management of a natural resource it destroys an immense stock of social capital ostrom 2001 baland and platteau 1996 summarize it brilliantly when resource responsibility is taken away from the village so is the concern for the viability of the resource two important factors lead to the decline in collective action in the ab during phases 4 and 5 i the committee s perceived lack of autonomy and ability to make any meaningful contribution to policy change and ii the loss of relevance when incorporated into the larger emlr plans our research adds evidence to the argument that although natural resources should be managed in an integrated manner face to face networks with on ground hydrogeologists and community members should remain for smaller scale problems to be better integrated into larger management areas an ab interviewee clearly stated that government plans should allow more flexibility for local institutions to self organize and create their own rules as put by social researcher brené brown in the context of organizational change we desperately want change but too often we want to engineer the vulnerability humanity and messiness out of change efforts we want to build systems and track accountability without engaging people not only does this kill change it corrodes trust and engagement connection and relationships are the heart of change brown 2021 6 limitations and future work it is difficult to draw generalized conclusions and policy recommendations from one case study especially considering groundwater management is highly contextual bekkar et al 2009 on the other hand the contextual flavor that a case study brings is important to understand the nuances of groundwater management and to provide lessons for managers researchers and uses to apply to their aquifer systems to the best of our knowledge this is one of very few groundwater management social studies including quotes and narratives from local stakeholders a rare example is cuadrado quesada 2014 it is important to document and examine such groundwater management history so that it can be preserved for posterity and available for the management and scientific communities in addition to the above discussed factors some other factors were scarcely mentioned by a few interviewees as potentially collective action influencing such as generational changes adaptability to change personal connections with politicians and time commitment these factors seem to have played a minor role for the involvement of particular people an example is some family farming businesses where the younger generation taking over did not engage in collective action as much as much as the previous one these factors were not explored further as we focused on factors relevant for the area at large future work on the angas bremer case study can include analyzing stakeholders perspectives on effectiveness and efficiency assertions in conjunction with biophysical data 7 conclusion this paper illustrates and discusses a rare example of collective action that led to successful co management and positive groundwater outcomes it answers calls for international successful examples on collective action and co management in groundwater and most importantly on their critical influencing factors e g molle and closas 2019 molle and closas 2020a the ab example confirms collective action is most effective when it starts from a community level and can serve as a catalyst for successful co management in turn leading to successful groundwater management the results show that during the phases when community collective action was high groundwater management was more successful with more and better outcomes as opposed to the phases where collective action was low this is mainly because resource users feel ownership of the problem and are more likely to accept and comply with management policies following the critiques that frameworks on collective action mainly focus on formal institutions rather than the resource users perspective this study used the ab irrigation system as a case study to identify and analyze the main factors that facilitate or impede collective action in groundwater management and how it evolved through time with climatic crises and governance changes 14 qualitative interviews were conducted to take into consideration the community s perspective on the socio cultural context in which ab s collective action arose examining the changes that happened within the ab community from the 1950s until the present day the main factors and conditions that facilitated the emergence of collective action within the ab community are i perceived crisis ii small homogenous community iii presence of strong leadership from respected members of the community iv shared norms and values v shared goals and vi trustworthy relationships between community members a main lesson learnt from the ab experience is that strong social and human capitals act as a catalyst for successful collective action and in turn for successful co management however these are not enough strong support from government departments and agencies is a crucial condition for a shared understanding of the groundwater system through monitoring and data co interpretation the ab committee by working together in a cooperative way with the government department developed and implemented innovative water management policies which led to reduction of groundwater extractions by 80 promoted artificial recharge from excess surface water changed crops for increased profitability and decreased water consumption and constructed pipelines accessing surface water sources although it is not possible to generalize from one case study we can confidently conclude that positive human and social capitals within a resource users community facilitates collective action which combined with support from the government departments and agencies leads to successful co management government departments can support users by providing funds to i monitor the resource and providing timely feedback on the resource and ii having on the ground hydrogeologists to provide the community with the necessary scientific information and technical advice finally on ground hydrogeologists must have the ability to form successful and trust building relationships with the user groups through open honest and regular communication between stakeholders additionally government departments must give users the autonomy required for users to be able to devise their own rules collective action is highly dependent on the specific location and the historical institutional social and economic contexts therefore groundwater management policies should consider local scale allowing for the community s norms and values and local knowledge to be reflected in policies and management approaches the findings from this study recommend against government institutions to change management areas and approaches in systems where effective collective action occurs without properly consulting groundwater users even if the changes may seem technically sound they will only facilitate better management if users understand and accept such changes otherwise government institutions risk eroding or erasing human and social capital and to break trust ties between stakeholders which are critical for managing groundwater systems in all their dimensions credit authorship contribution statement sarah shalsi conceptualization methodology formal analysis writing original draft writing review editing project administration carlos m ordens conceptualization methodology writing original draft supervision writing review editing allan curtis conceptualization methodology resources writing review editing craig t simmons conceptualization resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank ms diane davidson for suggesting us this interesting research project the authors would also like to thank prof christine trenorden ms emily mendham dr constantine seidl and ms leah hunter for insightful discussions that helped in conducting this research work we would like to thank the interviewees for their availability and valuable information provided we would also like to thank the editor and three anonymous reviewers for their contributions to improving the paper appendix 1 no question 1 can you tell me when and how you first became involved in the management of the ab groundwater resource has either the nature e g role or extent of your involvement changed over time if so how and why 2 what is your understanding of how local people have been involved in decisions about the management of the ab groundwater resource has that changed over time if so in your view what have been the main changes if so why do you think those changes occurred 3 how much influence have local people really had on decisions about the management of the ab groundwater resource has their influence changed over that time if so how if so why do you think those changes have occurred 4 what do you see as the main benefits of having local people involved in decision making about the management of the ab groundwater resource 5 have there been any negative outcomes as a result of having local people involved in decision making about the management of the ab groundwater resource 6 what do you think the lessons are for other communities in other places 7 what are some factors that motivated the ab community to engage in collective action 
