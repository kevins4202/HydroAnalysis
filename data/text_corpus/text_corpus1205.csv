index,text
6025,sustainable urban surface runoff management is receiving increased attention due to environmental and ecological consequences related to urbanization this study presents a useful new framework for green infrastructure gi planning for the management of urban runoff quality and quantity the proposed framework considers physical technical economic and multi stakeholder aspects related to urban runoff management while simultaneously addressing the uncertainties of the decision making process and model parameters the methodology is applied to regionally locating and sizing low impact development best management practices lid bmps while considering the hydrologic and hydraulic impacts a decision making multi objective optimization framework is developed by integrating 1 a multi layer perceptron neural network founded on a storm water management model swmm mlp meta model 2 nsga ii multi objective optimization 3 fuzzy α cut technique and 4 a decision making support model based on social choice theory to elicit trade offs among system cost and lid bmp performance indicators the decision making model based on fuzzy social choice fsc theory is applied to simulate consensus between stakeholders for a partially cooperative group decision making problem the proposed methodology is explored in a catchment located in the northeastern part of tehran iran results showed that the swmm could be effectively replaced with a mlp based meta model in simulation optimization problems for urban runoff management in the application of fsc methods the optimal scenarios were effective in reducing the volume of urban runoff and contamination loads while maintaining the optimality of the operation costs considering the optimal lid scenario a reduction of more than 99 in runoff volume and biochemical oxygen demand bod and a decrease of more than 92 of total suspended solids tss occurred for the lower bound of uncertainty lower left end of the α cut 0 3 for the upper bound of uncertainty upper right end of the α cut level 0 3 a maximum reduction of 57 was obtained in applying fsc methods through the decision making process the borda counting method considered the preferences of all stakeholders best moreover the proposed framework allows decision makers to decide on the acceptability and reliability of the optimal management scenarios considering their preferences and uncertainties keywords green infrastructure gi low impact development lid storm water management model swmm multi objective optimization fuzzy α cut techniques fuzzy social choice fsc theory 1 introduction urbanization has led to a reduction in vegetative cover which can adversely affect both the quantity and quality of urban runoff due to increasingly impervious urban watersheds greater volumes of precipitation cannot fully infiltrate into the soil and instead become runoff with the potential to wash away deposited pollutants yeh and labadie 1997 hsieh and davis 2005 the management of urban surface runoff is a matter of considerable environmental concern behera et al 1999 because pollutants in urban surface runoff can substantially impact the water quality of receiving waters behera et al 2006 low impact development best management practices lid bmps for urban surface runoff are environmentally sustainable techniques that are designed to reduce runoff quantity and improve runoff quality in a natural and aesthetic manner municipalities are becoming increasingly aware of green infrastructure gi planning such as lid bmps due to the growing environmental and ecological consequences associated with urbanization hsieh and davis 2005 the design of an effective urban surface runoff management plan requires a suitable combination of lid bmps scales and locations therefore full incorporation of hydrologic and hydraulic modeling processes is required for a lid bmps design optimization model the decision making process however is complicated by multiple objectives such as runoff volume reduction runoff water quality improvement and project cost effectiveness multi objective optimization techniques have been used as effective methods for identifying optimal lid bmp strategies for multi attribute urban runoff management problems jia et al 2013 chiang et al 2014 ghodsi et al 2016a one of the most efficient multi objective optimization algorithms is the nondominated sorting genetic algorithm ii nsga ii that was initially proposed by deb et al 2000 over the past few years meta heuristic algorithms such as the nsga ii search technique have been successfully applied to various hydro environmental management problems dorn and ranjithan 2003 yandamuri et al 2006 muschalla 2008 bazargan lari et al 2009 nikoo et al 2015 sahraei et al 2017 farhadi et al 2016 ghodsi et al 2016b alizadeh et al 2017b for more in depth information regarding these methods and the nsga ii please refer to deb et al 2000 2002 increasingly policy making for water resources is complicated by the need to address the conflicting objectives and interests of multiple stakeholders hydro environmental management problems involving multiple stakeholders can be divided into three categories 1 cooperative group decision making problems 2 non cooperative group decision making problems and 3 partial cooperative non cooperative group decision making problems madani et al 2014b of these classifications the third option best represents the problems associated with environmental and water resources planning and management as stakeholders may not fully adhere to cooperative or non cooperative decision making in practice a hybrid approach i e partially cooperative non cooperative is most appropriate social choice methods are simple yet efficient methods which can be reliably applied to partial cooperative non cooperative group decision making problems social choice methods can effectively develop stable solutions while remaining conscious of the co existence of multiple stakeholders due to the simplicity of this concept and its applicability in group decision making social choice theory has often been applied to hydro environmental management problems e g laukkanen et al 2002 laukkanen et al 2004 srdjevic 2007 sheikhmohammady and madani 2008 sheikhmohammady et al 2010 zarghami and szidarovszky 2011 srdjevic and srdjevic 2013 nikoo et al 2013 madani et al 2014a b nikoo et al 2014 mahjouri and abbasi 2015 ghodsi et al 2016b alizadeh et al 2017a b for more details about this method see madani et al 2014a b uncertainty is a fundamental component of decision making and as such uncertainty must be considered in environmental and water resources management uncertainty can arise from incomplete information regarding a given problem or misinformed judgments by decision makers alizadeh et al 2017b a comprehensive decision making analysis approach must be able to consider the uncertainties involved in the various elements of a decision making process and further how these uncertainties affect decisions a wide variety of approaches such as sensitivity analysis hyde et al 2005 fuzzy decision analysis zarghami et al 2008 afshar et al 2011 malakpour estalaki et al 2016 and monte carlo selection methods madani and lund 2011 madani et al 2014a have demonstrated the ability to handle uncertainty in hydro environmental decision making problems a review of these studies highlights the need for a multi objective decision making framework that helps in developing urban runoff management techniques researchers have employed different methods including multi objective optimization models with fuzzy concepts makropoulos et al 2003 zarghami 2010 or other bargaining techniques to consider stakeholders conflicting objectives ghodsi et al 2016a ghodsi et al 2016b recently eckart et al 2018 developed a coupled optimization simulation model by linking the storm water management model swmm to the borg multi objective evolutionary algorithm borg moea the optimization simulation tool was then used to evaluate low impact development lid strategies huang et al 2018 established an optimization model for flood mitigation by combining swmm and a simulated annealing sa algorithm macro et al 2019 developed an open source multi objective swmm optimization tool by connecting swmm with the optimization software toolkit for research involving computational heuristics ostrich other researchers have focused on investigating the effect of lid bmp techniques on flood control in urban areas using swmm bai et al 2019 hu et al 2019 or future scenarios modeling wang et al 2018 conventional methods in urban runoff management however still suffer from major deficiencies the developed multi objective simulation optimization models for urban runoff management have considered tradeoffs between different goals such as minimizing costs reducing runoff volume and improving runoff quality without considering the uncertainties of conflicting objectives in the system deficiencies arise from attempts to simultaneously consider both the uncertainties associated with conflicts and negotiation regarding multi objectivity of the system stakeholder preferences and the uncertainties in the physical input parameters throughout the decision making process consequently this research aims to propose a framework for solving partially cooperative group decision making problems with uncertain input data this is achieved by integrating the storm water management model swmm nsga ii optimization algorithm a non dominated ranking algorithm the fuzzy α cut technique and fuzzy social choice theory for decision analysis the key innovations of this research include 1 the development of a fuzzy multi objective optimization model for designing lid bmps that considers both quantity aspects minimizing runoff volume and relative operation costs of the lid bmps and quality indices such as total suspended solids tss and biological oxygen demand bod which align better with urban runoff quality quantity management 2 the development of an artificial intelligence meta model that uses the results of an iterative execution of the calibrated swmm for different area size scenarios to reduce the runtime associated with integrating a fuzzy multi objective model 3 the use of an advanced non dominated ranking algorithm deb et al 2002 to assess the monotonicity of all uncertain parameters individually for consideration in developing the models 4 the application of the fuzzy α cut technique to analyze the uncertainty defined by the fuzzy membership functions of uncertain parameters at diverse uncertainty levels from the highest level of uncertainty to the crisp values in order to generate the minimum and maximum possible values 5 the use of fuzzy social choice theory to incorporate uncertainties that stem from differing stakeholder perspectives in the decision making strategy this paper is the first attempt to develop and examine a multi objective decision making approach that considers both quality and quantity while addressing uncertainties in decision making and model parameters for integrated catchment level planning of urban runoff management systems this study presents a step wise framework for urban runoff management the framework involves the initial data collection followed by stakeholder analysis determining objective functions considering different types of uncertainties developing multi objective simulation optimization to acquire pareto fronts and finally the application of decision making models previous studies mostly focused on different aspects of this study separately such as the optimization phase or developing the simulation optimization models the primary difficulty with previously linked simulation optimization models based on swmm is the very significant computation time required due to the iterative execution of the numerical simulation model ghodsi et al 2016a b eckart et al 2018 huang et al 2018 therefore to decrease the computational complexity and runtime associated with the simulation model ann based meta models have been included in comparison with the swmm which allows for the simulation of large scale problems with diverse stakeholders and objective functions the meta models are trained and tested using the results of iterative executions of the swmm and coupled with the optimization model this study shows that the swmm model could be effectively replaced with an ann meta model with reasonable accuracy which can significantly decrease computational effort and runtime in developing simulation optimization models this study also extensively considered the effect of uncertainty on optimal outcome policies in designing the lid bmps both the uncertainties associated with conflicts and negotiation regarding the multi objectivity of the system stakeholder preferences and the uncertainties in the physical input parameters throughout the decision making process are considered simultaneously the uncertainty of input data rainfall imperviousness and area size the calibration coefficient of the model wash off and build up coefficients and stakeholders preferences are addressed using the fuzzy α cut technique to test the monotonicity of the model previous studies on multi objective optimization problems considered the model as monotonic based on all objective functions individually in this research using an advanced sorting method called a non dominated ranking algorithm deb et al 2002 all the objectives were considered simultaneously to assess the monotonicity of the model integrally the significance of incorporating conflicting preferences of stakeholders in integrated runoff quality and quantity management is also investigated although other methods such as game theory and the nash bargaining model have been applied to lid bmps here for the first time the fuzzy social choice theory has been applied to simulate the hybrid partial cooperative non cooperative group decision making conditions considering that stakeholders may not fully adhere to cooperative or non cooperative decision making in practice this method considers and simulates the real world conditions of a multi stakeholder decision making situation under uncertainty to demonstrate the practical applicability of the developed framework the nsga ii optimization algorithm is applied for regionally locating and sizing the lid bmps while considering their hydraulic and hydrological impacts using swmm a powerful rainfall runoff simulation model a multi objective optimization methodology is proposed to extract trade offs between system cost and lid bmps performance indicators after identifying the pareto optimal management policies of the stakeholders in the system the consensus based non dominated policy solution on the trade off curve is selected through the use of fuzzy social choice theory the proposed framework is applied to an urbanizing catchment in the velenjak basin of northeastern tehran iran 2 methodology this paper proposes a hierarchical framework using advanced procedures to model the technical environmental economic and decision making aspects of urban surface runoff management physically based models are used to estimate the quantity and quality of urban surface runoff using historical rainfall data coupled with other catchment features including the topography land use and urban runoff drainage system a fuzzy methodology for combining simulation and optimization models was developed to facilitate decision making in urban runoff management under uncertainty a flowchart of the suggested framework in urban runoff management is provided in fig 1 followed by a detailed discussion of its principal components the data required to build these models includes rainfall data land characteristics e g topography soil types land use types and urban runoff drainage networks non point source pollution loads along with the associated lid practices and their costs and the preferences of involved stakeholders the available information is then used to 1 calculate rainfall intensity and distribution 2 derive the objective functions of the participating stakeholders in the decision making process 3 prioritize and select the applicable lid practices and 4 cluster the sub catchments these results aid in updating and guiding the identification procedure for creating a list of potential lid bmps and locations it is further necessary to select the most uncertain parameters and determine their variation ranges a sensitivity analysis approach is also used to identify and select sensitive model parameters concerning model outputs of interest 2 1 fuzzy multi objective urban runoff simulation optimization meta model in this study a high resolution detailed swmm was used to model the quality and quantity of urban runoff the swmm was calibrated and validated using input data from monitored rainfall events wash off and build up coefficients area sizes and imperviousness data the calibrated and validated swmm can be run for extended periods typically twenty years to achieve precise annual estimations of urban runoff volume and nonpoint pollution loads regarding rainfall data land use and geomorphological characteristics this section describes the process by which available data and the results of similar studies were analyzed to determine the main swmm parameters and their values or uncertainty bounds the calibrated and validated swmm was run for all possible combinations of input values and uncertain parameters to examine the performance of each lid practice considered the process of an iterative execution of the calibrated swmm for a different combination of uncertain input data is presented in fig 2 these results were then used to develop the multi layer perceptron artificial neural networks mlp anns which were linked with the multi objective optimization algorithm for direct simulation of the urban runoff quantity and quality significantly reducing computation time the nsga ii multi objective optimization model and fuzzy α cut technique were then integrated to form a fuzzy optimization approach this approach optimizes the utility functions of the involved decision making stakeholders and determines the optimal features of the lid bmps in the considered catchment for different α cut levels from the highest level of uncertainty to the crisp values the characteristics of the sub catchments and input parameters of the swmm are presented with respect to the contents previously discussed the area imperviousness coefficient and land use type of the 27 sub basins in the study area are presented in table s1 supplementary material of the proposed lid bmps vegetative swales and bio retention cells table s2 supplementary material were selected according to the conditions of the region and their performance in controlling the volume and quality of runoff in order to train the swmm mlp meta model several outputs from the calibrated swmm version 5 and the r2015a version of matlab software were obtained input data for the swmm includes the imperviousness coefficients build up and wash off coefficients for tss and bod rainfall and area sizes of both lid bmps for the considered sub catchments the lower bound upper bound and the average value of build up and wash off parameters for tss bod and the imperviousness coefficient are presented in tables s3 s4 and s5 respectively supplementary material the area sizes of the considered sub catchments based on type of lid bmps are also presented in table s6 due to the large number of sub catchments and wide range of area sizes table s5 sub catchments were classified into three groups based on area size and slope table s1 the scenarios for the area sizes were then created to reduce the complexity of the mlp model each group was divided into smaller subgroups based on the imperviousness coefficient values the imperviousness coefficient of each subgroup was assumed to be constant for all sub catchments table s7 supplementary material shows the classification of sub catchments 12 to 27 into six subgroups based on area size slope and imperviousness values the lower and upper bounds and the average values of imperviousness coefficients for the considered subgroups are presented in table s8 supplementary material each subgroup has identical and independent lids for instance sub catchments 12 to 15 subgroup b have a total area of 1600 and 500 for lid1 and lid2 respectively as a result the number of scenarios of the area size was derived as 7 7 7 6 8 8 l i d 1 7 7 7 6 8 8 l i d 2 and the number of inputs for the mlp was reduced from 32 16 2 to 12 6 2 fig s1 shows the lower and upper bounds as well as the average values of imperviousness coefficients for subclasses 12 to 27 to consider uncertainty to account for the uncertainty of input parameters of the swmm intervals of 25 for imperviousness coefficients and intervals of 5 to 9 for rainfall were considered for other uncertain parameters such as the build up and wash off coefficients the interval of 20 of their certified crisp values was used 2 2 determining objective functions for the multi objective optimization model the multi objective optimization problem presented in this study is composed of three objective functions 1 minimizing the implementation cost of the lid bmps 2 reducing pollutants in urban runoff and 3 alleviating runoff volume at the catchment outlet these objectives are outlined and formulated as utility functions of the main stakeholders involved in the study area as follows objective 1 tehran agricultural organization tao farmers agricultural areas are located mostly in southern tehran the tao prefers that urban runoff volume be maximized resulting in a greater contribution to the downstream agricultural water supply hence the utility function of the tao is expressed as the maximization of runoff volume at the catchment outlet 1 f tao z 1 m i n w s 1 1 v i v max w s 2 ts s i ts s max where i stands for the urban runoff management scenario number v i represents the volume of runoff for the i th scenario of urban runoff management and v max stands for the potential maximum volume of runoff which was computed based on physical characteristics of the catchment the swmm was performed without considering any lid bmps and the resulting v was considered as the v max accordingly v max was estimated to be 80000 m3 ts s i is the total tss contamination load of scenario i and ts s max is the maximum tss contamination load which was found to be 60000 kg at the watershed outlet similarly based on the topographic hydraulic and hydrologic characteristics of the watershed the swmm was performed without considering any lid bmps and the associated tss load was determined as the potential maximum tss load ghodsi et al 2016b w s 1 and w s 2 are the relative significance weights of runoff volume and tss contamination load respectively the values of w s 1 and w s 2 were set to 0 5 based on engineering judgments objective 2 tehran regional water company trwc the trwc is responsible for the distribution of domestic industrial and agricultural water over extraction of groundwater from increasing water demands has resulted in a decline in groundwater levels within the study area in the areas with a low groundwater table the trwc would like to protect groundwater resources by maximizing urban runoff infiltration an objective that is in direct conflict with the tao for this study the utility function of trwc was considered as the minimization of runoff volume at the catchment outlet 2 f trwc z 2 m i n v i v max where v i is the runoff volume and v max is the maximum runoff volume objective 3 tehran municipality tm as the major sponsor of the lid bmps the tm prefers to minimize implementation costs associated with the lids as the tm seeks to reduce the costs associated with lid they are in direct conflict with the trwc which requires extensive use of lid to increase runoff infiltration the tm also prefers to control urban runoff volume by implementing lid bmps a desire which potentially conflicts with the tao and their interests aesthetic considerations are also a primary concern for the tm diverse pollutants from the urban environment degrade urban runoff quality during transport previous studies by soltani 2009 have shown that total suspended solids tss can be considered as an appropriate water quality indicator in the study area the utility function of tm is described as 3 f tm z 3 m i n w f 1 v i v max w f 2 c i c max w f 3 bo d i bo d max w f 4 ts s i ts s max where ts s i and bo d i represent the tss and bod contamination loads for the i th urban runoff management scenario respectively and ts s max and bo d max stand for potential maximum tss and bod loads respectively based on the topographic hydraulic and hydrologic characteristics of the watershed the swmm was performed without considering any lid bmps and the associated tss and bod loads were determined as the potential maximum tss and bod contamination loads ghodsi et al 2016b c i represents the implementation cost of the i th urban runoff management scenario and c max stands for the potential maximum implementation cost of the lids estimated based on iran s unit costs reference book the coefficients w f 1 w f 2 w f 3 and w f 4 are the relative weights of runoff volume the operation cost of the lid bmps bod load and tss contamination load respectively where w f 1 w f 2 w f 3 w f 4 1 the relative significance weights for the aforementioned coefficients w f 1 w f 2 w f 3 w f 4 were set to 0 25 0 35 0 2 and 0 2 respectively based on engineering judgments expert opinions from all participating stakeholder organizations were collected through interviews to estimate the relative weights subsequently the analytic hierarchy process ahp method was applied through paired comparisons to determine the associated weights for all terms of the objective functions here the fuzzy social choice methods were used as a benchmark to solve the uncertain collective decision making problem of velenjak s urban runoff this study illustrates how parties agree over the voting procedure for the selection of bmps in the pareto optimal outcome space 2 3 monotonicity test to test the monotonicity of the model each uncertain parameter of the calibrated swmm permeability coefficient tss build up coefficient bod build up coefficient tss wash off coefficient bod wash off coefficient and rainfall values were divided into five categories based on their initial estimated value 20 10 0 10 and 20 respectively then for a particular value of all uncertain parameters e g 20 of rainfall the optimal values for other parameters and area sizes of the lid bmps were determined using the nsga ii according to the upper and lower bounds consequently the non dominated ranking algorithm deb et al 2002 was used to rank the resultant values for each uncertain parameter from the previous step the input of this algorithm is a m 3 matrix where m n 20 n 10 n 0 n 10 n 20 and n i is the number of outputs from the optimization algorithm the output of this algorithm is a m 1 matrix containing whole integers increasing from 1 which represent the input data ranking the function is considered monotonic if the ranking of the input data has a regular upward or downward trend with no fracture between ranks 2 4 fuzzy α cut analysis in the process of formulating a fuzzy optimization approach for urban runoff management a fuzzy α cut analysis was used to analyze the impact of uncertain parameters after defining fuzzy membership functions for all fuzzy parameters the fuzzy α cut analysis was performed to examine the uncertainty defined with fuzzy membership functions at diverse α cut levels from the highest level of uncertainty to the crisp values the fuzzy α cut analysis is a robust technique which can be used in uncertainty analysis as a useful alternative to monte carlo analysis specifically when uncertain parameters have monotonic functions fuzzy α cut can perform an analysis faster the main concept of fuzzy α cut analysis is based on fuzzy logic and fuzzy set theory zadeh 1983 which is commonly used in uncertainty analysis in this method all uncertain parameters are defined with a membership function as an example fig 3 presents a triangular fuzzy membership function for the uncertain parameter p where a 0 is its uncertainty support a wider a 0 indicates a higher level of uncertainty of the system a α an α cut of the fuzzy number a is expressed as the set x r a x α a is determined by the support of a α with α 0 1 an alpha cut is the degree of confidence in the uncertain parameter for the α level abebe et al 2000 in the present study the model was run for every α cut level to generate the minimum and maximum feasible values of the output uncertainty corresponding to each fuzzy parameter was then determined using the resultant data 2 5 decision making using fuzzy social choice theory finally a simple but effective conflict resolution model in accordance with fuzzy social choice theory was used to develop an agreement between different decision making stakeholders involved in the moderately cooperative group this model then selected the most appropriate configuration of lid bmps since trade off curves by the fuzzy nsga ii optimization model present several optimal alternatives which are non dominated points various possible outcomes were obtained per stakeholder priorities each outcome may not be fully accepted by all involved stakeholders hence to attain an aggregate agreement on a unique socio optimal solution different fuzzy social choice methods were employed to choose a socio optimal compromise solution on the trade off curve namely fuzzy borda counting fbc fuzzy min max fmm fuzzy approval voting fav and fuzzy linguistic quantifiers flq 3 study area the study area catchment is located in the northeastern part of tehran 51 12 5 51 14 8 e 35 43 44 35 45 5 n and is part of the tehran grand urban runoff drainage network high population density along with an increasingly impervious urban landscape has prompted concerns about the environmental consequences of urbanization and the subsequent development of the region the catchment has a total area of approximately 20 km2 with the highest point being mt velenjak at 2590 m above sea level the catchment contains 27 sub catchments along the velenjak mainstream channel which are enumerated from upstream to downstream in fig 4 overall 16 potential sites sub catchments 12 27 were designated for the selected lid bmps shomal tehran is located at 35 34 n and 51 37 e and has 22 years of historical records from a synoptic weather station historical 6 hour rainfall data collected from 1994 to 2015 was used in calculating the rainfall distribution design for this study urban surface runoff from tehran is an important source of irrigation waters for downstream agriculture the impacts of poor quality urban storm water runoff on the three stakeholder groups operating in the urban runoff management system must be considered the three main decision making stakeholder groups for this study were the tehran municipality tm the tehran regional water company trwc and the tehran agricultural organization tao 4 results and discussion in order to find the optimal number of neurons and hidden layers the mlp models performed a trial and error analysis using a set of data from the calibrated swmm based on this an optimal double layer neural network with 35 and 20 neurons was selected the bayesian regularization backpropagation was also considered as a training function in developing the mlp meta models a split of 80 107 000 and 20 26 750 of the data obtained from the previous step for runoff and tss and bod contamination loads was used to train and test the meta model performance respectively the combination and type of input data for the mlp swmm meta models are presented in table 1 table 2 also shows the error indices mean square error mse mean absolute percentage error mape and r squared r2 for each developed meta model the monotonicity of the model was confirmed in a previous study by ghodsi et al 2016b in this study however the validity of the model was re evaluated for reliability due to the significant increase in scenarios for area size and the continuous nature of the decision variables the results for the monotonicity evaluation of the model for a state of each uncertain parameter are presented in fig 5 as previously explained in order to evaluate the model s monotonicity each uncertain parameter was classified into five categories then for each considered parameter the multi objective optimization model nsga ii was performed five times the outputs of the nsga ii model for all categories were imported in the non dominated ranking algorithm the output of this algorithm is a value of 1 or larger indicating the dominance of an answer over other solutions according to fig 5 in a multi objective optimization with two objective functions if the pareto fronts do not cut each other they are considered monotonic the lowest pareto front rank is 1 while higher pareto fronts have a higher ranking fig 5a as three objective functions exist eqs 1 to 3 fig 6 is provided to show the model s monotonicity for example fig 6 shows the monotonicity of rainfall as an uncertain parameter the x axis represents each of the five categories 20 to 20 from the bottom according to fig 6 each of the mutations in a line shows a change in the rank of an uncertain parameter obtained by the non dominated ranking algorithm as an example for the rain parameter in the 20 category red line 10 category light green line and part of the 0 category blue line the uncertain parameters are ranked first the remaining parts of the 0 category blue line and 10 category black line are ranked as second further the rest of the 10 category black line parts are ranked third and fourth and the 20 category green line are ranked fourth and fifth the top line in fig 6 represents a non monotonic example in which the output data of the optimization model for the 10 category light green line were ranked as first then the output data moved to an upper rank before finally returning to the first rank after analyzing the monotonicity of the model for each uncertain parameter imperviousness tss build up bod build up bod wash off tss wash off and rainfall values appropriate triangular fuzzy membership functions were considered fig 7 illustrates the triangular fuzzy membership functions for the uncertain parameters due to the existence of various stakeholders in the runoff management problem and the fuzzy nature of uncertain parameters 11 α cut levels were considered on the triangular membership functions the α cut level 0 represents the highest uncertainty interval and the α cut level 1 signifies an expert opinion for each parameter subsequently for the lower and upper limits of each α cut level the nsga ii model was used to optimize the volume of runoff tss bod and the cost of constructing the lids in each group by changing the area sizes of the lids as decision variables fig 8 illustrates a set of solutions from the nsga ii optimization process for the lower and upper bounds of each α cut level according to fig 8 for the lower bound l of α cut level 0 the surface is closer to the origin of the coordinate system for the upper bound r of α cut level 0 the surface is located furthest from the origin by increasing the α cut levels the r and l surfaces became closer to each other fig 8 shows the monotonicity of the objective functions as well finally fuzzy social choice methods were applied to determine the best stakeholder approved solution by considering 1 the presence of different conflicting stakeholders 2 the large number of solutions produced by the nsga ii model and 3 the fuzzy nature of uncertain parameters the results of the fuzzy social choice methods are presented in fig 9 in fig 9 the x axis consists of 21 columns indicating the lower and upper bound of each α cut level the y axis represents the outcomes of the nsga ii model which are the controversial alternatives suggested by the three different stakeholder groups each geometric shape specifies the type of fuzzy social choice method employed while the location of their intersection with vertical and horizontal axes indicates the best selected alternative accepted by all stakeholders in the desired α cut level for example the best alternatives selected by the linguistic quantifier method alternative number 45 with α cut levels of 0 1 l 0 5 l and 1 are specified in fig 9 with yellow arrows fig 10 depicts the calculated objective function values from the nsga ii multi objective model for each α cut level of 0 1 l 0 5 l and 1 the values of the objective functions eqs 1 to 3 for α cut levels of 0 3 and 0 7 as well as the best selected alternatives determined by the different fuzzy social choice methods are presented in table 3 by increasing the α cut levels from 0 3 to 0 7 the values of the uncertain parameters for the lower bound l e g imperviousness coefficients rainfall increase conversely for the upper bound r the values of uncertain parameters decline as a result the values of the objective functions z1 z2 and z3 in table 3 will increase and decrease respectively table 4 provides an example that demonstrates the optimal area size of the lid bmps chosen by the proposed methodology for α cut levels of 0 3 the letters used in table 4 represent the imperviousness subgroup table s7 and the numbers represent the lid type table s2 due to the nature of the objective functions the nsga ii model attempts to minimize the values of these objective functions as a result by enhancing the α cut levels the optimal area sizes of the lids increase and decrease respectively for the lower bound l and upper bound r of the fuzzy membership functions for swmm input parameters with small quantities the optimization algorithm increases the area size of the scenario lid 1 more than lid 2 by enlarging the swmm input values the area size of lid 2 increases and the difference in the area sizes of the two types of lid bmps becomes smaller table 5 presents the best scenario selected by the fuzzy social choice methods the smallest and largest area size of the lid bmps the first and last columns of table s6 respectively the scenario without any lid the volume of runoff tss and bod values and the cost of lid construction for the α cut level of 0 3 according to table 5 low values of swmm input parameters result in greater than 80 reduction in the volume of runoff bod and tss when compared with the scenario without lid in an area less than 42 of the maximum area size by increasing the input parameters of the swmm the volume of runoff bod and tss decreases by a maximum of 48 however the lid area sizes increase to 71 of the maximum area size regarding the upper bound of the α cut levels 0 3 r in table 5 the cost of lid construction for scenario 17 is lower than scenario 19 and the runoff volume and particulate contamination reduction is greater this is mainly due to the much larger area size of the lid 2 used in scenario 19 in comparison to lid 1 in scenario 17 the minimum area size of a lid site is less than 7 of the maximum area of all lid sites for the small and large values of the swmm input parameters the minimum area sizes of the lids are less than 4 and 1 4 respectively concerning the maximum values of the area of the lids considered in this study a decrease of more than 99 for runoff volume and bod and a decrease of more than 92 for tss were obtained for the α cut level of 0 3 l for maximum input values of the model α cut level 0 3 r the maximum decrease was 57 fig 11 shows the performance comparison of the different optimal scenarios obtained by the proposed framework and the non lid scenario in urban runoff management the values of all objective parameters including volume of urban runoff operation cost and tss and bod loads are compared in different management scenarios including 1 without lid bmps wo 2 the minimum possible area size for the lid bmps all lid sizes are considered to be 100 m2 based on table s6 3 the maximum possible area size for the lid bmps based on table s6 and 4 the optimal area size obtained by the fsc decision making methods in fig 11 the x axis represents different levels of uncertainty α cuts 0l 0 1l 0 2l 0 9l 1 0 9r 0 2r 0 1r 0r and the y axis shows the amount of objective function items according to fig 11a the volume of runoff is at its maximum when there are no lid bmps as was expected the minimum volume of runoff occurs in the maximum scenario with the maximum lid area sizes the optimal scenarios obtained by all fsc methods show an effective reduction of runoff and the fbc method specifically outperforms other methods in decreasing runoff volume moreover considering the triangular fuzzy membership function of uncertainties fig 3 the volume of runoff will increase for all scenarios by increasing the level of uncertainty from α cuts 0l to α cuts 0r right to left on the x axis according to fig 11d the optimal scenario by fmm is less costly than fav and the costs of management scenarios suggested by fbc and flq are similar to each other in most α cuts for fig 11b and 11c the minimum values of tss and bod loads occur when the area of the lid bmps is greatest the maximum scenario and vice versa the fbc outperforms other methods resulting in smaller tss and bod loads closer to the maximum scenario followed by flq and fmm relatively the worst results in contamination load reduction were obtained using the fav scenario so based on the results of the optimal scenarios produced by all fsc methods fbc can be considered as the best optimal scenario determination method in urban runoff management when considering stakeholder preferences and the uncertainties of the system the optimal management solution achieved by fbc demonstrated remarkable performance in reducing urban runoff volume and the associated tss and bod loads while considering lid bmp operation costs in the study area 5 conclusion the purpose of this study was to find the optimal area size of lids in the sub catchments of the study area that satisfies the objectives of the three stakeholder organizations tao trwc and tm an swmm mlp meta model based on a multi layer perceptron mlp network was trained using the results of a calibrated and validated swmm to achieve this next a multi objective fuzzy optimization framework was formulated by integrating the swmm mlp meta model nsga ii multi objective optimization and fuzzy α cut techniques to maximize the utility functions of the different decision making stakeholders and to determine the optimal attributes of the lid bmps in the modeled catchment the uncertainty of the parameters was considered in the model using the fuzzy α cut technique finally a simple but effective conflict resolution model based on four fuzzy social choice methods was used to determine a solution deemed acceptable by all stakeholders results demonstrated that 1 the swmm could be effectively replaced with the swmm mlp based meta model in simulation optimization models for urban runoff management with rigorous estimations of the annual volume of urban runoff and nonpoint pollution loads table 2 the framework significantly reduces the computational cost and runtime which can be applied for sustainable urban runoff management in large scale problems 2 in the application of fsc methods the optimal scenarios were effective in reducing the volume of urban runoff and contamination loads while maintaining optimality of the operation costs table 5 considering the optimal management scenarios a reduction of more than 99 for runoff volume and biochemical oxygen demand bod and a decrease of more than 92 of total suspended solids tss occurred for the lower bound of uncertainty left end of the α cut level 0 3 a maximum reduction of 57 was obtained for the upper bound of uncertainty right end of the α cut level 0 3 3 in applying fsc methods through the decision making process the fuzzy borda counting fbc method showed a better performance in considering preferences of all stakeholders fig 11 moreover the proposed framework assists decision makers in determining the acceptability and reliability of the optimal management scenarios by considering stakeholder preferences and uncertainties 4 based on the findings the final selection of the most preferred urban runoff management scenario depends mainly on the operation costs and the importance of bod and cod loads 5 by increasing the α cut levels from 0 to 1 the values of uncertain parameters e g imperviousness rainfall increased for the lower bound l side which accordingly increased the values of the objective functions z1 z2 and z3 in contrast for the upper bound r the uncertain parameters declined and the values of the objective functions consequently decreased in addition the optimal area size of the lids for the lower bound l of the membership functions increased while the upper bound r values decreased 6 for small values of the swmm input parameters the optimization algorithm increased the area size of the scenario lid 1 more than it did for lid 2 by raising the values of the input parameters the area size of lid 2 increased and the difference in the area size of the two types of lids was reduced 7 for low values of input parameters of the swmm there was a reduction of over 80 in the volume of runoff and bod and tss contamination compared to the scenario without any lids in an area size less than 42 of the maximum area size by increasing the values of the input parameters of the swmm the volume of runoff and bod and tss contamination decreased by a maximum of 48 the lid area sizes however increased by 48 to 71 of the maximum area in future studies the proposed framework could be extended and applied to a combination of conventional e g dual drainage system and decentralized storm water management systems e g bmp lids this would provide better practical solutions for urban storm water management for most watersheds furthermore the application of other partially cooperative decision making methods in determining socio optimal policies could be investigated declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data for this article can be found online at https doi org 10 1016 j jhydrol 2019 124091 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6025,sustainable urban surface runoff management is receiving increased attention due to environmental and ecological consequences related to urbanization this study presents a useful new framework for green infrastructure gi planning for the management of urban runoff quality and quantity the proposed framework considers physical technical economic and multi stakeholder aspects related to urban runoff management while simultaneously addressing the uncertainties of the decision making process and model parameters the methodology is applied to regionally locating and sizing low impact development best management practices lid bmps while considering the hydrologic and hydraulic impacts a decision making multi objective optimization framework is developed by integrating 1 a multi layer perceptron neural network founded on a storm water management model swmm mlp meta model 2 nsga ii multi objective optimization 3 fuzzy α cut technique and 4 a decision making support model based on social choice theory to elicit trade offs among system cost and lid bmp performance indicators the decision making model based on fuzzy social choice fsc theory is applied to simulate consensus between stakeholders for a partially cooperative group decision making problem the proposed methodology is explored in a catchment located in the northeastern part of tehran iran results showed that the swmm could be effectively replaced with a mlp based meta model in simulation optimization problems for urban runoff management in the application of fsc methods the optimal scenarios were effective in reducing the volume of urban runoff and contamination loads while maintaining the optimality of the operation costs considering the optimal lid scenario a reduction of more than 99 in runoff volume and biochemical oxygen demand bod and a decrease of more than 92 of total suspended solids tss occurred for the lower bound of uncertainty lower left end of the α cut 0 3 for the upper bound of uncertainty upper right end of the α cut level 0 3 a maximum reduction of 57 was obtained in applying fsc methods through the decision making process the borda counting method considered the preferences of all stakeholders best moreover the proposed framework allows decision makers to decide on the acceptability and reliability of the optimal management scenarios considering their preferences and uncertainties keywords green infrastructure gi low impact development lid storm water management model swmm multi objective optimization fuzzy α cut techniques fuzzy social choice fsc theory 1 introduction urbanization has led to a reduction in vegetative cover which can adversely affect both the quantity and quality of urban runoff due to increasingly impervious urban watersheds greater volumes of precipitation cannot fully infiltrate into the soil and instead become runoff with the potential to wash away deposited pollutants yeh and labadie 1997 hsieh and davis 2005 the management of urban surface runoff is a matter of considerable environmental concern behera et al 1999 because pollutants in urban surface runoff can substantially impact the water quality of receiving waters behera et al 2006 low impact development best management practices lid bmps for urban surface runoff are environmentally sustainable techniques that are designed to reduce runoff quantity and improve runoff quality in a natural and aesthetic manner municipalities are becoming increasingly aware of green infrastructure gi planning such as lid bmps due to the growing environmental and ecological consequences associated with urbanization hsieh and davis 2005 the design of an effective urban surface runoff management plan requires a suitable combination of lid bmps scales and locations therefore full incorporation of hydrologic and hydraulic modeling processes is required for a lid bmps design optimization model the decision making process however is complicated by multiple objectives such as runoff volume reduction runoff water quality improvement and project cost effectiveness multi objective optimization techniques have been used as effective methods for identifying optimal lid bmp strategies for multi attribute urban runoff management problems jia et al 2013 chiang et al 2014 ghodsi et al 2016a one of the most efficient multi objective optimization algorithms is the nondominated sorting genetic algorithm ii nsga ii that was initially proposed by deb et al 2000 over the past few years meta heuristic algorithms such as the nsga ii search technique have been successfully applied to various hydro environmental management problems dorn and ranjithan 2003 yandamuri et al 2006 muschalla 2008 bazargan lari et al 2009 nikoo et al 2015 sahraei et al 2017 farhadi et al 2016 ghodsi et al 2016b alizadeh et al 2017b for more in depth information regarding these methods and the nsga ii please refer to deb et al 2000 2002 increasingly policy making for water resources is complicated by the need to address the conflicting objectives and interests of multiple stakeholders hydro environmental management problems involving multiple stakeholders can be divided into three categories 1 cooperative group decision making problems 2 non cooperative group decision making problems and 3 partial cooperative non cooperative group decision making problems madani et al 2014b of these classifications the third option best represents the problems associated with environmental and water resources planning and management as stakeholders may not fully adhere to cooperative or non cooperative decision making in practice a hybrid approach i e partially cooperative non cooperative is most appropriate social choice methods are simple yet efficient methods which can be reliably applied to partial cooperative non cooperative group decision making problems social choice methods can effectively develop stable solutions while remaining conscious of the co existence of multiple stakeholders due to the simplicity of this concept and its applicability in group decision making social choice theory has often been applied to hydro environmental management problems e g laukkanen et al 2002 laukkanen et al 2004 srdjevic 2007 sheikhmohammady and madani 2008 sheikhmohammady et al 2010 zarghami and szidarovszky 2011 srdjevic and srdjevic 2013 nikoo et al 2013 madani et al 2014a b nikoo et al 2014 mahjouri and abbasi 2015 ghodsi et al 2016b alizadeh et al 2017a b for more details about this method see madani et al 2014a b uncertainty is a fundamental component of decision making and as such uncertainty must be considered in environmental and water resources management uncertainty can arise from incomplete information regarding a given problem or misinformed judgments by decision makers alizadeh et al 2017b a comprehensive decision making analysis approach must be able to consider the uncertainties involved in the various elements of a decision making process and further how these uncertainties affect decisions a wide variety of approaches such as sensitivity analysis hyde et al 2005 fuzzy decision analysis zarghami et al 2008 afshar et al 2011 malakpour estalaki et al 2016 and monte carlo selection methods madani and lund 2011 madani et al 2014a have demonstrated the ability to handle uncertainty in hydro environmental decision making problems a review of these studies highlights the need for a multi objective decision making framework that helps in developing urban runoff management techniques researchers have employed different methods including multi objective optimization models with fuzzy concepts makropoulos et al 2003 zarghami 2010 or other bargaining techniques to consider stakeholders conflicting objectives ghodsi et al 2016a ghodsi et al 2016b recently eckart et al 2018 developed a coupled optimization simulation model by linking the storm water management model swmm to the borg multi objective evolutionary algorithm borg moea the optimization simulation tool was then used to evaluate low impact development lid strategies huang et al 2018 established an optimization model for flood mitigation by combining swmm and a simulated annealing sa algorithm macro et al 2019 developed an open source multi objective swmm optimization tool by connecting swmm with the optimization software toolkit for research involving computational heuristics ostrich other researchers have focused on investigating the effect of lid bmp techniques on flood control in urban areas using swmm bai et al 2019 hu et al 2019 or future scenarios modeling wang et al 2018 conventional methods in urban runoff management however still suffer from major deficiencies the developed multi objective simulation optimization models for urban runoff management have considered tradeoffs between different goals such as minimizing costs reducing runoff volume and improving runoff quality without considering the uncertainties of conflicting objectives in the system deficiencies arise from attempts to simultaneously consider both the uncertainties associated with conflicts and negotiation regarding multi objectivity of the system stakeholder preferences and the uncertainties in the physical input parameters throughout the decision making process consequently this research aims to propose a framework for solving partially cooperative group decision making problems with uncertain input data this is achieved by integrating the storm water management model swmm nsga ii optimization algorithm a non dominated ranking algorithm the fuzzy α cut technique and fuzzy social choice theory for decision analysis the key innovations of this research include 1 the development of a fuzzy multi objective optimization model for designing lid bmps that considers both quantity aspects minimizing runoff volume and relative operation costs of the lid bmps and quality indices such as total suspended solids tss and biological oxygen demand bod which align better with urban runoff quality quantity management 2 the development of an artificial intelligence meta model that uses the results of an iterative execution of the calibrated swmm for different area size scenarios to reduce the runtime associated with integrating a fuzzy multi objective model 3 the use of an advanced non dominated ranking algorithm deb et al 2002 to assess the monotonicity of all uncertain parameters individually for consideration in developing the models 4 the application of the fuzzy α cut technique to analyze the uncertainty defined by the fuzzy membership functions of uncertain parameters at diverse uncertainty levels from the highest level of uncertainty to the crisp values in order to generate the minimum and maximum possible values 5 the use of fuzzy social choice theory to incorporate uncertainties that stem from differing stakeholder perspectives in the decision making strategy this paper is the first attempt to develop and examine a multi objective decision making approach that considers both quality and quantity while addressing uncertainties in decision making and model parameters for integrated catchment level planning of urban runoff management systems this study presents a step wise framework for urban runoff management the framework involves the initial data collection followed by stakeholder analysis determining objective functions considering different types of uncertainties developing multi objective simulation optimization to acquire pareto fronts and finally the application of decision making models previous studies mostly focused on different aspects of this study separately such as the optimization phase or developing the simulation optimization models the primary difficulty with previously linked simulation optimization models based on swmm is the very significant computation time required due to the iterative execution of the numerical simulation model ghodsi et al 2016a b eckart et al 2018 huang et al 2018 therefore to decrease the computational complexity and runtime associated with the simulation model ann based meta models have been included in comparison with the swmm which allows for the simulation of large scale problems with diverse stakeholders and objective functions the meta models are trained and tested using the results of iterative executions of the swmm and coupled with the optimization model this study shows that the swmm model could be effectively replaced with an ann meta model with reasonable accuracy which can significantly decrease computational effort and runtime in developing simulation optimization models this study also extensively considered the effect of uncertainty on optimal outcome policies in designing the lid bmps both the uncertainties associated with conflicts and negotiation regarding the multi objectivity of the system stakeholder preferences and the uncertainties in the physical input parameters throughout the decision making process are considered simultaneously the uncertainty of input data rainfall imperviousness and area size the calibration coefficient of the model wash off and build up coefficients and stakeholders preferences are addressed using the fuzzy α cut technique to test the monotonicity of the model previous studies on multi objective optimization problems considered the model as monotonic based on all objective functions individually in this research using an advanced sorting method called a non dominated ranking algorithm deb et al 2002 all the objectives were considered simultaneously to assess the monotonicity of the model integrally the significance of incorporating conflicting preferences of stakeholders in integrated runoff quality and quantity management is also investigated although other methods such as game theory and the nash bargaining model have been applied to lid bmps here for the first time the fuzzy social choice theory has been applied to simulate the hybrid partial cooperative non cooperative group decision making conditions considering that stakeholders may not fully adhere to cooperative or non cooperative decision making in practice this method considers and simulates the real world conditions of a multi stakeholder decision making situation under uncertainty to demonstrate the practical applicability of the developed framework the nsga ii optimization algorithm is applied for regionally locating and sizing the lid bmps while considering their hydraulic and hydrological impacts using swmm a powerful rainfall runoff simulation model a multi objective optimization methodology is proposed to extract trade offs between system cost and lid bmps performance indicators after identifying the pareto optimal management policies of the stakeholders in the system the consensus based non dominated policy solution on the trade off curve is selected through the use of fuzzy social choice theory the proposed framework is applied to an urbanizing catchment in the velenjak basin of northeastern tehran iran 2 methodology this paper proposes a hierarchical framework using advanced procedures to model the technical environmental economic and decision making aspects of urban surface runoff management physically based models are used to estimate the quantity and quality of urban surface runoff using historical rainfall data coupled with other catchment features including the topography land use and urban runoff drainage system a fuzzy methodology for combining simulation and optimization models was developed to facilitate decision making in urban runoff management under uncertainty a flowchart of the suggested framework in urban runoff management is provided in fig 1 followed by a detailed discussion of its principal components the data required to build these models includes rainfall data land characteristics e g topography soil types land use types and urban runoff drainage networks non point source pollution loads along with the associated lid practices and their costs and the preferences of involved stakeholders the available information is then used to 1 calculate rainfall intensity and distribution 2 derive the objective functions of the participating stakeholders in the decision making process 3 prioritize and select the applicable lid practices and 4 cluster the sub catchments these results aid in updating and guiding the identification procedure for creating a list of potential lid bmps and locations it is further necessary to select the most uncertain parameters and determine their variation ranges a sensitivity analysis approach is also used to identify and select sensitive model parameters concerning model outputs of interest 2 1 fuzzy multi objective urban runoff simulation optimization meta model in this study a high resolution detailed swmm was used to model the quality and quantity of urban runoff the swmm was calibrated and validated using input data from monitored rainfall events wash off and build up coefficients area sizes and imperviousness data the calibrated and validated swmm can be run for extended periods typically twenty years to achieve precise annual estimations of urban runoff volume and nonpoint pollution loads regarding rainfall data land use and geomorphological characteristics this section describes the process by which available data and the results of similar studies were analyzed to determine the main swmm parameters and their values or uncertainty bounds the calibrated and validated swmm was run for all possible combinations of input values and uncertain parameters to examine the performance of each lid practice considered the process of an iterative execution of the calibrated swmm for a different combination of uncertain input data is presented in fig 2 these results were then used to develop the multi layer perceptron artificial neural networks mlp anns which were linked with the multi objective optimization algorithm for direct simulation of the urban runoff quantity and quality significantly reducing computation time the nsga ii multi objective optimization model and fuzzy α cut technique were then integrated to form a fuzzy optimization approach this approach optimizes the utility functions of the involved decision making stakeholders and determines the optimal features of the lid bmps in the considered catchment for different α cut levels from the highest level of uncertainty to the crisp values the characteristics of the sub catchments and input parameters of the swmm are presented with respect to the contents previously discussed the area imperviousness coefficient and land use type of the 27 sub basins in the study area are presented in table s1 supplementary material of the proposed lid bmps vegetative swales and bio retention cells table s2 supplementary material were selected according to the conditions of the region and their performance in controlling the volume and quality of runoff in order to train the swmm mlp meta model several outputs from the calibrated swmm version 5 and the r2015a version of matlab software were obtained input data for the swmm includes the imperviousness coefficients build up and wash off coefficients for tss and bod rainfall and area sizes of both lid bmps for the considered sub catchments the lower bound upper bound and the average value of build up and wash off parameters for tss bod and the imperviousness coefficient are presented in tables s3 s4 and s5 respectively supplementary material the area sizes of the considered sub catchments based on type of lid bmps are also presented in table s6 due to the large number of sub catchments and wide range of area sizes table s5 sub catchments were classified into three groups based on area size and slope table s1 the scenarios for the area sizes were then created to reduce the complexity of the mlp model each group was divided into smaller subgroups based on the imperviousness coefficient values the imperviousness coefficient of each subgroup was assumed to be constant for all sub catchments table s7 supplementary material shows the classification of sub catchments 12 to 27 into six subgroups based on area size slope and imperviousness values the lower and upper bounds and the average values of imperviousness coefficients for the considered subgroups are presented in table s8 supplementary material each subgroup has identical and independent lids for instance sub catchments 12 to 15 subgroup b have a total area of 1600 and 500 for lid1 and lid2 respectively as a result the number of scenarios of the area size was derived as 7 7 7 6 8 8 l i d 1 7 7 7 6 8 8 l i d 2 and the number of inputs for the mlp was reduced from 32 16 2 to 12 6 2 fig s1 shows the lower and upper bounds as well as the average values of imperviousness coefficients for subclasses 12 to 27 to consider uncertainty to account for the uncertainty of input parameters of the swmm intervals of 25 for imperviousness coefficients and intervals of 5 to 9 for rainfall were considered for other uncertain parameters such as the build up and wash off coefficients the interval of 20 of their certified crisp values was used 2 2 determining objective functions for the multi objective optimization model the multi objective optimization problem presented in this study is composed of three objective functions 1 minimizing the implementation cost of the lid bmps 2 reducing pollutants in urban runoff and 3 alleviating runoff volume at the catchment outlet these objectives are outlined and formulated as utility functions of the main stakeholders involved in the study area as follows objective 1 tehran agricultural organization tao farmers agricultural areas are located mostly in southern tehran the tao prefers that urban runoff volume be maximized resulting in a greater contribution to the downstream agricultural water supply hence the utility function of the tao is expressed as the maximization of runoff volume at the catchment outlet 1 f tao z 1 m i n w s 1 1 v i v max w s 2 ts s i ts s max where i stands for the urban runoff management scenario number v i represents the volume of runoff for the i th scenario of urban runoff management and v max stands for the potential maximum volume of runoff which was computed based on physical characteristics of the catchment the swmm was performed without considering any lid bmps and the resulting v was considered as the v max accordingly v max was estimated to be 80000 m3 ts s i is the total tss contamination load of scenario i and ts s max is the maximum tss contamination load which was found to be 60000 kg at the watershed outlet similarly based on the topographic hydraulic and hydrologic characteristics of the watershed the swmm was performed without considering any lid bmps and the associated tss load was determined as the potential maximum tss load ghodsi et al 2016b w s 1 and w s 2 are the relative significance weights of runoff volume and tss contamination load respectively the values of w s 1 and w s 2 were set to 0 5 based on engineering judgments objective 2 tehran regional water company trwc the trwc is responsible for the distribution of domestic industrial and agricultural water over extraction of groundwater from increasing water demands has resulted in a decline in groundwater levels within the study area in the areas with a low groundwater table the trwc would like to protect groundwater resources by maximizing urban runoff infiltration an objective that is in direct conflict with the tao for this study the utility function of trwc was considered as the minimization of runoff volume at the catchment outlet 2 f trwc z 2 m i n v i v max where v i is the runoff volume and v max is the maximum runoff volume objective 3 tehran municipality tm as the major sponsor of the lid bmps the tm prefers to minimize implementation costs associated with the lids as the tm seeks to reduce the costs associated with lid they are in direct conflict with the trwc which requires extensive use of lid to increase runoff infiltration the tm also prefers to control urban runoff volume by implementing lid bmps a desire which potentially conflicts with the tao and their interests aesthetic considerations are also a primary concern for the tm diverse pollutants from the urban environment degrade urban runoff quality during transport previous studies by soltani 2009 have shown that total suspended solids tss can be considered as an appropriate water quality indicator in the study area the utility function of tm is described as 3 f tm z 3 m i n w f 1 v i v max w f 2 c i c max w f 3 bo d i bo d max w f 4 ts s i ts s max where ts s i and bo d i represent the tss and bod contamination loads for the i th urban runoff management scenario respectively and ts s max and bo d max stand for potential maximum tss and bod loads respectively based on the topographic hydraulic and hydrologic characteristics of the watershed the swmm was performed without considering any lid bmps and the associated tss and bod loads were determined as the potential maximum tss and bod contamination loads ghodsi et al 2016b c i represents the implementation cost of the i th urban runoff management scenario and c max stands for the potential maximum implementation cost of the lids estimated based on iran s unit costs reference book the coefficients w f 1 w f 2 w f 3 and w f 4 are the relative weights of runoff volume the operation cost of the lid bmps bod load and tss contamination load respectively where w f 1 w f 2 w f 3 w f 4 1 the relative significance weights for the aforementioned coefficients w f 1 w f 2 w f 3 w f 4 were set to 0 25 0 35 0 2 and 0 2 respectively based on engineering judgments expert opinions from all participating stakeholder organizations were collected through interviews to estimate the relative weights subsequently the analytic hierarchy process ahp method was applied through paired comparisons to determine the associated weights for all terms of the objective functions here the fuzzy social choice methods were used as a benchmark to solve the uncertain collective decision making problem of velenjak s urban runoff this study illustrates how parties agree over the voting procedure for the selection of bmps in the pareto optimal outcome space 2 3 monotonicity test to test the monotonicity of the model each uncertain parameter of the calibrated swmm permeability coefficient tss build up coefficient bod build up coefficient tss wash off coefficient bod wash off coefficient and rainfall values were divided into five categories based on their initial estimated value 20 10 0 10 and 20 respectively then for a particular value of all uncertain parameters e g 20 of rainfall the optimal values for other parameters and area sizes of the lid bmps were determined using the nsga ii according to the upper and lower bounds consequently the non dominated ranking algorithm deb et al 2002 was used to rank the resultant values for each uncertain parameter from the previous step the input of this algorithm is a m 3 matrix where m n 20 n 10 n 0 n 10 n 20 and n i is the number of outputs from the optimization algorithm the output of this algorithm is a m 1 matrix containing whole integers increasing from 1 which represent the input data ranking the function is considered monotonic if the ranking of the input data has a regular upward or downward trend with no fracture between ranks 2 4 fuzzy α cut analysis in the process of formulating a fuzzy optimization approach for urban runoff management a fuzzy α cut analysis was used to analyze the impact of uncertain parameters after defining fuzzy membership functions for all fuzzy parameters the fuzzy α cut analysis was performed to examine the uncertainty defined with fuzzy membership functions at diverse α cut levels from the highest level of uncertainty to the crisp values the fuzzy α cut analysis is a robust technique which can be used in uncertainty analysis as a useful alternative to monte carlo analysis specifically when uncertain parameters have monotonic functions fuzzy α cut can perform an analysis faster the main concept of fuzzy α cut analysis is based on fuzzy logic and fuzzy set theory zadeh 1983 which is commonly used in uncertainty analysis in this method all uncertain parameters are defined with a membership function as an example fig 3 presents a triangular fuzzy membership function for the uncertain parameter p where a 0 is its uncertainty support a wider a 0 indicates a higher level of uncertainty of the system a α an α cut of the fuzzy number a is expressed as the set x r a x α a is determined by the support of a α with α 0 1 an alpha cut is the degree of confidence in the uncertain parameter for the α level abebe et al 2000 in the present study the model was run for every α cut level to generate the minimum and maximum feasible values of the output uncertainty corresponding to each fuzzy parameter was then determined using the resultant data 2 5 decision making using fuzzy social choice theory finally a simple but effective conflict resolution model in accordance with fuzzy social choice theory was used to develop an agreement between different decision making stakeholders involved in the moderately cooperative group this model then selected the most appropriate configuration of lid bmps since trade off curves by the fuzzy nsga ii optimization model present several optimal alternatives which are non dominated points various possible outcomes were obtained per stakeholder priorities each outcome may not be fully accepted by all involved stakeholders hence to attain an aggregate agreement on a unique socio optimal solution different fuzzy social choice methods were employed to choose a socio optimal compromise solution on the trade off curve namely fuzzy borda counting fbc fuzzy min max fmm fuzzy approval voting fav and fuzzy linguistic quantifiers flq 3 study area the study area catchment is located in the northeastern part of tehran 51 12 5 51 14 8 e 35 43 44 35 45 5 n and is part of the tehran grand urban runoff drainage network high population density along with an increasingly impervious urban landscape has prompted concerns about the environmental consequences of urbanization and the subsequent development of the region the catchment has a total area of approximately 20 km2 with the highest point being mt velenjak at 2590 m above sea level the catchment contains 27 sub catchments along the velenjak mainstream channel which are enumerated from upstream to downstream in fig 4 overall 16 potential sites sub catchments 12 27 were designated for the selected lid bmps shomal tehran is located at 35 34 n and 51 37 e and has 22 years of historical records from a synoptic weather station historical 6 hour rainfall data collected from 1994 to 2015 was used in calculating the rainfall distribution design for this study urban surface runoff from tehran is an important source of irrigation waters for downstream agriculture the impacts of poor quality urban storm water runoff on the three stakeholder groups operating in the urban runoff management system must be considered the three main decision making stakeholder groups for this study were the tehran municipality tm the tehran regional water company trwc and the tehran agricultural organization tao 4 results and discussion in order to find the optimal number of neurons and hidden layers the mlp models performed a trial and error analysis using a set of data from the calibrated swmm based on this an optimal double layer neural network with 35 and 20 neurons was selected the bayesian regularization backpropagation was also considered as a training function in developing the mlp meta models a split of 80 107 000 and 20 26 750 of the data obtained from the previous step for runoff and tss and bod contamination loads was used to train and test the meta model performance respectively the combination and type of input data for the mlp swmm meta models are presented in table 1 table 2 also shows the error indices mean square error mse mean absolute percentage error mape and r squared r2 for each developed meta model the monotonicity of the model was confirmed in a previous study by ghodsi et al 2016b in this study however the validity of the model was re evaluated for reliability due to the significant increase in scenarios for area size and the continuous nature of the decision variables the results for the monotonicity evaluation of the model for a state of each uncertain parameter are presented in fig 5 as previously explained in order to evaluate the model s monotonicity each uncertain parameter was classified into five categories then for each considered parameter the multi objective optimization model nsga ii was performed five times the outputs of the nsga ii model for all categories were imported in the non dominated ranking algorithm the output of this algorithm is a value of 1 or larger indicating the dominance of an answer over other solutions according to fig 5 in a multi objective optimization with two objective functions if the pareto fronts do not cut each other they are considered monotonic the lowest pareto front rank is 1 while higher pareto fronts have a higher ranking fig 5a as three objective functions exist eqs 1 to 3 fig 6 is provided to show the model s monotonicity for example fig 6 shows the monotonicity of rainfall as an uncertain parameter the x axis represents each of the five categories 20 to 20 from the bottom according to fig 6 each of the mutations in a line shows a change in the rank of an uncertain parameter obtained by the non dominated ranking algorithm as an example for the rain parameter in the 20 category red line 10 category light green line and part of the 0 category blue line the uncertain parameters are ranked first the remaining parts of the 0 category blue line and 10 category black line are ranked as second further the rest of the 10 category black line parts are ranked third and fourth and the 20 category green line are ranked fourth and fifth the top line in fig 6 represents a non monotonic example in which the output data of the optimization model for the 10 category light green line were ranked as first then the output data moved to an upper rank before finally returning to the first rank after analyzing the monotonicity of the model for each uncertain parameter imperviousness tss build up bod build up bod wash off tss wash off and rainfall values appropriate triangular fuzzy membership functions were considered fig 7 illustrates the triangular fuzzy membership functions for the uncertain parameters due to the existence of various stakeholders in the runoff management problem and the fuzzy nature of uncertain parameters 11 α cut levels were considered on the triangular membership functions the α cut level 0 represents the highest uncertainty interval and the α cut level 1 signifies an expert opinion for each parameter subsequently for the lower and upper limits of each α cut level the nsga ii model was used to optimize the volume of runoff tss bod and the cost of constructing the lids in each group by changing the area sizes of the lids as decision variables fig 8 illustrates a set of solutions from the nsga ii optimization process for the lower and upper bounds of each α cut level according to fig 8 for the lower bound l of α cut level 0 the surface is closer to the origin of the coordinate system for the upper bound r of α cut level 0 the surface is located furthest from the origin by increasing the α cut levels the r and l surfaces became closer to each other fig 8 shows the monotonicity of the objective functions as well finally fuzzy social choice methods were applied to determine the best stakeholder approved solution by considering 1 the presence of different conflicting stakeholders 2 the large number of solutions produced by the nsga ii model and 3 the fuzzy nature of uncertain parameters the results of the fuzzy social choice methods are presented in fig 9 in fig 9 the x axis consists of 21 columns indicating the lower and upper bound of each α cut level the y axis represents the outcomes of the nsga ii model which are the controversial alternatives suggested by the three different stakeholder groups each geometric shape specifies the type of fuzzy social choice method employed while the location of their intersection with vertical and horizontal axes indicates the best selected alternative accepted by all stakeholders in the desired α cut level for example the best alternatives selected by the linguistic quantifier method alternative number 45 with α cut levels of 0 1 l 0 5 l and 1 are specified in fig 9 with yellow arrows fig 10 depicts the calculated objective function values from the nsga ii multi objective model for each α cut level of 0 1 l 0 5 l and 1 the values of the objective functions eqs 1 to 3 for α cut levels of 0 3 and 0 7 as well as the best selected alternatives determined by the different fuzzy social choice methods are presented in table 3 by increasing the α cut levels from 0 3 to 0 7 the values of the uncertain parameters for the lower bound l e g imperviousness coefficients rainfall increase conversely for the upper bound r the values of uncertain parameters decline as a result the values of the objective functions z1 z2 and z3 in table 3 will increase and decrease respectively table 4 provides an example that demonstrates the optimal area size of the lid bmps chosen by the proposed methodology for α cut levels of 0 3 the letters used in table 4 represent the imperviousness subgroup table s7 and the numbers represent the lid type table s2 due to the nature of the objective functions the nsga ii model attempts to minimize the values of these objective functions as a result by enhancing the α cut levels the optimal area sizes of the lids increase and decrease respectively for the lower bound l and upper bound r of the fuzzy membership functions for swmm input parameters with small quantities the optimization algorithm increases the area size of the scenario lid 1 more than lid 2 by enlarging the swmm input values the area size of lid 2 increases and the difference in the area sizes of the two types of lid bmps becomes smaller table 5 presents the best scenario selected by the fuzzy social choice methods the smallest and largest area size of the lid bmps the first and last columns of table s6 respectively the scenario without any lid the volume of runoff tss and bod values and the cost of lid construction for the α cut level of 0 3 according to table 5 low values of swmm input parameters result in greater than 80 reduction in the volume of runoff bod and tss when compared with the scenario without lid in an area less than 42 of the maximum area size by increasing the input parameters of the swmm the volume of runoff bod and tss decreases by a maximum of 48 however the lid area sizes increase to 71 of the maximum area size regarding the upper bound of the α cut levels 0 3 r in table 5 the cost of lid construction for scenario 17 is lower than scenario 19 and the runoff volume and particulate contamination reduction is greater this is mainly due to the much larger area size of the lid 2 used in scenario 19 in comparison to lid 1 in scenario 17 the minimum area size of a lid site is less than 7 of the maximum area of all lid sites for the small and large values of the swmm input parameters the minimum area sizes of the lids are less than 4 and 1 4 respectively concerning the maximum values of the area of the lids considered in this study a decrease of more than 99 for runoff volume and bod and a decrease of more than 92 for tss were obtained for the α cut level of 0 3 l for maximum input values of the model α cut level 0 3 r the maximum decrease was 57 fig 11 shows the performance comparison of the different optimal scenarios obtained by the proposed framework and the non lid scenario in urban runoff management the values of all objective parameters including volume of urban runoff operation cost and tss and bod loads are compared in different management scenarios including 1 without lid bmps wo 2 the minimum possible area size for the lid bmps all lid sizes are considered to be 100 m2 based on table s6 3 the maximum possible area size for the lid bmps based on table s6 and 4 the optimal area size obtained by the fsc decision making methods in fig 11 the x axis represents different levels of uncertainty α cuts 0l 0 1l 0 2l 0 9l 1 0 9r 0 2r 0 1r 0r and the y axis shows the amount of objective function items according to fig 11a the volume of runoff is at its maximum when there are no lid bmps as was expected the minimum volume of runoff occurs in the maximum scenario with the maximum lid area sizes the optimal scenarios obtained by all fsc methods show an effective reduction of runoff and the fbc method specifically outperforms other methods in decreasing runoff volume moreover considering the triangular fuzzy membership function of uncertainties fig 3 the volume of runoff will increase for all scenarios by increasing the level of uncertainty from α cuts 0l to α cuts 0r right to left on the x axis according to fig 11d the optimal scenario by fmm is less costly than fav and the costs of management scenarios suggested by fbc and flq are similar to each other in most α cuts for fig 11b and 11c the minimum values of tss and bod loads occur when the area of the lid bmps is greatest the maximum scenario and vice versa the fbc outperforms other methods resulting in smaller tss and bod loads closer to the maximum scenario followed by flq and fmm relatively the worst results in contamination load reduction were obtained using the fav scenario so based on the results of the optimal scenarios produced by all fsc methods fbc can be considered as the best optimal scenario determination method in urban runoff management when considering stakeholder preferences and the uncertainties of the system the optimal management solution achieved by fbc demonstrated remarkable performance in reducing urban runoff volume and the associated tss and bod loads while considering lid bmp operation costs in the study area 5 conclusion the purpose of this study was to find the optimal area size of lids in the sub catchments of the study area that satisfies the objectives of the three stakeholder organizations tao trwc and tm an swmm mlp meta model based on a multi layer perceptron mlp network was trained using the results of a calibrated and validated swmm to achieve this next a multi objective fuzzy optimization framework was formulated by integrating the swmm mlp meta model nsga ii multi objective optimization and fuzzy α cut techniques to maximize the utility functions of the different decision making stakeholders and to determine the optimal attributes of the lid bmps in the modeled catchment the uncertainty of the parameters was considered in the model using the fuzzy α cut technique finally a simple but effective conflict resolution model based on four fuzzy social choice methods was used to determine a solution deemed acceptable by all stakeholders results demonstrated that 1 the swmm could be effectively replaced with the swmm mlp based meta model in simulation optimization models for urban runoff management with rigorous estimations of the annual volume of urban runoff and nonpoint pollution loads table 2 the framework significantly reduces the computational cost and runtime which can be applied for sustainable urban runoff management in large scale problems 2 in the application of fsc methods the optimal scenarios were effective in reducing the volume of urban runoff and contamination loads while maintaining optimality of the operation costs table 5 considering the optimal management scenarios a reduction of more than 99 for runoff volume and biochemical oxygen demand bod and a decrease of more than 92 of total suspended solids tss occurred for the lower bound of uncertainty left end of the α cut level 0 3 a maximum reduction of 57 was obtained for the upper bound of uncertainty right end of the α cut level 0 3 3 in applying fsc methods through the decision making process the fuzzy borda counting fbc method showed a better performance in considering preferences of all stakeholders fig 11 moreover the proposed framework assists decision makers in determining the acceptability and reliability of the optimal management scenarios by considering stakeholder preferences and uncertainties 4 based on the findings the final selection of the most preferred urban runoff management scenario depends mainly on the operation costs and the importance of bod and cod loads 5 by increasing the α cut levels from 0 to 1 the values of uncertain parameters e g imperviousness rainfall increased for the lower bound l side which accordingly increased the values of the objective functions z1 z2 and z3 in contrast for the upper bound r the uncertain parameters declined and the values of the objective functions consequently decreased in addition the optimal area size of the lids for the lower bound l of the membership functions increased while the upper bound r values decreased 6 for small values of the swmm input parameters the optimization algorithm increased the area size of the scenario lid 1 more than it did for lid 2 by raising the values of the input parameters the area size of lid 2 increased and the difference in the area size of the two types of lids was reduced 7 for low values of input parameters of the swmm there was a reduction of over 80 in the volume of runoff and bod and tss contamination compared to the scenario without any lids in an area size less than 42 of the maximum area size by increasing the values of the input parameters of the swmm the volume of runoff and bod and tss contamination decreased by a maximum of 48 the lid area sizes however increased by 48 to 71 of the maximum area in future studies the proposed framework could be extended and applied to a combination of conventional e g dual drainage system and decentralized storm water management systems e g bmp lids this would provide better practical solutions for urban storm water management for most watersheds furthermore the application of other partially cooperative decision making methods in determining socio optimal policies could be investigated declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data for this article can be found online at https doi org 10 1016 j jhydrol 2019 124091 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6026,agricultural practices intended to increase productivity can adversely affect our soil and water resources expected changes in climate and other social pressure are anticipated to exacerbate these impacts jeopardizing the sustainability of the agro ecosystems watershed management practices wmps are meant to achieve a rational use of resources as well as enhance ecosystem resilience to climate change however the effectiveness of wmps depends on the complex interactions between processes occurring across the watershed the objective of this study was to simulate the impacts of wmps and projected climate on the sediment and nitrate nitrogen no3 n stream loads in an intensively managed watershed the modeling framework was developed with the physically based distributed model mike she for the upper sangamon river basin usrb an agricultural watershed in central illinois the fate and transport of sediment and no3 n in the watershed and rivers was simulated using a generic advection dispersion equation ade with no3 n and sediment as the main species results showed that non structural wmps such as crop rotation and cover crops presented the highest reductions of simulated no3 n and sediment load respectively while structural wmps had higher area efficiency performance on the other hand climate conditions had a strong impact on the transport of both pollutants due to water fluxes alterations especially for a future dry climate scenario sediment transport was shown to be more sensitive to climate given that rainfall is one of the main drivers of the erosion processes outcomes from this research will give a more comprehensive approach toward understanding the impacts of environmental stressors at a watershed scale and how they may be propagated to ecological systems keywords hydrologic model transport model water management practices nonpoint source pollution advection dispersion equation musle mike she mike 11 1 introduction agriculture is one of the most important sources of surface and groundwater pollution in the u s tim and jolly 1994 nonpoint source pollution from fertilizers pesticides sediments animal wastes and other agricultural activities can compromise the quality of our water bodies and impose a threat to the freshwater ecosystems these problems are expected to be exacerbated by the projected changes in climate and the need for intensifying food production to support the growing population tai et al 2014 less environmentally aggressive practices and conservation schemes are being sought after for implementation to mitigate these issues reduced tillage crop rotation cover crops vegetative buffers and conservation tillage are some of the watershed management practices wmps applied to promote a sustainable agro production system where productivity and environmental soundness are optimized to effectively propose a sustainable watershed management plan it is necessary to understand the system s behavior under varied scenarios of environmental stressors like wmps and future climate conditions zhen et al 2006 epa 2018 specifically the combined impacts of these stressors on the movement of water and contaminants in the system should be evaluated however hydrologic systems are complex to study due to the multifaceted interactions of surface and subsurface water fluxes with biochemical processes that vary in time and space for instance understanding how farming and industrial practices or climate variabilities affect watershed responses and how these effects are propagated in time and space require a holistic approach that accounts for the spatio temporal interactions of the main processes in the system liu et al 2016 bergstrom et al 2016 agricultural watersheds are subjected to dynamic surface and subsurface alteration from farming activities such as tillage tile drainage and fertilizer inputs to mention a few as a result water movement across the watershed is significantly altered that can exacerbate sediment and nutrient pollution the upper sangamon river basin usrb located in central illinois has experienced the effects of these practices for decades depositing large loads of nitrogen phosphorus and sediments into lake decatur the main source of freshwater for the cities of decatur and mt zion the usrb predominantly covered with row crops is the main source of the non point source pollution in lake decatur via surface run off and subsurface tile drainage resulting in water quality impairment in the lake nitrogen concentrations have exceeded drinking water standards bekele et al 2014 and the lake capacity has been reduced significantly due to the sedimentation of suspended solids rhoads et al 2016 by the 1980s one third of the original lake s capacity had been lost due to approximately 200 000 tons of sediment delivered yearly to lake decatur rhoads et al 2016 efforts are being made to repair the damages that nonpoint source pollution has brought to the usrb a dredging project is taking place to recover lake decatur s capacity by 2019 rhoads et al 2016 and environmental agencies such as the illinois state water survey and the illinois environmental protection agency are taking actions in the watershed planning iepa 2017 bekele et al 2014 to reduce the agricultural practices impacts on water quality according to the illinois nutrient loss strategy iepa 2017 a reduction of 15 in nitrate nitrogen load is targeted by 2025 and a final goal of 45 load reduction is expected to be met over time therefore there is a critical need to assess the future response of the usrb to environmental stressors such as watershed management practices and future climate conditions the projected impacts of these stressors can provide valuable insights of what actions need to be taken to attain a sustainable agro production system the objective of this study was to apply the coupled physically based distributed model mike she and mike 11 to simulate the effects of environmental stressors on the fate and transport of no3 n and sediment in the upper sangamon river basin usrb water bodies mike she and mike 11 can simulate the systemic responses of a watershed accounting for changes in time and space and to propagate these responses from the surface to the subsurface these capabilities enabled mike she and the mike 11 to sufficiently mimic the physical phenomena occurring at the usrb under various stressors the transport model for the usrb used a generic advection dispersion equation ade customized for no3 n and sediment the modified universal soil loss equation musle was used to compute the distributed and time varying sediment inputs from hydrologic and environmental variables while the distributed and time varying inputs of nitrate nitrogen were created in accordance with the registered fertilizer application schedule for corn in illinois eighteen scenarios were created by combining wmps and climate cases to estimate the impacts of environmental stressors over nonpoint source pollution in the usrb 2 methodology 2 1 study area the usrb located in central illinois has an approximate area of 2400 km2 draining to lake decatur fig 1 a man made reservoir built in 1922 to supply water to the city of decatur and the village of mt zion with populations of 73 000 and 5800 respectively uscb 2016 presently almost 80 of the watershed area is allocated for row crops primarily corn and soybeans the transformation of prairie and savannah landscape into agricultural cropland occurred with the installation of ditches and subsurface tile drains that were used successfully to drain flat lands with poorly drained soils the usrb has a temperate climate with hot summers and cold snowy winters and has an average annual precipitation of approximately 1000 mm iepa 2007 2 2 modelling overview to study the effects of wmps over the usrb a watershed model was set up using the physically based distributed model mike she coupled with the hydrodynamic river model mike 11 hydrologic and transport processes were included in this model to account for nonpoint source pollution in the usrb the water movement wm on the overland ol unsaturated zone uz and saturated zone sz were simulated and three streamflow measuring stations fisher monticello and decatur fig 1 usgs 2017 were used as assessment endpoints to verify the capacity of the models to represent the system additionally the transport processes for sediments and nitrate nitrogen were simulated and verified with the measured loads at the stream the verified model was used to simulate the baseline scenario 1980 2015 period under the current conditions of the watershed and historic climate data afterwards scenario based changes were implemented to quantify the effects of wmps on the water quality of the ursb the streamflow nitrate nitrogen load and sediment load were used as assessment endpoints 2 2 1 mike she and mike 11 2 2 1 1 hydrologic module the hydrologic processes taking place in the usrb were simulated using mike she and mike 11 which fully integrates surface subsurface and river flows the wm in the ol uz sz and rivers were simulated by solving the partial differential equations describing mass flow and transfer of momentum the simulation of the ol run off was performed by solving the 2 dimensional flow diffusive wave equation using the finite difference method while the flow through the vadose zone was simulated with the 1 dimensional finite difference solution of the richard s equation and the movement of water percolating into the sz was simulated with the 3 dimensional finite difference solution of the darcy equation subsurface drainage through tile drains was simulated with a linear reservoir model an empirical formula that requires a drain level and a time constant that accounts for the density of drainage network and the permeability around the drains dhi 2017a in this method the drainage flow was made proportional to the water table height above the drain level and the time constant value zhou et al 2013 once the water reaches the river the 1 dimensional hydrodynamic model mike 11 simulates the hydrograph propagation along the streams by solving the system of flow equations through an implicit finite difference scheme the flow in the upstream tributaries was simulated through kinematic routing while that in the main branch 148 5 km length was simulated by solving the fully dynamic continuity and momentum equations the mike 11 model interacts with the ol uz and sz compartments from mike she at the river linked cells established by the river topology 2 2 1 2 transport module the transport module of the mike she and mike 11 model was applied to simulate the nitrate n and sediment transport across the usrb the advection dispersion equation ade eq 1 was applied to simulate the transport in each compartment of the hydrologic model ol uz sz and channels the advection part of the equation accounted for the transport of solutes due to the wm and the dispersion part included the spreading of solutes caused by concentration gradients and the complex variability of microscopic velocities in the medium the water fluxes resulting from the hydrologic model were used as inputs to the transport model for this reason the wm simulations were stored frequently enough to account for the temporal changes in solute transport mike she model accounted for sorption attenuation of solute by exponential decay and plant uptake processes decay was enabled in the ol flow model and both sorption and decay in the uz and the sz the conservative transport of solutes in the sz was governed by the ade eq 1 which required the dispersion coefficient tensor dij and the groundwater velocity vector v i when sorption and decay were included the equation resulted to 1 c t x i c v i x i d ij c x j ρ b n c t c t reac r c i j 1 2 3 where c is the concentration of the solute ρ b is the bulk density of the soil and n is the porosity the last three terms account for the sources and sinks where c is the mass of sorbed solutes per dry unit weight of solid c t reac indicates the reaction of the solute and r c is the sum of external sources and sinks the groundwater flux q i or darcy s velocities in the sz computed by the hydrologic model was used to determine the groundwater velocity for the advective transport eq 2 2 v i q i n eff the ade eq 1 can be modified for uz ol and rivers for example the 1d version of this equation resulted in the ade for the uz removing the third term from the right hand side of the equation eq 1 which accounted for sorbed mass onto the porous media and using a 2 dimensional version resulted in the ade for ol finally a 1 dimensional version of the ol ade will give the ade for rivers the ades were solved numerically by the finite difference method the time step used for the numerical solution of each compartment transport model i e ol uz and sz varied accordingly with the behavior of the wm in each of them for example the movement of solutes in the river is faster than the movement of solutes through an aquifer hence the time step of the river compartment can be much smaller than the time step for the sz this will guarantee that solutes will not travel too far in one time step and will keep the numerical solution stable the variability of time steps in the different simulated compartments was controlled by the courant number a stability criterion defined as the ratio of flow rate to the grid size also it is important to note that the hydrologic model and the transport model were independently executed the former simulated the exchange between the groundwater and the surface flow using the river model mike 11 and the latter used the wm results to calculate the solute fluxes between the watershed compartments 2 2 1 2 1 sediment fate and transport the sediment transport in the usrb was simulated with the conservative two dimensional ade as a suspended species in the ol compartment suspended species do not infiltrate to the uz or sz and they cannot be sorbed the ol flow transported the sediment particles to the river network where the mike 11 model took over the cohesive sediment transport simulation the ade has a lateral inflow term representing the input of sediment load from the ol and a source sink term to account for erosion deposition from the river bed the r c term in eq 1 will then be the combination of the inputs outputs of ol lateral inflow and erosion deposition sero and sdep the erosion and deposition rates depend on the hydraulic conditions and the concentration of sediments the main parameters used to describe these processes were the free settling velocity w the critical shear stresses for erosion τce and the shear stress for deposition τcd deposition will occur when the bed shear stress is lower than the critical shear stress for deposition likewise erosion will happen when bed shear stress is higher than the erosion critical shear stress the rate of deposition was expressed as 3 s dep wc h 1 τ τ cd τ τ cd where h is the average depth through which particles settle and τ is the bed shear stress the source term for erosion is 4 s ero m h τ τ ce 1 b τ τ ce where m is the erodibility of the bed or erosion coefficient g m 2 s 1 h is the flow depth and b is the erosion exponent which describes the degree of non linearity of the erosion rate dhi 2017b 2 2 1 2 2 nitrogen fate and transport the no3 n transport over the usrb was simulated by the reactive ade nitrate decay and adsorption were implemented to simulate the processes of denitrification and adsorption to soil particles in order to include complex biological and chemical reactions the decay was set to be dependent on soil water content and soil temperature boesten and van der linden 1991 cited in dhi 2017a a first order degradation with an exponential decrease in concentration over the half life corrected by the temperature and the water content factors was used to simulate the attenuation of the solute the reaction term c t reac in eq 1 was then expressed as 5 c t reac l n 2 λ f w f t c 6 f w θ θ s b 7 f t 0 if t s 0 c t s 5 e α 5 t ref if 0 t s 5 c e α t s t ref if t s 5 c where λ is the half life of nitrate fw and ft are the water content and temperature functions respectively eq 6 and 7 and c is the concentration of no3 n the water content function eq 6 depends on the actual soil moisture θ the saturated moisture content θs and an empirical constant b the temperature function eq 7 uses the actual temperature of the soil ts the reference temperature tref at which the half life was estimated and a constant α depending on ts tref the gas constant and the molar activation when the temperature is above the reference temperature the rate of decay increases for ol the temperature of water is assumed to be the same as the air while for the uz and sz the temperature was computed based on the air temperature using an empirical formula eq 8 klein 1995 cited in dhi 2017a 8 t s t sy 0 346 t air t sy e 2 7028 z where tsy is the average daily soil temperature from the day before tair is the average daily air temperature for the current day and z is the depth the adsorption was simulated by the freundlich isotherm where the c in eq 1 was expressed as 9 c k f c n where kf and n were calibrated with measured no3 n concentration from grab samples the nitrate nitrogen transport in the ol was modeled by a two dimensional reactive ade where decay was allowed source terms in this compartment included rainfall deposition and fertilizer inputs a one and three dimensional reactive ades were applied for the uz and the sz respectively both decay and adsorption processes were simulated in the porous media and the background concentration of no3 n for groundwater was used as the initial condition in the uz the plant uptake was represented as a sink term and was computed as a function of the plant transpiration plant s roots soil moisture and nitrate nitrogen concentration an empirical factor was used to include the root s filtering capabilities and a factor of 1 was used for nitrate nitrogen finally the transport of no3 n along the river was simulated with a one dimensional reactive ade including decay 2 2 2 model parameters and inputs for hydrologic module the parameters used in these equations were measured from the physical system the model input data for the model are climate data model domain topography physical parameters for the hydrologic processes simulated at watershed scale empirical parameters for the linear reservoir method simplifying plot scale drainage river topology and transport parameters the climate data are one of the most important inputs for the model rainfall is the main driver of all hydrologic processes from surface runoff to aquifer recharge while temperature solar radiation and wind speed affect evapotranspiration a main process in the water cycle daily values of precipitation temperature and reference evapotranspiration were required as station based inputs sixteen precipitation stations in the usrb and its neighboring watersheds and seven temperature stations were used noaa 2016 fig 1 as main climate inputs missing values from the time series were filled using the inverse distance weighting method reference evapotranspiration was estimated from solar radiation and temperature data by means of the modified makkink s equation de bruin and lablans 1998 following the procedure in botero acosta et al 2018 the model domain was discretized into 300 300 m grids to take into account the spatial variability of the physical parameters in the usrb a topographic map was created from the digital elevation model dem usgs 2016 the physical parameters to simulate the hydrologic processes occurring across the usrb derive from vegetation paved areas soil characterization and geology data a map of vegetation distribution for the usrb was created from the nass 2016 usda 2016 data layer and time series of leaf area index lai root depth and crop coefficient kc were defined for each vegetation type data for root depth and kc were obtained from the cropwat database fao 2016 the location of paved areas and the values of manning coefficient m for each land use type were entered as grids the water retention curves of the soil profiles defined by the nrcs official soil series descriptions nrcs 2016 were used to characterize the uz in the usrb as described in botero acosta et al 2018 the geological stratigraphy of the sz was conceptualized by a two layer system the henry ashmore layer and the glasford pearl layer following the methodology described by botero acosta et al 2018 the henry asmore layer is mainly composed of till sand and gravel from the henry formation and the ashmore tongue while the glasford pearl layer has till sand and gravel and silt and clay from the glasford and pearl formations maps of the lower level elevation of each geological layer horizontal and vertical hydraulic conductivities specific yield and the initial potential head were created and included in the sz model as the geologic units in the usrb were grouped into two main aquifer layers their hydraulic properties were adjusted to achieve the equivalent value that best represented the saturated zone behavior the initial water table depth was set to be 2 m below ground level bgl in accordance with a preliminary four year run botero acosta et al 2018 since no data is available that defines the actual locations of the tile drains in usrb they were placed in the model in accordance with the hydrologic group of the soils and the land use type sugg 2007 ssurgo database was used to identify cells with soils having slow and very slow infiltration rates i e soil hydrologic groups c d and dual soils a d b d and c d fifty eight percent of the usrb was found to have poorly drained soils after crossing soil and land use type data usda 2016 fifty two percent of the usrb area was found to be suitable for subsurface tile drainage installation the drainage was set at 1 m below ground level and the time constant was adjusted to 3 10 7 s 1 to match the measured streamflow at fisher monticello and decatur stations usgs 2017 a 30 30 m pixel resolution dem usgs 2016 was used to draw the river branches across the usrb four cross sections personal communication usgs were included in the main branch and five more at lake decatur isws 1987 2001 the manning coefficient n for the main branch bed and banks was set to 0 04 isws 1994 2 2 3 model parameters and inputs for sediment transport module the transport parameter values and the sources for both sediments and no3 n were specified in the model for each simulated compartment the modified universal soil loss equation musle williams and berndt 1977 sadeghi 2004 was used to simulate the erosion processes occurring at the surface of the watershed fig 2 that served as external source in term rc of the ade eq 1 in this method the value of sediment yield produced in a month y ton was computed as follows 10 y 11 8 q q p 0 56 k c p l s where q is the surface runoff volume accumulated in a month m3 qp is the peak runoff rate in a month m3 s k is the soil erodibility ls is the slope length c is the crop factor and p is the conservation practice daily maps of ol depth were extracted from the hydrologic model and monthly accumulated to create the surface runoff volume q maps to make the monthly maps of peak runoff rates qp the watershed was divided into 32 subwatersheds each one corresponding to a river branch the peak runoff rate qp for each month of simulation was then determined from the daily time series of ol flow rate and was linked to the subwatershed area of the corresponding branch the k factor map was created from the ssurgo database nrcs 2017 the k factor eq 10 accounts for the soil susceptibility to erosion which depends on the soil properties such as texture structure and permeability the distribution of k values in the usrb ranges from 0 05 to 0 49 these values correspond to poorly drained silty clay loams and silt loams soils found in the usrb isws 1996 the c factor map was created according to the land use types table 1 ward et al 2016 and their distribution across the watershed this factor accounted for the temporal variations of crops within a cyclical period of time for example a corn soybean rotation cell has one unique c factor that included the effects of both corn and soybean crops and was applied for all months of simulation the p factor was fixed to 1 0 since no strip cropping contouring and terraces were implemented in the usrb finally the ls factor map was computed from the digital elevation model dem and the methodology proposed by desmet and govers 1996 cited by luna 2016 the geographic information system gis tools flow accumulation and slope calculation were used along with eq 11 13 in computing the l portion of the ls factor as follows 11 m f 1 f 12 f sin β 0 0896 3 sin β 0 8 0 56 13 l a d 2 m 1 a m 1 x m d m 2 22 13 m where β and a are the slope and the flow accumulation values for each pixel respectively d is the pixel side size e g 300 m and x is the shape coefficient set to one for gridded systems the s portion of the ls factor was computed using eq 14 for slopes smaller than 9 mccool et al 1987 renard et al 1997 panagos et al 2015a which is the case for the entire usrb 14 s 10 8 sin β 0 03 the monthly sediment yield computed from musle was divided by the number of days in a month and was entered into the mike she model as daily source maps of mean step accumulated values in kg day a threshold concentration was used by the model to avoid unrealistic high species concentrations in the ol flow the species will precipitate if this concentration was exceeded and put back into motion if the concentration falls below the threshold this effect was considered in the source sink term of eq 1 this threshold will control the amount of eroded soil computed by the musle that was actually transported and reached the streamflow according to chinnasamy et al 2013 the sediment delivery ratio for the usrb ranges from 0 32 to 0 4 these values correspond to the ratio of the sediment delivered at the catchment outlet to on site erosion throughout the basin 2 2 4 model parameters and inputs for nitrate nitrogen transport module no3 n nonpoint sources for the water quality model were created based on the fertilizer application schedule for corn crops in illinois the most commonly used fertilizer in illinois is anhydrous ammonia nh3 which is injected at 25 cm depth and oxidizes to form nitrate that is highly soluble in water this process is called nitrification and is accomplished by soil bacteria nitrosomonas and nitrobacter the former oxidizes the ammonia to nitrite while the latter transforms the nitrite to nitrate both bacteria commonly found in soils require moderate soil water content and temperature to transform ammonia sources to nitrate within a few days of application ipni 2015a on the other hand warm and wet soils with high concentration of no3 will foster denitrification processes under anaerobic conditions and high carbon concentrations microbial activity will transform the nitrate to nitrogen gases which will be released to the atmosphere ipni 2015b daily maps of no3 n sources were created based on the application schedule of fertilizers in the usrb it was assumed that the nitrogen applied to corn crops either in the form of anhydrous ammonia or urea ammonium nitrate co nh2 2 nh4no3 would be converted to nitrate n which is highly soluble in water and then transported throughout the ol sz uz and rivers nitrogen application in the usrb vary from year to year depending on the producer s preferences three cases were identified to simulate this variation table 2 the iepa 2017 reported that approximately 207 kg ha of nitrogen was applied yearly in illinois corn crops either through fertilizer or manure the cases shown in table 2 provided a yearly application of 190 3 kg ha of n which followed the same order of magnitude as the reported one the fertilizer inputs for the baseline period were set in accordance with the information provided by the illinois fertilizer chemical association schaefer personal communication 2018 as follows from 1980 to 2008 case 1 was applied from 2009 to 2011 case 2 and from 2012 to 2015 case 3 the usrb is reported as one of the eight watersheds in illinois with the highest loading of nitrate n and phosphorus from point sources iepa 2017 available mean annual loads of nitrogen discharge for 9 facilities in the usrb epa 2017 ranging from 3 76 kg n year to 9300 kg n year were included as boundary conditions in the mike 11 model at the river branch closest to the facility location since the most common form of inorganic nitrogen in surface water is no3 n wall 2013 the reported loads were assumed to be in nitrate n form natural sources such as fixation of atmospheric nitrogen by bacteria soil organic matter and rainfall deposition generate a background no3 n concentration for groundwater systems the background concentration of nitrate is usually considered to be less than 3 mg l isws 1996 since 22 of nitrate mass corresponds to no3 n the initial no3 n concentration in the groundwater was set to 0 7 mg l inputs from rainfall were considered to be 0 3 mg l of no3 n in accordance with the data measured by the national atmospheric deposition program 2018 from 1979 to 2016 at the nearest station 17 km east of monticello long 88 3719 lat 40 0528 2 2 5 model calibration the flow parameters of the ol uz sz and river compartments in mike she and mike 11 are measurable in the field hence no calibration of these parameters should be needed given the physically based nature of the model nonetheless certain processes and simplifications such as drainage routing and geological layers conceptualization required the adjustment of a few parameters to ensure that the response of the system is well represented daily measured streamflow data usgs 2017 for the 1995 1999 period i and 2011 2015 period ii periods at three stream gauges fisher monticello and decatur fig 1 were used to calibrate and validate the performance of the model decatur s stream gauge station corresponding to the outlet of the usrb had a mean streamflow of 20 73 m3 s for the 1980 2015 period while monticello and fisher average streamflow were 13 81 m3 s and 6 31 m3 s respectively three metrics were implemented to assess the hydrologic module performance under the two periods the nash sutcliffe ns nash and sutcliffe 1970 was computed to evaluate the agreement between observed and simulated stream flow the percent bias pbias gupta et al 1999 estimated the error in the water balance and the pearson s correlation coefficient r was computed to assess the linear correlation between measured and simulated variables similar to flow the transport simulation was performed using physically based equations but certain simplifications and processes required the adjustment of some transport parameters this was the case for the sz layers equivalent transport parameters and the inclusion of processes not explicitly incorporated in the model such as denitrification and sediment trapping the performance of the transport model for sediment and no3 n was evaluated by comparing the simulated load with the observed load from grab samples observed grab sample measurements from 1980 to 1997 for fisher from 1996 to 2013 to monticello and from 1982 to 1997 for decatur were used for the calibration and validation of the transport model the mean observed load of suspended solids for the three stations were computed to be 61 5 ton d 140 4 ton d and 113 7 ton d for fisher monticello and decatur respectively for its part the mean observed no3 n load was 6 3 ton d for fisher 11 8 ton d for monticello and 13 1 ton d for decatur load represents the total mass of a pollutant reaching certain location per unit of time and it is commonly used to assess transport models li et al 2010 talebizadeh et al 2010 zhang and zhang 2011 strauch et al 2013 spieles and mitsch 2000 abbaspour et al 2007 the model efficiency metrics were computed using the simulated value against the grab sample taken on the same day the pbias and pearson correlation coefficient were computed to estimate the degree of over or underestimation of the model with respect to the observed data and the collinearity of the two datasets respectively two time periods denoted period i and period ii were considered for calibrating and validating the parameters the dates and length of these periods mainly depended on the availability of data number of grab samples 2 3 scenarios a scenario based analysis was designed to simulate the watershed responses to selected wmps and climate conditions two structural wmps constructed wetlands and grassed riparian buffers and three non structural wmps crop rotation cover crops and reduced tillage were selected according to the information collected from the stakeholders and experts in management practices in the usrb these wmps appeared to be the most feasible to be used by landowners or implemented as conservation practice by environmental agencies each of these wmps were analyzed under the current and future climate scenarios to identify the effects of climatic variations in the watershed hydrologic processes 2 3 1 wmps constructed wetlands storm water wetlands remove pollutants from overland runoff through vegetation filtering and settling processes wetlands are found to be long lasting pollutant removal facilities that can effectively work even 20 years after construction groh et al 2015 potential wetland restoration areas were identified as those with hydric soils not currently developed covered by water or forested hydric soils are characterized by being permanently or seasonally saturated according to the iepa 2007 most of the usrb is suitable for wetland construction results from the baseline were applied to locate the cells with large accumulation of ol water for this the accumulated ol depth for the 1980 2015 period was computed cells originally devoted to crop production or grass and with cumulative ol depth higher than 10 m for the 36 year period of the baseline were chosen as those suitable for wetland construction in accordance to this 3 4 921 cells of the total usrb was converted to wetlands were 61 of wetlands cells received drained water from 180 ha while 16 collected the water from 360 ha 10 from 540 ha and 5 from 720 ha the remaining 8 received water from 900 ha or more wetlands were conceptualized in the mike she model by modifying the manning number the detention storage the vegetation properties leaf area index lai crop coefficient kc and root depth and the c factor for the musle a manning m value of 1 6 n 0 6 was applied to wetlands cells tsihrintzis and madiedo 2000 and a detention storage of 60 cm was set in accordance to new jersey stormwater best management practices manual 2004 for a pond wetland the detention storage allows water to infiltrate and evaporate but limits the amount of water flowing over the surface when the depth of ponded water is less than the specified value the vegetation properties were set to those of herbaceous plants and since wetlands and other inland waters are not prone to soil erosion panagos et al 2015b their c factor was set to 0 grassed riparian buffers riparian buffers are areas next to the river with permanent vegetation that help stabilize soils and control pollutants mainly by reducing runoff flow rate and filtering sediments and nutrients iepa 2007 the installation of a grassed riparian buffers in the model were achieved in all cells along the streams buffer width was set to 300 m similar to that in botero acosta et al 2018 the vegetation properties the ol manning coefficient and the musle c factor were modified in order to include its effects in the model crop rotation agricultural practices and subsurface tile drainage are the most important aspects affecting nitrate nitrogen stream loads it has been reported that no3 n concentrations downstream from agricultural lands were nine times larger than the concentrations downstream of forested zones among the agricultural lands annual row crop lands had no3 n losses ranging from 30 to 50 times higher than those growing perennial crops randall and mulla 2001 however when proposing an alternative cropping system it is crucial to consider the producers acceptance which highly depends on the economic return of their investment considering the inputs from stakeholders meeting the nature conservancy 2017 2018 a two year corn soybean rotation was chosen to be implemented in continuous corn croplands this cropping system was included in the mike she model through the vegetation properties time series and into the transport model by the musle c factor and the fertilizer application schedule schaefer personal communication 2018 the first year of the two year rotation was allocated to soybean production with no fertilizer application while the second year had fertilizer inputs for corn crops in march 23th and april 15th of 157 kg of n ha and 50 kg of n ha respectively in this scenario all the corn crops approximately 40 of the total area were converted to corn soybean rotation cover crops one year rotation with cover crops was proposed as an alternative cropping system winter wheat serves as overwintering cover crop to prevent erosion add organic matter and scavenge excess nutrients if planted in september winter wheat can absorb 44 kg n ha by december sare 2012 winter wheat was included between regular growing seasons of row crops of either corn or soybean since it works well in reduced tillage systems sare 2012 no additional tillage from the one contemplated in the original row crop needed to be considered this wmp was implemented by modifying vegetation variables time series and the musle c factor reduced tillage conservation tillage requires at least 30 of residue cover from the previous crop to be retained iepa 2007 this land cover creates a preferential flow path through the unsaturated zone increasing infiltration and reducing runoff and sediment movement conventional tillage is usually used for corn crops in the usrb while soybean crops are managed with either conventional or reduced tillage iepa 2007 the baseline for the usrb was set to run with the manning for row crops chow 1959 for both soybean and corn cropland m 28 the effects of conservation tillage were represented in the mike she model through the ol manning number the detention storage and the musle c factor in accordance with the findings and recommendations by mohamoud 1992 a detention storage of 2 2 mm and a manning m of 7 7 n 0 13 were used for reduced till cells the musle c factor was set in accordance with table 1 the cover crops and reduce tillage wmps were applied where they were most influential the vulnerable areas for sediments and nutrients transport were selected by identifying the cells devoted to row crops with large stream power index spi values the spi is a secondary topographic index that estimates the erosive power of the water movement botero acosta et al 2017 it is computed as the natural logarithm of the product of the specific catchment area for each cell ac and the local slope s eq 15 15 spi l n a c s the spi for the usrb ranged from 9 3 to 20 8 cells with spi values equal or larger than the 50th percentile 3 4 and originally used for row crop production approximately 25 of the entire watershed area were chosen for the implementation of cover crop and reduced tillage wmps 2 3 2 future climate scenario the inclusion of climate as a natural stressor allows the study of the combined effects of wmps and climate on the systemic response of the usrb future climate data for the 2020 2055 period were extracted from the coupled model intercomparison project cmip coupled model intercomparision project cmip5 2017 an international program with the mission of simulating future climate and comparing existing climate models the representative concentration pathway 8 5 rcp 8 5 was chosen for the future climate scenarios since it has the highest greenhouse gas emissions caused by high population growth with technology and energy intensification riahi et al 2011 data from the 32 global circulation models from cmip5 were analyzed to determine the most critical climate scenario for usrb being an agricultural watershed precipitation is one of the most important climatological variables that drives agricultural activities hence it was used to identify the models having the driest and the wettest conditions for the 2020 2055 period the global circulation model with the highest total cumulative rainfall at decatur station for the 2020 2055 period and having the most similar climate for the historical analysis 1980 2005 p values from 0 77 to 0 91 for the kolmogorov smirnov ks and t tests for temperature and precipitation respectively was gfdl esm2g 1 rcp85 on the other hand the driest climate model in which the cumulative rainfall was predominantly lower than all the other models for the 2020 2055 period was access1 0 1 rcp85 p values from 0 36 to 0 97 for the ks and t tests for temperature and precipitation respectively both climate models were verified to be among the wettest and driest respectively at other locations across the watershed a polynomial regression analysis similar to botero acosta et al 2018 was conducted to obtain an expression to estimate the future daily reference evapotranspiration from temperature and precipitation at the usrb the historic climate 1980 2015 was found to have lower mean values of daily precipitation 2 75 mm temperature 11 95 c and reference evapotranspiration 2 64 mm d than the future scenarios gfdl esm2g 1 wet 2 92 mm 13 38 c and 2 96 mm d respectively and access1 0 1 dry 2 36 mm 14 69 c and 3 25 mm d respectively for the 2020 2055 period 3 results and discussion 3 1 model calibration and performance 3 1 1 hydrologic module to improve the agreement between the measured and simulated streamflow the equivalent hydraulic conductivities of the henry ashmore and the glasford pearl layers were adjusted as described in botero acosta et al 2018 on the other hand the drain time constant was set to 3 10 7 s 1 a value that agrees with the findings presented in zhou et al 2013 and the recommended range in the mike she manual 1 10 7 s 1 to 1 10 6 s 1 dhi 2017a the model was simulated for the two evaluation periods table 3 with a 2 year period to set up the initial conditions of the model a good agreement between observed and simulated daily streamflow was found where the ns for the three stations in both periods ranged from 0 54 to 0 72 the pbias from 2 2 to 8 5 and the correlation coefficients from 0 73 to 0 85 table 3 3 1 2 transport module the general transport parameters non species related such as porosity dispersion ol and dispersivities uz and sz were adjusted to improve model performance the porosity of both sz layers was set to 0 2 these layers were composed of till sand gravel and clay for which an equivalent porosity was adjusted the ol dispersion coefficient was set to 0 075 m2 s abbasi et al 2003 garcia navarro et al 2000 while the uz and sz dispersivities were set to 0 05 m and 10 m respectively values within the usual ranges used for these parameters forrer et al 1999 adams and gelhar 1992 neuman 1990 the product of the dispersivity and the flow velocity gives the dispersion coefficient for the uz and the sz compartments 3 1 2 1 sediments the sediment was defined in the model as a suspended species hence only the ol and the river compartment flows carried out its transport the yearly mass balance was used in order to check the total amount of sediments entering the river from the ol compartment the threshold concentration for the ol sediment concentration explained in section 2 2 1 2 was adjusted in order to get as close as possible to the reported yearly sediment load reaching lake decatur 200 000 ton year rhoads et al 2016 the adjusted value was found to be 1 104 kg m3 which produced approximately 30 of the total in site eroded soil computed at the grid scale to be transported to the river network however an examination of the daily ol concentration maps for sediments showed that approximately 95 of the grids manifesting sediment transport never reached this threshold experiencing concentrations of up to 2 103 kg m3 according to isws 1994 the sediments reaching lake decatur are predominantly clay which has very low settling rates in fresh water suthernland et al 2013 a conservative ade was applied to simulate the transport of cohesive sediments along the streams towards lake decatur once in the lake the source sink erosion deposition term was activated to include the lake s sediment trapping effects and the lakeshore bank erosion the sediment trap efficiency which represents the percentage of sediments held in the lake was reported to be 78 in 1983 isws 1987 the trap efficiency depends on the spillway height for example in 1956 the peak of sediment trap was reached due to the rise in the spillway height and hence the increase in the lake volume isws 1987 in addition to this sediment traps are being constructed since 2011 huffer 2016 city of decatur 2017 three traps located at the lake inlets capture the incoming sediment before it reaches the main body of the lake one of them treats 85 of the incoming water on the other hand isws 1987 reported that the lakeshore bank erosion was responsible of contributing 2 2 of the total yearly sediment deposited in the reservoir the main causes of this are the steep bluffs and the waves formed at the lake in order to simulate this effect in the sediment concentration at the outlet of the usrb the free settling velocity w the critical shear stresses for erosion τce and deposition τcd and the erodibility of the lake m were adjusted the settling velocity was found to be 2 10 5 m s which agreed with settling velocities for particles with diameters ranging from 0 001 mm to 0 07 mm range that includes clay and silt cheng 1997 a critical shear stress for deposition of 4 n m2 was found to reproduce the lake s sediment trapping effects as shown in the observed data and reported by isws 1987 the maximum bed shear stress at the lake was found to be 3 8 n m2 having a τcd approximately equal to this value allowed continuous sedimentation at the lake similar to borsje et al 2008 since the 1 τ τ cd factor in eq 3 represents the probability of deposition happening lumborg and vested 2008 having a large τcd signifies that the settling process is very likely to happen on the other hand the τce and the m were adjusted to 0 5 n m2 and 0 2 g m2 s respectively these values were in accordance with measurements from other studies on cohesive sediment erosion borsje et al 2008 and are within the typical ranges proposed in the mike 11 manual for these parameters dhi 2017b the sediment transport model performance was tested by comparing the simulated sediment load for the days with available data grab samples an example of this comparison is shown in fig 3 for period ii the observed mean load at the outlet of the usrb decatur was found to be 113 7 ton day which is 20 less than the load observed at the upstream station monticello 140 4 ton day the effect of sediment trapping of the lake and the recently installed sediment traps caused a load reduction at the outlet of the lake by contrast fisher presented a mean sediment load of 61 5 ton day less than half of the load observed at the following downstream station monticello the pbias for the simulated loads at the three stations in both periods showed very good agreement with the observed load 0 83 5 54 in absolute values except for fisher station during period i which presented an underestimation of 23 table 4 a pbias of up to 20 for sediment transport simulation is considered to be good and satisfactory up to 55 moriasi et al 2015 asabe 2017 additionally this station had a pearson s correlation coefficient of 0 88 and a pbias of 4 5 for the period ii table 4 the correlation coefficient for the three stations and two periods showed a good collinearity of observed and simulated values ranging from 0 65 to 0 88 3 1 2 2 nitrate n the dissolved nature of the no3 n allowed the transport to be simulated through the ol uz sz and rivers decay processes were included in all the watershed compartments while sorption was simulated in the uz and sz parameters of no3 n transport were adjusted to better reproduce the observed data the half life λ of the no3 n used in the decay reaction eq 5 was set to 1 2 years with a reference temperature tref of 20 c this value agreed with that of klein et al 2013 who stated that no3 n half life was approximately 500 days for zones where organic substances were present empirical parameters b and α used in the water content and temperature decay correction eq 6 and 7 were adjusted to 0 7 and 1 respectively the adsorption processes in the uz and the sz were simulated using the freundlich isotherm eq 9 where parameters kf and n were set to 8 10 10 m3 g and 0 78 respectively these values agreed with the ones used by hamdi et al 2013 for nitrate sorption in agricultural soils the initial sorbed concentration in the uz and the sz layers ranged from 3 10 6 g g to 2 10 5 g g model simulation results were compared with the observed no3 n load obtained from the grab samples at fisher monticello and decatur for periods i and ii table 4 an example of this comparison is shown in fig 4 for period ii the observed mean of no3 n load at decatur was found to be 13 1 ton day while fisher and monticello had 6 3 ton day and 11 8 ton day respectively the pbias in absolute values and the pearson s correlation coefficient ranged from 0 87 to 9 32 and 0 55 to 0 91 respectively showing a satisfactory behavior of the no3 n transport model table 4 fig 4 3 2 baseline the baseline model was simulated from 1980 to 2015 with a 2 year period to set up the initial conditions of the model the current land use in the usrb and the historic climate were used to set up the model the no3 n inputs were created as explained in section 2 2 1 1 from 1980 to 2008 case 1 table 2 was applied from 2009 to 2011 case 2 and from 2012 to 2015 case 3 sediment inputs were computed through the musle equation and the wm outputs section 2 2 1 2 results for the baseline at the three stations are presented in table 5 the mean values of streamflow sediment and no3 n loads at the outlet of the watershed decatur for the entire simulation period were found to be 20 7 m3 s 78 2 ton day and 14 ton day respectively the mass balance analysis revealed that more than 95 of the total cumulative no3 n reaching the streams during the simulated period came from the subsurface tile drainage flow this was also confirmed by panno et al 2008 who reported that nitrate transported to illinois river tributaries mainly comes from tile drained agricultural lands the sediment trapping effect of the lake is manifested in the reduction of sediment load between monticello and decatur the baseline model exhibited maximum and minimum monthly means at may and august respectively for the three studied variables fig 5 a b and c these results were highly related to the monthly rainfall trends of the historic climate and were expected given the relationship of rainfall with runoff drainage flow erosion and transport processes previous studies about the usrb water and nutrient s seasonal variation had also reported these trends for streamflow and nutrient load li et al 2010 isws 2000 3 3 environmental stressors the six selected wmps and the three climate cases were combined in order to study the usrb response to individual and combined environmental stressors a total of 18 scenarios were created including the baseline table 6 to simulate the impacts of climate wmps and climate wmps over the water quality in usrb graphs of monthly values figs 5 6 and 7 were created to analyze the seasonal trends and changes produced by the selected stressors at decatur the climate scenarios were applied by modifying the daily precipitation temperature and evapotranspiration while the wmps modifications were implemented as explained in section 2 3 1 the fertilizer application schedule and rates for the future climate scenarios were set in accordance with case 2 table 2 this schedule was chosen since case 2 is currently the most common application scheme in central illinois schaefer personal communication 2018 for the corn soybean rotation scenario the same fertilizer application schedule was used for both past and future scenarios 3 3 1 impacts of future climate scenarios an initial analysis of the climate impact on the sediment and no3 n load was achieved by comparing the results for the three climate cases under current wmps application scenarios 1 baseline 2 and 3 in table 6 in this way the effects of solely the climate can be identified since the wmp remained the same as in the baseline although the wet climate slightly increased the no3 n load for the months of january through may with respect to the baseline similar to the streamflow fig 5b the reduction of load for the rest of the months caused a general decrease in the mean load for the simulated period with reductions of up to 11 at the three stations a larger decrease was observed for the no3 n under the dry climate reaching load reductions by up to 74 this result was expected given the small amount of water available to drain to the streams fig 5a the effect of climate was observed to be more significant on the sediment load than the no3 n the general impact of the wettest climate was to increase the sediment load by up to 48 while the driest reduced it by up to 91 fig 5c shows the high impact of climate over the monthly mean sediment load following the monthly trend observed for the streamflow fig 5a the accentuated effect of climate over the sediment load compared to the no3 n is probably due to the nature of the sources for both species the sediment inputs to the model depended on the ol volume and the ol flow musle while the no3 n inputs were solely dependent upon anthropogenic activities with this in mind climate variables especially rainfall modified the sources and the transport processes for the sediments while the no3 n from applied fertilizer sources remained unchanged 3 3 2 impacts of wmps the impacts of wmps were assessed by comparing the sediment and no3 n loads of all the wmp scenarios under historic climate scenarios 1 baseline 4 7 10 13 and 16 in table 6 3 3 2 1 wetland construction by converting flooding prone local depressions to wetlands flow patterns were not altered significantly the 3 4 of the total area turned into wetlands cells did not significantly modify the streamflow but highly impacted the sediment load cells with high ol depth produced the largest sediment inputs on the baseline scenario converting those cells to wetlands caused load reductions from 12 to 40 at the three stations with the highest reductions occurring the months of march april and june fig 6c special attention was paid to an increase in the maximum sediment load at fisher 133 with respect to the baseline this value corresponded to an extreme event observed once during the simulated period on 13 04 1994 the day after the highest observed rainfall which reinforced erosion and transport processes being the smallest of the three sub watersheds and having the highest elevation change botero acosta et al 2018 fisher subwatershed might have limited ability to buffer extreme events the impacts of wetlands on no3 n were minimal given that no3 n is mostly transported through the subsurface drainage system fig 6a and b and storm water wetlands were not intercepting tile drained water 3 3 2 2 reduced till similar to the wetlands the reduced till scenario had very low impacts on the flow and the no3 n load relative changes of less than 1 were observed for the means of both variables at the three stations with respect to the baseline this effect was also manifested in the monthly average of these two variables fig 6a and b in mesoscale watersheds the runoff and flood mitigation effects of reduced tillage are triggered only by convective rainfall high intensity short duration events haag et al 2006 however in large scale basins like the usrb even convective rain will drive minor impacts on the runoff and flood patterns given their localized occurrence niehoff et al 2002 making reduced till effects hardly detectable over the streamflow on the other hand minor reductions of no3 n load were confirmed by daryanto et al 2017 who reported that conservational tillage practices by itself do not impact no3 n loss from cropland unless implemented along with other practices as cover crops or reduced fertilizer rates their findings indicated that the combined effects of no till practices over the no3 n concentration and the flow patterns may not affect the resulting no3 n load for example an increase in no3 n concentration in the runoff along with a proportional reduction of the amount of runoff water would not impact the total amount of no3 n being transported out of the cropland in contrast reduced till caused reductions of sediment load by up to 33 at the three stations erosion processes simulated by the musle were modified by the soil cover effect decreasing the sediment inputs to the transport model 3 3 2 3 grassed riparian buffer the grassed riparian buffer constructed on cells originally devoted to row crops caused the reduction of the streamflow by up to 14 with respect to the baseline mostly manifested during the wettest months april to june at decatur fig 6a this streamflow reduction was most likely produced by increases in evapotranspiration pasture s annual evapotranspiration is expected to be greater than that of row crops due to their longer growth duration and higher lai value at developed plant stage 33 larger the usda 2007 has reported grassed buffers to reduce nitrogen by 10 60 simulated reductions of no3 n load ranged from 16 to 20 at the three stations and were mainly caused by ol load reductions the mass balance of no3 n revealed a reduction of ol inputs to the river of 56 with respect to the baseline highlighting the importance of ol no3 n contributions along the riparian zone although drainage was the most common way of no3 n transport from inland farming areas to the river ol flow was found of main relevance along the riparian zone removing fertilizer application along the riparian zone had a strong impact in the amount of no3 n reaching the streams due to its proximity to water ways on the other hand reductions of sediment loads of 31 7 and 3 were observed at fisher monticello and decatur respectively pasture continuously covering the soil with no till practices resulted in the reduction of erosion along the riparian zone this effect was conceptualized in the model through the land cover factor c factor reduction from 0 4 for row crops to 0 005 for pastures a denser riparian buffer network in upland areas might have caused a greater sediment load reduction in fisher 3 3 2 4 crop rotation crop rotation had very little impacts on the streamflow manifesting reductions of approximately 4 at the three stations probably due to the increase in the evapotranspiration rate caused by a higher lai of soybean with respect to corn during the developed stage of the plant corn soybean rotation had the highest no3 n load reduction among all the wmps fig 6b due to the removal of fertilizer inputs for the soybean production year on 40 of the usrb however this scenario was the only one increasing the sediment load at the three stations by up to 22 soybean cropland have been reported to have higher soil losses than corn under conventional and no till methods while presenting very low impact in water flow patterns alberts et al 1985 this fact is explained by the plant dynamics and the way canopy developed through the first plant growth stages soil coverage around a corn plant is significantly better than that of a soybean plant alberts et al 1985 effect was introduced to the model through the c factor which increased by 5 for corn soybean rotation with respect to only corn scheme 3 3 2 5 cover crops the last wmp to be analyzed is the cover crops this scenario reported the highest reduction in streamflow up to 26 and sediment load up to 47 and the second highest for no3 n load up to 30 for the three stations the reductions occurred mostly during the wettest months march through may fig 6a b and c the water mass balance showed a reduction of approximately 20 for both tile drain and ol water contributions to the river which in turn decreased erosion rates by reducing the ol flow and depth changes in the lai root depth and kc time series when cover crops were implemented in approximately 25 of the usrb led to increase in evapotranspiration rate that caused the reduction in flow consequently this also led to a 23 increase in no3 n plant uptake from the baseline to gain better insight on the level of impacts of the wmps the ratio between the percentage of change in the mean streamflow and loads at decatur and the percentage of modified area was determined for each scenario higher ratio in absolute value would mean larger effects in the study variable with less area modified from the current state of the watershed to this end if two scenarios have the same percentage of pollutant load reduction the one with the least percentage of modified area would be considered more area efficient than the other one considering this approach the most area efficient wmps in reducing no3 n and sediments were the buffer and the wetlands respectively with changes of 12 and 3 4 of the total usrb area 3 3 3 impacts of wmps and future climate the combined effects of wmps and climate were analyzed through scenarios 1 baseline 5 6 8 9 11 12 14 15 17 and 18 table 6 the relative difference in the average streamflow sediment and no3 n loads were computed at the three stations and monthly averages were plotted to visualize seasonal trends fig 7 the monthly plots showed a shift of the streamflow sediment and no3 n load peaks from may towards march april for both future climates fig 7 in general terms wmps applied under the wet climate showed diverse responses over the study variables wetlands and reduced till wmps that barely affected the streamflow and the no3 n load under historic climate section 3 3 2 modified the average streamflow and no3 n load by up to 6 and 12 under wet climate respectively no3 n load reductions were also observed for the riparian buffer crop rotation and cover crops under the wet scenario 26 46 and 38 respectively being the crop rotation the wmp providing the highest reduction of no3 n under wet climate these overall reductions stemmed from substantial load reductions on the months of november and december fig 7b which coincided with months of drier conditions than the historic climate under wet climate the sediment reduction performance of all the alternative wmps was better than the current wmp case meaning that if a wet climate condition was to happen in the future the worst case of sediment loads would occur if the current state of the watershed is maintained the highest reductions of sediment load under the wet climate was achieved with cover crops the reductions denoted as a negative changes of sediment load for all the wmps except crop rotation were smaller as water flowed downstream sediment load changes under wet climate ranged from 36 to 59 at fisher from 15 and 47 at monticello and from 35 to 15 at decatur crop rotation for its part reported increases of sediment load at the three stations up to 43 at decatur with respect to the monthly values of sediment load under wet climate all wmps exhibited a peak in march and april fig 7c while significantly lower loads were observed from july through december almost as low as the ones observed under the dry climate fig 7f the dry climate reduced streamflow no3 n and sediment loads in the three stations by up to 78 90 and 98 respectively from the baseline under the dry climate the highest reduction for the three variables were always obtained for the cover crops however the substantial reduction caused by all wmps under the dry climate was mostly driven by the climate the reductions in the scenario with current wmp and dry climate scenario 3 in table 6 are 61 75 and 91 for streamflow no3 n and sediments respectively in this case an imminent drought would be the main problem 4 conclusion the simulation of nonpoint source pollution at a watershed scale through a physically based distributed model is a complex task due to the interactions among the compartments the physicochemical processes and the conceptualization of the nonpoint sources results from this study can be used as a tool for stakeholders and managerial agencies in the planning of short and long term recovery strategies for highly managed watershed the gains and trade offs of the selected wmps in terms of water quality and the foresight of climate change impacts over their performance will allow a better and more efficient use of the resources the simulation of the erosion process in mike she and mike 11 models facilitated the quantification of the effects of climate and wmps on sediment load in the waterways of usrb erosion processes were found to be localized occurring in the cells with high ol depth hence a wmp implementation in a reduced area 3 4 for wetlands was found to have relatively high reductions compared to other wmps altering a larger portion of the watershed incorporating the filtering effects of vegetation in the sediment transport model presented in this study would allow a better understanding of the effects of riparian buffers and wetlands over the sediment transport dynamics implementing cover crops resulted in the highest streamflow and sediment reduction with respect to the baseline for the three stations up to 25 and 47 respectively while the crop rotation scenario had the highest no3 n load reduction up to 40 although increasing the sediment load these performances were similarly observed for the future wet climate in accordance with the results of this study the most suitable wmps to apply in order to achieve the no3 n reduction goals proposed in the illinois nutrient loss strategy iepa 2017 15 by 2025 and 45 over time assuming the future wet climate condition would be the crop rotation or the cover crops with the risk of increasing stream sediment loads if crop rotation is implemented the wetlands and the riparian buffer were found to be the most area efficient wmp for sediments and no3 n load reduction respectively the buffer effect over the no3 n load was explained by the fact that inland agricultural lands transport no3 n to streams mainly through the drainage flow while the riparian zone no3 n inputs to the river stem primarily from the surface run off removing row crops entirely from the riparian zone would produce a considerable reduction in no3 n load with this in mind it is possible to affirm that non structural wmps caused the highest overall reductions of both pollutant loads but structural wmps were more area efficient the impact of wpms on stream pollutants load under dry climate scenarios was negligible a decrease of up to 78 in the average streamflow due to the reduction in ol and tile drainage flows was accompanied by an extreme load drop at the three control stations in this case nonpoint source pollution would not the main issue but water shortage the three wmp cases with the smallest streamflow reduction would be recommended for this climate condition current wmp reduced till or wetlands located using the methodology proposed in this study declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement funding for this research was provided by the national institute for food and agriculture nifa project illu 741 380 the authors would like to acknowledge the danish hydraulic institute dhi for providing the educational licenses of mike she and mike 11 
6026,agricultural practices intended to increase productivity can adversely affect our soil and water resources expected changes in climate and other social pressure are anticipated to exacerbate these impacts jeopardizing the sustainability of the agro ecosystems watershed management practices wmps are meant to achieve a rational use of resources as well as enhance ecosystem resilience to climate change however the effectiveness of wmps depends on the complex interactions between processes occurring across the watershed the objective of this study was to simulate the impacts of wmps and projected climate on the sediment and nitrate nitrogen no3 n stream loads in an intensively managed watershed the modeling framework was developed with the physically based distributed model mike she for the upper sangamon river basin usrb an agricultural watershed in central illinois the fate and transport of sediment and no3 n in the watershed and rivers was simulated using a generic advection dispersion equation ade with no3 n and sediment as the main species results showed that non structural wmps such as crop rotation and cover crops presented the highest reductions of simulated no3 n and sediment load respectively while structural wmps had higher area efficiency performance on the other hand climate conditions had a strong impact on the transport of both pollutants due to water fluxes alterations especially for a future dry climate scenario sediment transport was shown to be more sensitive to climate given that rainfall is one of the main drivers of the erosion processes outcomes from this research will give a more comprehensive approach toward understanding the impacts of environmental stressors at a watershed scale and how they may be propagated to ecological systems keywords hydrologic model transport model water management practices nonpoint source pollution advection dispersion equation musle mike she mike 11 1 introduction agriculture is one of the most important sources of surface and groundwater pollution in the u s tim and jolly 1994 nonpoint source pollution from fertilizers pesticides sediments animal wastes and other agricultural activities can compromise the quality of our water bodies and impose a threat to the freshwater ecosystems these problems are expected to be exacerbated by the projected changes in climate and the need for intensifying food production to support the growing population tai et al 2014 less environmentally aggressive practices and conservation schemes are being sought after for implementation to mitigate these issues reduced tillage crop rotation cover crops vegetative buffers and conservation tillage are some of the watershed management practices wmps applied to promote a sustainable agro production system where productivity and environmental soundness are optimized to effectively propose a sustainable watershed management plan it is necessary to understand the system s behavior under varied scenarios of environmental stressors like wmps and future climate conditions zhen et al 2006 epa 2018 specifically the combined impacts of these stressors on the movement of water and contaminants in the system should be evaluated however hydrologic systems are complex to study due to the multifaceted interactions of surface and subsurface water fluxes with biochemical processes that vary in time and space for instance understanding how farming and industrial practices or climate variabilities affect watershed responses and how these effects are propagated in time and space require a holistic approach that accounts for the spatio temporal interactions of the main processes in the system liu et al 2016 bergstrom et al 2016 agricultural watersheds are subjected to dynamic surface and subsurface alteration from farming activities such as tillage tile drainage and fertilizer inputs to mention a few as a result water movement across the watershed is significantly altered that can exacerbate sediment and nutrient pollution the upper sangamon river basin usrb located in central illinois has experienced the effects of these practices for decades depositing large loads of nitrogen phosphorus and sediments into lake decatur the main source of freshwater for the cities of decatur and mt zion the usrb predominantly covered with row crops is the main source of the non point source pollution in lake decatur via surface run off and subsurface tile drainage resulting in water quality impairment in the lake nitrogen concentrations have exceeded drinking water standards bekele et al 2014 and the lake capacity has been reduced significantly due to the sedimentation of suspended solids rhoads et al 2016 by the 1980s one third of the original lake s capacity had been lost due to approximately 200 000 tons of sediment delivered yearly to lake decatur rhoads et al 2016 efforts are being made to repair the damages that nonpoint source pollution has brought to the usrb a dredging project is taking place to recover lake decatur s capacity by 2019 rhoads et al 2016 and environmental agencies such as the illinois state water survey and the illinois environmental protection agency are taking actions in the watershed planning iepa 2017 bekele et al 2014 to reduce the agricultural practices impacts on water quality according to the illinois nutrient loss strategy iepa 2017 a reduction of 15 in nitrate nitrogen load is targeted by 2025 and a final goal of 45 load reduction is expected to be met over time therefore there is a critical need to assess the future response of the usrb to environmental stressors such as watershed management practices and future climate conditions the projected impacts of these stressors can provide valuable insights of what actions need to be taken to attain a sustainable agro production system the objective of this study was to apply the coupled physically based distributed model mike she and mike 11 to simulate the effects of environmental stressors on the fate and transport of no3 n and sediment in the upper sangamon river basin usrb water bodies mike she and mike 11 can simulate the systemic responses of a watershed accounting for changes in time and space and to propagate these responses from the surface to the subsurface these capabilities enabled mike she and the mike 11 to sufficiently mimic the physical phenomena occurring at the usrb under various stressors the transport model for the usrb used a generic advection dispersion equation ade customized for no3 n and sediment the modified universal soil loss equation musle was used to compute the distributed and time varying sediment inputs from hydrologic and environmental variables while the distributed and time varying inputs of nitrate nitrogen were created in accordance with the registered fertilizer application schedule for corn in illinois eighteen scenarios were created by combining wmps and climate cases to estimate the impacts of environmental stressors over nonpoint source pollution in the usrb 2 methodology 2 1 study area the usrb located in central illinois has an approximate area of 2400 km2 draining to lake decatur fig 1 a man made reservoir built in 1922 to supply water to the city of decatur and the village of mt zion with populations of 73 000 and 5800 respectively uscb 2016 presently almost 80 of the watershed area is allocated for row crops primarily corn and soybeans the transformation of prairie and savannah landscape into agricultural cropland occurred with the installation of ditches and subsurface tile drains that were used successfully to drain flat lands with poorly drained soils the usrb has a temperate climate with hot summers and cold snowy winters and has an average annual precipitation of approximately 1000 mm iepa 2007 2 2 modelling overview to study the effects of wmps over the usrb a watershed model was set up using the physically based distributed model mike she coupled with the hydrodynamic river model mike 11 hydrologic and transport processes were included in this model to account for nonpoint source pollution in the usrb the water movement wm on the overland ol unsaturated zone uz and saturated zone sz were simulated and three streamflow measuring stations fisher monticello and decatur fig 1 usgs 2017 were used as assessment endpoints to verify the capacity of the models to represent the system additionally the transport processes for sediments and nitrate nitrogen were simulated and verified with the measured loads at the stream the verified model was used to simulate the baseline scenario 1980 2015 period under the current conditions of the watershed and historic climate data afterwards scenario based changes were implemented to quantify the effects of wmps on the water quality of the ursb the streamflow nitrate nitrogen load and sediment load were used as assessment endpoints 2 2 1 mike she and mike 11 2 2 1 1 hydrologic module the hydrologic processes taking place in the usrb were simulated using mike she and mike 11 which fully integrates surface subsurface and river flows the wm in the ol uz sz and rivers were simulated by solving the partial differential equations describing mass flow and transfer of momentum the simulation of the ol run off was performed by solving the 2 dimensional flow diffusive wave equation using the finite difference method while the flow through the vadose zone was simulated with the 1 dimensional finite difference solution of the richard s equation and the movement of water percolating into the sz was simulated with the 3 dimensional finite difference solution of the darcy equation subsurface drainage through tile drains was simulated with a linear reservoir model an empirical formula that requires a drain level and a time constant that accounts for the density of drainage network and the permeability around the drains dhi 2017a in this method the drainage flow was made proportional to the water table height above the drain level and the time constant value zhou et al 2013 once the water reaches the river the 1 dimensional hydrodynamic model mike 11 simulates the hydrograph propagation along the streams by solving the system of flow equations through an implicit finite difference scheme the flow in the upstream tributaries was simulated through kinematic routing while that in the main branch 148 5 km length was simulated by solving the fully dynamic continuity and momentum equations the mike 11 model interacts with the ol uz and sz compartments from mike she at the river linked cells established by the river topology 2 2 1 2 transport module the transport module of the mike she and mike 11 model was applied to simulate the nitrate n and sediment transport across the usrb the advection dispersion equation ade eq 1 was applied to simulate the transport in each compartment of the hydrologic model ol uz sz and channels the advection part of the equation accounted for the transport of solutes due to the wm and the dispersion part included the spreading of solutes caused by concentration gradients and the complex variability of microscopic velocities in the medium the water fluxes resulting from the hydrologic model were used as inputs to the transport model for this reason the wm simulations were stored frequently enough to account for the temporal changes in solute transport mike she model accounted for sorption attenuation of solute by exponential decay and plant uptake processes decay was enabled in the ol flow model and both sorption and decay in the uz and the sz the conservative transport of solutes in the sz was governed by the ade eq 1 which required the dispersion coefficient tensor dij and the groundwater velocity vector v i when sorption and decay were included the equation resulted to 1 c t x i c v i x i d ij c x j ρ b n c t c t reac r c i j 1 2 3 where c is the concentration of the solute ρ b is the bulk density of the soil and n is the porosity the last three terms account for the sources and sinks where c is the mass of sorbed solutes per dry unit weight of solid c t reac indicates the reaction of the solute and r c is the sum of external sources and sinks the groundwater flux q i or darcy s velocities in the sz computed by the hydrologic model was used to determine the groundwater velocity for the advective transport eq 2 2 v i q i n eff the ade eq 1 can be modified for uz ol and rivers for example the 1d version of this equation resulted in the ade for the uz removing the third term from the right hand side of the equation eq 1 which accounted for sorbed mass onto the porous media and using a 2 dimensional version resulted in the ade for ol finally a 1 dimensional version of the ol ade will give the ade for rivers the ades were solved numerically by the finite difference method the time step used for the numerical solution of each compartment transport model i e ol uz and sz varied accordingly with the behavior of the wm in each of them for example the movement of solutes in the river is faster than the movement of solutes through an aquifer hence the time step of the river compartment can be much smaller than the time step for the sz this will guarantee that solutes will not travel too far in one time step and will keep the numerical solution stable the variability of time steps in the different simulated compartments was controlled by the courant number a stability criterion defined as the ratio of flow rate to the grid size also it is important to note that the hydrologic model and the transport model were independently executed the former simulated the exchange between the groundwater and the surface flow using the river model mike 11 and the latter used the wm results to calculate the solute fluxes between the watershed compartments 2 2 1 2 1 sediment fate and transport the sediment transport in the usrb was simulated with the conservative two dimensional ade as a suspended species in the ol compartment suspended species do not infiltrate to the uz or sz and they cannot be sorbed the ol flow transported the sediment particles to the river network where the mike 11 model took over the cohesive sediment transport simulation the ade has a lateral inflow term representing the input of sediment load from the ol and a source sink term to account for erosion deposition from the river bed the r c term in eq 1 will then be the combination of the inputs outputs of ol lateral inflow and erosion deposition sero and sdep the erosion and deposition rates depend on the hydraulic conditions and the concentration of sediments the main parameters used to describe these processes were the free settling velocity w the critical shear stresses for erosion τce and the shear stress for deposition τcd deposition will occur when the bed shear stress is lower than the critical shear stress for deposition likewise erosion will happen when bed shear stress is higher than the erosion critical shear stress the rate of deposition was expressed as 3 s dep wc h 1 τ τ cd τ τ cd where h is the average depth through which particles settle and τ is the bed shear stress the source term for erosion is 4 s ero m h τ τ ce 1 b τ τ ce where m is the erodibility of the bed or erosion coefficient g m 2 s 1 h is the flow depth and b is the erosion exponent which describes the degree of non linearity of the erosion rate dhi 2017b 2 2 1 2 2 nitrogen fate and transport the no3 n transport over the usrb was simulated by the reactive ade nitrate decay and adsorption were implemented to simulate the processes of denitrification and adsorption to soil particles in order to include complex biological and chemical reactions the decay was set to be dependent on soil water content and soil temperature boesten and van der linden 1991 cited in dhi 2017a a first order degradation with an exponential decrease in concentration over the half life corrected by the temperature and the water content factors was used to simulate the attenuation of the solute the reaction term c t reac in eq 1 was then expressed as 5 c t reac l n 2 λ f w f t c 6 f w θ θ s b 7 f t 0 if t s 0 c t s 5 e α 5 t ref if 0 t s 5 c e α t s t ref if t s 5 c where λ is the half life of nitrate fw and ft are the water content and temperature functions respectively eq 6 and 7 and c is the concentration of no3 n the water content function eq 6 depends on the actual soil moisture θ the saturated moisture content θs and an empirical constant b the temperature function eq 7 uses the actual temperature of the soil ts the reference temperature tref at which the half life was estimated and a constant α depending on ts tref the gas constant and the molar activation when the temperature is above the reference temperature the rate of decay increases for ol the temperature of water is assumed to be the same as the air while for the uz and sz the temperature was computed based on the air temperature using an empirical formula eq 8 klein 1995 cited in dhi 2017a 8 t s t sy 0 346 t air t sy e 2 7028 z where tsy is the average daily soil temperature from the day before tair is the average daily air temperature for the current day and z is the depth the adsorption was simulated by the freundlich isotherm where the c in eq 1 was expressed as 9 c k f c n where kf and n were calibrated with measured no3 n concentration from grab samples the nitrate nitrogen transport in the ol was modeled by a two dimensional reactive ade where decay was allowed source terms in this compartment included rainfall deposition and fertilizer inputs a one and three dimensional reactive ades were applied for the uz and the sz respectively both decay and adsorption processes were simulated in the porous media and the background concentration of no3 n for groundwater was used as the initial condition in the uz the plant uptake was represented as a sink term and was computed as a function of the plant transpiration plant s roots soil moisture and nitrate nitrogen concentration an empirical factor was used to include the root s filtering capabilities and a factor of 1 was used for nitrate nitrogen finally the transport of no3 n along the river was simulated with a one dimensional reactive ade including decay 2 2 2 model parameters and inputs for hydrologic module the parameters used in these equations were measured from the physical system the model input data for the model are climate data model domain topography physical parameters for the hydrologic processes simulated at watershed scale empirical parameters for the linear reservoir method simplifying plot scale drainage river topology and transport parameters the climate data are one of the most important inputs for the model rainfall is the main driver of all hydrologic processes from surface runoff to aquifer recharge while temperature solar radiation and wind speed affect evapotranspiration a main process in the water cycle daily values of precipitation temperature and reference evapotranspiration were required as station based inputs sixteen precipitation stations in the usrb and its neighboring watersheds and seven temperature stations were used noaa 2016 fig 1 as main climate inputs missing values from the time series were filled using the inverse distance weighting method reference evapotranspiration was estimated from solar radiation and temperature data by means of the modified makkink s equation de bruin and lablans 1998 following the procedure in botero acosta et al 2018 the model domain was discretized into 300 300 m grids to take into account the spatial variability of the physical parameters in the usrb a topographic map was created from the digital elevation model dem usgs 2016 the physical parameters to simulate the hydrologic processes occurring across the usrb derive from vegetation paved areas soil characterization and geology data a map of vegetation distribution for the usrb was created from the nass 2016 usda 2016 data layer and time series of leaf area index lai root depth and crop coefficient kc were defined for each vegetation type data for root depth and kc were obtained from the cropwat database fao 2016 the location of paved areas and the values of manning coefficient m for each land use type were entered as grids the water retention curves of the soil profiles defined by the nrcs official soil series descriptions nrcs 2016 were used to characterize the uz in the usrb as described in botero acosta et al 2018 the geological stratigraphy of the sz was conceptualized by a two layer system the henry ashmore layer and the glasford pearl layer following the methodology described by botero acosta et al 2018 the henry asmore layer is mainly composed of till sand and gravel from the henry formation and the ashmore tongue while the glasford pearl layer has till sand and gravel and silt and clay from the glasford and pearl formations maps of the lower level elevation of each geological layer horizontal and vertical hydraulic conductivities specific yield and the initial potential head were created and included in the sz model as the geologic units in the usrb were grouped into two main aquifer layers their hydraulic properties were adjusted to achieve the equivalent value that best represented the saturated zone behavior the initial water table depth was set to be 2 m below ground level bgl in accordance with a preliminary four year run botero acosta et al 2018 since no data is available that defines the actual locations of the tile drains in usrb they were placed in the model in accordance with the hydrologic group of the soils and the land use type sugg 2007 ssurgo database was used to identify cells with soils having slow and very slow infiltration rates i e soil hydrologic groups c d and dual soils a d b d and c d fifty eight percent of the usrb was found to have poorly drained soils after crossing soil and land use type data usda 2016 fifty two percent of the usrb area was found to be suitable for subsurface tile drainage installation the drainage was set at 1 m below ground level and the time constant was adjusted to 3 10 7 s 1 to match the measured streamflow at fisher monticello and decatur stations usgs 2017 a 30 30 m pixel resolution dem usgs 2016 was used to draw the river branches across the usrb four cross sections personal communication usgs were included in the main branch and five more at lake decatur isws 1987 2001 the manning coefficient n for the main branch bed and banks was set to 0 04 isws 1994 2 2 3 model parameters and inputs for sediment transport module the transport parameter values and the sources for both sediments and no3 n were specified in the model for each simulated compartment the modified universal soil loss equation musle williams and berndt 1977 sadeghi 2004 was used to simulate the erosion processes occurring at the surface of the watershed fig 2 that served as external source in term rc of the ade eq 1 in this method the value of sediment yield produced in a month y ton was computed as follows 10 y 11 8 q q p 0 56 k c p l s where q is the surface runoff volume accumulated in a month m3 qp is the peak runoff rate in a month m3 s k is the soil erodibility ls is the slope length c is the crop factor and p is the conservation practice daily maps of ol depth were extracted from the hydrologic model and monthly accumulated to create the surface runoff volume q maps to make the monthly maps of peak runoff rates qp the watershed was divided into 32 subwatersheds each one corresponding to a river branch the peak runoff rate qp for each month of simulation was then determined from the daily time series of ol flow rate and was linked to the subwatershed area of the corresponding branch the k factor map was created from the ssurgo database nrcs 2017 the k factor eq 10 accounts for the soil susceptibility to erosion which depends on the soil properties such as texture structure and permeability the distribution of k values in the usrb ranges from 0 05 to 0 49 these values correspond to poorly drained silty clay loams and silt loams soils found in the usrb isws 1996 the c factor map was created according to the land use types table 1 ward et al 2016 and their distribution across the watershed this factor accounted for the temporal variations of crops within a cyclical period of time for example a corn soybean rotation cell has one unique c factor that included the effects of both corn and soybean crops and was applied for all months of simulation the p factor was fixed to 1 0 since no strip cropping contouring and terraces were implemented in the usrb finally the ls factor map was computed from the digital elevation model dem and the methodology proposed by desmet and govers 1996 cited by luna 2016 the geographic information system gis tools flow accumulation and slope calculation were used along with eq 11 13 in computing the l portion of the ls factor as follows 11 m f 1 f 12 f sin β 0 0896 3 sin β 0 8 0 56 13 l a d 2 m 1 a m 1 x m d m 2 22 13 m where β and a are the slope and the flow accumulation values for each pixel respectively d is the pixel side size e g 300 m and x is the shape coefficient set to one for gridded systems the s portion of the ls factor was computed using eq 14 for slopes smaller than 9 mccool et al 1987 renard et al 1997 panagos et al 2015a which is the case for the entire usrb 14 s 10 8 sin β 0 03 the monthly sediment yield computed from musle was divided by the number of days in a month and was entered into the mike she model as daily source maps of mean step accumulated values in kg day a threshold concentration was used by the model to avoid unrealistic high species concentrations in the ol flow the species will precipitate if this concentration was exceeded and put back into motion if the concentration falls below the threshold this effect was considered in the source sink term of eq 1 this threshold will control the amount of eroded soil computed by the musle that was actually transported and reached the streamflow according to chinnasamy et al 2013 the sediment delivery ratio for the usrb ranges from 0 32 to 0 4 these values correspond to the ratio of the sediment delivered at the catchment outlet to on site erosion throughout the basin 2 2 4 model parameters and inputs for nitrate nitrogen transport module no3 n nonpoint sources for the water quality model were created based on the fertilizer application schedule for corn crops in illinois the most commonly used fertilizer in illinois is anhydrous ammonia nh3 which is injected at 25 cm depth and oxidizes to form nitrate that is highly soluble in water this process is called nitrification and is accomplished by soil bacteria nitrosomonas and nitrobacter the former oxidizes the ammonia to nitrite while the latter transforms the nitrite to nitrate both bacteria commonly found in soils require moderate soil water content and temperature to transform ammonia sources to nitrate within a few days of application ipni 2015a on the other hand warm and wet soils with high concentration of no3 will foster denitrification processes under anaerobic conditions and high carbon concentrations microbial activity will transform the nitrate to nitrogen gases which will be released to the atmosphere ipni 2015b daily maps of no3 n sources were created based on the application schedule of fertilizers in the usrb it was assumed that the nitrogen applied to corn crops either in the form of anhydrous ammonia or urea ammonium nitrate co nh2 2 nh4no3 would be converted to nitrate n which is highly soluble in water and then transported throughout the ol sz uz and rivers nitrogen application in the usrb vary from year to year depending on the producer s preferences three cases were identified to simulate this variation table 2 the iepa 2017 reported that approximately 207 kg ha of nitrogen was applied yearly in illinois corn crops either through fertilizer or manure the cases shown in table 2 provided a yearly application of 190 3 kg ha of n which followed the same order of magnitude as the reported one the fertilizer inputs for the baseline period were set in accordance with the information provided by the illinois fertilizer chemical association schaefer personal communication 2018 as follows from 1980 to 2008 case 1 was applied from 2009 to 2011 case 2 and from 2012 to 2015 case 3 the usrb is reported as one of the eight watersheds in illinois with the highest loading of nitrate n and phosphorus from point sources iepa 2017 available mean annual loads of nitrogen discharge for 9 facilities in the usrb epa 2017 ranging from 3 76 kg n year to 9300 kg n year were included as boundary conditions in the mike 11 model at the river branch closest to the facility location since the most common form of inorganic nitrogen in surface water is no3 n wall 2013 the reported loads were assumed to be in nitrate n form natural sources such as fixation of atmospheric nitrogen by bacteria soil organic matter and rainfall deposition generate a background no3 n concentration for groundwater systems the background concentration of nitrate is usually considered to be less than 3 mg l isws 1996 since 22 of nitrate mass corresponds to no3 n the initial no3 n concentration in the groundwater was set to 0 7 mg l inputs from rainfall were considered to be 0 3 mg l of no3 n in accordance with the data measured by the national atmospheric deposition program 2018 from 1979 to 2016 at the nearest station 17 km east of monticello long 88 3719 lat 40 0528 2 2 5 model calibration the flow parameters of the ol uz sz and river compartments in mike she and mike 11 are measurable in the field hence no calibration of these parameters should be needed given the physically based nature of the model nonetheless certain processes and simplifications such as drainage routing and geological layers conceptualization required the adjustment of a few parameters to ensure that the response of the system is well represented daily measured streamflow data usgs 2017 for the 1995 1999 period i and 2011 2015 period ii periods at three stream gauges fisher monticello and decatur fig 1 were used to calibrate and validate the performance of the model decatur s stream gauge station corresponding to the outlet of the usrb had a mean streamflow of 20 73 m3 s for the 1980 2015 period while monticello and fisher average streamflow were 13 81 m3 s and 6 31 m3 s respectively three metrics were implemented to assess the hydrologic module performance under the two periods the nash sutcliffe ns nash and sutcliffe 1970 was computed to evaluate the agreement between observed and simulated stream flow the percent bias pbias gupta et al 1999 estimated the error in the water balance and the pearson s correlation coefficient r was computed to assess the linear correlation between measured and simulated variables similar to flow the transport simulation was performed using physically based equations but certain simplifications and processes required the adjustment of some transport parameters this was the case for the sz layers equivalent transport parameters and the inclusion of processes not explicitly incorporated in the model such as denitrification and sediment trapping the performance of the transport model for sediment and no3 n was evaluated by comparing the simulated load with the observed load from grab samples observed grab sample measurements from 1980 to 1997 for fisher from 1996 to 2013 to monticello and from 1982 to 1997 for decatur were used for the calibration and validation of the transport model the mean observed load of suspended solids for the three stations were computed to be 61 5 ton d 140 4 ton d and 113 7 ton d for fisher monticello and decatur respectively for its part the mean observed no3 n load was 6 3 ton d for fisher 11 8 ton d for monticello and 13 1 ton d for decatur load represents the total mass of a pollutant reaching certain location per unit of time and it is commonly used to assess transport models li et al 2010 talebizadeh et al 2010 zhang and zhang 2011 strauch et al 2013 spieles and mitsch 2000 abbaspour et al 2007 the model efficiency metrics were computed using the simulated value against the grab sample taken on the same day the pbias and pearson correlation coefficient were computed to estimate the degree of over or underestimation of the model with respect to the observed data and the collinearity of the two datasets respectively two time periods denoted period i and period ii were considered for calibrating and validating the parameters the dates and length of these periods mainly depended on the availability of data number of grab samples 2 3 scenarios a scenario based analysis was designed to simulate the watershed responses to selected wmps and climate conditions two structural wmps constructed wetlands and grassed riparian buffers and three non structural wmps crop rotation cover crops and reduced tillage were selected according to the information collected from the stakeholders and experts in management practices in the usrb these wmps appeared to be the most feasible to be used by landowners or implemented as conservation practice by environmental agencies each of these wmps were analyzed under the current and future climate scenarios to identify the effects of climatic variations in the watershed hydrologic processes 2 3 1 wmps constructed wetlands storm water wetlands remove pollutants from overland runoff through vegetation filtering and settling processes wetlands are found to be long lasting pollutant removal facilities that can effectively work even 20 years after construction groh et al 2015 potential wetland restoration areas were identified as those with hydric soils not currently developed covered by water or forested hydric soils are characterized by being permanently or seasonally saturated according to the iepa 2007 most of the usrb is suitable for wetland construction results from the baseline were applied to locate the cells with large accumulation of ol water for this the accumulated ol depth for the 1980 2015 period was computed cells originally devoted to crop production or grass and with cumulative ol depth higher than 10 m for the 36 year period of the baseline were chosen as those suitable for wetland construction in accordance to this 3 4 921 cells of the total usrb was converted to wetlands were 61 of wetlands cells received drained water from 180 ha while 16 collected the water from 360 ha 10 from 540 ha and 5 from 720 ha the remaining 8 received water from 900 ha or more wetlands were conceptualized in the mike she model by modifying the manning number the detention storage the vegetation properties leaf area index lai crop coefficient kc and root depth and the c factor for the musle a manning m value of 1 6 n 0 6 was applied to wetlands cells tsihrintzis and madiedo 2000 and a detention storage of 60 cm was set in accordance to new jersey stormwater best management practices manual 2004 for a pond wetland the detention storage allows water to infiltrate and evaporate but limits the amount of water flowing over the surface when the depth of ponded water is less than the specified value the vegetation properties were set to those of herbaceous plants and since wetlands and other inland waters are not prone to soil erosion panagos et al 2015b their c factor was set to 0 grassed riparian buffers riparian buffers are areas next to the river with permanent vegetation that help stabilize soils and control pollutants mainly by reducing runoff flow rate and filtering sediments and nutrients iepa 2007 the installation of a grassed riparian buffers in the model were achieved in all cells along the streams buffer width was set to 300 m similar to that in botero acosta et al 2018 the vegetation properties the ol manning coefficient and the musle c factor were modified in order to include its effects in the model crop rotation agricultural practices and subsurface tile drainage are the most important aspects affecting nitrate nitrogen stream loads it has been reported that no3 n concentrations downstream from agricultural lands were nine times larger than the concentrations downstream of forested zones among the agricultural lands annual row crop lands had no3 n losses ranging from 30 to 50 times higher than those growing perennial crops randall and mulla 2001 however when proposing an alternative cropping system it is crucial to consider the producers acceptance which highly depends on the economic return of their investment considering the inputs from stakeholders meeting the nature conservancy 2017 2018 a two year corn soybean rotation was chosen to be implemented in continuous corn croplands this cropping system was included in the mike she model through the vegetation properties time series and into the transport model by the musle c factor and the fertilizer application schedule schaefer personal communication 2018 the first year of the two year rotation was allocated to soybean production with no fertilizer application while the second year had fertilizer inputs for corn crops in march 23th and april 15th of 157 kg of n ha and 50 kg of n ha respectively in this scenario all the corn crops approximately 40 of the total area were converted to corn soybean rotation cover crops one year rotation with cover crops was proposed as an alternative cropping system winter wheat serves as overwintering cover crop to prevent erosion add organic matter and scavenge excess nutrients if planted in september winter wheat can absorb 44 kg n ha by december sare 2012 winter wheat was included between regular growing seasons of row crops of either corn or soybean since it works well in reduced tillage systems sare 2012 no additional tillage from the one contemplated in the original row crop needed to be considered this wmp was implemented by modifying vegetation variables time series and the musle c factor reduced tillage conservation tillage requires at least 30 of residue cover from the previous crop to be retained iepa 2007 this land cover creates a preferential flow path through the unsaturated zone increasing infiltration and reducing runoff and sediment movement conventional tillage is usually used for corn crops in the usrb while soybean crops are managed with either conventional or reduced tillage iepa 2007 the baseline for the usrb was set to run with the manning for row crops chow 1959 for both soybean and corn cropland m 28 the effects of conservation tillage were represented in the mike she model through the ol manning number the detention storage and the musle c factor in accordance with the findings and recommendations by mohamoud 1992 a detention storage of 2 2 mm and a manning m of 7 7 n 0 13 were used for reduced till cells the musle c factor was set in accordance with table 1 the cover crops and reduce tillage wmps were applied where they were most influential the vulnerable areas for sediments and nutrients transport were selected by identifying the cells devoted to row crops with large stream power index spi values the spi is a secondary topographic index that estimates the erosive power of the water movement botero acosta et al 2017 it is computed as the natural logarithm of the product of the specific catchment area for each cell ac and the local slope s eq 15 15 spi l n a c s the spi for the usrb ranged from 9 3 to 20 8 cells with spi values equal or larger than the 50th percentile 3 4 and originally used for row crop production approximately 25 of the entire watershed area were chosen for the implementation of cover crop and reduced tillage wmps 2 3 2 future climate scenario the inclusion of climate as a natural stressor allows the study of the combined effects of wmps and climate on the systemic response of the usrb future climate data for the 2020 2055 period were extracted from the coupled model intercomparison project cmip coupled model intercomparision project cmip5 2017 an international program with the mission of simulating future climate and comparing existing climate models the representative concentration pathway 8 5 rcp 8 5 was chosen for the future climate scenarios since it has the highest greenhouse gas emissions caused by high population growth with technology and energy intensification riahi et al 2011 data from the 32 global circulation models from cmip5 were analyzed to determine the most critical climate scenario for usrb being an agricultural watershed precipitation is one of the most important climatological variables that drives agricultural activities hence it was used to identify the models having the driest and the wettest conditions for the 2020 2055 period the global circulation model with the highest total cumulative rainfall at decatur station for the 2020 2055 period and having the most similar climate for the historical analysis 1980 2005 p values from 0 77 to 0 91 for the kolmogorov smirnov ks and t tests for temperature and precipitation respectively was gfdl esm2g 1 rcp85 on the other hand the driest climate model in which the cumulative rainfall was predominantly lower than all the other models for the 2020 2055 period was access1 0 1 rcp85 p values from 0 36 to 0 97 for the ks and t tests for temperature and precipitation respectively both climate models were verified to be among the wettest and driest respectively at other locations across the watershed a polynomial regression analysis similar to botero acosta et al 2018 was conducted to obtain an expression to estimate the future daily reference evapotranspiration from temperature and precipitation at the usrb the historic climate 1980 2015 was found to have lower mean values of daily precipitation 2 75 mm temperature 11 95 c and reference evapotranspiration 2 64 mm d than the future scenarios gfdl esm2g 1 wet 2 92 mm 13 38 c and 2 96 mm d respectively and access1 0 1 dry 2 36 mm 14 69 c and 3 25 mm d respectively for the 2020 2055 period 3 results and discussion 3 1 model calibration and performance 3 1 1 hydrologic module to improve the agreement between the measured and simulated streamflow the equivalent hydraulic conductivities of the henry ashmore and the glasford pearl layers were adjusted as described in botero acosta et al 2018 on the other hand the drain time constant was set to 3 10 7 s 1 a value that agrees with the findings presented in zhou et al 2013 and the recommended range in the mike she manual 1 10 7 s 1 to 1 10 6 s 1 dhi 2017a the model was simulated for the two evaluation periods table 3 with a 2 year period to set up the initial conditions of the model a good agreement between observed and simulated daily streamflow was found where the ns for the three stations in both periods ranged from 0 54 to 0 72 the pbias from 2 2 to 8 5 and the correlation coefficients from 0 73 to 0 85 table 3 3 1 2 transport module the general transport parameters non species related such as porosity dispersion ol and dispersivities uz and sz were adjusted to improve model performance the porosity of both sz layers was set to 0 2 these layers were composed of till sand gravel and clay for which an equivalent porosity was adjusted the ol dispersion coefficient was set to 0 075 m2 s abbasi et al 2003 garcia navarro et al 2000 while the uz and sz dispersivities were set to 0 05 m and 10 m respectively values within the usual ranges used for these parameters forrer et al 1999 adams and gelhar 1992 neuman 1990 the product of the dispersivity and the flow velocity gives the dispersion coefficient for the uz and the sz compartments 3 1 2 1 sediments the sediment was defined in the model as a suspended species hence only the ol and the river compartment flows carried out its transport the yearly mass balance was used in order to check the total amount of sediments entering the river from the ol compartment the threshold concentration for the ol sediment concentration explained in section 2 2 1 2 was adjusted in order to get as close as possible to the reported yearly sediment load reaching lake decatur 200 000 ton year rhoads et al 2016 the adjusted value was found to be 1 104 kg m3 which produced approximately 30 of the total in site eroded soil computed at the grid scale to be transported to the river network however an examination of the daily ol concentration maps for sediments showed that approximately 95 of the grids manifesting sediment transport never reached this threshold experiencing concentrations of up to 2 103 kg m3 according to isws 1994 the sediments reaching lake decatur are predominantly clay which has very low settling rates in fresh water suthernland et al 2013 a conservative ade was applied to simulate the transport of cohesive sediments along the streams towards lake decatur once in the lake the source sink erosion deposition term was activated to include the lake s sediment trapping effects and the lakeshore bank erosion the sediment trap efficiency which represents the percentage of sediments held in the lake was reported to be 78 in 1983 isws 1987 the trap efficiency depends on the spillway height for example in 1956 the peak of sediment trap was reached due to the rise in the spillway height and hence the increase in the lake volume isws 1987 in addition to this sediment traps are being constructed since 2011 huffer 2016 city of decatur 2017 three traps located at the lake inlets capture the incoming sediment before it reaches the main body of the lake one of them treats 85 of the incoming water on the other hand isws 1987 reported that the lakeshore bank erosion was responsible of contributing 2 2 of the total yearly sediment deposited in the reservoir the main causes of this are the steep bluffs and the waves formed at the lake in order to simulate this effect in the sediment concentration at the outlet of the usrb the free settling velocity w the critical shear stresses for erosion τce and deposition τcd and the erodibility of the lake m were adjusted the settling velocity was found to be 2 10 5 m s which agreed with settling velocities for particles with diameters ranging from 0 001 mm to 0 07 mm range that includes clay and silt cheng 1997 a critical shear stress for deposition of 4 n m2 was found to reproduce the lake s sediment trapping effects as shown in the observed data and reported by isws 1987 the maximum bed shear stress at the lake was found to be 3 8 n m2 having a τcd approximately equal to this value allowed continuous sedimentation at the lake similar to borsje et al 2008 since the 1 τ τ cd factor in eq 3 represents the probability of deposition happening lumborg and vested 2008 having a large τcd signifies that the settling process is very likely to happen on the other hand the τce and the m were adjusted to 0 5 n m2 and 0 2 g m2 s respectively these values were in accordance with measurements from other studies on cohesive sediment erosion borsje et al 2008 and are within the typical ranges proposed in the mike 11 manual for these parameters dhi 2017b the sediment transport model performance was tested by comparing the simulated sediment load for the days with available data grab samples an example of this comparison is shown in fig 3 for period ii the observed mean load at the outlet of the usrb decatur was found to be 113 7 ton day which is 20 less than the load observed at the upstream station monticello 140 4 ton day the effect of sediment trapping of the lake and the recently installed sediment traps caused a load reduction at the outlet of the lake by contrast fisher presented a mean sediment load of 61 5 ton day less than half of the load observed at the following downstream station monticello the pbias for the simulated loads at the three stations in both periods showed very good agreement with the observed load 0 83 5 54 in absolute values except for fisher station during period i which presented an underestimation of 23 table 4 a pbias of up to 20 for sediment transport simulation is considered to be good and satisfactory up to 55 moriasi et al 2015 asabe 2017 additionally this station had a pearson s correlation coefficient of 0 88 and a pbias of 4 5 for the period ii table 4 the correlation coefficient for the three stations and two periods showed a good collinearity of observed and simulated values ranging from 0 65 to 0 88 3 1 2 2 nitrate n the dissolved nature of the no3 n allowed the transport to be simulated through the ol uz sz and rivers decay processes were included in all the watershed compartments while sorption was simulated in the uz and sz parameters of no3 n transport were adjusted to better reproduce the observed data the half life λ of the no3 n used in the decay reaction eq 5 was set to 1 2 years with a reference temperature tref of 20 c this value agreed with that of klein et al 2013 who stated that no3 n half life was approximately 500 days for zones where organic substances were present empirical parameters b and α used in the water content and temperature decay correction eq 6 and 7 were adjusted to 0 7 and 1 respectively the adsorption processes in the uz and the sz were simulated using the freundlich isotherm eq 9 where parameters kf and n were set to 8 10 10 m3 g and 0 78 respectively these values agreed with the ones used by hamdi et al 2013 for nitrate sorption in agricultural soils the initial sorbed concentration in the uz and the sz layers ranged from 3 10 6 g g to 2 10 5 g g model simulation results were compared with the observed no3 n load obtained from the grab samples at fisher monticello and decatur for periods i and ii table 4 an example of this comparison is shown in fig 4 for period ii the observed mean of no3 n load at decatur was found to be 13 1 ton day while fisher and monticello had 6 3 ton day and 11 8 ton day respectively the pbias in absolute values and the pearson s correlation coefficient ranged from 0 87 to 9 32 and 0 55 to 0 91 respectively showing a satisfactory behavior of the no3 n transport model table 4 fig 4 3 2 baseline the baseline model was simulated from 1980 to 2015 with a 2 year period to set up the initial conditions of the model the current land use in the usrb and the historic climate were used to set up the model the no3 n inputs were created as explained in section 2 2 1 1 from 1980 to 2008 case 1 table 2 was applied from 2009 to 2011 case 2 and from 2012 to 2015 case 3 sediment inputs were computed through the musle equation and the wm outputs section 2 2 1 2 results for the baseline at the three stations are presented in table 5 the mean values of streamflow sediment and no3 n loads at the outlet of the watershed decatur for the entire simulation period were found to be 20 7 m3 s 78 2 ton day and 14 ton day respectively the mass balance analysis revealed that more than 95 of the total cumulative no3 n reaching the streams during the simulated period came from the subsurface tile drainage flow this was also confirmed by panno et al 2008 who reported that nitrate transported to illinois river tributaries mainly comes from tile drained agricultural lands the sediment trapping effect of the lake is manifested in the reduction of sediment load between monticello and decatur the baseline model exhibited maximum and minimum monthly means at may and august respectively for the three studied variables fig 5 a b and c these results were highly related to the monthly rainfall trends of the historic climate and were expected given the relationship of rainfall with runoff drainage flow erosion and transport processes previous studies about the usrb water and nutrient s seasonal variation had also reported these trends for streamflow and nutrient load li et al 2010 isws 2000 3 3 environmental stressors the six selected wmps and the three climate cases were combined in order to study the usrb response to individual and combined environmental stressors a total of 18 scenarios were created including the baseline table 6 to simulate the impacts of climate wmps and climate wmps over the water quality in usrb graphs of monthly values figs 5 6 and 7 were created to analyze the seasonal trends and changes produced by the selected stressors at decatur the climate scenarios were applied by modifying the daily precipitation temperature and evapotranspiration while the wmps modifications were implemented as explained in section 2 3 1 the fertilizer application schedule and rates for the future climate scenarios were set in accordance with case 2 table 2 this schedule was chosen since case 2 is currently the most common application scheme in central illinois schaefer personal communication 2018 for the corn soybean rotation scenario the same fertilizer application schedule was used for both past and future scenarios 3 3 1 impacts of future climate scenarios an initial analysis of the climate impact on the sediment and no3 n load was achieved by comparing the results for the three climate cases under current wmps application scenarios 1 baseline 2 and 3 in table 6 in this way the effects of solely the climate can be identified since the wmp remained the same as in the baseline although the wet climate slightly increased the no3 n load for the months of january through may with respect to the baseline similar to the streamflow fig 5b the reduction of load for the rest of the months caused a general decrease in the mean load for the simulated period with reductions of up to 11 at the three stations a larger decrease was observed for the no3 n under the dry climate reaching load reductions by up to 74 this result was expected given the small amount of water available to drain to the streams fig 5a the effect of climate was observed to be more significant on the sediment load than the no3 n the general impact of the wettest climate was to increase the sediment load by up to 48 while the driest reduced it by up to 91 fig 5c shows the high impact of climate over the monthly mean sediment load following the monthly trend observed for the streamflow fig 5a the accentuated effect of climate over the sediment load compared to the no3 n is probably due to the nature of the sources for both species the sediment inputs to the model depended on the ol volume and the ol flow musle while the no3 n inputs were solely dependent upon anthropogenic activities with this in mind climate variables especially rainfall modified the sources and the transport processes for the sediments while the no3 n from applied fertilizer sources remained unchanged 3 3 2 impacts of wmps the impacts of wmps were assessed by comparing the sediment and no3 n loads of all the wmp scenarios under historic climate scenarios 1 baseline 4 7 10 13 and 16 in table 6 3 3 2 1 wetland construction by converting flooding prone local depressions to wetlands flow patterns were not altered significantly the 3 4 of the total area turned into wetlands cells did not significantly modify the streamflow but highly impacted the sediment load cells with high ol depth produced the largest sediment inputs on the baseline scenario converting those cells to wetlands caused load reductions from 12 to 40 at the three stations with the highest reductions occurring the months of march april and june fig 6c special attention was paid to an increase in the maximum sediment load at fisher 133 with respect to the baseline this value corresponded to an extreme event observed once during the simulated period on 13 04 1994 the day after the highest observed rainfall which reinforced erosion and transport processes being the smallest of the three sub watersheds and having the highest elevation change botero acosta et al 2018 fisher subwatershed might have limited ability to buffer extreme events the impacts of wetlands on no3 n were minimal given that no3 n is mostly transported through the subsurface drainage system fig 6a and b and storm water wetlands were not intercepting tile drained water 3 3 2 2 reduced till similar to the wetlands the reduced till scenario had very low impacts on the flow and the no3 n load relative changes of less than 1 were observed for the means of both variables at the three stations with respect to the baseline this effect was also manifested in the monthly average of these two variables fig 6a and b in mesoscale watersheds the runoff and flood mitigation effects of reduced tillage are triggered only by convective rainfall high intensity short duration events haag et al 2006 however in large scale basins like the usrb even convective rain will drive minor impacts on the runoff and flood patterns given their localized occurrence niehoff et al 2002 making reduced till effects hardly detectable over the streamflow on the other hand minor reductions of no3 n load were confirmed by daryanto et al 2017 who reported that conservational tillage practices by itself do not impact no3 n loss from cropland unless implemented along with other practices as cover crops or reduced fertilizer rates their findings indicated that the combined effects of no till practices over the no3 n concentration and the flow patterns may not affect the resulting no3 n load for example an increase in no3 n concentration in the runoff along with a proportional reduction of the amount of runoff water would not impact the total amount of no3 n being transported out of the cropland in contrast reduced till caused reductions of sediment load by up to 33 at the three stations erosion processes simulated by the musle were modified by the soil cover effect decreasing the sediment inputs to the transport model 3 3 2 3 grassed riparian buffer the grassed riparian buffer constructed on cells originally devoted to row crops caused the reduction of the streamflow by up to 14 with respect to the baseline mostly manifested during the wettest months april to june at decatur fig 6a this streamflow reduction was most likely produced by increases in evapotranspiration pasture s annual evapotranspiration is expected to be greater than that of row crops due to their longer growth duration and higher lai value at developed plant stage 33 larger the usda 2007 has reported grassed buffers to reduce nitrogen by 10 60 simulated reductions of no3 n load ranged from 16 to 20 at the three stations and were mainly caused by ol load reductions the mass balance of no3 n revealed a reduction of ol inputs to the river of 56 with respect to the baseline highlighting the importance of ol no3 n contributions along the riparian zone although drainage was the most common way of no3 n transport from inland farming areas to the river ol flow was found of main relevance along the riparian zone removing fertilizer application along the riparian zone had a strong impact in the amount of no3 n reaching the streams due to its proximity to water ways on the other hand reductions of sediment loads of 31 7 and 3 were observed at fisher monticello and decatur respectively pasture continuously covering the soil with no till practices resulted in the reduction of erosion along the riparian zone this effect was conceptualized in the model through the land cover factor c factor reduction from 0 4 for row crops to 0 005 for pastures a denser riparian buffer network in upland areas might have caused a greater sediment load reduction in fisher 3 3 2 4 crop rotation crop rotation had very little impacts on the streamflow manifesting reductions of approximately 4 at the three stations probably due to the increase in the evapotranspiration rate caused by a higher lai of soybean with respect to corn during the developed stage of the plant corn soybean rotation had the highest no3 n load reduction among all the wmps fig 6b due to the removal of fertilizer inputs for the soybean production year on 40 of the usrb however this scenario was the only one increasing the sediment load at the three stations by up to 22 soybean cropland have been reported to have higher soil losses than corn under conventional and no till methods while presenting very low impact in water flow patterns alberts et al 1985 this fact is explained by the plant dynamics and the way canopy developed through the first plant growth stages soil coverage around a corn plant is significantly better than that of a soybean plant alberts et al 1985 effect was introduced to the model through the c factor which increased by 5 for corn soybean rotation with respect to only corn scheme 3 3 2 5 cover crops the last wmp to be analyzed is the cover crops this scenario reported the highest reduction in streamflow up to 26 and sediment load up to 47 and the second highest for no3 n load up to 30 for the three stations the reductions occurred mostly during the wettest months march through may fig 6a b and c the water mass balance showed a reduction of approximately 20 for both tile drain and ol water contributions to the river which in turn decreased erosion rates by reducing the ol flow and depth changes in the lai root depth and kc time series when cover crops were implemented in approximately 25 of the usrb led to increase in evapotranspiration rate that caused the reduction in flow consequently this also led to a 23 increase in no3 n plant uptake from the baseline to gain better insight on the level of impacts of the wmps the ratio between the percentage of change in the mean streamflow and loads at decatur and the percentage of modified area was determined for each scenario higher ratio in absolute value would mean larger effects in the study variable with less area modified from the current state of the watershed to this end if two scenarios have the same percentage of pollutant load reduction the one with the least percentage of modified area would be considered more area efficient than the other one considering this approach the most area efficient wmps in reducing no3 n and sediments were the buffer and the wetlands respectively with changes of 12 and 3 4 of the total usrb area 3 3 3 impacts of wmps and future climate the combined effects of wmps and climate were analyzed through scenarios 1 baseline 5 6 8 9 11 12 14 15 17 and 18 table 6 the relative difference in the average streamflow sediment and no3 n loads were computed at the three stations and monthly averages were plotted to visualize seasonal trends fig 7 the monthly plots showed a shift of the streamflow sediment and no3 n load peaks from may towards march april for both future climates fig 7 in general terms wmps applied under the wet climate showed diverse responses over the study variables wetlands and reduced till wmps that barely affected the streamflow and the no3 n load under historic climate section 3 3 2 modified the average streamflow and no3 n load by up to 6 and 12 under wet climate respectively no3 n load reductions were also observed for the riparian buffer crop rotation and cover crops under the wet scenario 26 46 and 38 respectively being the crop rotation the wmp providing the highest reduction of no3 n under wet climate these overall reductions stemmed from substantial load reductions on the months of november and december fig 7b which coincided with months of drier conditions than the historic climate under wet climate the sediment reduction performance of all the alternative wmps was better than the current wmp case meaning that if a wet climate condition was to happen in the future the worst case of sediment loads would occur if the current state of the watershed is maintained the highest reductions of sediment load under the wet climate was achieved with cover crops the reductions denoted as a negative changes of sediment load for all the wmps except crop rotation were smaller as water flowed downstream sediment load changes under wet climate ranged from 36 to 59 at fisher from 15 and 47 at monticello and from 35 to 15 at decatur crop rotation for its part reported increases of sediment load at the three stations up to 43 at decatur with respect to the monthly values of sediment load under wet climate all wmps exhibited a peak in march and april fig 7c while significantly lower loads were observed from july through december almost as low as the ones observed under the dry climate fig 7f the dry climate reduced streamflow no3 n and sediment loads in the three stations by up to 78 90 and 98 respectively from the baseline under the dry climate the highest reduction for the three variables were always obtained for the cover crops however the substantial reduction caused by all wmps under the dry climate was mostly driven by the climate the reductions in the scenario with current wmp and dry climate scenario 3 in table 6 are 61 75 and 91 for streamflow no3 n and sediments respectively in this case an imminent drought would be the main problem 4 conclusion the simulation of nonpoint source pollution at a watershed scale through a physically based distributed model is a complex task due to the interactions among the compartments the physicochemical processes and the conceptualization of the nonpoint sources results from this study can be used as a tool for stakeholders and managerial agencies in the planning of short and long term recovery strategies for highly managed watershed the gains and trade offs of the selected wmps in terms of water quality and the foresight of climate change impacts over their performance will allow a better and more efficient use of the resources the simulation of the erosion process in mike she and mike 11 models facilitated the quantification of the effects of climate and wmps on sediment load in the waterways of usrb erosion processes were found to be localized occurring in the cells with high ol depth hence a wmp implementation in a reduced area 3 4 for wetlands was found to have relatively high reductions compared to other wmps altering a larger portion of the watershed incorporating the filtering effects of vegetation in the sediment transport model presented in this study would allow a better understanding of the effects of riparian buffers and wetlands over the sediment transport dynamics implementing cover crops resulted in the highest streamflow and sediment reduction with respect to the baseline for the three stations up to 25 and 47 respectively while the crop rotation scenario had the highest no3 n load reduction up to 40 although increasing the sediment load these performances were similarly observed for the future wet climate in accordance with the results of this study the most suitable wmps to apply in order to achieve the no3 n reduction goals proposed in the illinois nutrient loss strategy iepa 2017 15 by 2025 and 45 over time assuming the future wet climate condition would be the crop rotation or the cover crops with the risk of increasing stream sediment loads if crop rotation is implemented the wetlands and the riparian buffer were found to be the most area efficient wmp for sediments and no3 n load reduction respectively the buffer effect over the no3 n load was explained by the fact that inland agricultural lands transport no3 n to streams mainly through the drainage flow while the riparian zone no3 n inputs to the river stem primarily from the surface run off removing row crops entirely from the riparian zone would produce a considerable reduction in no3 n load with this in mind it is possible to affirm that non structural wmps caused the highest overall reductions of both pollutant loads but structural wmps were more area efficient the impact of wpms on stream pollutants load under dry climate scenarios was negligible a decrease of up to 78 in the average streamflow due to the reduction in ol and tile drainage flows was accompanied by an extreme load drop at the three control stations in this case nonpoint source pollution would not the main issue but water shortage the three wmp cases with the smallest streamflow reduction would be recommended for this climate condition current wmp reduced till or wetlands located using the methodology proposed in this study declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement funding for this research was provided by the national institute for food and agriculture nifa project illu 741 380 the authors would like to acknowledge the danish hydraulic institute dhi for providing the educational licenses of mike she and mike 11 
6027,a long term continuous and consistent pan evaporation epan reanalysis dataset will augment the analysis of epan distributions when the observation network is discontinuous or inconsistent and assist in the evaluation of the outputs of general circulation models gcms and land surface models lsms from the 1950s to early 2000s china had a continuous observation of the d20 pan but this was replaced by the 601b pan across china around 2002 and thus the epan observation network became discontinuous and inconsistent this study developed a long term monthly 0 05 continuous and consistent reanalysis dataset for both d20 and 601b pans covering mainland china throughout 1960 2014 based on meteorological data homogenization and interpolation and epan assimilation the penpan v3 model used in epan assimilation was successfully validated by observations at 767 and 591 stations for d20 and 601b pans respectively comprehensively considering the physical influence of elevation radiation wind speed humidity and air temperature the average annual and seasonal gridded epan reanalyses show significant spatial dependent on proximity to the ocean and latitude consistent with previous studies the reanalysis dataset can be used to analyze epan distributions across china including the areas without observations and to estimate the representativeness of epan to atmospheric evaporative demand the dataset has been released in two cloud servers in china and the united states and it will continue to be maintained and updated keywords pan evaporation reanalysis dataset long term continuous and consistent dataset representativeness to atmospheric evaporative demand 1 introduction pan evaporation epan is the rate of evaporation from a pan and it is measured by the change in the level of its free water surface epan has become an important physical indicator to gauge atmospheric evaporative demand since it integrates all the effects of climate variables on terrestrial evapotranspiration thus observation networks of epan have been established and maintained across the globe peterson et al 1995 roderick et al 2009a 2009b lim et al 2016 the networks are widely used for practical applications in crop irrigation scheduling and water resources management and for global climate change analysis in evaluating the outputs of general circulation models gcms and land surface models lsms rotstayn et al 2006 liu and sun 2016 and in explaining the reasons for global evaporation paradox brutsaert and parlange 1998 roderick and farquhar 2002 however within the global epan observation network observed epan in china is discontinuous and inconsistent due primarily to the use of a different type of evaporimeter the d20 pan fig 1 b and its subsequent replacement by the 601b pan fig 1 c from the 1950s to early 2000s china had continuous observations of the d20 pan while it was replaced by the 601b pan across china around 2002 the 601b pan is not working when the inside water is frozen mainly in the winter months in northern china to measure the ice sublimation where or when the 601b pan is not working due to water freezing the d20 pan would be reused by meteorological stations the nationwide evaporimeter replacement and the d20 pan each year reuse in some regions or months make it difficult to apply epan observations from china in estimating long term trends in atmospheric evaporative demand wang et al 2012 brutsaert 2013 li et al 2013 as a consequence a robust data assimilation method capable of estimating missing epan measurements is being explored the us class a pan is the first type of evaporation pan to have robust epan assimilation methods that can simulate the physical processes of a pan i e the vapor transfer process between the water surface and atmosphere the heat transfer process in boundary layers and the radiation exchange processes on the water body and the pan wall lim et al 2013 wang et al 2018 the development of epan assimilation methods for us class a pans relies on a penman style model proposed by thom et al 1981 the penpan model derived by linacre 1994 and a penman monteith style model developed by pereira et al 1995 rotstayn et al 2006 combined the radiative component of penpan model and the aerodynamic component of thom et al 1981 to develop the penpan model note the two capital ps to differentiate it from linacre s 1994 penpan by contrast epan from the chinese d20 pan was not widely assimilated until yang and yang 2012 parameterized the penpan model while the corresponding method for the 601b pan was not available until recently though the above models have been widely applied they use empirical functions to estimate the vapor transfer process and cannot distinguish the effect of the pan wall on the radiation balance of the water in the pan and the turbulence structure over it which will increase epan beyond that of a free water surface the pan wall affects epan through the radiation absorption from the atmosphere and the surrounding environment and through heat conduction between the pan wall and the water body wang et al 2019a to simulate the vapor transfer and radiation processes of the water body and the pan wall fully physical models further versions of the penpan model were developed recently lim et al 2016 wang et al 2018 lim et al 2016 derived the penpan v2 model for the us class a pan and successfully applied in australia epan simulations wang et al 2018 derived the penpan v3 model and showed good performance in epan simulations of d20 and 601b pans in china in addition to using the new penpan v3 model using as inputs homogenized meteorological driven data is essential to ensure the quality of epan assimilation in china that said the available meteorological observations provided by the china meteorological administration cma remain non homogenized xu et al 2013 sun et al 2016 since long term climate data have been adversely affected by some non climatic factors for example changes in instrumentation station moves changes in the local environment or the introduction of different observing practices peterson et al 1998 to diminish these non climatic influences and develop a continuous and consistent long term gridded epan reanalysis dataset for d20 and 601b pans in china this study used the rhtestsv4 and anuspline software which are widely used by cma xu et al 2013 sun et al 2016 for homogenization and interpolation respectively the publicly available homogenization software rhtestsv4 wang et al 2007 wang 2008 was used to test the homogeneity of climate data and to homogenize the series of different climate data whenever necessary for each meteorological station the homogenized station data were interpolated to 0 05 0 05 gridded data using anuspline software hutchinson and xu 2013 by inputting the homogenized gridded climate data into penpan v3 model we developed a long term continuous and consistent gridded epan reanalysis dataset for d20 and 601b pans in china the reanalysis dataset covers the mainland china at a monthly time step and a spatial resolution of 0 05 spanning from 1960 to 2014 and it is freely available from two online cloud servers in china and the united states the dataset could benefit the water resources planning and management in china benefit the evaluation of the outputs of gcms and lsms and benefit the prediction of long term atmospheric evaporative demand in china rotstayn et al 2006 roderick et al 2009a 2009b wang et al 2012 mcvicar et al 2012 liu and sun 2016 wang et al 2017 2019a 2 data and methods 2 1 climatic and radiative data continuous daily climatic and radiative data for 1960 2014 were collected from existing cma digital records the climatic data include wind speed u maximum and minimum air temperature ta sunshine duration ssd relative humidity rh and epan of d20 and 601b pans from 824 meteorological stations the radiative data are global solar irradiance sg observations at 130 radiation stations represented by red crosses in fig 1 a all the daily data were calculated to monthly data based on roderick et al 2007 which calculated the monthly means of data only when a minimum of 25 days was available and excluded those months that did not meet this condition 767 stations for d20 pans and 591 stations for 601b pans in fig 1 a had near continuous records of epan during 1960 2014 and hence these stations were used to interpolate parameters in the aerodynamic function details in section 2 3 and to evaluate the penpan v3 model see section 3 1 most long term climatological time series are affected by several non climatic factors that make these data unrepresentative of the actual climate variation occurring over time peterson et al 1998 these factors include changes in instruments station locations observing practices formulae used to calculate means and station environment these factors are usually recorded in the metadata for each station however for most stations in this study metadata are incomplete or inaccessible for common users to diminish these non climatic influences thus we employ the publicly available homogenization software rhtestsv4 wang et al 2007 wang 2008 which has been widely used by cma for climate data homogenization xu et al 2013 sun et al 2016 since it is a robust statistical method to detect shifts in climate data series and to estimate the magnitude of shifts in this study we selected the penalized maximal f test algorithm in rhtestsv4 wang 2008 which is recommended when lack of the metadata to test the homogeneity of monthly climate data and to homogenize the series of different climate data whenever necessary 2 2 penpan v3 model the latest version of the penpan model penpan v3 wang et al 2018 is used to derive a long term continuous and consistent epan reanalysis dataset for two chinese pan types the penpan v3 model is based on a steady state energy balance assumption which for a d20 or 601b pan requires periods of at least a week so the applications described later use monthly input data consistent with previous versions of penpan model rotstayn et al 2006 lim et al 2016 in penpan v3 model epan m s is written as the sum of radiative epan r m s and aerodynamic epan a m s components 1 e pan s s β γ r n λ ρ w e pan r β γ s β γ v p d f v e pan a where s pa k is the slope of the saturation vapor pressure versus temperature curve at the air temperature two meters above the ground γ pa k is the psychrometric constant λ j kg is the latent heat of vaporization of liquid water β is the ratio of heat to mass transfer coefficient of the pan ρw kg m3 is the density of liquid water 1000 vpd pa is the vapor pressure deficit at 2 m fv m s pa is the aerodynamic function and rn w m2 is the net irradiance of a pan as a physical model fv is different from the function of wind speed used in previous evaporation simulations e g penman 1948 allen et al 1998 rotstayn et al 2006 which are empirical without physical meaning mcmahon et al 2013 based on the boundary layer theory lim et al 2012 derived fv and integrated it in the penpan v2 model 2 f v m w r ρ w t a d v ρ a n u 2 l η a q l where mw kg mol is the molecular mass of water 0 018 r j mol k is the ideal gas constant 8 314 dv m2 s is the diffusion coefficient for water vapor in air u2 m s is the wind speed at 2 m ρa kg m3 is the density of air ηa kg m s is the dynamic viscosity of air l m is the characteristic length of the evaporating surface n is the dimensionless site dependent parameter range 0 1 0 and q is the dimensionless site dependent parameter range 1 0 0 the calculation methods for parameters in eqs 1 and 2 are recorded in wang et al 2018 to examine the physical processes of the different parts of a pan wang et al 2019a divided epan into two components the evaporation determined by processes occurring on surfaces of the water body epan wb and the pan wall epan pw respectively epan wb consists of epan a and the evaporation affected by heat transfer and radiation processes occurring on the water surface epan w epan pw consists of the evaporation affected by heat transfer and radiation processes occurring on the outside pan rim epan rim inside pan rim epan rim side wall epan wall and pan bottom epan bot respectively the explanation and discussion of these components are introduced in wang et al 2019a eq 1 can be modified as 3 e pan β γ s β γ v p d f v s s β γ r n w λ ρ w e pan w b s s β γ r n r i m r n r i m r n w a l l r n b o t λ ρ w e pan p w e pan a e pan w e pan w b e pan r i m e pan r i m e pan w a l l e pan b o t e pan p w where rn w rn rim rn rim rn wall and rn bot w m2 are the net irradiance of the pan water surface outside rim inside rim side wall and bottom respectively and they are influenced by the pan geometry the effective areas albedo and emissivity to different irradiance ta rh and sg w m2 we collected sg observations from 130 radiation stations but these observations cannot be used to derive a reliable gridded dataset across china due to their small number instead we used ssd observations from 824 meteorological stations and the angstrom formula eq 4 to estimate sg in 824 locations 4 s g a s b s ssd n r a where n hour is the maximum possible duration of sunshine or daylight hours ra mj m2day is the extraterrestrial radiation and as and bs are regression constants only ssd and sg data from 1993 to 2014 are used to optimize as and bs as the sg observations were inconsistent owing to instrument replacement around 1993 yang et al 2015 the comparison between sg observations and simulations in fig 2 b indicates that sg simulations using our angstrom parameterization agreed well with observations the percent bias pbias nash sutcliffe efficiency nse and root mean square error rmse were 8 7 0 94 and 23 4 w m2 respectively 2 3 process of generating the gridded reanalysis dataset first ssd and sg at 130 stations during 1993 2014 were used in angstrom formula to optimize parameters as and bs second u2 rh ta max and min and epan at 767 and 591 stations were used in dalton relationship to optimize parameter n and q in fv for d20 and 601b pans see section 3 2 in wang et al 2018 respectively third ssd u2 rh and ta max and min at 824 stations were ingested into rhtestsv4 software wang et al 2007 wang 2008 to test the homogeneity and then to homogenize the monthly series if necessary taking the rh data as an example fig 2 c shows a sharp decrease of observed non homogenized annual rh presumably caused by the nationwide replacement of rh automated instruments around 2003 wang et al 2019a after homogenization the inhomogeneity around 2003 was diminished for homogenized annual rh then ssd u2 rh and ta max and min at 824 stations as and bs at 130 stations and n and q at 767 and 591 stations for d20 and 601b pans were inputted into anuspline software hutchinson and xu 2013 to interpolate 0 05 0 05 gridded data the gridded data and dem were inputted in penpan v3 model to calculate epan epan a epan r epan w epan rim epan rim epan wall and epan bot finally 0 05 0 05 gridded epan epan wb and epan pw for d20 and 601b pans during 1960 2014 were exported and released as the long term reanalysis dataset two things need to be noted here first the values of as and bs gradually varied in a year thus as and bs were separately optimized for each month i e the gridded as and bs data have 12 different spatial distributions second choosing different covariates in anuspline software may cause uncertainties in the interpolated results other potential uncertainties were discussed in section 4 3 2 4 dataset access the long term epan reanalysis dataset for two chinese pan types was released in two cloud servers in china and the united states users can download the instruction stored in china cloud server from https kaiwenwang 1257660865 cos ap beijing myqcloud com readme pdf and in the united states cloud server from https geohydro 1257660865 cos na siliconvalley myqcloud com readme pdf the dataset will continue to be maintained and updated and it will be available to every research community interested in the dataset 3 results 3 1 evaluation of the penpan v3 model we evaluated the penpan v3 model by comparing epan of two chinese pan types simulated by the model with the observations at different stations in the comparison the penpan v3 model was driven by non homogenized climatic observations rather than the homogenized climate data as a station s epan record may suffer from station relocation inhomogeneity problems and it may in fact represent epan from several locations however once epan simulations use homogenized climate data the simulations will only represent epan from a fixed location since the homogenization can solve the station relocation inhomogeneity problem therefore to evaluate the penpan v3 model epan observations were compared with epan simulations driven by observed non homogenized climate data fig 3 fig 3 a and b illustrate that epan simulated by penpan v3 model agrees well with the observations and pbias values of d20 and 601b pans are 8 15 and 1 1 nse values are 0 93 and 0 88 and rmse values are 22 5 and 16 0 mm month fig 3 c shows that for d20 pans at 767 stations the 25th 50th and 75th percentiles of pbias are 14 9 and 5 respectively the 25th 50th and 75th percentiles of nse are 0 85 0 90 and 0 94 respectively the 25th 50th and 75th percentiles of rmse are 17 22 and 25 mm month respectively for 601b pans at 591 stations the 25th 50th and 75th percentiles of pbias are 4 1 and 2 respectively the 25th 50th and 75th percentiles of nse are 0 75 0 83 and 0 87 respectively the 25th 50th and 75th percentiles of rmse are 12 14 and 16 mm month respectively the observed and simulated average monthly epan are shown in fig 3 d for d20 pans and in fig 3 e for 601b pans as d20 pans were replaced by 601b pans around 2002 across china epan observations before and after 2002 were separately denoted by two different colors fig 3 d shows that different from epan simulations average monthly epan observations suddenly decrease after 2002 due to the reduction of stations for d20 pan observations this finding explains the 2002 sharp change of average annual pan coefficient in china reported by wang et al 2019b for 601b pans epan cannot be measured when the water freezes and hence some stations in northern china do not have 601b epan observations in winter in fig 3 e the average monthly epan observations in winter are the average of stations where no icing happens while the epan simulations are the average of all the stations since stations where icing happens are set to 0 in penpan v3 model consequently fig 3 e shows that simulated average monthly epan in winter is lower than observations which bias upwards and towards warmer months 3 2 distributions of the gridded epan reanalysis dataset 3 2 1 spatial distributions of annual and seasonal epan the spatial distributions of average annual epan in fig 4 a and a show a strong spatial gradient although the spatial patterns of d20 and 601b pans are different for d20 pans the average annual epan varies from 600 to 2500 mm with higher values in the northwest of china which is mainly caused by the high wind speed and vapor pressure deficit and with lower values in the northeast of china and the source region of the yangtze and yellow river for 601b pans the average annual epan varies from 450 to 1250 mm with higher values in the northwest of china and the west of the tibetan plateau and with lower values in the northeast of china and the middle and lower reaches of the yangtze river a year is divided into spring march to may summer june to august autumn september to november and winter december to february to analyze seasonal epan distributions of d20 and 601b pans in spring the average epan varies from 150 to 720 mm and from 120 to 370 mm for d20 and 601b pans respectively and epan spatial patterns are similar to the average annual epan in summer the average epan varies from 160 to 1250 mm and from 180 to 570 mm for d20 and 601b pans respectively with the highest values in the northwest and north of china for both pans in autumn the average epan varies from 110 to 550 mm and from 50 to 310 mm for d20 and 601b pans respectively the northwest and south of china have the highest values for d20 pans the west of the tibetan plateau and south of china have the highest values for 601b pans in winter the average epan gradually decreases from south to north and shows distinct latitude belt distribution characteristics 3 2 2 the impacts of the pan wall on epan dynamics epan has been widely measured and recorded in agricultural hydrological and meteorological stations for estimating the open water evaporation eow and atmospheric evaporative demand fu et al 2004 ideally epan should be completely contributed by the water body and the ratio eow epan would be as close as possible to 1 however the pan wall affects the radiation balance of the water in the pan and the turbulence structure over it which increases epan beyond that of a free water surface if the pan wall absorbs and conducts more heat for vaporizing than water body in a pan epan may reflect the heat absorbing and conduction ability of the pan wall rather than eow wang et al 2019a we distinguish the impacts of the pan wall on epan dynamics and examine to what extent epan deviates from eow by calculating the ratios epan w epan of d20 and 601b pans the ratio epan w epan in fig 5 increases from the southeast to the northwest and the northeast of china and sichuan basin have small ratios the ratios vary from 37 to 76 and 87 5 to 94 5 for d20 and 601b pans respectively the small ratio of the d20 pan indicates that a d20 pan observed epan deviates much from eow and it is more affected by the pan wall than a 601b pan that is the reason china replaced d20 pans with 601b pans nationwide 4 discussion 4 1 comparisons of epan distributions the epan observation network and its interpolation are usually used to analyze epan distributions china built the epan observation network based on the d20 pan which was continuously observed from the 1950 s to early 2000 s but was replaced by the 601b pan around 2002 for the d20 pans observations are used to analyze epan distributions before the 2000 s e g cong et al 2009 liu et al 2004 while epan simulated by penpan style models is used to analyze epan distributions after the 2000 s due to the discontinuous observations e g liu et al 2011 yang and yang 2012 li et al 2013 liu and sun 2016 for the 601b pans observations are used to analyze epan distributions after the 2000 s e g wang et al 2018 and epan simulations are used to analyze epan distributions before 2000 s e g xiong et al 2012 wang et al 2018 epan observations are interpolated to analyze the continuous spatial distributions across china since observations only represent epan at the stations the spatial patterns of the interpolated annual epan changing from the coast towards inland and lower latitudes towards higher latitudes reported by zuo et al 2005 xiong et al 2012 and li et al 2016 are consistent with the spatial distributions in fig 4 a and a based on the interpolation of observed epan at 573 stations in china li et al 2016 reported that the average annual epan varied from 500 to 2100 mm and from 315 to 1300 mm for d20 and 601b pans respectively which are close to the ranges of our reanalysis dataset however the interpolation of observed epan cannot reflect the integrated influence of natural and climatic variables on epan especially the influence of elevation inputting dem and gridded climate data interpolated by the anuspline software into the state of art penpan v3 model our reanalysis dataset comprehensively considers the physical influence of elevation radiation and different climatic variables on epan additionally how well epan represents atmospheric evaporative demand can be estimated by the reanalysis dataset based on the ratio of epan w to epan the distribution of epan w epan fig 5 illustrates that the representativeness of epan to atmospheric evaporative demand decreases from coast to inland and from lower latitudes to higher latitudes in china because epan and potential evapotranspiration e g reference crop evapotranspiration are both considered as the physical indicator of the atmospheric evaporative demand we compare the spatial distributions of annual and seasonal potential evapotranspiration in some studies with the reanalysis dataset note the following comparisons mainly focus on the spatial patterns rather than the values fan et al 2016 calculated the seasonal distribution patterns of reference crop evapotranspiration in china during 1956 2015 the distribution patterns of reference crop evapotranspiration were consistent with the spatial patterns in fig 4 including the low values in the yangtze river basin in spring the high values in the northwest of china in spring and summer the low values in the southeast of china in summer and the distinct latitude belt distribution characteristics in winter the reanalysis dataset also shows the same spatial patterns with seasonal potential evapotranspiration distributions in some regional studies e g the spatial distributions in the yangtze river basin xu et al 2006 the yellow river basin she et al 2017 the southwest of china sun et al 2017 and the tibetan plateau zhang et al 2007 the above comparisons with different studies show that the distributions of potential evapotranspiration are more similar to epan distributions of the 601b pans than the d20 pans since the d20 pan is adversely affected by the pan wall fu et al 2004 wang et al 2019a owing to tremendous differences in latitude longitude and altitude the climate of china is extremely diverse and the reasons for the epan spatial differentiation are complex therefore more regional studies need to be conducted in the future to validate and improve the reanalysis dataset 4 2 a case study using the reanalysis dataset we choose the haihe river basin as a case study and compare epan observations of d20 pans at 32 meteorological stations with the reanalysis dataset located in northern china the haihe river basin fig 6 a is one of the most developed areas in china including the two megacities of beijing and tianjin climatically the haihe river basin belongs to the east asian monsoon region the annual precipitation and evaporation are about 539 and 470 mm respectively the annual mean temperature varies from 8 to 12 c and the average relative humidity varies from 50 to 70 because of the nationwide evaporimeter replacement the number of stations with epan observations suddenly decreases from over 27 stations to less than 18 stations after 2002 fig 6 b due to the reduction of stations average annual epan in fig 6 b sharply decreases after 2002 in contrast average annual epan calculated by the reanalysis dataset changes smoothly without a sudden decrease fig 6 c additionally the average annual epan calculated by observations represents the average value of these stations rather than the entire basin and it ranges between 1400 and 2200 mm however the gridded epan of the reanalysis dataset covers the entire basin and the average annual epan calculated by the dataset ranges between 1000 and 1500 mm 4 3 uncertainties of the reanalysis dataset the derivation of the long term epan reanalysis dataset is complex with a variety of meteorological input data which inevitably imparts several uncertainties in the present version of the reanalysis dataset first all the climate data were homogenized using the penalized maximal f test algorithm in the rhtestsv4 software and the homogenization results were not verified by any reference series the rhtestsv4 software has two algorithms to homogenize climate data namely the penalized maximal t test and f test the penalized maximal t test is recommended by rhtestsv4 since it uses the reference series obtained from the metadata to verify and improve the homogenization results however the penalized maximal t test is not used in this study as the metadata of most stations are incomplete or inaccessible for common users and we cannot create reliable reference series for most of the stations though the penalized maximal f test can identify most of the inhomogeneity problems xu et al 2013 wang 2008 some inhomogeneity problems may still exist to improve the quality of the epan reanalysis dataset in the future we will cooperate with cma to obtain detailed metadata and use the penalized maximal t test for climate data homogenization second we cannot execute the missing station analysis for all the interpolated data in fig 2 a in these types of analyses interpolated outputs are generally evaluated by removing a station from the input time series hence missing and the interpolated outputs at the missing station coordinates are compared with the observations however as shown in fig 2 a all the interpolated data have been homogenized before interpolation the homogenized data do not have the station relocation inhomogeneity problem and so the interpolated data do not have this problem either that said we cannot compare the interpolated data with observations since observations have the station relocation inhomogeneity problem while the interpolated data do not therefore we cannot execute the missing station analysis for the interpolated data in fig 2 a third penpan style models rotstayn et al 2006 lim et al 2016 wang et al 2018 cannot simulate ice sublimation the water in a pan freezes when ta descends below 0 c the d20 pan is small and it can be weighed to measure the ice sublimation when the water freezes thus the monthly epan observations in fig 3 a and d include ice sublimation which mainly happens in the winter at high latitudes the good simulation results in fig 3 a indicate that ignoring ice sublimation in d20 pans does not generate significant simulation error in china to extend the penpan style models to epan simulations in high latitudes the ice sublimation process needs to be formulated in the future fourth the gridded as and bs parameters in this study were interpolated based on their values at 130 stations according to the angstrom formula eq 4 as and bs optimization at a station requires both sg and ssd observations in this study we obtained sg data at 130 stations and as a consequence we only had as and bs values at 130 stations for interpolation introducing some radiative data observed by individuals or using some reliable radiative products can be tried in the future to improve the quality of the reanalysis dataset 5 conclusion this study developed a long term monthly 0 05 continuous and consistent reanalysis dataset for d20 and 601b pans covering mainland china throughout 1960 2014 the penpan v3 model used in generating the dataset was validated by epan observations at 767 and 591 stations for d20 and 601b pans respectively the epan simulations agreed well with the observations and the values of pbias nse and rmse were 8 15 1 1 0 93 0 88 and 22 5 16 0 mm month for d20 pans 601b pans comprehensively considering the physical influence of elevation radiation and different climatic variables the average annual and seasonal epan distributions of the reanalysis dataset are consistent with previous researches based on the epan observation network the reanalysis dataset provides opportunities to expand applications of epan first we can use the gridded dataset to analyze epan distributions across china including the areas without epan observations second the reanalysis dataset enables us to research long term epan distributions even though the observation network is discontinuous from the 1950s to early 2000s china had continuous observations of the d20 pans which were replaced by the 601b pans around 2002 as this reanalysis dataset spans from 1950 to 2014 it can be used to estimate epan from d20 pans after 2002 and to estimate epan from 601b pans before 2002 third the reanalysis dataset can distinguish the impacts of the pan wall on epan dynamics and thus we can use it to estimate how well epan represents atmospheric evaporative demand the dataset indicates the representativeness decreases from coast to inland and from lower latitudes to higher latitudes in china and that d20 pans are more affected by the pan wall than 601b pans fourth since epan integrates all the effects of climate variables such as ta rh rn and u2 on terrestrial evapotranspiration the reanalysis dataset may benefit the evaluation of the outputs from gcms and lsms the derivation of the reanalysis dataset is complex and uses a variety of meteorological data hence the present version of the reanalysis dataset may unavoidably incur several uncertainties some of which may be resolved in the future by obtaining more metadata and using the penalized maximal t test for climate data homogenization formulating the ice sublimation process for epan simulations in high latitudes and using more reliable radiative data to improve the quality of the dataset the long term epan reanalysis dataset for two chinese pan types has been released in two cloud servers in china and the united states and it will continue to be maintained and updated declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national key r d program of china nos 2018yfa0605404 2017yfc0506603 and 2016yfc0401305 the general program of national natural science foundation of china nos 51679007 and 51379013 and the state key program of national natural science of china no 41530635 this research benefited from the climatic data provided by the china meteorological data sharing service system http data cma cn data cdcindex cid 6d1b5efbdcbf9a58 html the long term pan evaporation reanalysis dataset for two chinese pan types can be downloaded following the instruction from https kaiwenwang 1257660865 cos ap beijing myqcloud com readme pdf or https geohydro 1257660865 cos na siliconvalley myqcloud com readme pdf the rhtestsv4 package used for homogenization which was downloaded from the expert team on climate change detection and indices etccdi website http etccdi pacifcclimate org software shtml with the help of dr xiaolan wang and yang feng kaiwen wang wishes to thank all the rainy days of the emerald city all of the authors acknowledge editor marco borga associate editor shengping wang and two anonymous reviewers for their invaluable comments and constructive suggestions for this research 
6027,a long term continuous and consistent pan evaporation epan reanalysis dataset will augment the analysis of epan distributions when the observation network is discontinuous or inconsistent and assist in the evaluation of the outputs of general circulation models gcms and land surface models lsms from the 1950s to early 2000s china had a continuous observation of the d20 pan but this was replaced by the 601b pan across china around 2002 and thus the epan observation network became discontinuous and inconsistent this study developed a long term monthly 0 05 continuous and consistent reanalysis dataset for both d20 and 601b pans covering mainland china throughout 1960 2014 based on meteorological data homogenization and interpolation and epan assimilation the penpan v3 model used in epan assimilation was successfully validated by observations at 767 and 591 stations for d20 and 601b pans respectively comprehensively considering the physical influence of elevation radiation wind speed humidity and air temperature the average annual and seasonal gridded epan reanalyses show significant spatial dependent on proximity to the ocean and latitude consistent with previous studies the reanalysis dataset can be used to analyze epan distributions across china including the areas without observations and to estimate the representativeness of epan to atmospheric evaporative demand the dataset has been released in two cloud servers in china and the united states and it will continue to be maintained and updated keywords pan evaporation reanalysis dataset long term continuous and consistent dataset representativeness to atmospheric evaporative demand 1 introduction pan evaporation epan is the rate of evaporation from a pan and it is measured by the change in the level of its free water surface epan has become an important physical indicator to gauge atmospheric evaporative demand since it integrates all the effects of climate variables on terrestrial evapotranspiration thus observation networks of epan have been established and maintained across the globe peterson et al 1995 roderick et al 2009a 2009b lim et al 2016 the networks are widely used for practical applications in crop irrigation scheduling and water resources management and for global climate change analysis in evaluating the outputs of general circulation models gcms and land surface models lsms rotstayn et al 2006 liu and sun 2016 and in explaining the reasons for global evaporation paradox brutsaert and parlange 1998 roderick and farquhar 2002 however within the global epan observation network observed epan in china is discontinuous and inconsistent due primarily to the use of a different type of evaporimeter the d20 pan fig 1 b and its subsequent replacement by the 601b pan fig 1 c from the 1950s to early 2000s china had continuous observations of the d20 pan while it was replaced by the 601b pan across china around 2002 the 601b pan is not working when the inside water is frozen mainly in the winter months in northern china to measure the ice sublimation where or when the 601b pan is not working due to water freezing the d20 pan would be reused by meteorological stations the nationwide evaporimeter replacement and the d20 pan each year reuse in some regions or months make it difficult to apply epan observations from china in estimating long term trends in atmospheric evaporative demand wang et al 2012 brutsaert 2013 li et al 2013 as a consequence a robust data assimilation method capable of estimating missing epan measurements is being explored the us class a pan is the first type of evaporation pan to have robust epan assimilation methods that can simulate the physical processes of a pan i e the vapor transfer process between the water surface and atmosphere the heat transfer process in boundary layers and the radiation exchange processes on the water body and the pan wall lim et al 2013 wang et al 2018 the development of epan assimilation methods for us class a pans relies on a penman style model proposed by thom et al 1981 the penpan model derived by linacre 1994 and a penman monteith style model developed by pereira et al 1995 rotstayn et al 2006 combined the radiative component of penpan model and the aerodynamic component of thom et al 1981 to develop the penpan model note the two capital ps to differentiate it from linacre s 1994 penpan by contrast epan from the chinese d20 pan was not widely assimilated until yang and yang 2012 parameterized the penpan model while the corresponding method for the 601b pan was not available until recently though the above models have been widely applied they use empirical functions to estimate the vapor transfer process and cannot distinguish the effect of the pan wall on the radiation balance of the water in the pan and the turbulence structure over it which will increase epan beyond that of a free water surface the pan wall affects epan through the radiation absorption from the atmosphere and the surrounding environment and through heat conduction between the pan wall and the water body wang et al 2019a to simulate the vapor transfer and radiation processes of the water body and the pan wall fully physical models further versions of the penpan model were developed recently lim et al 2016 wang et al 2018 lim et al 2016 derived the penpan v2 model for the us class a pan and successfully applied in australia epan simulations wang et al 2018 derived the penpan v3 model and showed good performance in epan simulations of d20 and 601b pans in china in addition to using the new penpan v3 model using as inputs homogenized meteorological driven data is essential to ensure the quality of epan assimilation in china that said the available meteorological observations provided by the china meteorological administration cma remain non homogenized xu et al 2013 sun et al 2016 since long term climate data have been adversely affected by some non climatic factors for example changes in instrumentation station moves changes in the local environment or the introduction of different observing practices peterson et al 1998 to diminish these non climatic influences and develop a continuous and consistent long term gridded epan reanalysis dataset for d20 and 601b pans in china this study used the rhtestsv4 and anuspline software which are widely used by cma xu et al 2013 sun et al 2016 for homogenization and interpolation respectively the publicly available homogenization software rhtestsv4 wang et al 2007 wang 2008 was used to test the homogeneity of climate data and to homogenize the series of different climate data whenever necessary for each meteorological station the homogenized station data were interpolated to 0 05 0 05 gridded data using anuspline software hutchinson and xu 2013 by inputting the homogenized gridded climate data into penpan v3 model we developed a long term continuous and consistent gridded epan reanalysis dataset for d20 and 601b pans in china the reanalysis dataset covers the mainland china at a monthly time step and a spatial resolution of 0 05 spanning from 1960 to 2014 and it is freely available from two online cloud servers in china and the united states the dataset could benefit the water resources planning and management in china benefit the evaluation of the outputs of gcms and lsms and benefit the prediction of long term atmospheric evaporative demand in china rotstayn et al 2006 roderick et al 2009a 2009b wang et al 2012 mcvicar et al 2012 liu and sun 2016 wang et al 2017 2019a 2 data and methods 2 1 climatic and radiative data continuous daily climatic and radiative data for 1960 2014 were collected from existing cma digital records the climatic data include wind speed u maximum and minimum air temperature ta sunshine duration ssd relative humidity rh and epan of d20 and 601b pans from 824 meteorological stations the radiative data are global solar irradiance sg observations at 130 radiation stations represented by red crosses in fig 1 a all the daily data were calculated to monthly data based on roderick et al 2007 which calculated the monthly means of data only when a minimum of 25 days was available and excluded those months that did not meet this condition 767 stations for d20 pans and 591 stations for 601b pans in fig 1 a had near continuous records of epan during 1960 2014 and hence these stations were used to interpolate parameters in the aerodynamic function details in section 2 3 and to evaluate the penpan v3 model see section 3 1 most long term climatological time series are affected by several non climatic factors that make these data unrepresentative of the actual climate variation occurring over time peterson et al 1998 these factors include changes in instruments station locations observing practices formulae used to calculate means and station environment these factors are usually recorded in the metadata for each station however for most stations in this study metadata are incomplete or inaccessible for common users to diminish these non climatic influences thus we employ the publicly available homogenization software rhtestsv4 wang et al 2007 wang 2008 which has been widely used by cma for climate data homogenization xu et al 2013 sun et al 2016 since it is a robust statistical method to detect shifts in climate data series and to estimate the magnitude of shifts in this study we selected the penalized maximal f test algorithm in rhtestsv4 wang 2008 which is recommended when lack of the metadata to test the homogeneity of monthly climate data and to homogenize the series of different climate data whenever necessary 2 2 penpan v3 model the latest version of the penpan model penpan v3 wang et al 2018 is used to derive a long term continuous and consistent epan reanalysis dataset for two chinese pan types the penpan v3 model is based on a steady state energy balance assumption which for a d20 or 601b pan requires periods of at least a week so the applications described later use monthly input data consistent with previous versions of penpan model rotstayn et al 2006 lim et al 2016 in penpan v3 model epan m s is written as the sum of radiative epan r m s and aerodynamic epan a m s components 1 e pan s s β γ r n λ ρ w e pan r β γ s β γ v p d f v e pan a where s pa k is the slope of the saturation vapor pressure versus temperature curve at the air temperature two meters above the ground γ pa k is the psychrometric constant λ j kg is the latent heat of vaporization of liquid water β is the ratio of heat to mass transfer coefficient of the pan ρw kg m3 is the density of liquid water 1000 vpd pa is the vapor pressure deficit at 2 m fv m s pa is the aerodynamic function and rn w m2 is the net irradiance of a pan as a physical model fv is different from the function of wind speed used in previous evaporation simulations e g penman 1948 allen et al 1998 rotstayn et al 2006 which are empirical without physical meaning mcmahon et al 2013 based on the boundary layer theory lim et al 2012 derived fv and integrated it in the penpan v2 model 2 f v m w r ρ w t a d v ρ a n u 2 l η a q l where mw kg mol is the molecular mass of water 0 018 r j mol k is the ideal gas constant 8 314 dv m2 s is the diffusion coefficient for water vapor in air u2 m s is the wind speed at 2 m ρa kg m3 is the density of air ηa kg m s is the dynamic viscosity of air l m is the characteristic length of the evaporating surface n is the dimensionless site dependent parameter range 0 1 0 and q is the dimensionless site dependent parameter range 1 0 0 the calculation methods for parameters in eqs 1 and 2 are recorded in wang et al 2018 to examine the physical processes of the different parts of a pan wang et al 2019a divided epan into two components the evaporation determined by processes occurring on surfaces of the water body epan wb and the pan wall epan pw respectively epan wb consists of epan a and the evaporation affected by heat transfer and radiation processes occurring on the water surface epan w epan pw consists of the evaporation affected by heat transfer and radiation processes occurring on the outside pan rim epan rim inside pan rim epan rim side wall epan wall and pan bottom epan bot respectively the explanation and discussion of these components are introduced in wang et al 2019a eq 1 can be modified as 3 e pan β γ s β γ v p d f v s s β γ r n w λ ρ w e pan w b s s β γ r n r i m r n r i m r n w a l l r n b o t λ ρ w e pan p w e pan a e pan w e pan w b e pan r i m e pan r i m e pan w a l l e pan b o t e pan p w where rn w rn rim rn rim rn wall and rn bot w m2 are the net irradiance of the pan water surface outside rim inside rim side wall and bottom respectively and they are influenced by the pan geometry the effective areas albedo and emissivity to different irradiance ta rh and sg w m2 we collected sg observations from 130 radiation stations but these observations cannot be used to derive a reliable gridded dataset across china due to their small number instead we used ssd observations from 824 meteorological stations and the angstrom formula eq 4 to estimate sg in 824 locations 4 s g a s b s ssd n r a where n hour is the maximum possible duration of sunshine or daylight hours ra mj m2day is the extraterrestrial radiation and as and bs are regression constants only ssd and sg data from 1993 to 2014 are used to optimize as and bs as the sg observations were inconsistent owing to instrument replacement around 1993 yang et al 2015 the comparison between sg observations and simulations in fig 2 b indicates that sg simulations using our angstrom parameterization agreed well with observations the percent bias pbias nash sutcliffe efficiency nse and root mean square error rmse were 8 7 0 94 and 23 4 w m2 respectively 2 3 process of generating the gridded reanalysis dataset first ssd and sg at 130 stations during 1993 2014 were used in angstrom formula to optimize parameters as and bs second u2 rh ta max and min and epan at 767 and 591 stations were used in dalton relationship to optimize parameter n and q in fv for d20 and 601b pans see section 3 2 in wang et al 2018 respectively third ssd u2 rh and ta max and min at 824 stations were ingested into rhtestsv4 software wang et al 2007 wang 2008 to test the homogeneity and then to homogenize the monthly series if necessary taking the rh data as an example fig 2 c shows a sharp decrease of observed non homogenized annual rh presumably caused by the nationwide replacement of rh automated instruments around 2003 wang et al 2019a after homogenization the inhomogeneity around 2003 was diminished for homogenized annual rh then ssd u2 rh and ta max and min at 824 stations as and bs at 130 stations and n and q at 767 and 591 stations for d20 and 601b pans were inputted into anuspline software hutchinson and xu 2013 to interpolate 0 05 0 05 gridded data the gridded data and dem were inputted in penpan v3 model to calculate epan epan a epan r epan w epan rim epan rim epan wall and epan bot finally 0 05 0 05 gridded epan epan wb and epan pw for d20 and 601b pans during 1960 2014 were exported and released as the long term reanalysis dataset two things need to be noted here first the values of as and bs gradually varied in a year thus as and bs were separately optimized for each month i e the gridded as and bs data have 12 different spatial distributions second choosing different covariates in anuspline software may cause uncertainties in the interpolated results other potential uncertainties were discussed in section 4 3 2 4 dataset access the long term epan reanalysis dataset for two chinese pan types was released in two cloud servers in china and the united states users can download the instruction stored in china cloud server from https kaiwenwang 1257660865 cos ap beijing myqcloud com readme pdf and in the united states cloud server from https geohydro 1257660865 cos na siliconvalley myqcloud com readme pdf the dataset will continue to be maintained and updated and it will be available to every research community interested in the dataset 3 results 3 1 evaluation of the penpan v3 model we evaluated the penpan v3 model by comparing epan of two chinese pan types simulated by the model with the observations at different stations in the comparison the penpan v3 model was driven by non homogenized climatic observations rather than the homogenized climate data as a station s epan record may suffer from station relocation inhomogeneity problems and it may in fact represent epan from several locations however once epan simulations use homogenized climate data the simulations will only represent epan from a fixed location since the homogenization can solve the station relocation inhomogeneity problem therefore to evaluate the penpan v3 model epan observations were compared with epan simulations driven by observed non homogenized climate data fig 3 fig 3 a and b illustrate that epan simulated by penpan v3 model agrees well with the observations and pbias values of d20 and 601b pans are 8 15 and 1 1 nse values are 0 93 and 0 88 and rmse values are 22 5 and 16 0 mm month fig 3 c shows that for d20 pans at 767 stations the 25th 50th and 75th percentiles of pbias are 14 9 and 5 respectively the 25th 50th and 75th percentiles of nse are 0 85 0 90 and 0 94 respectively the 25th 50th and 75th percentiles of rmse are 17 22 and 25 mm month respectively for 601b pans at 591 stations the 25th 50th and 75th percentiles of pbias are 4 1 and 2 respectively the 25th 50th and 75th percentiles of nse are 0 75 0 83 and 0 87 respectively the 25th 50th and 75th percentiles of rmse are 12 14 and 16 mm month respectively the observed and simulated average monthly epan are shown in fig 3 d for d20 pans and in fig 3 e for 601b pans as d20 pans were replaced by 601b pans around 2002 across china epan observations before and after 2002 were separately denoted by two different colors fig 3 d shows that different from epan simulations average monthly epan observations suddenly decrease after 2002 due to the reduction of stations for d20 pan observations this finding explains the 2002 sharp change of average annual pan coefficient in china reported by wang et al 2019b for 601b pans epan cannot be measured when the water freezes and hence some stations in northern china do not have 601b epan observations in winter in fig 3 e the average monthly epan observations in winter are the average of stations where no icing happens while the epan simulations are the average of all the stations since stations where icing happens are set to 0 in penpan v3 model consequently fig 3 e shows that simulated average monthly epan in winter is lower than observations which bias upwards and towards warmer months 3 2 distributions of the gridded epan reanalysis dataset 3 2 1 spatial distributions of annual and seasonal epan the spatial distributions of average annual epan in fig 4 a and a show a strong spatial gradient although the spatial patterns of d20 and 601b pans are different for d20 pans the average annual epan varies from 600 to 2500 mm with higher values in the northwest of china which is mainly caused by the high wind speed and vapor pressure deficit and with lower values in the northeast of china and the source region of the yangtze and yellow river for 601b pans the average annual epan varies from 450 to 1250 mm with higher values in the northwest of china and the west of the tibetan plateau and with lower values in the northeast of china and the middle and lower reaches of the yangtze river a year is divided into spring march to may summer june to august autumn september to november and winter december to february to analyze seasonal epan distributions of d20 and 601b pans in spring the average epan varies from 150 to 720 mm and from 120 to 370 mm for d20 and 601b pans respectively and epan spatial patterns are similar to the average annual epan in summer the average epan varies from 160 to 1250 mm and from 180 to 570 mm for d20 and 601b pans respectively with the highest values in the northwest and north of china for both pans in autumn the average epan varies from 110 to 550 mm and from 50 to 310 mm for d20 and 601b pans respectively the northwest and south of china have the highest values for d20 pans the west of the tibetan plateau and south of china have the highest values for 601b pans in winter the average epan gradually decreases from south to north and shows distinct latitude belt distribution characteristics 3 2 2 the impacts of the pan wall on epan dynamics epan has been widely measured and recorded in agricultural hydrological and meteorological stations for estimating the open water evaporation eow and atmospheric evaporative demand fu et al 2004 ideally epan should be completely contributed by the water body and the ratio eow epan would be as close as possible to 1 however the pan wall affects the radiation balance of the water in the pan and the turbulence structure over it which increases epan beyond that of a free water surface if the pan wall absorbs and conducts more heat for vaporizing than water body in a pan epan may reflect the heat absorbing and conduction ability of the pan wall rather than eow wang et al 2019a we distinguish the impacts of the pan wall on epan dynamics and examine to what extent epan deviates from eow by calculating the ratios epan w epan of d20 and 601b pans the ratio epan w epan in fig 5 increases from the southeast to the northwest and the northeast of china and sichuan basin have small ratios the ratios vary from 37 to 76 and 87 5 to 94 5 for d20 and 601b pans respectively the small ratio of the d20 pan indicates that a d20 pan observed epan deviates much from eow and it is more affected by the pan wall than a 601b pan that is the reason china replaced d20 pans with 601b pans nationwide 4 discussion 4 1 comparisons of epan distributions the epan observation network and its interpolation are usually used to analyze epan distributions china built the epan observation network based on the d20 pan which was continuously observed from the 1950 s to early 2000 s but was replaced by the 601b pan around 2002 for the d20 pans observations are used to analyze epan distributions before the 2000 s e g cong et al 2009 liu et al 2004 while epan simulated by penpan style models is used to analyze epan distributions after the 2000 s due to the discontinuous observations e g liu et al 2011 yang and yang 2012 li et al 2013 liu and sun 2016 for the 601b pans observations are used to analyze epan distributions after the 2000 s e g wang et al 2018 and epan simulations are used to analyze epan distributions before 2000 s e g xiong et al 2012 wang et al 2018 epan observations are interpolated to analyze the continuous spatial distributions across china since observations only represent epan at the stations the spatial patterns of the interpolated annual epan changing from the coast towards inland and lower latitudes towards higher latitudes reported by zuo et al 2005 xiong et al 2012 and li et al 2016 are consistent with the spatial distributions in fig 4 a and a based on the interpolation of observed epan at 573 stations in china li et al 2016 reported that the average annual epan varied from 500 to 2100 mm and from 315 to 1300 mm for d20 and 601b pans respectively which are close to the ranges of our reanalysis dataset however the interpolation of observed epan cannot reflect the integrated influence of natural and climatic variables on epan especially the influence of elevation inputting dem and gridded climate data interpolated by the anuspline software into the state of art penpan v3 model our reanalysis dataset comprehensively considers the physical influence of elevation radiation and different climatic variables on epan additionally how well epan represents atmospheric evaporative demand can be estimated by the reanalysis dataset based on the ratio of epan w to epan the distribution of epan w epan fig 5 illustrates that the representativeness of epan to atmospheric evaporative demand decreases from coast to inland and from lower latitudes to higher latitudes in china because epan and potential evapotranspiration e g reference crop evapotranspiration are both considered as the physical indicator of the atmospheric evaporative demand we compare the spatial distributions of annual and seasonal potential evapotranspiration in some studies with the reanalysis dataset note the following comparisons mainly focus on the spatial patterns rather than the values fan et al 2016 calculated the seasonal distribution patterns of reference crop evapotranspiration in china during 1956 2015 the distribution patterns of reference crop evapotranspiration were consistent with the spatial patterns in fig 4 including the low values in the yangtze river basin in spring the high values in the northwest of china in spring and summer the low values in the southeast of china in summer and the distinct latitude belt distribution characteristics in winter the reanalysis dataset also shows the same spatial patterns with seasonal potential evapotranspiration distributions in some regional studies e g the spatial distributions in the yangtze river basin xu et al 2006 the yellow river basin she et al 2017 the southwest of china sun et al 2017 and the tibetan plateau zhang et al 2007 the above comparisons with different studies show that the distributions of potential evapotranspiration are more similar to epan distributions of the 601b pans than the d20 pans since the d20 pan is adversely affected by the pan wall fu et al 2004 wang et al 2019a owing to tremendous differences in latitude longitude and altitude the climate of china is extremely diverse and the reasons for the epan spatial differentiation are complex therefore more regional studies need to be conducted in the future to validate and improve the reanalysis dataset 4 2 a case study using the reanalysis dataset we choose the haihe river basin as a case study and compare epan observations of d20 pans at 32 meteorological stations with the reanalysis dataset located in northern china the haihe river basin fig 6 a is one of the most developed areas in china including the two megacities of beijing and tianjin climatically the haihe river basin belongs to the east asian monsoon region the annual precipitation and evaporation are about 539 and 470 mm respectively the annual mean temperature varies from 8 to 12 c and the average relative humidity varies from 50 to 70 because of the nationwide evaporimeter replacement the number of stations with epan observations suddenly decreases from over 27 stations to less than 18 stations after 2002 fig 6 b due to the reduction of stations average annual epan in fig 6 b sharply decreases after 2002 in contrast average annual epan calculated by the reanalysis dataset changes smoothly without a sudden decrease fig 6 c additionally the average annual epan calculated by observations represents the average value of these stations rather than the entire basin and it ranges between 1400 and 2200 mm however the gridded epan of the reanalysis dataset covers the entire basin and the average annual epan calculated by the dataset ranges between 1000 and 1500 mm 4 3 uncertainties of the reanalysis dataset the derivation of the long term epan reanalysis dataset is complex with a variety of meteorological input data which inevitably imparts several uncertainties in the present version of the reanalysis dataset first all the climate data were homogenized using the penalized maximal f test algorithm in the rhtestsv4 software and the homogenization results were not verified by any reference series the rhtestsv4 software has two algorithms to homogenize climate data namely the penalized maximal t test and f test the penalized maximal t test is recommended by rhtestsv4 since it uses the reference series obtained from the metadata to verify and improve the homogenization results however the penalized maximal t test is not used in this study as the metadata of most stations are incomplete or inaccessible for common users and we cannot create reliable reference series for most of the stations though the penalized maximal f test can identify most of the inhomogeneity problems xu et al 2013 wang 2008 some inhomogeneity problems may still exist to improve the quality of the epan reanalysis dataset in the future we will cooperate with cma to obtain detailed metadata and use the penalized maximal t test for climate data homogenization second we cannot execute the missing station analysis for all the interpolated data in fig 2 a in these types of analyses interpolated outputs are generally evaluated by removing a station from the input time series hence missing and the interpolated outputs at the missing station coordinates are compared with the observations however as shown in fig 2 a all the interpolated data have been homogenized before interpolation the homogenized data do not have the station relocation inhomogeneity problem and so the interpolated data do not have this problem either that said we cannot compare the interpolated data with observations since observations have the station relocation inhomogeneity problem while the interpolated data do not therefore we cannot execute the missing station analysis for the interpolated data in fig 2 a third penpan style models rotstayn et al 2006 lim et al 2016 wang et al 2018 cannot simulate ice sublimation the water in a pan freezes when ta descends below 0 c the d20 pan is small and it can be weighed to measure the ice sublimation when the water freezes thus the monthly epan observations in fig 3 a and d include ice sublimation which mainly happens in the winter at high latitudes the good simulation results in fig 3 a indicate that ignoring ice sublimation in d20 pans does not generate significant simulation error in china to extend the penpan style models to epan simulations in high latitudes the ice sublimation process needs to be formulated in the future fourth the gridded as and bs parameters in this study were interpolated based on their values at 130 stations according to the angstrom formula eq 4 as and bs optimization at a station requires both sg and ssd observations in this study we obtained sg data at 130 stations and as a consequence we only had as and bs values at 130 stations for interpolation introducing some radiative data observed by individuals or using some reliable radiative products can be tried in the future to improve the quality of the reanalysis dataset 5 conclusion this study developed a long term monthly 0 05 continuous and consistent reanalysis dataset for d20 and 601b pans covering mainland china throughout 1960 2014 the penpan v3 model used in generating the dataset was validated by epan observations at 767 and 591 stations for d20 and 601b pans respectively the epan simulations agreed well with the observations and the values of pbias nse and rmse were 8 15 1 1 0 93 0 88 and 22 5 16 0 mm month for d20 pans 601b pans comprehensively considering the physical influence of elevation radiation and different climatic variables the average annual and seasonal epan distributions of the reanalysis dataset are consistent with previous researches based on the epan observation network the reanalysis dataset provides opportunities to expand applications of epan first we can use the gridded dataset to analyze epan distributions across china including the areas without epan observations second the reanalysis dataset enables us to research long term epan distributions even though the observation network is discontinuous from the 1950s to early 2000s china had continuous observations of the d20 pans which were replaced by the 601b pans around 2002 as this reanalysis dataset spans from 1950 to 2014 it can be used to estimate epan from d20 pans after 2002 and to estimate epan from 601b pans before 2002 third the reanalysis dataset can distinguish the impacts of the pan wall on epan dynamics and thus we can use it to estimate how well epan represents atmospheric evaporative demand the dataset indicates the representativeness decreases from coast to inland and from lower latitudes to higher latitudes in china and that d20 pans are more affected by the pan wall than 601b pans fourth since epan integrates all the effects of climate variables such as ta rh rn and u2 on terrestrial evapotranspiration the reanalysis dataset may benefit the evaluation of the outputs from gcms and lsms the derivation of the reanalysis dataset is complex and uses a variety of meteorological data hence the present version of the reanalysis dataset may unavoidably incur several uncertainties some of which may be resolved in the future by obtaining more metadata and using the penalized maximal t test for climate data homogenization formulating the ice sublimation process for epan simulations in high latitudes and using more reliable radiative data to improve the quality of the dataset the long term epan reanalysis dataset for two chinese pan types has been released in two cloud servers in china and the united states and it will continue to be maintained and updated declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national key r d program of china nos 2018yfa0605404 2017yfc0506603 and 2016yfc0401305 the general program of national natural science foundation of china nos 51679007 and 51379013 and the state key program of national natural science of china no 41530635 this research benefited from the climatic data provided by the china meteorological data sharing service system http data cma cn data cdcindex cid 6d1b5efbdcbf9a58 html the long term pan evaporation reanalysis dataset for two chinese pan types can be downloaded following the instruction from https kaiwenwang 1257660865 cos ap beijing myqcloud com readme pdf or https geohydro 1257660865 cos na siliconvalley myqcloud com readme pdf the rhtestsv4 package used for homogenization which was downloaded from the expert team on climate change detection and indices etccdi website http etccdi pacifcclimate org software shtml with the help of dr xiaolan wang and yang feng kaiwen wang wishes to thank all the rainy days of the emerald city all of the authors acknowledge editor marco borga associate editor shengping wang and two anonymous reviewers for their invaluable comments and constructive suggestions for this research 
6028,the identification of groundwater contamination sources gcs can provide comprehensive knowledge for the remediation and risk assessment of contaminated sites this study develops an innovative framework that can be effectively and efficiently used for the optimal sampling well location design and gcs parameters identification the framework is based on bayesian theory and integrates the relative entropy re a 0 1 integer programming optimization model 0 1 ipom markov chain monte carlo mcmc and a kriging surrogate model ksm the expected re is used to quantify information about unknown parameters from concentration measurements based on a bayesian design the optimal sampling well locations are determined through the comprehensive application of 0 1 ipom and the expected re after determining the optimal sampling well locations a bayesian approach based on mcmc is employed to identify the gcs parameters however such problems are time consuming because both determination and identification require the contaminant transport model to be run multiple times to address this challenge a ksm is constructed for the contaminant transport model which greatly accelerates the determination and identification processes the feasibility and accuracy of the proposed approach are verified by two hypothetical numerical case studies the results show that the developed bayesian based integrated approach can be accurately and effectively applied for optimal sampling well location design and gcs parameter identification overall this study highlights that the bayesian based integrated approach represents a promising solution for gcs parameter identification keywords groundwater contamination sources optimal sampling well location design bayesian 0 1 integer programming optimization model markov chain monte carlo kriging 1 introduction knowledge of groundwater contamination sources gcs provides preconditions for the rational formulation of groundwater contamination remediation schemes and contamination risk assessment atmadja and bagtzoglou 2001a datta et al 2014 michalak and kitanidis 2004 sun 2007 sun et al 2006a woodbury and ulrych 1996 zeng et al 2012 however groundwater contamination is often concealed and exhibits hysteresis characteristics making it difficult to obtain gcs parameters such as the release history and contamination intensity atmadja and bagtzoglou 2001a sun et al 2006b sun 1999 therefore it is very important to develop an effective approach for gcs parameter identification table 1 at present the identification of gcs parameters is a challenging issue many identification methods infer the gcs parameters from measurements such as contamination concentrations and hydraulic heads that are relatively easy to obtain resulting in an inverse problem the simulation optimization approach ayvaz 2016 2010 jha and datta 2014 mahar and datta 2001 analytical solution and regression approach alapati and kabala 2000 bagtzoglou and atmadja 2003 woodbury and ulrych 1996 and direct approach atmadja and bagtzoglou 2001b bagtzoglou and atmadja 2003 neupauer et al 2000 have also been used for gcs parameters identification among these approaches the simulation optimization approach has been widely used in previous studies however even though the simulation optimization approach has the advantage of eliminating the unstable numerical solution schemes used to solve the inverse problem ayvaz 2016 the problem of ill posedness still exists skaggs and kabala 1994 furthermore the optimization approach cannot adequately describe the uncertainty of the solutions ma and zabaras 2009 zhang et al 2015 fortunately bayesian inversion approaches are a promising means of dealing with the uncertainty problems zhang et al 2015 generalized likelihood uncertainty estimation glue first applied bayes theorem to map the uncertainty in the hydrological simulation process to the parameter space using the monte carlo mc method beven and binley 1992 glue has also been widely used in gcs parameters identification feyen et al 2001 morse et al 2003 rojas et al 2008 however glue is not a standard bayesian method and the sampling technique is simple and inefficient blasone et al 2008 montanari 2005 thus glue can only be applied to relatively simple low dimensional problems compared with glue markov chain monte carlo mcmc sampling hastings 1970 metropolis et al 1953 has higher efficiency mcmc has been successfully employed to identify gcs parameters michalak and kitanidis 2003 zeng et al 2012 zhang et al 2015 in previous studies the sampling well locations were always assumed to be determined by bayesian inversion approaches prior to gcs parameter identification michalak and kitanidis 2003 wang and jin 2013 zeng et al 2012 however in many cases the sampling well locations largely determine the reliability of gcs parameter identification datta et al 2009 if the measurements from the sampling well locations contain more information related to the target parameters the subsequent parameter identification will be more efficient and accurate therefore it is necessary to design sampling well locations in a scientific manner before gcs parameter identification to obtain more information about the unknown parameters generally a utility function is needed to quantify the information from different sampling well locations and determine the optimal design by means of numerical simulations in groundwater hydrology the most common criteria for an optimal design are d optimality a optimality and e optimality sciortino et al 2002 these criteria are based on parameter covariance matrix through which the parameter sensitivity and correlation of different designs can be obtained zhang et al 2015 d optimality which minimizes the determinant of parameter covariance matrix has been widely used for the optimal design of groundwater research sites catania and paladino 2009 knopman et al 1991 sciortino et al 2002 it can balance high sensitivity and low correlation between parameters zhang et al 2015 furthermore a optimality minimizes the trace of the covariance matrix hsu and yeh 1989 knopman et al 1991 nishikawa and yeh 1989 vasco et al 1997 whereas e optimality maximizes the eigenvalue of the parameter estimates covariance matrix sciortino et al 2002 however a d and e optimality are all based on the gaussian linear hypothesis and are not suitable for highly nonlinear problems such as groundwater solute transport a bayesian design is more suitable for highly nonlinear systems huan and marzouk 2013 zhang et al 2015 in the bayesian design the relative entropy re also known as the kullback leibler divergence provides an effective method for quantifying information gain before and after quantization chaloner and verdinelli 1995 bayesian theory states that the difference between the posterior distribution and the prior distribution of parameters is caused by the measurements the greater the difference the more information about the parameters is carried by the measurements to facilitate the calculation the expected re is regarded as the utility function in this study thus the sampling well locations that give the maximum expected re are selected as the optimal sampling well locations to generate a scientific and effective design for the optimal sampling well locations a 0 1 integer programming optimization model 0 1 ipom is constructed first the expected re of each potential sampling well location is obtained through bayesian design the 0 1 ipom is then constructed based on these expectations the optimal sampling well locations are determined by solving the optimization model after determining the optimal sampling well locations and obtaining their measurements the posterior distribution is used to represent the updated parameter information however it is difficult to obtain an analytic expression directly from the posterior distribution of parameters this is because the posterior distribution of parameters is in a multiplicative form representing not only the prior information of parameters and measurement errors but also the nonlinearity of the system mcmc is an effective method of generating samples from the posterior distribution of parameters gamerman and lopes 2006 the required statistical information about the parameters can then be obtained by analyzing the samples regardless of the optimal sampling well location design or gcs parameter identification the original simulation model needs to run thousands of times multiple invocations of the simulation model not only consume a lot of time but also cause huge computational load to address this challenge a promising method involves building a surrogate for the original simulation model hence a kriging surrogate model ksm is constructed according to the input output datasets of the original simulation model enabling the addition of new input data to achieve accurate and efficient parameter identification using a kriging method to construct the surrogate model is not only well suited to fitting nonlinear problems but also has the advantages of fast convergence and good stability chen et al 2014 after the ksm is constructed for the original simulation model it is directly called in the optimal sampling well location design and gcs parameter identification which significantly reduces the computational load and the computation time in previous studies using bayesian inversion approaches to identify the gcs parameters sampling well location design was rarely considered this affects the efficiency of gcs parameter identification in this study we develop an approach that integrates the bayesian design re and 0 1 ipom to design the optimal sampling well locations the bayesian approach based on mcmc is used to identify the gcs parameters after obtaining measurements from the optimal sampling wells a flow diagram illustrating the study process is shown in fig 1 the remainder of this paper is organized as follows the theoretical framework is introduced in section 2 in section 3 two hypothetical numerical case studies are described to illustrate the performance of the proposed methods the results and discussions are presented in section 4 finally some conclusions are given in section 5 2 theoretical framework 2 1 simulation model in this study a single conservative contaminant is considered the groundwater contaminant transport model needs to be constructed on the basis of a groundwater flow model the partial differential equation describing the steady two dimensional flow of groundwater through a saturated aquifer can be given as 1 x i k i h x i 0 the two dimensional contaminant transport in groundwater may be written as 2 nc t x i n d ij c x j x i n u i c q s c s note that eq 2 is related to eq 1 through darcy s law 3 u i k i n h x i where x i and x j are the distances along the respective cartesian coordinate axes l k i is a principal component of the hydraulic conductivity tensor in the corresponding coordinate direction l t 1 h is the hydraulic head l c is the concentration of pollutants dissolved in groundwater m l 3 n is the porosity of the porous medium t is time t u i is the flow velocity l t 1 q s is the volumetric flow rate per unit volume of aquifer representing fluid sources positive t 1 c s is the concentration of the sources or sinks m l 3 d ij is the hydrodynamics dispersion tensor l 2 t 1 and d ij is described as 4 d xx α l u x 2 α t u y 2 u d yy α l u y 2 α t u x 2 u d xy d yx α l α t u x u y u where u x and u y are the components of pore water velocity u is its magnitude and α l α t denote longitudinal and transverse dispersivities respectively analytical method and numerical method are two common methods to solve groundwater model the analytical solution is an exact solution which has been studied by many scholars batu 1993 1989 chen et al 2017 2016 2012 2011 2008 gao et al 2010 lai et al 2016 the analytical method is mainly applicable to simple situations and the numerical method can effectively solve more complex problems in this study the groundwater flow and contaminant transport equations are sloved by modflow mcdonald and harbaugh 1988 and mt3dms zheng and wang 1999 2 2 optimal sampling well location design 2 2 1 bayesian design under a certain experimental condition s the model parameters θ can be estimated by indirect measurements m using bayes theorem huan and marzouk 2013 5 p θ m s p θ s p m θ s p m s where p θ s is the prior distribution p m θ s is the likelihood p θ m s is the posterior distribution and p m s is usually regarded as a normalization constant p m s p m θ s p θ s d θ in this study θ denotes the unknown gcs parameters m denotes the concentration measurements and s represent the sampling well locations corresponding to the concentration measurements the prior distribution p θ s represents the knowledge of the unknown parameters before we obtain the measurements this is independent of the sampling well locations s so p θ s p θ because the difference between the posterior distribution p θ m s and the prior distribution p θ s is the result of the concentration measurements m the magnitude of this difference is directly related to the amount of information about the parameters θ carried by the sampling well locations the re of the prior with respect to the posterior is employed to measure the difference between the two distributions and it can be expressed as lindley 1956 6 u s m θ p θ m s ln p θ m s p θ s d θ where m denotes the simulation measurements obtained with the given parameters θ and sampling well locations s to facilitate the calculation the expected re is used as the utility function in this study the expected re of a design s can be expressed as follow lindley 1956 7 u s γ θ u s m θ p θ m s d θ d m γ θ p θ m s ln p θ m s p θ s d θ p m s d m where u s is the expected re θ is the support of p θ and γ is the support of p m s the expected re in eq 7 has no analytic solutions and it must be approximated numerically huan and marzouk 2013 the expected re can be solved using the method proposed by huan and marzouk 2013 firstly the formula is rewritten according to bayes theorem 8 u s γ θ p θ m s ln p θ m s p θ s d θ p m s d m γ θ ln p m θ s p m s p m θ s p θ d θ d m γ θ ln p m θ s ln p m s p m θ s p θ d θ d m monte carlo simulation can then be used to solve eq 8 9 u s 1 n out i 1 n out ln p m i θ i s ln p m i s and 10 p m i s θ p m i θ s p θ d θ 1 n in j 1 n in p m i θ i j s where θ i represents samples randomly drawn from the prior distribution p θ s in the outer monte carlo simulation m i denotes the simulated measurements drawn from p m θ θ i s and n out is the number of samples in the outer monte carlo simulation θ i j represents samples randomly drawn from the prior distribution p θ s in the inner monte carlo simulation and n in is the number of samples in the inner monte carlo simulation to reduce the computational load the same batch of samples can be used in both eqs 9 and 10 by referring to huan and marzouk 2013 n out n in 80000 in this study 2 2 2 optimization model the values of u s at each potential sampling well location can be obtained by the abovementioned bayesian design a 0 1 ipom can then be constructed based on the values of u s this requires the decision variables to be 0 or 1 in this study a decision variable with a value of 1 indicates that a sampling well is placed at that location otherwise no sampling well is installed the optimal sampling well locations can be obtained by solving the 0 1 ipom the exhaustive method which considers each combination with decision variables of 0 or 1 and then compares the objective function values to find the optimal solution is used to solve the 0 1 ipom 2 3 parameter identification 2 3 1 bayesian inversion the forward problem is the process of estimating the result by using known information in this study only the measurement errors are considered so the forward model can be expressed as 11 m f θ s ε where m denotes the measurements obtained at the chosen sampling well locations s f is the simulation model θ denotes the unknown parameters and ε denotes the measurement errors after determining the optimal sampling well locations the measurements can be obtained by using the measurements m the posterior distribution p θ m can be updated as 12 p θ m p θ p m θ p m where p m θ is the likelihood and p m is usually regarded as a normalization constant in this study the measurement errors are assumed to conform to the normal distribution with a mean of 0 and a covariance of r the likelihood equation can be expressed as 13 p m θ 1 2 π n 2 r 1 2 exp 1 2 m f θ t r 1 m f θ where n is the number of measurements r is the determinant of the matrix r r 1 is the inverse of r f is the simulation model and t indicates transposition for highly non linear systems such as groundwater simulation models analytic forms of the parameter posterior distribution rarely exist in this study mcmc is employed to draw samples from the posterior distribution of parameters and analyze the samples 2 3 2 mcmc mcmc generates samples by constructing a suitable markov chain and converges to a stationary distribution π θ after running the chain for a sufficiently long time after convergence to the stationary distribution π θ samples can be drawn from the parameter posterior distribution p θ m by running the markov chain we can estimate the statistical properties of the parameter posterior distribution p θ m using these samples in this study we utilize the most widely used metropolis hastings m h algorithm tierney 1994 the m h method is not described in detail here readers are referred to tierney 1994 2 4 kriging to reduce the computational load a surrogate model is constructed for the original simulation model f θ s using the kriging method the surrogate model is used for both optimal sampling well location design and gcs parameters identification the regression equation of the kriging method can be expressed as an et al 2015 14 y x i 1 k f i x β i z x for a given set of sample points x x 1 x 2 x i x j x m t each sample point x i k k 1 2 n and the corresponding response y y 1 y 2 y i y j y m t and m is the number of sample points n is the number of variables k is the dimension of x x i k represents the k dimensional coordinates of the ith sample point the predicted value y x 0 and predicted standard deviations s x 0 of the unsampled point x 0 can then be written in the following form 15 y x 0 f t β 0 r x 0 t r 1 y f β 0 16 s x 0 σ z 2 1 μ t f t r 1 f 1 μ r x 0 t r 1 r x 0 where f i x represents the k predetermined basis functions and β i denotes the corresponding undetermined parameters r x 0 denotes the correlation vectors between x 0 and the m sampling points y is an m 1 vector containing the corresponding response values of the m sampling points β 0 can be obtained by optimal linear unbiased estimation and z x is a statistical stochastic process with a mean of 0 and a variance of σ z 2 and its covariance is 17 cov z x i z x j σ z 2 r η x i x j where r η x i x j is the correlation function between sampling points x i and x j and η is the parameter of the correlation model the correlation function r η x i x j usually has a simple form such as a gaussian function exponential function spherical function or spline function in this study the gauss function is chosen as the correlation function and its form is as follows 18 r η x i x j k 1 n η k x i k x j k p k where p k is an empirical parameter and 0 p k 2 the value of p k is 2 in this study and 19 μ f t r 1 r x 0 f 20 σ z 2 1 n y f β 0 t r 1 y f β 0 21 r x 0 r x 0 x 1 η r x 0 x 2 η r x 0 x m η thus solving for η is the key to constructing the ksm in this study a genetic algorithm ga mirghani et al 2009 is used to determine η 3 numerical applications the proposed approach was applied to two hypothetical case studies in both cases it was assumed that the released contaminant was typically conservative one of the advantages of using hypothetical case studies is that the estimated results can be compared with the theoretical results so the performance of the proposed approach can easily be verified zhao et al 2016 3 1 case studies 3 1 1 case 1 in this case study the range of the groundwater flow field was 16 l 10 l as shown in fig 2 the upper and lower boundaries were impermeable and the left and right boundaries had constant pressure heads 9l and 8l we assumed that the unknown gcs parameters were the intensity s and release history t on t off other parameters such as the locations and number of gcss hydraulic conductivity k porosity n and dispersivities α l and α t were considered to be known and homogeneous the unknown gcs parameters were θ s 1 s 2 t on t off among them s 1 s 2 were constant gcss intensities m t 1 and t on t off were the start and end times t of gcs release s 1 and s 2 were assumed to start and finish releasing contaminants at the same time the unknown gcss parameters θ s 1 s 2 t on t off were assumed to obey uniform distribution the prior ranges and true values of the unknown gcs parameters are presented in table 2 the concentration measurements of all potential sampling wells were obtained at t 6 t 9 t a n d 12 t and the measurement error ε was assumed to conform to an independent normal distribution with a mean of 0 and a variance of 0 05 as shown in fig 2 there were 96 potential sampling well locations 3 1 2 case 2 in the second case study the range of the groundwater flow field was 16 l 10 l as shown in fig 3 the boundary conditions porosity n and dispersivities α l and α t were the same as in case 1 however the conductivity field had three hydraulic conductivity zones z1 z2 and z3 with hydraulic conductivity k of 9 10 11 5 l t 1 respectively as shown in fig 3 it was assumed that a single contamination source with unknown location x s and y s l released contaminant at different intensities s 1 s 2 and s 3 m t 1 during three stress periods s p 1 0 5 t s p 2 6 10 t and s p 3 11 15 t the unknown gcs parameters were θ s 1 s 2 s 3 x s y s these parameters were assumed to obey uniform distributions their prior ranges and true values are presented in table 3 the concentration measurements of all potential sampling wells were obtained at t 5 t 10 t a n d 15 t and the measurement error ε was assumed to conform to an independent normal distribution with a mean of 0 and a variance of 0 05 as shown in fig 3 there were 88 potential sampling well locations in this case study 3 2 application of the surrogate model to reduce the computational load of designing the optimal sampling well locations and identifying the gcs parameters a surrogate model of the original simulation model was constructed using the kriging method the first step was to sample from the prior ranges of the unknown gcs parameters to gather the necessary parameters samples as training samples for the establishment of the ksm the obtained parameters samples served as input data in the original simulation model and the corresponding concentration outputs for all potential sampling well locations were obtained by running the original simulation model the ksm was then constructed according to the input output datasets in this study 80 sets of input output datasets were used to construct the ksm of the original simulation model to test the accuracy of the newly constructed ksm 15 new sets of parameters samples were randomly drawn from the prior ranges of the unknown gcs parameters as test samples the 15 sets of parameter samples were served as input of original simulation model and newly constructed ksm respectively and the 15 sets of corresponding concentration outputs of original simulation model and ksm were obtained and 15 sets of concentration outputs from the original simulation model were compared with those obtained by the ksm it should be noted that for each set of parameter samples the original simulation model and the ksm have the corresponding concentration output for all potential sampling well locations 96 potential sampling well locations for case 1 and 88 potential sampling well locations for case 2 at t 3 t 5 t 8 t 10 t 12 t and 15 t in this study to test the accuracy of the ksm more accurately all the outputs of the original simulation model are compared with those of the ksm one by one in this study and the relative fitting error rfe was used to quantify the accuracy of the ksm 22 rfe output of original simulation model output of ksm output of original simulation model 100 3 3 optimization model for case studies according to eqs 9 11 and the constructed ksm the values of u s were obtained for all the potential sampling well locations the 0 1 ipom was then constructed based on the known values of u s the optimization model for case 1 can be expressed as 23 maximum u k 1 96 u s k x k 24 subject to k 1 96 x k p x k 0 1 where u s k is the expected re of the kth potential sampling well location the number 96 corresponds to the potential sampling well locations for case 1 as shown in fig 2 x k is the decision variable where x k 1 indicates that a sampling well is installed in the kth potential sampling well location and x k 0 indicates that no sampling well is installed and p is the maximum number of sampling wells that can be installed in the second case study we assumed that the distance between any two sampling wells must be greater than or equal to 1 2l thus the 0 1 ipom for case 2 can be expressed as 25 maximum u k 1 88 g 1 3 u s kg x k 26 subject to k 1 88 x k p δ a k 2 δ b k 2 1 2 l k k x k 1 x k 0 1 where u s kg is the expected re of the kth potential sampling well location in the gth stress period the number 88 corresponds to the number of potential sampling well locations for case 2 as shown in fig 3 and there are three stress periods δ a k is the horizontal coordinate of potential sampling well locations δ b k is the longitudinal coordinate of potential sampling well locations and the other variables are consistent with those in eqs 23 and 24 3 4 computation time analysis one of the main objectives of this study is to improve the efficiency of the iteration process for optimal sampling well location design and gcs parameter identification therefore the computation time was measured to compare the execution time of the original simulation model with that of the ksm the procedures described above for case 2 are the same as those for case 1 the purpose of considering cases 1 and 2 is to test whether the proposed approach can be applied to both uniform and nonuniform media 4 results and discussions 4 1 analysis of the surrogate model the performance of the ksm constructed in this study is illustrated in fig 4 fig 4 shows the average rfe of all optimal sampling well locations at each moment t 3 t 5 t 8 t 10 t 12 t and 15 t for 15 sets test samples the rfe values are small indicating that the ksm achieves high precision and fully approximates the original simulation model thus the ksm can be directly called in the optimal sampling well location design and gcs parameter identification which not only improves the overall computational efficiency but also retains high accuracy furthermore by comparing the accuracy of the ksm in case 1 whose overall average rfe is 0 00552 with that in case 2 whose overall average rfe is 0 00630 it is clear that more accurate results can be obtained in the former than in the latter this is mainly because case 2 is more complicated and has greater nonlinearity than case 1 however the surrogate model is a black box model therefore it has some limitations because we cannot analyze its precise mechanisms generally surrogate models are applied in situations where simulation models must be called many times such as for obtaining the optimal iterative solution of an optimization model and uncertainty analysis 4 2 analysis of the optimal sampling well locations by solving the 0 1 ipom for case 1 eqs 23 and 24 and the 0 1 ipom for case 2 eqs 25 and 26 the locations of the optimal sampling wells were determined for p 1 2 3 4 5 6 the locations of the optimal sampling wells are shown in figs 5a and b and table 4 most of the sampling wells determined by the optimization model are located near the contamination sources along the flow direction this indicates that more information about the unknown gcs parameters can be obtained by sampling close to the contamination sources this is mainly because measurements from sampling wells close to pollution sources are less easily affected by other factors 4 3 analysis of the parameter identification results to test the validity of the optimal sampling locations proposed in section 4 2 we compared the parameter identification accuracy of the optimal sampling well locations design with that of five random designs by taking p 3 as an example see fig 6 to ensure the stable convergence of the markov chains geweke method geweke 1991 was used for convergence diagnosis in the stable convergence stage the final 2 000 sets of samples were used to estimate the statistical properties of the posterior distribution the posterior probability distribution of the gcs parameters obtained by the optimal sampling well location design and the five random sampling designs were then compared the comparison results are shown in figs 7 and 8 figs 7 and 8 showed that the optimal sampling well location design obtained a maximum a posteriori probability map that is closer to the true value of the gcs parameters than the other five random designs the uncertainty of the parameter posterior distribution is also lower this demonstrates that the optimal sampling well locations design can obtain more accurate identification results the mean values of the parameters obtained by the optimal sampling well location design are also listed in figs 7 and 8 hence the optimal sampling well location design and identification method is valid however although the ksm fits the original simulation model quite well the error between the ksm and the original simulation model may have a slight effect on the identification results we will study this aspect in detail in future research to examine the relationship between the values of u s and the identification accuracy pearson s correlation coefficient benesty et al 2009 between u s and the identification accuracy were calculated using spss the results are discussed in terms of sig and r where sig represents the significant level sig 0 05 indicates correlation between variables and r represents the degree of correlation with higher values indicating closer correlation 27 r i 1 n x i x y i y i 1 n x i x 2 i 1 n y i y 2 where x is the sample mean of variable x y is the sample mean of variable y and n is the number of variable samples to reduce the statistical error 10 sets of unknown gcs parameters see table 5 were randomly generated from prior distributions for case 1 the 10 sets of parameters were regarded as true values and the comprehensive identification results of different sampling well location designs were compared including the optimal sampling well locations design and the five random designs the root mean squared relative difference rmap between the map estimation and the true parameter value a and root mean squared relative difference rmean between the mean and a were used to evaluate the accuracy of the unknown parameter identification given by different sampling well location designs as expressed in eqs 28 and 29 28 rmap l pm ma p l a l a l 2 pm 29 rmean l pm mea n l a l a l 2 pm where pm is the number of unknown gcs parameters ma p l is the map value of the lth unknown gcs parameter mean l is the mean of the lth unknown gcs parameter and a l is the actual value of the lth unknown gcs parameter from tables 6a and b it is clear that u s is significantly negatively correlated with rmap and rmean indicating that larger values of u s produce more accurate gcs parameter identification results and vice versa therefore the optimal sampling well location design in this study is reasonable and effective the rmap and rmean values of the gcs parameter identification results obtained by different optimal sampling well location designs p 1 2 3 4 5 6 are compared in fig 9 this figure shows that with an increase in the number of sampling wells rmap and rmean gradually decrease that is the parameter identification results become closer to their true values and after p 4 the descending slopes of rmap and rmean are obviously slowed down that is to say the speed of improving the accuracy of parameter identification is slower obviously therefore based on the results of this study and considering that the installation of sampling wells requires manpower and financial resources we suggest that four or five sampling wells should be installed to identify the gcs parameters furthermore the gcs parameters identification results for uniform media are more accurate than those of nonuniform media this is mainly because the ksm for case 1 is more accurate than that for case 2 overall the rmap values of the gcs parameter identification results are lower than the rmean values moreover the constructed ksm achieved a reduced computation time throughout the process the required cpu time for completing 21 420 simulations in the original simulation model was about 125 min whereas the ksm took only about 10 min to finish 20 000 simulations on a pc with an intel i3 8100 3 60 ghz processor and 8 gb ram the shorter computation time of the ksm promotes its use in solving gcs parameter identification problems 5 conclusions this study developed a bayesian based integrated approach that combined re 0 1 ipom mcmc and a ksm to design the optimal sampling well locations and identify the unknown gcs parameters the expected re which is efficient for nonlinear systems is used to quantify information about unknown parameters carried by concentration measurements through bayesian design on the basis of the estimated expected re the optimum sampling well locations are determined by applying 0 1 ipom synthetically after the optimal sampling locations have been determined mcmc is used to generate realizations from the posterior distribution of the unknown gcs parameters to improve the overall computational efficiency a surrogate model is constructed for the original simulation model by applying a kriging method to the optimal sampling well location design and gcs parameter identification the resulting ksm significantly reduces the computational load and computation time therefore the design and estimation can be greatly accelerated case studies of both uniform media and nonuniform media were used to test the validity of this method in gcs parameters identification problems it was found that the designed optimal sampling locations allowed the unknown gcs parameters to be identified with higher accuracy furthermore the gcs parameter identification results for uniform media achieved higher accuracy than those for nonuniform media declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by real time mornitoring modeling and warning technology and equipments in soil contaminant sites no 2018yfc1800900 graduate innovation fund of jilin university no 101832018c049 the authors thank the editor and anonymous reviewers for their constructive comments and suggested revisions and we thank stuart jenkinson phd from liwen bianji edanz group china www liwenbianji cn ac for editing the english text of a draft of this manuscript 
6028,the identification of groundwater contamination sources gcs can provide comprehensive knowledge for the remediation and risk assessment of contaminated sites this study develops an innovative framework that can be effectively and efficiently used for the optimal sampling well location design and gcs parameters identification the framework is based on bayesian theory and integrates the relative entropy re a 0 1 integer programming optimization model 0 1 ipom markov chain monte carlo mcmc and a kriging surrogate model ksm the expected re is used to quantify information about unknown parameters from concentration measurements based on a bayesian design the optimal sampling well locations are determined through the comprehensive application of 0 1 ipom and the expected re after determining the optimal sampling well locations a bayesian approach based on mcmc is employed to identify the gcs parameters however such problems are time consuming because both determination and identification require the contaminant transport model to be run multiple times to address this challenge a ksm is constructed for the contaminant transport model which greatly accelerates the determination and identification processes the feasibility and accuracy of the proposed approach are verified by two hypothetical numerical case studies the results show that the developed bayesian based integrated approach can be accurately and effectively applied for optimal sampling well location design and gcs parameter identification overall this study highlights that the bayesian based integrated approach represents a promising solution for gcs parameter identification keywords groundwater contamination sources optimal sampling well location design bayesian 0 1 integer programming optimization model markov chain monte carlo kriging 1 introduction knowledge of groundwater contamination sources gcs provides preconditions for the rational formulation of groundwater contamination remediation schemes and contamination risk assessment atmadja and bagtzoglou 2001a datta et al 2014 michalak and kitanidis 2004 sun 2007 sun et al 2006a woodbury and ulrych 1996 zeng et al 2012 however groundwater contamination is often concealed and exhibits hysteresis characteristics making it difficult to obtain gcs parameters such as the release history and contamination intensity atmadja and bagtzoglou 2001a sun et al 2006b sun 1999 therefore it is very important to develop an effective approach for gcs parameter identification table 1 at present the identification of gcs parameters is a challenging issue many identification methods infer the gcs parameters from measurements such as contamination concentrations and hydraulic heads that are relatively easy to obtain resulting in an inverse problem the simulation optimization approach ayvaz 2016 2010 jha and datta 2014 mahar and datta 2001 analytical solution and regression approach alapati and kabala 2000 bagtzoglou and atmadja 2003 woodbury and ulrych 1996 and direct approach atmadja and bagtzoglou 2001b bagtzoglou and atmadja 2003 neupauer et al 2000 have also been used for gcs parameters identification among these approaches the simulation optimization approach has been widely used in previous studies however even though the simulation optimization approach has the advantage of eliminating the unstable numerical solution schemes used to solve the inverse problem ayvaz 2016 the problem of ill posedness still exists skaggs and kabala 1994 furthermore the optimization approach cannot adequately describe the uncertainty of the solutions ma and zabaras 2009 zhang et al 2015 fortunately bayesian inversion approaches are a promising means of dealing with the uncertainty problems zhang et al 2015 generalized likelihood uncertainty estimation glue first applied bayes theorem to map the uncertainty in the hydrological simulation process to the parameter space using the monte carlo mc method beven and binley 1992 glue has also been widely used in gcs parameters identification feyen et al 2001 morse et al 2003 rojas et al 2008 however glue is not a standard bayesian method and the sampling technique is simple and inefficient blasone et al 2008 montanari 2005 thus glue can only be applied to relatively simple low dimensional problems compared with glue markov chain monte carlo mcmc sampling hastings 1970 metropolis et al 1953 has higher efficiency mcmc has been successfully employed to identify gcs parameters michalak and kitanidis 2003 zeng et al 2012 zhang et al 2015 in previous studies the sampling well locations were always assumed to be determined by bayesian inversion approaches prior to gcs parameter identification michalak and kitanidis 2003 wang and jin 2013 zeng et al 2012 however in many cases the sampling well locations largely determine the reliability of gcs parameter identification datta et al 2009 if the measurements from the sampling well locations contain more information related to the target parameters the subsequent parameter identification will be more efficient and accurate therefore it is necessary to design sampling well locations in a scientific manner before gcs parameter identification to obtain more information about the unknown parameters generally a utility function is needed to quantify the information from different sampling well locations and determine the optimal design by means of numerical simulations in groundwater hydrology the most common criteria for an optimal design are d optimality a optimality and e optimality sciortino et al 2002 these criteria are based on parameter covariance matrix through which the parameter sensitivity and correlation of different designs can be obtained zhang et al 2015 d optimality which minimizes the determinant of parameter covariance matrix has been widely used for the optimal design of groundwater research sites catania and paladino 2009 knopman et al 1991 sciortino et al 2002 it can balance high sensitivity and low correlation between parameters zhang et al 2015 furthermore a optimality minimizes the trace of the covariance matrix hsu and yeh 1989 knopman et al 1991 nishikawa and yeh 1989 vasco et al 1997 whereas e optimality maximizes the eigenvalue of the parameter estimates covariance matrix sciortino et al 2002 however a d and e optimality are all based on the gaussian linear hypothesis and are not suitable for highly nonlinear problems such as groundwater solute transport a bayesian design is more suitable for highly nonlinear systems huan and marzouk 2013 zhang et al 2015 in the bayesian design the relative entropy re also known as the kullback leibler divergence provides an effective method for quantifying information gain before and after quantization chaloner and verdinelli 1995 bayesian theory states that the difference between the posterior distribution and the prior distribution of parameters is caused by the measurements the greater the difference the more information about the parameters is carried by the measurements to facilitate the calculation the expected re is regarded as the utility function in this study thus the sampling well locations that give the maximum expected re are selected as the optimal sampling well locations to generate a scientific and effective design for the optimal sampling well locations a 0 1 integer programming optimization model 0 1 ipom is constructed first the expected re of each potential sampling well location is obtained through bayesian design the 0 1 ipom is then constructed based on these expectations the optimal sampling well locations are determined by solving the optimization model after determining the optimal sampling well locations and obtaining their measurements the posterior distribution is used to represent the updated parameter information however it is difficult to obtain an analytic expression directly from the posterior distribution of parameters this is because the posterior distribution of parameters is in a multiplicative form representing not only the prior information of parameters and measurement errors but also the nonlinearity of the system mcmc is an effective method of generating samples from the posterior distribution of parameters gamerman and lopes 2006 the required statistical information about the parameters can then be obtained by analyzing the samples regardless of the optimal sampling well location design or gcs parameter identification the original simulation model needs to run thousands of times multiple invocations of the simulation model not only consume a lot of time but also cause huge computational load to address this challenge a promising method involves building a surrogate for the original simulation model hence a kriging surrogate model ksm is constructed according to the input output datasets of the original simulation model enabling the addition of new input data to achieve accurate and efficient parameter identification using a kriging method to construct the surrogate model is not only well suited to fitting nonlinear problems but also has the advantages of fast convergence and good stability chen et al 2014 after the ksm is constructed for the original simulation model it is directly called in the optimal sampling well location design and gcs parameter identification which significantly reduces the computational load and the computation time in previous studies using bayesian inversion approaches to identify the gcs parameters sampling well location design was rarely considered this affects the efficiency of gcs parameter identification in this study we develop an approach that integrates the bayesian design re and 0 1 ipom to design the optimal sampling well locations the bayesian approach based on mcmc is used to identify the gcs parameters after obtaining measurements from the optimal sampling wells a flow diagram illustrating the study process is shown in fig 1 the remainder of this paper is organized as follows the theoretical framework is introduced in section 2 in section 3 two hypothetical numerical case studies are described to illustrate the performance of the proposed methods the results and discussions are presented in section 4 finally some conclusions are given in section 5 2 theoretical framework 2 1 simulation model in this study a single conservative contaminant is considered the groundwater contaminant transport model needs to be constructed on the basis of a groundwater flow model the partial differential equation describing the steady two dimensional flow of groundwater through a saturated aquifer can be given as 1 x i k i h x i 0 the two dimensional contaminant transport in groundwater may be written as 2 nc t x i n d ij c x j x i n u i c q s c s note that eq 2 is related to eq 1 through darcy s law 3 u i k i n h x i where x i and x j are the distances along the respective cartesian coordinate axes l k i is a principal component of the hydraulic conductivity tensor in the corresponding coordinate direction l t 1 h is the hydraulic head l c is the concentration of pollutants dissolved in groundwater m l 3 n is the porosity of the porous medium t is time t u i is the flow velocity l t 1 q s is the volumetric flow rate per unit volume of aquifer representing fluid sources positive t 1 c s is the concentration of the sources or sinks m l 3 d ij is the hydrodynamics dispersion tensor l 2 t 1 and d ij is described as 4 d xx α l u x 2 α t u y 2 u d yy α l u y 2 α t u x 2 u d xy d yx α l α t u x u y u where u x and u y are the components of pore water velocity u is its magnitude and α l α t denote longitudinal and transverse dispersivities respectively analytical method and numerical method are two common methods to solve groundwater model the analytical solution is an exact solution which has been studied by many scholars batu 1993 1989 chen et al 2017 2016 2012 2011 2008 gao et al 2010 lai et al 2016 the analytical method is mainly applicable to simple situations and the numerical method can effectively solve more complex problems in this study the groundwater flow and contaminant transport equations are sloved by modflow mcdonald and harbaugh 1988 and mt3dms zheng and wang 1999 2 2 optimal sampling well location design 2 2 1 bayesian design under a certain experimental condition s the model parameters θ can be estimated by indirect measurements m using bayes theorem huan and marzouk 2013 5 p θ m s p θ s p m θ s p m s where p θ s is the prior distribution p m θ s is the likelihood p θ m s is the posterior distribution and p m s is usually regarded as a normalization constant p m s p m θ s p θ s d θ in this study θ denotes the unknown gcs parameters m denotes the concentration measurements and s represent the sampling well locations corresponding to the concentration measurements the prior distribution p θ s represents the knowledge of the unknown parameters before we obtain the measurements this is independent of the sampling well locations s so p θ s p θ because the difference between the posterior distribution p θ m s and the prior distribution p θ s is the result of the concentration measurements m the magnitude of this difference is directly related to the amount of information about the parameters θ carried by the sampling well locations the re of the prior with respect to the posterior is employed to measure the difference between the two distributions and it can be expressed as lindley 1956 6 u s m θ p θ m s ln p θ m s p θ s d θ where m denotes the simulation measurements obtained with the given parameters θ and sampling well locations s to facilitate the calculation the expected re is used as the utility function in this study the expected re of a design s can be expressed as follow lindley 1956 7 u s γ θ u s m θ p θ m s d θ d m γ θ p θ m s ln p θ m s p θ s d θ p m s d m where u s is the expected re θ is the support of p θ and γ is the support of p m s the expected re in eq 7 has no analytic solutions and it must be approximated numerically huan and marzouk 2013 the expected re can be solved using the method proposed by huan and marzouk 2013 firstly the formula is rewritten according to bayes theorem 8 u s γ θ p θ m s ln p θ m s p θ s d θ p m s d m γ θ ln p m θ s p m s p m θ s p θ d θ d m γ θ ln p m θ s ln p m s p m θ s p θ d θ d m monte carlo simulation can then be used to solve eq 8 9 u s 1 n out i 1 n out ln p m i θ i s ln p m i s and 10 p m i s θ p m i θ s p θ d θ 1 n in j 1 n in p m i θ i j s where θ i represents samples randomly drawn from the prior distribution p θ s in the outer monte carlo simulation m i denotes the simulated measurements drawn from p m θ θ i s and n out is the number of samples in the outer monte carlo simulation θ i j represents samples randomly drawn from the prior distribution p θ s in the inner monte carlo simulation and n in is the number of samples in the inner monte carlo simulation to reduce the computational load the same batch of samples can be used in both eqs 9 and 10 by referring to huan and marzouk 2013 n out n in 80000 in this study 2 2 2 optimization model the values of u s at each potential sampling well location can be obtained by the abovementioned bayesian design a 0 1 ipom can then be constructed based on the values of u s this requires the decision variables to be 0 or 1 in this study a decision variable with a value of 1 indicates that a sampling well is placed at that location otherwise no sampling well is installed the optimal sampling well locations can be obtained by solving the 0 1 ipom the exhaustive method which considers each combination with decision variables of 0 or 1 and then compares the objective function values to find the optimal solution is used to solve the 0 1 ipom 2 3 parameter identification 2 3 1 bayesian inversion the forward problem is the process of estimating the result by using known information in this study only the measurement errors are considered so the forward model can be expressed as 11 m f θ s ε where m denotes the measurements obtained at the chosen sampling well locations s f is the simulation model θ denotes the unknown parameters and ε denotes the measurement errors after determining the optimal sampling well locations the measurements can be obtained by using the measurements m the posterior distribution p θ m can be updated as 12 p θ m p θ p m θ p m where p m θ is the likelihood and p m is usually regarded as a normalization constant in this study the measurement errors are assumed to conform to the normal distribution with a mean of 0 and a covariance of r the likelihood equation can be expressed as 13 p m θ 1 2 π n 2 r 1 2 exp 1 2 m f θ t r 1 m f θ where n is the number of measurements r is the determinant of the matrix r r 1 is the inverse of r f is the simulation model and t indicates transposition for highly non linear systems such as groundwater simulation models analytic forms of the parameter posterior distribution rarely exist in this study mcmc is employed to draw samples from the posterior distribution of parameters and analyze the samples 2 3 2 mcmc mcmc generates samples by constructing a suitable markov chain and converges to a stationary distribution π θ after running the chain for a sufficiently long time after convergence to the stationary distribution π θ samples can be drawn from the parameter posterior distribution p θ m by running the markov chain we can estimate the statistical properties of the parameter posterior distribution p θ m using these samples in this study we utilize the most widely used metropolis hastings m h algorithm tierney 1994 the m h method is not described in detail here readers are referred to tierney 1994 2 4 kriging to reduce the computational load a surrogate model is constructed for the original simulation model f θ s using the kriging method the surrogate model is used for both optimal sampling well location design and gcs parameters identification the regression equation of the kriging method can be expressed as an et al 2015 14 y x i 1 k f i x β i z x for a given set of sample points x x 1 x 2 x i x j x m t each sample point x i k k 1 2 n and the corresponding response y y 1 y 2 y i y j y m t and m is the number of sample points n is the number of variables k is the dimension of x x i k represents the k dimensional coordinates of the ith sample point the predicted value y x 0 and predicted standard deviations s x 0 of the unsampled point x 0 can then be written in the following form 15 y x 0 f t β 0 r x 0 t r 1 y f β 0 16 s x 0 σ z 2 1 μ t f t r 1 f 1 μ r x 0 t r 1 r x 0 where f i x represents the k predetermined basis functions and β i denotes the corresponding undetermined parameters r x 0 denotes the correlation vectors between x 0 and the m sampling points y is an m 1 vector containing the corresponding response values of the m sampling points β 0 can be obtained by optimal linear unbiased estimation and z x is a statistical stochastic process with a mean of 0 and a variance of σ z 2 and its covariance is 17 cov z x i z x j σ z 2 r η x i x j where r η x i x j is the correlation function between sampling points x i and x j and η is the parameter of the correlation model the correlation function r η x i x j usually has a simple form such as a gaussian function exponential function spherical function or spline function in this study the gauss function is chosen as the correlation function and its form is as follows 18 r η x i x j k 1 n η k x i k x j k p k where p k is an empirical parameter and 0 p k 2 the value of p k is 2 in this study and 19 μ f t r 1 r x 0 f 20 σ z 2 1 n y f β 0 t r 1 y f β 0 21 r x 0 r x 0 x 1 η r x 0 x 2 η r x 0 x m η thus solving for η is the key to constructing the ksm in this study a genetic algorithm ga mirghani et al 2009 is used to determine η 3 numerical applications the proposed approach was applied to two hypothetical case studies in both cases it was assumed that the released contaminant was typically conservative one of the advantages of using hypothetical case studies is that the estimated results can be compared with the theoretical results so the performance of the proposed approach can easily be verified zhao et al 2016 3 1 case studies 3 1 1 case 1 in this case study the range of the groundwater flow field was 16 l 10 l as shown in fig 2 the upper and lower boundaries were impermeable and the left and right boundaries had constant pressure heads 9l and 8l we assumed that the unknown gcs parameters were the intensity s and release history t on t off other parameters such as the locations and number of gcss hydraulic conductivity k porosity n and dispersivities α l and α t were considered to be known and homogeneous the unknown gcs parameters were θ s 1 s 2 t on t off among them s 1 s 2 were constant gcss intensities m t 1 and t on t off were the start and end times t of gcs release s 1 and s 2 were assumed to start and finish releasing contaminants at the same time the unknown gcss parameters θ s 1 s 2 t on t off were assumed to obey uniform distribution the prior ranges and true values of the unknown gcs parameters are presented in table 2 the concentration measurements of all potential sampling wells were obtained at t 6 t 9 t a n d 12 t and the measurement error ε was assumed to conform to an independent normal distribution with a mean of 0 and a variance of 0 05 as shown in fig 2 there were 96 potential sampling well locations 3 1 2 case 2 in the second case study the range of the groundwater flow field was 16 l 10 l as shown in fig 3 the boundary conditions porosity n and dispersivities α l and α t were the same as in case 1 however the conductivity field had three hydraulic conductivity zones z1 z2 and z3 with hydraulic conductivity k of 9 10 11 5 l t 1 respectively as shown in fig 3 it was assumed that a single contamination source with unknown location x s and y s l released contaminant at different intensities s 1 s 2 and s 3 m t 1 during three stress periods s p 1 0 5 t s p 2 6 10 t and s p 3 11 15 t the unknown gcs parameters were θ s 1 s 2 s 3 x s y s these parameters were assumed to obey uniform distributions their prior ranges and true values are presented in table 3 the concentration measurements of all potential sampling wells were obtained at t 5 t 10 t a n d 15 t and the measurement error ε was assumed to conform to an independent normal distribution with a mean of 0 and a variance of 0 05 as shown in fig 3 there were 88 potential sampling well locations in this case study 3 2 application of the surrogate model to reduce the computational load of designing the optimal sampling well locations and identifying the gcs parameters a surrogate model of the original simulation model was constructed using the kriging method the first step was to sample from the prior ranges of the unknown gcs parameters to gather the necessary parameters samples as training samples for the establishment of the ksm the obtained parameters samples served as input data in the original simulation model and the corresponding concentration outputs for all potential sampling well locations were obtained by running the original simulation model the ksm was then constructed according to the input output datasets in this study 80 sets of input output datasets were used to construct the ksm of the original simulation model to test the accuracy of the newly constructed ksm 15 new sets of parameters samples were randomly drawn from the prior ranges of the unknown gcs parameters as test samples the 15 sets of parameter samples were served as input of original simulation model and newly constructed ksm respectively and the 15 sets of corresponding concentration outputs of original simulation model and ksm were obtained and 15 sets of concentration outputs from the original simulation model were compared with those obtained by the ksm it should be noted that for each set of parameter samples the original simulation model and the ksm have the corresponding concentration output for all potential sampling well locations 96 potential sampling well locations for case 1 and 88 potential sampling well locations for case 2 at t 3 t 5 t 8 t 10 t 12 t and 15 t in this study to test the accuracy of the ksm more accurately all the outputs of the original simulation model are compared with those of the ksm one by one in this study and the relative fitting error rfe was used to quantify the accuracy of the ksm 22 rfe output of original simulation model output of ksm output of original simulation model 100 3 3 optimization model for case studies according to eqs 9 11 and the constructed ksm the values of u s were obtained for all the potential sampling well locations the 0 1 ipom was then constructed based on the known values of u s the optimization model for case 1 can be expressed as 23 maximum u k 1 96 u s k x k 24 subject to k 1 96 x k p x k 0 1 where u s k is the expected re of the kth potential sampling well location the number 96 corresponds to the potential sampling well locations for case 1 as shown in fig 2 x k is the decision variable where x k 1 indicates that a sampling well is installed in the kth potential sampling well location and x k 0 indicates that no sampling well is installed and p is the maximum number of sampling wells that can be installed in the second case study we assumed that the distance between any two sampling wells must be greater than or equal to 1 2l thus the 0 1 ipom for case 2 can be expressed as 25 maximum u k 1 88 g 1 3 u s kg x k 26 subject to k 1 88 x k p δ a k 2 δ b k 2 1 2 l k k x k 1 x k 0 1 where u s kg is the expected re of the kth potential sampling well location in the gth stress period the number 88 corresponds to the number of potential sampling well locations for case 2 as shown in fig 3 and there are three stress periods δ a k is the horizontal coordinate of potential sampling well locations δ b k is the longitudinal coordinate of potential sampling well locations and the other variables are consistent with those in eqs 23 and 24 3 4 computation time analysis one of the main objectives of this study is to improve the efficiency of the iteration process for optimal sampling well location design and gcs parameter identification therefore the computation time was measured to compare the execution time of the original simulation model with that of the ksm the procedures described above for case 2 are the same as those for case 1 the purpose of considering cases 1 and 2 is to test whether the proposed approach can be applied to both uniform and nonuniform media 4 results and discussions 4 1 analysis of the surrogate model the performance of the ksm constructed in this study is illustrated in fig 4 fig 4 shows the average rfe of all optimal sampling well locations at each moment t 3 t 5 t 8 t 10 t 12 t and 15 t for 15 sets test samples the rfe values are small indicating that the ksm achieves high precision and fully approximates the original simulation model thus the ksm can be directly called in the optimal sampling well location design and gcs parameter identification which not only improves the overall computational efficiency but also retains high accuracy furthermore by comparing the accuracy of the ksm in case 1 whose overall average rfe is 0 00552 with that in case 2 whose overall average rfe is 0 00630 it is clear that more accurate results can be obtained in the former than in the latter this is mainly because case 2 is more complicated and has greater nonlinearity than case 1 however the surrogate model is a black box model therefore it has some limitations because we cannot analyze its precise mechanisms generally surrogate models are applied in situations where simulation models must be called many times such as for obtaining the optimal iterative solution of an optimization model and uncertainty analysis 4 2 analysis of the optimal sampling well locations by solving the 0 1 ipom for case 1 eqs 23 and 24 and the 0 1 ipom for case 2 eqs 25 and 26 the locations of the optimal sampling wells were determined for p 1 2 3 4 5 6 the locations of the optimal sampling wells are shown in figs 5a and b and table 4 most of the sampling wells determined by the optimization model are located near the contamination sources along the flow direction this indicates that more information about the unknown gcs parameters can be obtained by sampling close to the contamination sources this is mainly because measurements from sampling wells close to pollution sources are less easily affected by other factors 4 3 analysis of the parameter identification results to test the validity of the optimal sampling locations proposed in section 4 2 we compared the parameter identification accuracy of the optimal sampling well locations design with that of five random designs by taking p 3 as an example see fig 6 to ensure the stable convergence of the markov chains geweke method geweke 1991 was used for convergence diagnosis in the stable convergence stage the final 2 000 sets of samples were used to estimate the statistical properties of the posterior distribution the posterior probability distribution of the gcs parameters obtained by the optimal sampling well location design and the five random sampling designs were then compared the comparison results are shown in figs 7 and 8 figs 7 and 8 showed that the optimal sampling well location design obtained a maximum a posteriori probability map that is closer to the true value of the gcs parameters than the other five random designs the uncertainty of the parameter posterior distribution is also lower this demonstrates that the optimal sampling well locations design can obtain more accurate identification results the mean values of the parameters obtained by the optimal sampling well location design are also listed in figs 7 and 8 hence the optimal sampling well location design and identification method is valid however although the ksm fits the original simulation model quite well the error between the ksm and the original simulation model may have a slight effect on the identification results we will study this aspect in detail in future research to examine the relationship between the values of u s and the identification accuracy pearson s correlation coefficient benesty et al 2009 between u s and the identification accuracy were calculated using spss the results are discussed in terms of sig and r where sig represents the significant level sig 0 05 indicates correlation between variables and r represents the degree of correlation with higher values indicating closer correlation 27 r i 1 n x i x y i y i 1 n x i x 2 i 1 n y i y 2 where x is the sample mean of variable x y is the sample mean of variable y and n is the number of variable samples to reduce the statistical error 10 sets of unknown gcs parameters see table 5 were randomly generated from prior distributions for case 1 the 10 sets of parameters were regarded as true values and the comprehensive identification results of different sampling well location designs were compared including the optimal sampling well locations design and the five random designs the root mean squared relative difference rmap between the map estimation and the true parameter value a and root mean squared relative difference rmean between the mean and a were used to evaluate the accuracy of the unknown parameter identification given by different sampling well location designs as expressed in eqs 28 and 29 28 rmap l pm ma p l a l a l 2 pm 29 rmean l pm mea n l a l a l 2 pm where pm is the number of unknown gcs parameters ma p l is the map value of the lth unknown gcs parameter mean l is the mean of the lth unknown gcs parameter and a l is the actual value of the lth unknown gcs parameter from tables 6a and b it is clear that u s is significantly negatively correlated with rmap and rmean indicating that larger values of u s produce more accurate gcs parameter identification results and vice versa therefore the optimal sampling well location design in this study is reasonable and effective the rmap and rmean values of the gcs parameter identification results obtained by different optimal sampling well location designs p 1 2 3 4 5 6 are compared in fig 9 this figure shows that with an increase in the number of sampling wells rmap and rmean gradually decrease that is the parameter identification results become closer to their true values and after p 4 the descending slopes of rmap and rmean are obviously slowed down that is to say the speed of improving the accuracy of parameter identification is slower obviously therefore based on the results of this study and considering that the installation of sampling wells requires manpower and financial resources we suggest that four or five sampling wells should be installed to identify the gcs parameters furthermore the gcs parameters identification results for uniform media are more accurate than those of nonuniform media this is mainly because the ksm for case 1 is more accurate than that for case 2 overall the rmap values of the gcs parameter identification results are lower than the rmean values moreover the constructed ksm achieved a reduced computation time throughout the process the required cpu time for completing 21 420 simulations in the original simulation model was about 125 min whereas the ksm took only about 10 min to finish 20 000 simulations on a pc with an intel i3 8100 3 60 ghz processor and 8 gb ram the shorter computation time of the ksm promotes its use in solving gcs parameter identification problems 5 conclusions this study developed a bayesian based integrated approach that combined re 0 1 ipom mcmc and a ksm to design the optimal sampling well locations and identify the unknown gcs parameters the expected re which is efficient for nonlinear systems is used to quantify information about unknown parameters carried by concentration measurements through bayesian design on the basis of the estimated expected re the optimum sampling well locations are determined by applying 0 1 ipom synthetically after the optimal sampling locations have been determined mcmc is used to generate realizations from the posterior distribution of the unknown gcs parameters to improve the overall computational efficiency a surrogate model is constructed for the original simulation model by applying a kriging method to the optimal sampling well location design and gcs parameter identification the resulting ksm significantly reduces the computational load and computation time therefore the design and estimation can be greatly accelerated case studies of both uniform media and nonuniform media were used to test the validity of this method in gcs parameters identification problems it was found that the designed optimal sampling locations allowed the unknown gcs parameters to be identified with higher accuracy furthermore the gcs parameter identification results for uniform media achieved higher accuracy than those for nonuniform media declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by real time mornitoring modeling and warning technology and equipments in soil contaminant sites no 2018yfc1800900 graduate innovation fund of jilin university no 101832018c049 the authors thank the editor and anonymous reviewers for their constructive comments and suggested revisions and we thank stuart jenkinson phd from liwen bianji edanz group china www liwenbianji cn ac for editing the english text of a draft of this manuscript 
6029,an integrated framework is proposed for parametric uncertainty analysis in hydrological modeling using a generalized polynomial chaos expansion pce approach pce represents model output as a polynomial expression in terms of critical random variables that are determined by parameter uncertainties thus offers an efficient way of sampling without running the original model which is appealing to computationally expensive models to demonstrate the applicability of generalized pce approach both second and third order pces pce 2 and pce 3 are constructed for xinanjiang hydrological model using three selected uncertain parameters uncertainties in streamflow predictions are assessed by sampling the random inputs results show that 1 both pce 2 and pce 3 are capable of capturing the uncertainty information in hydrological predictions generating consistent mean variance skewness and kurtosis estimates with the standard monte carlo mc methodology 2 using more collocation points and more polynomial terms pce 3 approximation slightly improves the model simulation and provides more matched distribution with that of mc compared to pce 2 3 the computational cost using the pce approach is greatly reduced by 71 20 with pce 2 pce 3 in general pce 2 is recommended to serve as a good surrogate model for xinanjiang hydrological modelling in future with much higher computation speed more efficient sampling and compatible approximation results keywords polynomial chaos expansion collocation points hydrological model uncertainty quantification 1 introduction a hydrological model is a simplified representation of the real watershed hydrological processes it uses simple mathematical equations to conceptualize and aggregate the complex spatially distributed and highly interrelated water energy and vegetation processes in a watershed vrugt et al 2005 the conceptualization and aggregation produce extensive uncertainties in model parameters and structures thus leading to great uncertainties in hydrological predictions singh and bárdossy 2012 therefore it is necessary to quantify the parameter uncertainties inherent to hydrological models in water resource applications such as flood forecasting drought prediction and water resource management up to date different uncertainty analysis techniques have been introduced in hydrologic literature including monte carlo simulation mc ang and tang 1984 generalized likelihood uncertainty estimation glue beven and binley 1992 bayesian recursive estimation bare thiemann et al 2001 the shuffled complex evolution metropolis algorithm scem vrugt et al 2003a the multi objective extension of scem vrugt et al 2003b the dual state parameter estimation methods moradkhani et al 2005a b the simultaneous optimization and data assimilation soda vrugt et al 2005 and the model averaging methods e g least squares model averaging diks and vrugt 2010 among these mc provides the greatest flexibility for uncertainty propagation and is widely used with sufficiently large number of samples stable estimates of model output distribution can be easily derived liu and gupta 2007 mishra 2009 the main drawback of mc technique and sampling based method e g glue is that huge number of model simulations are required to get satisfactory estimates of the output statistics which is a challenge for models that have high computational demand possible ways to overcome the problem could be 1 using more efficient sampling scheme such as latin hypercube method 2 using a faster surrogate model to replace the computationally intensive model 3 combining the above two techniques khu and werner 2003 the polynomial chaos expansion pce approach could be an alternative to surrogate modeling scheme in addition to the applications in engineering and uncertainty quantification uq of dynamical systems hu and youn 2011 sanzida and nagy 2014 the pce approach has received attention in hydrologic studies recently fan et al 2015 huang and qin 2014 wang et al 2015 zheng et al 2011 originating from wiener s homogeneous chaos theory wiener 1938 and generalized by xiu and karniadakis 2002 using wiener askey polynomial chaos pce provides a spectral expression to the random process in terms of orthogonal polynomials pce is beneficial because 1 pce can be used to expand any second order random process a second order random process x t t t is one for which e x t 2 for all t i e a process with finite bounded variance it applies to most physical processes xiu and karniadakis 2002 2 the generalized pce can handle both gaussian and non gaussian random processes xiu and karniadakis 2002 2003 the selection of the polynomial basis depends on the distribution of the random inputs it is shown that exponential convergence rate can be ensured if an optimal polynomial basis is selected xiu and karniadakis 2002 3 pce offers an approximation to the dynamic model allowing for the fully probabilistic distribution of the model output the statistical information for example the mean variance covariance skewness etc can be estimated by sampling the random variable in pce 4 in virtue of a polynomial expression pce offers an efficient way of sampling without running the original model which is appealing particularly to computationally expensive models it is of interest to examine the usefulness of generalized pce approach in quantifying the uncertainty in hydrological predictions due to uncertain parameters in this study the pce approach is applied to the widely used xinanjiang hydrological model with the assumption that three of its 15 parameters are nondeterministic a guidance for its potential usage in quantifying the uncertainties of xinanjiang model is proposed the effectiveness of pce in quantifying the modeling uncertainty is investigated by comparison against the standard mc simulations by offering a surrogate model the accuracy and computational cost of pce approximation are assessed further through comparison against those from running the xinanjiang model the structure of this paper is as follows section 2 provides a brief review of pce methodology and the framework of parametric uncertainty analysis using generalized pce for uq in hydrological modeling in section 3 the second and third order pces are constructed after introducing the xinanjiang hydrological model and its parameters experimental results with discussions are provided in section 4 finally the concluding remarks along with possible future extensions to the current study are provided in section 5 2 methodology 2 1 polynomial chaos expansion the concept of pce method was originally proposed by wiener 1938 in wiener s chaos theory it is suggested to express a second order random process which applies to most physical process in terms of orthogonal polynomials hermite polynomials in wiener 1938 some earlier studies have employed hermite pce to solve stochastic differential equations and demonstrated its effectiveness for gaussian or some non gaussian random inputs ghanem 1999 ghanem and spanos 1991 spanos and ghanem 1989 xiu and karniadakis 2003 however for general non gaussian random inputs the convergence rate may not be optimal by extending hermite polynomials to polynomials in wiener askey family xiu and karniadakis 2002 proposed the generalized pce they suggested that an optimal choice is made if the polynomial basis is chosen based on the distribution of the random inputs according to table 1 adapted from table 4 1 in xiu and karniadakis 2002 for example the hermite polynomials are used for gaussian random variables and the legendre polynomials are for uniform distributions they further demonstrated that the exponential convergence rate can be achieved if an optimal choice is made given a dynamic model 1 y t f x t where x r n is the model input t is time y t r m is the model output and f x t maps the input x into output y the output y t would be random if some of the input fields are indeterminate generally pce is seeking to approximate the random output y t as an orthogonal polynomial expression of a predefined random variable ξ by 2 y t i 0 v i t φ i ξ where v i t r m is defined as expansion coefficient vector at time t φ i ξ is a wiener askey polynomial in terms of a n dimensional random variable ξ ξ 1 ξ 2 ξ n and i p 1 p 2 p n is a multi index the n variate polynomial φ i ξ φ p 1 p 2 p n ξ is constructed as the product of those univariate polynomials ϕ p j ξ j i e 3 φ i ξ j 1 n ϕ p j ξ j where ϕ p j ξ j is the orthogonal polynomial in ξ j dimension with order p j the order of φ i ξ is defined as p i p 1 p 2 p n in practice approximations are made by a finite summation in a finite dimensional space this is accomplished by truncating the expression in eq 2 to a low order pce as expressed in eq 4 4 y t i 0 p v i t φ i ξ the selection of truncation order p is made according to the accuracy requirement wan et al 2004 for a p th order the highest order of the polynomial chaos n dimensional the number of random variables pce the total number of polynomial basis terms will be 5 p n n p n p n the vital part in pce is to determine the expansion coefficients v i t generally there are two classes of approaches to estimate the coefficients namely intrusive and non intrusive methods oladyshkin and nowak 2012 intrusive method transforms the original dynamic model to a set of equations usually coupled with the expansion coefficients as unknowns the coefficients are obtained by solving the resulting equations hu et al 2017 the procedure is usually cumbersome and sometimes impractical especially for high complex nonlinear problems in contrast no model transformation is needed in non intrusive method the superiority of non intrusive method is remarkable when the dynamic takes complicated forms and it is difficult to derive the equations for the expansion coefficients the projection method le maı tre et al 2002 stochastic collocation method xiu and hesthaven 2005 regression method berveiller et al 2006 and gradient based method perez 2008 are some examples of non intrusive method the non intrusive method specifically the stochastic collocation sc method is used in this study due to its merit 2 2 the stochastic collocation method the sc method assumes the pce approximations be equal to the model outputs at predefined points called collocation points in random input space the expansion coefficients are then obtained by solving a set of linear equations the widely used strategy to specify the collocation points is based on the roots of the orthogonal polynomials adopted in pce a hydrological model usually has multiple parameters and the distribution of each varies with time study region initial conditions etc the focus of this study is to demonstrate the applicability of generalized pce approach in quantifying the uncertainties in hydrological predictions therefore less efforts were made to study the parameters following previous studies bárdossy 2007 feyen et al 2007 2008 parameters in hydrological models are assumed uniformly distributed if their actual distributions are unknown it is worth noting that even though uniform distribution is adopted in this study the generalized pce approach works for other distributions listed in table 1 as well the generalized pce approach utilizes the optimal choice of legendre polynomials to describe uniform distribution table 1 which is different from previous studies where hermite polynomials are used and transformation between uniform and normal distributions is required fan et al 2015 wang et al 2015 zheng et al 2011 the first few legendre polynomials 0 m 3 m is the order of the polynomial with one and two random variables are defined as follows 6 1 ξ 3 ξ 2 1 5 ξ 3 3 ξ 7 1 ξ 1 ξ 2 3 ξ 1 2 1 ξ 1 ξ 2 3 ξ 2 2 1 5 ξ 1 3 3 ξ 1 3 ξ 1 2 ξ 2 ξ 2 3 ξ 1 ξ 2 2 ξ 1 5 ξ 2 3 3 ξ 2 for one dimensional case the choice of collocation points follows gaussian quadrature rule for estimating integrals and they are the roots of the polynomials specifically suppose the truncation order is p the roots of the p 1 th order polynomial and value of zero are selected as collocation points for example if p 2 the collocation points are 0 15 5 and 15 5 if p 3 the points are 0 3 7 2 30 35 3 7 2 30 35 3 7 2 30 35 and 3 7 2 30 35 for multidimensional case the tensor product is the most intuitive strategy to construct the collocation points xiu and hesthaven 2005 zio and fernando 2012 as an example table 2 lists the collocation points for two variate second and third order pce following tensor product rule it is worth noting that the number of collocation points following tensor product rule increases exponentially as dimension n increases hence the tensor product rule is only applicable to low dimension n several studies have been conducted on effectively constructing collocation points to alleviate the computation burden while ensuring the degree of accuracy for example sparse grid strategy jia et al 2012 xiu 2007 the efficient collocation method ecm isukapalli 1999 villadsen and michelsen 1978 the regression based stochastic response surface method srsm isukapalli 1999 etc for the sake of simplicity the tensor product rule is used in this study as we only consider three random variables once achieving the expansion coefficients a polynomial approximation is constructed and can be used as a surrogate model without running the original model ensembles of the dynamic model simulation can be easily created by sampling the random variable ξ in pce for time consuming models large amount of time will be saved one can estimate the statistics based on the ensembles and further build the histogram to estimate the probability density function pdf 2 3 parameter uncertainty quantification for the hydrological model for brevity the procedure of uq using pce is summarized in the following 1 determine random input parameters of the hydrological model in this study of concern denoted as x x 1 x 2 x s 2 specify the random variable ξ ξ 1 ξ 2 ξ n together with polynomials φ i ξ according to the probabilistic distribution of random input x 3 construct the p th order pce of model output y t as g ξ t i 0 p v i t φ i ξ and express the random input x as a function of the random variable ξ 4 select l collocation points η 1 η 2 η l for random variable ξ 5 obtain input values x j j 1 2 l at collocation points η j run the original model f x j t and get l outputs y 1 t y 2 t y l t at each time t 6 by letting g x j t y j t j 1 2 l a set of linear equations with the expansion coefficients v i t i 0 1 p as unknowns are established 7 solve linear equations to obtain the expansion coefficients v i t at each time now a surrogate model g ξ t for the original model f x t has been established and uncertainty assessment can then be performed on g ξ t 2 4 metrics for quantitative assessment to quantitatively evaluate the uq ability of generalized pce approximation the mean uncertainty error mue and mean uncertainty absolute error muae of estimates on the mean value standard deviation std skewness and kurtosis are calculated relative to the standard mc simulation the formulas are given as follows 8 m u e i 1 t u pc u mc t 9 m u a e i 1 t a b s u pc u mc t where t is the number of simulation times u stands for uncertainty index including mean value standard deviation skewness and kurtosis and subscript pc denotes pce approximation and mc refers to mc simulation to further quantitatively evaluate the accuracy of the pce approximation to output variable q compared to the model simulation metrics include the pearson linear correlation coefficient cc root mean square error rmse mean absolute error mae bias and relative bias rb are calculated with following formulas 10 c c c o v q pc q model σ pc σ model 11 r m s e i 1 t q pc i q model i 2 t 12 m a e i 1 t a b s q pc i q model i t 13 bias i 1 t q pc i q model i t 14 r b i 1 t q pc i q model i i 1 t q model i where rmse mae and bias are in m3 s cc and rb are dimensionless cov in eq 10 refers to covariance and σ stands for std the rb denotes the degree of overestimation or underestimation i is the simulation time index and t is the total number of simulation times the abbreviation pc stands for the simulation from pce approximation and model is from the hydrological model 3 experimental configurations 3 1 study region the proposed framework is applied to the tar river basin that confluences to the united states geological survey usgs gauging station usgs02083500 this basin is located in the northern north carolina state nc fig 1 with latitude ranging from 35 81 n to 36 45 n and longitude ranging from 78 87 w to 77 35 w the drainage area is about 2183 square miles with the runoff outlet at the location of 77 31 59 w and 35 53 40 n the basin is topographically complicated with mountains and hills distributed in the western basin except the relatively flat eastern basin where the alluvial plains govern the lower reach of tar river the east of the basin is the pamlico sound which drains into atlantic ocean the basin has a humid subtropical climate type and is impacted by monsoon and hurricane precipitation systems that usually bring significant amount of precipitation to this basin and trigger floods 3 2 hydrological model the hydrological model used in this study is xinanjiang model a well known physically based conceptual model developed by zhao 1992 in 1979s this model has been widely used in china and other countries since its development chen et al 2015 in this model the runoff is separated into surface interflow and ground water components the core of this model is a water storage capacity distribution curve that describes the spatial heterogeneity of tension water and free water within a basin such curve has been applied in the well known three layer variable infiltration capacity vic 3l hydrologic model liang 1994 liang et al 1996 xinanjiang model has 15 major parameters defined in table 3 usually not all parameters have a large impact on the model output sensitivity analysis can be performed e g christiaens and feyen 2002 to discriminate between sensitive and non sensitive parameters and usually the non sensitive parameters are fixed and only those sensitive parameters are assessed blasone et al 2008 study by ren et al 2010 shows that the sensitivity of the parameters in xinanjiang model differs with the objective function initial conditions flood type and other factors among the 15 parameters three of them namely sm cki and ckg are found commonly sensitive with different objective functions this study investigates the uncertainty in hydrological modeling prediction under these three sensitive parameters sm cki and ckg to achieve this sm cki and ckg are assumed uniformly distributed see discussion in section 2 2 and the remaining 12 parameters are deterministic the values of the parameters table 3 are calibrated using daily streamflow observations from tar river basin between 1 january 2002 and 31 december 2004 with the shuffled complex evolution university of arizona sce ua algorithm duan et al 1992 note that the aim is to demonstrate the ability of pce in quantifying the uncertainty in hydrological prediction compared to mc sampling strategy therefore the value should be fine as long as it falls within reasonable range and the methodology is applicable to different parameter settings daily simulations from 1 january 2008 to 31 december 2009 731 days altogether are conducted in this study 3 3 pce and mc experimental configurations second order pce denoted as pce 2 hereafter in the form of g ξ t i 0 2 v i t φ i ξ where ξ ξ 1 ξ 2 ξ 3 and ξ j 1 1 j 1 2 3 is first constructed at each time t each day here expression g ξ t has 2 3 3 10 polynomial terms φ i ξ i 0 1 2 and by tensor product a number of 33 27 collocation points 27 model runs are used to obtain the expansion coefficients v i t as long as the coefficients are acquired a surrogate model in the form of pce 2 is created by sampling the random variable ξ a total number of 100 000 samples in this study samples for pce 2 approximation are created afterwards and further statistical analysis is performed it is assumed that a higher order pce can give better estimates for complete study the third order pce pce 3 hereafter approximation is also examined compared to pce 2 more polynomial terms 28 are adopted in pce 3 and correspondingly more collocation points 125 are involved to obtain the expansion coefficients the same set of samples for ξ in pce 2 are used to create ensembles of pce 3 approximation the performance of pce in quantifying the uncertainty of hydrological modeling prediction is assessed by comparison with the classic mc simulation in mc simulation the values of the parameters sm cki and ckg are initiated based on the 100 000 samples of ξ created and the xinanjiang model is run with these parameter values the design of the experiment ensures that both pce and mc use the same parameter values which helps to examine the accuracy of the pce approximation 4 experimental results in this section the experimental results of pce are compared with those using the mc method in terms of uncertainty analysis simulation accuracy and computational cost 4 1 uncertainty quantification fig 2 displays the mean and std of daily streamflow simulation over the period of two years calculated from the 100 000 samples by pce 2 approximation and mc simulation it is noticed that both mean and std values obtained from pce 2 agree well with those from the mc method fig 2a b the differences of mean and std for pce 2 and mc methods are marginally small with maximum difference less than 10 m3 s fig 2c d the scatter plots in fig 3 show that the mean std simulations with pce 2 and mc lie very close to the 1 1 line this indicates that the pce approach has very good ability to capture the mean and standard deviation in hydrological outputs similarly the comparison of the mean and std values of the daily streamflow from pce 3 and mc approaches are displayed in figs 4 and 5 respectively the difference between the mean std estimates from pce 3 and mc is very small with maximum difference less than 5 8 m3 s fig 4c d it is noticed that the estimates from pce 3 match better with those from mc when compared to pce 2 especially for the std values as shown in table 4 the muae is reduced from 0 66 pce 2 to 0 46 pce 3 for mean value 1 33 to 0 54 for std 0 44 to 0 23 for skewness and 1 46 to 0 93 for kurtosis the mue values exhibit similar behavior in order to present an overall view of the simulation distribution fig 6 displays the histograms constructed using the samples from pce 2 pce 3 as well as mc at selected days i e the 148th 323rd and 685th days the left column plots are from mc those from pce 2 are in the middle column and the right column is from pce 3 here the performance of pce approximation is demonstrated at high the 685th day low the 148th day and medium the 323th day streamflow simulations overall samples from pce 2 and pce 3 have similar distributions to those from mc especially at those days with high streamflow outputs the detailed statistical information including mean std skewness and kurtosis listed in table 5 indicate that both pce 3 and pce 2 generally capture the behavior of the hydrological model hence they are able to give reliable uncertainty assessment to the model outputs compared to pce 2 pce 3 shows overall slightly closer estimates to the statistics obtained from mc for example mean value for the 323th day from mc is 166 62 pce 2 has a value of 164 38 and pce 3 has an estimate of 165 59 one thing needs to be kept in mind is that the computational cost also increases with a higher order pce since more terms and collocation points are introduced in practice the balance between accuracy requirement and computational cost needs to be taken into account 4 2 simulation accuracy besides examining the ability of uq using pce the accuracy of pce approximation is also assessed the streamflow ensembles from pce and mc at selected times in table 5 together with cc values are displayed in fig 7 it can be seen that the ensembles from both pce 2 and pce 3 match well with those from mc approach especially for higher streamflow simulations overall pce 3 generates higher cc values analysis of the 2008 2009 2 year simulations reveals that with pce 2 713 of 731 simulation days have cc value greater than 0 8 and 623 days with cc greater than 0 9 while with pce 3 all 731 days have cc value greater than 0 8 and 721 days with cc greater than 0 9 this indicates that the difference between pce 3 approximation and model simulation is smaller i e pce 3 is more accurate than pce 2 fig 8 displays the model simulation pce 2 approximation and pce 3 approximation at three different parameter settings a sm 49 32 ckg 0 95 cki 0 97 b sm 24 02 ckg 0 95 cki 0 97 and c sm 13 01 ckg 0 99 cki 0 91 which are randomly chosen it is noticed that the simulations from xinanjiang model pce 2 and pce 3 approximations almost overlap with each other especially pce 3 is almost identical to the model quantitatively it is found that the pce approximations are relatively well compared with xinanjiang model simulations high cc 0 9 small rmse 6 m3 s and mae 4 m3 s and a margin of bias 2 m3 s and rb 1 particularly pce 3 shows smaller rmse and mae and a smaller margin of bias and rb indicating higher order pce outperforms low order pce in surrogating the xinanjiang model compared to pce 3 pce 2 overestimates high streamflow simulations but not remarkable 4 3 computational cost the computational time is investigated in the study as well under the same computational environment it takes mc 5823 s to make 100 000 runs for a period of 731 days the computation of sampling by pce approach is divided into two parts the expansion coefficient calculation and sampling process it takes pce 2 6 s to obtain the expansion coefficients and 1654 s to finish the sampling process therefore about 69 min 71 are saved by adopting pce 2 as anticipated pce 3 needs more time 15 s for coefficient acquiring and 4662 s for sampling consequently it takes 19 min 20 less by pce 3 than mc it is worth mentioning that pce spends most of its time in evaluating the polynomial basis at 100 000 random input values in fact this task can be accomplished in advance and a lookup table could be built for reference by excluding this part in pce the sampling process can be done in less than one minute and it is irrelevant to the hydrological model which in turn saves large amount of time in conclusion pce provides an efficient way of quantifying uncertainty which is especially appealing to complex models 5 conclusions this study proposes an integrated framework for parametric uncertainty analysis in hydrological modeling by using the generalized pce approach the essence of this pce approach is to expand the model as a spectral expression in terms of orthogonal polynomials which in turn serves as a surrogate model of the specific model like xinanjiang hydrological model the selection of the polynomials is determined by the probability distribution of input parameters the generalized pce deals with not only gaussian but also non gaussian random inputs being a polynomial expression pce offers an efficient way of sampling for uncertainty assessment without actually running the hydrological model which is crucial if the model runs are computationally intensive and considerably timesaving in computational efforts may be achieved note that the samples of the random input in pce and values of the polynomial basis can be calculated in advance to construct a lookup table for future use which further saves large amount of computational time the popular xinanjiang hydrological model is used to demonstrate the applicability of pce in hydrological uncertainty analysis we used three sensitive parameters sm ckg and cki out of the 15 parameters of xinanjiang model in this study uniform distribution was assumed for the three sensitive parameters and legendre polynomials are adopted for the construction of pce non intrusive approach specifically the sc method is used to estimate the expansion coefficients in pce the collocation points are selected based on the roots of the legendre polynomials and tensor product rule is used for constructing multi dimensional collocation points daily streamflow is simulated during a period of two years from 1 january 2008 to 31 december 2009 in tar river basin both pce 2 and pce 3 are utilized to assess the uncertainties in streamflow simulation mean std skewness kurtosis and histograms from pce are compared with those from the standard mc approach results indicate that both pce 2 and pce 3 provide consistent uncertainty estimates with mc not surprisingly with more terms and more collocation points pce 3 exhibits better performance in capturing the uncertainty information than pce 2 besides the capability of uncertainty assessment the accuracy of the pce approximation of the hydrological model is investigated in this study overall both pce 2 and pce 3 are able to provide reliable approximations to long term simulations as well as extreme streamflows like the uq ability the proximity of pce 3 is slightly improved over pce 2 by reducing rmse mae bias and rb but increasing cc fig 8 a c generally the higher accuracy is achieved with more computational costs compared with mc method pce 2 saves about 70 computational time while pce 3 saves 20 considering the accuracy and computational saving pce 2 is suggested to use as a surrogate model of the xinanjiang hydrological model in the future in summary the generalized pce offers a reliable surrogate model which further provides an efficient alternative to analyze the uncertainties in hydrological modeling though uniform distribution was used to demonstrate the applicability of generalized pce in this study it can be extended to other types of distribution as well further studies related to hydrological modeling using generalized pce approach can be performed on 1 addressing the uncertainty of complex distributed hydrological models 2 improving hydrological forecasts by combining pce with data assimilation methods etc these studies are underway declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the help from dr s lakshmivarahan from the university of oklahoma and dr john m lewis from national severe storms laboratory norman oklahoma and desert research institute reno nevada this research was partially sponsored by the 100 top talents program 74110 18841203 at sun yat sen university guangzhou guangdong china and by the national natural science foundation of china 41675109 41875182 the authors thank the editor and the anonymous reviewer for their constructive comments to improve this paper 
6029,an integrated framework is proposed for parametric uncertainty analysis in hydrological modeling using a generalized polynomial chaos expansion pce approach pce represents model output as a polynomial expression in terms of critical random variables that are determined by parameter uncertainties thus offers an efficient way of sampling without running the original model which is appealing to computationally expensive models to demonstrate the applicability of generalized pce approach both second and third order pces pce 2 and pce 3 are constructed for xinanjiang hydrological model using three selected uncertain parameters uncertainties in streamflow predictions are assessed by sampling the random inputs results show that 1 both pce 2 and pce 3 are capable of capturing the uncertainty information in hydrological predictions generating consistent mean variance skewness and kurtosis estimates with the standard monte carlo mc methodology 2 using more collocation points and more polynomial terms pce 3 approximation slightly improves the model simulation and provides more matched distribution with that of mc compared to pce 2 3 the computational cost using the pce approach is greatly reduced by 71 20 with pce 2 pce 3 in general pce 2 is recommended to serve as a good surrogate model for xinanjiang hydrological modelling in future with much higher computation speed more efficient sampling and compatible approximation results keywords polynomial chaos expansion collocation points hydrological model uncertainty quantification 1 introduction a hydrological model is a simplified representation of the real watershed hydrological processes it uses simple mathematical equations to conceptualize and aggregate the complex spatially distributed and highly interrelated water energy and vegetation processes in a watershed vrugt et al 2005 the conceptualization and aggregation produce extensive uncertainties in model parameters and structures thus leading to great uncertainties in hydrological predictions singh and bárdossy 2012 therefore it is necessary to quantify the parameter uncertainties inherent to hydrological models in water resource applications such as flood forecasting drought prediction and water resource management up to date different uncertainty analysis techniques have been introduced in hydrologic literature including monte carlo simulation mc ang and tang 1984 generalized likelihood uncertainty estimation glue beven and binley 1992 bayesian recursive estimation bare thiemann et al 2001 the shuffled complex evolution metropolis algorithm scem vrugt et al 2003a the multi objective extension of scem vrugt et al 2003b the dual state parameter estimation methods moradkhani et al 2005a b the simultaneous optimization and data assimilation soda vrugt et al 2005 and the model averaging methods e g least squares model averaging diks and vrugt 2010 among these mc provides the greatest flexibility for uncertainty propagation and is widely used with sufficiently large number of samples stable estimates of model output distribution can be easily derived liu and gupta 2007 mishra 2009 the main drawback of mc technique and sampling based method e g glue is that huge number of model simulations are required to get satisfactory estimates of the output statistics which is a challenge for models that have high computational demand possible ways to overcome the problem could be 1 using more efficient sampling scheme such as latin hypercube method 2 using a faster surrogate model to replace the computationally intensive model 3 combining the above two techniques khu and werner 2003 the polynomial chaos expansion pce approach could be an alternative to surrogate modeling scheme in addition to the applications in engineering and uncertainty quantification uq of dynamical systems hu and youn 2011 sanzida and nagy 2014 the pce approach has received attention in hydrologic studies recently fan et al 2015 huang and qin 2014 wang et al 2015 zheng et al 2011 originating from wiener s homogeneous chaos theory wiener 1938 and generalized by xiu and karniadakis 2002 using wiener askey polynomial chaos pce provides a spectral expression to the random process in terms of orthogonal polynomials pce is beneficial because 1 pce can be used to expand any second order random process a second order random process x t t t is one for which e x t 2 for all t i e a process with finite bounded variance it applies to most physical processes xiu and karniadakis 2002 2 the generalized pce can handle both gaussian and non gaussian random processes xiu and karniadakis 2002 2003 the selection of the polynomial basis depends on the distribution of the random inputs it is shown that exponential convergence rate can be ensured if an optimal polynomial basis is selected xiu and karniadakis 2002 3 pce offers an approximation to the dynamic model allowing for the fully probabilistic distribution of the model output the statistical information for example the mean variance covariance skewness etc can be estimated by sampling the random variable in pce 4 in virtue of a polynomial expression pce offers an efficient way of sampling without running the original model which is appealing particularly to computationally expensive models it is of interest to examine the usefulness of generalized pce approach in quantifying the uncertainty in hydrological predictions due to uncertain parameters in this study the pce approach is applied to the widely used xinanjiang hydrological model with the assumption that three of its 15 parameters are nondeterministic a guidance for its potential usage in quantifying the uncertainties of xinanjiang model is proposed the effectiveness of pce in quantifying the modeling uncertainty is investigated by comparison against the standard mc simulations by offering a surrogate model the accuracy and computational cost of pce approximation are assessed further through comparison against those from running the xinanjiang model the structure of this paper is as follows section 2 provides a brief review of pce methodology and the framework of parametric uncertainty analysis using generalized pce for uq in hydrological modeling in section 3 the second and third order pces are constructed after introducing the xinanjiang hydrological model and its parameters experimental results with discussions are provided in section 4 finally the concluding remarks along with possible future extensions to the current study are provided in section 5 2 methodology 2 1 polynomial chaos expansion the concept of pce method was originally proposed by wiener 1938 in wiener s chaos theory it is suggested to express a second order random process which applies to most physical process in terms of orthogonal polynomials hermite polynomials in wiener 1938 some earlier studies have employed hermite pce to solve stochastic differential equations and demonstrated its effectiveness for gaussian or some non gaussian random inputs ghanem 1999 ghanem and spanos 1991 spanos and ghanem 1989 xiu and karniadakis 2003 however for general non gaussian random inputs the convergence rate may not be optimal by extending hermite polynomials to polynomials in wiener askey family xiu and karniadakis 2002 proposed the generalized pce they suggested that an optimal choice is made if the polynomial basis is chosen based on the distribution of the random inputs according to table 1 adapted from table 4 1 in xiu and karniadakis 2002 for example the hermite polynomials are used for gaussian random variables and the legendre polynomials are for uniform distributions they further demonstrated that the exponential convergence rate can be achieved if an optimal choice is made given a dynamic model 1 y t f x t where x r n is the model input t is time y t r m is the model output and f x t maps the input x into output y the output y t would be random if some of the input fields are indeterminate generally pce is seeking to approximate the random output y t as an orthogonal polynomial expression of a predefined random variable ξ by 2 y t i 0 v i t φ i ξ where v i t r m is defined as expansion coefficient vector at time t φ i ξ is a wiener askey polynomial in terms of a n dimensional random variable ξ ξ 1 ξ 2 ξ n and i p 1 p 2 p n is a multi index the n variate polynomial φ i ξ φ p 1 p 2 p n ξ is constructed as the product of those univariate polynomials ϕ p j ξ j i e 3 φ i ξ j 1 n ϕ p j ξ j where ϕ p j ξ j is the orthogonal polynomial in ξ j dimension with order p j the order of φ i ξ is defined as p i p 1 p 2 p n in practice approximations are made by a finite summation in a finite dimensional space this is accomplished by truncating the expression in eq 2 to a low order pce as expressed in eq 4 4 y t i 0 p v i t φ i ξ the selection of truncation order p is made according to the accuracy requirement wan et al 2004 for a p th order the highest order of the polynomial chaos n dimensional the number of random variables pce the total number of polynomial basis terms will be 5 p n n p n p n the vital part in pce is to determine the expansion coefficients v i t generally there are two classes of approaches to estimate the coefficients namely intrusive and non intrusive methods oladyshkin and nowak 2012 intrusive method transforms the original dynamic model to a set of equations usually coupled with the expansion coefficients as unknowns the coefficients are obtained by solving the resulting equations hu et al 2017 the procedure is usually cumbersome and sometimes impractical especially for high complex nonlinear problems in contrast no model transformation is needed in non intrusive method the superiority of non intrusive method is remarkable when the dynamic takes complicated forms and it is difficult to derive the equations for the expansion coefficients the projection method le maı tre et al 2002 stochastic collocation method xiu and hesthaven 2005 regression method berveiller et al 2006 and gradient based method perez 2008 are some examples of non intrusive method the non intrusive method specifically the stochastic collocation sc method is used in this study due to its merit 2 2 the stochastic collocation method the sc method assumes the pce approximations be equal to the model outputs at predefined points called collocation points in random input space the expansion coefficients are then obtained by solving a set of linear equations the widely used strategy to specify the collocation points is based on the roots of the orthogonal polynomials adopted in pce a hydrological model usually has multiple parameters and the distribution of each varies with time study region initial conditions etc the focus of this study is to demonstrate the applicability of generalized pce approach in quantifying the uncertainties in hydrological predictions therefore less efforts were made to study the parameters following previous studies bárdossy 2007 feyen et al 2007 2008 parameters in hydrological models are assumed uniformly distributed if their actual distributions are unknown it is worth noting that even though uniform distribution is adopted in this study the generalized pce approach works for other distributions listed in table 1 as well the generalized pce approach utilizes the optimal choice of legendre polynomials to describe uniform distribution table 1 which is different from previous studies where hermite polynomials are used and transformation between uniform and normal distributions is required fan et al 2015 wang et al 2015 zheng et al 2011 the first few legendre polynomials 0 m 3 m is the order of the polynomial with one and two random variables are defined as follows 6 1 ξ 3 ξ 2 1 5 ξ 3 3 ξ 7 1 ξ 1 ξ 2 3 ξ 1 2 1 ξ 1 ξ 2 3 ξ 2 2 1 5 ξ 1 3 3 ξ 1 3 ξ 1 2 ξ 2 ξ 2 3 ξ 1 ξ 2 2 ξ 1 5 ξ 2 3 3 ξ 2 for one dimensional case the choice of collocation points follows gaussian quadrature rule for estimating integrals and they are the roots of the polynomials specifically suppose the truncation order is p the roots of the p 1 th order polynomial and value of zero are selected as collocation points for example if p 2 the collocation points are 0 15 5 and 15 5 if p 3 the points are 0 3 7 2 30 35 3 7 2 30 35 3 7 2 30 35 and 3 7 2 30 35 for multidimensional case the tensor product is the most intuitive strategy to construct the collocation points xiu and hesthaven 2005 zio and fernando 2012 as an example table 2 lists the collocation points for two variate second and third order pce following tensor product rule it is worth noting that the number of collocation points following tensor product rule increases exponentially as dimension n increases hence the tensor product rule is only applicable to low dimension n several studies have been conducted on effectively constructing collocation points to alleviate the computation burden while ensuring the degree of accuracy for example sparse grid strategy jia et al 2012 xiu 2007 the efficient collocation method ecm isukapalli 1999 villadsen and michelsen 1978 the regression based stochastic response surface method srsm isukapalli 1999 etc for the sake of simplicity the tensor product rule is used in this study as we only consider three random variables once achieving the expansion coefficients a polynomial approximation is constructed and can be used as a surrogate model without running the original model ensembles of the dynamic model simulation can be easily created by sampling the random variable ξ in pce for time consuming models large amount of time will be saved one can estimate the statistics based on the ensembles and further build the histogram to estimate the probability density function pdf 2 3 parameter uncertainty quantification for the hydrological model for brevity the procedure of uq using pce is summarized in the following 1 determine random input parameters of the hydrological model in this study of concern denoted as x x 1 x 2 x s 2 specify the random variable ξ ξ 1 ξ 2 ξ n together with polynomials φ i ξ according to the probabilistic distribution of random input x 3 construct the p th order pce of model output y t as g ξ t i 0 p v i t φ i ξ and express the random input x as a function of the random variable ξ 4 select l collocation points η 1 η 2 η l for random variable ξ 5 obtain input values x j j 1 2 l at collocation points η j run the original model f x j t and get l outputs y 1 t y 2 t y l t at each time t 6 by letting g x j t y j t j 1 2 l a set of linear equations with the expansion coefficients v i t i 0 1 p as unknowns are established 7 solve linear equations to obtain the expansion coefficients v i t at each time now a surrogate model g ξ t for the original model f x t has been established and uncertainty assessment can then be performed on g ξ t 2 4 metrics for quantitative assessment to quantitatively evaluate the uq ability of generalized pce approximation the mean uncertainty error mue and mean uncertainty absolute error muae of estimates on the mean value standard deviation std skewness and kurtosis are calculated relative to the standard mc simulation the formulas are given as follows 8 m u e i 1 t u pc u mc t 9 m u a e i 1 t a b s u pc u mc t where t is the number of simulation times u stands for uncertainty index including mean value standard deviation skewness and kurtosis and subscript pc denotes pce approximation and mc refers to mc simulation to further quantitatively evaluate the accuracy of the pce approximation to output variable q compared to the model simulation metrics include the pearson linear correlation coefficient cc root mean square error rmse mean absolute error mae bias and relative bias rb are calculated with following formulas 10 c c c o v q pc q model σ pc σ model 11 r m s e i 1 t q pc i q model i 2 t 12 m a e i 1 t a b s q pc i q model i t 13 bias i 1 t q pc i q model i t 14 r b i 1 t q pc i q model i i 1 t q model i where rmse mae and bias are in m3 s cc and rb are dimensionless cov in eq 10 refers to covariance and σ stands for std the rb denotes the degree of overestimation or underestimation i is the simulation time index and t is the total number of simulation times the abbreviation pc stands for the simulation from pce approximation and model is from the hydrological model 3 experimental configurations 3 1 study region the proposed framework is applied to the tar river basin that confluences to the united states geological survey usgs gauging station usgs02083500 this basin is located in the northern north carolina state nc fig 1 with latitude ranging from 35 81 n to 36 45 n and longitude ranging from 78 87 w to 77 35 w the drainage area is about 2183 square miles with the runoff outlet at the location of 77 31 59 w and 35 53 40 n the basin is topographically complicated with mountains and hills distributed in the western basin except the relatively flat eastern basin where the alluvial plains govern the lower reach of tar river the east of the basin is the pamlico sound which drains into atlantic ocean the basin has a humid subtropical climate type and is impacted by monsoon and hurricane precipitation systems that usually bring significant amount of precipitation to this basin and trigger floods 3 2 hydrological model the hydrological model used in this study is xinanjiang model a well known physically based conceptual model developed by zhao 1992 in 1979s this model has been widely used in china and other countries since its development chen et al 2015 in this model the runoff is separated into surface interflow and ground water components the core of this model is a water storage capacity distribution curve that describes the spatial heterogeneity of tension water and free water within a basin such curve has been applied in the well known three layer variable infiltration capacity vic 3l hydrologic model liang 1994 liang et al 1996 xinanjiang model has 15 major parameters defined in table 3 usually not all parameters have a large impact on the model output sensitivity analysis can be performed e g christiaens and feyen 2002 to discriminate between sensitive and non sensitive parameters and usually the non sensitive parameters are fixed and only those sensitive parameters are assessed blasone et al 2008 study by ren et al 2010 shows that the sensitivity of the parameters in xinanjiang model differs with the objective function initial conditions flood type and other factors among the 15 parameters three of them namely sm cki and ckg are found commonly sensitive with different objective functions this study investigates the uncertainty in hydrological modeling prediction under these three sensitive parameters sm cki and ckg to achieve this sm cki and ckg are assumed uniformly distributed see discussion in section 2 2 and the remaining 12 parameters are deterministic the values of the parameters table 3 are calibrated using daily streamflow observations from tar river basin between 1 january 2002 and 31 december 2004 with the shuffled complex evolution university of arizona sce ua algorithm duan et al 1992 note that the aim is to demonstrate the ability of pce in quantifying the uncertainty in hydrological prediction compared to mc sampling strategy therefore the value should be fine as long as it falls within reasonable range and the methodology is applicable to different parameter settings daily simulations from 1 january 2008 to 31 december 2009 731 days altogether are conducted in this study 3 3 pce and mc experimental configurations second order pce denoted as pce 2 hereafter in the form of g ξ t i 0 2 v i t φ i ξ where ξ ξ 1 ξ 2 ξ 3 and ξ j 1 1 j 1 2 3 is first constructed at each time t each day here expression g ξ t has 2 3 3 10 polynomial terms φ i ξ i 0 1 2 and by tensor product a number of 33 27 collocation points 27 model runs are used to obtain the expansion coefficients v i t as long as the coefficients are acquired a surrogate model in the form of pce 2 is created by sampling the random variable ξ a total number of 100 000 samples in this study samples for pce 2 approximation are created afterwards and further statistical analysis is performed it is assumed that a higher order pce can give better estimates for complete study the third order pce pce 3 hereafter approximation is also examined compared to pce 2 more polynomial terms 28 are adopted in pce 3 and correspondingly more collocation points 125 are involved to obtain the expansion coefficients the same set of samples for ξ in pce 2 are used to create ensembles of pce 3 approximation the performance of pce in quantifying the uncertainty of hydrological modeling prediction is assessed by comparison with the classic mc simulation in mc simulation the values of the parameters sm cki and ckg are initiated based on the 100 000 samples of ξ created and the xinanjiang model is run with these parameter values the design of the experiment ensures that both pce and mc use the same parameter values which helps to examine the accuracy of the pce approximation 4 experimental results in this section the experimental results of pce are compared with those using the mc method in terms of uncertainty analysis simulation accuracy and computational cost 4 1 uncertainty quantification fig 2 displays the mean and std of daily streamflow simulation over the period of two years calculated from the 100 000 samples by pce 2 approximation and mc simulation it is noticed that both mean and std values obtained from pce 2 agree well with those from the mc method fig 2a b the differences of mean and std for pce 2 and mc methods are marginally small with maximum difference less than 10 m3 s fig 2c d the scatter plots in fig 3 show that the mean std simulations with pce 2 and mc lie very close to the 1 1 line this indicates that the pce approach has very good ability to capture the mean and standard deviation in hydrological outputs similarly the comparison of the mean and std values of the daily streamflow from pce 3 and mc approaches are displayed in figs 4 and 5 respectively the difference between the mean std estimates from pce 3 and mc is very small with maximum difference less than 5 8 m3 s fig 4c d it is noticed that the estimates from pce 3 match better with those from mc when compared to pce 2 especially for the std values as shown in table 4 the muae is reduced from 0 66 pce 2 to 0 46 pce 3 for mean value 1 33 to 0 54 for std 0 44 to 0 23 for skewness and 1 46 to 0 93 for kurtosis the mue values exhibit similar behavior in order to present an overall view of the simulation distribution fig 6 displays the histograms constructed using the samples from pce 2 pce 3 as well as mc at selected days i e the 148th 323rd and 685th days the left column plots are from mc those from pce 2 are in the middle column and the right column is from pce 3 here the performance of pce approximation is demonstrated at high the 685th day low the 148th day and medium the 323th day streamflow simulations overall samples from pce 2 and pce 3 have similar distributions to those from mc especially at those days with high streamflow outputs the detailed statistical information including mean std skewness and kurtosis listed in table 5 indicate that both pce 3 and pce 2 generally capture the behavior of the hydrological model hence they are able to give reliable uncertainty assessment to the model outputs compared to pce 2 pce 3 shows overall slightly closer estimates to the statistics obtained from mc for example mean value for the 323th day from mc is 166 62 pce 2 has a value of 164 38 and pce 3 has an estimate of 165 59 one thing needs to be kept in mind is that the computational cost also increases with a higher order pce since more terms and collocation points are introduced in practice the balance between accuracy requirement and computational cost needs to be taken into account 4 2 simulation accuracy besides examining the ability of uq using pce the accuracy of pce approximation is also assessed the streamflow ensembles from pce and mc at selected times in table 5 together with cc values are displayed in fig 7 it can be seen that the ensembles from both pce 2 and pce 3 match well with those from mc approach especially for higher streamflow simulations overall pce 3 generates higher cc values analysis of the 2008 2009 2 year simulations reveals that with pce 2 713 of 731 simulation days have cc value greater than 0 8 and 623 days with cc greater than 0 9 while with pce 3 all 731 days have cc value greater than 0 8 and 721 days with cc greater than 0 9 this indicates that the difference between pce 3 approximation and model simulation is smaller i e pce 3 is more accurate than pce 2 fig 8 displays the model simulation pce 2 approximation and pce 3 approximation at three different parameter settings a sm 49 32 ckg 0 95 cki 0 97 b sm 24 02 ckg 0 95 cki 0 97 and c sm 13 01 ckg 0 99 cki 0 91 which are randomly chosen it is noticed that the simulations from xinanjiang model pce 2 and pce 3 approximations almost overlap with each other especially pce 3 is almost identical to the model quantitatively it is found that the pce approximations are relatively well compared with xinanjiang model simulations high cc 0 9 small rmse 6 m3 s and mae 4 m3 s and a margin of bias 2 m3 s and rb 1 particularly pce 3 shows smaller rmse and mae and a smaller margin of bias and rb indicating higher order pce outperforms low order pce in surrogating the xinanjiang model compared to pce 3 pce 2 overestimates high streamflow simulations but not remarkable 4 3 computational cost the computational time is investigated in the study as well under the same computational environment it takes mc 5823 s to make 100 000 runs for a period of 731 days the computation of sampling by pce approach is divided into two parts the expansion coefficient calculation and sampling process it takes pce 2 6 s to obtain the expansion coefficients and 1654 s to finish the sampling process therefore about 69 min 71 are saved by adopting pce 2 as anticipated pce 3 needs more time 15 s for coefficient acquiring and 4662 s for sampling consequently it takes 19 min 20 less by pce 3 than mc it is worth mentioning that pce spends most of its time in evaluating the polynomial basis at 100 000 random input values in fact this task can be accomplished in advance and a lookup table could be built for reference by excluding this part in pce the sampling process can be done in less than one minute and it is irrelevant to the hydrological model which in turn saves large amount of time in conclusion pce provides an efficient way of quantifying uncertainty which is especially appealing to complex models 5 conclusions this study proposes an integrated framework for parametric uncertainty analysis in hydrological modeling by using the generalized pce approach the essence of this pce approach is to expand the model as a spectral expression in terms of orthogonal polynomials which in turn serves as a surrogate model of the specific model like xinanjiang hydrological model the selection of the polynomials is determined by the probability distribution of input parameters the generalized pce deals with not only gaussian but also non gaussian random inputs being a polynomial expression pce offers an efficient way of sampling for uncertainty assessment without actually running the hydrological model which is crucial if the model runs are computationally intensive and considerably timesaving in computational efforts may be achieved note that the samples of the random input in pce and values of the polynomial basis can be calculated in advance to construct a lookup table for future use which further saves large amount of computational time the popular xinanjiang hydrological model is used to demonstrate the applicability of pce in hydrological uncertainty analysis we used three sensitive parameters sm ckg and cki out of the 15 parameters of xinanjiang model in this study uniform distribution was assumed for the three sensitive parameters and legendre polynomials are adopted for the construction of pce non intrusive approach specifically the sc method is used to estimate the expansion coefficients in pce the collocation points are selected based on the roots of the legendre polynomials and tensor product rule is used for constructing multi dimensional collocation points daily streamflow is simulated during a period of two years from 1 january 2008 to 31 december 2009 in tar river basin both pce 2 and pce 3 are utilized to assess the uncertainties in streamflow simulation mean std skewness kurtosis and histograms from pce are compared with those from the standard mc approach results indicate that both pce 2 and pce 3 provide consistent uncertainty estimates with mc not surprisingly with more terms and more collocation points pce 3 exhibits better performance in capturing the uncertainty information than pce 2 besides the capability of uncertainty assessment the accuracy of the pce approximation of the hydrological model is investigated in this study overall both pce 2 and pce 3 are able to provide reliable approximations to long term simulations as well as extreme streamflows like the uq ability the proximity of pce 3 is slightly improved over pce 2 by reducing rmse mae bias and rb but increasing cc fig 8 a c generally the higher accuracy is achieved with more computational costs compared with mc method pce 2 saves about 70 computational time while pce 3 saves 20 considering the accuracy and computational saving pce 2 is suggested to use as a surrogate model of the xinanjiang hydrological model in the future in summary the generalized pce offers a reliable surrogate model which further provides an efficient alternative to analyze the uncertainties in hydrological modeling though uniform distribution was used to demonstrate the applicability of generalized pce in this study it can be extended to other types of distribution as well further studies related to hydrological modeling using generalized pce approach can be performed on 1 addressing the uncertainty of complex distributed hydrological models 2 improving hydrological forecasts by combining pce with data assimilation methods etc these studies are underway declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the help from dr s lakshmivarahan from the university of oklahoma and dr john m lewis from national severe storms laboratory norman oklahoma and desert research institute reno nevada this research was partially sponsored by the 100 top talents program 74110 18841203 at sun yat sen university guangzhou guangdong china and by the national natural science foundation of china 41675109 41875182 the authors thank the editor and the anonymous reviewer for their constructive comments to improve this paper 
