index,text
23885,this work presents simulations of ocean circulation in the southwestern south atlantic ocean with emphasis on the são paulo plateau region a unique physiographic feature at the foot of the continental slope offshore southeast brazil where the flow is dominated by ocean eddies and dipoles surface dynamics south of 23 s presents a heterogeneous circulation pattern intimately related to the presence of mesoscale features such as meanders of the brazil current along the continental slope and eddies that interacts with deep ocean features the reproduction of these eddies at the correct time and spatial structure are quite challenging in the context of a non assimilative model considering the limitations imposed by the model s numerical schemes physical parameterizations boundary conditions and surface forcing in this sense the regional ocean modeling system roms 4 dimensional variational data assimilation 4d var module was used to increase model skill and minimize deviations from oceanic observations weekly observations of sea surface height ssh daily sea surface temperature sst fields and in situ vertical profiles of temperature and salinity from multiple sources were used in consecutive assimilation cycles to produce an accurate representation of ocean features and their variability both the assimilative and free run were evaluated against observations including in situ current measurements results showed significant improvements of the assimilation procedure on both assimilated and non assimilated variables with rmse reductions of 27 and 47 for sst and ssh respectively and 51 for current speed measurements during a dipole event in the são paulo plateau the assimilative run was able to reproduce a remarkable event of mesoscale eddies interaction dipole and consequent current intensification leading to important improvements on model skill the correct use of observational information of open ocean surface features through data assimilation is a key factor for a proper simulation of such eddy dipole events keywords são paulo plateau oceanic eddies data assimilation roms 4d var 1 introduction the são paulo plateau is a unique physiographic feature of the southeast brazilian continental margin it is a low declivity region located between the 2000 m and 3000 m isobaths approximately 2 degrees apart and zonally from 21 s just south of the vitoria trindade ridge to 28 s de almeida and kowsmann 2016 kumar et al 1977 kumar and gambôa 1979 this study is concerned with the ocean circulation in the são paulo plateau region south of 23 s approximate latitude of cape frio where the coastline orientation has an abrupt change from ne sw to e w fig 1 in this southern stretch the plateau has a large width greater than 300 km on average it is a region of intense mesoscale eddies activity andrioni et al 2012 the surface ocean circulation off southeast brazil is marked by the presence of the brazil current bc the western boundary current associated with the sverdrup balance of the wind driven south atlantic subtropical gyre originated from the bifurcation of the south equatorial current sec the bc flows southward approximately following the continental slope stramma and england 1999 along its path the bc develops intense mesoscale activity and large meanders that sometimes encloses eddies the mechanism of baroclinic instability is one of the main drivers of such mesoscale activity da silveira et al 2008 rocha et al 2014 the most recurrent eddies of this kind are found off cape são tomé 22 s and off cape frio 23 s feature oriented numerical modeling has been applied to study these eddies calado et al 2008 2006 reinforcing the point that the use of observational data hydrographic current meter and satellite data and numerical models are powerful tools to understand and study these mesoscale features along the southeast brazilian continental slope south of 23 s on the so called southeast brazilian bight sbb which extends from cape frio to cape santa marta 28 s the bc meanders and its eddies can induce shelf break upwelling events campos et al 2000 distinct methods were used to evaluate the brazil current structure and velocities on this region biló et al 2014 observational data both direct measured adcp current velocities as well as derived geostrophic velocities from ctd and xbt data along transects have shown that the bc meanders along its path on the continental slope from 23 s to 28 s belo 2011 biló et al 2014 but it does not dominate the deep ocean circulation on the são paulo plateau further offshore the ocean circulation on this plateau was evaluated by belo 2011 with a series of measured current and hydrographic transects revealing a pattern of successive eddy structures these vortical features can sometimes be enhanced by the cape frio cyclonic eddy coupled with westward propagating anticyclonic features leading to the formation of an eddy dipole structure and generating a strong intensification of surface currents in its middle section the dipole structure commonly moves in the south southwest direction and significantly changes the circulation pattern of the são paulo plateau this seems to be a recurrent feature as its surface signature can be frequently observed in satellite derived sea surface height andrioni et al 2012 the plateau acts as a natural eddy corridor where dipoles gradually move westward as shown in fig 2 where a sequence of snapshots of sea surface height and geostrophic velocity fields during august and september 2010 is presented an intense cyclone centered at 25 s 43 w in the first snapshot is joined by an anticyclone giving rise to a strong dipole its bounds are roughly indicated in fig 2 by the black dashed line circle its influence on currents behavior as will be shown later could be captured by a current meter mooring the p1 mooring indicated by the red square the purpose of this work is to assess the impact of data assimilation on the simulation of eddy dipoles at the são paulo plateau and not to identify their possible local or remote driving mechanisms however besides the local baroclinic instability mechanism discussed earlier it has been observed that the arrival of westward propagating agulhas current eddies can contribute to generate enhanced dipole structures guerra et al 2018 also the vorticity contribution of rossby waves reaching the western boundary of the south atlantic can contribute to the modulation of the bc transport as well as its meandering and eddy activity majumder et al 2019 considering that the generation of dipole structures may depend on the conjugation of many distinct mechanisms a precise reproduction of these features in time and space is a challenging task for a non assimilative model in fact inaccuracies in the bathymetry representation initial conditions lateral boundary conditions and surface forcing as well as limitations of sub grid processes parametrization may introduce large uncertainties lima et al 2019 and contribute to deviations of the numerical simulations from the ocean real state despite the limitations imposed by the numerical nature of the simulation there must exist an optimum state or initialization field that minimizes the differences between model and observations finding these states and or initial conditions is the core of the data assimilation methods and it is a requirement if one is interested in simulating and forecasting high variability mesoscale features other studies have shown a positive impact of assimilation on the simulation of the ocean circulation at the southeast brazilian oceanic region da rocha fragoso et al 2016 lima and tanajura 2013 tanajura et al 2016 2015 due to the importance of data assimilation to operational oceanography and physical oceanography the oceanographic modeling and observation network remo portuguese acronym for rede de modelagem e observação oceanográfica was established in 2007 lima et al 2013 the main goal was to implement an operational forecasting system in the brazilian navy hydrography center chm with focus on the south atlantic efforts were first dedicated to build a data assimilation system into the hybrid coordinate ocean model hycom santana et al 2020 tanajura et al 2020 another effort is also being conducted by the present work under remo to explore the regional ocean modeling system roms with the 4 dimensional variational data assimilation 4d var method moore et al 2011b in the southwestern atlantic several works have demonstrated this system s capacity to produce accurate representation and forecasts in regions of high oceanic variability da rocha fragoso et al 2016 lee et al 2018 moore et al 2011a powell et al 2008 the present work aims to describe the implementation of roms primal formulation of incremental strong constraint 4d var over the southwestern atlantic to investigate the ocean circulation at the são paulo plateau region particularly to simulate its characteristic mesoscale eddies a particular event of an intense observed dipole structure that occurred in september 2010 is used to assess the impact of the data assimilation in model skill especially its ability to reproduce the dipole with the correct spatial and time scales as well as their associated intense currents the paper is organized as follows section 2 describes the model setup the data assimilation system and the assimilated observations section 3 presents simulation results with particular emphasis in model skills and in improvements achieved with assimilation including comparisons with non assimilated variables and observations as well as global reanalysis products section 4 summarizes the main aspects and conclusions of this study 2 modeling framework 2 1 model description and free run setup the model employed in this study is the regional ocean modeling system roms revision 904 along with the incremental strong constrain 4d var better described in the next section roms is a split explicit free surface 3d primitive equation and terrain following vertical coordinate oceanic model and has been widely use by the oceanographic community a comprehensive description of roms and its 4d var formulations can be found in shchepetkin and mcwilliams 2005 2003 and moore et al 2011b the domain encompasses the entire brazilian southeastern oceanic region within the longitude and latitude ranges of 50 5 w 32 5 w and 30 0 s 13 0 s respectively as shown in fig 1 this region was horizontally discretized with 217 by 222 grid points resulting in a 1 12 horizontal resolution 9 km the vertical discretization is made with 32 vertical layers an enhanced resolution at the surface is achieved by the use of the surface and bottom stretching parameters θ s 7 0 and θ b 0 3 and the critical depth parameter t c l i n e 30 m initial and boundary conditions come from the operational mercator global ocean 1 12 physical analysis and forecast copernicus marine and environmental services cmems daily means lellouche et al 2018 these fields are linearly interpolated by roms during execution to get boundary data at each model time step in order to avoid discontinuities and provide a smooth transition between inner and boundary fields we follow the scheme proposed by penven et al 2006 where roms bathymetry near the open boundaries is gradually adjusted to match the outer global model grid the distance from the boundaries where the transition begins was set to 40 km which is close to the internal rossby radius of deformation for this region also a 160 km sponge layer with increasing viscosity and diffusivity factors of 20 and 10 respectively was implemented to suppress numerical noise at the boundary being the explicit viscosity and diffusivity coefficients set to 4 m2 1 mixed radiative nudging boundary conditions marchesiello et al 2001 with a 1 day timescale were chosen for tracers and baroclinic momentum chapman chapman 1985 implicit and flatter flather 1975 boundary conditions were used for the free surface and barotropic velocities respectively and a gradient boundary condition is set for the mixing turbulent kinetic energy this choice of boundary conditions in combination with the sponge layer is efficient to propagate inertial signals generated within the model domain and suppress any numerical noise due to radiation of signals not resolved within the daily averaged boundary data the unresolved subgrid scale vertical processes were parametrized with the mellor and yamada 1982 turbulent closure scheme my level 2 5 coded in roms the bottom topography is derived from a 1 arc minute global relief model etopo 1 with corrections performed by the hydrography center of the brazilian navy from nautical charts and in situ surveys the raw bathymetry presents regions of very steep topographic features particularly the continental shelf break along cape são tomé the abrolhos bank and the vitoria trindade ridge see fig 1 such features were leading to baroclinic pressure gradient errors long known to happen in sigma coordinate models mellor et al 1998 and had to be smoothed in respect to the slope parameter r δ h 2 h beckmann and haidvogel 1993 to reduce these errors to acceptable levels however commonly used smoothing techniques such as two dimensional gaussian filters were leading to a large displacement of the continental shelf break and consequently the core of the western boundary circulation this shift in the average position of the bc system produced in preliminary runs resulted in large initial conditions increments at each assimilation step even after several consecutive cycles thus the smoothing procedure employed here was the linear programming approach proposed by sikirić et al 2009 which was able to simultaneously achieve a value of r lower than 0 25 everywhere with a minimum modification to the original topography another common issue of sigma coordinate models detected in the model setup runs is the numerical attenuation of deep isopycnals caused by numerical diffusion of tracers marchesiello et al 2009 the use of less diffusive higher order tracer advection schemes instead of the standard upstream 3rd order horizontal advection available in roms along with explicit biharmonic laplacian viscosity and diffusion showed marginal improvements in this matter the split scheme proposed by marchesiello et al 2009 worked well for the free run at the cost of external timestep reduction but became unstable in the forward runs of the nonlinear model during the very first assimilative cycle to address this issue the multidimensional positive definite advection transport algorithm mpdata tracer advection schemes were used and a depth dependent nudging scheme was adopted this scheme consists of adding an additional term to the right hand side of the prognostic equations of temperature and salinity with the form δ t τ ϕ c l m ϕ where δ t is the model time step in seconds τ x y z is the relaxation time scale in seconds ϕ x y z t is the tracer variable and ϕ c l m x y z t is the tracer climatological value towards which the variable will be relaxed in this work monthly means calculated from 10 years 2007 to 2016 of the global mercator analysis were used as climatological fields a stronger nudging timescale of 30 days was set below 800 m to preserve deep water masses throughout the simulation and a very long timescale of 1080 days was used above 400 m to achieve a smooth transition between these two timescales a logistic function was applied this nudging scheme was used on both free and assimilative runs given that very few observations of subsurface fields were available to be assimilated surface boundary conditions were taken from the european centre for medium range weather forecast ecmwf era 5 reanalysis hersbach et al 2020 with 31 km horizontal resolution era5 hourly fields of 10 m wind velocity components temperature relative humidity incoming short and longwave radiation fluxes and precipitation rate were used to compute momentum heat and mass fluxes the surface fluxes are computed using bulk formulas of liu et al 1979 and fairall et al 1996a b no tidal forcing was employed in this model application as tidal signals are very weak at the são paulo plateau our main interest region when compared to signals associated with mesoscale features the model was then run for 6 years from october 2008 to january 2015 the resulting fields were used to compute all statistics necessary for the assimilation run as detailed below 2 2 data assimilation system a 4d var system available in roms was used in this work roms provides three variants of the 4d var a primal formulation of incremental strong constraint 4d var i4d var a dual formulation based on a physical space statistical analysis system 4d psas and a dual formulation representer based variant of 4d var r4dvar moore et al 2011b in the strong constraint approach the model physics is considered perfect and the model errors are thus neglected zhang et al 2010 when model errors are admitted 4d var is said to be subject to a weak constraint imposed by the model dynamics moore et al 2011b we made use of the i4d var and a brief description of the concepts that turned out to be most relevant to this application is presented below the main objective of the i4d var data assimilation is to estimate the increments to the model state vector x t i ζ t s u v t at a time t i comprised of all prognostic variables sea surface displacement ζ potential temperature t salinity s and horizontal velocity components u and v and subject to surface forcing conditions f t i for momentum heat and freshwater fluxes and lateral open boundary conditions b t i that minimizes in a least squares sense the difference between the model and observations li et al 2015 this difference is mathematically expressed in the form of a nonlinear cost function j n l neveu et al 2016 1 j n l 1 2 z z b t d 1 z z b j b n l 1 2 y o h z t r 1 y o h z j o n l where z x t 0 t f t t b t t and z b x b t 0 t f b t t b b t t are the posterior and background control variables vectors respectively d is the background error covariance matrix y o is the observation vector h is the nonlinear operator that projects the state vector into the observation location and r is the observational error covariance matrix the cost function is composed of two terms j o n l and j b n l which represent respectively the distance or misfit between the adjusted model z posterior or analysis and the observations and the distance between the model and its background z b or prior solution this first guess of the ocean state is obtained from a nonlinear model nlm run which can be a non assimilative or assimilative run the nonlinear cost function may possess several local minima so that numerous solutions to z are possible however assuming that the background estimation z b is sufficiently close to an optimum state a gauss newton method approach may be used to transform the nonlinear problem into a sequence of linear minimizations through the so called inner and one or more outer loops the reason for executing multiple outer loops is that it is sometimes necessary to update the nlm trajectory in order to account for non linear effects that arise in the flow during the assimilation period powell et al 2008 the analysis is obtained in terms of small successive increments δ z to the prior estimation 2 z k z b l 1 k 1 δ z l where k refers to the k th outer loop iteration index and δ z l are the increments from all previous outer loops given by δ z l δ x t 0 l t δ f l t δ b l t neveu et al 2016 thus the linearized cost function in its incremental form is given by 3 j 1 2 δ z t d 1 δ z j b 1 2 d g δ z t r 1 d g δ z j o where g is the linear operator that samples the tangent linear model tlm at observation locations d y o h x b is the innovation vector the difference between the first guess and the observations and r is the observation error covariance matrix matthews et al 2012 the background error covariance matrix is assumed to be time invariant and block diagonal so that d d i a g b x b f b b where b x b f and b b are the full multivariate prior error covariance matrices of the initial conditions surface forcing and open boundary conditions neveu et al 2016 these matrices penalize departures of the increments from the original background and act as regularization term by spatially smoothing the updated fields zavala garay et al 2012 due to its high dimensionality in the order of the number of variables in the 3d grid squared the b x matrix is factorized and expressed as 4 b x k b σ x c σ x k b t where k b is the multivariate balance operator σ x is the diagonal matrix of standard deviations computed from a model run and c is a matrix of univariate correlations that are modeled as solutions of a diffusion equation broquet et al 2009a moore et al 2011b k b is responsible for transferring observational information among model variables and is critical for extracting information about unobserved variables from directly observed quantities weaver et al 2006 this is most commonly done through the use of dynamical and physical relationships between variables in roms geostrophic and hydrostatic balance are used to construct the multivariate balance operator the background error covariance matrices for surface forcing b f and open boundary conditions b b do not include a balance operator and are simply factorized by σ f c f σ f t and σ b c b σ b t respectively neveu et al 2016 the background error correlation matrix c is given by 5 c c h c v with 6 c h λ h l h 1 2 w h 1 l h 1 2 t λ h 7 c v λ v l v 1 2 w v 1 l v 1 2 t λ v where λ is a diagonal matrix of normalization coefficients required to ensure that c values are between 1 w is a diagonal matrix with elements corresponding to the grid box areas in the case of w h and level thicknesses in the case of w v l represents the action of the matrix obtained by solving either a 1d for l v or 2d for l h diffusion equation moore et al 2011b the normalization coefficients of λ are the costliest part of the covariance modeling but fortunately must be computed only once given that the vertical and horizontal correlation lengths do not change to illustrate how the modeled background error correlation operates in a single adimensional observation fig 3 shows the horizontal and vertical amplitudes of a point perturbation in the são paulo plateau when convolved with c a state variable is perturbed at the surface and the signal spreads horizontally fig 3a and b and vertically fig 3c and d through c h and c v this allows the observational information to spread spatially in the 4d var assimilation isotropic correlation length scales for the state variable used in this example are 100 km in the horizontal and 50 m in the vertical the minimization of j involves the computation of the gradient j j δ z demanding the calculation of the transpose of very large and sparce matrices and thus roms makes use of the adjoint model adm and a preconditioned lanczos formulation of the conjugate gradient method this method is also used in the estimation of the background error covariance matrices considering m a finite number of inner loops and k a finite number of outer loops the assimilation cycle begins with the initialization of the background control variables vector z b obtained from a nlm run and the initial increment δ z k 0 m 0 is set to zero the operator g and its transpose are found through the execution of the tlm and adm along a certain time window after computing the error covariance matrix r the gradient of j is then calculated a forward and a backward integration of the tlm along with an update of the gradient is performed in order to estimate the optimum increments if the maximum number of inner loops has not been reached the value found for the increments is used in the next inner step otherwise a nlm run is executed using the initial background fields added with the newly estimated increments then if the maximum number of outer loops has not been reached a new round of inner loops is done using the updated nlm solution as starting point for the estimate of the δ z otherwise this last nlm run is the analysis z a which consists of the final result of the assimilation cycle 2 3 data assimilation setup in this work an assimilation time window of 7 days is used tests performed for few consecutive cycles using intervals of 4 and 14 days not shown similar to powell et al 2008 revealed that the shortest window although presenting highest accuracy to observations has large discontinuities between cycles which is undesirable in this regard the differences between 14 and 7 days intervals were small additionally shorter integration cycles are less prone to violations of the tangent linear assumption than longer time intervals also a second level of preconditioning with 2 ritz vectors is used to further reduce final nonlinear cost function as discussed in moore et al 2011a the first assimilative run was initialized from a daily mean of the cmems operational mercator global ocean 1 12 physical analysis and forecast for 01 january 2010 and 52 consecutive cycles were then executed to obtain a 1 year analysis run as sketched in fig 4 initial and boundary conditions as well as surface atmospheric forcing wind drag and heat fluxes were subject to corrections in this setup of roms i4d var module the update frequency for surface forcing and lateral boundary increments was set to 1 and 12 h respectively the diagonal matrices of standard deviations σ x σ f and σ b were all computed from the 6 year free run surface wind stress components net heat and salt fluxes were stored during roms free run execution to allow estimations of surface forcing standard deviations for lateral boundary conditions standard deviations were estimated from boundary grid points variability the balance operator k b was disabled because it was leading to unstable solutions in the bottom salinity field over the continental shelf nonetheless the linearized dynamics embodied in the roms tangent linear and adjoint effectively allows the transfer of information between variables during the assimilation procedure neveu et al 2016 in fact a positive impact over non assimilated variables could be achieved as it will be later demonstrated for the modeling of the background error correlation matrix c table 1 summarizes the values adopted as decorrelation scales for initial and boundary conditions and for surface forcing usual starting points for these scales can be based on the internal rossby radius of deformation or more sophisticated approaches like semivariogram techniques matthews et al 2011 but some experimentation for fine tuning is usually required thus most of the values adopted here follow da rocha fragoso et al 2016 who also applied the 4d var assimilation in a similar domain except for the vertical decorrelation lengths which were reduced to avoid excessive subsurface perturbation an issue that is discussed by broquet et al 2009a tracers and momentum advection schemes for both nlm and adm were set to the default 3rd order upwind horizontal and 4th order centered vertical schemes which proved to give the most stable solution the boundary conditions for the nlm were kept the same as described in section 2 1 for the adm mixing radiative nudging boundary conditions are not coded so that clamped boundary conditions were used for temperature salinity and 3d momentum the choice of the number of inner and outer loops was based on preliminary results of a 1 year i4d var integration in which 2 outer loops and 25 inner loops were used this first experiment was able to minimize the cost function in all cycles although much of the minimization was achieved in the first 8 to 14 inner loops also subsurface perturbations were detected in this solution probably due to an overfitting to the observations as the errors between the analysis and assimilated observed data mostly at the surface were deemed too low although other factors may lead to such issue like small observational errors inconsistent decorrelation lengths and other model setup parameters the decrease in the number of inner loops in this case significantly reduced the problem the use of 1 outer loop over 2 was also tested but lead to much inferior results in terms of model skill indicating that non linearities play an important role in this particular application the combination of 2 outer loops and 8 inner loops was then used throughout the simulations the experiments were run in a linux computational cluster using 8 nodes each containing 16 intel r xeon r e5 2670 2 60 ghz cores resulting in the allocation of 128 processors per run with this setup each of the 52 assimilative cycles spanning 7 days of simulation took about 3 5 h this gives about 182 h of computational time to fulfill an entire year putting these numbers in perspective the 6 year free run consumed 40 h when executed with the same number of processors and at the same machine however very recent improvements in roms source code including the implementation of a single precision kernel in some of the subroutines and parallel io capability might substantially reduce the computational overhead of the 4d var assimilation 2 4 assimilated data the data sets assimilated into roms are griddedsatellite altimetric observations of sea surface height ssh sea surface temperature sst and in situ vertical profiles of temperature and salinity t s some of these data sets were also used in the skill assessment presented below fig 5 shows monthly availability of each observation type within the entire modeling domain during the year of 2010 the vast majority of the data are surface observations daily sst observations are the most abundant with more than 700 thousand values per month followed by weekly ssh with about 100 thousand observations per month in situ temperature and salinity vertical profiles are much less numerous with an average count of 1 thousand temperature and 1 thousand salinity measurements per month ssh data is obtained from the project altimetry tailored and optimized for brazilian applications atoba developed by the french institute collecte localisation satellites cls this project was conceived under the framework of remo initiative lima et al 2013 and consists of refined and gridded weekly fields of 1 12 resolution sea level anomaly sla and absolute dynamic topography adt measured from multiple altimetry satellites over the entire south southeastern region offshore brazil this data set has greater mesoscale energy in continental shelf and slope regions when compared with data made available globally by aviso daher and junior 2014 a time space average of the adt computed for the entire time range of the data 1993 2013 is subtracted from the weekly adt fields and the time space average of the 6 year roms free run is added to make observed and model reference levels compatible the resulting ssh weekly fields were linearly interpolated to a daily basis to improve data availability and masked over depths shallower than 200 m although the development of the fastest growing perturbations of the bc which double its size each 8 to 16 days biló et al 2014 da silveira et al 2008 might not be precisely represented by a weekly ssh gridded product it can comfortably resolve the typical mesoscale timescales of the region 100 days goes et al 2019 and the eddy field evolution over the são paulo plateau that spans several weeks for example the eddy dipole event reported in this work occurs at time scales of 30 days or more as depicted in the sequence of ssh snapshots of fig 2 eddies and meanders found in the region have typical lengths from 100 km to 400 km belo 2011 calado et al 2006 fernandes et al 2009 the horizontal resolution of the ssh data is about 8 km approximately a quarter of the internal rossby radius of deformation for the region 30 km and is adequate to resolve the local mesoscale dynamics daily sst was obtained from operational sea surface temperature and sea ice analysis ostia ostia uses satellite data provided by the group for high resolution sea surface temperature ghrsst project together with in situ observations and optimal interpolation oi to produce a continuous and gap free analysis of the global foundation sst with 1 18 resolution donlon et al 2012 sst data were masked in regions shallower than 200 m to avoid degradation of strong upwelling events adequately reproduced by roms but underestimated by ostia no corrections due to diurnal warming cycle were made the in situ ts vertical profile data came from multiple sources including argo floats roemmich et al 2019 and shipboard ctd conductivity temperature and depth sensor measurements fig 6 shows the distribution of in situ ts vertical profiles the ctd data were collected by petrobras and the brazilian navy and were kindly supplied for this study most of argo float data are concentrated in water depths greater than 1000 m while the shipboard ctd transects covering the continental shelf and the deep ocean were obtained from the ceres iv oceanographic cruises belo 2011 a total of 1147 ts profiles were assimilated by roms for the determination of the observation error covariance matrix r the observations errors adopted are summarized in table 2 along with other relevant information to facilitate pre processing of in situ profiles argo floats and shipboard ctd instrumental errors were assumed equal misrepresentation errors associated with processes not resolved by the model physics and the representativeness error associated with the ability of a single observation to describe the circulation in a single model grid are difficult to estimate da rocha fragoso et al 2016 thus the choice of these values was made primarily considering the instrumental precision of each data source and the values commonly found in the literature broquet et al 2009a da rocha fragoso et al 2016 neveu et al 2016 powell et al 2008 zavala garay et al 2012 zhang et al 2010 slight modifications were then made to achieve an optimum balance between the weight of observations and the background in the cost function minimizing procedure for instance the choice for ssh error of 0 02 m considered the usual measurement precision associated with altimetric data broquet et al 2009b and it was used in similar studies broquet et al 2009a da rocha fragoso et al 2016 moore et al 2013 the results of sensitivity tests using observational errors up to 0 04 m and the better performance of the atoba data set with respect to global altimetric gridded products in the region of the bc pita et al 2020 indicated that the value adopted was a reasonable choice following moore et al 2011a neveu et al 2016 and powell et al 2008 all observations within each model grid cell over a 6 h time window were combined into the so called super observations to reduce data redundancy the largest error within the same variable and grid cell is used the gridded ssh and sst data are assimilated at the observation time 00 00 for ssh and 12 00 for sst the temperature and salinity profiles are assimilated at 00 00 06 00 12 00 or 18 00 as a result of the binning procedure 2 5 model skill assessment the metrics used to assess model skill and the assimilation performance were the cross correlation cc the root mean square error rmse and the error bias eb defined as oke et al 2002 8 c c 1 s ˆ s 1 n i 1 n y ˆ i y ˆ y i y 9 r m s e 1 n i 1 n y ˆ i y i 2 10 e b 1 n i 1 n y ˆ i y i where y ˆ i and y i are the i th modeled and observed quantities of a variable s ˆ and s are the respective standard deviations and the overbar denotes the average over all sample points 3 results and discussion 3 1 assimilation performance to monitor the operation of the i4d var assimilation procedure it is useful to analyze the cost function over consecutive cycles fig 7a shows the behavior of the tlm cost function during inner loop iterations of all assimilative cycles and fig 7b the final tlm j and nlm j n l cost functions at the end of the minimization algorithm the variables are normalized by their values at the beginning of each cycle a decrease in j is achieved in all cycles indicating that the system is behaving correctly the jump of j at the tenth iteration is associated with the update of the nlm fields over which the tlm operates during the second outer loop the initial value of both the tlm and nlm cost functions is reduced to about half at the end of the minimization algorithm although the final reduction of j n l is always lower than that achieved for j which is expected due to the effects of nonlinearities the consistent reduction of both functions shows that the minimization algorithm is working properly during all assimilation cycles the average initial conditions increment i e the mean of the differences between posterior analysis and prior surface fields at the beginning of each cycle are shown in fig 8a to c the evolution of these increments across consecutive i4d var integrations are also shown in fig 8d to e for the surface temperature and salinity regions with the highest average increments are over water depths shallower than 1000 m on the continental shelf and slope these areas present intense mesoscale activity and these increments perform the correction of the bc density gradient position it is interesting to note that for latitudes lower than 23 s there are positive average increments close to the coast and for higher latitudes negative increments we speculate that the smoothing procedure in latitudes lower than 23 s where bathymetry is steeper than in higher latitudes inevitably causes a shift of the bc core and consequently imposes temperature and salinity signatures at the surface for ssh the spatial average increments are mostly positive indicating that despite the offset correction of the observations to match the model reference level a slight difference might persist we credit this to changes in the advection schemes used for the 6 year free run over which the model sea surface elevation reference level was calculated and the nlm setup used in the assimilative run another possibility that was not further investigated is the existence of biases sourced in the background error covariance matrix d which is constructed from values of the 6 year roms free run standard deviations it is worth to note major increments over the são paulo plateau and south off the vitoria trindade ridge where intense mesoscale eddy activity not entirely captured by the free run occurs despite the existence of regions with relatively large corrections the area average of the absolute value of increments at the initial conditions of each cycle are less than 0 3 c for sst 5 cm for ssh and 0 1 for salinity also the domain averaged increments do not present any growth trends in consecutive cycles indicating that the prior estimates are consistently close to the observations fig 9 presents magnitude and spatial patterns of the increments made to surface wind stress and surface heat flux throughout the assimilation cycles the adjustments in surface wind stress are of the order of 10 4 n m 2 with major corrections on the continental shelf north of 23 s where a weakening tendency of the along shore north and northeast winds associated with coastal upwelling is identified this is possibly due to the fact that assimilated sst from ostia underestimates the magnitude of the temperature drop in the upwelling peres et al 2017 which is controlled by the wind and is well represented by the model dynamics the averaged heat flux adjustments are towards surface cooling in most of the domain especially near the eastern boundary and surface heating in a small portion of the continental shelf between 17 s and 24 s these corrections are in the order of 6 w m 2 during the eddy dipole period in august and september 2010 fig 10 there is a positive heat flux adjustment in the são paulo plateau east of 43 5 w and a negative correction west of this meridian which is compatible with an increase of sea surface gradients through thermal expansion no significant spatial differences between the surface wind stress corrections during the eddy dipole period and the annual mean were identified but slight increase or reduction of the wind stress on distinct regions of the domain a final assessment of the assimilation performance might be done in light of error statistics calculated at the end of each assimilative cycle the panel shown in fig 11 presents the behavior of all these error metrics over the 1 year roms i4d var integration the cc of all assimilated variables fig 11a are higher than 80 over the entire period sst and subsurface temperature followed by salinity are the best correlated variables with cc higher than 90 all year long sst presents the most stable cc timeseries with values consistently higher than 95 possibly because it is the most frequently assimilated variable another possibility for the excellent quality of sst may be associated with the fact that it is also driven by surface air temperature so that the atmospheric forcing may efficiently contribute to produce accurate ssts however this is not the case of ssh for this variable cc has an initial value of 94 at the very first assimilative cycle then it slowly reduces oscillating around 90 reaching a minimum of 85 during the cycles of november and increasing again to 90 level at the last cycles this behavior is more or less accompanied by both eb and rmse which present peaks at the same periods when cc is lower the model bias previously identified from the averaged ssh increments is clearly seen in fig 11b where a constant negative bias in the surface elevation is present in most of the cycles the same picture can be depicted on subsurface temperature and salinity fig 11c and d indicating that roms has a cold and lower salinity bias with maximum values of 1 2 c and 0 2 respectively the rmse ranges between 2 and 4 cm for ssh fig 11e 0 2 c 0 5 c and 0 4 c 2 5 c for sst subsurface temperature fig 11f and 0 2 and 0 4 for salinity fig 11g however error estimations of subsurface temperature and salinity might not be very accurate as the number of observations is considerably smaller than those for ssh and sst these variations in the error statistics timeseries are expected due to natural variability of the number of available observations in each assimilation cycle even after interpolating ssh observations to a daily basis to improve the frequency in which this variable is assimilated as explained in section 2 4 the error of the gridded weekly fields is not constant and may be increased over periods of higher mesoscale activity or due to the presence of features for which time and spatial scales could not be adequately captured by the satellite track nonetheless no significant trends in cc rmse or eb were identified and the error magnitudes are low corroborating that the assimilation procedure was working as expected 3 2 impact of assimilation on assimilated variables the comparison of roms i4d var results with assimilated data is useful to diagnose if the assimilation algorithm is converging and if j o the misfit between the model and observations is actually being reduced however a better picture of the impact of data assimilation procedure is achieved by including the free run results in the evaluation of the error statistics and using independent observations not assimilated whenever possible for an unbiased skill assessment fig 12 presents sst and ssh rmses for the free non assimilative run the prior and the posterior circulation for the year of 2010 to compute sst model errors the multi scale ultra high resolution mur sea surface temperature analysis a data set that was not assimilated into roms was used mur presents daily sst estimates on a global 0 01 0 01 grid featuring the 1 km resolution modis retrievals which are fused with avhrr gac microwave and in situ sst data by applying internal correction for relative biases among the data sets chin et al 2017 thus the mur fields may not be considered a fully independent data set as data coming from avhrr are also used in ostia analysis assimilated in the present experiment for the ssh errors aviso atoba weekly absolute dynamic topography fields assimilated into roms were used prior to this error estimation sea surface heights from both the observations and model were masked out for water depths shallower than 200 m and were subtracted by their spatial and time average over the entire period the rmse values between roms and mur sst are mostly in the range between 0 and 1 c for both the free and assimilative runs for the free run fig 12a highest errors are concentrated at coastal regions above the latitude of 23 s and at upwelling sites where the rmse is higher than 2 c with smaller magnitudes the west and south boundaries and significant part of santos basin show rmse values up to 1 c the prior fig 12b and posterior fig 12c fields have similar patterns though considerably smaller errors occur particularly for the last one the regions with largest errors indicate an intrinsic bias source at this model setup which could be minimized but not entirely corrected by the assimilation procedure either way substantial error reductions are achieved over the entire domain the area averaged rmses for sst are 0 64 0 57 and 0 47 c for the free run prior and posterior respectively corresponding to a reduction of 27 in the rmse achieved by the assimilation for ssh the assimilation impact is even more evident the free run fig 12d presents rmses up to 0 13 m while the prior fig 12e and posterior fig 12f fields maximum rmse are about 0 09 m and 0 05 m respectively these errors are concentrated over the são paulo plateau in water depths larger than a 1000 m where mesoscale activity due to the interaction of energetic eddies is intense such as the dipole structure described in section 1 the free run cannot correctly capture these features in space and time and produces larger errors the roms i4d var system is able to substantially mitigate this model limitation so that the ssh rmse is reduced by more than 50 over the são paulo plateau a comparison of the prior and posterior ssh rmse fields shows relatively larger differences than those for the sst rmse fields possibly due to the same data source be used for assimilation and to compute error statistics also ssh is not as efficiently constrained by atmospheric forcing as sst the area averaged rmses for ssh are 0 054 0 04 and 0 028 m for the free run prior and posterior respectively thus an average reduction of 48 in the ssh rmse over the entire domain is achieved with the assimilation subsurface fields are also affected by assimilation fig 13 shows rmse and eb estimates between roms and all vertical temperature and salinity profiles assimilated see fig 6 the largest errors occur near surface in water depths of about 100 150 m this can be related to errors in the representation of the mixed layer depth in the region the ocean surface boundary layer is a region of intense heat and momentum exchange with many sub grid processes it is naturally more challenging for the model to appropriately reproduce its dynamics lying solely in its vertical mixing parametrization and bulk fluxes formulations the rmse between the free run and observed temperature profiles grows from less than 1 5 c near surface to about 2 0 c at 100 150 m the same pattern occurs for the assimilative runs although the maximum rmse is slightly reduced between 150 m and about 800 m temperature rmse is smaller after assimilation the rmse for salinity also peaks at 100 150 m with 0 4 for the free run and 0 3 for the assimilation runs between 300 m and 900 m the rmse is smaller for the free run this result is in line with other modeling studies carried out over approximately the same region such as those by da rocha fragoso et al 2016 who report peak rmses for temperature 1 to 2 c and salinity 0 2 0 4 between 100 and 200 m water depth similar results were also obtained by santana et al 2020 with an ensemble optimal interpolation scheme into hycom in their work the maximum temperature salinity rmses in the free run and in the assimilation run were attained at the 150 m depth about 1 9 c and 1 0 c 0 26 and 0 18 respectively below 1000 m both the free and assimilative runs perform equally we credit this to three factors the first is the choice of the advection scheme for tracers where the upwind 3rd order advection was used during the assimilation cycles instead of the mpdata used in the free run the latter is more effective in preserving the subsurface density gradients while the former tends to smooth density fronts leading to larger errors the second is the choice of the observational errors for the in situ temperature 0 4 c and salinity 0 1 profiles slightly higher than most of the values found in the literature giving less weight to these observations in the minimization procedure lastly the nudging procedure described in section 2 1 for both the assimilative and free runs leads to identical behaviors in water depths greater than 1500 m for the temperature eb the assimilation impact is more pronounced a warm bias of up to 1 5 c in the free run at 200 m gives place to a cold but lower bias of 1 c after assimilation the eb reduction in the prior and posterior salinities are more consistent with almost zero bias from surface down to 150 m against a positive bias of 0 3 of the free run between 300 and 900 m the eb of the assimilative runs are positive and slightly greater than those of the free run below 1000 m all simulations present biases of the same order that vary between 0 15 the prior and posterior show similar error statistics fig 14 illustrates the impact of the 4d var assimilation of shipboard ctd profiles in a subsurface temperature vertical section the transect presented is one of the ceres iv oceanographic cruise radials at the são paulo plateau belo 2011 the free run shows a tendency of thermocline deepening particularly at the upper continental slope and shelf break where free run modeled temperatures are consistently higher than observations at the bottom and intermediate levels this deviation is significantly reduced by assimilation which raises the isotherms and smooths near surface temperature gradients associated with the bc front the cold bottom shelf waters observed in the ctd data in the first 100 km of the transect are better reproduced in the posterior between depth levels of 500 and 1000 m assimilation increased temperature gradients as illustrated by the downward tilting of the 10 c and 5 c isotherms below 1000 m no significant changes between free run and posterior are observed in the temperature field showing that ctd observed data were close to climatology for deep layers 3 3 impact of assimilation over non assimilated variables beyond improvements to assimilated variables the i4d var data assimilation does modify the behavior of non assimilated state variables in this case the horizontal velocity components the correction of surface elevation gradients temperature and salinity fields as well as surface stress and heat flux indirectly affects velocities through the pressure gradient term and viscous stress terms of the momentum balance equations fig 15 shows averaged cross sectional velocities for the same time period and similar transect of the ceres iv cruise presented in fig 14 this location is particularly interesting as the bc and the intermediate western boundary current iwbc are well established and the interaction of this current system with topography in a point where coastline orientation changes can trigger the formation of meanders eddies and vortex dipoles south of cape frio miranda 2013 the previously discussed corrections made to the temperature field and consequently to the density field directly affect surface and subsurface velocities the slight thermocline lifting and the reduction of surface temperature gradients observed in the posterior adjust the bc position and strength with its core being moved from the continental shelf break at 200 m water depth in free run to the 800 m isobath over the continental slope in the posterior below the bc the increase of density gradients at intermediate water levels lead to intensification of the iwbc jet and an increase of its vertical extension compared to the free run the adjusted velocity field on the continental slope after ctd assimilation is much closer to the one provided by belo 2011 when evaluating data from the same radial of the ceres iv oceanographic cruise posterior field also shows much richer along transect velocity variability further offshore on the são paulo plateau distances greater than 200 km due to both surface features imputed by ssh and ctd data assimilation the meridional mass transport associated with the bc which is the western boundary current of the south atlantic subtropical gyre gives a good indication of model consistency with the large scale circulation climatological values of the meridional transport of the bc consolidated by schmid and majumder 2018 from earlier studies range from 1 to 7 sv 1 sv is 106 m3 s between 19 s and 22 5 s in the upper 400 to 500 m to about 17 sv at 28 s as the vertical extent and strength of the bc increases due to limitations on the length of observed timeseries and on the number of surveys these estimates present large standard deviations fig 16 shows a comparison between climatological ranges of the bc mass transport from literature and those obtained from roms over the course of 2010 the climatological values are derived from schmid and majumder 2018 who gathered in situ mass transport estimates from previous studies the layer thicknesses used to compute roms mass transports were 400 m north of 27 s and 800 m elsewhere which is close to what was used in most of the observational studies the overall trend of absolute volume transport growth southward of 22 s is adequately captured by all roms simulations clearly showing the southward increase of bc transport negative values the free run presents slightly lower estimated transports at 20 s 22 s and 28 s and the assimilated runs at 20 s and 28 s it is also observed that at the southernmost latitude 28 s where the bc transport has contribution of both surface and intermediate water masses the assimilated runs present lower deviations than free run regarding the latitudes where roms transports are slightly higher than the observed climatology a similar pattern was found by schmid and majumder 2018 when calculating the mass transport from a combination of the global assimilative models hycom reanalysis 1993 2012 and hycom analysis 2013 2015 monthly mean fields according to the authors the strengthening of the bc in the referred model was beginning farther north than estimated with observational data explaining the higher transport values found a similar analysis of the mean fields not shown revealed an analogous pattern for this roms simulation however all model estimations have considerable overlapping regions within the large standard deviations of the observed climatology further comparisons to western boundary current transports will be considered in a future work regarding the continental slope circulation the present work is mainly focused on the são paulo plateau mesoscale ocean circulation the i4d var runs showed stronger mass transports and wider standard deviations which can be verified in fig 16 by comparing the medians and the width of the horizontal boxes of the free run with the prior and posterior runs the most notable increase occurs at 24 s this zonal section is right after the sudden change of the continental slope orientation and steepness off cape frio where more intense variability of the bc and the presence of energetic eddies are expected the intensification of the mesoscale eddy activity achieved through the assimilation procedure is thus responsible to greater variance of the meridional mass transport at this particular transect a remarkable example of the rich mesoscale field south of 24 s is the eddy dipole presented in fig 2 where a sequence of ssh snapshots and geostrophic velocity field during august and september 2010 were presented the striking current intensification of this particular dipole structure was captured by in situ current data measurements at p1 mooring located at 25 83 s 42 86 w marked as a red square in fig 17 at 2200 m depth hourly sampled mooring data were available in the months of august and september 2010 during the occurrence of the aforementioned dipole the upper 400 m of the water column were profiled with an upward looking 75 khz adcp and the 50 m water depth bin observations were used to assess model performance the observed current measurements were filtered using a 40 h low pass lanczos filter to retain the sub inertial variability prior to model comparisons fig 17 shows ssh and surface currents from roms free run prior and posterior on 5 september 2010 when the mooring location is best aligned with the dipole central jet axis it is interesting to note that a structure resembling an eddy dipole is present in the free run near 25 s and 41 w there a strong meandering of the bc and an anticyclonic eddy interact causing a southeastward deflection of the bc jet however the core of this feature is dislocated by almost 2 east and 1 north off the position seen in the altimetric observations presented in fig 2 and off the p1 mooring coordinates in the prior and posterior fields the eddy dipole is correctly positioned the major difference between the prior and posterior is the increase of surface elevation maximums in the latter one the main circulation features shown in the analysis are already present in the prior i e the sequence of alternating low and high surface elevations east of the p1 mooring this is very similar to that seen in the altimetry as an obvious consequence of the data assimilation such variability is not present in the free run where ssh field is smoother north of 24 s and south of 26 s where the bc is reorganized and follows the contours of the continental slope a fairly good representation is achieved in the free run with minor differences to the assimilation run this was already noticed in the mass transport analysis showed in fig 16 which reinforces the vicinity of 24 s to 26 s as a region with higher variability and more impacted by the assimilation procedure current speeds at the p1 mooring during the dipole event presented peaks over 1 m s 1 on september 5 2010 black dots in fig 18a with a southward direction fig 18b this agrees with the sea surface topography signature of fig 17 it is interesting to note a directional migration of the single point eulerian currents from a west northwest to a south southwest orientation during the first 30 days of august this is associated to the westward migration of the cyclonic eddy in the inshore side of the dipole see fig 2 modeled timeseries presents substantial differences between the free and assimilative runs the free run fails to capture the magnitude and direction of currents greatly underestimating its intensity and variability the direction is also incorrectly reproduced and poorly correlated in virtue of the smoothness of the mesoscale field at this particular period as already seen in fig 17 on the other hand prior and posterior timeseries are able to capture the main current intensification on september 5 2010 with maximum velocities of 0 8 and 0 9 m s 1 respectively although missing the first current intensification in august the subsequent main event during september is fairly well represented in both speed and direction the directional transition mentioned on previous paragraph is reproduced by both prior and posterior runs it is worth noting that the abrupt variations of the prior direction in fig 18b are caused by the cartesian representation of a circular variable where angles in the north sector abruptly change from 360 to 0 a better skill assessment of the various simulations is presented in fig 18c in the form of the so called taylor diagram this diagram provides a concise statistical summary of how well patterns match each other in terms of their correlation their root mean square difference and the ratio of their variance taylor 2001 statistics of modeled and observed current speeds shown in fig 18a were graphically represented in fig 18c the taylor diagram confirms that the posterior run is the best simulation with higher correlation 0 55 and a standard deviation closer to the observations 0 2 m s than the free and the prior runs the prior presents similar standard deviations to the posterior although with much lower correlation 0 24 the free run has a standard deviation about 10 times smaller than observations due to the absence of variability in its timeseries despite having higher correlation 0 32 the large velocity bias of the free run makes it the least accurate simulation the current speed rmses for the free run prior and posterior are 0 43 0 27 and 0 21 m s respectively while the ebs are 0 38 0 15 and 0 11 m s the adequate input of open ocean surface signals through the assimilation procedure is then crucial for adequate reproduction of eddy dipoles driven currents over the são paulo plateau with error and bias reductions in current speed on the order of 51 and 71 respectively the directional distribution of surface currents at the p1 mooring during the dipole event is presented in fig 19 in the form of polar histograms roms results are also shown the timeseries used are those of fig 18 observed current directions are mainly towards the south and west sectors and these are also the directions of the most intense currents the most frequent speed values are between 0 2 and 0 6 m s 1 the free run directional distribution is concentrated northeastward although no measured currents are observed in this particular sector and all modeled speed values lie in the class between 0 and 0 2 m s 1 much lower than measured ones the directional distributions of the assimilative runs are much closer to the observations in the prior the most frequent directions are south and south southeastward with peak current speeds between 0 6 and 0 8 m s 1 however the frequently measured west and west northwest directions are not well reproduced with more occurrences in the north northwest and north directions the posterior has a predominant southward flow but frequent occurrences towards the west and west northwest are also present peak velocities between 0 8 and 1 0 m s 1 are reached in the south direction and no occurrences are found in the north northeast and east directions just like the observations the directional distribution of surface current speeds during the dipole event is much better reproduced by the posterior assimilative run which correctly captures most of frequent directions and speed values a final skill assessment is performed by comparing this roms i4d var implementation with publicly available global reanalysis products of similar resolution frequently used by the scientific community the selected models chosen for comparison were the 3 hourly snapshots of the global ocean forecasting system gofs 3 1 from the hycom consortium with the navy coupled ocean data assimilation hycom ncoda system publicly available at https www hycom org dataserver gofs 3pt1 reanalysis hereafter hycom and daily means from the mercator ocean global reanalysis 12v1 glorys from copernicus marine and environmental services cmems publicly available at https resources marine copernicus eu option com csw view details product id global reanalysis phy 001 030 hereafter glorys both products have 1 12 horizontal resolution hycom has 41 vertical levels while glorys has 50 vertical levels in this study both global reanalysis timeseries were low pass filtered with a 40 h lanczos filter before comparisons fig 20 presents measured and modeled current time series for the level 56 m below sea surface along the full year 2010 it is observed that most of the time measured current speeds have values lower than 1 knot 0 51 m s but gradually increase in august and september due to the eddy dipole previously discussed observed current direction shows a rich variability along the year migrating from w to s anti cyclonic sense during the passage of the eddy dipole in august and september the regional roms and global hycom and glorys models are capable to capture the measured current variability along the year even in the complex directionally scattered flow conditions of the são paulo plateau the taylor diagram shows that all models have similar standard deviation and correlation when observed data of the full year is used for evaluation correlation coefficients were 0 56 0 54 and 0 53 for glorys roms and hycom respectively it is important to point out that the models have distinct methodologies and intervals of data assimilation a detailed look into september 2010 in the period of major current intensification better reveals differences on how each reanalysis reproduces the eddy dipole dynamics in the p1 mooring site fig 21 shows the currents time series and model skill just like fig 20 but for the period of september 1st to 25th the observed extreme current on september 5 is better simulated by roms i4d var as the current growth and its peak velocity are better reproduced on timeline hycom and glorys show intensification however the peak velocities are delayed by a few days the current speed behavior following this peak is also better reproduced by roms i4d var while hycom and glorys under or overestimate it the directional behavior however is better reproduced in the global reanalyses particularly by hycom although all models converge to the same directional sectors particularly during the extreme event on september 5 the final skill presented in the taylor diagram confirms that roms i4d var overperforms the global reanalyses during this particular period with higher correlation 0 84 than hycom 0 57 and glorys 0 5 and similar standard deviations centered root mean square differences for hycom and glorys are between 0 20 and 0 25 m s 1 which are larger than 0 15 m s 1 attained by roms i4d var 4 conclusions this paper presents an application of the regional ocean modeling system roms to simulate the ocean circulation in the southwestern atlantic ocean within a domain covering the entire south southeast brazilian shelf a hindcast for the year of 2010 using roms i4d var assimilation module was produced assimilating satellite ssh sst and in situ ts vertical profiles results were compared against both assimilated and non assimilated variables to assess the assimilation convergence and evaluate its impact a particular emphasis was given on the assessment of an extreme mesoscale event at the são paulo plateau an eddy dipole south of 24 s during august and september 2010 where current measurements were available the simulation of this feature in the correct spatial and time dimensions is quite challenging as it depends on the interaction between the bc instabilities and large scale open ocean signals coming from the east the assimilation algorithm worked properly reducing the nonlinear cost function by about 50 of its initial values over all 7 day assimilative cycles the magnitude of the increments to the posterior analysis fields remained stable during the integration period and the cross correlation between the posterior and assimilated variables was greater than 80 although the free run presented biases in the surface fields most of them could be reduced but not entirely corrected by assimilation the regions with larger biases were coastal areas in the continental shelf north of 23 s for sst and the deep portion of santos basin for ssh when compared to the free run all assimilated variables ssh sst and in situ ts profiles were positively impacted by assimilation rmse reductions of 47 and 27 were achieved for ssh and sst over the entire domain comparisons with vertical ts profiles showed significant improvements in the upper 250 m depth and null or slight degradation below possibly due to differences in the ts advection schemes between the simulations and magnitude of observational errors assigned for the profiles nevertheless eb were consistently reduced for both temperature and salinity in the entire water column although not assimilated near surface velocity was profoundly impacted by the assimilation due to the information provided by observed ssh this result is consistent with other assimilation experiments santana et al 2020 tanajura et al 2020 zavala garay et al 2012 the bc meridional mass transport growth south of 20 s is properly reproduced by both assimilative and free runs an increase in the median and intensification of mass transport were detected in the prior and posterior results with respect to the free run although the median mass transport of all simulations was always higher than climatological values between 22 s and 28 s most of the estimations were within the large uncertainty of observed values the surface signature of the eddy dipole event on august and september 2010 at the são paulo plateau was adequately reproduced by the assimilative runs with the conjunction of a cyclonic and an anticyclonic eddy and a strong southward jet in their common interface although a large bc meander and an anticyclonic structure resembling a dipole were present in the free run it was dislocated by more than 1 from its correct position and much of the surface elevation variability over the são paulo plateau was absent surface currents intensification associated with the core of the eddy dipole was captured by a mooring deployed at 2200 m depth at the plateau measured current speeds at 56 m depth reached more than 1 m s 1 on september 5 2010 the prior and posterior assimilative roms runs correctly represented this event with maximum velocities of 0 8 and 0 9 m s 1 respectively the posterior run presented rmse and eb reductions for current velocities of 51 and 71 respectively which are quite significant results the directional distribution of current speeds with south and westward intensifications was also much better represented in the assimilative runs compared to established global reanalyses products the regional roms i4d var implementation have similar skill in simulating the overall flow conditions at the são paulo plateau for instance when compared to observed near surface current data for the full year of 2010 in the middle of the plateau glorys presented slightly higher correlation coefficient 0 56 than our implementation of roms i4d var 0 54 and hycom 0 53 on a broad sense we think that for basin scale features such as the atlantic meridional overturning circulation amoc or cyclogenesis and trajectories of agulhas current eddies over the south atlantic basin the global models might be the most suitable research tools on the other hand for some specific regional features such as mesoscale eddies at the são paulo plateau or bc instabilities regional ocean models can be very skillful tools to improve global model results and pursue detailed oceanographic processes studies in this sense this regional roms i4d var implementation showed better skill to reproduce the eddy dipole event of september 2010 and outperformed these reanalysis products during the most intense currents period by achieving higher correlation coefficient 0 84 when compared to hycom 0 56 and glorys 0 5 this work demonstrates that assimilative regional simulations using boundary conditions from global models can improve simulations of the oceanic circulation at regional scales not only by increasing grid resolution but also by assimilating more detailed local observations not available for the global models this is particularly reinforced for oceanic regions where local observational data streams are not easily available to the world centers where global scale models are integrated to produce both reanalysis and forecasts however more extensive evaluation considering longer timeseries and a greater number of dipole occurrences should be done in the future for a definite estimation of higher potential skill of the regional model the realistic simulations achieved with data assimilation as reported here are capable of reproducing the main features of these intensive mesoscale events at são paulo plateau so that roms 4d var may be employed in future investigations that may lead to a better understanding of the dynamical processes that trigger and feed the dipole features we conclude that data assimilation in particular of ssh is essential to adequately simulate the complex circulation patterns that take place at the são paulo plateau where the western boundary flow along the continental slope no longer dominates mesoscale dynamics further offshore but interact with open ocean signals generating successive eddies andrioni et al 2012 belo 2011 requirements of computational efficient data assimilation for regional models with higher horizontal and vertical resolution will continue to be a priority and a challenge moore et al 2019 notwithstanding model biases show that there is room for further improvements of the non assimilative setup in order to achieve better results as presented by fox kemper et al 2019 that among challenges and prospects on ocean modeling discusses further improvement on existing or new parametrizations for eddies future efforts will be conducted to assess the roms i4d var short range predictability in the region and to assimilate new observational data such as surface currents and high resolution sea surface height provided by the future satellite mission surface water and ocean topography swot morrow et al 2019 credit authorship contribution statement thiago pires de paula methodology software data curation visualization writing original draft jose antonio moreira lima conceptualization supervision data curation writing original draft clemente augusto souza tanajura conceptualization writing review editing marcelo andrioni software data curation writing review editing renato parkinson martins project administration resources writing review editing wilton zumpichiatti arruda supervision resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge petróleo brasileiro s a petrobras for providing funding computational resources observed currents and ts profiles measurements in santos basin to execute and validate our simulations and the centro de hidrografia da marinha chm and the instituto de física of universidade federal da bahia ufba for kindly supplying qualified data from argo floats assimilated into roms we also thank the anonymous reviewers that made valuable comments and suggestions to improve the manuscript and the center for parallel computations nacad at the federal university of rio de janeiro ufrj for additional computational resources used for i4d var assimilation sensitivity tests agência nacional do petróleo gás natural e biocombustíveis anp also provided funding for the research assistant of prh 9 1 at laboratorio de mecânica computacional e sistemas offshore lamcso coppe ufrj 
23885,this work presents simulations of ocean circulation in the southwestern south atlantic ocean with emphasis on the são paulo plateau region a unique physiographic feature at the foot of the continental slope offshore southeast brazil where the flow is dominated by ocean eddies and dipoles surface dynamics south of 23 s presents a heterogeneous circulation pattern intimately related to the presence of mesoscale features such as meanders of the brazil current along the continental slope and eddies that interacts with deep ocean features the reproduction of these eddies at the correct time and spatial structure are quite challenging in the context of a non assimilative model considering the limitations imposed by the model s numerical schemes physical parameterizations boundary conditions and surface forcing in this sense the regional ocean modeling system roms 4 dimensional variational data assimilation 4d var module was used to increase model skill and minimize deviations from oceanic observations weekly observations of sea surface height ssh daily sea surface temperature sst fields and in situ vertical profiles of temperature and salinity from multiple sources were used in consecutive assimilation cycles to produce an accurate representation of ocean features and their variability both the assimilative and free run were evaluated against observations including in situ current measurements results showed significant improvements of the assimilation procedure on both assimilated and non assimilated variables with rmse reductions of 27 and 47 for sst and ssh respectively and 51 for current speed measurements during a dipole event in the são paulo plateau the assimilative run was able to reproduce a remarkable event of mesoscale eddies interaction dipole and consequent current intensification leading to important improvements on model skill the correct use of observational information of open ocean surface features through data assimilation is a key factor for a proper simulation of such eddy dipole events keywords são paulo plateau oceanic eddies data assimilation roms 4d var 1 introduction the são paulo plateau is a unique physiographic feature of the southeast brazilian continental margin it is a low declivity region located between the 2000 m and 3000 m isobaths approximately 2 degrees apart and zonally from 21 s just south of the vitoria trindade ridge to 28 s de almeida and kowsmann 2016 kumar et al 1977 kumar and gambôa 1979 this study is concerned with the ocean circulation in the são paulo plateau region south of 23 s approximate latitude of cape frio where the coastline orientation has an abrupt change from ne sw to e w fig 1 in this southern stretch the plateau has a large width greater than 300 km on average it is a region of intense mesoscale eddies activity andrioni et al 2012 the surface ocean circulation off southeast brazil is marked by the presence of the brazil current bc the western boundary current associated with the sverdrup balance of the wind driven south atlantic subtropical gyre originated from the bifurcation of the south equatorial current sec the bc flows southward approximately following the continental slope stramma and england 1999 along its path the bc develops intense mesoscale activity and large meanders that sometimes encloses eddies the mechanism of baroclinic instability is one of the main drivers of such mesoscale activity da silveira et al 2008 rocha et al 2014 the most recurrent eddies of this kind are found off cape são tomé 22 s and off cape frio 23 s feature oriented numerical modeling has been applied to study these eddies calado et al 2008 2006 reinforcing the point that the use of observational data hydrographic current meter and satellite data and numerical models are powerful tools to understand and study these mesoscale features along the southeast brazilian continental slope south of 23 s on the so called southeast brazilian bight sbb which extends from cape frio to cape santa marta 28 s the bc meanders and its eddies can induce shelf break upwelling events campos et al 2000 distinct methods were used to evaluate the brazil current structure and velocities on this region biló et al 2014 observational data both direct measured adcp current velocities as well as derived geostrophic velocities from ctd and xbt data along transects have shown that the bc meanders along its path on the continental slope from 23 s to 28 s belo 2011 biló et al 2014 but it does not dominate the deep ocean circulation on the são paulo plateau further offshore the ocean circulation on this plateau was evaluated by belo 2011 with a series of measured current and hydrographic transects revealing a pattern of successive eddy structures these vortical features can sometimes be enhanced by the cape frio cyclonic eddy coupled with westward propagating anticyclonic features leading to the formation of an eddy dipole structure and generating a strong intensification of surface currents in its middle section the dipole structure commonly moves in the south southwest direction and significantly changes the circulation pattern of the são paulo plateau this seems to be a recurrent feature as its surface signature can be frequently observed in satellite derived sea surface height andrioni et al 2012 the plateau acts as a natural eddy corridor where dipoles gradually move westward as shown in fig 2 where a sequence of snapshots of sea surface height and geostrophic velocity fields during august and september 2010 is presented an intense cyclone centered at 25 s 43 w in the first snapshot is joined by an anticyclone giving rise to a strong dipole its bounds are roughly indicated in fig 2 by the black dashed line circle its influence on currents behavior as will be shown later could be captured by a current meter mooring the p1 mooring indicated by the red square the purpose of this work is to assess the impact of data assimilation on the simulation of eddy dipoles at the são paulo plateau and not to identify their possible local or remote driving mechanisms however besides the local baroclinic instability mechanism discussed earlier it has been observed that the arrival of westward propagating agulhas current eddies can contribute to generate enhanced dipole structures guerra et al 2018 also the vorticity contribution of rossby waves reaching the western boundary of the south atlantic can contribute to the modulation of the bc transport as well as its meandering and eddy activity majumder et al 2019 considering that the generation of dipole structures may depend on the conjugation of many distinct mechanisms a precise reproduction of these features in time and space is a challenging task for a non assimilative model in fact inaccuracies in the bathymetry representation initial conditions lateral boundary conditions and surface forcing as well as limitations of sub grid processes parametrization may introduce large uncertainties lima et al 2019 and contribute to deviations of the numerical simulations from the ocean real state despite the limitations imposed by the numerical nature of the simulation there must exist an optimum state or initialization field that minimizes the differences between model and observations finding these states and or initial conditions is the core of the data assimilation methods and it is a requirement if one is interested in simulating and forecasting high variability mesoscale features other studies have shown a positive impact of assimilation on the simulation of the ocean circulation at the southeast brazilian oceanic region da rocha fragoso et al 2016 lima and tanajura 2013 tanajura et al 2016 2015 due to the importance of data assimilation to operational oceanography and physical oceanography the oceanographic modeling and observation network remo portuguese acronym for rede de modelagem e observação oceanográfica was established in 2007 lima et al 2013 the main goal was to implement an operational forecasting system in the brazilian navy hydrography center chm with focus on the south atlantic efforts were first dedicated to build a data assimilation system into the hybrid coordinate ocean model hycom santana et al 2020 tanajura et al 2020 another effort is also being conducted by the present work under remo to explore the regional ocean modeling system roms with the 4 dimensional variational data assimilation 4d var method moore et al 2011b in the southwestern atlantic several works have demonstrated this system s capacity to produce accurate representation and forecasts in regions of high oceanic variability da rocha fragoso et al 2016 lee et al 2018 moore et al 2011a powell et al 2008 the present work aims to describe the implementation of roms primal formulation of incremental strong constraint 4d var over the southwestern atlantic to investigate the ocean circulation at the são paulo plateau region particularly to simulate its characteristic mesoscale eddies a particular event of an intense observed dipole structure that occurred in september 2010 is used to assess the impact of the data assimilation in model skill especially its ability to reproduce the dipole with the correct spatial and time scales as well as their associated intense currents the paper is organized as follows section 2 describes the model setup the data assimilation system and the assimilated observations section 3 presents simulation results with particular emphasis in model skills and in improvements achieved with assimilation including comparisons with non assimilated variables and observations as well as global reanalysis products section 4 summarizes the main aspects and conclusions of this study 2 modeling framework 2 1 model description and free run setup the model employed in this study is the regional ocean modeling system roms revision 904 along with the incremental strong constrain 4d var better described in the next section roms is a split explicit free surface 3d primitive equation and terrain following vertical coordinate oceanic model and has been widely use by the oceanographic community a comprehensive description of roms and its 4d var formulations can be found in shchepetkin and mcwilliams 2005 2003 and moore et al 2011b the domain encompasses the entire brazilian southeastern oceanic region within the longitude and latitude ranges of 50 5 w 32 5 w and 30 0 s 13 0 s respectively as shown in fig 1 this region was horizontally discretized with 217 by 222 grid points resulting in a 1 12 horizontal resolution 9 km the vertical discretization is made with 32 vertical layers an enhanced resolution at the surface is achieved by the use of the surface and bottom stretching parameters θ s 7 0 and θ b 0 3 and the critical depth parameter t c l i n e 30 m initial and boundary conditions come from the operational mercator global ocean 1 12 physical analysis and forecast copernicus marine and environmental services cmems daily means lellouche et al 2018 these fields are linearly interpolated by roms during execution to get boundary data at each model time step in order to avoid discontinuities and provide a smooth transition between inner and boundary fields we follow the scheme proposed by penven et al 2006 where roms bathymetry near the open boundaries is gradually adjusted to match the outer global model grid the distance from the boundaries where the transition begins was set to 40 km which is close to the internal rossby radius of deformation for this region also a 160 km sponge layer with increasing viscosity and diffusivity factors of 20 and 10 respectively was implemented to suppress numerical noise at the boundary being the explicit viscosity and diffusivity coefficients set to 4 m2 1 mixed radiative nudging boundary conditions marchesiello et al 2001 with a 1 day timescale were chosen for tracers and baroclinic momentum chapman chapman 1985 implicit and flatter flather 1975 boundary conditions were used for the free surface and barotropic velocities respectively and a gradient boundary condition is set for the mixing turbulent kinetic energy this choice of boundary conditions in combination with the sponge layer is efficient to propagate inertial signals generated within the model domain and suppress any numerical noise due to radiation of signals not resolved within the daily averaged boundary data the unresolved subgrid scale vertical processes were parametrized with the mellor and yamada 1982 turbulent closure scheme my level 2 5 coded in roms the bottom topography is derived from a 1 arc minute global relief model etopo 1 with corrections performed by the hydrography center of the brazilian navy from nautical charts and in situ surveys the raw bathymetry presents regions of very steep topographic features particularly the continental shelf break along cape são tomé the abrolhos bank and the vitoria trindade ridge see fig 1 such features were leading to baroclinic pressure gradient errors long known to happen in sigma coordinate models mellor et al 1998 and had to be smoothed in respect to the slope parameter r δ h 2 h beckmann and haidvogel 1993 to reduce these errors to acceptable levels however commonly used smoothing techniques such as two dimensional gaussian filters were leading to a large displacement of the continental shelf break and consequently the core of the western boundary circulation this shift in the average position of the bc system produced in preliminary runs resulted in large initial conditions increments at each assimilation step even after several consecutive cycles thus the smoothing procedure employed here was the linear programming approach proposed by sikirić et al 2009 which was able to simultaneously achieve a value of r lower than 0 25 everywhere with a minimum modification to the original topography another common issue of sigma coordinate models detected in the model setup runs is the numerical attenuation of deep isopycnals caused by numerical diffusion of tracers marchesiello et al 2009 the use of less diffusive higher order tracer advection schemes instead of the standard upstream 3rd order horizontal advection available in roms along with explicit biharmonic laplacian viscosity and diffusion showed marginal improvements in this matter the split scheme proposed by marchesiello et al 2009 worked well for the free run at the cost of external timestep reduction but became unstable in the forward runs of the nonlinear model during the very first assimilative cycle to address this issue the multidimensional positive definite advection transport algorithm mpdata tracer advection schemes were used and a depth dependent nudging scheme was adopted this scheme consists of adding an additional term to the right hand side of the prognostic equations of temperature and salinity with the form δ t τ ϕ c l m ϕ where δ t is the model time step in seconds τ x y z is the relaxation time scale in seconds ϕ x y z t is the tracer variable and ϕ c l m x y z t is the tracer climatological value towards which the variable will be relaxed in this work monthly means calculated from 10 years 2007 to 2016 of the global mercator analysis were used as climatological fields a stronger nudging timescale of 30 days was set below 800 m to preserve deep water masses throughout the simulation and a very long timescale of 1080 days was used above 400 m to achieve a smooth transition between these two timescales a logistic function was applied this nudging scheme was used on both free and assimilative runs given that very few observations of subsurface fields were available to be assimilated surface boundary conditions were taken from the european centre for medium range weather forecast ecmwf era 5 reanalysis hersbach et al 2020 with 31 km horizontal resolution era5 hourly fields of 10 m wind velocity components temperature relative humidity incoming short and longwave radiation fluxes and precipitation rate were used to compute momentum heat and mass fluxes the surface fluxes are computed using bulk formulas of liu et al 1979 and fairall et al 1996a b no tidal forcing was employed in this model application as tidal signals are very weak at the são paulo plateau our main interest region when compared to signals associated with mesoscale features the model was then run for 6 years from october 2008 to january 2015 the resulting fields were used to compute all statistics necessary for the assimilation run as detailed below 2 2 data assimilation system a 4d var system available in roms was used in this work roms provides three variants of the 4d var a primal formulation of incremental strong constraint 4d var i4d var a dual formulation based on a physical space statistical analysis system 4d psas and a dual formulation representer based variant of 4d var r4dvar moore et al 2011b in the strong constraint approach the model physics is considered perfect and the model errors are thus neglected zhang et al 2010 when model errors are admitted 4d var is said to be subject to a weak constraint imposed by the model dynamics moore et al 2011b we made use of the i4d var and a brief description of the concepts that turned out to be most relevant to this application is presented below the main objective of the i4d var data assimilation is to estimate the increments to the model state vector x t i ζ t s u v t at a time t i comprised of all prognostic variables sea surface displacement ζ potential temperature t salinity s and horizontal velocity components u and v and subject to surface forcing conditions f t i for momentum heat and freshwater fluxes and lateral open boundary conditions b t i that minimizes in a least squares sense the difference between the model and observations li et al 2015 this difference is mathematically expressed in the form of a nonlinear cost function j n l neveu et al 2016 1 j n l 1 2 z z b t d 1 z z b j b n l 1 2 y o h z t r 1 y o h z j o n l where z x t 0 t f t t b t t and z b x b t 0 t f b t t b b t t are the posterior and background control variables vectors respectively d is the background error covariance matrix y o is the observation vector h is the nonlinear operator that projects the state vector into the observation location and r is the observational error covariance matrix the cost function is composed of two terms j o n l and j b n l which represent respectively the distance or misfit between the adjusted model z posterior or analysis and the observations and the distance between the model and its background z b or prior solution this first guess of the ocean state is obtained from a nonlinear model nlm run which can be a non assimilative or assimilative run the nonlinear cost function may possess several local minima so that numerous solutions to z are possible however assuming that the background estimation z b is sufficiently close to an optimum state a gauss newton method approach may be used to transform the nonlinear problem into a sequence of linear minimizations through the so called inner and one or more outer loops the reason for executing multiple outer loops is that it is sometimes necessary to update the nlm trajectory in order to account for non linear effects that arise in the flow during the assimilation period powell et al 2008 the analysis is obtained in terms of small successive increments δ z to the prior estimation 2 z k z b l 1 k 1 δ z l where k refers to the k th outer loop iteration index and δ z l are the increments from all previous outer loops given by δ z l δ x t 0 l t δ f l t δ b l t neveu et al 2016 thus the linearized cost function in its incremental form is given by 3 j 1 2 δ z t d 1 δ z j b 1 2 d g δ z t r 1 d g δ z j o where g is the linear operator that samples the tangent linear model tlm at observation locations d y o h x b is the innovation vector the difference between the first guess and the observations and r is the observation error covariance matrix matthews et al 2012 the background error covariance matrix is assumed to be time invariant and block diagonal so that d d i a g b x b f b b where b x b f and b b are the full multivariate prior error covariance matrices of the initial conditions surface forcing and open boundary conditions neveu et al 2016 these matrices penalize departures of the increments from the original background and act as regularization term by spatially smoothing the updated fields zavala garay et al 2012 due to its high dimensionality in the order of the number of variables in the 3d grid squared the b x matrix is factorized and expressed as 4 b x k b σ x c σ x k b t where k b is the multivariate balance operator σ x is the diagonal matrix of standard deviations computed from a model run and c is a matrix of univariate correlations that are modeled as solutions of a diffusion equation broquet et al 2009a moore et al 2011b k b is responsible for transferring observational information among model variables and is critical for extracting information about unobserved variables from directly observed quantities weaver et al 2006 this is most commonly done through the use of dynamical and physical relationships between variables in roms geostrophic and hydrostatic balance are used to construct the multivariate balance operator the background error covariance matrices for surface forcing b f and open boundary conditions b b do not include a balance operator and are simply factorized by σ f c f σ f t and σ b c b σ b t respectively neveu et al 2016 the background error correlation matrix c is given by 5 c c h c v with 6 c h λ h l h 1 2 w h 1 l h 1 2 t λ h 7 c v λ v l v 1 2 w v 1 l v 1 2 t λ v where λ is a diagonal matrix of normalization coefficients required to ensure that c values are between 1 w is a diagonal matrix with elements corresponding to the grid box areas in the case of w h and level thicknesses in the case of w v l represents the action of the matrix obtained by solving either a 1d for l v or 2d for l h diffusion equation moore et al 2011b the normalization coefficients of λ are the costliest part of the covariance modeling but fortunately must be computed only once given that the vertical and horizontal correlation lengths do not change to illustrate how the modeled background error correlation operates in a single adimensional observation fig 3 shows the horizontal and vertical amplitudes of a point perturbation in the são paulo plateau when convolved with c a state variable is perturbed at the surface and the signal spreads horizontally fig 3a and b and vertically fig 3c and d through c h and c v this allows the observational information to spread spatially in the 4d var assimilation isotropic correlation length scales for the state variable used in this example are 100 km in the horizontal and 50 m in the vertical the minimization of j involves the computation of the gradient j j δ z demanding the calculation of the transpose of very large and sparce matrices and thus roms makes use of the adjoint model adm and a preconditioned lanczos formulation of the conjugate gradient method this method is also used in the estimation of the background error covariance matrices considering m a finite number of inner loops and k a finite number of outer loops the assimilation cycle begins with the initialization of the background control variables vector z b obtained from a nlm run and the initial increment δ z k 0 m 0 is set to zero the operator g and its transpose are found through the execution of the tlm and adm along a certain time window after computing the error covariance matrix r the gradient of j is then calculated a forward and a backward integration of the tlm along with an update of the gradient is performed in order to estimate the optimum increments if the maximum number of inner loops has not been reached the value found for the increments is used in the next inner step otherwise a nlm run is executed using the initial background fields added with the newly estimated increments then if the maximum number of outer loops has not been reached a new round of inner loops is done using the updated nlm solution as starting point for the estimate of the δ z otherwise this last nlm run is the analysis z a which consists of the final result of the assimilation cycle 2 3 data assimilation setup in this work an assimilation time window of 7 days is used tests performed for few consecutive cycles using intervals of 4 and 14 days not shown similar to powell et al 2008 revealed that the shortest window although presenting highest accuracy to observations has large discontinuities between cycles which is undesirable in this regard the differences between 14 and 7 days intervals were small additionally shorter integration cycles are less prone to violations of the tangent linear assumption than longer time intervals also a second level of preconditioning with 2 ritz vectors is used to further reduce final nonlinear cost function as discussed in moore et al 2011a the first assimilative run was initialized from a daily mean of the cmems operational mercator global ocean 1 12 physical analysis and forecast for 01 january 2010 and 52 consecutive cycles were then executed to obtain a 1 year analysis run as sketched in fig 4 initial and boundary conditions as well as surface atmospheric forcing wind drag and heat fluxes were subject to corrections in this setup of roms i4d var module the update frequency for surface forcing and lateral boundary increments was set to 1 and 12 h respectively the diagonal matrices of standard deviations σ x σ f and σ b were all computed from the 6 year free run surface wind stress components net heat and salt fluxes were stored during roms free run execution to allow estimations of surface forcing standard deviations for lateral boundary conditions standard deviations were estimated from boundary grid points variability the balance operator k b was disabled because it was leading to unstable solutions in the bottom salinity field over the continental shelf nonetheless the linearized dynamics embodied in the roms tangent linear and adjoint effectively allows the transfer of information between variables during the assimilation procedure neveu et al 2016 in fact a positive impact over non assimilated variables could be achieved as it will be later demonstrated for the modeling of the background error correlation matrix c table 1 summarizes the values adopted as decorrelation scales for initial and boundary conditions and for surface forcing usual starting points for these scales can be based on the internal rossby radius of deformation or more sophisticated approaches like semivariogram techniques matthews et al 2011 but some experimentation for fine tuning is usually required thus most of the values adopted here follow da rocha fragoso et al 2016 who also applied the 4d var assimilation in a similar domain except for the vertical decorrelation lengths which were reduced to avoid excessive subsurface perturbation an issue that is discussed by broquet et al 2009a tracers and momentum advection schemes for both nlm and adm were set to the default 3rd order upwind horizontal and 4th order centered vertical schemes which proved to give the most stable solution the boundary conditions for the nlm were kept the same as described in section 2 1 for the adm mixing radiative nudging boundary conditions are not coded so that clamped boundary conditions were used for temperature salinity and 3d momentum the choice of the number of inner and outer loops was based on preliminary results of a 1 year i4d var integration in which 2 outer loops and 25 inner loops were used this first experiment was able to minimize the cost function in all cycles although much of the minimization was achieved in the first 8 to 14 inner loops also subsurface perturbations were detected in this solution probably due to an overfitting to the observations as the errors between the analysis and assimilated observed data mostly at the surface were deemed too low although other factors may lead to such issue like small observational errors inconsistent decorrelation lengths and other model setup parameters the decrease in the number of inner loops in this case significantly reduced the problem the use of 1 outer loop over 2 was also tested but lead to much inferior results in terms of model skill indicating that non linearities play an important role in this particular application the combination of 2 outer loops and 8 inner loops was then used throughout the simulations the experiments were run in a linux computational cluster using 8 nodes each containing 16 intel r xeon r e5 2670 2 60 ghz cores resulting in the allocation of 128 processors per run with this setup each of the 52 assimilative cycles spanning 7 days of simulation took about 3 5 h this gives about 182 h of computational time to fulfill an entire year putting these numbers in perspective the 6 year free run consumed 40 h when executed with the same number of processors and at the same machine however very recent improvements in roms source code including the implementation of a single precision kernel in some of the subroutines and parallel io capability might substantially reduce the computational overhead of the 4d var assimilation 2 4 assimilated data the data sets assimilated into roms are griddedsatellite altimetric observations of sea surface height ssh sea surface temperature sst and in situ vertical profiles of temperature and salinity t s some of these data sets were also used in the skill assessment presented below fig 5 shows monthly availability of each observation type within the entire modeling domain during the year of 2010 the vast majority of the data are surface observations daily sst observations are the most abundant with more than 700 thousand values per month followed by weekly ssh with about 100 thousand observations per month in situ temperature and salinity vertical profiles are much less numerous with an average count of 1 thousand temperature and 1 thousand salinity measurements per month ssh data is obtained from the project altimetry tailored and optimized for brazilian applications atoba developed by the french institute collecte localisation satellites cls this project was conceived under the framework of remo initiative lima et al 2013 and consists of refined and gridded weekly fields of 1 12 resolution sea level anomaly sla and absolute dynamic topography adt measured from multiple altimetry satellites over the entire south southeastern region offshore brazil this data set has greater mesoscale energy in continental shelf and slope regions when compared with data made available globally by aviso daher and junior 2014 a time space average of the adt computed for the entire time range of the data 1993 2013 is subtracted from the weekly adt fields and the time space average of the 6 year roms free run is added to make observed and model reference levels compatible the resulting ssh weekly fields were linearly interpolated to a daily basis to improve data availability and masked over depths shallower than 200 m although the development of the fastest growing perturbations of the bc which double its size each 8 to 16 days biló et al 2014 da silveira et al 2008 might not be precisely represented by a weekly ssh gridded product it can comfortably resolve the typical mesoscale timescales of the region 100 days goes et al 2019 and the eddy field evolution over the são paulo plateau that spans several weeks for example the eddy dipole event reported in this work occurs at time scales of 30 days or more as depicted in the sequence of ssh snapshots of fig 2 eddies and meanders found in the region have typical lengths from 100 km to 400 km belo 2011 calado et al 2006 fernandes et al 2009 the horizontal resolution of the ssh data is about 8 km approximately a quarter of the internal rossby radius of deformation for the region 30 km and is adequate to resolve the local mesoscale dynamics daily sst was obtained from operational sea surface temperature and sea ice analysis ostia ostia uses satellite data provided by the group for high resolution sea surface temperature ghrsst project together with in situ observations and optimal interpolation oi to produce a continuous and gap free analysis of the global foundation sst with 1 18 resolution donlon et al 2012 sst data were masked in regions shallower than 200 m to avoid degradation of strong upwelling events adequately reproduced by roms but underestimated by ostia no corrections due to diurnal warming cycle were made the in situ ts vertical profile data came from multiple sources including argo floats roemmich et al 2019 and shipboard ctd conductivity temperature and depth sensor measurements fig 6 shows the distribution of in situ ts vertical profiles the ctd data were collected by petrobras and the brazilian navy and were kindly supplied for this study most of argo float data are concentrated in water depths greater than 1000 m while the shipboard ctd transects covering the continental shelf and the deep ocean were obtained from the ceres iv oceanographic cruises belo 2011 a total of 1147 ts profiles were assimilated by roms for the determination of the observation error covariance matrix r the observations errors adopted are summarized in table 2 along with other relevant information to facilitate pre processing of in situ profiles argo floats and shipboard ctd instrumental errors were assumed equal misrepresentation errors associated with processes not resolved by the model physics and the representativeness error associated with the ability of a single observation to describe the circulation in a single model grid are difficult to estimate da rocha fragoso et al 2016 thus the choice of these values was made primarily considering the instrumental precision of each data source and the values commonly found in the literature broquet et al 2009a da rocha fragoso et al 2016 neveu et al 2016 powell et al 2008 zavala garay et al 2012 zhang et al 2010 slight modifications were then made to achieve an optimum balance between the weight of observations and the background in the cost function minimizing procedure for instance the choice for ssh error of 0 02 m considered the usual measurement precision associated with altimetric data broquet et al 2009b and it was used in similar studies broquet et al 2009a da rocha fragoso et al 2016 moore et al 2013 the results of sensitivity tests using observational errors up to 0 04 m and the better performance of the atoba data set with respect to global altimetric gridded products in the region of the bc pita et al 2020 indicated that the value adopted was a reasonable choice following moore et al 2011a neveu et al 2016 and powell et al 2008 all observations within each model grid cell over a 6 h time window were combined into the so called super observations to reduce data redundancy the largest error within the same variable and grid cell is used the gridded ssh and sst data are assimilated at the observation time 00 00 for ssh and 12 00 for sst the temperature and salinity profiles are assimilated at 00 00 06 00 12 00 or 18 00 as a result of the binning procedure 2 5 model skill assessment the metrics used to assess model skill and the assimilation performance were the cross correlation cc the root mean square error rmse and the error bias eb defined as oke et al 2002 8 c c 1 s ˆ s 1 n i 1 n y ˆ i y ˆ y i y 9 r m s e 1 n i 1 n y ˆ i y i 2 10 e b 1 n i 1 n y ˆ i y i where y ˆ i and y i are the i th modeled and observed quantities of a variable s ˆ and s are the respective standard deviations and the overbar denotes the average over all sample points 3 results and discussion 3 1 assimilation performance to monitor the operation of the i4d var assimilation procedure it is useful to analyze the cost function over consecutive cycles fig 7a shows the behavior of the tlm cost function during inner loop iterations of all assimilative cycles and fig 7b the final tlm j and nlm j n l cost functions at the end of the minimization algorithm the variables are normalized by their values at the beginning of each cycle a decrease in j is achieved in all cycles indicating that the system is behaving correctly the jump of j at the tenth iteration is associated with the update of the nlm fields over which the tlm operates during the second outer loop the initial value of both the tlm and nlm cost functions is reduced to about half at the end of the minimization algorithm although the final reduction of j n l is always lower than that achieved for j which is expected due to the effects of nonlinearities the consistent reduction of both functions shows that the minimization algorithm is working properly during all assimilation cycles the average initial conditions increment i e the mean of the differences between posterior analysis and prior surface fields at the beginning of each cycle are shown in fig 8a to c the evolution of these increments across consecutive i4d var integrations are also shown in fig 8d to e for the surface temperature and salinity regions with the highest average increments are over water depths shallower than 1000 m on the continental shelf and slope these areas present intense mesoscale activity and these increments perform the correction of the bc density gradient position it is interesting to note that for latitudes lower than 23 s there are positive average increments close to the coast and for higher latitudes negative increments we speculate that the smoothing procedure in latitudes lower than 23 s where bathymetry is steeper than in higher latitudes inevitably causes a shift of the bc core and consequently imposes temperature and salinity signatures at the surface for ssh the spatial average increments are mostly positive indicating that despite the offset correction of the observations to match the model reference level a slight difference might persist we credit this to changes in the advection schemes used for the 6 year free run over which the model sea surface elevation reference level was calculated and the nlm setup used in the assimilative run another possibility that was not further investigated is the existence of biases sourced in the background error covariance matrix d which is constructed from values of the 6 year roms free run standard deviations it is worth to note major increments over the são paulo plateau and south off the vitoria trindade ridge where intense mesoscale eddy activity not entirely captured by the free run occurs despite the existence of regions with relatively large corrections the area average of the absolute value of increments at the initial conditions of each cycle are less than 0 3 c for sst 5 cm for ssh and 0 1 for salinity also the domain averaged increments do not present any growth trends in consecutive cycles indicating that the prior estimates are consistently close to the observations fig 9 presents magnitude and spatial patterns of the increments made to surface wind stress and surface heat flux throughout the assimilation cycles the adjustments in surface wind stress are of the order of 10 4 n m 2 with major corrections on the continental shelf north of 23 s where a weakening tendency of the along shore north and northeast winds associated with coastal upwelling is identified this is possibly due to the fact that assimilated sst from ostia underestimates the magnitude of the temperature drop in the upwelling peres et al 2017 which is controlled by the wind and is well represented by the model dynamics the averaged heat flux adjustments are towards surface cooling in most of the domain especially near the eastern boundary and surface heating in a small portion of the continental shelf between 17 s and 24 s these corrections are in the order of 6 w m 2 during the eddy dipole period in august and september 2010 fig 10 there is a positive heat flux adjustment in the são paulo plateau east of 43 5 w and a negative correction west of this meridian which is compatible with an increase of sea surface gradients through thermal expansion no significant spatial differences between the surface wind stress corrections during the eddy dipole period and the annual mean were identified but slight increase or reduction of the wind stress on distinct regions of the domain a final assessment of the assimilation performance might be done in light of error statistics calculated at the end of each assimilative cycle the panel shown in fig 11 presents the behavior of all these error metrics over the 1 year roms i4d var integration the cc of all assimilated variables fig 11a are higher than 80 over the entire period sst and subsurface temperature followed by salinity are the best correlated variables with cc higher than 90 all year long sst presents the most stable cc timeseries with values consistently higher than 95 possibly because it is the most frequently assimilated variable another possibility for the excellent quality of sst may be associated with the fact that it is also driven by surface air temperature so that the atmospheric forcing may efficiently contribute to produce accurate ssts however this is not the case of ssh for this variable cc has an initial value of 94 at the very first assimilative cycle then it slowly reduces oscillating around 90 reaching a minimum of 85 during the cycles of november and increasing again to 90 level at the last cycles this behavior is more or less accompanied by both eb and rmse which present peaks at the same periods when cc is lower the model bias previously identified from the averaged ssh increments is clearly seen in fig 11b where a constant negative bias in the surface elevation is present in most of the cycles the same picture can be depicted on subsurface temperature and salinity fig 11c and d indicating that roms has a cold and lower salinity bias with maximum values of 1 2 c and 0 2 respectively the rmse ranges between 2 and 4 cm for ssh fig 11e 0 2 c 0 5 c and 0 4 c 2 5 c for sst subsurface temperature fig 11f and 0 2 and 0 4 for salinity fig 11g however error estimations of subsurface temperature and salinity might not be very accurate as the number of observations is considerably smaller than those for ssh and sst these variations in the error statistics timeseries are expected due to natural variability of the number of available observations in each assimilation cycle even after interpolating ssh observations to a daily basis to improve the frequency in which this variable is assimilated as explained in section 2 4 the error of the gridded weekly fields is not constant and may be increased over periods of higher mesoscale activity or due to the presence of features for which time and spatial scales could not be adequately captured by the satellite track nonetheless no significant trends in cc rmse or eb were identified and the error magnitudes are low corroborating that the assimilation procedure was working as expected 3 2 impact of assimilation on assimilated variables the comparison of roms i4d var results with assimilated data is useful to diagnose if the assimilation algorithm is converging and if j o the misfit between the model and observations is actually being reduced however a better picture of the impact of data assimilation procedure is achieved by including the free run results in the evaluation of the error statistics and using independent observations not assimilated whenever possible for an unbiased skill assessment fig 12 presents sst and ssh rmses for the free non assimilative run the prior and the posterior circulation for the year of 2010 to compute sst model errors the multi scale ultra high resolution mur sea surface temperature analysis a data set that was not assimilated into roms was used mur presents daily sst estimates on a global 0 01 0 01 grid featuring the 1 km resolution modis retrievals which are fused with avhrr gac microwave and in situ sst data by applying internal correction for relative biases among the data sets chin et al 2017 thus the mur fields may not be considered a fully independent data set as data coming from avhrr are also used in ostia analysis assimilated in the present experiment for the ssh errors aviso atoba weekly absolute dynamic topography fields assimilated into roms were used prior to this error estimation sea surface heights from both the observations and model were masked out for water depths shallower than 200 m and were subtracted by their spatial and time average over the entire period the rmse values between roms and mur sst are mostly in the range between 0 and 1 c for both the free and assimilative runs for the free run fig 12a highest errors are concentrated at coastal regions above the latitude of 23 s and at upwelling sites where the rmse is higher than 2 c with smaller magnitudes the west and south boundaries and significant part of santos basin show rmse values up to 1 c the prior fig 12b and posterior fig 12c fields have similar patterns though considerably smaller errors occur particularly for the last one the regions with largest errors indicate an intrinsic bias source at this model setup which could be minimized but not entirely corrected by the assimilation procedure either way substantial error reductions are achieved over the entire domain the area averaged rmses for sst are 0 64 0 57 and 0 47 c for the free run prior and posterior respectively corresponding to a reduction of 27 in the rmse achieved by the assimilation for ssh the assimilation impact is even more evident the free run fig 12d presents rmses up to 0 13 m while the prior fig 12e and posterior fig 12f fields maximum rmse are about 0 09 m and 0 05 m respectively these errors are concentrated over the são paulo plateau in water depths larger than a 1000 m where mesoscale activity due to the interaction of energetic eddies is intense such as the dipole structure described in section 1 the free run cannot correctly capture these features in space and time and produces larger errors the roms i4d var system is able to substantially mitigate this model limitation so that the ssh rmse is reduced by more than 50 over the são paulo plateau a comparison of the prior and posterior ssh rmse fields shows relatively larger differences than those for the sst rmse fields possibly due to the same data source be used for assimilation and to compute error statistics also ssh is not as efficiently constrained by atmospheric forcing as sst the area averaged rmses for ssh are 0 054 0 04 and 0 028 m for the free run prior and posterior respectively thus an average reduction of 48 in the ssh rmse over the entire domain is achieved with the assimilation subsurface fields are also affected by assimilation fig 13 shows rmse and eb estimates between roms and all vertical temperature and salinity profiles assimilated see fig 6 the largest errors occur near surface in water depths of about 100 150 m this can be related to errors in the representation of the mixed layer depth in the region the ocean surface boundary layer is a region of intense heat and momentum exchange with many sub grid processes it is naturally more challenging for the model to appropriately reproduce its dynamics lying solely in its vertical mixing parametrization and bulk fluxes formulations the rmse between the free run and observed temperature profiles grows from less than 1 5 c near surface to about 2 0 c at 100 150 m the same pattern occurs for the assimilative runs although the maximum rmse is slightly reduced between 150 m and about 800 m temperature rmse is smaller after assimilation the rmse for salinity also peaks at 100 150 m with 0 4 for the free run and 0 3 for the assimilation runs between 300 m and 900 m the rmse is smaller for the free run this result is in line with other modeling studies carried out over approximately the same region such as those by da rocha fragoso et al 2016 who report peak rmses for temperature 1 to 2 c and salinity 0 2 0 4 between 100 and 200 m water depth similar results were also obtained by santana et al 2020 with an ensemble optimal interpolation scheme into hycom in their work the maximum temperature salinity rmses in the free run and in the assimilation run were attained at the 150 m depth about 1 9 c and 1 0 c 0 26 and 0 18 respectively below 1000 m both the free and assimilative runs perform equally we credit this to three factors the first is the choice of the advection scheme for tracers where the upwind 3rd order advection was used during the assimilation cycles instead of the mpdata used in the free run the latter is more effective in preserving the subsurface density gradients while the former tends to smooth density fronts leading to larger errors the second is the choice of the observational errors for the in situ temperature 0 4 c and salinity 0 1 profiles slightly higher than most of the values found in the literature giving less weight to these observations in the minimization procedure lastly the nudging procedure described in section 2 1 for both the assimilative and free runs leads to identical behaviors in water depths greater than 1500 m for the temperature eb the assimilation impact is more pronounced a warm bias of up to 1 5 c in the free run at 200 m gives place to a cold but lower bias of 1 c after assimilation the eb reduction in the prior and posterior salinities are more consistent with almost zero bias from surface down to 150 m against a positive bias of 0 3 of the free run between 300 and 900 m the eb of the assimilative runs are positive and slightly greater than those of the free run below 1000 m all simulations present biases of the same order that vary between 0 15 the prior and posterior show similar error statistics fig 14 illustrates the impact of the 4d var assimilation of shipboard ctd profiles in a subsurface temperature vertical section the transect presented is one of the ceres iv oceanographic cruise radials at the são paulo plateau belo 2011 the free run shows a tendency of thermocline deepening particularly at the upper continental slope and shelf break where free run modeled temperatures are consistently higher than observations at the bottom and intermediate levels this deviation is significantly reduced by assimilation which raises the isotherms and smooths near surface temperature gradients associated with the bc front the cold bottom shelf waters observed in the ctd data in the first 100 km of the transect are better reproduced in the posterior between depth levels of 500 and 1000 m assimilation increased temperature gradients as illustrated by the downward tilting of the 10 c and 5 c isotherms below 1000 m no significant changes between free run and posterior are observed in the temperature field showing that ctd observed data were close to climatology for deep layers 3 3 impact of assimilation over non assimilated variables beyond improvements to assimilated variables the i4d var data assimilation does modify the behavior of non assimilated state variables in this case the horizontal velocity components the correction of surface elevation gradients temperature and salinity fields as well as surface stress and heat flux indirectly affects velocities through the pressure gradient term and viscous stress terms of the momentum balance equations fig 15 shows averaged cross sectional velocities for the same time period and similar transect of the ceres iv cruise presented in fig 14 this location is particularly interesting as the bc and the intermediate western boundary current iwbc are well established and the interaction of this current system with topography in a point where coastline orientation changes can trigger the formation of meanders eddies and vortex dipoles south of cape frio miranda 2013 the previously discussed corrections made to the temperature field and consequently to the density field directly affect surface and subsurface velocities the slight thermocline lifting and the reduction of surface temperature gradients observed in the posterior adjust the bc position and strength with its core being moved from the continental shelf break at 200 m water depth in free run to the 800 m isobath over the continental slope in the posterior below the bc the increase of density gradients at intermediate water levels lead to intensification of the iwbc jet and an increase of its vertical extension compared to the free run the adjusted velocity field on the continental slope after ctd assimilation is much closer to the one provided by belo 2011 when evaluating data from the same radial of the ceres iv oceanographic cruise posterior field also shows much richer along transect velocity variability further offshore on the são paulo plateau distances greater than 200 km due to both surface features imputed by ssh and ctd data assimilation the meridional mass transport associated with the bc which is the western boundary current of the south atlantic subtropical gyre gives a good indication of model consistency with the large scale circulation climatological values of the meridional transport of the bc consolidated by schmid and majumder 2018 from earlier studies range from 1 to 7 sv 1 sv is 106 m3 s between 19 s and 22 5 s in the upper 400 to 500 m to about 17 sv at 28 s as the vertical extent and strength of the bc increases due to limitations on the length of observed timeseries and on the number of surveys these estimates present large standard deviations fig 16 shows a comparison between climatological ranges of the bc mass transport from literature and those obtained from roms over the course of 2010 the climatological values are derived from schmid and majumder 2018 who gathered in situ mass transport estimates from previous studies the layer thicknesses used to compute roms mass transports were 400 m north of 27 s and 800 m elsewhere which is close to what was used in most of the observational studies the overall trend of absolute volume transport growth southward of 22 s is adequately captured by all roms simulations clearly showing the southward increase of bc transport negative values the free run presents slightly lower estimated transports at 20 s 22 s and 28 s and the assimilated runs at 20 s and 28 s it is also observed that at the southernmost latitude 28 s where the bc transport has contribution of both surface and intermediate water masses the assimilated runs present lower deviations than free run regarding the latitudes where roms transports are slightly higher than the observed climatology a similar pattern was found by schmid and majumder 2018 when calculating the mass transport from a combination of the global assimilative models hycom reanalysis 1993 2012 and hycom analysis 2013 2015 monthly mean fields according to the authors the strengthening of the bc in the referred model was beginning farther north than estimated with observational data explaining the higher transport values found a similar analysis of the mean fields not shown revealed an analogous pattern for this roms simulation however all model estimations have considerable overlapping regions within the large standard deviations of the observed climatology further comparisons to western boundary current transports will be considered in a future work regarding the continental slope circulation the present work is mainly focused on the são paulo plateau mesoscale ocean circulation the i4d var runs showed stronger mass transports and wider standard deviations which can be verified in fig 16 by comparing the medians and the width of the horizontal boxes of the free run with the prior and posterior runs the most notable increase occurs at 24 s this zonal section is right after the sudden change of the continental slope orientation and steepness off cape frio where more intense variability of the bc and the presence of energetic eddies are expected the intensification of the mesoscale eddy activity achieved through the assimilation procedure is thus responsible to greater variance of the meridional mass transport at this particular transect a remarkable example of the rich mesoscale field south of 24 s is the eddy dipole presented in fig 2 where a sequence of ssh snapshots and geostrophic velocity field during august and september 2010 were presented the striking current intensification of this particular dipole structure was captured by in situ current data measurements at p1 mooring located at 25 83 s 42 86 w marked as a red square in fig 17 at 2200 m depth hourly sampled mooring data were available in the months of august and september 2010 during the occurrence of the aforementioned dipole the upper 400 m of the water column were profiled with an upward looking 75 khz adcp and the 50 m water depth bin observations were used to assess model performance the observed current measurements were filtered using a 40 h low pass lanczos filter to retain the sub inertial variability prior to model comparisons fig 17 shows ssh and surface currents from roms free run prior and posterior on 5 september 2010 when the mooring location is best aligned with the dipole central jet axis it is interesting to note that a structure resembling an eddy dipole is present in the free run near 25 s and 41 w there a strong meandering of the bc and an anticyclonic eddy interact causing a southeastward deflection of the bc jet however the core of this feature is dislocated by almost 2 east and 1 north off the position seen in the altimetric observations presented in fig 2 and off the p1 mooring coordinates in the prior and posterior fields the eddy dipole is correctly positioned the major difference between the prior and posterior is the increase of surface elevation maximums in the latter one the main circulation features shown in the analysis are already present in the prior i e the sequence of alternating low and high surface elevations east of the p1 mooring this is very similar to that seen in the altimetry as an obvious consequence of the data assimilation such variability is not present in the free run where ssh field is smoother north of 24 s and south of 26 s where the bc is reorganized and follows the contours of the continental slope a fairly good representation is achieved in the free run with minor differences to the assimilation run this was already noticed in the mass transport analysis showed in fig 16 which reinforces the vicinity of 24 s to 26 s as a region with higher variability and more impacted by the assimilation procedure current speeds at the p1 mooring during the dipole event presented peaks over 1 m s 1 on september 5 2010 black dots in fig 18a with a southward direction fig 18b this agrees with the sea surface topography signature of fig 17 it is interesting to note a directional migration of the single point eulerian currents from a west northwest to a south southwest orientation during the first 30 days of august this is associated to the westward migration of the cyclonic eddy in the inshore side of the dipole see fig 2 modeled timeseries presents substantial differences between the free and assimilative runs the free run fails to capture the magnitude and direction of currents greatly underestimating its intensity and variability the direction is also incorrectly reproduced and poorly correlated in virtue of the smoothness of the mesoscale field at this particular period as already seen in fig 17 on the other hand prior and posterior timeseries are able to capture the main current intensification on september 5 2010 with maximum velocities of 0 8 and 0 9 m s 1 respectively although missing the first current intensification in august the subsequent main event during september is fairly well represented in both speed and direction the directional transition mentioned on previous paragraph is reproduced by both prior and posterior runs it is worth noting that the abrupt variations of the prior direction in fig 18b are caused by the cartesian representation of a circular variable where angles in the north sector abruptly change from 360 to 0 a better skill assessment of the various simulations is presented in fig 18c in the form of the so called taylor diagram this diagram provides a concise statistical summary of how well patterns match each other in terms of their correlation their root mean square difference and the ratio of their variance taylor 2001 statistics of modeled and observed current speeds shown in fig 18a were graphically represented in fig 18c the taylor diagram confirms that the posterior run is the best simulation with higher correlation 0 55 and a standard deviation closer to the observations 0 2 m s than the free and the prior runs the prior presents similar standard deviations to the posterior although with much lower correlation 0 24 the free run has a standard deviation about 10 times smaller than observations due to the absence of variability in its timeseries despite having higher correlation 0 32 the large velocity bias of the free run makes it the least accurate simulation the current speed rmses for the free run prior and posterior are 0 43 0 27 and 0 21 m s respectively while the ebs are 0 38 0 15 and 0 11 m s the adequate input of open ocean surface signals through the assimilation procedure is then crucial for adequate reproduction of eddy dipoles driven currents over the são paulo plateau with error and bias reductions in current speed on the order of 51 and 71 respectively the directional distribution of surface currents at the p1 mooring during the dipole event is presented in fig 19 in the form of polar histograms roms results are also shown the timeseries used are those of fig 18 observed current directions are mainly towards the south and west sectors and these are also the directions of the most intense currents the most frequent speed values are between 0 2 and 0 6 m s 1 the free run directional distribution is concentrated northeastward although no measured currents are observed in this particular sector and all modeled speed values lie in the class between 0 and 0 2 m s 1 much lower than measured ones the directional distributions of the assimilative runs are much closer to the observations in the prior the most frequent directions are south and south southeastward with peak current speeds between 0 6 and 0 8 m s 1 however the frequently measured west and west northwest directions are not well reproduced with more occurrences in the north northwest and north directions the posterior has a predominant southward flow but frequent occurrences towards the west and west northwest are also present peak velocities between 0 8 and 1 0 m s 1 are reached in the south direction and no occurrences are found in the north northeast and east directions just like the observations the directional distribution of surface current speeds during the dipole event is much better reproduced by the posterior assimilative run which correctly captures most of frequent directions and speed values a final skill assessment is performed by comparing this roms i4d var implementation with publicly available global reanalysis products of similar resolution frequently used by the scientific community the selected models chosen for comparison were the 3 hourly snapshots of the global ocean forecasting system gofs 3 1 from the hycom consortium with the navy coupled ocean data assimilation hycom ncoda system publicly available at https www hycom org dataserver gofs 3pt1 reanalysis hereafter hycom and daily means from the mercator ocean global reanalysis 12v1 glorys from copernicus marine and environmental services cmems publicly available at https resources marine copernicus eu option com csw view details product id global reanalysis phy 001 030 hereafter glorys both products have 1 12 horizontal resolution hycom has 41 vertical levels while glorys has 50 vertical levels in this study both global reanalysis timeseries were low pass filtered with a 40 h lanczos filter before comparisons fig 20 presents measured and modeled current time series for the level 56 m below sea surface along the full year 2010 it is observed that most of the time measured current speeds have values lower than 1 knot 0 51 m s but gradually increase in august and september due to the eddy dipole previously discussed observed current direction shows a rich variability along the year migrating from w to s anti cyclonic sense during the passage of the eddy dipole in august and september the regional roms and global hycom and glorys models are capable to capture the measured current variability along the year even in the complex directionally scattered flow conditions of the são paulo plateau the taylor diagram shows that all models have similar standard deviation and correlation when observed data of the full year is used for evaluation correlation coefficients were 0 56 0 54 and 0 53 for glorys roms and hycom respectively it is important to point out that the models have distinct methodologies and intervals of data assimilation a detailed look into september 2010 in the period of major current intensification better reveals differences on how each reanalysis reproduces the eddy dipole dynamics in the p1 mooring site fig 21 shows the currents time series and model skill just like fig 20 but for the period of september 1st to 25th the observed extreme current on september 5 is better simulated by roms i4d var as the current growth and its peak velocity are better reproduced on timeline hycom and glorys show intensification however the peak velocities are delayed by a few days the current speed behavior following this peak is also better reproduced by roms i4d var while hycom and glorys under or overestimate it the directional behavior however is better reproduced in the global reanalyses particularly by hycom although all models converge to the same directional sectors particularly during the extreme event on september 5 the final skill presented in the taylor diagram confirms that roms i4d var overperforms the global reanalyses during this particular period with higher correlation 0 84 than hycom 0 57 and glorys 0 5 and similar standard deviations centered root mean square differences for hycom and glorys are between 0 20 and 0 25 m s 1 which are larger than 0 15 m s 1 attained by roms i4d var 4 conclusions this paper presents an application of the regional ocean modeling system roms to simulate the ocean circulation in the southwestern atlantic ocean within a domain covering the entire south southeast brazilian shelf a hindcast for the year of 2010 using roms i4d var assimilation module was produced assimilating satellite ssh sst and in situ ts vertical profiles results were compared against both assimilated and non assimilated variables to assess the assimilation convergence and evaluate its impact a particular emphasis was given on the assessment of an extreme mesoscale event at the são paulo plateau an eddy dipole south of 24 s during august and september 2010 where current measurements were available the simulation of this feature in the correct spatial and time dimensions is quite challenging as it depends on the interaction between the bc instabilities and large scale open ocean signals coming from the east the assimilation algorithm worked properly reducing the nonlinear cost function by about 50 of its initial values over all 7 day assimilative cycles the magnitude of the increments to the posterior analysis fields remained stable during the integration period and the cross correlation between the posterior and assimilated variables was greater than 80 although the free run presented biases in the surface fields most of them could be reduced but not entirely corrected by assimilation the regions with larger biases were coastal areas in the continental shelf north of 23 s for sst and the deep portion of santos basin for ssh when compared to the free run all assimilated variables ssh sst and in situ ts profiles were positively impacted by assimilation rmse reductions of 47 and 27 were achieved for ssh and sst over the entire domain comparisons with vertical ts profiles showed significant improvements in the upper 250 m depth and null or slight degradation below possibly due to differences in the ts advection schemes between the simulations and magnitude of observational errors assigned for the profiles nevertheless eb were consistently reduced for both temperature and salinity in the entire water column although not assimilated near surface velocity was profoundly impacted by the assimilation due to the information provided by observed ssh this result is consistent with other assimilation experiments santana et al 2020 tanajura et al 2020 zavala garay et al 2012 the bc meridional mass transport growth south of 20 s is properly reproduced by both assimilative and free runs an increase in the median and intensification of mass transport were detected in the prior and posterior results with respect to the free run although the median mass transport of all simulations was always higher than climatological values between 22 s and 28 s most of the estimations were within the large uncertainty of observed values the surface signature of the eddy dipole event on august and september 2010 at the são paulo plateau was adequately reproduced by the assimilative runs with the conjunction of a cyclonic and an anticyclonic eddy and a strong southward jet in their common interface although a large bc meander and an anticyclonic structure resembling a dipole were present in the free run it was dislocated by more than 1 from its correct position and much of the surface elevation variability over the são paulo plateau was absent surface currents intensification associated with the core of the eddy dipole was captured by a mooring deployed at 2200 m depth at the plateau measured current speeds at 56 m depth reached more than 1 m s 1 on september 5 2010 the prior and posterior assimilative roms runs correctly represented this event with maximum velocities of 0 8 and 0 9 m s 1 respectively the posterior run presented rmse and eb reductions for current velocities of 51 and 71 respectively which are quite significant results the directional distribution of current speeds with south and westward intensifications was also much better represented in the assimilative runs compared to established global reanalyses products the regional roms i4d var implementation have similar skill in simulating the overall flow conditions at the são paulo plateau for instance when compared to observed near surface current data for the full year of 2010 in the middle of the plateau glorys presented slightly higher correlation coefficient 0 56 than our implementation of roms i4d var 0 54 and hycom 0 53 on a broad sense we think that for basin scale features such as the atlantic meridional overturning circulation amoc or cyclogenesis and trajectories of agulhas current eddies over the south atlantic basin the global models might be the most suitable research tools on the other hand for some specific regional features such as mesoscale eddies at the são paulo plateau or bc instabilities regional ocean models can be very skillful tools to improve global model results and pursue detailed oceanographic processes studies in this sense this regional roms i4d var implementation showed better skill to reproduce the eddy dipole event of september 2010 and outperformed these reanalysis products during the most intense currents period by achieving higher correlation coefficient 0 84 when compared to hycom 0 56 and glorys 0 5 this work demonstrates that assimilative regional simulations using boundary conditions from global models can improve simulations of the oceanic circulation at regional scales not only by increasing grid resolution but also by assimilating more detailed local observations not available for the global models this is particularly reinforced for oceanic regions where local observational data streams are not easily available to the world centers where global scale models are integrated to produce both reanalysis and forecasts however more extensive evaluation considering longer timeseries and a greater number of dipole occurrences should be done in the future for a definite estimation of higher potential skill of the regional model the realistic simulations achieved with data assimilation as reported here are capable of reproducing the main features of these intensive mesoscale events at são paulo plateau so that roms 4d var may be employed in future investigations that may lead to a better understanding of the dynamical processes that trigger and feed the dipole features we conclude that data assimilation in particular of ssh is essential to adequately simulate the complex circulation patterns that take place at the são paulo plateau where the western boundary flow along the continental slope no longer dominates mesoscale dynamics further offshore but interact with open ocean signals generating successive eddies andrioni et al 2012 belo 2011 requirements of computational efficient data assimilation for regional models with higher horizontal and vertical resolution will continue to be a priority and a challenge moore et al 2019 notwithstanding model biases show that there is room for further improvements of the non assimilative setup in order to achieve better results as presented by fox kemper et al 2019 that among challenges and prospects on ocean modeling discusses further improvement on existing or new parametrizations for eddies future efforts will be conducted to assess the roms i4d var short range predictability in the region and to assimilate new observational data such as surface currents and high resolution sea surface height provided by the future satellite mission surface water and ocean topography swot morrow et al 2019 credit authorship contribution statement thiago pires de paula methodology software data curation visualization writing original draft jose antonio moreira lima conceptualization supervision data curation writing original draft clemente augusto souza tanajura conceptualization writing review editing marcelo andrioni software data curation writing review editing renato parkinson martins project administration resources writing review editing wilton zumpichiatti arruda supervision resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge petróleo brasileiro s a petrobras for providing funding computational resources observed currents and ts profiles measurements in santos basin to execute and validate our simulations and the centro de hidrografia da marinha chm and the instituto de física of universidade federal da bahia ufba for kindly supplying qualified data from argo floats assimilated into roms we also thank the anonymous reviewers that made valuable comments and suggestions to improve the manuscript and the center for parallel computations nacad at the federal university of rio de janeiro ufrj for additional computational resources used for i4d var assimilation sensitivity tests agência nacional do petróleo gás natural e biocombustíveis anp also provided funding for the research assistant of prh 9 1 at laboratorio de mecânica computacional e sistemas offshore lamcso coppe ufrj 
23886,the northern pacific ocean swell environment is generated by extratropical cyclones originating at mid latitude regions that travel thousands of miles unimpeded across the pacific ocean some of these massive swells reach the hawaiian islands causing damage to the shoreline and coastal infrastructure understanding the cause and relation between extratropical ex cyclone trends and associated swells that affect the hawaiian islands is essential towards coastal mitigation from destructive flooding the strong ex cyclogenesis events are detected from the atmospheric reanalysis dataset during 1979 2017 and are used to hindcast swells in the north pacific domain using modeling and in situ observations our results show a rise in the number and intensity of strong ex cyclones during 1979 2017 and this increase accelerates during 2007 2017 the deseasonalized and thiel sen trends show that poleward and westward movement and increment in the frequency of strong ex cyclones cause a significant rise in swell generation and intensity during 2007 2017 almost one third of the strong ex cyclone generated waves reach the hawaiian islands during 1979 2017 and one quarter of it during 2007 2017 the deseasonalized maximum daily significant wave height and peak period trend slightly decreased during 1979 2017 however it significantly increased during 2007 2017 these trends show similarity with el niño southern oscillation events which affect the ex cyclone pattern keywords extratropical storm wave hindcast ocean waves enso wave trend 1 introduction ozone depletion at the stratosphere in the polar cycle bengtsson et al 2009 vose et al 2014 rising greenhouse gas emission in the troposphere geng and sugi 2003 graham and diaz 2001 and the increasing temperature gradient of the ocean surface inatsu et al 2003 have been impacting the extratropical winter cyclone ex cyclone intensity and the frequency in the north pacific the mid latitude cyclones have decreased with reduced upper level westerlies due to the declining trend of a temperature gradient from the equator berry et al 2011 brancome and gutowski 1992 gitelman et al 1997 graham et al 2013 graham and diaz 2001 gulev et al 2001 hall et al 1994 iwao et al 2012 ulbrich et al 2009 wang et al 2006 zhang and wang 1997 the cyclonic activity decrease and the mean intensity at the mid latitudes in winter are accompanied by an increase in the cyclonic activity at the high latitudes due to the pacific jet s northward expansion and baroclinic instability moving towards the equator berry et al 2011 chang and fu 2002 chang and yau 2016 geng and sugi 2001 graham and diaz 2001 gulev et al 2001 harnik and chang 2004 lambert 1996 ulbrich et al 2009 wang et al 2006 this positional change towards poles of the storms reduces the intensity and the number of cyclonic events below 45 n bengtsson et al 2006 fischer bruns et al 2005 lambert and fyfe 2006 löptien et al 2008 seiler and zwiers 2016 ulbrich et al 2009 yin 2005 during winter northwest swells reaching the hawaiian islands are generated at the aleutian and kuril islands lambert 1996 li et al 2016 simmonds and keay 2002 vitousek and fletcher 2008 the swells reaching the island shorelines can impact the flooding frequency damage occurrence and surf tourism of the region even though the multi model wave state around the island has been examined using observations caldwell 2005 buoy measurement vitousek and fletcher 2008 and hindcast modeling hemer et al 2011 li et al 2016 the regional and seasonal variations in the trend of ex cyclones and its influence on the northwest swells remain uncertain the correlation between the high energy waves and ex cyclones has been done either in high latitudes i e francis et al 2011 francis and atkinson 2012 thomson and rogers 2014 or in a limited temporal scale i e onat and francis 2018 in the north pacific we aim to define the trend in the ex cyclone generated swells affecting the hawaiian islands to understand how the atmospheric drivers impact the swell trends to achieve that we identify the strong ex cyclones and their trends use them to generate swells reaching the hawaiian islands employing a wave model and examine the trends of those swells these associations are done regionally and seasonally winter in decadal 2007 2017 and long term variations 1979 2017 this article proceeds with the methods section where we explain the atmospheric reanalysis and buoy datasets used and the approach to spot the strong ex cyclones wave modeling and statistical analysis within the results section we present the trend of the ex cyclones swells and the modeling validation and discuss the implications in the discussion finally we conclude by summarizing the results and their indication for future studies 2 methods 2 1 wind and buoy datasets the atmospheric data used is the combination of two six hourly reanalysis datasets from climate forecast system reanalysis cfsr and cfsr2 saha et al 2011 2010 between december of 1979 to january of 2018 the boundary of an extracted dataset of pressure reduced to mean sea level mslp geopotential height z and meridional v and zonal u wind speeds 10 m above sea level at every hour is 23 n 66 n and 120 w 120 e at 0 5 grid resolution the cyclone detection algorithm is applied to this extracted data to capture the strong extratropical cyclogenesis locations the national data buoy center ndbc noaa 2017 buoys detailed in table 1 and fig 1 were used for validation 2 2 strong extratropical cyclone detection algorithm we use an algorithm to detect the strong extratropical cyclones to record the cyclogenesis location winds at 10 m above the sea surface and the cyclone deepening rate reduction in the mslp over time with a 0 5 grid resolution in the np multiple counts are eliminated by recording only one cyclone event at and around the diameter of any grid throughout 72 h this algorithm captures small and synoptic scale events from strong eddies by i removing background flow due to unfiltered pressures using geopotential height filters and ii capturing slower progressing synoptic systems using mslp hodges et al 2003 and iii distinguishing storms at the beginning of cyclogenesis using vorticity field filters sorteberg and walsh 2008 the algorithm identifies the individual strong cyclonic movement generation that followed the constraints stated in table 2 but does not track them in the baroclinic field the detected strong ex cyclone locations can be seen in appendix the algorithm criteria and reasoning at any grid point are given in table 2 the algorithm is verified by comparing it with the best track data of hurricane and tropical storm datasets of hurdat2 landsea et al 2016 cphc chu and wu 2008 and jtwc joint typhoon warning center jtwc 2014 between 1979 2014 using hurdat2 and jtwc the algorithm eliminates wind noise within 65 km h 35 knot range due to depressions storms or pressure lows comparing the algorithm captured storms and the hurdat2 cphc and jwtc indicated that the algorithm does not accidentally capture any tropical storm depression or lows and identifies it as a strong ex cyclone 2 3 wave model wavewatch iii ww3 version 5 16 the wavewatch iii development group 2016 tolman 1991 is used to hindcast wind forcing in the hawaiian islands the model wave parameters and source files are given in table 3 the model domain comprised of two nested rectangular grids as the main domain covers the np 120 w 120 e and 0 66 n with 0 5 resolution and the nested one covers the hawaiian islands 161 w 154 w and 18 23 n with 0 05 resolution the continuous 6 hourly wind fields from cfsr and cfsr2 during 1979 2017 are used as wind forcing for hindcast simulations the bathymetry is prepared using etopo1 amante and eakins 2009 with one arcmin resolution the land sea boundaries are defined using the full resolution gshhg dataset https www soest hawaii edu pwessel gshhg the wave open boundary conditions used are from noaa ww3 30 year hindcast archives https polar ncep noaa gov waves hindcasts the directional spectrum partitioning creates a storm generated series of swells that are referred to as swell systems here the partitioned swell systems at the buoy locations are also correlated to the ex cyclone events identified from the algorithm ex cyclogenesis detection is advantageous in finding all the ex cyclonic locations by identifying individual cyclones however the cyclone track is not used to run the model due to uncertainty of the swell start up time leading to duration limited waves in the ocean after the swell system partition is applied to the model results at the buoy locations these systems are backtracked to the detected cyclogenesis locations using the dispersion equation the correlation is made using the backtracking of the swell system approach this approach includes finding the group velocity of the swell system by deep water wave dispersion and comparing the swell system origination time with the strong ex cyclone generation time the accepted error is 3 h due to 6 hourly wind reanalysis dataset along the 2 5 degree of the peak direction this backtracking approach also allows for removing the uncorrelated swell records and separating the adjacent swells by setting an angle and a distance threshold to the partitioning algorithm however automating the spectral spread may cause additional swell system formation the finer directional spectral resolution was chosen to reduce the garden sprinkler effect in the wave model resulting from breaking down the swell fields into discrete zones during spatial propagation tolman 2002 the swell attenuation and garden sprinkler effect are eliminated by partitioning the swells in deep water buoy locations in a finer directional resolution 2 4 statistical analysis statistical analysis includes the trend analysis on mslp geopotential height significant wave height wave peak period wave peak direction and validation between the model and buoy wave data the trends are calculated via two approaches using thiel sentrend ts and deseasonalized trend t calculations over the recording period similar to onat 2018 and onat and francis 2018 the monotonic trend h α is assessed using the mann kendall non parametric test gilbert 1987 kendall 1975 mann 1945 to identify significant results and the relation to randomness by eliminating gross errors and non normality of the distribution wu et al 2017 the first approach the thiel sen trend is calculated by 1 ts median x ij x ik j k where i is month and j and k represents the time for that i th month and j k for the data x aarnes et al 2015 sen 1968 stopa and cheung 2014 wang and swail 2001 young et al 2011 not having any distributional assumption allows the test to be less sensitive to accumulated errors the months used for the analysis are i 1 is january i 2 is february i 3 is march i 4 is october i 5 is november i 6 is december the number of differences between the positive and negative s for any dataset x 1 x 2 x n for n measurements is given by 2 s i k 1 n i 1 j k 1 n i s g n x ij x ik where sgn x ij x ik 0 for may june july august and september which only affect winter and fall months the monthly trend for each year is s 0 and the variance of s is given by 3 s i 1 6 s i 4 v a r s i 1 6 v a r s i i 1 6 l 1 6 c o v s i s l 5 v a r s i n i n i 1 2 n i 5 18 where s is modified to consider n i number of data points in the i th month the covariance c o v s i s l and i l hirsch et al 1982 the tolerable probability of α 0 05 is used to accept the randomness of the null hypothesis to satisfy that the absolute value of the standard normal variate is smaller than 1 96 the standard normal variate z is given by 6 z s 1 v a r s i f s 0 0 i f s 0 s 1 v a r s i f s 0 the second approach to calculate the trend uses the deseasonalized trend approach t the cyclical pattern of the swell and cyclones are eliminated by separating the time series y into a non seasonal deterministic trend t seasonal deterministic component s and the stochastic irregular component i the time series components are assumed as 7 y t s i the deseasonalization of the time series y is performed by deducting its moving average from itself the deseasonalized trend series t is obtained by applying a seasonal filter to the de trended time series y s which results in the linear regression fitting findley et al 1998 additionally we applied partial least square fitting using leave one out cross validation to compare the effect of the el niño years to understand the behavior of enso on the maximum daily significant wave height the maximum significant wave height yearly values as a set of five yearly predictors describe the average trend response in minitab statistical software the response plot to indicate how well the trend average predicts each set of observations was given the validation between the wave model and the buoy measurements is calculated via mean error me root mean square error rmse bias correlation coefficient r 2 and scatter index si 3 results this section examines the trends of ex cyclones and their generated swells reaching the hawaiian islands in the np the modeled swells from ww3 are validated with the in situ measurement results for hanalei during 2015 2016 fig 2 the significant wave height hs comparison shows a high r2 a small rmse and si and low biases table 4 this indicates accurate decomposition of the swells at the buoy locations except for 188 hilo sheltered from the northwest facing swells table 4 the peak period tp comparison shows higher rmse si bias and lower r2 than the hs validation comparison table 4 this is due to the coarse partitioning of the swell systems in the refracted zones the model comparison shows a high correlation of the north to northwest swells 3 1 the strong extratropical cyclone trends the detected strong extratropical cyclogenesis points are counted for each year during 1979 2017 and found to increase by 7 3 cyclogenesis points per year during the 2007 2017 period the mslp and geopotential height significantly decrease compared to the 1979 2017 results table 5 the results indicate the number of high intensity ex cyclonic events increasing with an exceedingly higher rate during 2007 2017 the positional trend of the detected ex cyclonic events over 1979 2017 indicates 0 63 0 02 year southward and 4 62 0 12 year westward during 1979 2017 fig 3 during 2007 2017 the latitude positional change of the strong ex cyclogenesis locations moved them more northward by 2 7 0 30 year and decreased the equatorward positional change the meridional change has not shown much difference compared to all the years with 4 65 however the shift rate increased to 0 52 year westward during 2007 2017 still the strong ex cyclones originated along 43 45 n around the kuril and aleutian islands the barrier island in the arctic sea prevents wave energy from reaching the hawaiian islands the strong ex cyclone positions are impacted with enso el niño southern oscillation events moving towards the equator during the el niño seasons and poleward during the la niña seasons the results showed that the number of storm cyclogenesis events increases during the strong i e high indices el niño seasons like 2009 2010 and 2015 2016 whereas the number of storms decreases during the strong la niña seasons 2007 2008 2010 2011 and 2011 2012 appendix the strongest ex cyclone events occur during december february 3 2 swell trends the trends of the strong ex cyclones and associated swells are examined from the model results the trend rate defined in this manuscript is the slope of the linear trend line two methods calculate the trend line i deseasonalizing the average modeled wave data for each day and ii applying the thiel sen method to the moving averages the trend magnitude is the change value between the start and end values of the trend line the monthly intensity of the cyclones increases starting from november with the highest intensity in february the statistical descriptions of the daily time series of the swells through the months are given in table 6 the mann kendall test on the swell results presents significant trends during all the recorded months except january during 1979 2017 table 6 the deseasonalized trend of daily max hs of the swells indicates the greatest trend changes are observed in january fig 4 the monthly hs trend decreases from october to december before peaking in january up to 0 21 m fig 4 during 1979 2017 during 2007 2017 the monthly hs trends show a higher pattern than 1979 2017 the monthly trend increases during 2007 2017 ranging around 0 40 0 45 m and peaks in january and february to 0 65 m fig 5 the south shores of the islands are sheltered from the north pacific swells and show the lowest trend rates the maximum daily peak period deseasonalized trend of the swells shows the movement of the strong swells throughout the months figs 6 and 7 even though there is a slight increase in the trend rate magnitude of peak period during winter months peaking in january this change is very small up to 0 008 s and is not significant according to the mann kendall test fig 6 the strong ex cyclone belt moves towards the equator in winter making the trend rate smaller as the swells travel a shorter distance than in other seasons fig 7 in february the ex cyclone belt is closest to the hawaiian islands showing the smallest trend magnitude during 2007 2017 the highest hs trend differences are located northwest of kaua i the wave events that affect the hawaiian islands are trade winds east northeast southern swells south southwest swells kona storms south southeast tropical cyclones and north pacific swells vitousek and fletcher 2008 the wave climate reaching the hanalei buoy during the october january period is partitioned to understand the entire swell systems reaching the islands during the recording period the modeled swell systems that matched and generated from the strong ex cyclogenesis locations are divided into the total swell systems to understand how much of the swells are impacting the islands from these cyclones the strong ex cyclonic events generate up to 28 5 of the total swells during 1979 2017 and 25 8 of the total swells during 2007 2017 reaching the hawaiian islands the deseasonalized trend of the swells during 1979 2017 for the modeled results is presented using the highest peak of the daily time series distribution of the swell series table 7 the trend characteristics during 1979 2017 and within 2007 2017 show differences for instance in the hanalei location the deseasonalized trend rate of the maximum daily hs t at hs max in table 7 shows a definite increase 0 29 m between 2007 2017 while showing a decrease 0 23 m during 1979 2017 table 7 the trend of the maximum swell hs and tp indicates a decrease of 0 003 m year and 0 004 s year during 1979 2017 compared to an increase of 0 02 m year and 0 08 s year during 2007 2017 for the hanalei location table 7 the average swell deseasonalized trend of hs and tp shows a decrease of 0 002 m year and 0 008 s year during 1979 2017 compared to an increase of 0 008 m year and 0 06 s year during 2007 2017 for the hanalei location table 7 regarding hanalei northwest of kaua i the change in average hs trend is 0 13 m and the change in average tp trend is 0 58 s during 1979 2017 on the other hand during 2007 2017 the trend magnitude of maximum daily hs is 0 29 m and the tp is 1 51 s and the change in average hs is 0 15 m and the average tp is 1 12 s the most observed direction ranges from 325 to 330 similar patterns are observed in the other buoy locations the deseasonalized trend computation results are similar to the thiel sen method results similarly for the waimea buoy location oahu the overall trend of maximum swell hs and tp shows a decrease of 0 003 m year and 0 002 s year table 5 during 1979 2017 compared to an increase of 0 021 m year and 0 046 s year during 2007 2017 table 7 the north facing buoy locations hanalei waimea and paunela reveal higher trend rates than the sheltered buoy locations mokapu and hilo table 7 the length of the data series and the wave climate interaction with enso essentially affect the trend analysis bromirski et al 2005 graham and diaz 2001 the trend rates indicate how the swells behave during the modeled timeline the trend rates of 1979 2017 show a slight decrease fig 8a and b the biggest swell wave height encountered during the recording period is observed at the beginning of the record period 1982 83 el niño year contrarily during 2007 2017 the 2016 el niño increases the trend close to the end of the recorded timeline fig 8c and d the mann kendall trend results also indicate a significant increase in the daily maximum swell trends the non normality of the distribution does not affect the mann kendall test wu et al 2017 thus it assesses the significant changes without a bias therefore the trend rates are the indication of the behavior of the correlated swells the trend difference maps of the hs and tp over the years also demonstrate a slight decrease in hs values change between 0 03 to 0 27 m during 1979 2017 whereas there is an increase in hs values change between 0 12 to 0 15 m during 1979 2017 fig 9 the non parametric test also aligns with deseasonalized trends throughout the years even though the overall strong ex generated swell intensity slightly decreases during 1979 2017 fig 9a b and table 7 it increased during 2007 2017 fig 9c d the partial least square regression with leave one out cross validation results on the daily maximum significant wave heights showed the regression p value is smaller than 0 5 which showed the significance of enso events on the swell trend estimates two tests are performed with five year and ten year components to include at least one el niño year in the cumulative swell systems and show decadal variability respectively in the five year method the highest predicted r2 value is 0 999 and highest predicted r2 is 0 936 and the prediction of the sum of squares is 0 108 in the decadal method the highest predicted r2 value is 1 0 and highest predicted r2 is 0 937 and the prediction of the sum of squares is 0 106 this higher r2 and the lowest sum of squares indicate the trend line is very well predicted by the daily maximum significant wave height of the swell systems in every five year or decadal components in other words a good model of trend estimation of the swell systems requires the enso years to be included the response plots of the two fits are given between the calculated and the actual trend line response in fig 10 the plot fig 10 shows a linear fit with less difference between the fitted and the cross validated values which indicates the swell systems predict the trend line well the yearly and bi yearly total of the mei multivariate enso index and pdo pacific decadal oscillation indices are plotted for 1979 2017 and 2007 2017 to observe the enso fluctuations and how their trends align with the significant wave height trend of the peak swells each year fig 11 the linear trends of the indices are calculated with linear regression fitting the total mei and pdo indices fluctuate similarly during the yearly and bi yearly sums the total bi yearly during the modeled timeline and the total yearly mei and pdo index scatter plots show a decreasing trend during 1979 2017 fig 11a b and an increasing trend during 2007 2017 fig 11c d the mei and pdo trend lines show similar patterns where the maximum hs trend line of the swells is at the hanalei location fig 11 4 discussion the wind reanalysis dataset greatly impacts the wave model accuracy the cfsr dataset is reported to show additional moderate intensity cyclones wang et al 2016 which may result in slight variations in the captured ex cyclogenesis locations compared to other reanalysis datasets like era interim and merra it should be emphasized that the strong ex cyclogenesis events have not been grouped under independent storms the reason is that the number of counted cyclogenesis events would create a different density of cyclogenesis events per storm to analyze a movement trend the meridional shift of the cyclones to the west is observed during la niña the cyclonic belt moves slightly equatorward during 1979 2017 whereas during 2007 2017 ex cyclones move northward supporting poleward intensification by fyfe 2003 and yin 2005 there is a high correlation between the wave model and the buoy data on the swell facing shores northwest to north there is a low correlation of the model results with the buoys in the sheltered areas like 188 hilo which does not face the northwest swells directly which may lead to overestimating the model results similar findings of overestimation of the models for the multi state ocean were also found by li et al 2016 further tuning the dispersion of frequency and angular spreading can provide a better swell attenuation rate in tropical and subtropical zones jiang et al 2016 also accurate wave state modeling requires more nested and high resolution nearshore models to reduce abrupt changes in the continental shelf and bathymetry the trend rates and trend magnitude present a relationship between the strong ex cyclonic points and the swells generated the trend calculations are highly dependent on the data series the difference of the rates between 1979 2017 and 2007 2017 demonstrates that the trends should be considered an indication of general behavior to understand the changes in decadal or overall scale whether computed by the thiel sen or deseasonalized methods these trends should be tested with a non parametric test such as mann kendall to assess the significance of the trend we noticed that trend calculations depend on storm cycles annual and seasonal fluctuations and enso intensity the cyclones and thus the swell systems intensify from november reaching the highest in february however a more detailed analysis can be done to separately analyze the el niño year swells to understand whether their impact on the swells has changed the leave one out cross validation can be improved by carefully examining the start and end date of the enso years and applying leave one out cross validation however this may also create a bias in the results due to the uncertainty of the event period we also suggest that the minimum component selection should be five years because anything lower than that may reflect the trend line falsely the r2 value reduces and the difference between the r2 and the predicted r2 gets bigger this may lead to an over fit issue in which the trend line may fail to predict the future estimates even though there is an increase in hs during the boreal winter we found that the decreasing trend for 38 years for the northwest swells aligns with a slightly decreasing trend found by wang et al 2009 and young et al 2011 our study finds an increase in hs over the last ten years for the np which is similar to the francis et al s 2011 results stating a 0 020 m year increase of hs for the se chukchi sea and a 0 025 m year increase for the pacific arctic over recent years 1993 2011 the strong trade winds coming from the eastern equatorial pacific and enhancing with la niña might also be the reason for the slight decreasing trends in the propagated swells sasaki 2014 5 conclusion our work presents the relationship between the strong ex cyclones and their generated swells reaching the hawaiian islands strong ex cyclones in the northern pacific ocean are found to be increasing in frequency and intensity the strong ex cyclones are identified by constraints on the mslp geopotential height and vorticity fields of the cfsr wind reanalysis dataset from 1979 2017 we found that the number of strong ex cyclogenesis over 1979 2017 has increased and this rise accelerated during 2007 2017 the average of mslp and geopotential height drops indicated the intensification during 1979 2017 the strong ex cyclones also moved southward and westward during 1979 2017 compared to the northward and a westward shift during 2007 2017 the strong ex cyclones gradually increase during the winter months reaching their highest number of events in february the strong ex cyclones generate 28 5 of the total swells during 1979 2017 and 25 8 of the total swells during 2007 2017 reaching the hawaiian islands for the northwest of kaua i hanalei and o ahu waimea the deseasonalized peak trend of the hs and tp shows a slight decrease during 1979 2017 however they increase at higher rates during 2007 2017 our trend patterns align with annual and seasonal fluctuations of storm cycles and enso fluctuations and intensity we find a similar hs increase on northwest facing buoy locations hanalei waimea and paunela and a slightly lower trend rate increase in the sheltered buoy locations mokapu and hilo the tp change reflects how the strong ex cyclone belt fluctuates moving closer to the equator during boreal winter the strong enso events impact the trend rates the mei and pdo index trends align with the hs trend to reflect these enso fluctuations during the recording period the increase in frequency and intensity of strong ex storms and swells in the northern pacific ocean means greater wave exposure on coastal ecosystems and infrastructure onat et al 2018a b and onat and francis 2018 state that geomorphology and wave exposure cause the highest levels of risk in defining the vulnerability in the hawaiian islands the swell statistics should also be examined at the regional and local levels to demonstrate the significant changes in the inundation hanafin et al 2012 therefore the results from our study may be essential to evaluate the coastal hazard impacts on the hawaiian coasts to keep up with the ever changing wave climate credit authorship contribution statement yaprak onat conceptualization methodology software validation formal analysis writing original draft visualization writing review editing oceana p francis supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to acknowledge the coastal hydraulics engineering resilience cher research group and lab at the department of civil and environmental engineering the university of hawai i at manoa where this research was conducted we also would like to thank the following persons from the university of hawai i at manoa ning li eva marie nosal bruce howe karl kim and zhenhua huang and peter justeson for their valuable and constructive comments on a previous study related to our manuscript and anonymous reviewers of this manuscript funding this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors appendix a supplementary data location of the cyclogenesis events the detected cyclogenesis points between october 1979 to december 2017 from the ex cyclone detection algorithm video supplementary material related to this article can be found online at https doi org 10 1016 j ocemod 2021 101888 appendix a supplementary data the following is the supplementary material related to this article video s1 the detected cyclogenesis points between october 1979 to december 2017 from the ex cyclone detection algorithm 
23886,the northern pacific ocean swell environment is generated by extratropical cyclones originating at mid latitude regions that travel thousands of miles unimpeded across the pacific ocean some of these massive swells reach the hawaiian islands causing damage to the shoreline and coastal infrastructure understanding the cause and relation between extratropical ex cyclone trends and associated swells that affect the hawaiian islands is essential towards coastal mitigation from destructive flooding the strong ex cyclogenesis events are detected from the atmospheric reanalysis dataset during 1979 2017 and are used to hindcast swells in the north pacific domain using modeling and in situ observations our results show a rise in the number and intensity of strong ex cyclones during 1979 2017 and this increase accelerates during 2007 2017 the deseasonalized and thiel sen trends show that poleward and westward movement and increment in the frequency of strong ex cyclones cause a significant rise in swell generation and intensity during 2007 2017 almost one third of the strong ex cyclone generated waves reach the hawaiian islands during 1979 2017 and one quarter of it during 2007 2017 the deseasonalized maximum daily significant wave height and peak period trend slightly decreased during 1979 2017 however it significantly increased during 2007 2017 these trends show similarity with el niño southern oscillation events which affect the ex cyclone pattern keywords extratropical storm wave hindcast ocean waves enso wave trend 1 introduction ozone depletion at the stratosphere in the polar cycle bengtsson et al 2009 vose et al 2014 rising greenhouse gas emission in the troposphere geng and sugi 2003 graham and diaz 2001 and the increasing temperature gradient of the ocean surface inatsu et al 2003 have been impacting the extratropical winter cyclone ex cyclone intensity and the frequency in the north pacific the mid latitude cyclones have decreased with reduced upper level westerlies due to the declining trend of a temperature gradient from the equator berry et al 2011 brancome and gutowski 1992 gitelman et al 1997 graham et al 2013 graham and diaz 2001 gulev et al 2001 hall et al 1994 iwao et al 2012 ulbrich et al 2009 wang et al 2006 zhang and wang 1997 the cyclonic activity decrease and the mean intensity at the mid latitudes in winter are accompanied by an increase in the cyclonic activity at the high latitudes due to the pacific jet s northward expansion and baroclinic instability moving towards the equator berry et al 2011 chang and fu 2002 chang and yau 2016 geng and sugi 2001 graham and diaz 2001 gulev et al 2001 harnik and chang 2004 lambert 1996 ulbrich et al 2009 wang et al 2006 this positional change towards poles of the storms reduces the intensity and the number of cyclonic events below 45 n bengtsson et al 2006 fischer bruns et al 2005 lambert and fyfe 2006 löptien et al 2008 seiler and zwiers 2016 ulbrich et al 2009 yin 2005 during winter northwest swells reaching the hawaiian islands are generated at the aleutian and kuril islands lambert 1996 li et al 2016 simmonds and keay 2002 vitousek and fletcher 2008 the swells reaching the island shorelines can impact the flooding frequency damage occurrence and surf tourism of the region even though the multi model wave state around the island has been examined using observations caldwell 2005 buoy measurement vitousek and fletcher 2008 and hindcast modeling hemer et al 2011 li et al 2016 the regional and seasonal variations in the trend of ex cyclones and its influence on the northwest swells remain uncertain the correlation between the high energy waves and ex cyclones has been done either in high latitudes i e francis et al 2011 francis and atkinson 2012 thomson and rogers 2014 or in a limited temporal scale i e onat and francis 2018 in the north pacific we aim to define the trend in the ex cyclone generated swells affecting the hawaiian islands to understand how the atmospheric drivers impact the swell trends to achieve that we identify the strong ex cyclones and their trends use them to generate swells reaching the hawaiian islands employing a wave model and examine the trends of those swells these associations are done regionally and seasonally winter in decadal 2007 2017 and long term variations 1979 2017 this article proceeds with the methods section where we explain the atmospheric reanalysis and buoy datasets used and the approach to spot the strong ex cyclones wave modeling and statistical analysis within the results section we present the trend of the ex cyclones swells and the modeling validation and discuss the implications in the discussion finally we conclude by summarizing the results and their indication for future studies 2 methods 2 1 wind and buoy datasets the atmospheric data used is the combination of two six hourly reanalysis datasets from climate forecast system reanalysis cfsr and cfsr2 saha et al 2011 2010 between december of 1979 to january of 2018 the boundary of an extracted dataset of pressure reduced to mean sea level mslp geopotential height z and meridional v and zonal u wind speeds 10 m above sea level at every hour is 23 n 66 n and 120 w 120 e at 0 5 grid resolution the cyclone detection algorithm is applied to this extracted data to capture the strong extratropical cyclogenesis locations the national data buoy center ndbc noaa 2017 buoys detailed in table 1 and fig 1 were used for validation 2 2 strong extratropical cyclone detection algorithm we use an algorithm to detect the strong extratropical cyclones to record the cyclogenesis location winds at 10 m above the sea surface and the cyclone deepening rate reduction in the mslp over time with a 0 5 grid resolution in the np multiple counts are eliminated by recording only one cyclone event at and around the diameter of any grid throughout 72 h this algorithm captures small and synoptic scale events from strong eddies by i removing background flow due to unfiltered pressures using geopotential height filters and ii capturing slower progressing synoptic systems using mslp hodges et al 2003 and iii distinguishing storms at the beginning of cyclogenesis using vorticity field filters sorteberg and walsh 2008 the algorithm identifies the individual strong cyclonic movement generation that followed the constraints stated in table 2 but does not track them in the baroclinic field the detected strong ex cyclone locations can be seen in appendix the algorithm criteria and reasoning at any grid point are given in table 2 the algorithm is verified by comparing it with the best track data of hurricane and tropical storm datasets of hurdat2 landsea et al 2016 cphc chu and wu 2008 and jtwc joint typhoon warning center jtwc 2014 between 1979 2014 using hurdat2 and jtwc the algorithm eliminates wind noise within 65 km h 35 knot range due to depressions storms or pressure lows comparing the algorithm captured storms and the hurdat2 cphc and jwtc indicated that the algorithm does not accidentally capture any tropical storm depression or lows and identifies it as a strong ex cyclone 2 3 wave model wavewatch iii ww3 version 5 16 the wavewatch iii development group 2016 tolman 1991 is used to hindcast wind forcing in the hawaiian islands the model wave parameters and source files are given in table 3 the model domain comprised of two nested rectangular grids as the main domain covers the np 120 w 120 e and 0 66 n with 0 5 resolution and the nested one covers the hawaiian islands 161 w 154 w and 18 23 n with 0 05 resolution the continuous 6 hourly wind fields from cfsr and cfsr2 during 1979 2017 are used as wind forcing for hindcast simulations the bathymetry is prepared using etopo1 amante and eakins 2009 with one arcmin resolution the land sea boundaries are defined using the full resolution gshhg dataset https www soest hawaii edu pwessel gshhg the wave open boundary conditions used are from noaa ww3 30 year hindcast archives https polar ncep noaa gov waves hindcasts the directional spectrum partitioning creates a storm generated series of swells that are referred to as swell systems here the partitioned swell systems at the buoy locations are also correlated to the ex cyclone events identified from the algorithm ex cyclogenesis detection is advantageous in finding all the ex cyclonic locations by identifying individual cyclones however the cyclone track is not used to run the model due to uncertainty of the swell start up time leading to duration limited waves in the ocean after the swell system partition is applied to the model results at the buoy locations these systems are backtracked to the detected cyclogenesis locations using the dispersion equation the correlation is made using the backtracking of the swell system approach this approach includes finding the group velocity of the swell system by deep water wave dispersion and comparing the swell system origination time with the strong ex cyclone generation time the accepted error is 3 h due to 6 hourly wind reanalysis dataset along the 2 5 degree of the peak direction this backtracking approach also allows for removing the uncorrelated swell records and separating the adjacent swells by setting an angle and a distance threshold to the partitioning algorithm however automating the spectral spread may cause additional swell system formation the finer directional spectral resolution was chosen to reduce the garden sprinkler effect in the wave model resulting from breaking down the swell fields into discrete zones during spatial propagation tolman 2002 the swell attenuation and garden sprinkler effect are eliminated by partitioning the swells in deep water buoy locations in a finer directional resolution 2 4 statistical analysis statistical analysis includes the trend analysis on mslp geopotential height significant wave height wave peak period wave peak direction and validation between the model and buoy wave data the trends are calculated via two approaches using thiel sentrend ts and deseasonalized trend t calculations over the recording period similar to onat 2018 and onat and francis 2018 the monotonic trend h α is assessed using the mann kendall non parametric test gilbert 1987 kendall 1975 mann 1945 to identify significant results and the relation to randomness by eliminating gross errors and non normality of the distribution wu et al 2017 the first approach the thiel sen trend is calculated by 1 ts median x ij x ik j k where i is month and j and k represents the time for that i th month and j k for the data x aarnes et al 2015 sen 1968 stopa and cheung 2014 wang and swail 2001 young et al 2011 not having any distributional assumption allows the test to be less sensitive to accumulated errors the months used for the analysis are i 1 is january i 2 is february i 3 is march i 4 is october i 5 is november i 6 is december the number of differences between the positive and negative s for any dataset x 1 x 2 x n for n measurements is given by 2 s i k 1 n i 1 j k 1 n i s g n x ij x ik where sgn x ij x ik 0 for may june july august and september which only affect winter and fall months the monthly trend for each year is s 0 and the variance of s is given by 3 s i 1 6 s i 4 v a r s i 1 6 v a r s i i 1 6 l 1 6 c o v s i s l 5 v a r s i n i n i 1 2 n i 5 18 where s is modified to consider n i number of data points in the i th month the covariance c o v s i s l and i l hirsch et al 1982 the tolerable probability of α 0 05 is used to accept the randomness of the null hypothesis to satisfy that the absolute value of the standard normal variate is smaller than 1 96 the standard normal variate z is given by 6 z s 1 v a r s i f s 0 0 i f s 0 s 1 v a r s i f s 0 the second approach to calculate the trend uses the deseasonalized trend approach t the cyclical pattern of the swell and cyclones are eliminated by separating the time series y into a non seasonal deterministic trend t seasonal deterministic component s and the stochastic irregular component i the time series components are assumed as 7 y t s i the deseasonalization of the time series y is performed by deducting its moving average from itself the deseasonalized trend series t is obtained by applying a seasonal filter to the de trended time series y s which results in the linear regression fitting findley et al 1998 additionally we applied partial least square fitting using leave one out cross validation to compare the effect of the el niño years to understand the behavior of enso on the maximum daily significant wave height the maximum significant wave height yearly values as a set of five yearly predictors describe the average trend response in minitab statistical software the response plot to indicate how well the trend average predicts each set of observations was given the validation between the wave model and the buoy measurements is calculated via mean error me root mean square error rmse bias correlation coefficient r 2 and scatter index si 3 results this section examines the trends of ex cyclones and their generated swells reaching the hawaiian islands in the np the modeled swells from ww3 are validated with the in situ measurement results for hanalei during 2015 2016 fig 2 the significant wave height hs comparison shows a high r2 a small rmse and si and low biases table 4 this indicates accurate decomposition of the swells at the buoy locations except for 188 hilo sheltered from the northwest facing swells table 4 the peak period tp comparison shows higher rmse si bias and lower r2 than the hs validation comparison table 4 this is due to the coarse partitioning of the swell systems in the refracted zones the model comparison shows a high correlation of the north to northwest swells 3 1 the strong extratropical cyclone trends the detected strong extratropical cyclogenesis points are counted for each year during 1979 2017 and found to increase by 7 3 cyclogenesis points per year during the 2007 2017 period the mslp and geopotential height significantly decrease compared to the 1979 2017 results table 5 the results indicate the number of high intensity ex cyclonic events increasing with an exceedingly higher rate during 2007 2017 the positional trend of the detected ex cyclonic events over 1979 2017 indicates 0 63 0 02 year southward and 4 62 0 12 year westward during 1979 2017 fig 3 during 2007 2017 the latitude positional change of the strong ex cyclogenesis locations moved them more northward by 2 7 0 30 year and decreased the equatorward positional change the meridional change has not shown much difference compared to all the years with 4 65 however the shift rate increased to 0 52 year westward during 2007 2017 still the strong ex cyclones originated along 43 45 n around the kuril and aleutian islands the barrier island in the arctic sea prevents wave energy from reaching the hawaiian islands the strong ex cyclone positions are impacted with enso el niño southern oscillation events moving towards the equator during the el niño seasons and poleward during the la niña seasons the results showed that the number of storm cyclogenesis events increases during the strong i e high indices el niño seasons like 2009 2010 and 2015 2016 whereas the number of storms decreases during the strong la niña seasons 2007 2008 2010 2011 and 2011 2012 appendix the strongest ex cyclone events occur during december february 3 2 swell trends the trends of the strong ex cyclones and associated swells are examined from the model results the trend rate defined in this manuscript is the slope of the linear trend line two methods calculate the trend line i deseasonalizing the average modeled wave data for each day and ii applying the thiel sen method to the moving averages the trend magnitude is the change value between the start and end values of the trend line the monthly intensity of the cyclones increases starting from november with the highest intensity in february the statistical descriptions of the daily time series of the swells through the months are given in table 6 the mann kendall test on the swell results presents significant trends during all the recorded months except january during 1979 2017 table 6 the deseasonalized trend of daily max hs of the swells indicates the greatest trend changes are observed in january fig 4 the monthly hs trend decreases from october to december before peaking in january up to 0 21 m fig 4 during 1979 2017 during 2007 2017 the monthly hs trends show a higher pattern than 1979 2017 the monthly trend increases during 2007 2017 ranging around 0 40 0 45 m and peaks in january and february to 0 65 m fig 5 the south shores of the islands are sheltered from the north pacific swells and show the lowest trend rates the maximum daily peak period deseasonalized trend of the swells shows the movement of the strong swells throughout the months figs 6 and 7 even though there is a slight increase in the trend rate magnitude of peak period during winter months peaking in january this change is very small up to 0 008 s and is not significant according to the mann kendall test fig 6 the strong ex cyclone belt moves towards the equator in winter making the trend rate smaller as the swells travel a shorter distance than in other seasons fig 7 in february the ex cyclone belt is closest to the hawaiian islands showing the smallest trend magnitude during 2007 2017 the highest hs trend differences are located northwest of kaua i the wave events that affect the hawaiian islands are trade winds east northeast southern swells south southwest swells kona storms south southeast tropical cyclones and north pacific swells vitousek and fletcher 2008 the wave climate reaching the hanalei buoy during the october january period is partitioned to understand the entire swell systems reaching the islands during the recording period the modeled swell systems that matched and generated from the strong ex cyclogenesis locations are divided into the total swell systems to understand how much of the swells are impacting the islands from these cyclones the strong ex cyclonic events generate up to 28 5 of the total swells during 1979 2017 and 25 8 of the total swells during 2007 2017 reaching the hawaiian islands the deseasonalized trend of the swells during 1979 2017 for the modeled results is presented using the highest peak of the daily time series distribution of the swell series table 7 the trend characteristics during 1979 2017 and within 2007 2017 show differences for instance in the hanalei location the deseasonalized trend rate of the maximum daily hs t at hs max in table 7 shows a definite increase 0 29 m between 2007 2017 while showing a decrease 0 23 m during 1979 2017 table 7 the trend of the maximum swell hs and tp indicates a decrease of 0 003 m year and 0 004 s year during 1979 2017 compared to an increase of 0 02 m year and 0 08 s year during 2007 2017 for the hanalei location table 7 the average swell deseasonalized trend of hs and tp shows a decrease of 0 002 m year and 0 008 s year during 1979 2017 compared to an increase of 0 008 m year and 0 06 s year during 2007 2017 for the hanalei location table 7 regarding hanalei northwest of kaua i the change in average hs trend is 0 13 m and the change in average tp trend is 0 58 s during 1979 2017 on the other hand during 2007 2017 the trend magnitude of maximum daily hs is 0 29 m and the tp is 1 51 s and the change in average hs is 0 15 m and the average tp is 1 12 s the most observed direction ranges from 325 to 330 similar patterns are observed in the other buoy locations the deseasonalized trend computation results are similar to the thiel sen method results similarly for the waimea buoy location oahu the overall trend of maximum swell hs and tp shows a decrease of 0 003 m year and 0 002 s year table 5 during 1979 2017 compared to an increase of 0 021 m year and 0 046 s year during 2007 2017 table 7 the north facing buoy locations hanalei waimea and paunela reveal higher trend rates than the sheltered buoy locations mokapu and hilo table 7 the length of the data series and the wave climate interaction with enso essentially affect the trend analysis bromirski et al 2005 graham and diaz 2001 the trend rates indicate how the swells behave during the modeled timeline the trend rates of 1979 2017 show a slight decrease fig 8a and b the biggest swell wave height encountered during the recording period is observed at the beginning of the record period 1982 83 el niño year contrarily during 2007 2017 the 2016 el niño increases the trend close to the end of the recorded timeline fig 8c and d the mann kendall trend results also indicate a significant increase in the daily maximum swell trends the non normality of the distribution does not affect the mann kendall test wu et al 2017 thus it assesses the significant changes without a bias therefore the trend rates are the indication of the behavior of the correlated swells the trend difference maps of the hs and tp over the years also demonstrate a slight decrease in hs values change between 0 03 to 0 27 m during 1979 2017 whereas there is an increase in hs values change between 0 12 to 0 15 m during 1979 2017 fig 9 the non parametric test also aligns with deseasonalized trends throughout the years even though the overall strong ex generated swell intensity slightly decreases during 1979 2017 fig 9a b and table 7 it increased during 2007 2017 fig 9c d the partial least square regression with leave one out cross validation results on the daily maximum significant wave heights showed the regression p value is smaller than 0 5 which showed the significance of enso events on the swell trend estimates two tests are performed with five year and ten year components to include at least one el niño year in the cumulative swell systems and show decadal variability respectively in the five year method the highest predicted r2 value is 0 999 and highest predicted r2 is 0 936 and the prediction of the sum of squares is 0 108 in the decadal method the highest predicted r2 value is 1 0 and highest predicted r2 is 0 937 and the prediction of the sum of squares is 0 106 this higher r2 and the lowest sum of squares indicate the trend line is very well predicted by the daily maximum significant wave height of the swell systems in every five year or decadal components in other words a good model of trend estimation of the swell systems requires the enso years to be included the response plots of the two fits are given between the calculated and the actual trend line response in fig 10 the plot fig 10 shows a linear fit with less difference between the fitted and the cross validated values which indicates the swell systems predict the trend line well the yearly and bi yearly total of the mei multivariate enso index and pdo pacific decadal oscillation indices are plotted for 1979 2017 and 2007 2017 to observe the enso fluctuations and how their trends align with the significant wave height trend of the peak swells each year fig 11 the linear trends of the indices are calculated with linear regression fitting the total mei and pdo indices fluctuate similarly during the yearly and bi yearly sums the total bi yearly during the modeled timeline and the total yearly mei and pdo index scatter plots show a decreasing trend during 1979 2017 fig 11a b and an increasing trend during 2007 2017 fig 11c d the mei and pdo trend lines show similar patterns where the maximum hs trend line of the swells is at the hanalei location fig 11 4 discussion the wind reanalysis dataset greatly impacts the wave model accuracy the cfsr dataset is reported to show additional moderate intensity cyclones wang et al 2016 which may result in slight variations in the captured ex cyclogenesis locations compared to other reanalysis datasets like era interim and merra it should be emphasized that the strong ex cyclogenesis events have not been grouped under independent storms the reason is that the number of counted cyclogenesis events would create a different density of cyclogenesis events per storm to analyze a movement trend the meridional shift of the cyclones to the west is observed during la niña the cyclonic belt moves slightly equatorward during 1979 2017 whereas during 2007 2017 ex cyclones move northward supporting poleward intensification by fyfe 2003 and yin 2005 there is a high correlation between the wave model and the buoy data on the swell facing shores northwest to north there is a low correlation of the model results with the buoys in the sheltered areas like 188 hilo which does not face the northwest swells directly which may lead to overestimating the model results similar findings of overestimation of the models for the multi state ocean were also found by li et al 2016 further tuning the dispersion of frequency and angular spreading can provide a better swell attenuation rate in tropical and subtropical zones jiang et al 2016 also accurate wave state modeling requires more nested and high resolution nearshore models to reduce abrupt changes in the continental shelf and bathymetry the trend rates and trend magnitude present a relationship between the strong ex cyclonic points and the swells generated the trend calculations are highly dependent on the data series the difference of the rates between 1979 2017 and 2007 2017 demonstrates that the trends should be considered an indication of general behavior to understand the changes in decadal or overall scale whether computed by the thiel sen or deseasonalized methods these trends should be tested with a non parametric test such as mann kendall to assess the significance of the trend we noticed that trend calculations depend on storm cycles annual and seasonal fluctuations and enso intensity the cyclones and thus the swell systems intensify from november reaching the highest in february however a more detailed analysis can be done to separately analyze the el niño year swells to understand whether their impact on the swells has changed the leave one out cross validation can be improved by carefully examining the start and end date of the enso years and applying leave one out cross validation however this may also create a bias in the results due to the uncertainty of the event period we also suggest that the minimum component selection should be five years because anything lower than that may reflect the trend line falsely the r2 value reduces and the difference between the r2 and the predicted r2 gets bigger this may lead to an over fit issue in which the trend line may fail to predict the future estimates even though there is an increase in hs during the boreal winter we found that the decreasing trend for 38 years for the northwest swells aligns with a slightly decreasing trend found by wang et al 2009 and young et al 2011 our study finds an increase in hs over the last ten years for the np which is similar to the francis et al s 2011 results stating a 0 020 m year increase of hs for the se chukchi sea and a 0 025 m year increase for the pacific arctic over recent years 1993 2011 the strong trade winds coming from the eastern equatorial pacific and enhancing with la niña might also be the reason for the slight decreasing trends in the propagated swells sasaki 2014 5 conclusion our work presents the relationship between the strong ex cyclones and their generated swells reaching the hawaiian islands strong ex cyclones in the northern pacific ocean are found to be increasing in frequency and intensity the strong ex cyclones are identified by constraints on the mslp geopotential height and vorticity fields of the cfsr wind reanalysis dataset from 1979 2017 we found that the number of strong ex cyclogenesis over 1979 2017 has increased and this rise accelerated during 2007 2017 the average of mslp and geopotential height drops indicated the intensification during 1979 2017 the strong ex cyclones also moved southward and westward during 1979 2017 compared to the northward and a westward shift during 2007 2017 the strong ex cyclones gradually increase during the winter months reaching their highest number of events in february the strong ex cyclones generate 28 5 of the total swells during 1979 2017 and 25 8 of the total swells during 2007 2017 reaching the hawaiian islands for the northwest of kaua i hanalei and o ahu waimea the deseasonalized peak trend of the hs and tp shows a slight decrease during 1979 2017 however they increase at higher rates during 2007 2017 our trend patterns align with annual and seasonal fluctuations of storm cycles and enso fluctuations and intensity we find a similar hs increase on northwest facing buoy locations hanalei waimea and paunela and a slightly lower trend rate increase in the sheltered buoy locations mokapu and hilo the tp change reflects how the strong ex cyclone belt fluctuates moving closer to the equator during boreal winter the strong enso events impact the trend rates the mei and pdo index trends align with the hs trend to reflect these enso fluctuations during the recording period the increase in frequency and intensity of strong ex storms and swells in the northern pacific ocean means greater wave exposure on coastal ecosystems and infrastructure onat et al 2018a b and onat and francis 2018 state that geomorphology and wave exposure cause the highest levels of risk in defining the vulnerability in the hawaiian islands the swell statistics should also be examined at the regional and local levels to demonstrate the significant changes in the inundation hanafin et al 2012 therefore the results from our study may be essential to evaluate the coastal hazard impacts on the hawaiian coasts to keep up with the ever changing wave climate credit authorship contribution statement yaprak onat conceptualization methodology software validation formal analysis writing original draft visualization writing review editing oceana p francis supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to acknowledge the coastal hydraulics engineering resilience cher research group and lab at the department of civil and environmental engineering the university of hawai i at manoa where this research was conducted we also would like to thank the following persons from the university of hawai i at manoa ning li eva marie nosal bruce howe karl kim and zhenhua huang and peter justeson for their valuable and constructive comments on a previous study related to our manuscript and anonymous reviewers of this manuscript funding this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors appendix a supplementary data location of the cyclogenesis events the detected cyclogenesis points between october 1979 to december 2017 from the ex cyclone detection algorithm video supplementary material related to this article can be found online at https doi org 10 1016 j ocemod 2021 101888 appendix a supplementary data the following is the supplementary material related to this article video s1 the detected cyclogenesis points between october 1979 to december 2017 from the ex cyclone detection algorithm 
23887,coastal flooding models are used to predict the timing and magnitude of inundation during storms both for real time forecasting and long term design however there is a need for faster flooding predictions that also represent flow pathways and barriers at the scales of critical infrastructure this need can be addressed via subgrid corrections which use information at smaller scales to correct the flow variables water levels current velocities averaged over the mesh scale recent studies have shown a decrease in run time by 1 to 2 orders of magnitude with the ability to decrease further if the model time step is also increased in this study subgrid corrections are added to a widely used finite element based shallow water model to better understand how they can improve the accuracy and efficiency of inundation predictions the performance of the model with and without subgrid corrections is evaluated on scenarios of tidal flooding in a synthetic domain and a small bay in massachusetts as well as a scenario with a real atmospheric forcing and storm surge in southwest louisiana in these tests we observed that the subgrid corrections can increase model speed by 10 to 50 times while still representing flow through channels below the mesh scale to inland locations keywords storm surge subgrid adcirc wetting and drying shallow water equations 1 introduction storm surge defined as the storm induced rise in water above the normal astronomical tide is the principal cause of loss of lives and damages to natural and built infrastructure during coastal storms storm surge can cause extensive flooding in regions with relatively flat coastal topography such as the flooding of southeast texas during ike 2008 which pushed floodwaters up to 65 km inland hope et al 2013 as storms become more intense due to climate change emanuel 2020 their associated flooding and impacts will be exacerbated in the united states about 7 1 million single family and 250 000 multi family residences are at risk of damage from storm surge and the combined reconstruction costs assuming complete destruction of these structures has been estimated at nearly 1 8 trillion corelogic 2020 there is a need to predict coastal flooding both in real time to aid in emergency management cheung et al 2003 and between storms to aid in long term planning and mitigation efforts helderop and grubesic 2019 predictive numerical models must represent the evolution of storm surge over a wide range of spatial scales from its generation in shallow shelfs bays and estuaries to its conveyance into inland regions via narrow natural and man made channels to its interactions with hydraulic controls like dunes levees and raised roadways the advanced circulation adcirc modeling system luettich et al 1992 westerink et al 2008 is widely used in coastal flooding predictions due partly to its use of unstructured finite element meshes which can vary resolution from kilometers in the open ocean to tens of meters in small scale channels and inland regions adcirc has been well validated for predictions of storm surge along the u s gulf and atlantic coasts dietrich et al 2011 hope et al 2013 deb and ferreira 2016 cialone et al 2017 often by using meshes with millions of elements to describe the coastal region of interest however this fine resolution typically as small as 100 to 200 m can lead to long simulation times although adcirc is highly scalable in high performance computing environments tanaka et al 2011 dietrich et al 2012 a typical adcirc storm surge simulation can require multiple hours of wall clock time on hundreds or thousands of cpus because of this when adcirc is used for real time forecasting fleming et al 2008 blanton et al 2012 dresback et al 2013 it is limited typically to simulations of the consensus forecast and a few perturbations for each advisory in contrast other less computationally expensive models may consider an ensemble of storm scenarios to account for uncertainties in storm track forward speed and intensity this method of ensemble forecasting is advantageous in that it gives researchers and emergency managers a broader view of potential storm impacts thereby increasing their preparedness at the same time because adcirc and other coastal models are used for predictions on regional single or multiple state coastlines domains it has been computationally expensive for them to represent variability in topography and land cover at the highest available resolution there has been significant improvement to both the quality and availability of topo bathy data to describe the coastal zone databases such as noaa digital coast national oceanic and atmospheric administration 2020 and the usgs coastal national elevation database coned u s geological survey 2020a offer high quality digital elevation models dems stretching across large swaths of coastline with resolutions typically ranging from 1 to 10 m these geospatial data resolutions are much smaller than the mesh resolution used by flooding models for model input these data can be upscaled to identify the critical flow pathways and barriers that can be represented at the mesh scale bilskie et al 2015 and with the model output these data can be used to downscale the flooding predictions for decision support rucker et al 2021 however it has been cost prohibitive to perform the model computations at the highest resolution of the geospatial data thus limiting the accuracy of flooding predictions through the smallest channels and over the smallest roughness features thus there is a need for faster flooding simulations that also represent flow pathways and barriers at the highest resolution of geospatial data sets this need can be addressed via subgrid corrections which use information at smaller scales to correct the flow variables water levels current velocities averaged over the mesh scale originally implemented to account for irregularities in model domains defina 2000 subgrid corrections have grown increasingly popular due to their abilities to improve accuracy by better representing flows below the model scale and or efficiency by enabling a similar prediction on a coarsened mesh the governing shallow water equations are averaged to account for topography and bathymetry smaller than the model scale defina 2000 casulli 2009 king 2001 these averaged equations contain variables that represent the integrated subgrid topography averaged over the computational cell area recent studies have shown a decrease in run time by 1 to 2 orders of magnitude when compared to simulations run on fine meshes with the ability to decrease further if model time step were also increased sehili et al 2014 wu et al 2016 subgrid corrections have been demonstrated for synthetic domains to show proof of concept and for relatively small realistic domains like a tidally influenced marsh roig 1994 bates and hervouet 1999 defina 2000 king 2001 wu et al 2016 kennedy et al 2019 many of these studies forced their models with either a sinusoidal tidal curve or with tidal data collected near the domain although some studies have forced a single flood wave viero 2019 and relatively minor storm surge events sehili et al 2014 none have considered forcing due to hurricane winds and thus there are remaining questions about the viability of subgrid corrections for storm driven flooding we explore the use of subgrid corrections for predictions of coastal flooding in realistic domains using adcirc it is hypothesized that even with a so called level 0 closure that corrects flow behavior only at the wet dry front the subgrid corrections will allow adcirc to better represent the smallest flow pathways while using coarser resolution thus improving both accuracy and efficiency we describe the implementation of subgrid correction factors into adcirc s governing equations the performance of the model with and without subgrid corrections is evaluated on three test domains an idealized winding channel domain a small tidally influenced bay in massachusetts and a larger domain in southwestern louisiana to provide a realistic storm surge scenario it is shown that subgrid corrections can drastically improve storm surge predictions on coarse meshes when tested on significantly coarsened meshes subgrid adcirc can match the results of fine counterparts run with traditional methodology while offering a 10 to 50 times increase in speed 2 methods 2 1 advanced circulation adcirc adcirc uses the continuous galerkin finite element method with linear c 0 triangular elements to numerically solve the 2d shallow water equations swe this set of equations consists of the depth averaged continuity and momentum equations which are solved for water surface elevations ζ and depth averaged velocities u and v for coastal circulation luettich and westerink 2004 adcirc solves the generalized wave continuity equation gwce a reformulation of the primitive continuity equation into a generalized second order wave equation to avoid spurious oscillations associated with the primitive form of the equation kinnmark 1986 this study uses the so called conservative form of the momentum equations in which the dependent variables are the fluxes u h and v h where h is the total water depth to ease the implementation the subgrid corrections will have their greatest effect in partially wet regions and thus their implementation will require a revision to adcirc s wetting and drying algorithm traditional adcirc uses a complicated but robust system of logic to determine whether mesh vertices are wet or dry luettich and westerink 1995 it analyzes not only the values of total water depth but also water surface gradients and current velocities to update a wet dry status of finite element vertices during the simulation these checks occur in the middle of each time marching step i e after the gwce is solved for updated water surface elevations but before the momentum equations are solved for updated current velocities a vertex becomes wet if a sufficient water surface gradient is large enough to allow a wetting velocity to its location and it remains wet if its total water depth is sufficiently large an element is considered wet only if its three vertices are wet otherwise it is dry thus there cannot be any partially wet vertices or elements in contrast to other algorithms see medeiros and hagen 2013 for a review of various wetting drying algorithms this can lead to inaccuracies in the wet dry front especially if it is not resolved sufficiently at the mesh scale however dick et al 2013 showed in 1d that adcirc s wetting and drying algorithm is amenable to a partially wet scheme adcirc converts wind velocity to wind stress using the drag formulation from garratt 1977 wind stress is then applied to vertices in the momentum solver when solving for flow velocity in this work this formulation was revised to reduce the wind stress magnitudes in regions with shallow water depths to mitigate the possibly unstable situation when high winds are blowing over a thin film of water the wind stress is multiplied by a wind limiter c τ in the form of a hyperbolic tangent function eq 1 1 c τ tanh ρ g h c w s τ s in which τ s is the unaltered wind stress ρ is the density of seawater g is the acceleration due to gravity h is the total water depth which can be grid averaged as defined below and c w s is a dimensionless constant c w s 2 5 e 6 in this study this limiter asymptotes to unity for low wind speeds and large water depths but decreases to zero as water level decreases and wind speed increases 2 2 averaged variables we follow the methodology from kennedy et al 2019 which formalizes various aspects of earlier subgrid corrections in the context of swe with unresolved bed profile at the model scale defina 2000 casulli 2009 volp et al 2013 flow variables including the water surface elevation ζ above mean sea level the total water depth h ζ h in which h is the bathymetric depth and the depth averaged horizontal velocity components u and v are averaged to the mesh scale it is noted that previous studies have used related but distinct approaches the flow variable is first integrated over the subgrid cells in the area of interest and then it is either area averaged defina 2000 or left as a volume quantity casulli 2009 in this study we perform an area averaging kennedy et al 2019 describe a level 0 closure in which the mesh scale areas are allowed to be partially wet this requires the a priori computation of mesh scale wet areas a w which are related to the mesh scale total areas a g via the wet area fraction ϕ 2 ϕ a w a g wet area fractions are pre computed from a given high resolution topographical dataset typically available as a digital elevation map dem for a possible water surface elevation ζ wet dem cells are identified as being within the averaging area and having a positive total water depth the number of wet cells divided by the total number of cells within the area is taken to be a wet area fraction ϕ this process is repeated for the full range of possible water surface elevations thus providing a look up table to connect wet area fractions ϕ to water surface elevations ζ at every element and vice versa with the wet area fraction ϕ we can convert between wet averaged and grid averaged quantities for any flow variable q the conversion is 3 q g ϕ q w in which the angle brackets indicate an averaging to the wet w or total g area 4 q g 1 a g a w q d a and q w 1 a w a w q d a there is a challenge to represent the averaged flow variables for an unstructured triangular mesh within a continuous galerkin finite element framework due to its vertex based placement of unknowns ζ u v this challenge is overcome via the use of representative areas for both elements and vertices fig 1 elements are sub divided into three sub areas with each sub area corresponding to the area nearest a vertex the elemental sub areas surrounding a vertex are then combined to form a vertex area averaged total water depth h averaged manning s n and wet area fraction ϕ are pre computed from a high resolution dem and land cover data for a range of possible water surface elevations with an increment of 0 05 m in this study the values are stored in lookup tables and then referenced at every time step during the simulation 2 3 averaged governing equations in this work we consider the governing equations arising from applying the formal averaging technique whitacker 1999 to the standard 2d swe written in the conservative form see detailed derivation in appendix these equations involve averaged flow variables namely the surface water level ζ w grid averaged x and y directed fluxes u h g and v h g more precisely they consist of the averaged horizontal x and y momentum equations in the conservative form 5 u h g t g h g ζ w x u u h g x v u h g y f v h g g h g p a x ϕ τ s x ρ 0 w c f u u h g h w x e h u h g x y e h u h g y 6 v h g t g h g ζ w y u v h g x v v h g y f u h g g h g p a y ϕ τ s y ρ 0 w c f u v h g h w x e h v h g x y e h v h g y and the averaged continuity equation recast into the gwce form 7 ϕ 2 ζ w t 2 ϕ t ζ w t τ 0 ϕ ζ w t x g h g ζ w x y g h g ζ w y j x g x j y g y u h g τ 0 x v h g τ 0 y 0 where j x g rhs of 5 τ 0 u h g and j y g rhs of 6 τ 0 v h g in which f is the coriolis parameter g is the acceleration due to gravity τ s x and τ s y are surface stresses ρ 0 is a reference density c f is the bottom friction coefficient e h is the lateral stress coefficient and τ 0 is a positive spatially varying parameter weighting the primitive continuity equation in the above equations the grid averaged total water depth h g and h w h g ϕ is assumed known for a given value of ζ w for the depth averaged velocity instead of using the formal definition of the averaged quantity as in eq 4 the averaged u u v corresponds to the so called volume averaged velocity more specifically u u h g h g this definition reduces to a point wise definition of velocity in the limit of the averaging area approaching zero a g 0 see appendix for more detailed discussion note that eqs 5 7 are structurally similar to the form of the shallow water equations considered in adcirc except for the additional parameter ϕ and term ϕ t the latter representing the time rate of change of the wet area fraction the spatial and temporal discretization of this term is described in a 4 it is noted that these equations are nonlinear both before and after the averaging however we avoid solving this nonlinear system through the time discretization scheme which converts the equations into a linear algebraic system the addition of the time derivative term in ϕ was an extra linearization step as demonstrated later it is important to note that c f must be determined carefully because a straightforward mesh scale average formula does not necessarily ensure satisfactory results indeed this aspect is the focus of ongoing research sehili et al 2014 viero 2019 volp et al 2013 the gwce is solved implicitly via the use of a global mass matrix while the momentum equations are solved semi implicitly in this study the adcirc solvers were kept the same but averaged variables were substituted for their non averaged counterparts both element and vertex based quantities are used in these solutions on each time marching step the gwce eq 7 uses elementally averaged quantities to find a vertex averaged water surface elevation ζ w this quantity is then used to look up the corresponding vertex averaged total water depth h g and wet area fraction ϕ which are used along with elementally averaged quantities to solve eqs 5 and 6 for the vertex averaged water velocities because we are solving averaged equations the solutions for ζ w u and v are appropriately averaged therefore no further manipulation to the solutions is required a primary contribution of this work is the use of a logic free wet dry algorithm the new algorithm determines the wet dry state by enforcing a minimum wet area fraction of the element 8 ϕ ϕ min this minimum fraction ϕ min is set by the user and can be adjusted depending on the application e g a minimum wet area fraction ϕ min 0 05 would require that only 5 of an element must be submerged for it to be active and included in calculations this new algorithm improves the code in several ways replaces the existing algorithm and its extensive logic statements gives a more accurate representation of the wet dry front smooths the transition between wet and dry elements and vertices and allows adcirc to resolve subgrid hydraulic features 2 4 test cases three test cases are used to evaluate the effectiveness of adcirc with subgrid corrections the first test case is a plane sloping beach with a small winding channel of width 250 m in the middle of the domain the domain is described by a synthetic 10 m dem which is then used to develop meshes with varying resolution to either fully or inadequately resolve the channel fig 2 the second test case is a tidal simulation for buttermilk bay massachusetts this domain is chosen because it has several well defined small scale channels which must be represented in numerical models for accurate predictions of flows into back bays kennedy et al 2019 coarse and fine meshes are generated for this domain with bathymetry interpolated from a 3 m dem fig 4 the topo bathy data are obtained from noaa digital coast national oceanic and atmospheric administration 2020 the third test case is chosen as a realistic scenario for storm surge predictions using a 3 m dem from usgs coned u s geological survey 2020a two adcirc meshes are created using oceanmesh2d roberts et al 2019 for calcasieu lake and the connected bayou contraband in southwestern louisiana its location along the gulf of mexico low lying topography and shallow flat bathymetry make it highly vulnerable to storm surge there are also numerous well defined small scale channels in this region including calcasieu pass bayou contraband and intra coastal waterways with traditional adcirc this domain requires a fine mesh with resolution down to 50 m to represent the hydraulic connectivity there also exist water elevation data both at the coast and far up the bayou which will serve to validate the results of the subgrid model 2 5 error metrics the accuracy and efficiency of the model will be evaluated in each test case to evaluate accuracy with and without the sub grid corrections on coarse meshes we select three error metrics that are focused on the conveyance of tides and flood waters through channels below the model scale first for tides we compute the duration in hours that channel locations are wet during one tidal cycle we compare to predictions from a fine mesh simulation and thus an optimal result is a perfect match between durations on the coarse and fine meshes second for flood waters we consider the predicted peak water levels at channel locations we compare to either the results from a fine mesh simulation or to gauge observations and an optimal result is a zero difference between peaks third for both tides and flood waters we consider the predicted maximum water levels along channel thalweg transects i e the line connecting the deepest parts of the channel again to examine the conveyance we compare to results from a fine mesh simulation by computing a root mean square error e rms using all points along the transect and thus an optimal result is an e rms 0 9 e rms i 1 n x i x ˆ i 2 n in which n is the number of points along the transect and x and x ˆ are the predicted maximum water levels from simulations on coarse and fine meshes respectively with these three error metrics we assess the accuracy of predictions of flow through small scale channels to inland locations model efficiency was measured by wall clock timings simulations were run on intel xeon e5 2650 v2 processors which have 8 dual thread cores per processor 20 mb of cache and a frequency of 2 60 ghz the processors are connected via an ib6131 infiniband switch in the high performance computing services at north carolina state university but all simulations were run in serial to remove the inter core communication times from the comparisons for the timing comparisons each simulation was run in triplicate and the average wall clock time was reported 3 results 3 1 winding channel the first test has a 12 km by 12 km plane sloping beach with a 250 m winding channel fig 2 a synthetic dem was created with a resolution of 10 m and with minimum and maximum elevations of 5 m and 2 m respectively the channel thalweg is always 1 m below the surrounding ground surface and it was included to test the ability of the subgrid adcirc to represent flows below the mesh scale two meshes are developed fig 2 a coarse mesh with average element side length of 1000 m and a fine mesh designed to fully resolve the winding channel with a minimum resolution of 50 m and maximum of 500 m the coarse mesh has 192 vertices and 334 elements while the fine mesh has 12 475 vertices and 24 852 elements thus the number of degrees of freedom of the coarse mesh is approximately 65 times less than that of the fine mesh the bathymetry for both meshes is set using inverse distance weighted idw interpolation from the dem burrough and mcdonnell 1998 we consider simulations of three run configurations 1 fine traditional 2 coarse traditional and 3 coarse subgrid each simulation is forced by a 5 day diurnal tidal signal with amplitude of 1 m with a 2 day ramp to prevent abrupt introduction of elevation forcing bottom friction is computed with a constant manning s coefficient of n 0 012 and horizontal eddy viscosity is set to a constant value of e h 20 m 2 s for traditional simulations the wet and dry states are controlled by requiring a minimum wetting velocity of 0 1 m s and a minimum water depth of 0 1 m respectively for the subgrid simulation the minimum wet area fraction ϕ min 0 05 predicted water levels were recorded at stations along the channel thalweg and near the top middle and bottom of the tidal range fig 2 the hydrographs show the ability of the subgrid corrections to represent the tidal behavior in this small channel fig 3 at the station near the top of the tidal range the ground surface is 0 5 m relative to mean sea level because the domain is small enough to prevent a significant lag between the boundary forcing and the water levels within the domain this station should be wetted for the 16 hr surrounding each peak tide however considering the fourth tidal peak when the model forcing is at full strength this wet duration is varied among the simulations table 1 the fine traditional simulation can represent about 12 5 hr wetting when the water level rises to 0 04 m and drying when the water level falls to 0 10 m the inability of the fine traditional simulation to represent the full 16 hr of the tidal peak at this location is likely due to inaccuracies introduced when upscaling the synthetic ground surface to its 50 m resolution and the binary nature of traditional adcirc s wet dry algorithm which can limit the predictions of the wetting front the coarse traditional simulation can represent less of the high tide or about 11 25 hr wetting when the water level rises to 0 1 m and drying when the water level falls to 0 096 m in contrast the coarse subgrid simulation is able to represent the full 16 hr of high tide wetting when the water level rises to 0 51 m and drying when the water level falls to 0 49 m the middle station is located where the ground surface is 1 45 m relative to mean sea level this station should stay wet throughout the duration of the tidal cycle however both the fine traditional and the coarse traditional simulations become dry at the middle station the fine traditional simulation represents 21 5 hr of the signal becoming wet with the flood tide at a water surface elevation of 0 95 m and drying with the receding tide when the water level falls past the same elevation of 0 95 m the coarse traditional simulation represents only 16 5 hr of the tidal cycle the middle station becomes wet at a water level of 0 57 m and dries when the water level falls back to 0 56 m the coarse subgrid simulation is able to represent the full tidal cycle at the middle station and does not dry at any time the bottom station is located where the ground surface elevation is 2 165 m relative to mean sea level this station lies well beneath the lowest part of the tidal signal and should never dry all three simulations were able to represent the full tidal range at the bottom station for the peak to peak differences and thalweg e rms relative to the fine mesh table 1 the values were about one order of magnitude smaller with the subgrid corrections e g the channel thalweg e rms 7 4e 5 for the coarse subgrid but e rms 1 2e 3 for the coarse traditional however all of these peak to peak differences and thalweg e rms were very small for both simulations the subgrid corrections add computational time when compared to traditional adcirc simulations on the same mesh table 2 the increase in run time is attributed to reading the lookup tables referencing to the tables at every time step of the simulation and interpolating between table increments for the coarse winding channel test case subgrid adcirc ran 73 more slowly than its traditional counterpart the efficiency of the subgrid implementation can likely be increased with better coding practices and smaller lookup table file sizes however the subgrid adcirc allowed flooding in the winding channel for more of the tidal cycle than a traditional simulation on a mesh with 65 times finer resolution and it produced results 54 times faster thus the decrease in efficiency at the same mesh resolution is more than overcome by the increase in accuracy at coarser mesh resolutions for the subgrid corrections 3 2 buttermilk bay buttermilk bay is a small bay near the community of bourne massachusetts fig 4 it is connected via the cape cod canal to cape cod and buzzards bay to the north and south respectively a channel with a width of 250 m connects into a main bay with surface area of 1 54 km 2 from the main bay a smaller channel with a width of 50 m connects into a smaller inner bay with a surface area of 0 42 km 2 thus it is a good test to represent the propagation of tidal flows through channels below the model scale a high resolution 3 m dem from noaa digital coast is used to represent the bathymetry and topography and two unstructured meshes are developed from this dem fig 4 in the coarse mesh the elements are paved over the region with no attempt to align their locations or sizes with the ground contours the average element side length for the coarse mesh is about 100 m in the fine mesh vertices are aligned with the 0 m elevation contour to ensure that channels and coastlines are properly defined the fine mesh has a minimum element side length of 10 m and a maximum of 50 m the coarse mesh has 830 vertices and 1569 elements while the fine mesh has 4795 vertices and 9412 elements the model parameters for the buttermilk bay simulations are similar to the winding channel test case a diurnal tidal signal of 1 m amplitude with a 2 day ramping period is forced at the ocean boundary constant manning s n 0 022 is applied over the entire domain horizontal eddy viscosity is set to e h 2 0 m 2 s for the fine simulation and e h 50 m 2 s for the coarse simulation for the traditional adcirc the wet dry parameters of minimum water depth and minimum velocity are set to 0 1 m and 0 1 m s respectively for subgrid adcirc the minimum wet area fraction ϕ min 0 05 water level results are evaluated at three stations in buttermilk bay fig 4 these stations are selected to evaluate the ability of subgrid adcirc to predict flow through regions with hydraulic features that are smaller than the resolution of the coarsened mesh the main station located in the fully wet area of the domain serves as a baseline to show all models were forced properly the arm station is in a small tidally influenced stream that is between 5 m and 10 m wide the back station lies in little buttermilk bay and is separated from the main bay by a 50 m wide channel at the main station the water level time series is matched in all three simulations in both amplitude and phase fig 5 and table 3 however only the coarse subgrid and fine traditional simulations can capture hydraulic connectivity to the stations located in or near small channels at the arm station again considering the fourth tidal peak when forcing is at its full strength there is variability in the predictions the coarse traditional simulation was unable to represent any water at the arm station throughout the duration of the tidal signal the fine traditional simulation is able to represent connectivity to the arm for about 9 hr during the crest of the fourth tidal peak it loses hydraulic connectivity from the arm to the main bay at hour 82 5 and maintains a steady water surface elevation of 0 39 m for 15 hr until the return of the flood tide at hour 97 the surface elevation is maintained because after connectivity is lost water becomes trapped and cannot drain to the main bay therefore this station remains wet throughout the simulation table 3 the coarse subgrid simulation maintains connectivity for 13 75 hr during the fourth tidal peak its arm was fully dried at hour 85 and water surface elevation of 0 2 m for 10 5 hr until hour 95 5 when it floods again with the incoming high tide thus at the arm the coarse subgrid simulation shows improved connectivity when compared to the coarse traditional and fine traditional simulations table 3 at the back station the coarse traditional simulation indicates that there is water but no tidal flow and thus the peak to peak difference is 1 m and the thalweg e rms 5 5e 1 m the coarse subgrid and fine traditional simulations are able to represent flow through the small channel that connects from the main bay for the coarse subgrid simulation the errors are reduced by three orders of magnitude the peak to peak difference is 1 6e 3 m and the e rms 8 9e 4 m the subgrid corrections increase the computational time when compared to traditional adcirc simulations on the same mesh table 2 for the coarse mesh subgrid adcirc ran 83 more slowly than its traditional counterpart however it produced results that showed greater connectivity through small channels than a traditional simulation run on a mesh with 6 times the resolution and its results were produced more than 8 times faster the coarse mesh can likely be coarsened further but was constrained by the width of the lateral boundary where the tidal forcing was applied if this constraint was not present further efficiency gains between the coarse subgrid and fine traditional simulations could be achieved 3 3 calcasieu lake calcasieu lake is a large 242 km 2 tidally influenced water body in southwest louisiana the south end of the lake is connected to the gulf of mexico by calcasieu pass which is an 8 5 km long 300 m wide shipping channel that is maintained for commerce and recreation the north end of the lake is connected to the community of lake charles by bayou contraband a natural riverine system that is about 300 m wide and extends 20 km northward to lake charles the east and west sides of the lake are connected to neighboring water bodies by maintained 200 m wide intracoastal waterways the storm used in this test case was rita 2005 which made landfall near the texas louisiana border as a category 3 hurricane on the saffir simpson scale knabb et al 2005 lake calcasieu and its neighboring communities were highly impacted by this storm due to their position in the northeast quadrant of the wind field and their low lying flat topography maximum water levels reached 4 7 m along the coast with flood waters extending as far as 80 km inland dietrich et al 2010 berenbrock et al 2008 similar to buttermilk bay a coarse resolution mesh is paved over the domain with no consideration of bathymetric details the average element side length for the coarse mesh is 2000 m a fine mesh is created with a minimum element side length of 50 m and a maximum of 2000 m vertices in the fine mesh are aligned along the 0 m elevation contour to ensure that channels and coastlines were properly defined the fine mesh has a similar resolution and development as in larger studies of storm surge in the same region hope et al 2013 the coarse resolution mesh has 1236 vertices and 2370 elements while the fine mesh has 40 816 vertices and 81 321 elements fig 6 the model parameters for the calcasieu lake meshes are interpolated from an ocean scale fine mesh available for this region these model parameters include wind reduction factors derived from land use land cover data horizontal eddy viscosities in classes of e h 2 20 50 m 2 s and values for the primitive weighting in the gwce in classes of τ 0 0 005 0 02 0 03 manning s n coefficients for the meshes were derived from a 2006 coastal change analysis program c cap regional land cover dataset downloaded from the noaa digital coast national oceanic and atmospheric administration 2021 values were interpolated onto the mesh vertices using a harmonic average of the manning s n values contained in the surrounding vertex elements for the subgrid simulation wet averaged manning s n values were computed prior to the simulation and looked up based on water surface elevations eq 10 10 g n w 2 u u h g h w 4 3 in which n w is the wet averaged manning s n this was done to prevent overestimation of bottom friction in the subgrid model traditional simulations use a minimum water depth and a minimum velocity for wetting of 0 1 m and 0 1 m s respectively while the subgrid model uses a threshold ϕ min 0 05 the model is forced along its ocean boundary with water surface data taken from an ocean scale adcirc simulation of rita and winds produced by a generalized asymmetric holland model gahm of the same storm gao 2018 at every vertex gahm computes wind velocities and surface atmospheric pressures the wind velocities are then scaled based on surface roughness and canopy cover present in the area parametric models such as gahm can generate a reasonable representation of a hurricane wind field provided that proper wind parameters are used lin and chavas 2012 and in this case gahm will provide a realistic forcing with which to evaluate the subgrid adcirc the simulation is run for a total of 23 days with water surface elevations recorded from locations in the mesh corresponding to usgs gauges deployed prior to the storm u s geological survey 2020b as well as locations spaced every 2000 m along the main channel thalweg from the gulf of mexico to lake charles la predicted water levels are compared with hydrographs at the usgs gauges fig 7 water levels at gauge stations la12 lc7 lc8a lc9 and lc12 were similar between simulations with differences less than 15 cm table 4 these gauges are located near the open coast so when the 5 m storm surge propagated in connectivity and subgrid corrections played less of a role in altering the overall water level however this is not the case for gauges lc2a lc5 and lc6a which are located further inland at these locations the coarse subgrid outperforms the coarse traditional simulation by more than 20 cm again this is expected because as the surge propagates further inland the influence of subgrid features and flow connectivity have greater effects on the flow the most notable difference between the coarse subgrid and coarse traditional simulation is at the lc2a gauge located north of calcasieu lake fig 7 this gauge is farthest from the open coast and is connected via the narrow bayou contraband and it recorded a maximum water level of 2 55 m during the storm at this location the coarse traditional simulation goes dry at 1100 utc 24 september at a water level of 0 m and then rapidly wets at 1400 utc 24 september during the peak of the storm surge the maximum water level of the coarse traditional simulation remains more than 1 m below the maximum surge predicted by the fine traditional simulation at this gauge and is hydraulically disconnected from calcasieu lake the fine traditional and coarse subgrid simulations predicted a peak surge of 2 45 m and 2 18 m respectively thus the coarse subgrid results are too low by about 0 27 m at this location when compared to the fine traditional results likely due to high winds pushing water out of calcasieu lake causing an excessive draw down and a minimum wet threshold of ϕ min 0 05 which may not fully capture the subgrid processes in bayou contraband to further evaluate the three simulations maximum water levels were taken along the main channel thalweg from the gulf of mexico to lake charles la fig 8 from the north end of lake calcasieu to lake charles the maximum water levels from the coarse subgrid simulation are 0 25 m below that from the fine traditional simulation while the coarse traditional simulation underpredicts water levels by more than 1 m compared to the fine simulation for the e rms along the main channel thalweg the coarse subgrid e rms 0 220 m while the coarse traditional e rms 0 564 m this further demonstrates the superiority of the subgrid simulation at conveying flows through narrow channels for these simulations the subgrid corrections add about 40 to the run time when compared to the coarse traditional simulation table 2 however the coarse subgrid was about 32 times faster than the fine traditional and was able to connect flow from the gulf of mexico through lake calcasieu and up the contraband bayou 4 discussion in these test cases the subgrid adcirc consistently out performs its traditional counterpart in terms of hydraulic connectivity and maximum water level accuracy and it allows for efficiency gains by using coarser meshes to represent coastal regions these advancements have implications for the prediction of storm surge and coastal flooding both in real time forecasting and for long term planning the subgrid corrections can be used for predictions with realistic storm forcing in realistic coastal domains this is an extension of recent subgrid modeling studies which have used water levels applied at the open boundary from idealized sinusoidal tidal curves or water level data from field measurements defina 2000 casulli 2009 kennedy et al 2019 wu et al 2016 42 used atmospheric forcing from a storm event in the north sea however this storm event was not on the scale or power of a tropical cyclone in our third test case subgrid adcirc was forced with hurricane strength winds and storm surge from rita 2005 the model was able to represent the storm s effects on flow at the coast more specifically the flooding of the low lying topography of southwest louisiana and the flow through channels smaller than the model scale the largest discrepancy between coarse traditional and subgrid simulations was at the lc2a gauge where the model resolution was about seven times larger than the 300 m wide bayou contraband subgrid adcirc also allows for a coarsening of the meshes used to describe the coastal region for the winding channel test case nearly identical maximum water levels were predicted in the channel by the coarse subgrid and the fine traditional simulations with improved connectivity in the coarse subgrid simulation fig 3 despite the coarse subgrid simulation having 65 times fewer degrees of freedom and a minimum resolution that was 20 times coarser the simulation of buttermilk bay also showed virtually no difference in maximum water levels between the coarse subgrid and fine traditional simulations despite the coarse subgrid simulation having almost 6 times fewer degrees of freedom and a minimum resolution that was 10 times coarser again the subgrid showed better hydraulic connectivity especially in locations in small scale channels than the fine traditional for the calcasieu lake test case the coarse subgrid and fine traditional showed good comparison to gauge observations from hurricane rita 2005 despite the coarse subgrid simulation having 33 times fewer degrees of freedom and a minimum resolution that was 40 times coarser the subgrid simulation was able to represent flows to the inland lc2a gauge because it allowed flow through the bayou contraband below the model scale these results are similar to those by kennedy et al 2019 sehili et al 2014 and wu et al 2016 who found that the subgrid corrections allowed for a coarsening of meshes by at least 1 order of magnitude these advancements have implications for real time forecasting and long term engineering and design when adcirc is run traditionally with fine resolution meshes each simulation can require thousands of compute cores and hours of wall clock time hope et al 2013 during a storm event this requirement can limit its use in a probabilistic forecasting framework which can account for slight variations in storm track intensity and timing fleming et al 2008 and which is used by other forecast models like the sea land and overland surges from hurricanes slosh model national hurricane center 2020 subgrid adcirc may enable probabilistic forecasting between storms agencies like the united states army corps of engineers usace and the federal emergency management administration fema use adcirc to better prepare coastal cities and communities from future flooding events u s army corps of engineers 2015 federal emergency management agency 2019 typically by simulating hundreds of synthetic storm surge scenarios to produce flood hazard maps for state and municipalities subgrid adcirc could drastically reduce these studies computational and monetary cost these results do indicate paths for future work specifically in the drawdown and underprediction of water levels at the lc2a gauge and the consistent underprediction of water levels by the subgrid simulation along the main channel thalweg in the calcasieu lake test case figs 7 and 8 in those tests the coarse subgrid consistently under predicted water levels when compared to the fine traditional this may be attributed to an over estimation of friction by the subgrid model and increases in manning s n values from interpolation to the coarsened mesh volp et al 2013 presented a scheme to correct this over prediction and take advantage of high resolution roughness data implementation of a friction correction should lend itself well to the current subgrid framework present in the code the drawdown that occurred at this location as the storm made landfall is present in both the fine traditional and coarse subgrid simulations the water levels are decreased to 1 0 m or about 1 3 m below the gauge data these differences can largely be attributed to the gauge installation the lc2a gauge was a barotropic pressure sensor mounted sub aerially at 0 303 m navd88 therefore the sensor was not able to measure a drawdown below 0 303 m the flattening of the gauge data from 0000 utc to 0500 utc 24 september indicates that the water level dropped below the gauge mount elevation thus there is no way of verifying prediction accuracy during this time period other factors that could have affected model accuracy include poor representation of vertical features like roadways and levees that lie along the lake s edge and act as hydraulic barriers to keep water in the lake during the storm these hydraulic features can be better represented with cell clones which prevent flow between non hydraulically connected features previous implementations of cell clones have used numerical schemes in which the velocities are located along the cell edge which allows for connectivity and or blocking of flows within the cell begmohammadi et al 2021 casulli 2019 this capability will be challenging to implement in adcirc because the model defines the flow variables at the vertices of each element and thus it is not straight forward to identify connectivity for each clone however the capability would better represent the blocking of flow due to subgrid obstacles 5 conclusions in this study subgrid corrections were implemented in the widely used adcirc model for storm surge and coastal flooding these corrections were tested on a variety of domains and showed promising results both for idealized and realistic tides and storm surge subgrid adcirc is able to capture hydraulic connectivity and water level calculations on coarsened meshes in which small hydraulic features are not resolved at the mesh scale this improvement is attributed to subgrid adcirc s ability to represent small hydraulic features contained within partially wet elements without the use of sufficiently small element sizes traditional adcirc cannot resolve these features the inclusion of partially wet elements to solve for water levels and velocities was achieved by redesigning the wetting and drying routine within the code to solely rely on the wet area fraction ϕ when determining the wet dry state of an element or vertex the main contributions and findings of this study are 1 extension of subgrid corrections using the widely used adcirc storm surge model with hurricane strength forcing the addition of subgrid corrections to adcirc s governing equations allowed for use of partially wet elements and vertices this permits modified storm forcing at the wet dry boundary by way of the wet area fraction testing on the realistic calcasieu lake domain using forcing from rita 2005 demonstrated that these modifications give good overall matches to gauge hydrographs when run on coarsened meshes 2 subgrid corrections in adcirc allow for increases in accuracy and hydraulic connectivity when running on significantly coarsened meshes in a forecasting scenario this would give emergency managers and decision makers a more accurate prediction of when flood waters will arrive and recede this will allow them to use the best information possible when deciding evacuation times and coordinating search and rescue missions 3 for a given grid introducing subgrid corrections to adcirc increases computational cost to the code however these costs are small when compared to the efficiency gained by running on coarsened meshes in our current implementation the coarse subgrid storm surge simulation on calcasieu lake is approximately 40 slower than its coarse traditional counterpart nevertheless it ran 32 times faster than the fine simulation and produced comparable results reducing the simulation run time from 42 2 h to 1 3 h with these additions subgrid adcirc has the potential to predict coastal flooding at a fraction of the computational cost further investigation is needed as to whether this efficiency can be further increased with adjustments to the model time step future work will include tests of subgrid adcirc on ocean scale domains the use of ensemble frameworks to forecast storm surge and the use of additional correction such as friction to further improve model results credit authorship contribution statement johnathan l woodruff conceptualization methodology software validation formal analysis investigation resources data curation writing original draft writing review editing visualization j c dietrich conceptualization methodology software resources writing original draft writing review editing supervision project administration funding acquisition d wirasaet conceptualization methodology software writing review editing supervision a b kennedy conceptualization methodology writing review editing supervision project administration funding acquisition d bolster conceptualization writing review editing supervision project administration funding acquisition z silver software s d medlin visualization r l kolar methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by national science foundation united states grants icer 1664037 and 1664040 the support of the national science foundation and the us army corps of engineers is greatly appreciated by all contributors to this project appendix averaged governing equations for adcirc the upscaled governing equations stated in section 2 3 are derived by applying a formal averaging technique whitacker 1999 to the standard 2d shallow water equations written in the conservative form by following such a technique we define a mesh scale average of any flow quantity q as a 1 q g 1 a g a w q d a where a g denotes the mesh area and a w the wet area within a g note that a g and a w are related through eq 2 in addition an alternative average use in the wet average commonly known as intrinsic phase average defined by a 2 q w 1 a w a w q d a in addition the following rules whitacker 1985 are used to interchange differentiation with respect to time and space and time dependent spatial integration in the formula below u b denotes the velocity of the potentially moving boundary n s n s x n s y is an outward pointing unit vector normal to the wet dry boundary γ w is the wet dry boundary and the subscript r denotes a dummy notation for the x or y coordinates a 3 q t g q g t 1 a g γ w q u b n s d s and a 4 q r g q g r 1 a g γ w n s r q d s the development of subgrid equations involves roughly applying a 2 to the mass and momentum equations making use of a 3 and a 4 and determining closures for terms that are not uniquely defined by the coarsened mesh scale variables the following subsections describe the development of the averaged mass equation the averaged momentum equations and the reformulation of the averaged continuity equation into the gwce form a 1 averaged primitive continuity equation the primitive continuity equation is a 5 h t u h x v h y 0 in which h h ζ is the total water depth h is the bathymetric depth measured positive downwards from a reference datum ζ is the water surface elevation measured positive upwards from the datum u and v are the depth averaged horizontal velocity components in the x and y directions respectively the mesh scale averaging of each term is described below first for the local rate of change in time we use a 3 to pull the time derivative out of the integral more specifically a 6 h t g 1 a g a w h t d a 1 a g t a w h d a 1 a g γ w h u b n s d s because h 0 at the wet dry front we eliminate the boundary integral and obtain a 7 h t g 1 a g a w h t d a 1 a g t a w h d a h g t which is now temporal rate of change of the averaged total water depth next for the volume flux in the x direction we apply the spatial averaging a 4 to pull the spatial derivative out of the integral more precisely a 8 u h x g 1 a g a w u h x d a 1 a g x a w u h d a 1 a g γ w u h n s x d s again h 0 at the wet dry boundary we eliminate the boundary integral and have a 9 u h x g 1 a g a w u h x d a 1 a g x a w u h d a u h g x the interchange between differentiation and integration in the averaging of the last term the volume flux in the y direction can be done in an analogous way after above manipulation the averaged primitive continuity equation becomes a 10 h g t u h g x v h g y 0 by postulating that ζ varies very slowly within a w one has h g 1 a g z inf z ζ w a g m a x 0 b z d a d z as a consequence we can rewrite eq a 10 as a 11 ϕ ζ w t u h g x v h g y 0 which is the final averaged form of the primitive continuity equation to be considered in the reformulation into the gwce described below in appendix a 3 note that in this study we consider u h g as the variable to be solved for instead of using a 2 the velocity when required is computed from the following formula a 12 u a w h u d a a w h d a h u g h g or equivalently a 13 u h g u h g it is worth mentioning that the so called volume averaged velocity defined above has an advantage over an averaged velocity defined by a 2 in that it permits a substitution of u h g by u h g in the governing equation without the need to resort to a more complicated closure from this point forward unless otherwise indicated the notation u is understood as the volume averaged velocity note that various forms of governing equations presented kennedy et al 2019 are obtained from making use of a 13 they are intended for the solution where u is chosen as an unknown variable a 2 averaged conservative momentum equations we now average to the mesh scale the conservative momentum equations including terms for the barotropic pressure gradient and lateral momentum mixing stress terms consider the momentum equation in the x direction a 14 u h t u u h x u v h y f v h g h ζ p a x τ s x ρ 0 τ b x ρ 0 m x it can be verified through the use of a 3 and a 4 and h 0 at the wet dry boundary that the mesh scale averaging of a 14 is equivalent to a 15 u h g t u u h g x v u h g y f v h g g h ζ x g g h g p a x τ s x ρ 0 g τ b x ρ 0 g m x in the above equation the coriolis parameter f and the atmospheric pressure p a are assumed to vary at a spatial scale much larger than the grid scale and hence can be moved out of their respective integral terms there is no unique way to define the averaging of convective momentum bottom friction surface gradients and lateral mixing stresses in terms of the mesh scale quantities h g u h g u further assumptions to be described below are therefore required to close the system for the convective accelerations we chose the closure of the form written below u u h g c u u u u h g u v h g c u v u v h g which resemble the particular forms of the convective momentum considered in adcirc see equation 2 2 on p 15 of the adcirc theory report luettich and westerink 2004 with additional correction coefficients c u u and c u v for the surface gradient pressure term we consider the following closure a 16 g h p a x g g h g p a x g ϕ h ζ x w g c ζ ϕ h w ζ w x g c ζ h g ζ w x where c ζ is an additional correction coefficient although counterintuitive numerical evidences demonstrate in kennedy et al 2019 indicated that c ζ is clearly needed in some cases for the surface stress term we consider the quadratic drag law for the surface stress caused by wind a 17 τ s x ρ 0 g ϕ τ s x ρ 0 w ϕ ρ a ρ 0 c d w 10 w 10 x where ρ a denotes the air density and w 10 w 10 x w 10 x denotes the 10 m wind velocity assumed to be known wind data comes typically from a numerical model with a spatial scale greater than the grid scale considered in the surge model the bottom stress τ b x is assumed to obey a quadratic bottom friction law and the closure below is considered a 18 τ b x ρ 0 g ϕ τ b x ρ 0 w ϕ c f u u h h w ϕ c m f u u h w h w where c m f is to be determined equivalent frictional coefficients that may depend on water surface elevations in this work for simplicity c m f is taken to be a 19 c m f g n w 2 h w 1 3 where n w is a value characterizing the manning s roughness coefficient of the wet area finally consider the average of the lateral mixing term a 20 m x g h τ x x x h τ y x y g 1 a g x a w h τ x x d a 1 a g γ w h τ x x n s x d s 1 a g y a w h τ y x d a 1 a g γ w h τ y x n s y d s h τ x x g x h τ y x g y boundary integrals go to zero because h 0 at the wet dry boundary indeed the vertically integrated lateral terms h τ x x and h τ y x by itself require a closure assumption adcirc supports several lateral closures here we consider one specific form of such closures more precisely h τ x x e h u h x h τ y x e h u h y the grid average of these lateral closures are approximated as a 21 h τ x x g e h u h g x h τ y x g e h u h g y where e h is a grid scale eddy viscosity potentially of different value than that used in the high resolution calculation with the closure terms given above the averaged momentum equation in the x direction becomes a 22 u h g t g c ζ h g ζ w x c u u u u h g x c v u v u h g y f v h g g h g p a x ϕ τ s x ρ 0 w g n w 2 u u h g h w 4 3 x e h u h g x y e h u h g y similarly the averaged momentum equation in the y direction with closure terms is a 23 v h g t g c ζ h g ζ w y c u v u v h g x c v v v v h g y f u h g g h g p a y ϕ τ s y ρ 0 w g n w 2 u v h g h w 4 3 x e h v h g x y e h v h g y the final step is to select the correction coefficients in this work we consider a so called level 0 closure kennedy et al 2019 in which c u u c u v c v u c v v 1 c ζ 1 then the only non unity closure is the wet area fraction as shown in the final eqs 5 and 6 a 3 averaged generalized wave continuity equation then the gwce is formed by differentiating eq a 11 with respect to time adding to this a 11 multiplied by a positive spatially varying numerical parameter τ 0 this leads to a 24 t ϕ ζ w t τ 0 ϕ ζ w t j x g x j y g y u h g τ 0 x v h g τ 0 y 0 where a 25 j x g u h g t τ 0 u h g and a 26 j y g v h g t τ 0 v h g the time derivative terms u h g t and v h g t in the above equation are further eliminated by means of the momentum equation a 22 and a 23 with the level 0 closure we obtain the final form of the gwce as it appears in eq 7 repeated below ϕ 2 ζ w t 2 ϕ t ζ w t τ 0 ϕ ζ w t x g h g ζ w x y g h g ζ w y j x g x j y g y u h g τ 0 x v h g τ 0 y 0 where j x g rhs of a 22 τ 0 u h g and j y g rhs of a 23 τ 0 v h g note that for h g 0 i e in fully wet or partial wet areas the gwce is a second order wave equation a 4 finite element discretization in this study the adcirc solvers were kept largely the same the gwce is solved implicitly via the use of a global mass matrix while the momentum equations are solved semi implicitly both element and vertex based quantities are used in these solutions on each time marching step the gwce eq 7 uses elementally averaged quantities fig 1 to find a vertex averaged water surface elevation ζ w this quantity is then used to look up the corresponding vertex averaged total water depth h w wet area fraction ϕ and wet averaged manning s n n w which are used along with elementally averaged quantities to solve eqs 5 and 6 for the vertex averaged water velocities because we are solving averaged equations the solutions for ζ w u and v are appropriately averaged therefore no further manipulation is required the only change was the addition of the ϕ t ζ w t which was discretized in the following way ϕ t ζ w t n 1 n e j a n 12 ϕ n t i 1 3 φ i j ζ w i t where ϕ n t ϕ n s ϕ n s 1 δ t and ζ w i t ζ i s 1 ζ i s 1 2 δ t here a n is the area of element n n e j is the number of elements containing node j ϕ n is the average wet area fraction over element n φ i j is the weighting function and s is the current timestep 
23887,coastal flooding models are used to predict the timing and magnitude of inundation during storms both for real time forecasting and long term design however there is a need for faster flooding predictions that also represent flow pathways and barriers at the scales of critical infrastructure this need can be addressed via subgrid corrections which use information at smaller scales to correct the flow variables water levels current velocities averaged over the mesh scale recent studies have shown a decrease in run time by 1 to 2 orders of magnitude with the ability to decrease further if the model time step is also increased in this study subgrid corrections are added to a widely used finite element based shallow water model to better understand how they can improve the accuracy and efficiency of inundation predictions the performance of the model with and without subgrid corrections is evaluated on scenarios of tidal flooding in a synthetic domain and a small bay in massachusetts as well as a scenario with a real atmospheric forcing and storm surge in southwest louisiana in these tests we observed that the subgrid corrections can increase model speed by 10 to 50 times while still representing flow through channels below the mesh scale to inland locations keywords storm surge subgrid adcirc wetting and drying shallow water equations 1 introduction storm surge defined as the storm induced rise in water above the normal astronomical tide is the principal cause of loss of lives and damages to natural and built infrastructure during coastal storms storm surge can cause extensive flooding in regions with relatively flat coastal topography such as the flooding of southeast texas during ike 2008 which pushed floodwaters up to 65 km inland hope et al 2013 as storms become more intense due to climate change emanuel 2020 their associated flooding and impacts will be exacerbated in the united states about 7 1 million single family and 250 000 multi family residences are at risk of damage from storm surge and the combined reconstruction costs assuming complete destruction of these structures has been estimated at nearly 1 8 trillion corelogic 2020 there is a need to predict coastal flooding both in real time to aid in emergency management cheung et al 2003 and between storms to aid in long term planning and mitigation efforts helderop and grubesic 2019 predictive numerical models must represent the evolution of storm surge over a wide range of spatial scales from its generation in shallow shelfs bays and estuaries to its conveyance into inland regions via narrow natural and man made channels to its interactions with hydraulic controls like dunes levees and raised roadways the advanced circulation adcirc modeling system luettich et al 1992 westerink et al 2008 is widely used in coastal flooding predictions due partly to its use of unstructured finite element meshes which can vary resolution from kilometers in the open ocean to tens of meters in small scale channels and inland regions adcirc has been well validated for predictions of storm surge along the u s gulf and atlantic coasts dietrich et al 2011 hope et al 2013 deb and ferreira 2016 cialone et al 2017 often by using meshes with millions of elements to describe the coastal region of interest however this fine resolution typically as small as 100 to 200 m can lead to long simulation times although adcirc is highly scalable in high performance computing environments tanaka et al 2011 dietrich et al 2012 a typical adcirc storm surge simulation can require multiple hours of wall clock time on hundreds or thousands of cpus because of this when adcirc is used for real time forecasting fleming et al 2008 blanton et al 2012 dresback et al 2013 it is limited typically to simulations of the consensus forecast and a few perturbations for each advisory in contrast other less computationally expensive models may consider an ensemble of storm scenarios to account for uncertainties in storm track forward speed and intensity this method of ensemble forecasting is advantageous in that it gives researchers and emergency managers a broader view of potential storm impacts thereby increasing their preparedness at the same time because adcirc and other coastal models are used for predictions on regional single or multiple state coastlines domains it has been computationally expensive for them to represent variability in topography and land cover at the highest available resolution there has been significant improvement to both the quality and availability of topo bathy data to describe the coastal zone databases such as noaa digital coast national oceanic and atmospheric administration 2020 and the usgs coastal national elevation database coned u s geological survey 2020a offer high quality digital elevation models dems stretching across large swaths of coastline with resolutions typically ranging from 1 to 10 m these geospatial data resolutions are much smaller than the mesh resolution used by flooding models for model input these data can be upscaled to identify the critical flow pathways and barriers that can be represented at the mesh scale bilskie et al 2015 and with the model output these data can be used to downscale the flooding predictions for decision support rucker et al 2021 however it has been cost prohibitive to perform the model computations at the highest resolution of the geospatial data thus limiting the accuracy of flooding predictions through the smallest channels and over the smallest roughness features thus there is a need for faster flooding simulations that also represent flow pathways and barriers at the highest resolution of geospatial data sets this need can be addressed via subgrid corrections which use information at smaller scales to correct the flow variables water levels current velocities averaged over the mesh scale originally implemented to account for irregularities in model domains defina 2000 subgrid corrections have grown increasingly popular due to their abilities to improve accuracy by better representing flows below the model scale and or efficiency by enabling a similar prediction on a coarsened mesh the governing shallow water equations are averaged to account for topography and bathymetry smaller than the model scale defina 2000 casulli 2009 king 2001 these averaged equations contain variables that represent the integrated subgrid topography averaged over the computational cell area recent studies have shown a decrease in run time by 1 to 2 orders of magnitude when compared to simulations run on fine meshes with the ability to decrease further if model time step were also increased sehili et al 2014 wu et al 2016 subgrid corrections have been demonstrated for synthetic domains to show proof of concept and for relatively small realistic domains like a tidally influenced marsh roig 1994 bates and hervouet 1999 defina 2000 king 2001 wu et al 2016 kennedy et al 2019 many of these studies forced their models with either a sinusoidal tidal curve or with tidal data collected near the domain although some studies have forced a single flood wave viero 2019 and relatively minor storm surge events sehili et al 2014 none have considered forcing due to hurricane winds and thus there are remaining questions about the viability of subgrid corrections for storm driven flooding we explore the use of subgrid corrections for predictions of coastal flooding in realistic domains using adcirc it is hypothesized that even with a so called level 0 closure that corrects flow behavior only at the wet dry front the subgrid corrections will allow adcirc to better represent the smallest flow pathways while using coarser resolution thus improving both accuracy and efficiency we describe the implementation of subgrid correction factors into adcirc s governing equations the performance of the model with and without subgrid corrections is evaluated on three test domains an idealized winding channel domain a small tidally influenced bay in massachusetts and a larger domain in southwestern louisiana to provide a realistic storm surge scenario it is shown that subgrid corrections can drastically improve storm surge predictions on coarse meshes when tested on significantly coarsened meshes subgrid adcirc can match the results of fine counterparts run with traditional methodology while offering a 10 to 50 times increase in speed 2 methods 2 1 advanced circulation adcirc adcirc uses the continuous galerkin finite element method with linear c 0 triangular elements to numerically solve the 2d shallow water equations swe this set of equations consists of the depth averaged continuity and momentum equations which are solved for water surface elevations ζ and depth averaged velocities u and v for coastal circulation luettich and westerink 2004 adcirc solves the generalized wave continuity equation gwce a reformulation of the primitive continuity equation into a generalized second order wave equation to avoid spurious oscillations associated with the primitive form of the equation kinnmark 1986 this study uses the so called conservative form of the momentum equations in which the dependent variables are the fluxes u h and v h where h is the total water depth to ease the implementation the subgrid corrections will have their greatest effect in partially wet regions and thus their implementation will require a revision to adcirc s wetting and drying algorithm traditional adcirc uses a complicated but robust system of logic to determine whether mesh vertices are wet or dry luettich and westerink 1995 it analyzes not only the values of total water depth but also water surface gradients and current velocities to update a wet dry status of finite element vertices during the simulation these checks occur in the middle of each time marching step i e after the gwce is solved for updated water surface elevations but before the momentum equations are solved for updated current velocities a vertex becomes wet if a sufficient water surface gradient is large enough to allow a wetting velocity to its location and it remains wet if its total water depth is sufficiently large an element is considered wet only if its three vertices are wet otherwise it is dry thus there cannot be any partially wet vertices or elements in contrast to other algorithms see medeiros and hagen 2013 for a review of various wetting drying algorithms this can lead to inaccuracies in the wet dry front especially if it is not resolved sufficiently at the mesh scale however dick et al 2013 showed in 1d that adcirc s wetting and drying algorithm is amenable to a partially wet scheme adcirc converts wind velocity to wind stress using the drag formulation from garratt 1977 wind stress is then applied to vertices in the momentum solver when solving for flow velocity in this work this formulation was revised to reduce the wind stress magnitudes in regions with shallow water depths to mitigate the possibly unstable situation when high winds are blowing over a thin film of water the wind stress is multiplied by a wind limiter c τ in the form of a hyperbolic tangent function eq 1 1 c τ tanh ρ g h c w s τ s in which τ s is the unaltered wind stress ρ is the density of seawater g is the acceleration due to gravity h is the total water depth which can be grid averaged as defined below and c w s is a dimensionless constant c w s 2 5 e 6 in this study this limiter asymptotes to unity for low wind speeds and large water depths but decreases to zero as water level decreases and wind speed increases 2 2 averaged variables we follow the methodology from kennedy et al 2019 which formalizes various aspects of earlier subgrid corrections in the context of swe with unresolved bed profile at the model scale defina 2000 casulli 2009 volp et al 2013 flow variables including the water surface elevation ζ above mean sea level the total water depth h ζ h in which h is the bathymetric depth and the depth averaged horizontal velocity components u and v are averaged to the mesh scale it is noted that previous studies have used related but distinct approaches the flow variable is first integrated over the subgrid cells in the area of interest and then it is either area averaged defina 2000 or left as a volume quantity casulli 2009 in this study we perform an area averaging kennedy et al 2019 describe a level 0 closure in which the mesh scale areas are allowed to be partially wet this requires the a priori computation of mesh scale wet areas a w which are related to the mesh scale total areas a g via the wet area fraction ϕ 2 ϕ a w a g wet area fractions are pre computed from a given high resolution topographical dataset typically available as a digital elevation map dem for a possible water surface elevation ζ wet dem cells are identified as being within the averaging area and having a positive total water depth the number of wet cells divided by the total number of cells within the area is taken to be a wet area fraction ϕ this process is repeated for the full range of possible water surface elevations thus providing a look up table to connect wet area fractions ϕ to water surface elevations ζ at every element and vice versa with the wet area fraction ϕ we can convert between wet averaged and grid averaged quantities for any flow variable q the conversion is 3 q g ϕ q w in which the angle brackets indicate an averaging to the wet w or total g area 4 q g 1 a g a w q d a and q w 1 a w a w q d a there is a challenge to represent the averaged flow variables for an unstructured triangular mesh within a continuous galerkin finite element framework due to its vertex based placement of unknowns ζ u v this challenge is overcome via the use of representative areas for both elements and vertices fig 1 elements are sub divided into three sub areas with each sub area corresponding to the area nearest a vertex the elemental sub areas surrounding a vertex are then combined to form a vertex area averaged total water depth h averaged manning s n and wet area fraction ϕ are pre computed from a high resolution dem and land cover data for a range of possible water surface elevations with an increment of 0 05 m in this study the values are stored in lookup tables and then referenced at every time step during the simulation 2 3 averaged governing equations in this work we consider the governing equations arising from applying the formal averaging technique whitacker 1999 to the standard 2d swe written in the conservative form see detailed derivation in appendix these equations involve averaged flow variables namely the surface water level ζ w grid averaged x and y directed fluxes u h g and v h g more precisely they consist of the averaged horizontal x and y momentum equations in the conservative form 5 u h g t g h g ζ w x u u h g x v u h g y f v h g g h g p a x ϕ τ s x ρ 0 w c f u u h g h w x e h u h g x y e h u h g y 6 v h g t g h g ζ w y u v h g x v v h g y f u h g g h g p a y ϕ τ s y ρ 0 w c f u v h g h w x e h v h g x y e h v h g y and the averaged continuity equation recast into the gwce form 7 ϕ 2 ζ w t 2 ϕ t ζ w t τ 0 ϕ ζ w t x g h g ζ w x y g h g ζ w y j x g x j y g y u h g τ 0 x v h g τ 0 y 0 where j x g rhs of 5 τ 0 u h g and j y g rhs of 6 τ 0 v h g in which f is the coriolis parameter g is the acceleration due to gravity τ s x and τ s y are surface stresses ρ 0 is a reference density c f is the bottom friction coefficient e h is the lateral stress coefficient and τ 0 is a positive spatially varying parameter weighting the primitive continuity equation in the above equations the grid averaged total water depth h g and h w h g ϕ is assumed known for a given value of ζ w for the depth averaged velocity instead of using the formal definition of the averaged quantity as in eq 4 the averaged u u v corresponds to the so called volume averaged velocity more specifically u u h g h g this definition reduces to a point wise definition of velocity in the limit of the averaging area approaching zero a g 0 see appendix for more detailed discussion note that eqs 5 7 are structurally similar to the form of the shallow water equations considered in adcirc except for the additional parameter ϕ and term ϕ t the latter representing the time rate of change of the wet area fraction the spatial and temporal discretization of this term is described in a 4 it is noted that these equations are nonlinear both before and after the averaging however we avoid solving this nonlinear system through the time discretization scheme which converts the equations into a linear algebraic system the addition of the time derivative term in ϕ was an extra linearization step as demonstrated later it is important to note that c f must be determined carefully because a straightforward mesh scale average formula does not necessarily ensure satisfactory results indeed this aspect is the focus of ongoing research sehili et al 2014 viero 2019 volp et al 2013 the gwce is solved implicitly via the use of a global mass matrix while the momentum equations are solved semi implicitly in this study the adcirc solvers were kept the same but averaged variables were substituted for their non averaged counterparts both element and vertex based quantities are used in these solutions on each time marching step the gwce eq 7 uses elementally averaged quantities to find a vertex averaged water surface elevation ζ w this quantity is then used to look up the corresponding vertex averaged total water depth h g and wet area fraction ϕ which are used along with elementally averaged quantities to solve eqs 5 and 6 for the vertex averaged water velocities because we are solving averaged equations the solutions for ζ w u and v are appropriately averaged therefore no further manipulation to the solutions is required a primary contribution of this work is the use of a logic free wet dry algorithm the new algorithm determines the wet dry state by enforcing a minimum wet area fraction of the element 8 ϕ ϕ min this minimum fraction ϕ min is set by the user and can be adjusted depending on the application e g a minimum wet area fraction ϕ min 0 05 would require that only 5 of an element must be submerged for it to be active and included in calculations this new algorithm improves the code in several ways replaces the existing algorithm and its extensive logic statements gives a more accurate representation of the wet dry front smooths the transition between wet and dry elements and vertices and allows adcirc to resolve subgrid hydraulic features 2 4 test cases three test cases are used to evaluate the effectiveness of adcirc with subgrid corrections the first test case is a plane sloping beach with a small winding channel of width 250 m in the middle of the domain the domain is described by a synthetic 10 m dem which is then used to develop meshes with varying resolution to either fully or inadequately resolve the channel fig 2 the second test case is a tidal simulation for buttermilk bay massachusetts this domain is chosen because it has several well defined small scale channels which must be represented in numerical models for accurate predictions of flows into back bays kennedy et al 2019 coarse and fine meshes are generated for this domain with bathymetry interpolated from a 3 m dem fig 4 the topo bathy data are obtained from noaa digital coast national oceanic and atmospheric administration 2020 the third test case is chosen as a realistic scenario for storm surge predictions using a 3 m dem from usgs coned u s geological survey 2020a two adcirc meshes are created using oceanmesh2d roberts et al 2019 for calcasieu lake and the connected bayou contraband in southwestern louisiana its location along the gulf of mexico low lying topography and shallow flat bathymetry make it highly vulnerable to storm surge there are also numerous well defined small scale channels in this region including calcasieu pass bayou contraband and intra coastal waterways with traditional adcirc this domain requires a fine mesh with resolution down to 50 m to represent the hydraulic connectivity there also exist water elevation data both at the coast and far up the bayou which will serve to validate the results of the subgrid model 2 5 error metrics the accuracy and efficiency of the model will be evaluated in each test case to evaluate accuracy with and without the sub grid corrections on coarse meshes we select three error metrics that are focused on the conveyance of tides and flood waters through channels below the model scale first for tides we compute the duration in hours that channel locations are wet during one tidal cycle we compare to predictions from a fine mesh simulation and thus an optimal result is a perfect match between durations on the coarse and fine meshes second for flood waters we consider the predicted peak water levels at channel locations we compare to either the results from a fine mesh simulation or to gauge observations and an optimal result is a zero difference between peaks third for both tides and flood waters we consider the predicted maximum water levels along channel thalweg transects i e the line connecting the deepest parts of the channel again to examine the conveyance we compare to results from a fine mesh simulation by computing a root mean square error e rms using all points along the transect and thus an optimal result is an e rms 0 9 e rms i 1 n x i x ˆ i 2 n in which n is the number of points along the transect and x and x ˆ are the predicted maximum water levels from simulations on coarse and fine meshes respectively with these three error metrics we assess the accuracy of predictions of flow through small scale channels to inland locations model efficiency was measured by wall clock timings simulations were run on intel xeon e5 2650 v2 processors which have 8 dual thread cores per processor 20 mb of cache and a frequency of 2 60 ghz the processors are connected via an ib6131 infiniband switch in the high performance computing services at north carolina state university but all simulations were run in serial to remove the inter core communication times from the comparisons for the timing comparisons each simulation was run in triplicate and the average wall clock time was reported 3 results 3 1 winding channel the first test has a 12 km by 12 km plane sloping beach with a 250 m winding channel fig 2 a synthetic dem was created with a resolution of 10 m and with minimum and maximum elevations of 5 m and 2 m respectively the channel thalweg is always 1 m below the surrounding ground surface and it was included to test the ability of the subgrid adcirc to represent flows below the mesh scale two meshes are developed fig 2 a coarse mesh with average element side length of 1000 m and a fine mesh designed to fully resolve the winding channel with a minimum resolution of 50 m and maximum of 500 m the coarse mesh has 192 vertices and 334 elements while the fine mesh has 12 475 vertices and 24 852 elements thus the number of degrees of freedom of the coarse mesh is approximately 65 times less than that of the fine mesh the bathymetry for both meshes is set using inverse distance weighted idw interpolation from the dem burrough and mcdonnell 1998 we consider simulations of three run configurations 1 fine traditional 2 coarse traditional and 3 coarse subgrid each simulation is forced by a 5 day diurnal tidal signal with amplitude of 1 m with a 2 day ramp to prevent abrupt introduction of elevation forcing bottom friction is computed with a constant manning s coefficient of n 0 012 and horizontal eddy viscosity is set to a constant value of e h 20 m 2 s for traditional simulations the wet and dry states are controlled by requiring a minimum wetting velocity of 0 1 m s and a minimum water depth of 0 1 m respectively for the subgrid simulation the minimum wet area fraction ϕ min 0 05 predicted water levels were recorded at stations along the channel thalweg and near the top middle and bottom of the tidal range fig 2 the hydrographs show the ability of the subgrid corrections to represent the tidal behavior in this small channel fig 3 at the station near the top of the tidal range the ground surface is 0 5 m relative to mean sea level because the domain is small enough to prevent a significant lag between the boundary forcing and the water levels within the domain this station should be wetted for the 16 hr surrounding each peak tide however considering the fourth tidal peak when the model forcing is at full strength this wet duration is varied among the simulations table 1 the fine traditional simulation can represent about 12 5 hr wetting when the water level rises to 0 04 m and drying when the water level falls to 0 10 m the inability of the fine traditional simulation to represent the full 16 hr of the tidal peak at this location is likely due to inaccuracies introduced when upscaling the synthetic ground surface to its 50 m resolution and the binary nature of traditional adcirc s wet dry algorithm which can limit the predictions of the wetting front the coarse traditional simulation can represent less of the high tide or about 11 25 hr wetting when the water level rises to 0 1 m and drying when the water level falls to 0 096 m in contrast the coarse subgrid simulation is able to represent the full 16 hr of high tide wetting when the water level rises to 0 51 m and drying when the water level falls to 0 49 m the middle station is located where the ground surface is 1 45 m relative to mean sea level this station should stay wet throughout the duration of the tidal cycle however both the fine traditional and the coarse traditional simulations become dry at the middle station the fine traditional simulation represents 21 5 hr of the signal becoming wet with the flood tide at a water surface elevation of 0 95 m and drying with the receding tide when the water level falls past the same elevation of 0 95 m the coarse traditional simulation represents only 16 5 hr of the tidal cycle the middle station becomes wet at a water level of 0 57 m and dries when the water level falls back to 0 56 m the coarse subgrid simulation is able to represent the full tidal cycle at the middle station and does not dry at any time the bottom station is located where the ground surface elevation is 2 165 m relative to mean sea level this station lies well beneath the lowest part of the tidal signal and should never dry all three simulations were able to represent the full tidal range at the bottom station for the peak to peak differences and thalweg e rms relative to the fine mesh table 1 the values were about one order of magnitude smaller with the subgrid corrections e g the channel thalweg e rms 7 4e 5 for the coarse subgrid but e rms 1 2e 3 for the coarse traditional however all of these peak to peak differences and thalweg e rms were very small for both simulations the subgrid corrections add computational time when compared to traditional adcirc simulations on the same mesh table 2 the increase in run time is attributed to reading the lookup tables referencing to the tables at every time step of the simulation and interpolating between table increments for the coarse winding channel test case subgrid adcirc ran 73 more slowly than its traditional counterpart the efficiency of the subgrid implementation can likely be increased with better coding practices and smaller lookup table file sizes however the subgrid adcirc allowed flooding in the winding channel for more of the tidal cycle than a traditional simulation on a mesh with 65 times finer resolution and it produced results 54 times faster thus the decrease in efficiency at the same mesh resolution is more than overcome by the increase in accuracy at coarser mesh resolutions for the subgrid corrections 3 2 buttermilk bay buttermilk bay is a small bay near the community of bourne massachusetts fig 4 it is connected via the cape cod canal to cape cod and buzzards bay to the north and south respectively a channel with a width of 250 m connects into a main bay with surface area of 1 54 km 2 from the main bay a smaller channel with a width of 50 m connects into a smaller inner bay with a surface area of 0 42 km 2 thus it is a good test to represent the propagation of tidal flows through channels below the model scale a high resolution 3 m dem from noaa digital coast is used to represent the bathymetry and topography and two unstructured meshes are developed from this dem fig 4 in the coarse mesh the elements are paved over the region with no attempt to align their locations or sizes with the ground contours the average element side length for the coarse mesh is about 100 m in the fine mesh vertices are aligned with the 0 m elevation contour to ensure that channels and coastlines are properly defined the fine mesh has a minimum element side length of 10 m and a maximum of 50 m the coarse mesh has 830 vertices and 1569 elements while the fine mesh has 4795 vertices and 9412 elements the model parameters for the buttermilk bay simulations are similar to the winding channel test case a diurnal tidal signal of 1 m amplitude with a 2 day ramping period is forced at the ocean boundary constant manning s n 0 022 is applied over the entire domain horizontal eddy viscosity is set to e h 2 0 m 2 s for the fine simulation and e h 50 m 2 s for the coarse simulation for the traditional adcirc the wet dry parameters of minimum water depth and minimum velocity are set to 0 1 m and 0 1 m s respectively for subgrid adcirc the minimum wet area fraction ϕ min 0 05 water level results are evaluated at three stations in buttermilk bay fig 4 these stations are selected to evaluate the ability of subgrid adcirc to predict flow through regions with hydraulic features that are smaller than the resolution of the coarsened mesh the main station located in the fully wet area of the domain serves as a baseline to show all models were forced properly the arm station is in a small tidally influenced stream that is between 5 m and 10 m wide the back station lies in little buttermilk bay and is separated from the main bay by a 50 m wide channel at the main station the water level time series is matched in all three simulations in both amplitude and phase fig 5 and table 3 however only the coarse subgrid and fine traditional simulations can capture hydraulic connectivity to the stations located in or near small channels at the arm station again considering the fourth tidal peak when forcing is at its full strength there is variability in the predictions the coarse traditional simulation was unable to represent any water at the arm station throughout the duration of the tidal signal the fine traditional simulation is able to represent connectivity to the arm for about 9 hr during the crest of the fourth tidal peak it loses hydraulic connectivity from the arm to the main bay at hour 82 5 and maintains a steady water surface elevation of 0 39 m for 15 hr until the return of the flood tide at hour 97 the surface elevation is maintained because after connectivity is lost water becomes trapped and cannot drain to the main bay therefore this station remains wet throughout the simulation table 3 the coarse subgrid simulation maintains connectivity for 13 75 hr during the fourth tidal peak its arm was fully dried at hour 85 and water surface elevation of 0 2 m for 10 5 hr until hour 95 5 when it floods again with the incoming high tide thus at the arm the coarse subgrid simulation shows improved connectivity when compared to the coarse traditional and fine traditional simulations table 3 at the back station the coarse traditional simulation indicates that there is water but no tidal flow and thus the peak to peak difference is 1 m and the thalweg e rms 5 5e 1 m the coarse subgrid and fine traditional simulations are able to represent flow through the small channel that connects from the main bay for the coarse subgrid simulation the errors are reduced by three orders of magnitude the peak to peak difference is 1 6e 3 m and the e rms 8 9e 4 m the subgrid corrections increase the computational time when compared to traditional adcirc simulations on the same mesh table 2 for the coarse mesh subgrid adcirc ran 83 more slowly than its traditional counterpart however it produced results that showed greater connectivity through small channels than a traditional simulation run on a mesh with 6 times the resolution and its results were produced more than 8 times faster the coarse mesh can likely be coarsened further but was constrained by the width of the lateral boundary where the tidal forcing was applied if this constraint was not present further efficiency gains between the coarse subgrid and fine traditional simulations could be achieved 3 3 calcasieu lake calcasieu lake is a large 242 km 2 tidally influenced water body in southwest louisiana the south end of the lake is connected to the gulf of mexico by calcasieu pass which is an 8 5 km long 300 m wide shipping channel that is maintained for commerce and recreation the north end of the lake is connected to the community of lake charles by bayou contraband a natural riverine system that is about 300 m wide and extends 20 km northward to lake charles the east and west sides of the lake are connected to neighboring water bodies by maintained 200 m wide intracoastal waterways the storm used in this test case was rita 2005 which made landfall near the texas louisiana border as a category 3 hurricane on the saffir simpson scale knabb et al 2005 lake calcasieu and its neighboring communities were highly impacted by this storm due to their position in the northeast quadrant of the wind field and their low lying flat topography maximum water levels reached 4 7 m along the coast with flood waters extending as far as 80 km inland dietrich et al 2010 berenbrock et al 2008 similar to buttermilk bay a coarse resolution mesh is paved over the domain with no consideration of bathymetric details the average element side length for the coarse mesh is 2000 m a fine mesh is created with a minimum element side length of 50 m and a maximum of 2000 m vertices in the fine mesh are aligned along the 0 m elevation contour to ensure that channels and coastlines were properly defined the fine mesh has a similar resolution and development as in larger studies of storm surge in the same region hope et al 2013 the coarse resolution mesh has 1236 vertices and 2370 elements while the fine mesh has 40 816 vertices and 81 321 elements fig 6 the model parameters for the calcasieu lake meshes are interpolated from an ocean scale fine mesh available for this region these model parameters include wind reduction factors derived from land use land cover data horizontal eddy viscosities in classes of e h 2 20 50 m 2 s and values for the primitive weighting in the gwce in classes of τ 0 0 005 0 02 0 03 manning s n coefficients for the meshes were derived from a 2006 coastal change analysis program c cap regional land cover dataset downloaded from the noaa digital coast national oceanic and atmospheric administration 2021 values were interpolated onto the mesh vertices using a harmonic average of the manning s n values contained in the surrounding vertex elements for the subgrid simulation wet averaged manning s n values were computed prior to the simulation and looked up based on water surface elevations eq 10 10 g n w 2 u u h g h w 4 3 in which n w is the wet averaged manning s n this was done to prevent overestimation of bottom friction in the subgrid model traditional simulations use a minimum water depth and a minimum velocity for wetting of 0 1 m and 0 1 m s respectively while the subgrid model uses a threshold ϕ min 0 05 the model is forced along its ocean boundary with water surface data taken from an ocean scale adcirc simulation of rita and winds produced by a generalized asymmetric holland model gahm of the same storm gao 2018 at every vertex gahm computes wind velocities and surface atmospheric pressures the wind velocities are then scaled based on surface roughness and canopy cover present in the area parametric models such as gahm can generate a reasonable representation of a hurricane wind field provided that proper wind parameters are used lin and chavas 2012 and in this case gahm will provide a realistic forcing with which to evaluate the subgrid adcirc the simulation is run for a total of 23 days with water surface elevations recorded from locations in the mesh corresponding to usgs gauges deployed prior to the storm u s geological survey 2020b as well as locations spaced every 2000 m along the main channel thalweg from the gulf of mexico to lake charles la predicted water levels are compared with hydrographs at the usgs gauges fig 7 water levels at gauge stations la12 lc7 lc8a lc9 and lc12 were similar between simulations with differences less than 15 cm table 4 these gauges are located near the open coast so when the 5 m storm surge propagated in connectivity and subgrid corrections played less of a role in altering the overall water level however this is not the case for gauges lc2a lc5 and lc6a which are located further inland at these locations the coarse subgrid outperforms the coarse traditional simulation by more than 20 cm again this is expected because as the surge propagates further inland the influence of subgrid features and flow connectivity have greater effects on the flow the most notable difference between the coarse subgrid and coarse traditional simulation is at the lc2a gauge located north of calcasieu lake fig 7 this gauge is farthest from the open coast and is connected via the narrow bayou contraband and it recorded a maximum water level of 2 55 m during the storm at this location the coarse traditional simulation goes dry at 1100 utc 24 september at a water level of 0 m and then rapidly wets at 1400 utc 24 september during the peak of the storm surge the maximum water level of the coarse traditional simulation remains more than 1 m below the maximum surge predicted by the fine traditional simulation at this gauge and is hydraulically disconnected from calcasieu lake the fine traditional and coarse subgrid simulations predicted a peak surge of 2 45 m and 2 18 m respectively thus the coarse subgrid results are too low by about 0 27 m at this location when compared to the fine traditional results likely due to high winds pushing water out of calcasieu lake causing an excessive draw down and a minimum wet threshold of ϕ min 0 05 which may not fully capture the subgrid processes in bayou contraband to further evaluate the three simulations maximum water levels were taken along the main channel thalweg from the gulf of mexico to lake charles la fig 8 from the north end of lake calcasieu to lake charles the maximum water levels from the coarse subgrid simulation are 0 25 m below that from the fine traditional simulation while the coarse traditional simulation underpredicts water levels by more than 1 m compared to the fine simulation for the e rms along the main channel thalweg the coarse subgrid e rms 0 220 m while the coarse traditional e rms 0 564 m this further demonstrates the superiority of the subgrid simulation at conveying flows through narrow channels for these simulations the subgrid corrections add about 40 to the run time when compared to the coarse traditional simulation table 2 however the coarse subgrid was about 32 times faster than the fine traditional and was able to connect flow from the gulf of mexico through lake calcasieu and up the contraband bayou 4 discussion in these test cases the subgrid adcirc consistently out performs its traditional counterpart in terms of hydraulic connectivity and maximum water level accuracy and it allows for efficiency gains by using coarser meshes to represent coastal regions these advancements have implications for the prediction of storm surge and coastal flooding both in real time forecasting and for long term planning the subgrid corrections can be used for predictions with realistic storm forcing in realistic coastal domains this is an extension of recent subgrid modeling studies which have used water levels applied at the open boundary from idealized sinusoidal tidal curves or water level data from field measurements defina 2000 casulli 2009 kennedy et al 2019 wu et al 2016 42 used atmospheric forcing from a storm event in the north sea however this storm event was not on the scale or power of a tropical cyclone in our third test case subgrid adcirc was forced with hurricane strength winds and storm surge from rita 2005 the model was able to represent the storm s effects on flow at the coast more specifically the flooding of the low lying topography of southwest louisiana and the flow through channels smaller than the model scale the largest discrepancy between coarse traditional and subgrid simulations was at the lc2a gauge where the model resolution was about seven times larger than the 300 m wide bayou contraband subgrid adcirc also allows for a coarsening of the meshes used to describe the coastal region for the winding channel test case nearly identical maximum water levels were predicted in the channel by the coarse subgrid and the fine traditional simulations with improved connectivity in the coarse subgrid simulation fig 3 despite the coarse subgrid simulation having 65 times fewer degrees of freedom and a minimum resolution that was 20 times coarser the simulation of buttermilk bay also showed virtually no difference in maximum water levels between the coarse subgrid and fine traditional simulations despite the coarse subgrid simulation having almost 6 times fewer degrees of freedom and a minimum resolution that was 10 times coarser again the subgrid showed better hydraulic connectivity especially in locations in small scale channels than the fine traditional for the calcasieu lake test case the coarse subgrid and fine traditional showed good comparison to gauge observations from hurricane rita 2005 despite the coarse subgrid simulation having 33 times fewer degrees of freedom and a minimum resolution that was 40 times coarser the subgrid simulation was able to represent flows to the inland lc2a gauge because it allowed flow through the bayou contraband below the model scale these results are similar to those by kennedy et al 2019 sehili et al 2014 and wu et al 2016 who found that the subgrid corrections allowed for a coarsening of meshes by at least 1 order of magnitude these advancements have implications for real time forecasting and long term engineering and design when adcirc is run traditionally with fine resolution meshes each simulation can require thousands of compute cores and hours of wall clock time hope et al 2013 during a storm event this requirement can limit its use in a probabilistic forecasting framework which can account for slight variations in storm track intensity and timing fleming et al 2008 and which is used by other forecast models like the sea land and overland surges from hurricanes slosh model national hurricane center 2020 subgrid adcirc may enable probabilistic forecasting between storms agencies like the united states army corps of engineers usace and the federal emergency management administration fema use adcirc to better prepare coastal cities and communities from future flooding events u s army corps of engineers 2015 federal emergency management agency 2019 typically by simulating hundreds of synthetic storm surge scenarios to produce flood hazard maps for state and municipalities subgrid adcirc could drastically reduce these studies computational and monetary cost these results do indicate paths for future work specifically in the drawdown and underprediction of water levels at the lc2a gauge and the consistent underprediction of water levels by the subgrid simulation along the main channel thalweg in the calcasieu lake test case figs 7 and 8 in those tests the coarse subgrid consistently under predicted water levels when compared to the fine traditional this may be attributed to an over estimation of friction by the subgrid model and increases in manning s n values from interpolation to the coarsened mesh volp et al 2013 presented a scheme to correct this over prediction and take advantage of high resolution roughness data implementation of a friction correction should lend itself well to the current subgrid framework present in the code the drawdown that occurred at this location as the storm made landfall is present in both the fine traditional and coarse subgrid simulations the water levels are decreased to 1 0 m or about 1 3 m below the gauge data these differences can largely be attributed to the gauge installation the lc2a gauge was a barotropic pressure sensor mounted sub aerially at 0 303 m navd88 therefore the sensor was not able to measure a drawdown below 0 303 m the flattening of the gauge data from 0000 utc to 0500 utc 24 september indicates that the water level dropped below the gauge mount elevation thus there is no way of verifying prediction accuracy during this time period other factors that could have affected model accuracy include poor representation of vertical features like roadways and levees that lie along the lake s edge and act as hydraulic barriers to keep water in the lake during the storm these hydraulic features can be better represented with cell clones which prevent flow between non hydraulically connected features previous implementations of cell clones have used numerical schemes in which the velocities are located along the cell edge which allows for connectivity and or blocking of flows within the cell begmohammadi et al 2021 casulli 2019 this capability will be challenging to implement in adcirc because the model defines the flow variables at the vertices of each element and thus it is not straight forward to identify connectivity for each clone however the capability would better represent the blocking of flow due to subgrid obstacles 5 conclusions in this study subgrid corrections were implemented in the widely used adcirc model for storm surge and coastal flooding these corrections were tested on a variety of domains and showed promising results both for idealized and realistic tides and storm surge subgrid adcirc is able to capture hydraulic connectivity and water level calculations on coarsened meshes in which small hydraulic features are not resolved at the mesh scale this improvement is attributed to subgrid adcirc s ability to represent small hydraulic features contained within partially wet elements without the use of sufficiently small element sizes traditional adcirc cannot resolve these features the inclusion of partially wet elements to solve for water levels and velocities was achieved by redesigning the wetting and drying routine within the code to solely rely on the wet area fraction ϕ when determining the wet dry state of an element or vertex the main contributions and findings of this study are 1 extension of subgrid corrections using the widely used adcirc storm surge model with hurricane strength forcing the addition of subgrid corrections to adcirc s governing equations allowed for use of partially wet elements and vertices this permits modified storm forcing at the wet dry boundary by way of the wet area fraction testing on the realistic calcasieu lake domain using forcing from rita 2005 demonstrated that these modifications give good overall matches to gauge hydrographs when run on coarsened meshes 2 subgrid corrections in adcirc allow for increases in accuracy and hydraulic connectivity when running on significantly coarsened meshes in a forecasting scenario this would give emergency managers and decision makers a more accurate prediction of when flood waters will arrive and recede this will allow them to use the best information possible when deciding evacuation times and coordinating search and rescue missions 3 for a given grid introducing subgrid corrections to adcirc increases computational cost to the code however these costs are small when compared to the efficiency gained by running on coarsened meshes in our current implementation the coarse subgrid storm surge simulation on calcasieu lake is approximately 40 slower than its coarse traditional counterpart nevertheless it ran 32 times faster than the fine simulation and produced comparable results reducing the simulation run time from 42 2 h to 1 3 h with these additions subgrid adcirc has the potential to predict coastal flooding at a fraction of the computational cost further investigation is needed as to whether this efficiency can be further increased with adjustments to the model time step future work will include tests of subgrid adcirc on ocean scale domains the use of ensemble frameworks to forecast storm surge and the use of additional correction such as friction to further improve model results credit authorship contribution statement johnathan l woodruff conceptualization methodology software validation formal analysis investigation resources data curation writing original draft writing review editing visualization j c dietrich conceptualization methodology software resources writing original draft writing review editing supervision project administration funding acquisition d wirasaet conceptualization methodology software writing review editing supervision a b kennedy conceptualization methodology writing review editing supervision project administration funding acquisition d bolster conceptualization writing review editing supervision project administration funding acquisition z silver software s d medlin visualization r l kolar methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by national science foundation united states grants icer 1664037 and 1664040 the support of the national science foundation and the us army corps of engineers is greatly appreciated by all contributors to this project appendix averaged governing equations for adcirc the upscaled governing equations stated in section 2 3 are derived by applying a formal averaging technique whitacker 1999 to the standard 2d shallow water equations written in the conservative form by following such a technique we define a mesh scale average of any flow quantity q as a 1 q g 1 a g a w q d a where a g denotes the mesh area and a w the wet area within a g note that a g and a w are related through eq 2 in addition an alternative average use in the wet average commonly known as intrinsic phase average defined by a 2 q w 1 a w a w q d a in addition the following rules whitacker 1985 are used to interchange differentiation with respect to time and space and time dependent spatial integration in the formula below u b denotes the velocity of the potentially moving boundary n s n s x n s y is an outward pointing unit vector normal to the wet dry boundary γ w is the wet dry boundary and the subscript r denotes a dummy notation for the x or y coordinates a 3 q t g q g t 1 a g γ w q u b n s d s and a 4 q r g q g r 1 a g γ w n s r q d s the development of subgrid equations involves roughly applying a 2 to the mass and momentum equations making use of a 3 and a 4 and determining closures for terms that are not uniquely defined by the coarsened mesh scale variables the following subsections describe the development of the averaged mass equation the averaged momentum equations and the reformulation of the averaged continuity equation into the gwce form a 1 averaged primitive continuity equation the primitive continuity equation is a 5 h t u h x v h y 0 in which h h ζ is the total water depth h is the bathymetric depth measured positive downwards from a reference datum ζ is the water surface elevation measured positive upwards from the datum u and v are the depth averaged horizontal velocity components in the x and y directions respectively the mesh scale averaging of each term is described below first for the local rate of change in time we use a 3 to pull the time derivative out of the integral more specifically a 6 h t g 1 a g a w h t d a 1 a g t a w h d a 1 a g γ w h u b n s d s because h 0 at the wet dry front we eliminate the boundary integral and obtain a 7 h t g 1 a g a w h t d a 1 a g t a w h d a h g t which is now temporal rate of change of the averaged total water depth next for the volume flux in the x direction we apply the spatial averaging a 4 to pull the spatial derivative out of the integral more precisely a 8 u h x g 1 a g a w u h x d a 1 a g x a w u h d a 1 a g γ w u h n s x d s again h 0 at the wet dry boundary we eliminate the boundary integral and have a 9 u h x g 1 a g a w u h x d a 1 a g x a w u h d a u h g x the interchange between differentiation and integration in the averaging of the last term the volume flux in the y direction can be done in an analogous way after above manipulation the averaged primitive continuity equation becomes a 10 h g t u h g x v h g y 0 by postulating that ζ varies very slowly within a w one has h g 1 a g z inf z ζ w a g m a x 0 b z d a d z as a consequence we can rewrite eq a 10 as a 11 ϕ ζ w t u h g x v h g y 0 which is the final averaged form of the primitive continuity equation to be considered in the reformulation into the gwce described below in appendix a 3 note that in this study we consider u h g as the variable to be solved for instead of using a 2 the velocity when required is computed from the following formula a 12 u a w h u d a a w h d a h u g h g or equivalently a 13 u h g u h g it is worth mentioning that the so called volume averaged velocity defined above has an advantage over an averaged velocity defined by a 2 in that it permits a substitution of u h g by u h g in the governing equation without the need to resort to a more complicated closure from this point forward unless otherwise indicated the notation u is understood as the volume averaged velocity note that various forms of governing equations presented kennedy et al 2019 are obtained from making use of a 13 they are intended for the solution where u is chosen as an unknown variable a 2 averaged conservative momentum equations we now average to the mesh scale the conservative momentum equations including terms for the barotropic pressure gradient and lateral momentum mixing stress terms consider the momentum equation in the x direction a 14 u h t u u h x u v h y f v h g h ζ p a x τ s x ρ 0 τ b x ρ 0 m x it can be verified through the use of a 3 and a 4 and h 0 at the wet dry boundary that the mesh scale averaging of a 14 is equivalent to a 15 u h g t u u h g x v u h g y f v h g g h ζ x g g h g p a x τ s x ρ 0 g τ b x ρ 0 g m x in the above equation the coriolis parameter f and the atmospheric pressure p a are assumed to vary at a spatial scale much larger than the grid scale and hence can be moved out of their respective integral terms there is no unique way to define the averaging of convective momentum bottom friction surface gradients and lateral mixing stresses in terms of the mesh scale quantities h g u h g u further assumptions to be described below are therefore required to close the system for the convective accelerations we chose the closure of the form written below u u h g c u u u u h g u v h g c u v u v h g which resemble the particular forms of the convective momentum considered in adcirc see equation 2 2 on p 15 of the adcirc theory report luettich and westerink 2004 with additional correction coefficients c u u and c u v for the surface gradient pressure term we consider the following closure a 16 g h p a x g g h g p a x g ϕ h ζ x w g c ζ ϕ h w ζ w x g c ζ h g ζ w x where c ζ is an additional correction coefficient although counterintuitive numerical evidences demonstrate in kennedy et al 2019 indicated that c ζ is clearly needed in some cases for the surface stress term we consider the quadratic drag law for the surface stress caused by wind a 17 τ s x ρ 0 g ϕ τ s x ρ 0 w ϕ ρ a ρ 0 c d w 10 w 10 x where ρ a denotes the air density and w 10 w 10 x w 10 x denotes the 10 m wind velocity assumed to be known wind data comes typically from a numerical model with a spatial scale greater than the grid scale considered in the surge model the bottom stress τ b x is assumed to obey a quadratic bottom friction law and the closure below is considered a 18 τ b x ρ 0 g ϕ τ b x ρ 0 w ϕ c f u u h h w ϕ c m f u u h w h w where c m f is to be determined equivalent frictional coefficients that may depend on water surface elevations in this work for simplicity c m f is taken to be a 19 c m f g n w 2 h w 1 3 where n w is a value characterizing the manning s roughness coefficient of the wet area finally consider the average of the lateral mixing term a 20 m x g h τ x x x h τ y x y g 1 a g x a w h τ x x d a 1 a g γ w h τ x x n s x d s 1 a g y a w h τ y x d a 1 a g γ w h τ y x n s y d s h τ x x g x h τ y x g y boundary integrals go to zero because h 0 at the wet dry boundary indeed the vertically integrated lateral terms h τ x x and h τ y x by itself require a closure assumption adcirc supports several lateral closures here we consider one specific form of such closures more precisely h τ x x e h u h x h τ y x e h u h y the grid average of these lateral closures are approximated as a 21 h τ x x g e h u h g x h τ y x g e h u h g y where e h is a grid scale eddy viscosity potentially of different value than that used in the high resolution calculation with the closure terms given above the averaged momentum equation in the x direction becomes a 22 u h g t g c ζ h g ζ w x c u u u u h g x c v u v u h g y f v h g g h g p a x ϕ τ s x ρ 0 w g n w 2 u u h g h w 4 3 x e h u h g x y e h u h g y similarly the averaged momentum equation in the y direction with closure terms is a 23 v h g t g c ζ h g ζ w y c u v u v h g x c v v v v h g y f u h g g h g p a y ϕ τ s y ρ 0 w g n w 2 u v h g h w 4 3 x e h v h g x y e h v h g y the final step is to select the correction coefficients in this work we consider a so called level 0 closure kennedy et al 2019 in which c u u c u v c v u c v v 1 c ζ 1 then the only non unity closure is the wet area fraction as shown in the final eqs 5 and 6 a 3 averaged generalized wave continuity equation then the gwce is formed by differentiating eq a 11 with respect to time adding to this a 11 multiplied by a positive spatially varying numerical parameter τ 0 this leads to a 24 t ϕ ζ w t τ 0 ϕ ζ w t j x g x j y g y u h g τ 0 x v h g τ 0 y 0 where a 25 j x g u h g t τ 0 u h g and a 26 j y g v h g t τ 0 v h g the time derivative terms u h g t and v h g t in the above equation are further eliminated by means of the momentum equation a 22 and a 23 with the level 0 closure we obtain the final form of the gwce as it appears in eq 7 repeated below ϕ 2 ζ w t 2 ϕ t ζ w t τ 0 ϕ ζ w t x g h g ζ w x y g h g ζ w y j x g x j y g y u h g τ 0 x v h g τ 0 y 0 where j x g rhs of a 22 τ 0 u h g and j y g rhs of a 23 τ 0 v h g note that for h g 0 i e in fully wet or partial wet areas the gwce is a second order wave equation a 4 finite element discretization in this study the adcirc solvers were kept largely the same the gwce is solved implicitly via the use of a global mass matrix while the momentum equations are solved semi implicitly both element and vertex based quantities are used in these solutions on each time marching step the gwce eq 7 uses elementally averaged quantities fig 1 to find a vertex averaged water surface elevation ζ w this quantity is then used to look up the corresponding vertex averaged total water depth h w wet area fraction ϕ and wet averaged manning s n n w which are used along with elementally averaged quantities to solve eqs 5 and 6 for the vertex averaged water velocities because we are solving averaged equations the solutions for ζ w u and v are appropriately averaged therefore no further manipulation is required the only change was the addition of the ϕ t ζ w t which was discretized in the following way ϕ t ζ w t n 1 n e j a n 12 ϕ n t i 1 3 φ i j ζ w i t where ϕ n t ϕ n s ϕ n s 1 δ t and ζ w i t ζ i s 1 ζ i s 1 2 δ t here a n is the area of element n n e j is the number of elements containing node j ϕ n is the average wet area fraction over element n φ i j is the weighting function and s is the current timestep 
23888,similar to the stokes drift in periodic gravity waves we introduce a second order stokes effect on the particle drift in isolated linear surface disturbances pulses in shallow water for a linear disturbance with the shape and length scale of a kdv solitary wave the model results agree surprisingly well with the observed drift in moderately steep solitary waves in the laboratory as well as with more comprehensive theory for surface drift in solitary waves keywords shallow water equations surface pulses stokes drift solitary waves 1 introduction wave induced particle drift in shallow water is a phenomenon that is of considerable interest for coastal engineers and environmentalists it has an impact on sediment transport as well as the spread of effluents and pollution in the near shore zone for periodic irrotational waves the story goes back to the seminal paper by stokes 1847 since then the number of papers on the mean drift in periodic surface waves has grown enormously the next major step forward was due to longuet higgins 1953 introducing the effect of viscosity into the wave drift problem for a recent overview of direct lagrangian calculations of the wave induced drift in a viscous ocean the reader is referred to weber 2019 where also relevant references to inviscid studies are listed for non periodic flows such as the motion of isolated disturbances or pulses along the sea surface there is also a mass transport unlike the spiraling forward particle motion in periodic irrotational waves this drift is just a finite forward particle displacement caused the passage of single pulse the most celebrated disturbance of this kind is the solitary wave observed by russell 1838 1845 which led to theoretical investigations by boussinesq 1871 and rayleigh 1876 the lowest order solution is obtained by the kdv equation korteweg and de vries 1895 valid asymptotically in the limit of small amplitude and long wavelength the solitary wave has been studied to third order in the parameter ɛ a h by grimshaw 1971 where a is the maximum surface amplitude and h is the undisturbed fluid depth and to ninth order by fenton 1972 see the review by miles 1980 existence theory for solitary waves has been developed by amongst others amick and toland 1981 more recently constantin and escher 2007 analyzed formally particle paths associated with solitary wave solutions see also constantin 2010 and constantin et al 2011 in borluk and kalisch 2012 velocity fields related to exact solutions of the kdv equation are reported and particle trajectories are computed numerically in the present study we follow the approach by eames and mcintyre 1999 for the lagrangian displacement due to periodic wave motion but apply it to isolated surface pulses the rest of the paper is organized as follows in section 2 we derive the exact equations for the particle drift in irrotational waves and section 3 gives the well known results for periodic waves section 4 considers non periodic flows in the form of isolated disturbances or pulses in shallow water and discusses the stokes drift in the general case the pulses are solutions of the small amplitude shallow water equation in section 5 we study a linear pulse with the spatial shape of solitary wave in the kdv approximation however we do not derive asymptotically valid results for the kdv solitary wave when the stokes drift is added to the drift in the linear pulse we obtain surprisingly good fit with laboratory experiments on moderately steep solitary waves as well as with higher order theory finally section 6 contains some concluding remarks 2 mathematical derivation we consider two dimensional motion of an incompressible and irrotational fluid in a horizontal layer when undisturbed the depth is constant and equal to h the effect of the earth s rotation is not taken into account the x axis is along the undisturbed surface and the z axis is vertically upward the bottom at z h is impermeable when we have a disturbance the velocity components are u w and free surface is given by z η x t where t denotes time since the fluid is irrotational we can write the velocity components u φ x w φ z where φ is the velocity potential hence 1 u d x d t φ x where x is a horizontal particle coordinate and d d t is the rate of change following a fluid particle we consider waves of permanent form that propagates with constant phase speed c in that case c x t and we can write 1 eames and mcintyre 1999 2 d x d t c 1 φ t c 1 d φ d t φ φ this expression has been derived earlier by eames et al 1994 in connection with the darwin drift caused by a single body moving through an inviscid fluid in the same way we can use that the fluid is incompressible and write w ψ x where ψ is the stream function hence 3 d z d t c 1 ψ t c 1 d ψ d t φ ψ c 1 d ψ d t where z is a vertical particle coordinate weber et al 2014 we realize that although 2 and 3 are exact equations the particle displacements are given in an implicit way in integrating these equations in time we must follow a fluid particle which at time t 0 has a position x 0 a c z 0 a c where a c are the independent lagrangian variables the gradient operator in 2 must also be evaluated in lagrangian terms formally from 2 and 3 we obtain for the lagrangian horizontal and vertical displacements skipping constants of integration 4 x a c t c 1 φ a c t x s 5 z a c t c 1 ψ a c t where 6 x s a c t c 1 x t 2 z t 2 d t here x s is the stokes particle displacement 3 periodic motion for a periodic disturbance due to an infinite train of waves we have that φ and ψ are purely periodic integrating 2 over the time period τ we find 7 x t τ x t c 1 φ t τ φ t x s t τ x s t since the bracket on the right hand side vanishes one obtains the lagrangian drift velocity u l by dividing by the period eames and mcintyre 1999 8 u l τ 1 x t τ x t τ 1 x s t τ x s t u s where u s is the stokes drift this again demonstrates that the lagrangian mean drift and the stokes drift is equal in irrotational inviscid periodic wave motion i e the eulerian mean motion vanishes identically longuet higgins 1953 likewise from 3 we obtain the trivial result for the vertical lagrangian drift w l 9 w l τ 1 z t τ z t τ c 1 ψ t τ ψ t 0 the result 9 is also valid for horizontally propagating internal waves which possess vorticity weber et al 2014 for periodic waves the stokes drift can be written from 6 10 u s τ 1 x s t τ x s t τ c 1 t t τ φ φ d t to lowest order the lagrangian and eulerian solutions for periodic waves are equal therefore one can evaluate the stokes drift to second order from 10 by inserting for the linear eulerian velocities in the integral on the right hand side see longuet higgins 1953 4 non periodic flows the aim of this paper is to study the effect of the stokes drift in small amplitude non periodic waves in the nonrotating shallow water approximation the lowest order surface elevation is governed by 11 2 η t 2 c 0 2 2 η x 2 0 where c 0 2 g h a general solution for isolated disturbances or pulses that propagates to the right can be written 12 η f ξ here 13 ξ x c 0 t l is the phase where l is the typical lateral extent of the disturbance the corresponding velocity components u w become 14 u g f ξ c 0 15 w c 0 z h f ξ l h where the prime denotes differentiation with respect to ξ hence since u φ x w ψ x we obtain from 4 and 5 16 x l h f d ξ h 1 f 2 d ξ 17 z 1 z h f ξ where the last term in 16 is the stokes displacement in a linear pulse here we have used the shallow water approximation u 2 w 2 in 16 assuming that the pulse is symmetrical and that the peak is situated at the origin at t 0 we can write the maximum horizontal and vertical displacements x and z as 18 x 2 l h 1 0 f ξ d ξ h 1 0 f 2 ξ d ξ 19 z h 1 z h f ξ 0 this is a general result for linear symmetric pulses in shallow water where the effect of the stokes drift has been taken into account 5 a solitary wave like pulse the results in the last section can be applied to linear pulses of any shape of particular interest is the surface shape that resembles a solitary wave in the kdv approximation in this approximation the surface displacement is given by 20 η a sech 2 α x c t h where 21 α 2 3 ɛ 4 and 22 c 2 c 0 2 1 ɛ we consider a linear pulse with the shape of a kdv solitary wave i e we take that 23 η f ξ a sech 2 ξ where ξ is given by 13 the maximum horizontal and vertical drift of particles during the passage of this wave becomes from 18 and 19 24 x 2 l ɛ 0 sech 2 ξ d ξ ɛ 0 sech 4 ξ d ξ 2 l ɛ 1 2 ɛ 3 25 z z h ɛ it is interesting to compare our results with the surface data in the laboratory experiments on solitary waves by longuet higgins 1981 and hsu et al 2012 considering cases of not too steep waves in linear theory the ratio l h in 18 is arbitrary as long as l h from 21 we have for long waves in the kdv approximation that 26 l 2 h 3 ɛ 1 2 this appears to be the relevant length scale we should use in our theory for comparison with laboratory experiments inserting into 24 the maximum particle displacements at the surface become 27 x h 2 l h ɛ 1 2 ɛ 3 4 3 3 ɛ 1 2 1 2 ɛ 3 28 z h ɛ the results for the surface drift are depicted in fig 1 where the non dimensional maximum displacements have been defined as xm x h and zm z h we note from the figure that our simple theoretical model with the inclusion of the stokes drift and the kdv length scale is able to reproduce fairly well the surface drift in laboratory experiments as well as the ninth order theoretical results by fenton 1972 formally from a small amplitude point of view we have obviously depicted the blue curve in fig 1 for too large values of the parameter ɛ a h where a is the maximum surface amplitude and h is the undisturbed fluid depth it is therefore quite surprising that the fit with experimental data and highly nonlinear theory are so good for larger ɛ it is an interesting fact that formal power series expansions in the parameter ɛ for solitary waves breaks down rather quickly as pointed out by longuet higgins 1981 the zm vs xm curve from the kdv solution very soon deviates from the experimental data when ɛ increases it is also found that third order theory grimshaw 1971 does not improve that result very much even fenton s ninth order solution loses accuracy for ɛ 0 7 longuet higgins and fenton 1974 the present approach does not constitute a formal power series expansion although it contains higher powers in ɛ we start out with a linear pulse but this is not a linear drift model more correctly it is a hybrid model that includes a nonlinear stokes drift and a kdv length scale judging from fig 1 this combination apparently captures some of the essence of this problem 6 concluding remarks particle drift in isolated surface pulses in shallow water is a quantity that are of considerable interest for coastal engineers and environmentalists a considerable amount of work has been devoted to the study of steep solitary waves see jonsson et al 2000 however isolated disturbances traveling along the sea surface are usually not very steep an example here is a tsunami in the open ocean then a simple theoretical approach like the present one may yield reasonable results for the particle drift in small and moderately steep surface pulses credit authorship contribution statement jan erik h weber ensuring that the descriptions are accurate declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
23888,similar to the stokes drift in periodic gravity waves we introduce a second order stokes effect on the particle drift in isolated linear surface disturbances pulses in shallow water for a linear disturbance with the shape and length scale of a kdv solitary wave the model results agree surprisingly well with the observed drift in moderately steep solitary waves in the laboratory as well as with more comprehensive theory for surface drift in solitary waves keywords shallow water equations surface pulses stokes drift solitary waves 1 introduction wave induced particle drift in shallow water is a phenomenon that is of considerable interest for coastal engineers and environmentalists it has an impact on sediment transport as well as the spread of effluents and pollution in the near shore zone for periodic irrotational waves the story goes back to the seminal paper by stokes 1847 since then the number of papers on the mean drift in periodic surface waves has grown enormously the next major step forward was due to longuet higgins 1953 introducing the effect of viscosity into the wave drift problem for a recent overview of direct lagrangian calculations of the wave induced drift in a viscous ocean the reader is referred to weber 2019 where also relevant references to inviscid studies are listed for non periodic flows such as the motion of isolated disturbances or pulses along the sea surface there is also a mass transport unlike the spiraling forward particle motion in periodic irrotational waves this drift is just a finite forward particle displacement caused the passage of single pulse the most celebrated disturbance of this kind is the solitary wave observed by russell 1838 1845 which led to theoretical investigations by boussinesq 1871 and rayleigh 1876 the lowest order solution is obtained by the kdv equation korteweg and de vries 1895 valid asymptotically in the limit of small amplitude and long wavelength the solitary wave has been studied to third order in the parameter ɛ a h by grimshaw 1971 where a is the maximum surface amplitude and h is the undisturbed fluid depth and to ninth order by fenton 1972 see the review by miles 1980 existence theory for solitary waves has been developed by amongst others amick and toland 1981 more recently constantin and escher 2007 analyzed formally particle paths associated with solitary wave solutions see also constantin 2010 and constantin et al 2011 in borluk and kalisch 2012 velocity fields related to exact solutions of the kdv equation are reported and particle trajectories are computed numerically in the present study we follow the approach by eames and mcintyre 1999 for the lagrangian displacement due to periodic wave motion but apply it to isolated surface pulses the rest of the paper is organized as follows in section 2 we derive the exact equations for the particle drift in irrotational waves and section 3 gives the well known results for periodic waves section 4 considers non periodic flows in the form of isolated disturbances or pulses in shallow water and discusses the stokes drift in the general case the pulses are solutions of the small amplitude shallow water equation in section 5 we study a linear pulse with the spatial shape of solitary wave in the kdv approximation however we do not derive asymptotically valid results for the kdv solitary wave when the stokes drift is added to the drift in the linear pulse we obtain surprisingly good fit with laboratory experiments on moderately steep solitary waves as well as with higher order theory finally section 6 contains some concluding remarks 2 mathematical derivation we consider two dimensional motion of an incompressible and irrotational fluid in a horizontal layer when undisturbed the depth is constant and equal to h the effect of the earth s rotation is not taken into account the x axis is along the undisturbed surface and the z axis is vertically upward the bottom at z h is impermeable when we have a disturbance the velocity components are u w and free surface is given by z η x t where t denotes time since the fluid is irrotational we can write the velocity components u φ x w φ z where φ is the velocity potential hence 1 u d x d t φ x where x is a horizontal particle coordinate and d d t is the rate of change following a fluid particle we consider waves of permanent form that propagates with constant phase speed c in that case c x t and we can write 1 eames and mcintyre 1999 2 d x d t c 1 φ t c 1 d φ d t φ φ this expression has been derived earlier by eames et al 1994 in connection with the darwin drift caused by a single body moving through an inviscid fluid in the same way we can use that the fluid is incompressible and write w ψ x where ψ is the stream function hence 3 d z d t c 1 ψ t c 1 d ψ d t φ ψ c 1 d ψ d t where z is a vertical particle coordinate weber et al 2014 we realize that although 2 and 3 are exact equations the particle displacements are given in an implicit way in integrating these equations in time we must follow a fluid particle which at time t 0 has a position x 0 a c z 0 a c where a c are the independent lagrangian variables the gradient operator in 2 must also be evaluated in lagrangian terms formally from 2 and 3 we obtain for the lagrangian horizontal and vertical displacements skipping constants of integration 4 x a c t c 1 φ a c t x s 5 z a c t c 1 ψ a c t where 6 x s a c t c 1 x t 2 z t 2 d t here x s is the stokes particle displacement 3 periodic motion for a periodic disturbance due to an infinite train of waves we have that φ and ψ are purely periodic integrating 2 over the time period τ we find 7 x t τ x t c 1 φ t τ φ t x s t τ x s t since the bracket on the right hand side vanishes one obtains the lagrangian drift velocity u l by dividing by the period eames and mcintyre 1999 8 u l τ 1 x t τ x t τ 1 x s t τ x s t u s where u s is the stokes drift this again demonstrates that the lagrangian mean drift and the stokes drift is equal in irrotational inviscid periodic wave motion i e the eulerian mean motion vanishes identically longuet higgins 1953 likewise from 3 we obtain the trivial result for the vertical lagrangian drift w l 9 w l τ 1 z t τ z t τ c 1 ψ t τ ψ t 0 the result 9 is also valid for horizontally propagating internal waves which possess vorticity weber et al 2014 for periodic waves the stokes drift can be written from 6 10 u s τ 1 x s t τ x s t τ c 1 t t τ φ φ d t to lowest order the lagrangian and eulerian solutions for periodic waves are equal therefore one can evaluate the stokes drift to second order from 10 by inserting for the linear eulerian velocities in the integral on the right hand side see longuet higgins 1953 4 non periodic flows the aim of this paper is to study the effect of the stokes drift in small amplitude non periodic waves in the nonrotating shallow water approximation the lowest order surface elevation is governed by 11 2 η t 2 c 0 2 2 η x 2 0 where c 0 2 g h a general solution for isolated disturbances or pulses that propagates to the right can be written 12 η f ξ here 13 ξ x c 0 t l is the phase where l is the typical lateral extent of the disturbance the corresponding velocity components u w become 14 u g f ξ c 0 15 w c 0 z h f ξ l h where the prime denotes differentiation with respect to ξ hence since u φ x w ψ x we obtain from 4 and 5 16 x l h f d ξ h 1 f 2 d ξ 17 z 1 z h f ξ where the last term in 16 is the stokes displacement in a linear pulse here we have used the shallow water approximation u 2 w 2 in 16 assuming that the pulse is symmetrical and that the peak is situated at the origin at t 0 we can write the maximum horizontal and vertical displacements x and z as 18 x 2 l h 1 0 f ξ d ξ h 1 0 f 2 ξ d ξ 19 z h 1 z h f ξ 0 this is a general result for linear symmetric pulses in shallow water where the effect of the stokes drift has been taken into account 5 a solitary wave like pulse the results in the last section can be applied to linear pulses of any shape of particular interest is the surface shape that resembles a solitary wave in the kdv approximation in this approximation the surface displacement is given by 20 η a sech 2 α x c t h where 21 α 2 3 ɛ 4 and 22 c 2 c 0 2 1 ɛ we consider a linear pulse with the shape of a kdv solitary wave i e we take that 23 η f ξ a sech 2 ξ where ξ is given by 13 the maximum horizontal and vertical drift of particles during the passage of this wave becomes from 18 and 19 24 x 2 l ɛ 0 sech 2 ξ d ξ ɛ 0 sech 4 ξ d ξ 2 l ɛ 1 2 ɛ 3 25 z z h ɛ it is interesting to compare our results with the surface data in the laboratory experiments on solitary waves by longuet higgins 1981 and hsu et al 2012 considering cases of not too steep waves in linear theory the ratio l h in 18 is arbitrary as long as l h from 21 we have for long waves in the kdv approximation that 26 l 2 h 3 ɛ 1 2 this appears to be the relevant length scale we should use in our theory for comparison with laboratory experiments inserting into 24 the maximum particle displacements at the surface become 27 x h 2 l h ɛ 1 2 ɛ 3 4 3 3 ɛ 1 2 1 2 ɛ 3 28 z h ɛ the results for the surface drift are depicted in fig 1 where the non dimensional maximum displacements have been defined as xm x h and zm z h we note from the figure that our simple theoretical model with the inclusion of the stokes drift and the kdv length scale is able to reproduce fairly well the surface drift in laboratory experiments as well as the ninth order theoretical results by fenton 1972 formally from a small amplitude point of view we have obviously depicted the blue curve in fig 1 for too large values of the parameter ɛ a h where a is the maximum surface amplitude and h is the undisturbed fluid depth it is therefore quite surprising that the fit with experimental data and highly nonlinear theory are so good for larger ɛ it is an interesting fact that formal power series expansions in the parameter ɛ for solitary waves breaks down rather quickly as pointed out by longuet higgins 1981 the zm vs xm curve from the kdv solution very soon deviates from the experimental data when ɛ increases it is also found that third order theory grimshaw 1971 does not improve that result very much even fenton s ninth order solution loses accuracy for ɛ 0 7 longuet higgins and fenton 1974 the present approach does not constitute a formal power series expansion although it contains higher powers in ɛ we start out with a linear pulse but this is not a linear drift model more correctly it is a hybrid model that includes a nonlinear stokes drift and a kdv length scale judging from fig 1 this combination apparently captures some of the essence of this problem 6 concluding remarks particle drift in isolated surface pulses in shallow water is a quantity that are of considerable interest for coastal engineers and environmentalists a considerable amount of work has been devoted to the study of steep solitary waves see jonsson et al 2000 however isolated disturbances traveling along the sea surface are usually not very steep an example here is a tsunami in the open ocean then a simple theoretical approach like the present one may yield reasonable results for the particle drift in small and moderately steep surface pulses credit authorship contribution statement jan erik h weber ensuring that the descriptions are accurate declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
23889,an improved estimation of the surface currents in the levantine basin of the mediterranean sea is crucial for a wide range of applications including pollutants transport and nutrients distribution this estimation remains challenging due to the scarcity or shortcomings of various data types used for this purpose in this paper we present an objective validation of a variational assimilation algorithm that blends geostrophic velocities derived from altimetry wind induced velocities and drifter positions to continuously obtain velocity corrections the assessment of the validation impact was based on available independent in situ data current meters gliders and independent drifters and satellite ocean color images in all cases the improvement was shown either qualitatively position of the eddies or quantitatively keywords altimetry lagrangian data data assimilation drifters surface velocity field levantine mediterranean 1 introduction the surface circulation in the southern part of the mediterranean sea along the north african coasts is characterized by the presence of unstable currents that generate mesoscale eddies see e g robinson et al 1992 millot and taupier letage 2005 amitai et al 2010 and schroeder et al 2012 these eddies have diameters of 10 100 km and lifetimes that can span several months to years see e g puillat et al 2002 hamad et al 2006 mkhinini et al 2014 and pessini et al 2020 mesoscale activity in the eastern mediterranean is intense with high eddy kinetic energy more than 700 cm 2 s 2 recorded historically see e g robinson et al 1992 pujol and larnicol 2005 and gerin et al 2009 mesoscale eddies can interact split or merge and induce smaller scale structures shear eddies and filaments thus tracking them is a real challenge see e g taupier letage et al 2003 d ovidio et al 2004 laxenaire et al 2018 and le vu et al 2018 all these structures can transport coastal waters trap and advect on large distances tracer anomalies such activity has a continuous and direct impact on biogeochemical water properties especially in the redistribution of nutrient rich coastal waters into the oligotrophic open sea see e g taupier letage et al 2003 lehahn et al 2007 levy and martin 2013 and escudier et al 2016 and the dispersion of pollutants an accurate and continuous estimation of surface circulation is therefore needed but remains challenging even though more and more data in particular operational products from the copernicus marine service marine copernicus eu are available for estimating surface currents at sub mesoscale each on their own have their limitations a powerful tool that is widely used to describe the mesoscale features of surface circulation is the state of the art satellite altimetry multi mission gridded altimeter products originated from copernicus marine service have the advantage of providing uninterrupted and continuous global surface velocities caballero et al 2013 nevertheless there are still uncertainties associated with these products relative low spatial resolution of current radar altimetry satellite information is degraded near the coastal areas within 20 50 km from land cipollini et al 2010 incorrect removal of high frequency atmospheric effects that exist at the sea surface caballero et al 2013 mean dynamic topography mdt is not always precisely known in the basin moreover the problem accentuates in the mediterranean sea where a precise knowledge of mdt is still an issue due to the presence of narrow straits and a high number of islands and the small rossby radius of deformation of around 10 km that makes the altimeter resolution insufficient to capture the small details rio et al 2014 due to the coarse resolution in both space and time of the altimeters and to the fact that mesoscale structures move continuously eddies can be missed artificially created smoothed or misplaced mkhinini et al 2014 ioannou et al 2017 characterizing eddies using altimetry can lead to an underestimation of the eddies density especially the small ones these eddies may be not captured by altimetry or tend to be aliased into larger structures compared to the true eddies amores et al 2018 in situ observations are used as a tool to complement and or validate altimetry le traon and hernandez 1992 drifters have the advantage of being autonomous and relatively inexpensive they are in situ lagrangian tools following the ocean current once they are released and adequately equipped with a drogue poulain et al 2012 characterized by positive buoyancy this restrains them along with the two dimensional flow at the surface or near surface of the ocean even though they help in providing a precise description of the surface circulation their spatio temporal distribution is not continuous because they are typically short lived and their spatial distribution is intrinsically uneven when large data sets are available combining altimetric and drifter data can be done using statistical approaches see e g niiler 2003 uchida and imawaki 2003 poulain et al 2009 maximenko et al 2009 poulain et al 2012 menna et al 2012 and stanichny et al 2016 alternatively data can be assimilated in a variational approach in which corrections of the velocity are obtained by minimizing an objective function measuring the difference between observations and their corresponding model variables variational methods that take into account the temporal variation within the optimization are called 4d var kamachi and o brien 1995 mead 2005 nodet 2006 carrier et al 2014 muscarella et al 2015 a more detailed review of various assimilation methodologies can be found in issa et al 2016 from the application point of view merging altimetry and in situ data for a better estimation of the sea surface circulation has previously had several successful applications for example in the gulf of mexico carrier et al 2014 muscarella et al 2015 berta et al 2015 the black sea kubryakov and stanichny 2011 stanichny et al 2016 the north pacific uchida and imawaki 2003 and the mediterranean sea taillandier et al 2006 menna et al 2012 issa et al 2016 each of them using different methodologies for merging validating these merged data sets using in situ current meter data was done in taillandier et al 2006 where the comparison focused on the net transport time series representing the total volume flux over a selected area referring to long term current meter measurements available across the corsica channel the assimilation showed a 10 increase of the estimated net transport leading to instantaneous transport values that are closer to those observed by the current meter the variational assimilation algorithm used by issa et al 2016 proved its efficiency in the eastern levantine mediterranean region specifically along the lebanese coast and in the region between lebanon and cyprus sensitivity analyses showed that the velocity estimation can be improved significantly even with only a small number of drifters the algorithm that was developed relies on continuously correcting the altimetry derived velocity by matching the observed drifters positions with those predicted by an advection model taking into account the wind effect and imposing a divergence free condition on the correction the algorithm needed very few computational resources and converged quickly the contribution of the current work is two fold i a further extension of the application of the previous algorithm by issa et al 2016 in the levantine mediterranean and ii an objective validation of the algorithm using reliable tools data independent of the algorithm itself in particular we use four different types of independent data first a current meter moored off libya is used to validate the algorithm results in terms of velocity intensity and direction second a glider derived near surface absolute geostrophic velocity perpendicular to its trajectory is compared with the projected velocities obtained after assimilation third we reproduce the path of a non assimilated drifter by the simulation of its position using velocities obtained by the assimilation of two other drifters finally we compare streamlines of the corrected velocity field with the shape of an eddy obtained by an ocean color satellite image this offers a qualitative but useful comparison except for products from copernicus operational forecast models or reanalysis we believe that no other surface current data are available in the levantine region for such a comparison the paper is structured as follows we introduce the data used in the assimilation and validation in section 2 in section 3 we provide a brief recap of the algorithm used for the assimilation as well as the sensitivity test done to optimally choose the parameters in section 4 we present the metrics used for validation finally in section 5 we show the results of the assimilation experiments as compared with in situ current meter data ocean color satellite images gliders we also show the results of the independent drifters experiment 2 data the study focuses on the eastern part of the mediterranean that is less investigated than its western counterpart more specifically on the levantine basin the data used for this study are listed in sections 2 1 2 7 2 1 drifters data the egypt egitto program eddies and gyres paths tracking taupier letage et al 2007 focused on the eastern mediterranean southern part spanning the period 2005 2007 it provided an extensive deployment of satellite tracked drifters which helps in characterizing mesoscale and sub mesoscale structures see the 2 years trajectories animation on southeastern mediterranean surface drifter database nettuno ogs trieste it doga sire egitto database egitto movies sep05 oct07 avi these drifters were tracked by the global argos system their time series were interpolated at 0 5 h poulain et al 2013 data were then low pass filtered using a hamming filter with a cut off period at 36 h to eliminate high frequency current components tidal and inertial currents in addition to those we used drifters from the surface circulation in the northeastern mediterranean nemed project from 2009 to 2010 nemed is an observational program releasing drifters between cyprus and the middle east drifters time series were interpolated at 6 h from this large drifters data set 97 drifters from egypt egitto and 31 drifters from nemed menna et al 2018 we selected drifters depending on each validation experiment all drifters used in the assimilation are equipped with a positioned drogue located at 15 m depth which reduces the wind forcing impact 2 2 altimetry data geostrophic surface velocity fields are processed by the duacs data unification and altimeter combination system multi mission altimeter data processing system and distributed by e u copernicus marine service information cmems the sla computation provides the absolute dynamic topography adt and geostrophic currents the gridded products are estimated by an optimal interpolation that merges measurements from several altimeter missions hy 2 a jason 2 jason 1 t p envisat gfo ers1 2 the interpolation provides a consistent and homogeneous database data were daily mapped at a resolution of 1 8 2 3 wind data six hourly wind data were obtained from ecmwf era interim products dee et al 2011 at 10 m above the surface data was re sampled on a half an hour time step the product spatial resolution is approximately 0 7 degrees wind velocities were interpolated at a resolution of 1 8 at the same grid point as the aviso background data although the actual resolution is much coarser 2 4 current meter the first comparison focused on the area of the libyo egyptian coast where the anticyclonic eddies generated by the libyo egyptian current move offshore hamad et al 2006 between april 2006 and april 2007 7 moorings each equipped with current meters were deployed off libya during the egypt egitto program taupier letage et al 2007 to provide information on the circulation of the water masses however since only sub surface moorings could be used because of safety issues the surface layer of atlantic water was sampled at 60 100 m deep and used to compare with the drifter 15 m deep we selected the current meter that met the following criteria a long record since some moorings have been cut accidentally fixed at 60 100 m deep and located on a mooring with a contemporary drifter passage the shallowest current meter of the c 3 mooring see fig 1 was the only one to meet all the criteria as the mooring c3 was located near the passage path of the 1st selected drifter argos number 57306 and providing data at less than 100 m depth 2 5 mediterranean forecasting system mfs the mediterranean forecasting system is a coupled hydrodynamic from nemo v3 6 and wave provided by wavewatch iii model with data assimilation components implemented over the mediterranean basin in situ vertical profiles of temperature and salinity from xbt ctd argo floats are assimilated with satellite sea level anomaly along track data from jason 1 2 cryosat envisat altika the product quality assessment is done by comparing with quasi independent satellite and in situ observations the model spatial resolution is 1 16 and the product is computed on 72 unevenly spaced vertical levels the depths levels are unevenly spaced and the thickness varies from 3 m at the surface to 300 m at the bottom the first level depth is at 1 5 m while the deepest one is at 5000 m tonani et al 2008 the model outputs were used to evaluate the comparability between the current vector velocity fields at the current meter and the drifters depth as detailed in section 4 1 2 6 gliders gliders are a type of robotic underwater vehicle that perform saw tooth trajectories testor et al 2019 the movement of the internal weights allows the glider to change its buoyancy thus it dives or climbs in the water column moreover the lift generated by the wings moving through the water converts vertical force into forwarding motion in the context of the eye of the levantine experiment gliders were deployed south of cyprus in november and december 2010 targeting the cyprus warm core eddy the transects followed a butterfly pattern near the eratosthenes seamount extending to a maximum depth of 1000 m collecting seawater characteristics such as temperature and salinity hayes et al 2011 the water density sections and the depth averaged current data derived from these glider positions are used to estimate profiles of absolute geostrophic velocity perpendicular to their trajectories eriksen et al 2001 during the campaign six gliders were deployed off limassol towards the cyprus eddy from these gliders we used the geostrophic velocities from the named trieste 1 glider it was a coastal glider that dived at 200 m depth maximum and was circulating close to a drifter argos number 92060 the obtained velocities used for the comparison corresponded to the near surface absolute geostrophic velocities perpendicular to the glider track and averaged in the upper 20 m the glider sampled the upper 200 m and geostrophic shear was integrated to the surface from a low pass filtered density section where variability smaller than 15 km corresponding to unbalanced isopycnal displacement was removed by a moving average this approach was applied in numerous studies in the past see e g bosse and fer 2019 2 7 ocean color eddies are oceanic structures with high vorticity able to modify the seawater physical distribution properties thus affecting the distribution of marine phytoplankton communities mcgillicuddy jr 2016 previous high resolution chlorophyll images have shown that even small swirling and filamentary patterns of chlorophyll could be determined from satellite imagery therefore high resolution ocean color images could be an efficient tool for mesoscale features monitoring such as eddies their shape and location could be detected from chlorophyll a concentration images leading to a better understanding of these physical processes sarangi 2012 these chlorophyll a images detected the shape of an eddy trapping a contemporary drifter argos number 57307 modis aqua chlorophyll level 2 data at 1 km spatial resolution corresponding to the days of assimilation for comparison were acquired from gsfc nasa 3 assimilation algorithm the correction is based on a variational assimilation method described in issa et al 2016 observations of drifter s positions are available every δ t we denote the background surface velocity field by 1 u m b u b m δ t m 1 2 m where this field is two dimensional u m b u m b v m b and where m is the integer time index this field is corrected by matching observed drifter s positions with those predicted by an advection model the background velocity field u m b used is the sum of a geostrophic component provided by altimetry u m geos and an ageostrophic component accounting for the effect induced by the wind u m wind 2 u m b u m geos u m wind this wind induced velocity is computed by the equation of poulain et al 2009 for drifters that are attached with a drogue 3 u m w i n d 0 007 exp 27 i u m 10 where u m w i n d u m wind i v m wind is the drifter velocity due to the wind effect and u m 10 u m 10 i v m 10 represents the wind velocity at 10 m above the surface both are expressed as complex numbers the wind speed above the sea surface varies considerably at a very short time scale thus the wind induced velocity field contribution to the total velocity depends on the varying weathering conditions an incremental approach talagrand and courtier 1987 is used so that the minimization is done for the incremental corrections δ u invariant in time within the time window of size t w the objective function to be minimized is 4 j δ u i 1 n f m 1 t w δ t r i b u m b δ r i δ u r i m obs 2 α 1 δ u b 2 α 2 j k δ u 2 where n f is the number of drifters i is the index of the drifter and δ t is the sampling time of the observations r i m obs represents the observed position of drifter i at time m δ t the term r i b resp δ r i is the position of the drifter i estimated by an advection model calculated from the background field u m b resp from the incremental correction δ u the advection model consists of a numerical integration of the advection equation for example using an euler scheme the first term measures the misfit between the observations and the positions of drifters simulated considering the advection by the surface velocity field the second component requires the corrected field to stay close to the background velocity here the b norm is defined as ψ b 2 ψ t b 1 ψ where b is the error covariance matrix the error covariance matrix b is obtained using the diffusion filter method of weaver and courtier 2001 the choice of the length scale r of the correction that enters in the error covariance matrix can be done in the context of the sensitivity analyses the last component is a constraint on the geostrophic part of the velocity required to stay divergence free this term is added to ensure a physical correction avoiding artifacts especially near the coasts the weights α 1 and α 2 correspond to the confidence given to the respective terms of the cost function relative to the observation error term because the cost function is defined within a multiplicative constant it is safe to set a standard confidence of one to the observation error term assuming that each observation error is equal and de correlated from the other the relative confidence in the background α 1 and in the non divergent constraint α 2 cannot be objectively determined so they are determined empirically using sensitivity analyses see section 3 1 after the minimization we compute a corrected velocity field 5 u m corr u m b δ u because δ u is constant inside a time window and to obtain a smooth time dependent velocity field a sliding window t w of time shift σ is used to obtain smoother corrections in time a detailed description of the algorithm is found in issa et al 2016 3 1 sensitivity tests sensitivity tests allow to tune the following parameters of the algorithm the temporal size of the window t w the divergence coefficient α 2 and the length scale r of the correction that enters in the error covariance matrix in fig 10 we show the setup of the sensitivity experiment three drifters were circulating close to each other near the libyan coast two drifters shown in colors are assimilated to produce a corrected velocity field the resulting corrected velocity field is used to simulate the trajectory of the third independent drifter shown in black the metric used is the mean separation distance between the simulated and observed trajectories 6 d t 1 n w j 1 n w r j t r j o b s t 2 where n w is the number of windows used during the simulation temporal window sizes t w of 1 2 and 3 days were compared fig 2 reveals that a window size of 2 days maximally reduces distances the improvement reaches around 70 compared to the background 5 and 9 more when compared to t w of 1 and 3 days respectively to produce a smooth time dependent velocity we use a sliding window of time shift σ we opted for σ of half a day to have a smoother correction the other two parameters seem not to have a significant impact on the assimilation for example if the value of α 2 is changed from 5 1 0 6 to null the solution is modified by only around 0 7 for the length scale parameter varying r from 20 to 30 km improves the correction by around 3 only consequently in the further experiments we apply the algorithm with the following parameters t w 2 days σ half day α 2 5 1 0 6 and r 30 km 4 validation method 4 1 current meter on the 1st of june 2006 the 1st selected drifter ogs drifter identification number 3627 circulated near the c 3 mooring at a distance shorter than 30 km this passage allows us to apply the algorithm to the area containing c 3 the drifter trajectory is assimilated starting from this day denoted by d 0 the experiment extends until the 14th of june d 13 the current meter was fluctuating around 73 m deep during the drifter passage as is revealed by its pressure reading on the other hand drifters track the current at 15 m to assess the validity of the comparison with these two different depths we computed the temporal variation of the velocity field intensity and angle at both depths using the products derived from the mediterranean forecasting system the variation of the intensity and direction of the current in the year 2006 is presented in fig 3 at 15 m and 74 m depth it includes the days of the experiments dating from the 1st and the 14th of june the jumps in the direction from mid june until mid july are due to the periodic definition of the direction during the experiment the difference between the velocities at the two depths is 0 033 m s on average with a standard deviation of 0 074 m s the difference in the direction is 0 3 on average with a standard deviation of 37 these differences are small compared with the natural variability of the signal standard deviation of 0 23 m s for the velocity and 97 for the angle moreover there is a high correlation existing between both levels with a correlation of 0 93 for the direction and 0 86 for the intensity it should be mentioned that the mixed layer was not deep enough to include the current meter 70 m depth so the comparison between the drifter and the current meter underneath could induce a bias however as discussed above the mfs results show the currents at the two different depths agree well in terms of direction and intensity during the time of the experiment thus the current meter measurements at 73 m depth can still be used to validate the corrected surface velocity estimated at 15 m depth let us denote the current meter velocity by u m ref and use u m for the fields associated with the assimilation experiment either the background or the corrected one the zonal and meridional components are u m ref u m ref v m ref and u m u m v m similarly we use θ ref for the current meter velocity angle variation and θ for either the background or the corrected velocities for an overall quantification of the assimilation impact we calculated the l 2 norm error between u m ref and u m velocity fields 7 e m u m ref u m 2 v m ref v m 2 low values of e m 2 reveal a similarity in both intensity and direction between the compared vectors 4 2 comparison with glider a drifter from the nemed project was circulating close to a glider providing geostrophic velocities perpendicular to its trajectories we use the glider derived velocities u m ref averaged between 0 and 20 m as observations to be compared with the experimented velocity fields u m the experimented velocities are interpolated and orthogonally projected to the glider trajectory as explained in the data section to assess the assimilation efficiency we compute the average error e a between the projected experimented velocities and the glider derived velocities 8 e a 1 m g m 1 m m g u m u m r e f m 1 m m g u m r e f 100 where m g represents the total glider positions used for comparison u m the norm of the background and assimilated projected velocities at each glider position and u m r e f represents the glider derived velocities norm at each position 4 3 comparison with ocean color data a drifter that was circulating in a high vorticity area is assimilated from the 1st of february 2006 until 28th of june 2006 the mesoscale structure trapping the drifter was also well defined in terms of shape and location by a contemporary chlorophyll image a visual observation of the eddy is possible by drawing the streamlines resulting from the background and assimilated velocity fields so the eddy shape could be represented by the flow lines of the resulting velocity fields a better agreement with the eddy as observed from the chlorophyll image is expected after correction in terms of shape and location 5 results in this section we show all the results of the comparisons from the background the corrected velocity field and the independent current measurements derived from different sources current meter glider ocean color drifters 5 1 comparison with current meter the first comparison focused on the area off the libyo egyptian coast see fig 1 in the period between the 1 st d0 and the 14th d13 of june 2006 the drifter 57306 argos number that collects data close to and concurrently to the c3 current meter is selected for the assimilation fig 4c shows the temporal variation of the current direction as recorded by c 3 this change in the angle current direction of c 3 was then compared to the variations of the background and corrected velocity fields significant improvements are seen starting from d 0 until d 12 during this period the direction of the corrected velocity is close to the one measured by c 3 furthermore the improvement in direction reaches more than 40 degrees after correction especially between d 2 and d 8 a significant shift in the current direction is detected between d 0 and d 2 varying from 60 to 140 degrees within only a few hours during these dates this adjustment corresponds to the time when the drifter gets closer to c 3 from 40 to 30 km see fig 4a fig 4b confirms the previous results and demonstrates how the assimilation reduces the overall l 2 error this error is reduced after correction starting from d 0 during d 4 and d 5 the largest improvement from the background is observed in fact the amplitude of the corrections depends on two main factors the initial error of the background and the distance between the drifter and the point of interest here the c 3 location the difference between the background and the corrected velocity field increases with decreasing distances when the drifter gets far away again 30 km the impact of the assimilation diminishes progressively excluding the ageostrophic component from the background during the assimilation does not have a significant impact on the resulting corrected velocity field as fig 4b shows adding the wind component to the background velocity slightly reduces the overall l 2 error between the corrected and current meter velocity fields during the experiment the wind forcing was oriented towards the south southeast and had an average speed of 7 m s the average velocity field during the days of the experiments from d 0 until d 12 is presented in fig 5 after the drifter passage the resulting assimilated velocity vectors red vectors are modified in a way that is consistent with the mean field recorded by the current meter dark vector fig 6 shows the daily average velocity field on the 4 t h d 3 6 t h d 5 8 t h d 7 1 2 t h d 11 of june 2006 on d 3 when the circulating drifter is still far from the current meter location the corrected velocity field near c 3 is close to the background both velocity fields are different from the current meter the average current as recorded by c 3 is oriented to the north northwest while both velocity fields are oriented north northeast in d 5 when the drifter gets closer to c 3 an important shift of the corrected velocity field vectors is noticed the agreement between the c 3 and the corrected current vectors improves up to the best match on d 7 in d 11 when the drifter becomes distant there is no more impact of the correction on the velocity field around c 3 as a result the background and the assimilated velocity fields are again similar 5 2 comparison with glider we targeted a drifter from the surface circulation in the northeastern mediterranean nemed project releasing drifters between cyprus and the middle east from summer 2009 to spring 2010 fig 7a shows that starting from december 3rd the glider deployment date and until the 21st of december 2006 there was a drifter circulating near the deployment location in the south of cyprus although they were many intersections between the glider and drifter trajectories most of these intersections occurred at different times only between the 10th and 11th of december 2009 the trieste 1 glider circulated at a distance less than 30 km with the drifter 92060 see red square we assimilate the latter and obtain corrected velocities around the glider location the glider surfaces approximately every hour with three observations starting from 7 pm on the 10th and seventeen observations on the 11th that is a total of twenty observations during these two days fig 7b the background and the assimilated velocity fields are then interpolated at these glider positions p because the derived geostrophic velocities are perpendicular to the glider trajectory the interpolated background and assimilation are orthogonally projected onto the glider trajectory in fig 7c we show the background and corrected fields together with the velocity computed using the glider data it can be seen that the projected velocity norm shows how the background tends to underestimate the intensity with a maximum value reaching 0 08 m s after correction the resulting velocity norm increases when we compare it with the glider results around 0 14 m s the corrected values are closer 0 12 m s than the background values 0 08 m s the overall error e a has been reduced by more than 20 by the assimilation this improvement is important despite two factors that could tend to penalize the assimilation first the different time scale of observation where the sampling time of the gliders is hourly while the sampling frequency of the drifter is every six hours the second factor is the distance between the assimilated drifter and the observed glider positions p the distance between the nearest sample drifter position and p1 is more than 25 km this distance increases continuously and reduces the correction impact 5 3 comparison with high resolution ocean color images we targeted a drifter argos number 57307 that was released in 20 85 e 33 055 n from the 1st of february 2006 until 28th of june 2006 this drifter was stuck in one of the highly active eddies off the egyptian coasts see fig 8 for several weeks starting may 17 2006 a contemporary chlorophyll image was available during this period specifically on may 20 showing the eddy shape and location the assimilation experiment was done for 6 days starting from the 17th of may the streamlines of the velocity fields before and after correction were compared with the simultaneous chlorophyll a concentration image in fig 9 the observed streamlines of the velocity field after correction red are close to the chlorophyll a image in terms of shape and location while the background velocity field presents a shift in location and difference in size the latter reveals an extension of the eddy towards the southeast 5 4 reconstruction of independent drifter trajectory as explained in section 3 1 we used three drifters trapped in the anticyclone noted le1 off libya see figs 2 and 5 in gerin et al 2009 see also fig 1 in sutyrin et al 2009 between the 8th and the 27th of may 2006 we assimilated the positions of the argo numbers 59777 and 59774 to simulate the position evolution of the third one 57312 based on the surrounding velocity field see fig 10 the prediction of the future drifter positions after correcting the velocity field is closer to the real trajectory during the 20 days of the experiment as shown in fig 11 predicted positions after correction in red reveal trends that are similar to the real ones on the other hand predictions based on the background velocities differ from the real observations as they do not show circular patterns the lower panel presents the evolution in time of the distance d t as in eq 6 between the observed position and the simulated position of the independent drifter before and after correction the simulated drifter position is reinitialized every 2 days to the position of the real drifter the distance is computed for each of these 2 days windows t w and then averaged to produce the average position error in time fig 11 shows a decrease of this error after the correction the distance between the expected and the real observation reaches around 40 km using the background velocities the assimilation reduces these distances to less than 9 km moreover the correction lowers the uncertainties standard deviation of the error over each of the 10 windows as compared to those of the background see fig 11 the standard deviation of the background distances increases continuously with time reaching more than 19 km at the end of the window after two days after correction these variations are significantly reduced and barely increase with time and do not exceed 3 7 km in other words on average the assimilation allows us to reduce the error from 40 to less than 9 km after two days when simulating the positions of independent drifter not included in the assimilation 6 perspectives when in situ drifters data are available the assimilation could be applied on a larger spatio temporal scale from all the 97 drifters of the egypt egitto campaign 29 drifters covering the area between the libyo egyptian coasts and crete between 21 to 31 e and 30 to 36 n in 2006 have been assimilated in general altimetry strongly underestimates the mean kinetic energy mke and eddy kinetic energy eke of the velocity field pujol and larnicol 2005 gerin et al 2009 poulain et al 2012 so we expect the assimilation to improve those estimates obtained from altimetry fig 12 reveals that the mke increases after assimilation especially when targeting a main regional mesoscale feature such as ierapetra eddy ie amitai et al 2010 ioannou et al 2017 after correction the mke in ie is more than 700 cm 2 s 2 on all sides with a maximum of 760 cm 2 s 2 for the background mke reaches a maximum of 630 cm 2 s 2 but only locally the eastern and the western sides of the eddy have low values of mke as they do not exceed 350 cm 2 s 2 moreover eke see fig 13 reveals a higher variability after assimilation especially in the ierapetra area and near the libyan coast after assimilation all sides of the ie structure reach more than 500 cm 2 s 2 with a maximum of 1100 cm 2 s 2 for the background values over 500 cm 2 s 2 are limited to the southern part of ie with a maximum of 860 cm 2 s 2 the differences in mke and eke reveal that the algorithm can help in revising the quantification of surface velocity features mainly in the ierapetra area and off the libyan coast where intense mesoscale features are found permanently a further detailed study of these areas based on this method could help investigate some oceanographic questions that are unclear especially off libya where the libyo egyptian current generates instabilities and thus a very high variability which paves the way to differing interpretations 7 conclusion this paper has extended the application and objectively validated the assimilation algorithm developed in issa et al 2016 when compared with in situ contemporary current meter data located in the assimilated area the modified velocity field is in better agreement with the current meter records significant improvements are seen when the assimilated drifter reaches a distance less than 30 km from the current meter location this spatial extension of correction is larger than the internal rossby radius in the mediterranean that is on the order of 10 14 km robinson et al 2001 we have shown that the corrected velocity field is closer to current meter data in both direction and intensity the application of the assimilation in high vorticity areas gives more realistic results than the altimetric product after assimilating drifter positions trapped in an eddy detected at the same time from high resolution chlorophyll images the resulting streamlines from the corrected velocity field are consistent with the eddy shape and location as shown by the ocean color image to quantify the assimilation efficiency we showed that the error between the real and simulated drifter positions decreases after assimilation from 40 km without assimilation to less than 10 km with assimilation after two days also the correction reduces the uncertainties during all the experiments further to the east gliders from the eye of the levantine campaign deployed in the south of cyprus were used for further validation the resulting perpendicular velocity norm has values closer to the glider derived velocities after assimilation despite the difference in the sampling time scale and the considerable distances the assimilation was able to reduce the error by more than 20 the results obtained pave the way for further investigations and larger spatio temporal applications in the eastern mediterranean where many drifter positions are available this application can provide a precise and detailed description improving the understanding of the mesoscale and sub mesoscale activity credit authorship contribution statement georges baaklini writing original draft software formal analysis visualization leila issa conceptualization methodology writing review editing project administration validation supervision milad fakhri funding acquisition writing review editing supervision julien brajard conceptualization methodology writing review editing project administration validation supervision gina fifani software writing review milena menna writing review editing resources isabelle taupier letage writing review editing resources anthony bosse writing review editing resources laurent mortier conceptualization funding acquisition writing review editing validation supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to acknowledge the national council for scientific research of lebanon cnrs l for granting a doctoral fellowship to georges baaklini this work was partially funded by the altilev program in the framework of the phc cedre project we would like to thank professor alexandre stegner cnrs for helping in data interpretation drifters data were provided from doi data 10 6092 7a8499bc c5ee 472c b8b5 03523d1e73e9 we thank pierre marie poulain cmre for his contribution in providing the drifters data egypt egitto eddies and gyres paths tracking program received funding from cnrs insu lefe idao and mercator programs glider data are available on http www ifremer fr co ego ego v2 trieste 1 trieste 1 20091124 they were collected and made freely available by the coriolis project and programmes that contribute to it http www coriolis eu org the altimeter products were produced by ssalto duacs and distributed by aviso with support from cnes http www aviso altimetry fr duacs the drifter data are distributed by ogs http nodc ogs trieste it chlorophyll image was provided by nasa goddard space flight center ocean ecology laboratory ocean biology processing group moderate resolution imaging spectroradiometer modis aqua chlorophyll data 2018 reprocessing nasa ob daac greenbelt md usa doi data 10 5067 aqua modis l3b chl 2018 the mio has received funding from european feder fund under project 1166 39417 bathymetry data are provided by gebco compilation group 2020 gebco 2020 grid doi 10 5285 a29c5465 b138 234d e053 6c86abc040b9 appendix if u and v are the zonal and meridional velocities respectively the mean kinetic energy mke cm 2 s 2 is computed m k e 1 2 u 2 v 2 where is the time averaging of the component in a given bin the eddy kinetic energy eke is e k e 1 2 u u v v u u and v v are the variances in the zonal and meridional directions respectively 
23889,an improved estimation of the surface currents in the levantine basin of the mediterranean sea is crucial for a wide range of applications including pollutants transport and nutrients distribution this estimation remains challenging due to the scarcity or shortcomings of various data types used for this purpose in this paper we present an objective validation of a variational assimilation algorithm that blends geostrophic velocities derived from altimetry wind induced velocities and drifter positions to continuously obtain velocity corrections the assessment of the validation impact was based on available independent in situ data current meters gliders and independent drifters and satellite ocean color images in all cases the improvement was shown either qualitatively position of the eddies or quantitatively keywords altimetry lagrangian data data assimilation drifters surface velocity field levantine mediterranean 1 introduction the surface circulation in the southern part of the mediterranean sea along the north african coasts is characterized by the presence of unstable currents that generate mesoscale eddies see e g robinson et al 1992 millot and taupier letage 2005 amitai et al 2010 and schroeder et al 2012 these eddies have diameters of 10 100 km and lifetimes that can span several months to years see e g puillat et al 2002 hamad et al 2006 mkhinini et al 2014 and pessini et al 2020 mesoscale activity in the eastern mediterranean is intense with high eddy kinetic energy more than 700 cm 2 s 2 recorded historically see e g robinson et al 1992 pujol and larnicol 2005 and gerin et al 2009 mesoscale eddies can interact split or merge and induce smaller scale structures shear eddies and filaments thus tracking them is a real challenge see e g taupier letage et al 2003 d ovidio et al 2004 laxenaire et al 2018 and le vu et al 2018 all these structures can transport coastal waters trap and advect on large distances tracer anomalies such activity has a continuous and direct impact on biogeochemical water properties especially in the redistribution of nutrient rich coastal waters into the oligotrophic open sea see e g taupier letage et al 2003 lehahn et al 2007 levy and martin 2013 and escudier et al 2016 and the dispersion of pollutants an accurate and continuous estimation of surface circulation is therefore needed but remains challenging even though more and more data in particular operational products from the copernicus marine service marine copernicus eu are available for estimating surface currents at sub mesoscale each on their own have their limitations a powerful tool that is widely used to describe the mesoscale features of surface circulation is the state of the art satellite altimetry multi mission gridded altimeter products originated from copernicus marine service have the advantage of providing uninterrupted and continuous global surface velocities caballero et al 2013 nevertheless there are still uncertainties associated with these products relative low spatial resolution of current radar altimetry satellite information is degraded near the coastal areas within 20 50 km from land cipollini et al 2010 incorrect removal of high frequency atmospheric effects that exist at the sea surface caballero et al 2013 mean dynamic topography mdt is not always precisely known in the basin moreover the problem accentuates in the mediterranean sea where a precise knowledge of mdt is still an issue due to the presence of narrow straits and a high number of islands and the small rossby radius of deformation of around 10 km that makes the altimeter resolution insufficient to capture the small details rio et al 2014 due to the coarse resolution in both space and time of the altimeters and to the fact that mesoscale structures move continuously eddies can be missed artificially created smoothed or misplaced mkhinini et al 2014 ioannou et al 2017 characterizing eddies using altimetry can lead to an underestimation of the eddies density especially the small ones these eddies may be not captured by altimetry or tend to be aliased into larger structures compared to the true eddies amores et al 2018 in situ observations are used as a tool to complement and or validate altimetry le traon and hernandez 1992 drifters have the advantage of being autonomous and relatively inexpensive they are in situ lagrangian tools following the ocean current once they are released and adequately equipped with a drogue poulain et al 2012 characterized by positive buoyancy this restrains them along with the two dimensional flow at the surface or near surface of the ocean even though they help in providing a precise description of the surface circulation their spatio temporal distribution is not continuous because they are typically short lived and their spatial distribution is intrinsically uneven when large data sets are available combining altimetric and drifter data can be done using statistical approaches see e g niiler 2003 uchida and imawaki 2003 poulain et al 2009 maximenko et al 2009 poulain et al 2012 menna et al 2012 and stanichny et al 2016 alternatively data can be assimilated in a variational approach in which corrections of the velocity are obtained by minimizing an objective function measuring the difference between observations and their corresponding model variables variational methods that take into account the temporal variation within the optimization are called 4d var kamachi and o brien 1995 mead 2005 nodet 2006 carrier et al 2014 muscarella et al 2015 a more detailed review of various assimilation methodologies can be found in issa et al 2016 from the application point of view merging altimetry and in situ data for a better estimation of the sea surface circulation has previously had several successful applications for example in the gulf of mexico carrier et al 2014 muscarella et al 2015 berta et al 2015 the black sea kubryakov and stanichny 2011 stanichny et al 2016 the north pacific uchida and imawaki 2003 and the mediterranean sea taillandier et al 2006 menna et al 2012 issa et al 2016 each of them using different methodologies for merging validating these merged data sets using in situ current meter data was done in taillandier et al 2006 where the comparison focused on the net transport time series representing the total volume flux over a selected area referring to long term current meter measurements available across the corsica channel the assimilation showed a 10 increase of the estimated net transport leading to instantaneous transport values that are closer to those observed by the current meter the variational assimilation algorithm used by issa et al 2016 proved its efficiency in the eastern levantine mediterranean region specifically along the lebanese coast and in the region between lebanon and cyprus sensitivity analyses showed that the velocity estimation can be improved significantly even with only a small number of drifters the algorithm that was developed relies on continuously correcting the altimetry derived velocity by matching the observed drifters positions with those predicted by an advection model taking into account the wind effect and imposing a divergence free condition on the correction the algorithm needed very few computational resources and converged quickly the contribution of the current work is two fold i a further extension of the application of the previous algorithm by issa et al 2016 in the levantine mediterranean and ii an objective validation of the algorithm using reliable tools data independent of the algorithm itself in particular we use four different types of independent data first a current meter moored off libya is used to validate the algorithm results in terms of velocity intensity and direction second a glider derived near surface absolute geostrophic velocity perpendicular to its trajectory is compared with the projected velocities obtained after assimilation third we reproduce the path of a non assimilated drifter by the simulation of its position using velocities obtained by the assimilation of two other drifters finally we compare streamlines of the corrected velocity field with the shape of an eddy obtained by an ocean color satellite image this offers a qualitative but useful comparison except for products from copernicus operational forecast models or reanalysis we believe that no other surface current data are available in the levantine region for such a comparison the paper is structured as follows we introduce the data used in the assimilation and validation in section 2 in section 3 we provide a brief recap of the algorithm used for the assimilation as well as the sensitivity test done to optimally choose the parameters in section 4 we present the metrics used for validation finally in section 5 we show the results of the assimilation experiments as compared with in situ current meter data ocean color satellite images gliders we also show the results of the independent drifters experiment 2 data the study focuses on the eastern part of the mediterranean that is less investigated than its western counterpart more specifically on the levantine basin the data used for this study are listed in sections 2 1 2 7 2 1 drifters data the egypt egitto program eddies and gyres paths tracking taupier letage et al 2007 focused on the eastern mediterranean southern part spanning the period 2005 2007 it provided an extensive deployment of satellite tracked drifters which helps in characterizing mesoscale and sub mesoscale structures see the 2 years trajectories animation on southeastern mediterranean surface drifter database nettuno ogs trieste it doga sire egitto database egitto movies sep05 oct07 avi these drifters were tracked by the global argos system their time series were interpolated at 0 5 h poulain et al 2013 data were then low pass filtered using a hamming filter with a cut off period at 36 h to eliminate high frequency current components tidal and inertial currents in addition to those we used drifters from the surface circulation in the northeastern mediterranean nemed project from 2009 to 2010 nemed is an observational program releasing drifters between cyprus and the middle east drifters time series were interpolated at 6 h from this large drifters data set 97 drifters from egypt egitto and 31 drifters from nemed menna et al 2018 we selected drifters depending on each validation experiment all drifters used in the assimilation are equipped with a positioned drogue located at 15 m depth which reduces the wind forcing impact 2 2 altimetry data geostrophic surface velocity fields are processed by the duacs data unification and altimeter combination system multi mission altimeter data processing system and distributed by e u copernicus marine service information cmems the sla computation provides the absolute dynamic topography adt and geostrophic currents the gridded products are estimated by an optimal interpolation that merges measurements from several altimeter missions hy 2 a jason 2 jason 1 t p envisat gfo ers1 2 the interpolation provides a consistent and homogeneous database data were daily mapped at a resolution of 1 8 2 3 wind data six hourly wind data were obtained from ecmwf era interim products dee et al 2011 at 10 m above the surface data was re sampled on a half an hour time step the product spatial resolution is approximately 0 7 degrees wind velocities were interpolated at a resolution of 1 8 at the same grid point as the aviso background data although the actual resolution is much coarser 2 4 current meter the first comparison focused on the area of the libyo egyptian coast where the anticyclonic eddies generated by the libyo egyptian current move offshore hamad et al 2006 between april 2006 and april 2007 7 moorings each equipped with current meters were deployed off libya during the egypt egitto program taupier letage et al 2007 to provide information on the circulation of the water masses however since only sub surface moorings could be used because of safety issues the surface layer of atlantic water was sampled at 60 100 m deep and used to compare with the drifter 15 m deep we selected the current meter that met the following criteria a long record since some moorings have been cut accidentally fixed at 60 100 m deep and located on a mooring with a contemporary drifter passage the shallowest current meter of the c 3 mooring see fig 1 was the only one to meet all the criteria as the mooring c3 was located near the passage path of the 1st selected drifter argos number 57306 and providing data at less than 100 m depth 2 5 mediterranean forecasting system mfs the mediterranean forecasting system is a coupled hydrodynamic from nemo v3 6 and wave provided by wavewatch iii model with data assimilation components implemented over the mediterranean basin in situ vertical profiles of temperature and salinity from xbt ctd argo floats are assimilated with satellite sea level anomaly along track data from jason 1 2 cryosat envisat altika the product quality assessment is done by comparing with quasi independent satellite and in situ observations the model spatial resolution is 1 16 and the product is computed on 72 unevenly spaced vertical levels the depths levels are unevenly spaced and the thickness varies from 3 m at the surface to 300 m at the bottom the first level depth is at 1 5 m while the deepest one is at 5000 m tonani et al 2008 the model outputs were used to evaluate the comparability between the current vector velocity fields at the current meter and the drifters depth as detailed in section 4 1 2 6 gliders gliders are a type of robotic underwater vehicle that perform saw tooth trajectories testor et al 2019 the movement of the internal weights allows the glider to change its buoyancy thus it dives or climbs in the water column moreover the lift generated by the wings moving through the water converts vertical force into forwarding motion in the context of the eye of the levantine experiment gliders were deployed south of cyprus in november and december 2010 targeting the cyprus warm core eddy the transects followed a butterfly pattern near the eratosthenes seamount extending to a maximum depth of 1000 m collecting seawater characteristics such as temperature and salinity hayes et al 2011 the water density sections and the depth averaged current data derived from these glider positions are used to estimate profiles of absolute geostrophic velocity perpendicular to their trajectories eriksen et al 2001 during the campaign six gliders were deployed off limassol towards the cyprus eddy from these gliders we used the geostrophic velocities from the named trieste 1 glider it was a coastal glider that dived at 200 m depth maximum and was circulating close to a drifter argos number 92060 the obtained velocities used for the comparison corresponded to the near surface absolute geostrophic velocities perpendicular to the glider track and averaged in the upper 20 m the glider sampled the upper 200 m and geostrophic shear was integrated to the surface from a low pass filtered density section where variability smaller than 15 km corresponding to unbalanced isopycnal displacement was removed by a moving average this approach was applied in numerous studies in the past see e g bosse and fer 2019 2 7 ocean color eddies are oceanic structures with high vorticity able to modify the seawater physical distribution properties thus affecting the distribution of marine phytoplankton communities mcgillicuddy jr 2016 previous high resolution chlorophyll images have shown that even small swirling and filamentary patterns of chlorophyll could be determined from satellite imagery therefore high resolution ocean color images could be an efficient tool for mesoscale features monitoring such as eddies their shape and location could be detected from chlorophyll a concentration images leading to a better understanding of these physical processes sarangi 2012 these chlorophyll a images detected the shape of an eddy trapping a contemporary drifter argos number 57307 modis aqua chlorophyll level 2 data at 1 km spatial resolution corresponding to the days of assimilation for comparison were acquired from gsfc nasa 3 assimilation algorithm the correction is based on a variational assimilation method described in issa et al 2016 observations of drifter s positions are available every δ t we denote the background surface velocity field by 1 u m b u b m δ t m 1 2 m where this field is two dimensional u m b u m b v m b and where m is the integer time index this field is corrected by matching observed drifter s positions with those predicted by an advection model the background velocity field u m b used is the sum of a geostrophic component provided by altimetry u m geos and an ageostrophic component accounting for the effect induced by the wind u m wind 2 u m b u m geos u m wind this wind induced velocity is computed by the equation of poulain et al 2009 for drifters that are attached with a drogue 3 u m w i n d 0 007 exp 27 i u m 10 where u m w i n d u m wind i v m wind is the drifter velocity due to the wind effect and u m 10 u m 10 i v m 10 represents the wind velocity at 10 m above the surface both are expressed as complex numbers the wind speed above the sea surface varies considerably at a very short time scale thus the wind induced velocity field contribution to the total velocity depends on the varying weathering conditions an incremental approach talagrand and courtier 1987 is used so that the minimization is done for the incremental corrections δ u invariant in time within the time window of size t w the objective function to be minimized is 4 j δ u i 1 n f m 1 t w δ t r i b u m b δ r i δ u r i m obs 2 α 1 δ u b 2 α 2 j k δ u 2 where n f is the number of drifters i is the index of the drifter and δ t is the sampling time of the observations r i m obs represents the observed position of drifter i at time m δ t the term r i b resp δ r i is the position of the drifter i estimated by an advection model calculated from the background field u m b resp from the incremental correction δ u the advection model consists of a numerical integration of the advection equation for example using an euler scheme the first term measures the misfit between the observations and the positions of drifters simulated considering the advection by the surface velocity field the second component requires the corrected field to stay close to the background velocity here the b norm is defined as ψ b 2 ψ t b 1 ψ where b is the error covariance matrix the error covariance matrix b is obtained using the diffusion filter method of weaver and courtier 2001 the choice of the length scale r of the correction that enters in the error covariance matrix can be done in the context of the sensitivity analyses the last component is a constraint on the geostrophic part of the velocity required to stay divergence free this term is added to ensure a physical correction avoiding artifacts especially near the coasts the weights α 1 and α 2 correspond to the confidence given to the respective terms of the cost function relative to the observation error term because the cost function is defined within a multiplicative constant it is safe to set a standard confidence of one to the observation error term assuming that each observation error is equal and de correlated from the other the relative confidence in the background α 1 and in the non divergent constraint α 2 cannot be objectively determined so they are determined empirically using sensitivity analyses see section 3 1 after the minimization we compute a corrected velocity field 5 u m corr u m b δ u because δ u is constant inside a time window and to obtain a smooth time dependent velocity field a sliding window t w of time shift σ is used to obtain smoother corrections in time a detailed description of the algorithm is found in issa et al 2016 3 1 sensitivity tests sensitivity tests allow to tune the following parameters of the algorithm the temporal size of the window t w the divergence coefficient α 2 and the length scale r of the correction that enters in the error covariance matrix in fig 10 we show the setup of the sensitivity experiment three drifters were circulating close to each other near the libyan coast two drifters shown in colors are assimilated to produce a corrected velocity field the resulting corrected velocity field is used to simulate the trajectory of the third independent drifter shown in black the metric used is the mean separation distance between the simulated and observed trajectories 6 d t 1 n w j 1 n w r j t r j o b s t 2 where n w is the number of windows used during the simulation temporal window sizes t w of 1 2 and 3 days were compared fig 2 reveals that a window size of 2 days maximally reduces distances the improvement reaches around 70 compared to the background 5 and 9 more when compared to t w of 1 and 3 days respectively to produce a smooth time dependent velocity we use a sliding window of time shift σ we opted for σ of half a day to have a smoother correction the other two parameters seem not to have a significant impact on the assimilation for example if the value of α 2 is changed from 5 1 0 6 to null the solution is modified by only around 0 7 for the length scale parameter varying r from 20 to 30 km improves the correction by around 3 only consequently in the further experiments we apply the algorithm with the following parameters t w 2 days σ half day α 2 5 1 0 6 and r 30 km 4 validation method 4 1 current meter on the 1st of june 2006 the 1st selected drifter ogs drifter identification number 3627 circulated near the c 3 mooring at a distance shorter than 30 km this passage allows us to apply the algorithm to the area containing c 3 the drifter trajectory is assimilated starting from this day denoted by d 0 the experiment extends until the 14th of june d 13 the current meter was fluctuating around 73 m deep during the drifter passage as is revealed by its pressure reading on the other hand drifters track the current at 15 m to assess the validity of the comparison with these two different depths we computed the temporal variation of the velocity field intensity and angle at both depths using the products derived from the mediterranean forecasting system the variation of the intensity and direction of the current in the year 2006 is presented in fig 3 at 15 m and 74 m depth it includes the days of the experiments dating from the 1st and the 14th of june the jumps in the direction from mid june until mid july are due to the periodic definition of the direction during the experiment the difference between the velocities at the two depths is 0 033 m s on average with a standard deviation of 0 074 m s the difference in the direction is 0 3 on average with a standard deviation of 37 these differences are small compared with the natural variability of the signal standard deviation of 0 23 m s for the velocity and 97 for the angle moreover there is a high correlation existing between both levels with a correlation of 0 93 for the direction and 0 86 for the intensity it should be mentioned that the mixed layer was not deep enough to include the current meter 70 m depth so the comparison between the drifter and the current meter underneath could induce a bias however as discussed above the mfs results show the currents at the two different depths agree well in terms of direction and intensity during the time of the experiment thus the current meter measurements at 73 m depth can still be used to validate the corrected surface velocity estimated at 15 m depth let us denote the current meter velocity by u m ref and use u m for the fields associated with the assimilation experiment either the background or the corrected one the zonal and meridional components are u m ref u m ref v m ref and u m u m v m similarly we use θ ref for the current meter velocity angle variation and θ for either the background or the corrected velocities for an overall quantification of the assimilation impact we calculated the l 2 norm error between u m ref and u m velocity fields 7 e m u m ref u m 2 v m ref v m 2 low values of e m 2 reveal a similarity in both intensity and direction between the compared vectors 4 2 comparison with glider a drifter from the nemed project was circulating close to a glider providing geostrophic velocities perpendicular to its trajectories we use the glider derived velocities u m ref averaged between 0 and 20 m as observations to be compared with the experimented velocity fields u m the experimented velocities are interpolated and orthogonally projected to the glider trajectory as explained in the data section to assess the assimilation efficiency we compute the average error e a between the projected experimented velocities and the glider derived velocities 8 e a 1 m g m 1 m m g u m u m r e f m 1 m m g u m r e f 100 where m g represents the total glider positions used for comparison u m the norm of the background and assimilated projected velocities at each glider position and u m r e f represents the glider derived velocities norm at each position 4 3 comparison with ocean color data a drifter that was circulating in a high vorticity area is assimilated from the 1st of february 2006 until 28th of june 2006 the mesoscale structure trapping the drifter was also well defined in terms of shape and location by a contemporary chlorophyll image a visual observation of the eddy is possible by drawing the streamlines resulting from the background and assimilated velocity fields so the eddy shape could be represented by the flow lines of the resulting velocity fields a better agreement with the eddy as observed from the chlorophyll image is expected after correction in terms of shape and location 5 results in this section we show all the results of the comparisons from the background the corrected velocity field and the independent current measurements derived from different sources current meter glider ocean color drifters 5 1 comparison with current meter the first comparison focused on the area off the libyo egyptian coast see fig 1 in the period between the 1 st d0 and the 14th d13 of june 2006 the drifter 57306 argos number that collects data close to and concurrently to the c3 current meter is selected for the assimilation fig 4c shows the temporal variation of the current direction as recorded by c 3 this change in the angle current direction of c 3 was then compared to the variations of the background and corrected velocity fields significant improvements are seen starting from d 0 until d 12 during this period the direction of the corrected velocity is close to the one measured by c 3 furthermore the improvement in direction reaches more than 40 degrees after correction especially between d 2 and d 8 a significant shift in the current direction is detected between d 0 and d 2 varying from 60 to 140 degrees within only a few hours during these dates this adjustment corresponds to the time when the drifter gets closer to c 3 from 40 to 30 km see fig 4a fig 4b confirms the previous results and demonstrates how the assimilation reduces the overall l 2 error this error is reduced after correction starting from d 0 during d 4 and d 5 the largest improvement from the background is observed in fact the amplitude of the corrections depends on two main factors the initial error of the background and the distance between the drifter and the point of interest here the c 3 location the difference between the background and the corrected velocity field increases with decreasing distances when the drifter gets far away again 30 km the impact of the assimilation diminishes progressively excluding the ageostrophic component from the background during the assimilation does not have a significant impact on the resulting corrected velocity field as fig 4b shows adding the wind component to the background velocity slightly reduces the overall l 2 error between the corrected and current meter velocity fields during the experiment the wind forcing was oriented towards the south southeast and had an average speed of 7 m s the average velocity field during the days of the experiments from d 0 until d 12 is presented in fig 5 after the drifter passage the resulting assimilated velocity vectors red vectors are modified in a way that is consistent with the mean field recorded by the current meter dark vector fig 6 shows the daily average velocity field on the 4 t h d 3 6 t h d 5 8 t h d 7 1 2 t h d 11 of june 2006 on d 3 when the circulating drifter is still far from the current meter location the corrected velocity field near c 3 is close to the background both velocity fields are different from the current meter the average current as recorded by c 3 is oriented to the north northwest while both velocity fields are oriented north northeast in d 5 when the drifter gets closer to c 3 an important shift of the corrected velocity field vectors is noticed the agreement between the c 3 and the corrected current vectors improves up to the best match on d 7 in d 11 when the drifter becomes distant there is no more impact of the correction on the velocity field around c 3 as a result the background and the assimilated velocity fields are again similar 5 2 comparison with glider we targeted a drifter from the surface circulation in the northeastern mediterranean nemed project releasing drifters between cyprus and the middle east from summer 2009 to spring 2010 fig 7a shows that starting from december 3rd the glider deployment date and until the 21st of december 2006 there was a drifter circulating near the deployment location in the south of cyprus although they were many intersections between the glider and drifter trajectories most of these intersections occurred at different times only between the 10th and 11th of december 2009 the trieste 1 glider circulated at a distance less than 30 km with the drifter 92060 see red square we assimilate the latter and obtain corrected velocities around the glider location the glider surfaces approximately every hour with three observations starting from 7 pm on the 10th and seventeen observations on the 11th that is a total of twenty observations during these two days fig 7b the background and the assimilated velocity fields are then interpolated at these glider positions p because the derived geostrophic velocities are perpendicular to the glider trajectory the interpolated background and assimilation are orthogonally projected onto the glider trajectory in fig 7c we show the background and corrected fields together with the velocity computed using the glider data it can be seen that the projected velocity norm shows how the background tends to underestimate the intensity with a maximum value reaching 0 08 m s after correction the resulting velocity norm increases when we compare it with the glider results around 0 14 m s the corrected values are closer 0 12 m s than the background values 0 08 m s the overall error e a has been reduced by more than 20 by the assimilation this improvement is important despite two factors that could tend to penalize the assimilation first the different time scale of observation where the sampling time of the gliders is hourly while the sampling frequency of the drifter is every six hours the second factor is the distance between the assimilated drifter and the observed glider positions p the distance between the nearest sample drifter position and p1 is more than 25 km this distance increases continuously and reduces the correction impact 5 3 comparison with high resolution ocean color images we targeted a drifter argos number 57307 that was released in 20 85 e 33 055 n from the 1st of february 2006 until 28th of june 2006 this drifter was stuck in one of the highly active eddies off the egyptian coasts see fig 8 for several weeks starting may 17 2006 a contemporary chlorophyll image was available during this period specifically on may 20 showing the eddy shape and location the assimilation experiment was done for 6 days starting from the 17th of may the streamlines of the velocity fields before and after correction were compared with the simultaneous chlorophyll a concentration image in fig 9 the observed streamlines of the velocity field after correction red are close to the chlorophyll a image in terms of shape and location while the background velocity field presents a shift in location and difference in size the latter reveals an extension of the eddy towards the southeast 5 4 reconstruction of independent drifter trajectory as explained in section 3 1 we used three drifters trapped in the anticyclone noted le1 off libya see figs 2 and 5 in gerin et al 2009 see also fig 1 in sutyrin et al 2009 between the 8th and the 27th of may 2006 we assimilated the positions of the argo numbers 59777 and 59774 to simulate the position evolution of the third one 57312 based on the surrounding velocity field see fig 10 the prediction of the future drifter positions after correcting the velocity field is closer to the real trajectory during the 20 days of the experiment as shown in fig 11 predicted positions after correction in red reveal trends that are similar to the real ones on the other hand predictions based on the background velocities differ from the real observations as they do not show circular patterns the lower panel presents the evolution in time of the distance d t as in eq 6 between the observed position and the simulated position of the independent drifter before and after correction the simulated drifter position is reinitialized every 2 days to the position of the real drifter the distance is computed for each of these 2 days windows t w and then averaged to produce the average position error in time fig 11 shows a decrease of this error after the correction the distance between the expected and the real observation reaches around 40 km using the background velocities the assimilation reduces these distances to less than 9 km moreover the correction lowers the uncertainties standard deviation of the error over each of the 10 windows as compared to those of the background see fig 11 the standard deviation of the background distances increases continuously with time reaching more than 19 km at the end of the window after two days after correction these variations are significantly reduced and barely increase with time and do not exceed 3 7 km in other words on average the assimilation allows us to reduce the error from 40 to less than 9 km after two days when simulating the positions of independent drifter not included in the assimilation 6 perspectives when in situ drifters data are available the assimilation could be applied on a larger spatio temporal scale from all the 97 drifters of the egypt egitto campaign 29 drifters covering the area between the libyo egyptian coasts and crete between 21 to 31 e and 30 to 36 n in 2006 have been assimilated in general altimetry strongly underestimates the mean kinetic energy mke and eddy kinetic energy eke of the velocity field pujol and larnicol 2005 gerin et al 2009 poulain et al 2012 so we expect the assimilation to improve those estimates obtained from altimetry fig 12 reveals that the mke increases after assimilation especially when targeting a main regional mesoscale feature such as ierapetra eddy ie amitai et al 2010 ioannou et al 2017 after correction the mke in ie is more than 700 cm 2 s 2 on all sides with a maximum of 760 cm 2 s 2 for the background mke reaches a maximum of 630 cm 2 s 2 but only locally the eastern and the western sides of the eddy have low values of mke as they do not exceed 350 cm 2 s 2 moreover eke see fig 13 reveals a higher variability after assimilation especially in the ierapetra area and near the libyan coast after assimilation all sides of the ie structure reach more than 500 cm 2 s 2 with a maximum of 1100 cm 2 s 2 for the background values over 500 cm 2 s 2 are limited to the southern part of ie with a maximum of 860 cm 2 s 2 the differences in mke and eke reveal that the algorithm can help in revising the quantification of surface velocity features mainly in the ierapetra area and off the libyan coast where intense mesoscale features are found permanently a further detailed study of these areas based on this method could help investigate some oceanographic questions that are unclear especially off libya where the libyo egyptian current generates instabilities and thus a very high variability which paves the way to differing interpretations 7 conclusion this paper has extended the application and objectively validated the assimilation algorithm developed in issa et al 2016 when compared with in situ contemporary current meter data located in the assimilated area the modified velocity field is in better agreement with the current meter records significant improvements are seen when the assimilated drifter reaches a distance less than 30 km from the current meter location this spatial extension of correction is larger than the internal rossby radius in the mediterranean that is on the order of 10 14 km robinson et al 2001 we have shown that the corrected velocity field is closer to current meter data in both direction and intensity the application of the assimilation in high vorticity areas gives more realistic results than the altimetric product after assimilating drifter positions trapped in an eddy detected at the same time from high resolution chlorophyll images the resulting streamlines from the corrected velocity field are consistent with the eddy shape and location as shown by the ocean color image to quantify the assimilation efficiency we showed that the error between the real and simulated drifter positions decreases after assimilation from 40 km without assimilation to less than 10 km with assimilation after two days also the correction reduces the uncertainties during all the experiments further to the east gliders from the eye of the levantine campaign deployed in the south of cyprus were used for further validation the resulting perpendicular velocity norm has values closer to the glider derived velocities after assimilation despite the difference in the sampling time scale and the considerable distances the assimilation was able to reduce the error by more than 20 the results obtained pave the way for further investigations and larger spatio temporal applications in the eastern mediterranean where many drifter positions are available this application can provide a precise and detailed description improving the understanding of the mesoscale and sub mesoscale activity credit authorship contribution statement georges baaklini writing original draft software formal analysis visualization leila issa conceptualization methodology writing review editing project administration validation supervision milad fakhri funding acquisition writing review editing supervision julien brajard conceptualization methodology writing review editing project administration validation supervision gina fifani software writing review milena menna writing review editing resources isabelle taupier letage writing review editing resources anthony bosse writing review editing resources laurent mortier conceptualization funding acquisition writing review editing validation supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to acknowledge the national council for scientific research of lebanon cnrs l for granting a doctoral fellowship to georges baaklini this work was partially funded by the altilev program in the framework of the phc cedre project we would like to thank professor alexandre stegner cnrs for helping in data interpretation drifters data were provided from doi data 10 6092 7a8499bc c5ee 472c b8b5 03523d1e73e9 we thank pierre marie poulain cmre for his contribution in providing the drifters data egypt egitto eddies and gyres paths tracking program received funding from cnrs insu lefe idao and mercator programs glider data are available on http www ifremer fr co ego ego v2 trieste 1 trieste 1 20091124 they were collected and made freely available by the coriolis project and programmes that contribute to it http www coriolis eu org the altimeter products were produced by ssalto duacs and distributed by aviso with support from cnes http www aviso altimetry fr duacs the drifter data are distributed by ogs http nodc ogs trieste it chlorophyll image was provided by nasa goddard space flight center ocean ecology laboratory ocean biology processing group moderate resolution imaging spectroradiometer modis aqua chlorophyll data 2018 reprocessing nasa ob daac greenbelt md usa doi data 10 5067 aqua modis l3b chl 2018 the mio has received funding from european feder fund under project 1166 39417 bathymetry data are provided by gebco compilation group 2020 gebco 2020 grid doi 10 5285 a29c5465 b138 234d e053 6c86abc040b9 appendix if u and v are the zonal and meridional velocities respectively the mean kinetic energy mke cm 2 s 2 is computed m k e 1 2 u 2 v 2 where is the time averaging of the component in a given bin the eddy kinetic energy eke is e k e 1 2 u u v v u u and v v are the variances in the zonal and meridional directions respectively 
