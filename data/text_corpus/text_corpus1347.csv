index,text
6735,snowmelt is the principal control on the timing and magnitude of water flow through mountainous watersheds the effects of precipitation type and quantity on storage and hydrologic connectivity in mountainous systems were explored by combining the observed stable isotope δ 18o in rain snow snowmelt and streamflow with numerically simulated hydrologic boundary fluxes and inverse techniques applied to transient travel time distributions ttd using storage selection sas functions hydrologic simulations of the east river er 85 km2 a snow dominated colorado river headwater basin for water years 2006 2017 were used to test a diverse set of snow accumulation scenarios during the snowmelt period the er released younger water during high storage periods across seasonal and annual timescales an inverse storage effect additionally more young water was released from storage during wet years than during dry years however wet years also appeared to increase hydrologic connectivity which simultaneously flushed older water from the basin during years with reduced snowpack flow paths were inactivated and snowmelt remained in the subsurface to become older water that was potentially reactivated in subsequent wet years incremental warming in hydrologic model simulations was used to evaluate ttd sensitivity to precipitation changing from snow to rain despite the altered timing of boundary fluxes because of warming years with basin average precipitation above 3 25 mm d 1 1200 mm y 1 were resilient to temperature increases up to 10 c with respect to annual water balance partitioning and streamflow ttd in contrast years with less precipitation were sensitive to increased temperatures showing marked increases in the fraction of inflow lost to evapotranspiration younger water was preferentially lost to evapotranspiration which led to an increase in the mean age of streamflow in drier years keywords east river snowmelt travel time distributions hydrologic model warming climate 1 introduction the colorado river is a major water source and economic engine for seven western states 90 of its water originates from the snow dominated upper watersheds of the rocky mountains in colorado utah and wyoming jacobs 2011 the upper watersheds like most snow dominated headwaters around the world are considered especially vulnerable to climate change increased temperatures have significantly affected water budget components at snow dominated watersheds by reducing the snow precipitation fraction foster et al 2016 and increasing the surface energy budget which drives more evapotranspiration et flerchinger et al 1996 recently frameworks have been developed to quantify the response of water budget component partitioning at snow dominated watersheds for example a basin characterization model bcm suggests a decrease in runoff and an increase in evapotranspiration with a shift in precipitation from snow to rain longley 2017 a water and energy budget distributed hydrological model with improved snow physics web dhm s suggests a warming climate reduces the contribution of snowmelt to streamflow discharge bhatti et al 2016 however further frameworks are still needed to quantify not only the water component partitioning but also when snowmelt and rain reach the snow dominated system and the travel time to the streamflow outlet there are two significant motivations for studying the timing and sufficiency of snowmelt at snow dominated systems first spring snowmelt increases subsurface storage and activates predominantly fast flow paths through overland flow and interflow heidbüchel et al 2012 webb et al 2018 monsoonal events are believed to activate only occasional fast flow paths because summer monsoon rain is largely consumed by et and is not an important streamflow contributor compared with snowmelt vivoni et al 2010 dry periods in the spring and fall show similar streamflow responses dominated by slow flow paths through the fractured bedrock second snowmelt is the dominant driver of infiltration siderius et al 2013 and plays a key role in chemical transport for example no 3 and dissolved organic carbon doc export are greater during melt season than in winter with consistent snow cover brooks et al 1998 finlay et al 2006 greater so 4 2 dilution smaller discrepancies between hco 3 and cation equivalent concentrations and smaller co2 efflux rates from surface waters occur during spring melt winnick et al 2017 these flow paths and chemical transport dynamics will become more complicated with climate change and temperature increases therefore quantifying variations in the amount and timing of spring snowmelt under different warming scenarios is very important stream water age distribution is a measure of a catchment s memory of past inputs and therefore it can be used to understand the sensitivity of hydrologic flow and transport processes to climate change since the 1960s isotope hydrograph separation ihs techniques have been widely used to study the age and residence time of stream water traditional ihs methods rely on two end members and a well mixed system however time and space invariance as well as neglect of soil water contributions in his methods have been challenged in recent studies e g casper et al 2003 and klaus and mcdonnell 2013 advanced ihs methods were recently developed to avoid these problems for example kirchner 2019 proposed an ensemble hydrograph separation based on correlations between tracer fluctuations that assume end member signatures are time invariant before and during each storm event another approach that can explicitly account for the mass balance of both water and tracers is the use of travel time distributions ttd a ttd represents the distribution of the ages of water parcels exiting a system relative to when they entered as rain or snowmelt decoding catchment ttds has primarily relied on direct observation payn et al 2008 mechanistic modelling and particle tracking maxwell 2013 sanford and pope 2013 and spectral analysis kirchner et al 2000 of stable isotopes such as δ2h and δ18o and conservative tracers such as chloride and bromide mcguire and mcdonnell 2006 via direct observation payn et al 2008 mechanistic modelling and particle tracking maxwell 2013 sanford and pope 2013 and spectral analysis kirchner et al 2000 a traditional ttd estimate often assumes a constant input and output flow rate or a uniform water parcel selection without bias toward any age set well mixed tank there is increasing evidence that age composition is not time invariant but that water partitions dynamically because of overland flow hydrologic connectivity flow paths and varying velocities specifically rapid transfers of young water will preserve some of the isotopic variability of precipitation in stream outflow whereas longer flow paths transfer a broader distribution of ages which significantly dampen the input signal these processes can be captured by computing time variable ttds that incorporate multiple dynamics based on conservation equations for both mass and age botter et al 2011 van der velde et al 2012 harman 2015 to solve the conservation equation a relationship that determines how the distribution of discharge ages is selected from the distribution of stored water ages must be provided the storage selection sas function captures this relationship a sas function must be provided for each outflow such as stream discharge and et variations of this approach include absolute storage selection functions asas botter 2012 botter et al 2011 fractional storage selection functions fsas van der velde et al 2015 van der velde et al 2012 and rank storage selection functions rsas harman 2015 these theoretical advances have been applied at small scale rain dominated watersheds benettin et al 2017 harman 2015 wilusz et al 2017 however they have not yet been applied to larger scale snow dominated basins partly because of the challenges of quantifying snow accumulation and melt in topographically complex terrain bales et al 2006 molotch et al 2009 lópez moreno et al 2014 gustafson et al 2010 as well as determining snowpack isotopic evolution and its dependence on melt rate taylor et al 2001 to address the challenges of spatial and temporal variability in high altitude snow and rain precipitation and quantify stream ttds we combined field observations with a multi model strategy specifically we developed a hydrologic model for water years 2006 2017 to estimate the spatially distributed water budget components of precipitation snowmelt discharge groundwater storage and et simulated hydrologic fluxes were then used to run the sas model the sas function parameters were calibrated to reproduce observed δ 18o in rain snow snowmelt and streamflow and then used to simulate ttds in addition to being the first use of sas theory for a large scale snow dominated watershed this study connected snow driven water budget components to streamflow ttds to assess their sensitivity to interannual variations in precipitation and temperature using the tools developed we asked the following questions 1 how do ttds vary in response to seasonally variable snowmelt 2 how do ttds vary in response to annually variable snowmelt precipitation 3 how do ttds vary with temperature increases and the conversion of snow to rain in both wet and dry years 2 site description the study site is the east river er fig 1 located in gothic colorado the er contributes 20 of streamflow to the gunnison river which then contributes 40 of the discharge to the colorado river at the colorado utah state line battaglin et al 2011 markstrom et al 2012 the er is considered representative of many snow dominated headwaters in the rocky mountains markstrom et al 2012 for a comprehensive description of the er see carroll et al 2018 the study catchment is 85 km2 with a nearly 1 4 km vertical drop in elevation 4120 m to 2760 m and it contains pristine alpine subalpine montane and riparian ecosystems the river resides primarily in the cretaceous marine shale of the mancos formation whereas the highest mountains are formed by cenozoic igneous formations intruding into the mancos along the western edge of the study domain and into paleozoic and mesozoic sedimentary strata along the eastern edge where these strata form steeply dipping beds that expose older units to the surface gaskill et al 1991 the study area is predominantly barren with sparsely vegetated land cover comprised of alpine conditions 26 conifer forests 45 aspens 12 grasslands 10 shrubs 2 riparian cover 3 and other land cover such as developed land and open water 2 representing the remaining land cover ryan and opperman 2013 the er experiences long cold winters and short cool summers there are two snow telemetry snotel sites in the vicinity of the er domain fig 1 schofield site number 737 and butte site number 380 at elevations 3261 m and 3097 m respectively snowfall occurs october through may and monsoonal rains generally begin in mid july and last into september annual average standard deviation precipitation at scofield over the period of record is 1200 233 mm yr 1 with 70 8 falling as snow butte annual precipitation is nearly half at 670 120 mm yr 1 with snow accounting for 66 12 annual precipitation mean daily air temperatures at butte range from 8 3 c in december to 11 c in june and 1 6 1 2 c cooler than temperatures at the higher elevation schofield station snowmelt processes dominated the observed discharge exiting the basin gauge location provided in fig 1 with peak flows occurring in early to mid june after peak discharge flow recedes through the summer and fall and monsoonal storm events occur in late summer that cause small transient increases in discharge baseflow occurs in the fall and winter months 3 methods 3 1 solute collection and analysis collection and analysis of rain snow snowmelt and streamflow for δ 18o ratio of stable isotopes oxygen 18 in vienna standard mean ocean water vsmow standard analysis sites provided in fig 1 are described by carroll et al 2018 and provided here in brief all samples were filtered at pall ny usa ptfe 0 45 μm and were placed in 1 5 ml glass vials with teflon coated septa lids rain n 70 and snow n 89 grab samples were collected at a single location from july 2014 to october 2017 in addition weekly aggregated rain samples n 46 were collected to assess spatial variability in precipitation at four locations fig 1 the rain gauges used in this study are described by carroll et al 2018 snowmelt was collected in situ during 2016 and 2017 fig 1 shows four snowmelt locations collection devices were modified in 2016 and updated in 2017 to include a 56 cm 66 cm 10 cm polyethylene tray and 2 cm diameter bulkhead to drain snowmelt into a 5l buried reservoir melt collection using a peristaltic pump began april 1 2014 and continued weekly until full melt was achieved n 56 stream water samples were collected daily from may 1 2014 to september 30 2017 using an automatic water sampler model 3700 teledyne isco ne usa via a peristaltic pump and uncapped 1 l polyethylene bottles each bottle was filled with 2 cm of mineral oil to eliminate evaporation effects between the collection and retrieval of samples the oxygen isotope ratios of the water samples were measured using an off axis integrated cavity output spectrometer coupled with an auto sampler interfaced with a heated injector block los gatos research san jose usa isotope ratios are reported in conventional δ notation relative to the vienna standard mean ocean water scale repeated measurements of laboratory standards associated with sample analysis yielded δ18o of 11 44 0 18 1σ 3 2 stream discharge stream discharge was measured at the pump house ph gauge location provided in fig 1 for water years 2015 to 2017 instantaneous readings were measured using a sontek flow tracker acoustic doppler velocimeter to create a depth discharge relationship in conjunction with solinst levelogger edge pressure transducers corrected with barometric pressure correlating daily flows with the united states geological survey usgs east river at almont 09112500 stream gauge located approximately 25 km downstream from the study site allowed stream discharge to be corrected during periods of winter ice when pressure transducer readings can be anomalously high and stream discharge estimates to be extended prior to observation 3 3 hydrologic numerical model hydrologic analysis of the er was done using the usgs precipitation runoff modelling system prms markstrom et al 2015 to account for flow within and between the plant canopy and soil zone streams and the groundwater system climate data drive prms calculations to spatially distribute the precipitation amount and type solar radiation potential et pet sublimation canopy interception soil evaporation and transpiration snowmelt infiltration recharge and groundwater storage supplemental information si provides detailed information on the prms framework parameterization calibration and simulated water budgets the model grid resolution is 100 m and simulations are run at the daily time step for water years 2006 to 2017 from october 1 to september 30 to capture a range of snow accumulation scenarios the prms parameters of dominant cover type summer and winter cover density canopy interception characteristics for snow and rain and transmission coefficients for shortwave radiation provided in fig s 9 were derived using the usgs landfire vegetation maps ryan and opperman 2013 climate inputs of daily minimum and maximum temperature were obtained from the two local snotel stations and spatially distributed as a function of daily lapse rate between stations with additional adjustment for cell aspect daily precipitation measured at the butte snotel was spatially distributed across the watershed using the parameter elevation regression on independent slopes model mean monthly precipitation patterns for water years 1981 to 2010 daly et al 2008 the model was calibrated to match the precipitation type at the butte snotel the monthly average solar radiation observed at four weather stations located in the er fig 1 and the observed streamflow at the ph site and several upstream gauge locations to ensure the spatial origin of streamflow was representative fig s 12 the sensitivity of hydrologic partitioning to changing temperatures and associated shifts in precipitation type from snow to rain was tested by incrementally increasing minimum and maximum daily temperatures from 2 c to 15 c above historically observed values the prms simulated daily effective precipitation peff snowmelt rain soil et groundwater storage and stream discharge were used in conjunction with observed δ2o described in section 4 2 to define the isotopic mass flux needed for ttd development 3 4 isotopic mass flux fig 2 shows the observed seasonal variation in isotopic signature in rain snow and snowmelt for may 1 2014 to september 30 2017 grab samples of rain were at maximum depletion in january snow and minimum depletion in august rain on average δ18o in the snow grab samples was 17 8 5 8 whereas it was 8 3 4 3 in the rain grab samples the weekly aggregated rain samples collected at locations across the basin which varied greatly in elevation exhibited isotopic values that were similar to the rain grab samples but with less variability snowmelt samples collected in the spring of 2016 and 2017 were depleted compared with the snow grab samples because enrichment occurred over the melt period observed stream discharge δ18o ranges from 12 28 to 17 97 generally δ18o declines throughout the winter months and reaches its annual minimum during spring melt after which it rebounds toward the annual maximum in the late summer and fall sinusoidal functions were developed following previous studies e g allen et al 2018 stockinger et al 2017 to smooth observed data for sas input and allow extrapolation of precipitation mass for the entire prms simulation functions minimized the root mean square error in observed values the fitting equations for rain and snowmelt are 1 δ 18 o 7 sin 0 172 x 170 π 180 12 85 2 δ 18 o 9 sin 0 172 x 150 π 180 18 where x water year day snowmelt values were truncated to the observed minimum 13 and maximum 23 values to limit unreasonable values especially with potential melt in the winter the two sine functions were combined for a single sas input function representing cj during the period when basin wide snow water equivalent swe was 0 3 the maximum swe for a given year the snowmelt function was used when swe 0 3 the basin was predominantly snow free and therefore the rain function was used the resulting mass inflow was calculated as peff cj such that heavily depleted values during rapid snowmelt were expressed as large positive mass flux fig 3 for example 2017 was a wet year with large melt rates that drove a large mass influx of δ 18o and therefore stream discharge responded with a more depleted δ 18o signature 3 5 sas theoretical considerations and inverse model approach we chose to use a method in which the sas function related the ttd to age ranked storage rather than absolute age harman 2015 this method did not contain a priori conceptual assumptions that partition the watershed into a number of compartments instead a functional form for the sas function was assumed and its parameters were calibrated using stable isotope observations theoretical considerations provided by others harman 2015 rinaldo et al 2015 are provided here in brief the backward cumulative ttd of outflows represents the distribution of water parcels at age t or younger that are leaving the system as discharge p q t t or evapotranspiration p et t t at time t in a hydrologic system with a total storage s t the continuity of water age and mass can be expressed as 3 s t t t t j t q t p q t t e t t p et t t s t t t t where j t q t and et t are inflow discharge and et at time t respectively the latter three terms on the right hand side of eq 3 represent parcels with age at or younger than t that either leave the system as discharge or evapotranspiration or become older than age t during δ t the age ranked storage s t t t is related to the residence time distribution p s t t which is the fraction of storage at time t with an age less than t that can be expressed as 4 s t t t s t p s t t eq 3 is underdetermined and requires additional assumptions to solve two sas functions are used to reexpress p q t t and p et t t as the equivalent cdf of s t t t instead of t 5 ω q s t t p q t t 6 ω et s t t p et t t for et we assume a time invariant uniform distribution for sas using a single parameter s et to represent a threshold volume of the young water in storage 7 ω et s t s t s et s t s et 1 s t s et we define the sas function for q as a time variant storage dependent gamma distribution 8 ω q s t t γ α s t λ s t s c γ α where γ is the incomplete gamma function γ is the gamma function α is the shape parameter and λ and s c relate the scale parameter to the estimate storage the parameters α λ s et and s c are obtained by inverse calibration against observed δ 18o based on the continuity equation of tracer concentration 9 c q t 0 c j t τ p q τ t d τ where c j a n d c q are the tracer concentration of inflow and outflow respectively and p q is the pdf of p q t t eqs 3 and 4 are solved using eqs 5 through 8 to get the time variant backward ttd at the outflow and the corresponding fraction of water given age t parameter estimation pest is a general purpose model independent parameter estimation and model predictive uncertainty analysis package that uses parallel programming to boost optimization efficiency doherty 2015 the pest optimization was done by adjusting α λ s et and s c to best match observed δ 18 o in stream discharge for water years 2015 to 2017 hydrologically this three year calibration period covers a low medium and high snow accumulation period the pest calibrated sas was then applied to the prms simulated boundary fluxes for water years 2006 to 2017 to address precipitation and temperature controls on streamflow age distributions similar to the test conducted for hydrologic partitioning the sensitivity of streamflow ttd to changing temperatures and associated shifts in precipitation type from snow to rain was tested by incrementally increasing temperatures from 2 c to 15 c above historically observed values this scenario study provided insight into how stream ttd in wet and dry years responded differently to climate change 4 results 4 1 simulated water budget water budget components peff et groundwater storage s and stream discharge q at the pumphouse ph site were derived using the prms model fig 4 over the 12 year simulation period peff was highest in 2011 mean peff 4 06 mm d 1 and lowest in 2012 mean peff 1 98 mm d 1 which represent typical wet and dry conditions respectively in this study streamflow was simulated to be the combined surface runoff interflow and groundwater total et was broken into the components of soil et ets sublimation and canopy evaporation the sas model used the basin averaged prms simulated daily values of peff ets s and q eqs 3 to 9 to estimate ttds variations under different climate situations refer to supplemental information sections si s 2 4 and s 3 for further discussion about water budget component variations and their responses to temperature increases the east river watershed hydrology is dominated by snow accumulation and melt in general this headwater basin is not water limited and et is fairly uniform over the historical range in precipitation we found that the other water budget components such as peff q and groundwater storage as well as snowmelt percentage sm vary from wet years to dry years in warmer years both wet and dry effective precipitation is more evenly distributed over time as opposed to the pulse input during spring melt that occurs in colder years see figs s 18 through s 20 this is because in warmer years winter rain frequency is greater and earlier spring snowmelt occurs which leads to earlier increases of recharge storage and discharge previous studies found a similar phenomenon using the basin characterization model bcm longley 2017 and global circulation models gcms stone et al 2002 however the total discharge recharge and groundwater storage declined sharply in spring and summer such a decline was also found in a parflow clm study gilbert and maxwell 2018 gcms zhai et al 2017 and web dhm s model bhatti et al 2016 the new findings from this study were that during wet years such as 2011 water in excess of system et buffered hydrologic response to climate variability and despite large seasonal changes in snowmelt amount and timing the annual partitioning of peff into stream discharge soil et soil moisture fgw and subsurface storage only changed slightly with temperature increases 7 c fig s 19 only during extreme warming temperature increases of 10 c to 15 c did the basin respond hydrologically at the annual scale through significant increases in et and subsequent decreases in streamflow in contrast dry years showed hydrologic sensitivity at much lower temperature increases fig s 20 evapotranspiration increased sharply at the expense of streamflow fig s 18cd this finding highlights the significant effect of warming on extending droughts at high altitude snow dominated basins barnett et al 2005 diffenbaugh et al 2013 4 2 stream discharge ttd as a function of hydrology table 1 lists the pest optimization of sas parameters α λ s et and s c and their uncertainty ranges with simulated stream δ18o concentrations cj provided in fig 5 the predicted cj agreed well with the observed values during winter and spring snowmelt season but it was consistently overestimated for the summer monsoon season which starts in early july we defined four categories of water based on age very young water t 50 d young water leaves the system in the same water year as it enters referred to as t 1 y old water leaves the system in the next 1 to 5 years referred to as 1 t 5 y water and very old water stays in the system more than 5 years referred to as t 5 y water we first focused on the effect of melt water on ttds at a seasonal timescale fig 6 compares seasonal variations in cumulative ttds and 95 confidence limits with the representative wet year 2011 and dry year 2012 winter or pre melt occurs from december to early march when snowmelt rates are 1 mm d 1 dashed curves spring melt occurs from mid march to mid june when snowmelt rates exceed 8 mm d 1 solid curves spring snowmelt drives streamflow ttd toward a greater younger water fraction than during pre snowmelt approximately 24 of the very young water t 50 d flowed out of the system during the spring melt season whereas the winter season experienced a sharp increase in pq which is indicative of older water the daily correlation between the fraction of t 50 days and snowmelt r 0 64 p 0 01 stresses the importance of snowmelt on the mobilization of very young water and the positive and significant correlation to groundwater storage r 0 77 p 0 01 highlights the movement of young water from the basin when groundwater storage is high a recent study webb et al 2018 found that hydrologic connectivity increased slowly with the accumulation of introduced precipitation and then it reached a threshold where deep flow paths were activated and the previously immobilized water was quickly transported to the system outlet our sas model simulated ttds provided insight into the variation of the hydrologic connectivity during the melt and pre melt seasons in spring flow paths become active almost immediately with the entry of abundant snowmelt and consequent increase in groundwater storage and more young water leaves the system quickly via active flow paths however in winter limited introduced precipitation leads to inactivated deep flow paths and therefore more young water is immobilized in deep zone similarly a previous study linking detailed oxygen 18 observations of stream water melt water soil water and groundwater with hydrometric measurements in a small catchment in northern sweden during the snowmelt period demonstrated this complementary deep flow path activation when a high amount of event snowmelt water infiltrated into the system in spring laudon et al 2004 at annual timescales for the entire simulation period from 2006 to 2017 the correlation coefficient r ywf p e f f for the very young water fraction ywf t 50 d increased during years with larger snow accumulation and larger inflow peff rates for example r 0 71 in 2011 and r 0 44 in 2012 the direct relationship between peff and the ywf correlation coefficient r ywf p e f f is significant r 0 84 p 0 01 because it further suggests that young water mobilization is a function of wet conditions and that there is less young water mobilization under dry conditions fig 7 illustrates the relationship between young water t 1 y and old water t 1 5y based on the inflow and outflow distributions that contribute to streamflow as a function of peff the peff for the inflow year is defined by the year it enters the watershed whereas the peff for the outflow year refers to the peff related to the year of discharge at the annual scale of analysis inflow year and outflow year are equivalent for t 1 y for old water t 1 5 y we investigated two cases for the first case we investigated how much of the water that entered the system for a given year e g year 2011 left the system in 1 to 5 years as old water for the second we investigated how much old water that entered the system in the previous 1 to 5 years left the system in a given year e g year 2011 the results of first case indicated that young water t 1y was highly dependent on the amount of precipitation r 0 86 slope 0 20 p 0 01 fig 7 circle marker the amount of old water t 1 5 y leaving the system was also dependent on the magnitude of peff for the year that water entered the system but with a lower slope and lower significance r 0 49 slope 0 08 p 0 01 fig 7 cross markers than t 1y table 2 provides the amount of water in a given inflow year that leaves in future years for example in 2011 inflow peff 4 06 mm d 1 and q 2 85 mm d 1 the amount of water with age t 1 in 2011 was 0 70 mm d 1 or 17 inflow peff and 25 of total stream discharge for that year water that entered the basin in 2011 that left 1 to 5 years later was 0 39 mm d 1 or 10 of 2011 inflows whereas 73 of inflowing peff stayed in the basin longer than 5 years during 2012 a representative dry year peff 1 98 mm d 1 and streamflow was 1 41 mm d 1 water transported to the stream in 1 year was 0 27 mm d 1 this is less than half the volume of young water leaving in a wet year which accounts for a lower fraction of 2012 inflow peff 13 and of total stream discharge 19 compared with 2011 water that entered the basin in a dry year and left in 1 to 5 years was also less than that transported during a wet year summing to 0 16 mm d 1 or only 8 the inflow volume of 2012 the different transport ability in wet and dry years can also be explained by the hydrologic connectivity theory high annual peff input keeps deep flow paths active to release more water to discharge in contrast dry years with low peff lose a larger component of inflow to et leading to declines in groundwater storage and decreases in hydrologic connectivity subsequently less young water is flushed to the stream and more water remains in storage or moves slowly through the subsurface to be flushed in subsequent years we noticed that young water in discharge is more sensitive slope 0 20 circle markers to change in peff than old water slope 0 08 triangle markers indicating that the system prefers to release younger water with peff increases previous studies applying the sas approach on rain dominated hydrologic systems suggested the inverse storage effect in which watershed systems release predominantly younger water to stream discharge when groundwater storage is high or precipitation events are large benettin et al 2017 harman 2015 wilusz et al 2017 this phenomenon also appears to occur in snow dominated watersheds at both seasonal and annual timescales in the second case water originating from 1 to 5 years prior to 2011 and leaving as stream discharge in 2011 summed to 0 39 mm d 1 or 14 total stream discharge table 2 the remaining 61 of 2011 streamflow by volume older than 5 years was not captured by the model simulation period water originating 1 to 5 years prior to 2012 and released in 2012 as stream discharge was 0 14 mm d 1 this is less than half the magnitude of older water mobilized during a wet year and accounts for 10 of stream volume which is also less than a wet year we found that a given year s peff had better correlation to old water entering the system in the past 1 to 5 years and leaving the system within this given year r 0 96 fig 7 triangle markers than to the water entering the system this given year that contributed to future 1 to 5 years outflow r 0 49 fig 7 cross markers this indicates that the fraction of old water in the discharge depends more on the sufficiency of peff in the year when it leaves the system than in the year when it enters the system a recent study applying ensemble hydrograph separation kirchner 2018 supports our conclusion that young water fraction increases with precipitation sufficiency interestingly a previous study using a theoretical framework to estimate ttd heidbüchel et al 2012 showed different results in the study of heidbüchel et al 2012 estimated ttd using the same isotope δ 18o at two catchments with different precipitation sufficiencies one humid and one semiarid their results indicated that the wet catchment had less young water t 315 d leaving the system and more old water t 315 d leaving the system than the dry catchment this contradicts our conclusion further study at the east river basin using the sas model with spatial variations in precipitation will give us better insight into the spatiotemporal variations of ttd estimates we observed stream releases of approximately 20 to 25 of peff water as discharge in the first 50 days fig 6 and 40 of peff in 10 years this fraction is much lower than previous studies that used sas approaches in which over 40 very young water fraction in the discharge and 80 to 90 of inflow water left the systems in 10 years benettin et al 2017 harman 2015 wilusz et al 2017 one reason for this lower fraction for precipitation to become discharge is the size of system all the previous studies were conducted at small scale watersheds 0 9 3 5 km2 similarly previous work on the activation of temporary flow paths laudon et al 2004 and variations in hydrologic connectivity yang and chu 2013 were also conducted at small scale watersheds however this study was conducted at a much larger scale watershed 85 km2 where long and tortuous flow paths are likely to extend the transit time for inflow water to reach the outlet another reason is that unlike previous studies at rain dominated systems our study was conducted at a snow dominated system therefore the peff occurs primarily during snowmelt from mid march to mid june although we treat october 1 as the start of a water year the melt water actually only has less than half a year to leave the system as discharge to be considered young water i e it leaves the system in the same year rainwater infiltration between october and march at rain dominated watersheds is quickly transmitted to the stream outlet and therefore it has much more time to leave the system as discharge to be considered young water the melt water will lose a much higher fraction to et in the following summer season than the rainwater which travels in the system uniformly through the year which further decreases the fraction of melt water that leaves the system as discharge 4 3 stream discharge ttd as a function of climate this is the first application of the sas approach to a watershed scale snow dominated system we found that streamflow ttds respond differently to temperature increases between wet years and dry years we tested different scenarios by increasing the temperature 1 2 4 5 6 7 8 9 10 11 12 and 15 c to investigate the response of stream ttd fig 8 a shows the changes in fractions of inflow leaving the system with a water age of less than one year during wet years changes in streamflow ttds were buffered from temperature increases therefore the amount and fraction of young water released to discharge remained almost unchanged when temperature was increased up to 8 c this was because of a sufficient amount of peff to offset the increasing et loss due to temperature increases the amount of young water discharge was not appreciably changed however in the case of extreme temperature increasing by 15 c the young water fraction also declined by approximately 14 over the 10 c case this was because the sharply increasing et consumption due to extreme temperature increases exceeded the amount the peff can afford and therefore part of discharge was diminished to compensate extensive et loss in contrast stream discharge ttds under dry conditions are more sensitive to increased temperatures a 2 c increase in temperature reduced the fraction of inflow reaching the river in one year by 5 and a 15 c increase in temperature reduced young water in the streamflow by 46 with limited peff et increases diminished stream discharge lost groundwater storage offset some of the estimated reductions in streamflow but the added et losses resulted in a loss of younger discharge with t 1 y even with modest changes in temperature with more significant increases in temperature i e 10 c a larger fraction of infiltration was immobilized below the root zone with temperature increases the young water fraction in streamflow dropped nearly linearly as a function of the decline in the percentage of snowmelt in peff sm fig 8b we found that the slope of a dry year was much higher than a wet year 11 9 to 7 1 indicating that hydrologic partitioning during dry years is more sensitive to increasing temperature and the associated shift in precipitation type fig 9 shows the fraction of inflow exiting the system in future years given no change and a 10 c increase in temperature over historical conditions wet years see little change in the fraction of inflow peff leaving the system in future years when temperature increases by 10 c whereas dry years experience a significant reduction in the first year as well as a reduction in the fraction of water leaving the basin over the next 5 years water remaining in the subsurface more than 5 years undergoes no obvious change in peff leaving the system despite an increased water limitation et pet 1 refer to si dry years result in larger et loss to warming than wet years fig 9 with loses primarily at the expense of younger water t 1 y and to a lesser degree at the expense of old water t 1 5 y to effectively increase the mean residence time of water in the basin with increasing temperatures up to 10 c streamflow ages increased for a dry year but remained relatively unchanged for a wet year for the old water that entered system 1 to 5 years before the wet dry years we found that increasing temperature reduces the fraction of the inflow from previous years in the discharge and forces the water to stay longer in the system which leads more water to be lost as et fig 10 shows that a rise in temperature has little effect on streamflow age distributions in a wet year but will delay water leaving the system by more than 30 to 50 days or even longer in a dry year such a delay repeats in each dry year and accumulates to cause more old water to either stay in the system over a longer period or to be lost as et when temperatures were increased by 15 c streamflow t 1 y in a wet year was larger than with no warming in a dry year fig 8a however both wet and dry years showed declines in ages t 5 y and age distributions of streamflow increased relative to historical conditions fig 9 when the majority of peff shifted from snow to rain with extreme temperature increases beyond 10 c peff was delivered uniformly into the system as rain over the winter and spring as opposed a pulse of melt only in the spring which caused the water to reside in the system over a longer period especially in the dry years fig 10 subsequently the temporary activation of deep flow paths by spring melt no longer exists making the overall hydrologic connectivity decline and the fraction of young water t 1 and prior old water 1 5 y to be held in the basin over a longer period of time fig 9 this finding implies that temperature change plays a key role in drought propagation at snow dominated basins because lag response to temperature change varies between wet and dry conditions an increase up to 8 c in temperature more than historical conditions leads to little change in the fraction of the wet year s inflow exiting the system in the future five years but it significantly reduces the fraction of the dry year s inflow leaving the system in both the near future t 1 y and over a longer period 1 5 y fig 9 this means that years with limited precipitation are more sensitive to climate change in addition with an increasing fraction of inflow lost to et hydrologic connectivity is further decreased and more water remains in the subsurface and becomes old which propagates droughts in snow dominated basins even longer foster et al 2016 found that with warming energy budget increases reduced streamflow more than snow rain transitions a 4 c of uniform warming reduced streamflow 44 8 more than a complete shift in precipitation from snow to rain however our study showed that large reductions in annual streamflow did not occur until temperature increases exceeded 7 c fig s 18 furthermore our study showed variations in wet and dry years in terms of streamflow ttd the transit time decreased with small increases in temperature 2 c to 4 c in dry years but remained almost the same until temperature increases exceeded 8 c in wet years and a significant reduction of ttd only happened with extreme warming 15 c when precipitation shifted from snow to rain fig 8a this finding indicates that energy budget increases in dry years have a greater effect on ttd variations whereas snow rain transitions in wet years have a have a greater effect on ttd variations furthermore our study found that more inflow water was flushed from the system in wet years with extreme temperature increases than in dry years under historical conditions which suggests that the sufficiency of precipitation is a more significant factor in controlling ttds than energy budget and the type of precipitation 4 4 limitation of prms sas pest estimation and related future work no model can represent the full detail of this large scale snow dominated system although the sas pest simulated δ18o concentration cq agreed well with the observations during winter and spring snowmelt the agreement during the summer monsoon season was poor and highly overestimated fig 5c remondi et al 2018 found a similar poor agreement and attributed it to the tracer concentration values rapidly shifting toward the concentration of the groundwater storage after a rainfall event there are also other potential reasons for poor agreement in summer first during the summer monsoon season only the hydraulically connected storage controlled the shape of the sas function and drove discharge rather than the increasing total storage a coefficient needed to be added to the total discharge to represent the hydraulically connected storage to better fit the monsoon season however it was very difficult to estimate this coefficient with the limited observed δ18o concentration data particularly considering this coefficient was heterogeneous depending on the variations of subsurface properties across the catchment second rain during the summer monsoon was largely consumed by et which greatly affected tracer concentrations of water budget components but quantifying the uncertainty of et was very difficult mcdonnell et al 2010 without direct measured et or cet we had to use simulated et and rely on a simple uniform distribution for et in the sas model subsequently the strong consumption of rain by et in the summer may not have been well represented by the model leading to high uncertainty an introduction of et transit time distribution will help improve the estimates of streamflow ttd third high uncertainty in summer precipitation measurements was reported in recent mountain watershed studies hrachowitz and weiler 2011 daly et al 2017 our limited cj observation during strong summer rain event along with the prms estimated rain rate could have also introduced high uncertainty in the sas model results further limitations arose from assuming uniform precipitation land surface cover topography and soil hydraulic properties in this study therefore the spatial variations of temperature swe snowmelt rate and peff vegetation and root distribution elevation and slope subsurface permeability soil moisture content and flow paths on the seasonal and annual dynamics of ttds were not investigated however these factors may play key roles in controlling hydrologic connectivity water budget stream discharge and evapotranspiration variations considering the complicated climate ecological and terrestrial structure in snow dominated systems for example spatial patterns of snowmelt are largely determined by the distribution of swe at the start of the melt season anderton et al 2004 northeast facing slopes receive greater snowmelt inflow than southwest facing slopes during the spring at mountain basins kormos et al 2014 runoff and et at different elevations have various sensitivities in response to warming gilbert and maxwell 2018 introducing entropy in the standard deviation of slope effectively reduces the local hydraulic gradients loss due to spatial aggregation fang et al 2016 as vegetation density increases hydrologic connectivity decreases at hillslopes with high irradiance but increases at hillslopes with low irradiance emanuel et al 2014 snowmelt contributions to stream response to summer temperature changes is buffered at higher watersheds than lower watersheds lisi et al 2015 variations in soil saturation also significantly affect sas functions for example saturated groundwater tends to release younger water to the discharge whereas the vadose zone prefers older water additionally the influence of recharge rate on the ttd estimation is closely dependent on the heterogeneity of subsurface hydraulic conductivity danesh yazdi et al 2018 a lack of representation of three dimensional heterogeneity in climate vegetation topography and subsurface properties may have hampered the ttd estimates in our prms sas pest model results therefore high resolution three dimensional climate and hydrologic models such as gsflow markstrom et al 2008 pflotran hammond et al 2014 and parflow clm maxwell and miller 2005 will be required to better understand the effect of spatiotemporal distribution variations of climate surface and subsurface parameters and quantify the hydrologic response in the future work uncertainty quantification of the impacts of climate change on snowmelt streamflow processes are also important to better understand streamflow ttd response to energy and water budget changes kudo et al 2017 5 conclusions in this study we coupled prms sas pest models to estimate water budget components simulate streamflow ttds and seasonal and yearly responses to hydrologic and climate changes at a high altitude snow dominated watershed in the east river basin the major findings of this study were i change in prms estimated water budget components was primarily restricted to dry years with insufficient peff input when temperature increased ii the inverse storage effect occurred in snow dominated systems between pre melt and spring snowmelt seasons as well as between wet and dry years seasonally more young water was released from storage during spring snowmelt season than winter pre melt season annually wet years with high peff contributed more young water in the stream discharge than dry years with water limitations iii dry year hydrology was more sensitive to climate change than wet year hydrology an increase of up to 10 c in temperature over the historical conditions led to little change in the fraction of the wet year s inflow exiting the system five years in the future but it significantly reduced the fraction of dry year inflow leaving the system for both young water t 1 y and old water 1 5 y with increasing temperature deep subsurface water was immobilized in dry years and an increasing fraction of inflow was lost to evapotranspiration which caused hydrologic connectivity to decrease further and more water to remain in the watershed propagating droughts in snow dominated basins iv energy budget increases had a greater effect on ttd variations in dry years whereas snow rain transitions had a greater effect ttd variations in wet years furthermore the sufficiency of precipitation was a more significant factor in controlling ttds than energy budget or the type of precipitation at this snow dominated watershed declaration of interests none acknowledgements work was supported by the united states geological survey through the national institute of water resources under grant cooperative agreement no g16ap00196 and the lawrence berkeley national laboratory s wfsfa through the u s department of energy office of science office of biological and environmental research under contract de ac02 05ch11231 special thanks to wendy brown for data collection efforts and markus bill at lbnl for analytical support appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 01 029 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6735,snowmelt is the principal control on the timing and magnitude of water flow through mountainous watersheds the effects of precipitation type and quantity on storage and hydrologic connectivity in mountainous systems were explored by combining the observed stable isotope δ 18o in rain snow snowmelt and streamflow with numerically simulated hydrologic boundary fluxes and inverse techniques applied to transient travel time distributions ttd using storage selection sas functions hydrologic simulations of the east river er 85 km2 a snow dominated colorado river headwater basin for water years 2006 2017 were used to test a diverse set of snow accumulation scenarios during the snowmelt period the er released younger water during high storage periods across seasonal and annual timescales an inverse storage effect additionally more young water was released from storage during wet years than during dry years however wet years also appeared to increase hydrologic connectivity which simultaneously flushed older water from the basin during years with reduced snowpack flow paths were inactivated and snowmelt remained in the subsurface to become older water that was potentially reactivated in subsequent wet years incremental warming in hydrologic model simulations was used to evaluate ttd sensitivity to precipitation changing from snow to rain despite the altered timing of boundary fluxes because of warming years with basin average precipitation above 3 25 mm d 1 1200 mm y 1 were resilient to temperature increases up to 10 c with respect to annual water balance partitioning and streamflow ttd in contrast years with less precipitation were sensitive to increased temperatures showing marked increases in the fraction of inflow lost to evapotranspiration younger water was preferentially lost to evapotranspiration which led to an increase in the mean age of streamflow in drier years keywords east river snowmelt travel time distributions hydrologic model warming climate 1 introduction the colorado river is a major water source and economic engine for seven western states 90 of its water originates from the snow dominated upper watersheds of the rocky mountains in colorado utah and wyoming jacobs 2011 the upper watersheds like most snow dominated headwaters around the world are considered especially vulnerable to climate change increased temperatures have significantly affected water budget components at snow dominated watersheds by reducing the snow precipitation fraction foster et al 2016 and increasing the surface energy budget which drives more evapotranspiration et flerchinger et al 1996 recently frameworks have been developed to quantify the response of water budget component partitioning at snow dominated watersheds for example a basin characterization model bcm suggests a decrease in runoff and an increase in evapotranspiration with a shift in precipitation from snow to rain longley 2017 a water and energy budget distributed hydrological model with improved snow physics web dhm s suggests a warming climate reduces the contribution of snowmelt to streamflow discharge bhatti et al 2016 however further frameworks are still needed to quantify not only the water component partitioning but also when snowmelt and rain reach the snow dominated system and the travel time to the streamflow outlet there are two significant motivations for studying the timing and sufficiency of snowmelt at snow dominated systems first spring snowmelt increases subsurface storage and activates predominantly fast flow paths through overland flow and interflow heidbüchel et al 2012 webb et al 2018 monsoonal events are believed to activate only occasional fast flow paths because summer monsoon rain is largely consumed by et and is not an important streamflow contributor compared with snowmelt vivoni et al 2010 dry periods in the spring and fall show similar streamflow responses dominated by slow flow paths through the fractured bedrock second snowmelt is the dominant driver of infiltration siderius et al 2013 and plays a key role in chemical transport for example no 3 and dissolved organic carbon doc export are greater during melt season than in winter with consistent snow cover brooks et al 1998 finlay et al 2006 greater so 4 2 dilution smaller discrepancies between hco 3 and cation equivalent concentrations and smaller co2 efflux rates from surface waters occur during spring melt winnick et al 2017 these flow paths and chemical transport dynamics will become more complicated with climate change and temperature increases therefore quantifying variations in the amount and timing of spring snowmelt under different warming scenarios is very important stream water age distribution is a measure of a catchment s memory of past inputs and therefore it can be used to understand the sensitivity of hydrologic flow and transport processes to climate change since the 1960s isotope hydrograph separation ihs techniques have been widely used to study the age and residence time of stream water traditional ihs methods rely on two end members and a well mixed system however time and space invariance as well as neglect of soil water contributions in his methods have been challenged in recent studies e g casper et al 2003 and klaus and mcdonnell 2013 advanced ihs methods were recently developed to avoid these problems for example kirchner 2019 proposed an ensemble hydrograph separation based on correlations between tracer fluctuations that assume end member signatures are time invariant before and during each storm event another approach that can explicitly account for the mass balance of both water and tracers is the use of travel time distributions ttd a ttd represents the distribution of the ages of water parcels exiting a system relative to when they entered as rain or snowmelt decoding catchment ttds has primarily relied on direct observation payn et al 2008 mechanistic modelling and particle tracking maxwell 2013 sanford and pope 2013 and spectral analysis kirchner et al 2000 of stable isotopes such as δ2h and δ18o and conservative tracers such as chloride and bromide mcguire and mcdonnell 2006 via direct observation payn et al 2008 mechanistic modelling and particle tracking maxwell 2013 sanford and pope 2013 and spectral analysis kirchner et al 2000 a traditional ttd estimate often assumes a constant input and output flow rate or a uniform water parcel selection without bias toward any age set well mixed tank there is increasing evidence that age composition is not time invariant but that water partitions dynamically because of overland flow hydrologic connectivity flow paths and varying velocities specifically rapid transfers of young water will preserve some of the isotopic variability of precipitation in stream outflow whereas longer flow paths transfer a broader distribution of ages which significantly dampen the input signal these processes can be captured by computing time variable ttds that incorporate multiple dynamics based on conservation equations for both mass and age botter et al 2011 van der velde et al 2012 harman 2015 to solve the conservation equation a relationship that determines how the distribution of discharge ages is selected from the distribution of stored water ages must be provided the storage selection sas function captures this relationship a sas function must be provided for each outflow such as stream discharge and et variations of this approach include absolute storage selection functions asas botter 2012 botter et al 2011 fractional storage selection functions fsas van der velde et al 2015 van der velde et al 2012 and rank storage selection functions rsas harman 2015 these theoretical advances have been applied at small scale rain dominated watersheds benettin et al 2017 harman 2015 wilusz et al 2017 however they have not yet been applied to larger scale snow dominated basins partly because of the challenges of quantifying snow accumulation and melt in topographically complex terrain bales et al 2006 molotch et al 2009 lópez moreno et al 2014 gustafson et al 2010 as well as determining snowpack isotopic evolution and its dependence on melt rate taylor et al 2001 to address the challenges of spatial and temporal variability in high altitude snow and rain precipitation and quantify stream ttds we combined field observations with a multi model strategy specifically we developed a hydrologic model for water years 2006 2017 to estimate the spatially distributed water budget components of precipitation snowmelt discharge groundwater storage and et simulated hydrologic fluxes were then used to run the sas model the sas function parameters were calibrated to reproduce observed δ 18o in rain snow snowmelt and streamflow and then used to simulate ttds in addition to being the first use of sas theory for a large scale snow dominated watershed this study connected snow driven water budget components to streamflow ttds to assess their sensitivity to interannual variations in precipitation and temperature using the tools developed we asked the following questions 1 how do ttds vary in response to seasonally variable snowmelt 2 how do ttds vary in response to annually variable snowmelt precipitation 3 how do ttds vary with temperature increases and the conversion of snow to rain in both wet and dry years 2 site description the study site is the east river er fig 1 located in gothic colorado the er contributes 20 of streamflow to the gunnison river which then contributes 40 of the discharge to the colorado river at the colorado utah state line battaglin et al 2011 markstrom et al 2012 the er is considered representative of many snow dominated headwaters in the rocky mountains markstrom et al 2012 for a comprehensive description of the er see carroll et al 2018 the study catchment is 85 km2 with a nearly 1 4 km vertical drop in elevation 4120 m to 2760 m and it contains pristine alpine subalpine montane and riparian ecosystems the river resides primarily in the cretaceous marine shale of the mancos formation whereas the highest mountains are formed by cenozoic igneous formations intruding into the mancos along the western edge of the study domain and into paleozoic and mesozoic sedimentary strata along the eastern edge where these strata form steeply dipping beds that expose older units to the surface gaskill et al 1991 the study area is predominantly barren with sparsely vegetated land cover comprised of alpine conditions 26 conifer forests 45 aspens 12 grasslands 10 shrubs 2 riparian cover 3 and other land cover such as developed land and open water 2 representing the remaining land cover ryan and opperman 2013 the er experiences long cold winters and short cool summers there are two snow telemetry snotel sites in the vicinity of the er domain fig 1 schofield site number 737 and butte site number 380 at elevations 3261 m and 3097 m respectively snowfall occurs october through may and monsoonal rains generally begin in mid july and last into september annual average standard deviation precipitation at scofield over the period of record is 1200 233 mm yr 1 with 70 8 falling as snow butte annual precipitation is nearly half at 670 120 mm yr 1 with snow accounting for 66 12 annual precipitation mean daily air temperatures at butte range from 8 3 c in december to 11 c in june and 1 6 1 2 c cooler than temperatures at the higher elevation schofield station snowmelt processes dominated the observed discharge exiting the basin gauge location provided in fig 1 with peak flows occurring in early to mid june after peak discharge flow recedes through the summer and fall and monsoonal storm events occur in late summer that cause small transient increases in discharge baseflow occurs in the fall and winter months 3 methods 3 1 solute collection and analysis collection and analysis of rain snow snowmelt and streamflow for δ 18o ratio of stable isotopes oxygen 18 in vienna standard mean ocean water vsmow standard analysis sites provided in fig 1 are described by carroll et al 2018 and provided here in brief all samples were filtered at pall ny usa ptfe 0 45 μm and were placed in 1 5 ml glass vials with teflon coated septa lids rain n 70 and snow n 89 grab samples were collected at a single location from july 2014 to october 2017 in addition weekly aggregated rain samples n 46 were collected to assess spatial variability in precipitation at four locations fig 1 the rain gauges used in this study are described by carroll et al 2018 snowmelt was collected in situ during 2016 and 2017 fig 1 shows four snowmelt locations collection devices were modified in 2016 and updated in 2017 to include a 56 cm 66 cm 10 cm polyethylene tray and 2 cm diameter bulkhead to drain snowmelt into a 5l buried reservoir melt collection using a peristaltic pump began april 1 2014 and continued weekly until full melt was achieved n 56 stream water samples were collected daily from may 1 2014 to september 30 2017 using an automatic water sampler model 3700 teledyne isco ne usa via a peristaltic pump and uncapped 1 l polyethylene bottles each bottle was filled with 2 cm of mineral oil to eliminate evaporation effects between the collection and retrieval of samples the oxygen isotope ratios of the water samples were measured using an off axis integrated cavity output spectrometer coupled with an auto sampler interfaced with a heated injector block los gatos research san jose usa isotope ratios are reported in conventional δ notation relative to the vienna standard mean ocean water scale repeated measurements of laboratory standards associated with sample analysis yielded δ18o of 11 44 0 18 1σ 3 2 stream discharge stream discharge was measured at the pump house ph gauge location provided in fig 1 for water years 2015 to 2017 instantaneous readings were measured using a sontek flow tracker acoustic doppler velocimeter to create a depth discharge relationship in conjunction with solinst levelogger edge pressure transducers corrected with barometric pressure correlating daily flows with the united states geological survey usgs east river at almont 09112500 stream gauge located approximately 25 km downstream from the study site allowed stream discharge to be corrected during periods of winter ice when pressure transducer readings can be anomalously high and stream discharge estimates to be extended prior to observation 3 3 hydrologic numerical model hydrologic analysis of the er was done using the usgs precipitation runoff modelling system prms markstrom et al 2015 to account for flow within and between the plant canopy and soil zone streams and the groundwater system climate data drive prms calculations to spatially distribute the precipitation amount and type solar radiation potential et pet sublimation canopy interception soil evaporation and transpiration snowmelt infiltration recharge and groundwater storage supplemental information si provides detailed information on the prms framework parameterization calibration and simulated water budgets the model grid resolution is 100 m and simulations are run at the daily time step for water years 2006 to 2017 from october 1 to september 30 to capture a range of snow accumulation scenarios the prms parameters of dominant cover type summer and winter cover density canopy interception characteristics for snow and rain and transmission coefficients for shortwave radiation provided in fig s 9 were derived using the usgs landfire vegetation maps ryan and opperman 2013 climate inputs of daily minimum and maximum temperature were obtained from the two local snotel stations and spatially distributed as a function of daily lapse rate between stations with additional adjustment for cell aspect daily precipitation measured at the butte snotel was spatially distributed across the watershed using the parameter elevation regression on independent slopes model mean monthly precipitation patterns for water years 1981 to 2010 daly et al 2008 the model was calibrated to match the precipitation type at the butte snotel the monthly average solar radiation observed at four weather stations located in the er fig 1 and the observed streamflow at the ph site and several upstream gauge locations to ensure the spatial origin of streamflow was representative fig s 12 the sensitivity of hydrologic partitioning to changing temperatures and associated shifts in precipitation type from snow to rain was tested by incrementally increasing minimum and maximum daily temperatures from 2 c to 15 c above historically observed values the prms simulated daily effective precipitation peff snowmelt rain soil et groundwater storage and stream discharge were used in conjunction with observed δ2o described in section 4 2 to define the isotopic mass flux needed for ttd development 3 4 isotopic mass flux fig 2 shows the observed seasonal variation in isotopic signature in rain snow and snowmelt for may 1 2014 to september 30 2017 grab samples of rain were at maximum depletion in january snow and minimum depletion in august rain on average δ18o in the snow grab samples was 17 8 5 8 whereas it was 8 3 4 3 in the rain grab samples the weekly aggregated rain samples collected at locations across the basin which varied greatly in elevation exhibited isotopic values that were similar to the rain grab samples but with less variability snowmelt samples collected in the spring of 2016 and 2017 were depleted compared with the snow grab samples because enrichment occurred over the melt period observed stream discharge δ18o ranges from 12 28 to 17 97 generally δ18o declines throughout the winter months and reaches its annual minimum during spring melt after which it rebounds toward the annual maximum in the late summer and fall sinusoidal functions were developed following previous studies e g allen et al 2018 stockinger et al 2017 to smooth observed data for sas input and allow extrapolation of precipitation mass for the entire prms simulation functions minimized the root mean square error in observed values the fitting equations for rain and snowmelt are 1 δ 18 o 7 sin 0 172 x 170 π 180 12 85 2 δ 18 o 9 sin 0 172 x 150 π 180 18 where x water year day snowmelt values were truncated to the observed minimum 13 and maximum 23 values to limit unreasonable values especially with potential melt in the winter the two sine functions were combined for a single sas input function representing cj during the period when basin wide snow water equivalent swe was 0 3 the maximum swe for a given year the snowmelt function was used when swe 0 3 the basin was predominantly snow free and therefore the rain function was used the resulting mass inflow was calculated as peff cj such that heavily depleted values during rapid snowmelt were expressed as large positive mass flux fig 3 for example 2017 was a wet year with large melt rates that drove a large mass influx of δ 18o and therefore stream discharge responded with a more depleted δ 18o signature 3 5 sas theoretical considerations and inverse model approach we chose to use a method in which the sas function related the ttd to age ranked storage rather than absolute age harman 2015 this method did not contain a priori conceptual assumptions that partition the watershed into a number of compartments instead a functional form for the sas function was assumed and its parameters were calibrated using stable isotope observations theoretical considerations provided by others harman 2015 rinaldo et al 2015 are provided here in brief the backward cumulative ttd of outflows represents the distribution of water parcels at age t or younger that are leaving the system as discharge p q t t or evapotranspiration p et t t at time t in a hydrologic system with a total storage s t the continuity of water age and mass can be expressed as 3 s t t t t j t q t p q t t e t t p et t t s t t t t where j t q t and et t are inflow discharge and et at time t respectively the latter three terms on the right hand side of eq 3 represent parcels with age at or younger than t that either leave the system as discharge or evapotranspiration or become older than age t during δ t the age ranked storage s t t t is related to the residence time distribution p s t t which is the fraction of storage at time t with an age less than t that can be expressed as 4 s t t t s t p s t t eq 3 is underdetermined and requires additional assumptions to solve two sas functions are used to reexpress p q t t and p et t t as the equivalent cdf of s t t t instead of t 5 ω q s t t p q t t 6 ω et s t t p et t t for et we assume a time invariant uniform distribution for sas using a single parameter s et to represent a threshold volume of the young water in storage 7 ω et s t s t s et s t s et 1 s t s et we define the sas function for q as a time variant storage dependent gamma distribution 8 ω q s t t γ α s t λ s t s c γ α where γ is the incomplete gamma function γ is the gamma function α is the shape parameter and λ and s c relate the scale parameter to the estimate storage the parameters α λ s et and s c are obtained by inverse calibration against observed δ 18o based on the continuity equation of tracer concentration 9 c q t 0 c j t τ p q τ t d τ where c j a n d c q are the tracer concentration of inflow and outflow respectively and p q is the pdf of p q t t eqs 3 and 4 are solved using eqs 5 through 8 to get the time variant backward ttd at the outflow and the corresponding fraction of water given age t parameter estimation pest is a general purpose model independent parameter estimation and model predictive uncertainty analysis package that uses parallel programming to boost optimization efficiency doherty 2015 the pest optimization was done by adjusting α λ s et and s c to best match observed δ 18 o in stream discharge for water years 2015 to 2017 hydrologically this three year calibration period covers a low medium and high snow accumulation period the pest calibrated sas was then applied to the prms simulated boundary fluxes for water years 2006 to 2017 to address precipitation and temperature controls on streamflow age distributions similar to the test conducted for hydrologic partitioning the sensitivity of streamflow ttd to changing temperatures and associated shifts in precipitation type from snow to rain was tested by incrementally increasing temperatures from 2 c to 15 c above historically observed values this scenario study provided insight into how stream ttd in wet and dry years responded differently to climate change 4 results 4 1 simulated water budget water budget components peff et groundwater storage s and stream discharge q at the pumphouse ph site were derived using the prms model fig 4 over the 12 year simulation period peff was highest in 2011 mean peff 4 06 mm d 1 and lowest in 2012 mean peff 1 98 mm d 1 which represent typical wet and dry conditions respectively in this study streamflow was simulated to be the combined surface runoff interflow and groundwater total et was broken into the components of soil et ets sublimation and canopy evaporation the sas model used the basin averaged prms simulated daily values of peff ets s and q eqs 3 to 9 to estimate ttds variations under different climate situations refer to supplemental information sections si s 2 4 and s 3 for further discussion about water budget component variations and their responses to temperature increases the east river watershed hydrology is dominated by snow accumulation and melt in general this headwater basin is not water limited and et is fairly uniform over the historical range in precipitation we found that the other water budget components such as peff q and groundwater storage as well as snowmelt percentage sm vary from wet years to dry years in warmer years both wet and dry effective precipitation is more evenly distributed over time as opposed to the pulse input during spring melt that occurs in colder years see figs s 18 through s 20 this is because in warmer years winter rain frequency is greater and earlier spring snowmelt occurs which leads to earlier increases of recharge storage and discharge previous studies found a similar phenomenon using the basin characterization model bcm longley 2017 and global circulation models gcms stone et al 2002 however the total discharge recharge and groundwater storage declined sharply in spring and summer such a decline was also found in a parflow clm study gilbert and maxwell 2018 gcms zhai et al 2017 and web dhm s model bhatti et al 2016 the new findings from this study were that during wet years such as 2011 water in excess of system et buffered hydrologic response to climate variability and despite large seasonal changes in snowmelt amount and timing the annual partitioning of peff into stream discharge soil et soil moisture fgw and subsurface storage only changed slightly with temperature increases 7 c fig s 19 only during extreme warming temperature increases of 10 c to 15 c did the basin respond hydrologically at the annual scale through significant increases in et and subsequent decreases in streamflow in contrast dry years showed hydrologic sensitivity at much lower temperature increases fig s 20 evapotranspiration increased sharply at the expense of streamflow fig s 18cd this finding highlights the significant effect of warming on extending droughts at high altitude snow dominated basins barnett et al 2005 diffenbaugh et al 2013 4 2 stream discharge ttd as a function of hydrology table 1 lists the pest optimization of sas parameters α λ s et and s c and their uncertainty ranges with simulated stream δ18o concentrations cj provided in fig 5 the predicted cj agreed well with the observed values during winter and spring snowmelt season but it was consistently overestimated for the summer monsoon season which starts in early july we defined four categories of water based on age very young water t 50 d young water leaves the system in the same water year as it enters referred to as t 1 y old water leaves the system in the next 1 to 5 years referred to as 1 t 5 y water and very old water stays in the system more than 5 years referred to as t 5 y water we first focused on the effect of melt water on ttds at a seasonal timescale fig 6 compares seasonal variations in cumulative ttds and 95 confidence limits with the representative wet year 2011 and dry year 2012 winter or pre melt occurs from december to early march when snowmelt rates are 1 mm d 1 dashed curves spring melt occurs from mid march to mid june when snowmelt rates exceed 8 mm d 1 solid curves spring snowmelt drives streamflow ttd toward a greater younger water fraction than during pre snowmelt approximately 24 of the very young water t 50 d flowed out of the system during the spring melt season whereas the winter season experienced a sharp increase in pq which is indicative of older water the daily correlation between the fraction of t 50 days and snowmelt r 0 64 p 0 01 stresses the importance of snowmelt on the mobilization of very young water and the positive and significant correlation to groundwater storage r 0 77 p 0 01 highlights the movement of young water from the basin when groundwater storage is high a recent study webb et al 2018 found that hydrologic connectivity increased slowly with the accumulation of introduced precipitation and then it reached a threshold where deep flow paths were activated and the previously immobilized water was quickly transported to the system outlet our sas model simulated ttds provided insight into the variation of the hydrologic connectivity during the melt and pre melt seasons in spring flow paths become active almost immediately with the entry of abundant snowmelt and consequent increase in groundwater storage and more young water leaves the system quickly via active flow paths however in winter limited introduced precipitation leads to inactivated deep flow paths and therefore more young water is immobilized in deep zone similarly a previous study linking detailed oxygen 18 observations of stream water melt water soil water and groundwater with hydrometric measurements in a small catchment in northern sweden during the snowmelt period demonstrated this complementary deep flow path activation when a high amount of event snowmelt water infiltrated into the system in spring laudon et al 2004 at annual timescales for the entire simulation period from 2006 to 2017 the correlation coefficient r ywf p e f f for the very young water fraction ywf t 50 d increased during years with larger snow accumulation and larger inflow peff rates for example r 0 71 in 2011 and r 0 44 in 2012 the direct relationship between peff and the ywf correlation coefficient r ywf p e f f is significant r 0 84 p 0 01 because it further suggests that young water mobilization is a function of wet conditions and that there is less young water mobilization under dry conditions fig 7 illustrates the relationship between young water t 1 y and old water t 1 5y based on the inflow and outflow distributions that contribute to streamflow as a function of peff the peff for the inflow year is defined by the year it enters the watershed whereas the peff for the outflow year refers to the peff related to the year of discharge at the annual scale of analysis inflow year and outflow year are equivalent for t 1 y for old water t 1 5 y we investigated two cases for the first case we investigated how much of the water that entered the system for a given year e g year 2011 left the system in 1 to 5 years as old water for the second we investigated how much old water that entered the system in the previous 1 to 5 years left the system in a given year e g year 2011 the results of first case indicated that young water t 1y was highly dependent on the amount of precipitation r 0 86 slope 0 20 p 0 01 fig 7 circle marker the amount of old water t 1 5 y leaving the system was also dependent on the magnitude of peff for the year that water entered the system but with a lower slope and lower significance r 0 49 slope 0 08 p 0 01 fig 7 cross markers than t 1y table 2 provides the amount of water in a given inflow year that leaves in future years for example in 2011 inflow peff 4 06 mm d 1 and q 2 85 mm d 1 the amount of water with age t 1 in 2011 was 0 70 mm d 1 or 17 inflow peff and 25 of total stream discharge for that year water that entered the basin in 2011 that left 1 to 5 years later was 0 39 mm d 1 or 10 of 2011 inflows whereas 73 of inflowing peff stayed in the basin longer than 5 years during 2012 a representative dry year peff 1 98 mm d 1 and streamflow was 1 41 mm d 1 water transported to the stream in 1 year was 0 27 mm d 1 this is less than half the volume of young water leaving in a wet year which accounts for a lower fraction of 2012 inflow peff 13 and of total stream discharge 19 compared with 2011 water that entered the basin in a dry year and left in 1 to 5 years was also less than that transported during a wet year summing to 0 16 mm d 1 or only 8 the inflow volume of 2012 the different transport ability in wet and dry years can also be explained by the hydrologic connectivity theory high annual peff input keeps deep flow paths active to release more water to discharge in contrast dry years with low peff lose a larger component of inflow to et leading to declines in groundwater storage and decreases in hydrologic connectivity subsequently less young water is flushed to the stream and more water remains in storage or moves slowly through the subsurface to be flushed in subsequent years we noticed that young water in discharge is more sensitive slope 0 20 circle markers to change in peff than old water slope 0 08 triangle markers indicating that the system prefers to release younger water with peff increases previous studies applying the sas approach on rain dominated hydrologic systems suggested the inverse storage effect in which watershed systems release predominantly younger water to stream discharge when groundwater storage is high or precipitation events are large benettin et al 2017 harman 2015 wilusz et al 2017 this phenomenon also appears to occur in snow dominated watersheds at both seasonal and annual timescales in the second case water originating from 1 to 5 years prior to 2011 and leaving as stream discharge in 2011 summed to 0 39 mm d 1 or 14 total stream discharge table 2 the remaining 61 of 2011 streamflow by volume older than 5 years was not captured by the model simulation period water originating 1 to 5 years prior to 2012 and released in 2012 as stream discharge was 0 14 mm d 1 this is less than half the magnitude of older water mobilized during a wet year and accounts for 10 of stream volume which is also less than a wet year we found that a given year s peff had better correlation to old water entering the system in the past 1 to 5 years and leaving the system within this given year r 0 96 fig 7 triangle markers than to the water entering the system this given year that contributed to future 1 to 5 years outflow r 0 49 fig 7 cross markers this indicates that the fraction of old water in the discharge depends more on the sufficiency of peff in the year when it leaves the system than in the year when it enters the system a recent study applying ensemble hydrograph separation kirchner 2018 supports our conclusion that young water fraction increases with precipitation sufficiency interestingly a previous study using a theoretical framework to estimate ttd heidbüchel et al 2012 showed different results in the study of heidbüchel et al 2012 estimated ttd using the same isotope δ 18o at two catchments with different precipitation sufficiencies one humid and one semiarid their results indicated that the wet catchment had less young water t 315 d leaving the system and more old water t 315 d leaving the system than the dry catchment this contradicts our conclusion further study at the east river basin using the sas model with spatial variations in precipitation will give us better insight into the spatiotemporal variations of ttd estimates we observed stream releases of approximately 20 to 25 of peff water as discharge in the first 50 days fig 6 and 40 of peff in 10 years this fraction is much lower than previous studies that used sas approaches in which over 40 very young water fraction in the discharge and 80 to 90 of inflow water left the systems in 10 years benettin et al 2017 harman 2015 wilusz et al 2017 one reason for this lower fraction for precipitation to become discharge is the size of system all the previous studies were conducted at small scale watersheds 0 9 3 5 km2 similarly previous work on the activation of temporary flow paths laudon et al 2004 and variations in hydrologic connectivity yang and chu 2013 were also conducted at small scale watersheds however this study was conducted at a much larger scale watershed 85 km2 where long and tortuous flow paths are likely to extend the transit time for inflow water to reach the outlet another reason is that unlike previous studies at rain dominated systems our study was conducted at a snow dominated system therefore the peff occurs primarily during snowmelt from mid march to mid june although we treat october 1 as the start of a water year the melt water actually only has less than half a year to leave the system as discharge to be considered young water i e it leaves the system in the same year rainwater infiltration between october and march at rain dominated watersheds is quickly transmitted to the stream outlet and therefore it has much more time to leave the system as discharge to be considered young water the melt water will lose a much higher fraction to et in the following summer season than the rainwater which travels in the system uniformly through the year which further decreases the fraction of melt water that leaves the system as discharge 4 3 stream discharge ttd as a function of climate this is the first application of the sas approach to a watershed scale snow dominated system we found that streamflow ttds respond differently to temperature increases between wet years and dry years we tested different scenarios by increasing the temperature 1 2 4 5 6 7 8 9 10 11 12 and 15 c to investigate the response of stream ttd fig 8 a shows the changes in fractions of inflow leaving the system with a water age of less than one year during wet years changes in streamflow ttds were buffered from temperature increases therefore the amount and fraction of young water released to discharge remained almost unchanged when temperature was increased up to 8 c this was because of a sufficient amount of peff to offset the increasing et loss due to temperature increases the amount of young water discharge was not appreciably changed however in the case of extreme temperature increasing by 15 c the young water fraction also declined by approximately 14 over the 10 c case this was because the sharply increasing et consumption due to extreme temperature increases exceeded the amount the peff can afford and therefore part of discharge was diminished to compensate extensive et loss in contrast stream discharge ttds under dry conditions are more sensitive to increased temperatures a 2 c increase in temperature reduced the fraction of inflow reaching the river in one year by 5 and a 15 c increase in temperature reduced young water in the streamflow by 46 with limited peff et increases diminished stream discharge lost groundwater storage offset some of the estimated reductions in streamflow but the added et losses resulted in a loss of younger discharge with t 1 y even with modest changes in temperature with more significant increases in temperature i e 10 c a larger fraction of infiltration was immobilized below the root zone with temperature increases the young water fraction in streamflow dropped nearly linearly as a function of the decline in the percentage of snowmelt in peff sm fig 8b we found that the slope of a dry year was much higher than a wet year 11 9 to 7 1 indicating that hydrologic partitioning during dry years is more sensitive to increasing temperature and the associated shift in precipitation type fig 9 shows the fraction of inflow exiting the system in future years given no change and a 10 c increase in temperature over historical conditions wet years see little change in the fraction of inflow peff leaving the system in future years when temperature increases by 10 c whereas dry years experience a significant reduction in the first year as well as a reduction in the fraction of water leaving the basin over the next 5 years water remaining in the subsurface more than 5 years undergoes no obvious change in peff leaving the system despite an increased water limitation et pet 1 refer to si dry years result in larger et loss to warming than wet years fig 9 with loses primarily at the expense of younger water t 1 y and to a lesser degree at the expense of old water t 1 5 y to effectively increase the mean residence time of water in the basin with increasing temperatures up to 10 c streamflow ages increased for a dry year but remained relatively unchanged for a wet year for the old water that entered system 1 to 5 years before the wet dry years we found that increasing temperature reduces the fraction of the inflow from previous years in the discharge and forces the water to stay longer in the system which leads more water to be lost as et fig 10 shows that a rise in temperature has little effect on streamflow age distributions in a wet year but will delay water leaving the system by more than 30 to 50 days or even longer in a dry year such a delay repeats in each dry year and accumulates to cause more old water to either stay in the system over a longer period or to be lost as et when temperatures were increased by 15 c streamflow t 1 y in a wet year was larger than with no warming in a dry year fig 8a however both wet and dry years showed declines in ages t 5 y and age distributions of streamflow increased relative to historical conditions fig 9 when the majority of peff shifted from snow to rain with extreme temperature increases beyond 10 c peff was delivered uniformly into the system as rain over the winter and spring as opposed a pulse of melt only in the spring which caused the water to reside in the system over a longer period especially in the dry years fig 10 subsequently the temporary activation of deep flow paths by spring melt no longer exists making the overall hydrologic connectivity decline and the fraction of young water t 1 and prior old water 1 5 y to be held in the basin over a longer period of time fig 9 this finding implies that temperature change plays a key role in drought propagation at snow dominated basins because lag response to temperature change varies between wet and dry conditions an increase up to 8 c in temperature more than historical conditions leads to little change in the fraction of the wet year s inflow exiting the system in the future five years but it significantly reduces the fraction of the dry year s inflow leaving the system in both the near future t 1 y and over a longer period 1 5 y fig 9 this means that years with limited precipitation are more sensitive to climate change in addition with an increasing fraction of inflow lost to et hydrologic connectivity is further decreased and more water remains in the subsurface and becomes old which propagates droughts in snow dominated basins even longer foster et al 2016 found that with warming energy budget increases reduced streamflow more than snow rain transitions a 4 c of uniform warming reduced streamflow 44 8 more than a complete shift in precipitation from snow to rain however our study showed that large reductions in annual streamflow did not occur until temperature increases exceeded 7 c fig s 18 furthermore our study showed variations in wet and dry years in terms of streamflow ttd the transit time decreased with small increases in temperature 2 c to 4 c in dry years but remained almost the same until temperature increases exceeded 8 c in wet years and a significant reduction of ttd only happened with extreme warming 15 c when precipitation shifted from snow to rain fig 8a this finding indicates that energy budget increases in dry years have a greater effect on ttd variations whereas snow rain transitions in wet years have a have a greater effect on ttd variations furthermore our study found that more inflow water was flushed from the system in wet years with extreme temperature increases than in dry years under historical conditions which suggests that the sufficiency of precipitation is a more significant factor in controlling ttds than energy budget and the type of precipitation 4 4 limitation of prms sas pest estimation and related future work no model can represent the full detail of this large scale snow dominated system although the sas pest simulated δ18o concentration cq agreed well with the observations during winter and spring snowmelt the agreement during the summer monsoon season was poor and highly overestimated fig 5c remondi et al 2018 found a similar poor agreement and attributed it to the tracer concentration values rapidly shifting toward the concentration of the groundwater storage after a rainfall event there are also other potential reasons for poor agreement in summer first during the summer monsoon season only the hydraulically connected storage controlled the shape of the sas function and drove discharge rather than the increasing total storage a coefficient needed to be added to the total discharge to represent the hydraulically connected storage to better fit the monsoon season however it was very difficult to estimate this coefficient with the limited observed δ18o concentration data particularly considering this coefficient was heterogeneous depending on the variations of subsurface properties across the catchment second rain during the summer monsoon was largely consumed by et which greatly affected tracer concentrations of water budget components but quantifying the uncertainty of et was very difficult mcdonnell et al 2010 without direct measured et or cet we had to use simulated et and rely on a simple uniform distribution for et in the sas model subsequently the strong consumption of rain by et in the summer may not have been well represented by the model leading to high uncertainty an introduction of et transit time distribution will help improve the estimates of streamflow ttd third high uncertainty in summer precipitation measurements was reported in recent mountain watershed studies hrachowitz and weiler 2011 daly et al 2017 our limited cj observation during strong summer rain event along with the prms estimated rain rate could have also introduced high uncertainty in the sas model results further limitations arose from assuming uniform precipitation land surface cover topography and soil hydraulic properties in this study therefore the spatial variations of temperature swe snowmelt rate and peff vegetation and root distribution elevation and slope subsurface permeability soil moisture content and flow paths on the seasonal and annual dynamics of ttds were not investigated however these factors may play key roles in controlling hydrologic connectivity water budget stream discharge and evapotranspiration variations considering the complicated climate ecological and terrestrial structure in snow dominated systems for example spatial patterns of snowmelt are largely determined by the distribution of swe at the start of the melt season anderton et al 2004 northeast facing slopes receive greater snowmelt inflow than southwest facing slopes during the spring at mountain basins kormos et al 2014 runoff and et at different elevations have various sensitivities in response to warming gilbert and maxwell 2018 introducing entropy in the standard deviation of slope effectively reduces the local hydraulic gradients loss due to spatial aggregation fang et al 2016 as vegetation density increases hydrologic connectivity decreases at hillslopes with high irradiance but increases at hillslopes with low irradiance emanuel et al 2014 snowmelt contributions to stream response to summer temperature changes is buffered at higher watersheds than lower watersheds lisi et al 2015 variations in soil saturation also significantly affect sas functions for example saturated groundwater tends to release younger water to the discharge whereas the vadose zone prefers older water additionally the influence of recharge rate on the ttd estimation is closely dependent on the heterogeneity of subsurface hydraulic conductivity danesh yazdi et al 2018 a lack of representation of three dimensional heterogeneity in climate vegetation topography and subsurface properties may have hampered the ttd estimates in our prms sas pest model results therefore high resolution three dimensional climate and hydrologic models such as gsflow markstrom et al 2008 pflotran hammond et al 2014 and parflow clm maxwell and miller 2005 will be required to better understand the effect of spatiotemporal distribution variations of climate surface and subsurface parameters and quantify the hydrologic response in the future work uncertainty quantification of the impacts of climate change on snowmelt streamflow processes are also important to better understand streamflow ttd response to energy and water budget changes kudo et al 2017 5 conclusions in this study we coupled prms sas pest models to estimate water budget components simulate streamflow ttds and seasonal and yearly responses to hydrologic and climate changes at a high altitude snow dominated watershed in the east river basin the major findings of this study were i change in prms estimated water budget components was primarily restricted to dry years with insufficient peff input when temperature increased ii the inverse storage effect occurred in snow dominated systems between pre melt and spring snowmelt seasons as well as between wet and dry years seasonally more young water was released from storage during spring snowmelt season than winter pre melt season annually wet years with high peff contributed more young water in the stream discharge than dry years with water limitations iii dry year hydrology was more sensitive to climate change than wet year hydrology an increase of up to 10 c in temperature over the historical conditions led to little change in the fraction of the wet year s inflow exiting the system five years in the future but it significantly reduced the fraction of dry year inflow leaving the system for both young water t 1 y and old water 1 5 y with increasing temperature deep subsurface water was immobilized in dry years and an increasing fraction of inflow was lost to evapotranspiration which caused hydrologic connectivity to decrease further and more water to remain in the watershed propagating droughts in snow dominated basins iv energy budget increases had a greater effect on ttd variations in dry years whereas snow rain transitions had a greater effect ttd variations in wet years furthermore the sufficiency of precipitation was a more significant factor in controlling ttds than energy budget or the type of precipitation at this snow dominated watershed declaration of interests none acknowledgements work was supported by the united states geological survey through the national institute of water resources under grant cooperative agreement no g16ap00196 and the lawrence berkeley national laboratory s wfsfa through the u s department of energy office of science office of biological and environmental research under contract de ac02 05ch11231 special thanks to wendy brown for data collection efforts and markus bill at lbnl for analytical support appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 01 029 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6736,satellite products like all datasets are subject to errors and uncertainties due to inherent biases embedded in satellite precipitation estimates we present an error adjustment approach based on the statistical differences between satellite precipitation products and in situ observations observed errors employing two widely used error models namely that additive and the multiplicative error models in an attempt to assess their suitability for the error correction of satellite based daily precipitation estimates over northeast austria an error adjustment technique based on the concept of the copula is adopted and applied to correct the supplied precipitation fields it was found that imerg precipitation estimates improved after error adjustment when compared to original satellite precipitation estimate ospe the additive error model resulted in a better improvement by fitting the entire range of data when compared with the multiplicative error model moreover the additive error model extracted the error with more accuracy and produced a better estimation of their characteristics while the method based on the multiplicative error was less robust however the overall spatial dependence of the observed errors is reasonably preserved as that of the generated errors by copula in addition the validation results implied that the simulated realizations error adjusted band encompassed the observed data reasonably moreover the copula based simulations associated with the additive error model performed much better in comparison to the multiplicative error model overall by using the t copula model with an emphasis on the additive error model and imposing the simulated error fields on the ospe one may generate multiple realizations of precipitation fields keywords uncertainty analysis error adjustment copula additive error multiplicative error satellite precipitation imerg 1 introduction the quantification of precipitation and its spatio temporal variability is very important for understanding hydrological processes precipitation characteristics may be captured through traditional ground based rain gauges radars and or satellite precipitation estimate spe products high resolution spes provide an effective source of data i e uninterrupted effectively global coverage for hydro meteorological applications and water resource management particularly over economically developing regions where there is often a lack of or very sparse ground based observations in order to understand the hydrological processes and their associated uncertainties in ungauged catchments the development of hydrological models is vital abimbola et al 2017 the uncertainties vagueness and inaccuracy of hydro meteorological data results from errors in the measurement equipment and precipitation estimation models such errors indicate that hydrological studies may potentially be unreliable leading to water allocations using hydrologic data being inaccurate for future studies khazaei and hosseini 2015 the high costs related to the set up and maintenance of hydro meteorological monitoring networks constraints the number of conventional i e in situ stations that can be established despite improved technology the quality and reliability of measured hydro meteorological data are not always assured and the accompanying uncertainty is often significant behrangi et al 2011 used precipitation products as input to a rainfall runoff model to generate streamflow at different time scales over the mid size illinois river basin they found that the bias adjusted satellite precipitation products agreed well with gauge adjusted radar compared with their counterparts with no bias adjustment particularly in capturing the timing occurrence and magnitude of precipitation events sharifi et al 2018 evaluated daily and sub daily imerg data against rain gauge observation in northeast austria they showed imerg fr systematically underestimates moderate to extreme precipitation and overestimates light precipitation for different time scales when compared to rain gauges in this region reliable precipitation is essential for hydrologists and meteorologists as the uncertainties associated with precipitation estimates propagate through related modeling predictions aghakouchak et al 2011 therefore bias correction procedures are often applied to produce local scale information before it can be employed in decision making activities previous studies have confirmed that efforts are needed to assess the accuracy of spes and their associated uncertainty as they are of great significance to research and applications in hydrology and climate studies e g ciach et al 2007 hossain and huffman 2008 habib et al 2009a villarini et al 2008 dong et al 2005 sharifi et al 2018 however satellite products are subject to errors and uncertainties due to the indirect nature of their estimates accordingly this study is focused on the error correction and uncertainty analysis of the highest resolution integrated multi satellite retrievals for gpm global precipitation measurement a joint japanese space agency nasa mission also known as imerg over northeast austria the gpm constellation satellite product imerg covers latitudes 60 n s it has a spatial resolution of 0 1 and is updated every 30 min imerg consists of three products imerg fr currently aimed at research activities imerg rt early run and imerg rt late run the imerg algorithm is intended to inter calibrate merge and interpolate entire satellite microwave precipitation estimates together with microwave calibrated infrared ir satellite estimates and precipitation gauge analysis the need to quantify the uncertainties in such precipitation products is gaining strength especially as the volume of accessible data is rapidly increasing leading the scientific community to focus more on the degree of data reliability precipitation uncertainty affects many research fields such as climate change the hydrological cycle and weather climate prediction data assimilation as well as the calibration and validation of earth observing instruments the assessment of uncertainty greatly depends on the adopted error model to evaluate the uncertainties in precipitation measurements two types of error models have been broadly adopted the additive and the multiplicative the applicability of different error models results in different interpretations of uncertainty which may potentially impede direct comparisons between datasets and mislead end users tian et al 2013 the accuracy of spes has been assessed over different spatio temporal resolutions in a number of studies aghakouchak et al 2011 dezfuli et al 2017 gebere et al 2015 guo et al 2015 khodadoust et al 2016 mahmud et al 2015 moazami et al 2013 prakash et al 2016 sharifi et al 2016 2018 sungmin et al 2016 tian et al 2009 although the application of spes to hydro meteorological predictions and water resource management has been intensified in recent years the accuracy evaluation of spes at the required spatio temporal resolution is needed before use the variability in precipitation is often represented by the error in the amount of precipitation over space and time in addition to the magnitude of precipitation the general pattern and its location are also important aghakouchak et al 2011 foufoula georgiou and vuruputur 2001 hydrological and meteorological phenomena are known to be multidimensional and thus require multivariate analyses as well as knowledge of the conditional probability distributions among variables classic families of multivariate distributions are frequently used for modeling joint probability distributions of multiple random variables multivariate distributions such as bivariate normal log normal and gamma are built with several model parameters that illustrate the behavior of each random variable as well as the joint probability distribution itself the main disadvantage of such methods is that modeling the dependence structure among variables is not independent of the choice of the marginal distributions dupuis 2007 genest and favre 2007 therefore using such models may lead to unrealistic simulations germann et al 2006 as the spatial correlation of satellite and radar rainfall error is significant ciach et al 2007 habib et al 2009a the error term is assumed to be spatially correlated and copulas may be used to describe the dependence structure in general in situ precipitation data employed as the reference are collected from high density gauge networks in the study region in order to quantify the spes error using different members of the copula family in multivariate data extreme value analysis and modeling dependence structure has become popular in hydro meteorological analysis kelly and krzysztofowicz 1997 employed a meta gaussian approach to bivariate rainfall analysis and pointed out that the meta gaussian distribution is independent of marginals and hence may be applied to represent the dependence structure of bivariate variables de michele and salvadori 2003 modeled the intensity duration of rainfall events utilizing copulas favre et al 2004 used copulas in multivariate hydrological frequency analysis bárdossy 2006 and bárdossy and li 2008 applied the concept of copulas to the interpolation of groundwater quality criterions using the gaussian copula renard and lang 2007 investigated multivariate extreme value analysis and its application to hydrology schölzel and friederichs 2008 modeled multivariate non gaussian random variables with copulas kuhn et al 2007 described the spatio temporal dependence of weekly precipitation extremes using copulas serinaldi 2008 and villarini et al 2008 presented a model for radar rainfall estimation uncertainties by using bivariate mixed distributions and a copula based markov approach aghakouchak 2014 introduced a drought indicator to predict drought conditions over the united states balistrocchi et al 2017 identified the dependence structure between peak flow discharge and flood volume featuring hydrographs forcing a flood control reservoir by using copula function liu et al 2017 developed a copula based hydrological uncertainty processor for probabilistic flood forecasting pham 2016 developed a framework that allowed for generating coupled precipitation and evaporation time series based on vine copulas major developments in the theory and implementation of copulas may be found in schweizer 1991 salvadori and de michele 2007 and dall aglio et al 1991 one way to evaluate the spatio temporal uncertainty of spe products is to simulate an ensemble of precipitation fields containing a large number of realizations with each realization standing for a possible rainfall event aghakouchak 2010 hossain and anagnostou 2005 expanded a two dimensional satellite rainfall error model for satellite rain fields ensemble simulations they reported the joint spatial probability of the successful delineation of rainy and non rainy areas using bernoulli uniform distribution experiments with a correlated structure generated according to gaussian random fields they also simulated spes random error fields by monte carlo simulations of any given realization bellerby and sun 2005 designed a methodology to quantify the uncertainty of high resolution spes by generating probabilistic and ensemble representations of the measured precipitation field an extensive copula based simulation study for applications involving up to 100 variables was presented by dong and patton 2015 teo and grimes 2007 characterized an approach for uncertainty estimation of satellite based rainfall values utilizing ensemble generation of rainfall fields according to a stochastic calibration they obtained the spatial correlation structure within each ensemble member via geostatistical sequential simulations in all of the studies noted above geostatistical approaches and monte carlo simulations were used in order to generate spatially correlated random fields and ensemble members of the precipitation estimation error the ensemble based model is selected because it can provide a better quantification of the precipitation uncertainty in comparison to single best estimates however geostatistical based methods e g a simple variogram model or a covariance matrix have limitations for instance the data is assumed to display three main features dependency stationarity and gaussian distribution johnston 2004 in addition the spatial dependence structure of daily precipitation is too complex to be modeled by a simple correlation coefficient over the range of observed values where the observed values are low they tend to be scattered and intermittent exhibiting a poor spatial dependency by contrast where precipitation is high it tends to be spatially and temporally more dependent such interdependence which is related to the amount of precipitation requires an appropriate quantification technique bárdossy and pegram 2009 multivariate copulas may be a suitable choice hence in this work copulas representing joint cumulative distribution functions cdf are employed to describe the dependence structure of variables as well as to model multivariate random variables with different marginal distributions indeed one of the most attractive features of copulas is their ability to describe the dependence structure of a dataset independent of the marginal distribution joe 1997 nelson 2006 in recent years several studies dealing with application of different families of copula in hydrological and meteorological processes have been carried out aghakouchak et al 2010a grimaldi and serinaldi 2006 renard and lang 2007 wang et al 2010 in this study a bias corrected imerg product using a copula based ensemble generation approach is generated a multivariate t copula is employed to describe the dependence structure and to simulate multivariate satellite precipitation error fields error is measured against observed daily precipitation events over 48 0 1 0 1 pixels within the study region the methodology presented here is similar to that of moazami et al 2014 who used copulas to generate an ensemble of precipitation realizations however moazami et al 2014 used a gaussian copula based additive error model in order to generate an ensemble of precipitation realizations while in this study an error correction model for the imerg product is developed by adopting comparing both additive and multiplicative error models based on t copula overall by analyzing the error characteristics of precipitation algorithms the objective of this study goes beyond the mere validation of the imerg product this paper is organized into six sections in the following sections after a brief review of copula theory in section 2 the t copula family used in this study is introduced in more detail section 3 introduces the study area and data resources used the methodology is described in section 4 section 5 details the results and discussion and section 6 summarizes the conclusions and remarks 2 copulas 2 1 concept of copula copulas are joint cdfs that describe dependency among variables regardless of their marginal distribution joe 1997 nelson 2006 the relationship among random variables is defined through their joint distribution function as follows 1 c n u 1 u n p r u 1 u 1 u n u n where function c n is called a copula which is an n dimensional joint cdf of a multivariate random variables u u 1 u n such that u u i u n represent one realization and p r is the probability of the variables the copula is therefore a function that links the multivariate distribution f x 1 x n to its univariate marginal f x i x i sklar 1959 demonstrated that 2 c n f x 1 x 1 f x n x n f x 1 x n where a copula c of n random variables is defined as a multivariate cdf f on the n dimensional unit cube with uniform marginals 3 c 0 1 n 0 1 in the copula model defined in eq 2 it is possible to integrate different families of probability distributions this is the main advantage of this approach compared to standard multivariate models used in practice favre et al 2004 in addition copula can preserve the dependency among variables that are described with a correlation n by n matrix where n is the number of variables the sklar theorem indicates that for multivariate distributions the multivariate dependence structure and the univariate marginal distributions may be separated and hence the dependence structure can be represented by a copula independent of the marginals for proof and derivations interested readers are referred to sklar 1996 there are numerous families of copulas developed within different practical contexts each copula family has a number of parameters the main difference associated with different copulas is in the detail of the dependence they represent in this study an elliptical copula in particular a t copula is used for simulations for additional information regarding the different copula families the readers are referred to joe 1997 and nelson 2006 2 2 t copula the t copula also known as student copula is an elliptical copula based on the student distribution for modeling the dependencies of extremes the application of the gaussian copula may not be an appropriate choice while the tail dependence is observed in the data thus the t copula may be more appropriate frahm et al 2005 moazami et al 2014 schmidt and stadtmuller 2006 serinaldi 2009a 2009b the asymptotic dependent behavior of t copula is expected even when the variables are negatively correlated embrechts et al 2001 the t copula is expected to specify different ranks of correlation between the marginals the t copula copula is suitable when more than two dimensions variables are used demarta and mcneil 2004 renard and lang 2007 a number of studies have reported on the application of the t copula to describe the dependence between variables in multivariate distributions aghakouchak et al 2010a daneshkhah et al 2016 in principle the choice of a suitable copula for modeling a data set is not straightforward especially if the data set is not informative enough to provide relevant indications about the asymptotic dependence properties renard and lang 2007 the simulation of multivariate random fields may be performed based on any given copula interested readers are referred to salvadori and de michele 2007 consequently in this study as a first attempt to quantify and bias correct imerg data over northeast austria a multivariate t copula is employed to simulate multivariate satellite precipitation error fields as noted before since a copula is invariant to monotonic transformations of the variables the simulated random variables will have the same spatial dependence structure as that of the input data this is one of the main interesting features of using copulas for the simulation of spatially dependent random fields in the current study the copula parameter is estimated based on the observed errors in each pixel 3 study area and dataset 3 1 study area austria is situated in a temperate climatic zone under the influence of the atlantic climate altitude determines the precipitation pattern as shown by fig 1 where the central parts towards the west of the country may experience an average precipitation of over 2000 mm year while regions in east and northeast of austria are drier with less than 600 mm in annual precipitation hiebl et al 2011 moreover according to the köppen geiger classification updated by rubel et al fig 2 the cfb warm temperate no dry season and warm summer and dfb boreal no dry season and warm summer are the prevailing climates in northern and eastern austria rubel et al 2017 northeast austria consists of about 290 0 1 0 1 imerg pixels there are 55 operating synoptic stations across the study area fig 3 falling within 48 imerg pixels the study period covers march 2015 to january 2016 52 daily precipitation events which occurred across the region were identified such that all stations simultaneously recorded precipitation consequently the analyses were carried out for 52 daily events over 48 pixels in the study area we selected the daily time scale because the correlation between spe and in situ precipitation measurements is expected to decrease compared with that of the daily scale 3 2 dataset the reference dataset employed in the present study is based on daily rain gauge meteorological observations provided by the zentralanstalt für meteorologie und geodynamik zamg austria zamg operates a network of semi automatic stations across the country and provides quality controlled precipitation data the zamg stations have tipping bucket gauges and weighting rain gauges equipped with a heating system haiden et al 2011 before evaluating the precipitation data we used a second derivative filter to identify unrealistic rapid and isolated changes in the precipitation time series such a derivative filter is quite sensitive to noise which should be eliminated before using the data for analysis shapiro and stochman 2001 furthermore the outliers that were removed make up only four out of the 419 890 hourly data points the rain gauge precipitation data was therefore derived from the 55 synoptic stations during the 52 days with precipitation between 15 march 2015 and 31 january 2016 fig 3 the resolution of the rain gauge data is 0 1 mm so that any observation less than this threshold was taken to be a dry day comparisons were made between the ground precipitation data with the corresponding imerg pixel precipitation it is notable that in this area the precipitation pattern is not directly affected by altitude and the topography is moderate in cases where two or more stations fall within a single pixel the reference ground precipitation was obtained based on the average precipitation of the stations the spe product used in this study is taken from imerg fr version 04 aggregated to daily accumulation from its original half hourly dataset imerg is based on components from three prior multi satellite algorithms namely the tropical rainfall measuring mission trmm multi satellite precipitation analysis tmpa huffman et al 2007 the climate prediction center cpc morphing technique cmorph joyse et al 2004 and the precipitation estimation from remotely sensed information using artificial neural networks persiann sorooshian et al 2000 products imerg v04 covers the global latitude belt from 60 n to 60 s interested readers are referred to huffman et al 2017a 2017b for further details on the imerg product specifications 4 methodology in this study the error fields associated with spes are simulated on the basis of two error models described above using copula based random generators then in order to obtain an ensemble of error adjustment spe easpe the simulated error fields are imposed over the original satellite precipitation estimate ospe before any adjustments are made a general overview of the proposed approach is presented as follows first spes daily event errors over selected pixels using additive and multiplicative error models are derived consequently a multivariate t copula is fitted to those observed errors and random ensembles of error fields are generated afterwards generated error fields are imposed over ospes to produce ensembles of easpes and eventually the accuracy of simulated ensembles is assessed the procedure is presented as follows step 1 49 94 out of 52 precipitation events over 48 pixels are employed randomly in order to calibrate the ensembles of error fields while another 3 events 6 are left to validate the predictive skill of the simulation model step 2 the difference between station measurements used as the reference precipitation data and the spe in the corresponding pixel represents the so called observed error using these observed error values a 49 by 48 matrix is formed step 3 the best probability distribution function pdf is fitted to the observed error values in each pixel subsequently the cdfs of the observed errors are computed for each pixel step 4 the n dimensional multivariate t copula is fitted to the cdfs from the previous step since the error in each pixel is assumed to be a variable the dimension n of the t copula is 48 in other words the spatial dependence structure of the error values among the 48 pixels is captured by the copula the marginal pdf is constructed empirically for each pixel using the anderson darling goodness of fit test to statistically examine whether or not data is sampled from the fitted distribution at 5 significance level this criterion has demonstrated its usefulness in hydrological applications laio 2004 step 5 the t copula is employed to randomly generate an ensemble of error cdfs step 6 ensembles of error fields i e the inverse of randomly generated cdfs are obtained step 7 outlier data of the randomly generated ensembles are identified and removed step 8 the simulated multiple random error fields are imposed over the ospes this step results in 49 ensembles of error adjusted realizations of spes indeed each ensemble member represents a possible realization precipitation step 9 the significance of the 49 simulated ensembles is measured and the best simulated ensembles are identified step 10 the best simulated ensemble from the previous step is employed to validate the performance of the model for the three remaining daily events all three simulated realizations are evaluated using bias and root mean square error rmse statistical indices aghakouchak 2010 moazami et al 2014 outlier identification is important in many multivariate analysis applications either because there is some specific interest in finding anomalous observations or as a pre processing task before the application of some multivariate method in order to preserve the results from the possible negative influence of those observations it should be mentioned that in step 7 outlier data i e data that are located rather far from the center of the data distribution are identified using a multivariate outlier detection technique and subsequently removed from the generated error fields several distance measures may be implemented for such a task in this study the mahalanobis distance also known as the generalized squared distance is adopted to detect multivariate outliers the mahalanobis distance relies on the estimated parameters of the multivariate distribution interested readers are referred to ben gal 2010 hodge and austin 2004 and werner 2003 for extensive review and details of this procedure after the outliers are detected and removed the generated errors are imposed on the ospe in order to obtain an ensemble of easpes moreover with respect to step 3 instead of fitting a standard distribution function to the data the empirical cdf of observed error is applied to the uniformly simulated error values so that the simulated error values will have the same cdf as that of the observed this significant improvement helps to avoid overshoot simulating unrealistically large values which typically happens when a standard distribution function is fitted and used for simulations two types of error models have been extensively adopted in dealing with uncertainty of precipitation estimation the additive error model and the multiplicative error model eqs 4 and 5 in this study we assessed the applicability of both error models in the quantification of satellite based daily precipitation uncertainty many studies on spe products have used the additive error model e g ebert et al 2007 habib et al 2009a moazami et al 2014 shrestha 2011 as expressed by 4 additive e r r o r 1 n i 1 n p o i p s i where p o i is the value of a rain gauge observation for the ith daily event p s i is the value of satellite precipitation estimates for the ith daily event and n is the number of observed days other studies e g ciach et al 2007 hossain and anagnostou 2005 villarini et al 2008 have used the multiplicative error model to quantify simulate errors in radar or satellite based measurements this model is expressed as follows 5 multiplicative e r r o r 1 n i 1 n p s i 1 n i 1 n p o i it should be mention that the errors obtained from eqs 4 and 5 are computed over each pixel in fact the use of different error models leads to different quantification of uncertainties tian et al 2013 essentially the additive error model explains the error as the difference between the satellite value and the corresponding station value while the multiplicative error model defines the error as the ratio of the two eqs 6 and 7 describe the general error adjustment formulations associated with additive and multiplicative error models respectively 6 easpe i a d d ospe i error i 7 easpe i m l t ospe i error i where easpe i a d d and easpe i m l t are ensembles of the easpe in the ith pixel according to additive and multiplicative error model where ospe i is the ospe in ith pixel and error i is the randomly generated error fields in ith pixel in the current study framework for a single hit event both rain gauge and satellite report non zero precipitation over p 0 1 mm threshold one can correct the satellite estimation by using both additive and multiplicative models however for a single miss event rain gauge reports non zero precipitation while satellite reports no precipitation the multiplicative model leads to an indeterminate form 0 0 therefore in the case of miss events the additive model is more practical for the estimation of error adjusted precipitation in this study we only evaluated the hit events i e both station and satellite reporting a precipitation depth of 0 1 mm day threshold precipitation or more furthermore following the previous studies if a precipitation value becomes negative after error adjustment it would be set to zero in this study the ensemble approach is adopted to address the uncertainty associated with the easpe the output uncertainty based on the additive error model is quantified by the 60 percentage prediction uncertainty ppu band enveloped by 20 lower and 80 upper limits of the simulated ensemble the 60 ppu and 75 ppu bands associated with additive and multiplicative error models are used respectively as a result some 40 and 25 of inappropriate simulations corresponding to 60 ppu and 75 ppu bands were ignored respectively expecting that the ground observation data fall within the selected bands the 60 ppu and 75 ppu band were found appropriate after conduction a sensitivity analysis within the additive and multiplicative error model frameworks the prediction uncertainty band may be evaluated by p factor and d factor indices abbaspour et al 2007 in this study the p factor is the percentage of pixels bracketed by the 60 ppu and 75 ppu bands corresponding to the additive and multiplicative error models respectively for example a p factor of 50 indicates that the 60 ppu band of the simulated ensemble brackets the observed values of 24 pixels the total number of studied pixels is 48 in other words 24 rain gauge values fall within the 60 ppu band the maximum value of p factor is 100 that ideally brackets all the observed data in the 60 ppu band the d factor is determined by 8 d f a c t o r 1 n i 1 n q i 80 q i 20 σ obs where q i 80 and q i 20 represent the upper and lower boundary of the 60 ppu in each pixel n is the number of pixels here 48 and σ obs stands for the standard deviation of the observed precipitation of a single daily event for all 48 pixels the d factor represents the ratio between the average thickness of the simulated band 60 ppu and 75 ppu and the standard deviation of the observed data it expresses the width of the uncertainty interval the smaller the d factor the closer the simulations are to the observations indeed the d factor denotes the strength of the simulation and ideally may be smaller than unity however in the practical cases a reasonable value for d factor is unity demonstrating that the simulated fields reproduce the standard deviation of observed data the goodness of calibration and prediction uncertainty is considered based on how close the average value of p factor is to 100 and the d factor to 1 schuol et al 2008 as a greater p factor leads to a greater d factor often a trade off between the two must be sought it is noted that both the p factor and d factor are determined for a simulated ensemble of easpe associated with a single daily event within the framework presented here the procedure is implemented for several sets of randomly generated error fields consequently for each set of generated errors the average values of the p factor and d factor for 49 simulated ensembles are computed therefore several pairs of averaged p and d factors are obtained then an appropriate set among different sets of randomly generated errors is selected based on the best values of both the p and d factors in fact the selected set can simulate an ensemble of easpe that has two features simultaneously the ppu band brackets most of the observed data p factor approaching 100 abbaspour et al 2007 and the average distance between the upper and lower parts of the 60 ppu 75 ppu at 80 87 5 and 20 12 5 level corresponding to additive multiplicative error model s is as small as permissible indicating a better correspondence between simulation and observation fields one of the advantage of the proposed methodology lies in its easily application to other geographical regions moreover the proposed methodology beside the spatially downscaled precipitation may be applied for fulfilling the needs of various application such as natural hazard hydro meteorology agricultural and climate change studies where the need for more reliable precipitation data is of paramount importance 5 results and discussion the results are presented in three parts 1 evaluation of the easpes 2 spatial dependency analysis and 3 copula based uncertainty analysis and assessing suitability of error models 5 1 evaluation of the easpes in order to assess the accuracy of the simulated ensembles bias and rmse statistical indices were used on ospe and easpe satellite precipitation products by denoting the station observations as reference data note that the bias and rmse indices are computed for 49 out of 52 daily events over 48 pixels as discussed before an ensemble of easpe of any given daily non zero event is simulated by imposing copula based randomly generated error fields over the ospe of the same event thus for 49 selected daily events a set of 49 ensembles are simulated each of which consists of a large number of realizations each realization represents a possible daily precipitation event that may occur over the study domain in figs 4 and 5 the ospe and easpe indices represent the average bias and rmse values for all 49 daily non zero events in each pixel it may be observed that the easpe add is improved while easpe mlt does not show significant improvements and seems it has increased bias to larger positive values in northeast and decreased bias to larger negative values in the southwest of the study area although easpe mlt values rather have decreased the rmse in some pixels but it has also increased the rmse in pixels in the northeastern part of the study area the additive error model with a bias and rmse of 0 03 mm and 8 09 mm respectively performed better by fitting the overall range of the data compared with the multiplicative error model with 0 78 mm and 7 58 mm for the same indices respectively 5 2 spatial dependency since copulas are invariant to monotonic transformations the simulated random errors will have the same spatial dependence structure as that of the observed errors it should be mentioned that although cc is a measure of linear dependency between a pair of random variables numerous studies argued that estimation of the cc suffers from several shortcomings specially for precipitation analysis for example willmott 1984 proposed that cc is insensitive to additive and proportional differences that may exist between the two variables which causes a problem if cc is used as a performance measure legates and davis 1997 stated that the existence of extreme events will lead to a high estimate of cc that may obscure the true relationship over most of the range of observations therefore correlation estimates for precipitation patterns observed via a variety of sources may be affected by the distribution of the data and sample size effects another problem with the correlation analysis comes from the fact that extreme events are characterized by short intense precipitation periods often associated with localized convective cells however in this study the cc has been used to examine whether the spatial dependency is preserved by the copula therefore a comparison between all pair pixels of the observed error and simulated random error was conducted scatterplots of the copula based randomly generated and observed errors for pair pixels with the highest and lowest correlation coefficients are displayed in fig 6 with respect to the additive error model the highest cc values between each pixel pair pixels 36 and 38 were 0 94 and 0 93 while the lowest ccs 0 24 and 0 10 pixels 2 and 48 corresponding to the observed and generated errors respectively however for the multiplicative error model similar values were 0 84 and 0 85 pixels 24 and 25 while the lowest ccs pixels 1 and 11 were 0 10 and 0 26 for the observed and generated errors respectively moreover fig 7 displays the location of stations with lowest and highest cc this figure illustrates the cc varies with stations pixels distances as seen in fig 6 the correlations between the observed errors marked with orange symbols are reasonably preserved by the generated errors marked with blue symbols for both the highest and lowest cc values between the pairs of pixels mentioned above furthermore the scatterplots of the error values between previously mentioned pixels for the three validation events are presented and marked with black symbols note that the values of cc associated with the three validation set in fig 6 a d are 0 30 and 0 05 for additive and 0 22 and 0 09 for multiplicative error models respectively the simulated error fields will be spatially dependent due to the dominance of the underlying spatial dependence structure of spes it is notable that in this model the satellite estimates are agitated with error fields and thus the dependence structure of the satellite estimates will be preserved within the simulated fields to illustrate this the spearman correlation matrix is employed to assess the dependence structure of the simulated precipitation fields fig 8 a f compares the spatial correlation structure of observed and copula based simulated errors corresponding to both error models in this figure the 48 48 dimensional cc matrices are shown the copula simulation is performed properly as the correlations are similar to those of the observations the lack of a true representation of precipitation in space and time causes most error models to particularly neglect the spatial dependency inherent in satellite precipitation error fields a visual comparison of fig 8 confirms that the spatial correlation of error between rain gauges and ospe and rain gauges and easpe are close to each other ciach et al 2007 habib et al 2008 and adequate spatial correlation structure within each ensemble is preserved via the t copula simulation fig 8a shows the correlation matrices of 49 observed errors fig 8b presents one set of simulated error fields and fig 8c shows the difference between the observed and simulated precipitation error fields using the t copula model based on additive error model furthermore fig 8d displays the correlation matrices of 49 precipitation observed errors fig 8e shows one set of simulated errors and fig 8f shows the difference between the observed and simulated precipitation error fields using the t copula model based on the multiplicative error model it may be noted that there is a robust spatial correlation of error using the additive error model in comparison with the multiplicative error model however as may be seen in fig 8 there is scatter in correlation variation among different pair pixels and the estimated values become more biased likely due to sample size effect habib et al 2001 generally one can argue that a reasonable representation of dependence structure may be required to generate an ensemble of precipitation data with similar dependence structures as that of the precipitation estimates however it may not be possible to obtain multiple generated precipitation fields with the exact correlation matrix as that of the original field data nonetheless in accurate models the general dependence structure of the simulated fields should be similar to the dependence structure of the observed precipitation fields the reason for this is that if some neighboring pixels show high dependence in the precipitation map the same pixels in the simulated precipitation fields should also exhibit a similar form of dependence the presented model is also evaluated with respect to the distribution function of the ospe and easpe fig 9 a b shows the empirical cdf of the daily gauge measurements blue ospes green and easpes red as shown in fig 9a the cdf of the gauge measurements is closer to the cdf of the easpe add compared with ospe particularly for light moderate precipitation and after the 68 frequency level the cdf of easpe add is moving above the gauge s cdf moreover the ospe s cdf is well above that of the gauge precipitation in contrast as may be seen in fig 9b the result shows that the cdf of rain gauges precipitation up to the 60 frequency level when the precipitation rate is 7 mm lies below those of the ospe and easpe mlt while beyond the 60 frequency the easpe mlt s cdf would be almost the same as that of the gauge cdf in addition this result shows an overestimated frequency of precipitation by ospe easpe add when the precipitation rate is above 8 mm and easpe mlt before the precipitation rate is around 7 mm 5 3 copula based uncertainty analysis and assessing suitability of error models the reliability of the copula based error adjustment model proposed in this study is evaluated for three daily precipitation events that were not used in the ensembles simulation for this purpose an appropriate set of generated errors among all 49 events was imposed on the ospe associated with the three events in order to simulate three easpe ensembles it is noted that the average values of the p and d factors for the selected set of generated errors were 79 and 0 36 for the additive error model and 67 and 0 21 for the multiplicative error model respectively see table 1 as fig 10 illustrates for each event the simulated ensemble is compared with the station observations in fig 11 a and b the average values of the bias and rmse of the three validated events over each pixel are illustrated in addition the error values associated with the validated events in each pixel for both error models are exhibited in appendix a the ospe and easpe error indices were obtained in comparison with the station data note that the easpe indices are computed based on the 50 quantile of simulated ensembles clearly the indices are improved after error adjustment of the satellite estimates in fig 10 solid blue lines solid red lines gray areas and solid green lines denote the ospes the station precipitation the 60 ppu and 75 ppu bands corresponding to additive and multiplicative error models of simulated realizations of easpes and the 50 quantiles of simulated realizations respectively as seen in fig 10 the simulated realizations of events 1 2 and 3 yielded a p factor of 75 65 and 98 for easpe add and 65 52 and 83 for easpe mlt respectively this figure indicates that the 60 ppu and 75 ppu band of the simulated ensemble bracketed the observed values of 36 31 and 47 pixels for easpe add and 31 25 and 40 pixels for easpe mlt respectively similarly d factor values of 0 59 and 0 33 for events 2 and 3 respectively demonstrate reasonable agreement for easpe add moreover the simulations via the additive error model perform much better in comparison with the multiplicative error model table 1 also summarizes the averages of bias rmse p and d factors of the three validation events based on additive and multiplicative error models over all 48 pixels the multiplicative error model produces larger errors for higher precipitation depths thus leading to unrealistic magnitude for the higher precipitation events however for each validation event there are a number of pixels where observed data fall outside of the simulated ensembles fig 11a b presents the average bias and rmse values of ospe easpe add and easpe mlt corresponding to three validation events respectively these indices are computed for the three daily events over the 48 pixels it is notable that the values of bias and rmse associated with the osre and easpes are the average values of the three daily events over each pixel as a result the estimates from the imerg satellite product are improved after error adjustment 6 conclusions the quantification of precipitation and its spatio temporal variability is very important for reliable hydro meteorological modeling however there are uncertainties in the precipitation values used as key input data in the models and these uncertainties will propagate throughout the employed hydro meteorological models in situ observations are often limited over highlands remote areas and oceans however currently available satellite precipitation products can potentially provide the precipitation estimation needed for hydro meteorological applications unlike traditional gauge measurements remotely sensed precipitation estimates capture the patterns of precipitation spatial variability although they are subject to various errors from different sources one way to assess spatial uncertainty of spe products is to simulate an ensemble of precipitation fields consisting of a large number of realizations as precipitation varies over space and time similarities in the spatial structure between generated and observation fields can be an important feature of precipitation simulation models therefore a copula based model that preserves the spatial dependency among variables independent of their marginals would be a useful tool in the simulation of multivariate random precipitation fields in this study the uncertainties associated with a high resolution spe product imerg fr v04 were quantified through a copula based model linked with additive and multiplicative error models in order to measure the robustness of the easpe simulated realizations p and d factors were computed for each simulated ensemble in light of observed data using p and d factors one can quantitatively predict the uncertainty associated with the easpes furthermore since each set of randomly generated errors resulted in an individual pair of p and d factors for simulated ensemble 49 sets of error fields were generated randomly while the most suitable set was selected based on the best pair of p and d factor values this procedure may lead to a more accurate simulation of ensembles based on bias and rmse error indices the presented framework was able to improve the spes considerably in addition the validation stage implied that the error adjusted band of the simulated realizations encompassed the observed data reasonably moreover by fitting the whole data range the simulations associated with the additive error model performed much better than the multiplicative error model the results also confirmed that the spatial correlation of error was not negligible adequate spatial correlation structures within each ensemble are preserved via the t copula in addition the results demonstrated that the additive error model was superior to the multiplicative error model overall the results presented here indicate that by using a t copula copula based model with an emphasis on an additive error model one can generate multiple realizations of precipitation fields through the simulation of error fields it is notable that in the presented copula based model instead of fitting a standard distribution function to the data the empirical cdf of the observed error is applied to the uniformly simulated error values so that the simulated error values will have the same cdf as that of the observed this avoids the effect of marginal distribution functions on copulas which typically happens when a standard distribution function is fitted alidoost et al 2017 in addition in ideal situations more than one gauge per single spe pixel should be used to provide reliable estimates of the error having only one gauge per pixel produces the point area effect which may be significant in highly variable events habib et al 2009b such a limitation may be addressed through downscaling we need to emphasize that the presented model is meant to describe random error stochastic sources of uncertainty associated with the spes and does not address systematic error bias involved in the quantification of precipitation uncertainty precipitation data may be subject to physical biases and may require further attempts to remove correct physical biases aghakouchak et al 2010b moreover as the number of events decline the sample size of the observed error decreases this may though not necessarily result in a narrower range of error one can intuitively conclude that any change in the error range and thus the distribution of error will also affect the estimated uncertainty in other words an insufficient precipitation sample size will lead to lower easpe robustness berg et al 2012 boé et al 2007 another cause might be due to seasonality in the data as well as the precipitation types therefore it is expected that improved accuracy may be warranted in adopting a denser station network and or using satellite products of finer spatial resolution with longer time series data availability in addition rain gauge measurement errors due to rainfall intensity wind induced undercatch precipitation type and particle falling velocities and the aerodynamic properties of a particular type of gauge could be other causes of uncertainty of spes when faired against rain gauge values an interesting issue for future research which may potentially improve the presented framework is to investigate the dependence of precipitation uncertainty on precipitation regime e g convective stratiform in different topographic regions finally the presented models are to be investigated for their robustness and transferability over different time scales acknowledgments this research was funded by abschlussstipendium from the university of vienna appendix a see table a1 
6736,satellite products like all datasets are subject to errors and uncertainties due to inherent biases embedded in satellite precipitation estimates we present an error adjustment approach based on the statistical differences between satellite precipitation products and in situ observations observed errors employing two widely used error models namely that additive and the multiplicative error models in an attempt to assess their suitability for the error correction of satellite based daily precipitation estimates over northeast austria an error adjustment technique based on the concept of the copula is adopted and applied to correct the supplied precipitation fields it was found that imerg precipitation estimates improved after error adjustment when compared to original satellite precipitation estimate ospe the additive error model resulted in a better improvement by fitting the entire range of data when compared with the multiplicative error model moreover the additive error model extracted the error with more accuracy and produced a better estimation of their characteristics while the method based on the multiplicative error was less robust however the overall spatial dependence of the observed errors is reasonably preserved as that of the generated errors by copula in addition the validation results implied that the simulated realizations error adjusted band encompassed the observed data reasonably moreover the copula based simulations associated with the additive error model performed much better in comparison to the multiplicative error model overall by using the t copula model with an emphasis on the additive error model and imposing the simulated error fields on the ospe one may generate multiple realizations of precipitation fields keywords uncertainty analysis error adjustment copula additive error multiplicative error satellite precipitation imerg 1 introduction the quantification of precipitation and its spatio temporal variability is very important for understanding hydrological processes precipitation characteristics may be captured through traditional ground based rain gauges radars and or satellite precipitation estimate spe products high resolution spes provide an effective source of data i e uninterrupted effectively global coverage for hydro meteorological applications and water resource management particularly over economically developing regions where there is often a lack of or very sparse ground based observations in order to understand the hydrological processes and their associated uncertainties in ungauged catchments the development of hydrological models is vital abimbola et al 2017 the uncertainties vagueness and inaccuracy of hydro meteorological data results from errors in the measurement equipment and precipitation estimation models such errors indicate that hydrological studies may potentially be unreliable leading to water allocations using hydrologic data being inaccurate for future studies khazaei and hosseini 2015 the high costs related to the set up and maintenance of hydro meteorological monitoring networks constraints the number of conventional i e in situ stations that can be established despite improved technology the quality and reliability of measured hydro meteorological data are not always assured and the accompanying uncertainty is often significant behrangi et al 2011 used precipitation products as input to a rainfall runoff model to generate streamflow at different time scales over the mid size illinois river basin they found that the bias adjusted satellite precipitation products agreed well with gauge adjusted radar compared with their counterparts with no bias adjustment particularly in capturing the timing occurrence and magnitude of precipitation events sharifi et al 2018 evaluated daily and sub daily imerg data against rain gauge observation in northeast austria they showed imerg fr systematically underestimates moderate to extreme precipitation and overestimates light precipitation for different time scales when compared to rain gauges in this region reliable precipitation is essential for hydrologists and meteorologists as the uncertainties associated with precipitation estimates propagate through related modeling predictions aghakouchak et al 2011 therefore bias correction procedures are often applied to produce local scale information before it can be employed in decision making activities previous studies have confirmed that efforts are needed to assess the accuracy of spes and their associated uncertainty as they are of great significance to research and applications in hydrology and climate studies e g ciach et al 2007 hossain and huffman 2008 habib et al 2009a villarini et al 2008 dong et al 2005 sharifi et al 2018 however satellite products are subject to errors and uncertainties due to the indirect nature of their estimates accordingly this study is focused on the error correction and uncertainty analysis of the highest resolution integrated multi satellite retrievals for gpm global precipitation measurement a joint japanese space agency nasa mission also known as imerg over northeast austria the gpm constellation satellite product imerg covers latitudes 60 n s it has a spatial resolution of 0 1 and is updated every 30 min imerg consists of three products imerg fr currently aimed at research activities imerg rt early run and imerg rt late run the imerg algorithm is intended to inter calibrate merge and interpolate entire satellite microwave precipitation estimates together with microwave calibrated infrared ir satellite estimates and precipitation gauge analysis the need to quantify the uncertainties in such precipitation products is gaining strength especially as the volume of accessible data is rapidly increasing leading the scientific community to focus more on the degree of data reliability precipitation uncertainty affects many research fields such as climate change the hydrological cycle and weather climate prediction data assimilation as well as the calibration and validation of earth observing instruments the assessment of uncertainty greatly depends on the adopted error model to evaluate the uncertainties in precipitation measurements two types of error models have been broadly adopted the additive and the multiplicative the applicability of different error models results in different interpretations of uncertainty which may potentially impede direct comparisons between datasets and mislead end users tian et al 2013 the accuracy of spes has been assessed over different spatio temporal resolutions in a number of studies aghakouchak et al 2011 dezfuli et al 2017 gebere et al 2015 guo et al 2015 khodadoust et al 2016 mahmud et al 2015 moazami et al 2013 prakash et al 2016 sharifi et al 2016 2018 sungmin et al 2016 tian et al 2009 although the application of spes to hydro meteorological predictions and water resource management has been intensified in recent years the accuracy evaluation of spes at the required spatio temporal resolution is needed before use the variability in precipitation is often represented by the error in the amount of precipitation over space and time in addition to the magnitude of precipitation the general pattern and its location are also important aghakouchak et al 2011 foufoula georgiou and vuruputur 2001 hydrological and meteorological phenomena are known to be multidimensional and thus require multivariate analyses as well as knowledge of the conditional probability distributions among variables classic families of multivariate distributions are frequently used for modeling joint probability distributions of multiple random variables multivariate distributions such as bivariate normal log normal and gamma are built with several model parameters that illustrate the behavior of each random variable as well as the joint probability distribution itself the main disadvantage of such methods is that modeling the dependence structure among variables is not independent of the choice of the marginal distributions dupuis 2007 genest and favre 2007 therefore using such models may lead to unrealistic simulations germann et al 2006 as the spatial correlation of satellite and radar rainfall error is significant ciach et al 2007 habib et al 2009a the error term is assumed to be spatially correlated and copulas may be used to describe the dependence structure in general in situ precipitation data employed as the reference are collected from high density gauge networks in the study region in order to quantify the spes error using different members of the copula family in multivariate data extreme value analysis and modeling dependence structure has become popular in hydro meteorological analysis kelly and krzysztofowicz 1997 employed a meta gaussian approach to bivariate rainfall analysis and pointed out that the meta gaussian distribution is independent of marginals and hence may be applied to represent the dependence structure of bivariate variables de michele and salvadori 2003 modeled the intensity duration of rainfall events utilizing copulas favre et al 2004 used copulas in multivariate hydrological frequency analysis bárdossy 2006 and bárdossy and li 2008 applied the concept of copulas to the interpolation of groundwater quality criterions using the gaussian copula renard and lang 2007 investigated multivariate extreme value analysis and its application to hydrology schölzel and friederichs 2008 modeled multivariate non gaussian random variables with copulas kuhn et al 2007 described the spatio temporal dependence of weekly precipitation extremes using copulas serinaldi 2008 and villarini et al 2008 presented a model for radar rainfall estimation uncertainties by using bivariate mixed distributions and a copula based markov approach aghakouchak 2014 introduced a drought indicator to predict drought conditions over the united states balistrocchi et al 2017 identified the dependence structure between peak flow discharge and flood volume featuring hydrographs forcing a flood control reservoir by using copula function liu et al 2017 developed a copula based hydrological uncertainty processor for probabilistic flood forecasting pham 2016 developed a framework that allowed for generating coupled precipitation and evaporation time series based on vine copulas major developments in the theory and implementation of copulas may be found in schweizer 1991 salvadori and de michele 2007 and dall aglio et al 1991 one way to evaluate the spatio temporal uncertainty of spe products is to simulate an ensemble of precipitation fields containing a large number of realizations with each realization standing for a possible rainfall event aghakouchak 2010 hossain and anagnostou 2005 expanded a two dimensional satellite rainfall error model for satellite rain fields ensemble simulations they reported the joint spatial probability of the successful delineation of rainy and non rainy areas using bernoulli uniform distribution experiments with a correlated structure generated according to gaussian random fields they also simulated spes random error fields by monte carlo simulations of any given realization bellerby and sun 2005 designed a methodology to quantify the uncertainty of high resolution spes by generating probabilistic and ensemble representations of the measured precipitation field an extensive copula based simulation study for applications involving up to 100 variables was presented by dong and patton 2015 teo and grimes 2007 characterized an approach for uncertainty estimation of satellite based rainfall values utilizing ensemble generation of rainfall fields according to a stochastic calibration they obtained the spatial correlation structure within each ensemble member via geostatistical sequential simulations in all of the studies noted above geostatistical approaches and monte carlo simulations were used in order to generate spatially correlated random fields and ensemble members of the precipitation estimation error the ensemble based model is selected because it can provide a better quantification of the precipitation uncertainty in comparison to single best estimates however geostatistical based methods e g a simple variogram model or a covariance matrix have limitations for instance the data is assumed to display three main features dependency stationarity and gaussian distribution johnston 2004 in addition the spatial dependence structure of daily precipitation is too complex to be modeled by a simple correlation coefficient over the range of observed values where the observed values are low they tend to be scattered and intermittent exhibiting a poor spatial dependency by contrast where precipitation is high it tends to be spatially and temporally more dependent such interdependence which is related to the amount of precipitation requires an appropriate quantification technique bárdossy and pegram 2009 multivariate copulas may be a suitable choice hence in this work copulas representing joint cumulative distribution functions cdf are employed to describe the dependence structure of variables as well as to model multivariate random variables with different marginal distributions indeed one of the most attractive features of copulas is their ability to describe the dependence structure of a dataset independent of the marginal distribution joe 1997 nelson 2006 in recent years several studies dealing with application of different families of copula in hydrological and meteorological processes have been carried out aghakouchak et al 2010a grimaldi and serinaldi 2006 renard and lang 2007 wang et al 2010 in this study a bias corrected imerg product using a copula based ensemble generation approach is generated a multivariate t copula is employed to describe the dependence structure and to simulate multivariate satellite precipitation error fields error is measured against observed daily precipitation events over 48 0 1 0 1 pixels within the study region the methodology presented here is similar to that of moazami et al 2014 who used copulas to generate an ensemble of precipitation realizations however moazami et al 2014 used a gaussian copula based additive error model in order to generate an ensemble of precipitation realizations while in this study an error correction model for the imerg product is developed by adopting comparing both additive and multiplicative error models based on t copula overall by analyzing the error characteristics of precipitation algorithms the objective of this study goes beyond the mere validation of the imerg product this paper is organized into six sections in the following sections after a brief review of copula theory in section 2 the t copula family used in this study is introduced in more detail section 3 introduces the study area and data resources used the methodology is described in section 4 section 5 details the results and discussion and section 6 summarizes the conclusions and remarks 2 copulas 2 1 concept of copula copulas are joint cdfs that describe dependency among variables regardless of their marginal distribution joe 1997 nelson 2006 the relationship among random variables is defined through their joint distribution function as follows 1 c n u 1 u n p r u 1 u 1 u n u n where function c n is called a copula which is an n dimensional joint cdf of a multivariate random variables u u 1 u n such that u u i u n represent one realization and p r is the probability of the variables the copula is therefore a function that links the multivariate distribution f x 1 x n to its univariate marginal f x i x i sklar 1959 demonstrated that 2 c n f x 1 x 1 f x n x n f x 1 x n where a copula c of n random variables is defined as a multivariate cdf f on the n dimensional unit cube with uniform marginals 3 c 0 1 n 0 1 in the copula model defined in eq 2 it is possible to integrate different families of probability distributions this is the main advantage of this approach compared to standard multivariate models used in practice favre et al 2004 in addition copula can preserve the dependency among variables that are described with a correlation n by n matrix where n is the number of variables the sklar theorem indicates that for multivariate distributions the multivariate dependence structure and the univariate marginal distributions may be separated and hence the dependence structure can be represented by a copula independent of the marginals for proof and derivations interested readers are referred to sklar 1996 there are numerous families of copulas developed within different practical contexts each copula family has a number of parameters the main difference associated with different copulas is in the detail of the dependence they represent in this study an elliptical copula in particular a t copula is used for simulations for additional information regarding the different copula families the readers are referred to joe 1997 and nelson 2006 2 2 t copula the t copula also known as student copula is an elliptical copula based on the student distribution for modeling the dependencies of extremes the application of the gaussian copula may not be an appropriate choice while the tail dependence is observed in the data thus the t copula may be more appropriate frahm et al 2005 moazami et al 2014 schmidt and stadtmuller 2006 serinaldi 2009a 2009b the asymptotic dependent behavior of t copula is expected even when the variables are negatively correlated embrechts et al 2001 the t copula is expected to specify different ranks of correlation between the marginals the t copula copula is suitable when more than two dimensions variables are used demarta and mcneil 2004 renard and lang 2007 a number of studies have reported on the application of the t copula to describe the dependence between variables in multivariate distributions aghakouchak et al 2010a daneshkhah et al 2016 in principle the choice of a suitable copula for modeling a data set is not straightforward especially if the data set is not informative enough to provide relevant indications about the asymptotic dependence properties renard and lang 2007 the simulation of multivariate random fields may be performed based on any given copula interested readers are referred to salvadori and de michele 2007 consequently in this study as a first attempt to quantify and bias correct imerg data over northeast austria a multivariate t copula is employed to simulate multivariate satellite precipitation error fields as noted before since a copula is invariant to monotonic transformations of the variables the simulated random variables will have the same spatial dependence structure as that of the input data this is one of the main interesting features of using copulas for the simulation of spatially dependent random fields in the current study the copula parameter is estimated based on the observed errors in each pixel 3 study area and dataset 3 1 study area austria is situated in a temperate climatic zone under the influence of the atlantic climate altitude determines the precipitation pattern as shown by fig 1 where the central parts towards the west of the country may experience an average precipitation of over 2000 mm year while regions in east and northeast of austria are drier with less than 600 mm in annual precipitation hiebl et al 2011 moreover according to the köppen geiger classification updated by rubel et al fig 2 the cfb warm temperate no dry season and warm summer and dfb boreal no dry season and warm summer are the prevailing climates in northern and eastern austria rubel et al 2017 northeast austria consists of about 290 0 1 0 1 imerg pixels there are 55 operating synoptic stations across the study area fig 3 falling within 48 imerg pixels the study period covers march 2015 to january 2016 52 daily precipitation events which occurred across the region were identified such that all stations simultaneously recorded precipitation consequently the analyses were carried out for 52 daily events over 48 pixels in the study area we selected the daily time scale because the correlation between spe and in situ precipitation measurements is expected to decrease compared with that of the daily scale 3 2 dataset the reference dataset employed in the present study is based on daily rain gauge meteorological observations provided by the zentralanstalt für meteorologie und geodynamik zamg austria zamg operates a network of semi automatic stations across the country and provides quality controlled precipitation data the zamg stations have tipping bucket gauges and weighting rain gauges equipped with a heating system haiden et al 2011 before evaluating the precipitation data we used a second derivative filter to identify unrealistic rapid and isolated changes in the precipitation time series such a derivative filter is quite sensitive to noise which should be eliminated before using the data for analysis shapiro and stochman 2001 furthermore the outliers that were removed make up only four out of the 419 890 hourly data points the rain gauge precipitation data was therefore derived from the 55 synoptic stations during the 52 days with precipitation between 15 march 2015 and 31 january 2016 fig 3 the resolution of the rain gauge data is 0 1 mm so that any observation less than this threshold was taken to be a dry day comparisons were made between the ground precipitation data with the corresponding imerg pixel precipitation it is notable that in this area the precipitation pattern is not directly affected by altitude and the topography is moderate in cases where two or more stations fall within a single pixel the reference ground precipitation was obtained based on the average precipitation of the stations the spe product used in this study is taken from imerg fr version 04 aggregated to daily accumulation from its original half hourly dataset imerg is based on components from three prior multi satellite algorithms namely the tropical rainfall measuring mission trmm multi satellite precipitation analysis tmpa huffman et al 2007 the climate prediction center cpc morphing technique cmorph joyse et al 2004 and the precipitation estimation from remotely sensed information using artificial neural networks persiann sorooshian et al 2000 products imerg v04 covers the global latitude belt from 60 n to 60 s interested readers are referred to huffman et al 2017a 2017b for further details on the imerg product specifications 4 methodology in this study the error fields associated with spes are simulated on the basis of two error models described above using copula based random generators then in order to obtain an ensemble of error adjustment spe easpe the simulated error fields are imposed over the original satellite precipitation estimate ospe before any adjustments are made a general overview of the proposed approach is presented as follows first spes daily event errors over selected pixels using additive and multiplicative error models are derived consequently a multivariate t copula is fitted to those observed errors and random ensembles of error fields are generated afterwards generated error fields are imposed over ospes to produce ensembles of easpes and eventually the accuracy of simulated ensembles is assessed the procedure is presented as follows step 1 49 94 out of 52 precipitation events over 48 pixels are employed randomly in order to calibrate the ensembles of error fields while another 3 events 6 are left to validate the predictive skill of the simulation model step 2 the difference between station measurements used as the reference precipitation data and the spe in the corresponding pixel represents the so called observed error using these observed error values a 49 by 48 matrix is formed step 3 the best probability distribution function pdf is fitted to the observed error values in each pixel subsequently the cdfs of the observed errors are computed for each pixel step 4 the n dimensional multivariate t copula is fitted to the cdfs from the previous step since the error in each pixel is assumed to be a variable the dimension n of the t copula is 48 in other words the spatial dependence structure of the error values among the 48 pixels is captured by the copula the marginal pdf is constructed empirically for each pixel using the anderson darling goodness of fit test to statistically examine whether or not data is sampled from the fitted distribution at 5 significance level this criterion has demonstrated its usefulness in hydrological applications laio 2004 step 5 the t copula is employed to randomly generate an ensemble of error cdfs step 6 ensembles of error fields i e the inverse of randomly generated cdfs are obtained step 7 outlier data of the randomly generated ensembles are identified and removed step 8 the simulated multiple random error fields are imposed over the ospes this step results in 49 ensembles of error adjusted realizations of spes indeed each ensemble member represents a possible realization precipitation step 9 the significance of the 49 simulated ensembles is measured and the best simulated ensembles are identified step 10 the best simulated ensemble from the previous step is employed to validate the performance of the model for the three remaining daily events all three simulated realizations are evaluated using bias and root mean square error rmse statistical indices aghakouchak 2010 moazami et al 2014 outlier identification is important in many multivariate analysis applications either because there is some specific interest in finding anomalous observations or as a pre processing task before the application of some multivariate method in order to preserve the results from the possible negative influence of those observations it should be mentioned that in step 7 outlier data i e data that are located rather far from the center of the data distribution are identified using a multivariate outlier detection technique and subsequently removed from the generated error fields several distance measures may be implemented for such a task in this study the mahalanobis distance also known as the generalized squared distance is adopted to detect multivariate outliers the mahalanobis distance relies on the estimated parameters of the multivariate distribution interested readers are referred to ben gal 2010 hodge and austin 2004 and werner 2003 for extensive review and details of this procedure after the outliers are detected and removed the generated errors are imposed on the ospe in order to obtain an ensemble of easpes moreover with respect to step 3 instead of fitting a standard distribution function to the data the empirical cdf of observed error is applied to the uniformly simulated error values so that the simulated error values will have the same cdf as that of the observed this significant improvement helps to avoid overshoot simulating unrealistically large values which typically happens when a standard distribution function is fitted and used for simulations two types of error models have been extensively adopted in dealing with uncertainty of precipitation estimation the additive error model and the multiplicative error model eqs 4 and 5 in this study we assessed the applicability of both error models in the quantification of satellite based daily precipitation uncertainty many studies on spe products have used the additive error model e g ebert et al 2007 habib et al 2009a moazami et al 2014 shrestha 2011 as expressed by 4 additive e r r o r 1 n i 1 n p o i p s i where p o i is the value of a rain gauge observation for the ith daily event p s i is the value of satellite precipitation estimates for the ith daily event and n is the number of observed days other studies e g ciach et al 2007 hossain and anagnostou 2005 villarini et al 2008 have used the multiplicative error model to quantify simulate errors in radar or satellite based measurements this model is expressed as follows 5 multiplicative e r r o r 1 n i 1 n p s i 1 n i 1 n p o i it should be mention that the errors obtained from eqs 4 and 5 are computed over each pixel in fact the use of different error models leads to different quantification of uncertainties tian et al 2013 essentially the additive error model explains the error as the difference between the satellite value and the corresponding station value while the multiplicative error model defines the error as the ratio of the two eqs 6 and 7 describe the general error adjustment formulations associated with additive and multiplicative error models respectively 6 easpe i a d d ospe i error i 7 easpe i m l t ospe i error i where easpe i a d d and easpe i m l t are ensembles of the easpe in the ith pixel according to additive and multiplicative error model where ospe i is the ospe in ith pixel and error i is the randomly generated error fields in ith pixel in the current study framework for a single hit event both rain gauge and satellite report non zero precipitation over p 0 1 mm threshold one can correct the satellite estimation by using both additive and multiplicative models however for a single miss event rain gauge reports non zero precipitation while satellite reports no precipitation the multiplicative model leads to an indeterminate form 0 0 therefore in the case of miss events the additive model is more practical for the estimation of error adjusted precipitation in this study we only evaluated the hit events i e both station and satellite reporting a precipitation depth of 0 1 mm day threshold precipitation or more furthermore following the previous studies if a precipitation value becomes negative after error adjustment it would be set to zero in this study the ensemble approach is adopted to address the uncertainty associated with the easpe the output uncertainty based on the additive error model is quantified by the 60 percentage prediction uncertainty ppu band enveloped by 20 lower and 80 upper limits of the simulated ensemble the 60 ppu and 75 ppu bands associated with additive and multiplicative error models are used respectively as a result some 40 and 25 of inappropriate simulations corresponding to 60 ppu and 75 ppu bands were ignored respectively expecting that the ground observation data fall within the selected bands the 60 ppu and 75 ppu band were found appropriate after conduction a sensitivity analysis within the additive and multiplicative error model frameworks the prediction uncertainty band may be evaluated by p factor and d factor indices abbaspour et al 2007 in this study the p factor is the percentage of pixels bracketed by the 60 ppu and 75 ppu bands corresponding to the additive and multiplicative error models respectively for example a p factor of 50 indicates that the 60 ppu band of the simulated ensemble brackets the observed values of 24 pixels the total number of studied pixels is 48 in other words 24 rain gauge values fall within the 60 ppu band the maximum value of p factor is 100 that ideally brackets all the observed data in the 60 ppu band the d factor is determined by 8 d f a c t o r 1 n i 1 n q i 80 q i 20 σ obs where q i 80 and q i 20 represent the upper and lower boundary of the 60 ppu in each pixel n is the number of pixels here 48 and σ obs stands for the standard deviation of the observed precipitation of a single daily event for all 48 pixels the d factor represents the ratio between the average thickness of the simulated band 60 ppu and 75 ppu and the standard deviation of the observed data it expresses the width of the uncertainty interval the smaller the d factor the closer the simulations are to the observations indeed the d factor denotes the strength of the simulation and ideally may be smaller than unity however in the practical cases a reasonable value for d factor is unity demonstrating that the simulated fields reproduce the standard deviation of observed data the goodness of calibration and prediction uncertainty is considered based on how close the average value of p factor is to 100 and the d factor to 1 schuol et al 2008 as a greater p factor leads to a greater d factor often a trade off between the two must be sought it is noted that both the p factor and d factor are determined for a simulated ensemble of easpe associated with a single daily event within the framework presented here the procedure is implemented for several sets of randomly generated error fields consequently for each set of generated errors the average values of the p factor and d factor for 49 simulated ensembles are computed therefore several pairs of averaged p and d factors are obtained then an appropriate set among different sets of randomly generated errors is selected based on the best values of both the p and d factors in fact the selected set can simulate an ensemble of easpe that has two features simultaneously the ppu band brackets most of the observed data p factor approaching 100 abbaspour et al 2007 and the average distance between the upper and lower parts of the 60 ppu 75 ppu at 80 87 5 and 20 12 5 level corresponding to additive multiplicative error model s is as small as permissible indicating a better correspondence between simulation and observation fields one of the advantage of the proposed methodology lies in its easily application to other geographical regions moreover the proposed methodology beside the spatially downscaled precipitation may be applied for fulfilling the needs of various application such as natural hazard hydro meteorology agricultural and climate change studies where the need for more reliable precipitation data is of paramount importance 5 results and discussion the results are presented in three parts 1 evaluation of the easpes 2 spatial dependency analysis and 3 copula based uncertainty analysis and assessing suitability of error models 5 1 evaluation of the easpes in order to assess the accuracy of the simulated ensembles bias and rmse statistical indices were used on ospe and easpe satellite precipitation products by denoting the station observations as reference data note that the bias and rmse indices are computed for 49 out of 52 daily events over 48 pixels as discussed before an ensemble of easpe of any given daily non zero event is simulated by imposing copula based randomly generated error fields over the ospe of the same event thus for 49 selected daily events a set of 49 ensembles are simulated each of which consists of a large number of realizations each realization represents a possible daily precipitation event that may occur over the study domain in figs 4 and 5 the ospe and easpe indices represent the average bias and rmse values for all 49 daily non zero events in each pixel it may be observed that the easpe add is improved while easpe mlt does not show significant improvements and seems it has increased bias to larger positive values in northeast and decreased bias to larger negative values in the southwest of the study area although easpe mlt values rather have decreased the rmse in some pixels but it has also increased the rmse in pixels in the northeastern part of the study area the additive error model with a bias and rmse of 0 03 mm and 8 09 mm respectively performed better by fitting the overall range of the data compared with the multiplicative error model with 0 78 mm and 7 58 mm for the same indices respectively 5 2 spatial dependency since copulas are invariant to monotonic transformations the simulated random errors will have the same spatial dependence structure as that of the observed errors it should be mentioned that although cc is a measure of linear dependency between a pair of random variables numerous studies argued that estimation of the cc suffers from several shortcomings specially for precipitation analysis for example willmott 1984 proposed that cc is insensitive to additive and proportional differences that may exist between the two variables which causes a problem if cc is used as a performance measure legates and davis 1997 stated that the existence of extreme events will lead to a high estimate of cc that may obscure the true relationship over most of the range of observations therefore correlation estimates for precipitation patterns observed via a variety of sources may be affected by the distribution of the data and sample size effects another problem with the correlation analysis comes from the fact that extreme events are characterized by short intense precipitation periods often associated with localized convective cells however in this study the cc has been used to examine whether the spatial dependency is preserved by the copula therefore a comparison between all pair pixels of the observed error and simulated random error was conducted scatterplots of the copula based randomly generated and observed errors for pair pixels with the highest and lowest correlation coefficients are displayed in fig 6 with respect to the additive error model the highest cc values between each pixel pair pixels 36 and 38 were 0 94 and 0 93 while the lowest ccs 0 24 and 0 10 pixels 2 and 48 corresponding to the observed and generated errors respectively however for the multiplicative error model similar values were 0 84 and 0 85 pixels 24 and 25 while the lowest ccs pixels 1 and 11 were 0 10 and 0 26 for the observed and generated errors respectively moreover fig 7 displays the location of stations with lowest and highest cc this figure illustrates the cc varies with stations pixels distances as seen in fig 6 the correlations between the observed errors marked with orange symbols are reasonably preserved by the generated errors marked with blue symbols for both the highest and lowest cc values between the pairs of pixels mentioned above furthermore the scatterplots of the error values between previously mentioned pixels for the three validation events are presented and marked with black symbols note that the values of cc associated with the three validation set in fig 6 a d are 0 30 and 0 05 for additive and 0 22 and 0 09 for multiplicative error models respectively the simulated error fields will be spatially dependent due to the dominance of the underlying spatial dependence structure of spes it is notable that in this model the satellite estimates are agitated with error fields and thus the dependence structure of the satellite estimates will be preserved within the simulated fields to illustrate this the spearman correlation matrix is employed to assess the dependence structure of the simulated precipitation fields fig 8 a f compares the spatial correlation structure of observed and copula based simulated errors corresponding to both error models in this figure the 48 48 dimensional cc matrices are shown the copula simulation is performed properly as the correlations are similar to those of the observations the lack of a true representation of precipitation in space and time causes most error models to particularly neglect the spatial dependency inherent in satellite precipitation error fields a visual comparison of fig 8 confirms that the spatial correlation of error between rain gauges and ospe and rain gauges and easpe are close to each other ciach et al 2007 habib et al 2008 and adequate spatial correlation structure within each ensemble is preserved via the t copula simulation fig 8a shows the correlation matrices of 49 observed errors fig 8b presents one set of simulated error fields and fig 8c shows the difference between the observed and simulated precipitation error fields using the t copula model based on additive error model furthermore fig 8d displays the correlation matrices of 49 precipitation observed errors fig 8e shows one set of simulated errors and fig 8f shows the difference between the observed and simulated precipitation error fields using the t copula model based on the multiplicative error model it may be noted that there is a robust spatial correlation of error using the additive error model in comparison with the multiplicative error model however as may be seen in fig 8 there is scatter in correlation variation among different pair pixels and the estimated values become more biased likely due to sample size effect habib et al 2001 generally one can argue that a reasonable representation of dependence structure may be required to generate an ensemble of precipitation data with similar dependence structures as that of the precipitation estimates however it may not be possible to obtain multiple generated precipitation fields with the exact correlation matrix as that of the original field data nonetheless in accurate models the general dependence structure of the simulated fields should be similar to the dependence structure of the observed precipitation fields the reason for this is that if some neighboring pixels show high dependence in the precipitation map the same pixels in the simulated precipitation fields should also exhibit a similar form of dependence the presented model is also evaluated with respect to the distribution function of the ospe and easpe fig 9 a b shows the empirical cdf of the daily gauge measurements blue ospes green and easpes red as shown in fig 9a the cdf of the gauge measurements is closer to the cdf of the easpe add compared with ospe particularly for light moderate precipitation and after the 68 frequency level the cdf of easpe add is moving above the gauge s cdf moreover the ospe s cdf is well above that of the gauge precipitation in contrast as may be seen in fig 9b the result shows that the cdf of rain gauges precipitation up to the 60 frequency level when the precipitation rate is 7 mm lies below those of the ospe and easpe mlt while beyond the 60 frequency the easpe mlt s cdf would be almost the same as that of the gauge cdf in addition this result shows an overestimated frequency of precipitation by ospe easpe add when the precipitation rate is above 8 mm and easpe mlt before the precipitation rate is around 7 mm 5 3 copula based uncertainty analysis and assessing suitability of error models the reliability of the copula based error adjustment model proposed in this study is evaluated for three daily precipitation events that were not used in the ensembles simulation for this purpose an appropriate set of generated errors among all 49 events was imposed on the ospe associated with the three events in order to simulate three easpe ensembles it is noted that the average values of the p and d factors for the selected set of generated errors were 79 and 0 36 for the additive error model and 67 and 0 21 for the multiplicative error model respectively see table 1 as fig 10 illustrates for each event the simulated ensemble is compared with the station observations in fig 11 a and b the average values of the bias and rmse of the three validated events over each pixel are illustrated in addition the error values associated with the validated events in each pixel for both error models are exhibited in appendix a the ospe and easpe error indices were obtained in comparison with the station data note that the easpe indices are computed based on the 50 quantile of simulated ensembles clearly the indices are improved after error adjustment of the satellite estimates in fig 10 solid blue lines solid red lines gray areas and solid green lines denote the ospes the station precipitation the 60 ppu and 75 ppu bands corresponding to additive and multiplicative error models of simulated realizations of easpes and the 50 quantiles of simulated realizations respectively as seen in fig 10 the simulated realizations of events 1 2 and 3 yielded a p factor of 75 65 and 98 for easpe add and 65 52 and 83 for easpe mlt respectively this figure indicates that the 60 ppu and 75 ppu band of the simulated ensemble bracketed the observed values of 36 31 and 47 pixels for easpe add and 31 25 and 40 pixels for easpe mlt respectively similarly d factor values of 0 59 and 0 33 for events 2 and 3 respectively demonstrate reasonable agreement for easpe add moreover the simulations via the additive error model perform much better in comparison with the multiplicative error model table 1 also summarizes the averages of bias rmse p and d factors of the three validation events based on additive and multiplicative error models over all 48 pixels the multiplicative error model produces larger errors for higher precipitation depths thus leading to unrealistic magnitude for the higher precipitation events however for each validation event there are a number of pixels where observed data fall outside of the simulated ensembles fig 11a b presents the average bias and rmse values of ospe easpe add and easpe mlt corresponding to three validation events respectively these indices are computed for the three daily events over the 48 pixels it is notable that the values of bias and rmse associated with the osre and easpes are the average values of the three daily events over each pixel as a result the estimates from the imerg satellite product are improved after error adjustment 6 conclusions the quantification of precipitation and its spatio temporal variability is very important for reliable hydro meteorological modeling however there are uncertainties in the precipitation values used as key input data in the models and these uncertainties will propagate throughout the employed hydro meteorological models in situ observations are often limited over highlands remote areas and oceans however currently available satellite precipitation products can potentially provide the precipitation estimation needed for hydro meteorological applications unlike traditional gauge measurements remotely sensed precipitation estimates capture the patterns of precipitation spatial variability although they are subject to various errors from different sources one way to assess spatial uncertainty of spe products is to simulate an ensemble of precipitation fields consisting of a large number of realizations as precipitation varies over space and time similarities in the spatial structure between generated and observation fields can be an important feature of precipitation simulation models therefore a copula based model that preserves the spatial dependency among variables independent of their marginals would be a useful tool in the simulation of multivariate random precipitation fields in this study the uncertainties associated with a high resolution spe product imerg fr v04 were quantified through a copula based model linked with additive and multiplicative error models in order to measure the robustness of the easpe simulated realizations p and d factors were computed for each simulated ensemble in light of observed data using p and d factors one can quantitatively predict the uncertainty associated with the easpes furthermore since each set of randomly generated errors resulted in an individual pair of p and d factors for simulated ensemble 49 sets of error fields were generated randomly while the most suitable set was selected based on the best pair of p and d factor values this procedure may lead to a more accurate simulation of ensembles based on bias and rmse error indices the presented framework was able to improve the spes considerably in addition the validation stage implied that the error adjusted band of the simulated realizations encompassed the observed data reasonably moreover by fitting the whole data range the simulations associated with the additive error model performed much better than the multiplicative error model the results also confirmed that the spatial correlation of error was not negligible adequate spatial correlation structures within each ensemble are preserved via the t copula in addition the results demonstrated that the additive error model was superior to the multiplicative error model overall the results presented here indicate that by using a t copula copula based model with an emphasis on an additive error model one can generate multiple realizations of precipitation fields through the simulation of error fields it is notable that in the presented copula based model instead of fitting a standard distribution function to the data the empirical cdf of the observed error is applied to the uniformly simulated error values so that the simulated error values will have the same cdf as that of the observed this avoids the effect of marginal distribution functions on copulas which typically happens when a standard distribution function is fitted alidoost et al 2017 in addition in ideal situations more than one gauge per single spe pixel should be used to provide reliable estimates of the error having only one gauge per pixel produces the point area effect which may be significant in highly variable events habib et al 2009b such a limitation may be addressed through downscaling we need to emphasize that the presented model is meant to describe random error stochastic sources of uncertainty associated with the spes and does not address systematic error bias involved in the quantification of precipitation uncertainty precipitation data may be subject to physical biases and may require further attempts to remove correct physical biases aghakouchak et al 2010b moreover as the number of events decline the sample size of the observed error decreases this may though not necessarily result in a narrower range of error one can intuitively conclude that any change in the error range and thus the distribution of error will also affect the estimated uncertainty in other words an insufficient precipitation sample size will lead to lower easpe robustness berg et al 2012 boé et al 2007 another cause might be due to seasonality in the data as well as the precipitation types therefore it is expected that improved accuracy may be warranted in adopting a denser station network and or using satellite products of finer spatial resolution with longer time series data availability in addition rain gauge measurement errors due to rainfall intensity wind induced undercatch precipitation type and particle falling velocities and the aerodynamic properties of a particular type of gauge could be other causes of uncertainty of spes when faired against rain gauge values an interesting issue for future research which may potentially improve the presented framework is to investigate the dependence of precipitation uncertainty on precipitation regime e g convective stratiform in different topographic regions finally the presented models are to be investigated for their robustness and transferability over different time scales acknowledgments this research was funded by abschlussstipendium from the university of vienna appendix a see table a1 
6737,adequate and accurate hydrological data is necessary to manage water resources which are critical in developing countries where such information is limited in recent years global reanalysis datasets have been developed to provide this information in climatic fields and more recently in hydrologic fields nevertheless these latest efforts have been limited to temporal coverage 30 years and mostly simplified hydraulic scheme routing in rivers which can be inadequate for regional and long term scale objectives in this article a dataset called hydrological reanalysis across the 20th century hrxx in the amazon basin was developed as a case study spanning back to the year 1900 through the use of 1 a large scale hydrologic hydrodynamic model mgb forced by a long term climatic reanalysis of rainfall era 20cm with bias removed and 2 a data assimilation da technique coupled with a localization method lenkf to use several ground observations of daily discharge within a radius of influence several tests were assessed to find the best bias removal method the optimal radius of influence for the localization method and the final hrxx dataset a total of 114 hydrological ground observations of daily information were used for assimilation and validation purposes and several statistics indexes were employed to assess their performance results indicate that both bias correction and the da with localization method greatly improved the simulations overestimations of the peaks in the open loop ol free run simulation mainly in the southern and northern regions of the amazon basin were removed and recession timing in the east central region as seen at the óbidos gauge station were corrected an average performance of 0 6 and 0 7 of the nash sutcliffe and kling gupta indexes was reached even when only a few of the longest ground observations were used which can be representative of the oldest periods since 1930 to assess extreme events the pearson correlation coefficient was used for maximum and minimum annual water level anomaly values reaching 0 6 and 0 7 respectively at the manaus gauge station which is remarkable considering that the analysis covers approximately 110 years considering the results of this case study and the global coverage of rainfall datasets this methodology can be transferred to other regions in order to better estimate and create a hydrological reanalysis that adequately represents the hydrologic and hydraulic spatio temporal fields keywords hydrological reanalysis hydrological hydrodynamic modeling data assimilation local enkf long term dataset amazon basin 1 introduction the requirements of hydrologic records have presented challenges for water management around the world mainly in developing countries where in situ data is temporally and spatially limited and uncertain sivapalan et al 2003 which makes it difficult to characterize past hydrology in a distributed manner some attempts to generate large records have been made in recent years using indirect or proxy data jarrett 1991 that span periods beyond the range of instrumental records moss et al 1988 for example paleoflood hydrology denlinger et al 2002 webb and jarrett 2002 and paleohydrology barber and finney 2000 nunnery 2012 studies have focused on periods that usually range from the last 5000 years to 100 years baker et al 2002 benito and thorndycraft 2005 these attempts aim to reproduce the historical hydrology for periods when records were not kept however they still present some uncertainties for example related to temporal scaling razavi et al 2016 and they are constrained at the gauge of reconstructed sites u s army corps of engineers 2003 where similar spatial restrictions are implied compared with current in situ observations in large basins moreover in the fields of climatology and oceanography data assimilation da techniques have been developed and applied to improve forecast systems and to create a consistent and retrospective record of state of the art climatology variables on a global scale through the optimal combination of models and several observations also widely known as climatic reanalysis e g gibson et al 1997 kistler et al 2001 compo et al 2011 in recent years da techniques have started to be used in the hydrological field sun et al 2016 although their implementation for local vrugt et al 2005 clark et al 2008 xie and zhang 2010 kurtz et al 2017 and large scale applications paiva et al 2013b van dijk et al 2014 lopez et al 2015 liu et al 2012a 2012b 2016 andreadis et al 2017 are still under development some initiatives to develop a coherent register of hydrologic variables in global coverage usually called hydrological reanalysis or water resource reanalysis aim to offer a database of hydrological variables mostly from around the year 1979 such as pcr globwb van beek et al 2011 wanders et al 2014 merra land reichle and liu 2015 era interim land balsamo et al 2015 earth2observe schellekens et al 2017 or era 40 uppala et al 2005 dutra et al 2008 since 1958 the main reason for the lack of many current hydrological reanalyses as global products is the use of simplifications in some procedures such as hydraulic propagation in rivers misrepresenting the hydraulic processes in regions with floodplain extensions for example the large amazon or niger basins which lead to increased uncertainties primarily in the context of a regional outlook recent studies have shown that a large scale hydrologic hydrodynamic model forced by multi decadal precipitation datasets allows for both hydrological variability and extreme events that occurred in the last decades e g wongchuig et al 2017 nkiaka et al 2017 lakew et al 2017 nevertheless one of the limitations of such products also known as hydrological retrospectives is their relatively short temporal extension for the best performing datasets wongchuig et al 2017 which can be extended by using long term climatic reanalysis compo et al 2011 hersbach et al 2013 moreover a long time series of discharges and water levels can be also combined within a da scheme allowing the production of an improved long term hydrological register since the early 1900s from among the diverse da techniques the ensemble kalman filter enkf evensen 2003 has emerged as a popular choice for assimilation into land surface and hydrological models because it enables a simplified implementation moradkhani 2008 in recent years a modified technique called local ensemble kalman filter lenkf has been developed patil et al 2001 ott et al 2002 2004 which implements the impact of local observations within the subset of the model state variables one remarkable advantage is that lenkf can avoid the spurious correlations in the model covariance matrices between the distant state variables of the model zhu et al 2011 where non zero correlations are assigned to variables that are uncorrelated because of a limited number of ensemble members bishop and hodyss 2009 or between two spatially remote locations hamill et al 2001 anderson 2007 because no physical connection for the assimilated state variable exists for sequential da schemes such as enkf a localization method was developed based on a distant dependent covariance localization houtekamer and mitchell 2001 campbell et al 2010 zhu et al 2011 houtekamer and zhang 2016 furthermore this implementation has been demonstrated to be relevant for hydrology studies rasmussen et al 2015 munier et al 2015 zhang et al 2016 long term hydrological simulation requires a consistent set of forcing data which is available in both global and long time scales by climatic reanalysis models numerous studies have demonstrated that raw output from global climate models gcm regional climate models rcm and climate reanalysis have biases mostly due to systematic model errors teutschbein and seibert 2012 ngai et al 2017 berg et al 2003 because of this a bias correction scheme is required for assessing the precipitation forcing as previous research concluded it necessary for long term reanalysis of precipitation decker et al 2012 kim et al 2018 on the other hand if the hydrologic model is simulated with the precipitation forcing biased the use of an observation within the da scheme may result in a synthetic shift in the state variables finally the development of the hydrological reanalysis across the 20th century hrxx is proposed in this research through the use of a da scheme of long temporal in situ discharge records within a large scale hydrologic hydrodynamic model forced by long term precipitation with bias correction understanding the implications of assimilating observations into large scale hydrologic hydrodynamic models for long temporal series is a significant exploration opportunity and may have potential advantages for water resource management van dijk and renzullo 2011 the distinctive benefits of using hrxx data are that their spatially distributed improved variables and long temporal series could be used to understand hydro climatology variability throughout the last century to estimate projected scenarios for hydroelectrical yield companies with less uncertainty to detect hydrological anomalies such as floods and droughts to adequately address these extreme events dottori et al 2016 and to further reduce their future impacts in this context the objectives of this research as a first proxy in the amazon basin are 1 to develop a hydrological reanalysis methodology and product that represents hydrology characteristics across the 20th century 2 to develop a proxy localization within a da scheme lenkf 3 to improve precipitation forcing representation through bias removal methods and 4 to validate hrxx against discharge and water level anomalies from several in situ gauges 2 data and methods 2 1 hydrological reanalysis approach hydrological reanalysis hr can be defined as a consistent and coherent register of spatial temporal fields of hydrologic variables taking as a concept their predecessor in climatology field reanalysis usually extends over several decades and its record is generated through the optimal combination updating of the model forecast with as much as possible observations used within the da scheme considering a global outlook various initiatives mainly based on land surface models forced by climate reanalysis have been developed to create hr datasets with the aim of improving and providing a coherent record of variables that correspond to the water cycle such as gldas houser and rodell 2002 rodell et al 2004 gswp 2 dirmeyer et al 2006 merra land reichle et al 2011 era land balsamoet al 2015 era 20cm r emerton et al 2017 and watch haddeland et al 2011 although these products are not focused to provide a precise record of discharge or water level due to limitations in their hydraulic propagation methods some attempts to evaluate hr were for instance to assess droughts during a relatively long term period van huijgevoort et al 2013 using a large scale based multi model ensemble focused on flood events gründemann et al 2018 these studies call for the importance of a consistent and long temporal dataset for assessment to schematize and summarize the methodology of hrxx proposed in this research fig 1 a shows the different components and processes here used for instance the hydrological hydrodynamic model da technique and bias correction as main processes to develop the hr these processes are explained in more detail in following sections besides the fig 1b schematizes the classic sequential da scheme and shows the time dimension of the long term da of in situ data proposed for this research 2 2 hydrologic hydrodynamic model the mgb model is a large scale semi distributed hydrological model that uses physical and conceptual based equations to simulate the terrestrial phase of the hydrological cycle collischonn et al 2007 the basin is discretized into irregular unit catchments and further into hydrological response units hrus where vertical water and energy budgets are computed individually each unit catchment is also made up of a river reach that encompasses both channel and floodplain units the latter depicted as a simple storage with ineffective flow pontes et al 2017 siqueira et al 2018 the soil is represented as a single layer bucket type model and the evapotranspiration from soil vegetation or open water is calculated using the penman monteith method surface subsurface and groundwater runoff at each unit catchment are produced according to water availability in the soil layer and are routed to a stream network based on a linear reservoir concept in the most recent version flow routing in river channels is computed using the explicit local inertial method bates et al 2010 pontes et al 2017 which is an approximation of the full 1d saint venant equations that neglect only the advective inertial term from the momentum equation i e a hydrodynamic model that is able to represent backwater effects jacon and cudo 1989 meade et al 1991 as it happens in the negro river at manaus due to the stem amazon river influence and floodplain attenuation our reasons for using the mgb model are 1 its satisfactory performance for large scale applications e g paiva et al 2013a pontes et al 2017 siqueira et al 2018 and 2 the past successful attempts with the enkf method e g paiva et al 2013b which demonstrate the potential of this methodology to improve spatio temporal estimates of river discharges 2 3 long term meteorological datasets the 20th century era 20cm climatic reanalysis hersbach et al 2013 was chosen as the input to drive the hydrological model mainly because the era 20cm can still produce statistical estimations despite assimilating no atmospheric observations hersbach et al 2015 which means it is independent of synoptic observations gao et al 2016 resulting in a more homogeneous performance along the temporal coverage 110 years further considering previous assessments of hydrological modeling wongchuig et al 2017 this dataset shows acceptable metric values kge and nse against 27 gauge observations although bias still remains relatively large average of 20 the era 20cm version used here was released in 2014 and it comprises 10 member ensemble predictions forced by the integrated forecast system cy38r1 sea surface temperature sst and sea ice cover sic from the hadsst2 and radiative forcing cmip5 titchner and rayner 2014 the spatial resolution of the final product used herein was 0 25 and the 10 available ensemble members were assessed the dataset is available at https apps ecmwf int datasets data era20cm daily levtype sfc last access 20 march 2016 for bias correction the hybam observed precipitation hop guimberteau et al 2012 dataset was used as referenced observation hop is a gridded daily rainfall data set 1 1 produced by geostatistical interpolation from 752 rain gauges across the amazon basin covering the period from 1980 to 2009 for more details see guimberteau et al 2012 and espinoza et al 2016 the dataset is available at ore hybam http www ore hybam org last access 24 october 2017 2 4 bias correction several methodologies have been developed to remove the bias of precipitation outputs from climatic models therefore three widely used bias adjustment methods were tested in this research the linear scaling lsc approach was often assessed to remove bias of precipitation schmidli et al 2006 lenderink et al 2007 teutschbein and seibert 2012 eisner and voss 2012 chen 2013 lafon et al 2013 n tcha m po et al 2016 because of its simplicity usually a multiplicative correction is used for precipitation instead of an additive to avoid negative corrected values the lsc bias removal was calculated for each unit catchment on a monthly basis the disadvantage of the lsc method is that this value is used equally for extreme events and common events and there is the possibility of overestimating corrected precipitation when 1 the ratio of monthly values between observations and era is large and 2 the daily era value to be corrected is larger than the corresponding observed daily value for the lsc method to perform better a ratio threshold was applied lsct so that when ratio values exceeded this threshold the multiplicative factor became an additive factor and this threshold was established once several values were tested we considered a ratio threshold greater than 1 to avoid negative values in corrected precipitation because lsc is usually used to remove bias in the mean only lenderink et al 2007 teutschbein and seibert 2013 quantile mapping methods were also applied which have already been widely used in hydrological applications to correct mean and variance as well wood et al 2004 teutschbein and seirbet 2012 2013 ngai et al 2017 the empirical quantile mapping eqm and the parametric quantile mapping gamma distribution gqm were assessed the aim was to match the quantile of a referenced precipitation value to the observed value at the same quantile through the construction of cumulative distribution functions cdfs during a referenced calibration period more details regarding the equations used for bias correction are described in the supplementary material in this study we relied on the bias correction as a stationarity assumption where a similar correction method is applied to both the referenced 1990 2009 and past period before 1990 2 5 data assimilation of long term in situ discharge the aim of da techniques is the efficient use of observational information to enhance predictions of model state variables using both model and observation uncertainties madsen and skotner 2005 the enkf method of da used in this research is widely employed in hydrological applications since it enables a simplified implementation of hydrological models where non linear models are predominant enkf defines the model uncertainty as a function of the spread of the model state ensemble using a monte carlo approach implementation of the enkf da scheme in mgb is based on the algorithm developed by evensen 2004 and it can be divided into two steps forecasting and updating as described below for the model the following relation holds 1 x k 1 m x k u k θ q k where the vector x represents model state variables u is the model forcing θ is the model parameters m is the model function that relates state variables at time k with those at time k 1 and qk represents the model uncertainties the observation equation is 2 y k h x k ε k where y is a vector with observations at time k here observed discharge h a function that relates the model state variables x with the correspondent observation y which is a matrix constructed with 1 values where there is a model prediction of the observation and 0 where there is not and ε means the observation uncertainty in the stochastic formulation of enkf the matrix of the forecasted or background ensemble of model states x f is represented as 3 x f x 1 f x 2 f x n ens f where x i f represents each ensemble member of the model states until the total number of defined members n ens the model state matrix x a is updated as the response to the new available observations as follows 4 x a x f k y h x f 5 k p f h t hp f h t r 1 where the x a and x f are the analysis updated and forecasted background model state variable respectively k is the kalman gain p f and r are the covariance matrices of model q and observation ε uncertainties respectively the particularity in the enkf method is that the model error covariance matrix is generated by a set of members from perturbations of the model forcing state variables parameters based on a priori known error this error covariance matrix is estimated from the ensemble anomalies clark et al 2008 as follow 6 p f p e f x f x f x f x f t p a p e a x a x a x a x a t where p e f and p e a are the covariance matrices of the model for the forecast and analysis respectively and t super index means the transpose operator 2 6 experiments and case study 2 6 1 amazon case study and model setup the amazon basin was chosen as a proof of the concept of hrxx because it is the world s largest basin and it drains more than 6 million km2 and discharges 15 of the freshwater that reaches the world s oceans yet its ground observational network is scarce willmott et al 1994 marengo 2005 and its water resources meet many human needs such as fluvial transportation agriculture fisheries and energy production the amazon basin is experiencing a noticeable process of biophysical transition nobre et al 2016 and hydrological extreme events such as floods and droughts have been recorded during the last years with reported increasing of magnitude and frequency due to rainfall intensity marengo et al 2013 2016 espinoza et al 2018 wang et al 2018 barichivich et al 2018 furthermore there is an evident pattern of an upward trend of the frequency of extreme floods in the northern and on the main stem region callède et al 2004 espinoza et al 2009 wongchuig et al 2017 and an upward trend of extreme drought events in southern regions lopes et al 2016 molina carpio et al 2017 herein we applied the same model setup and parameterization used in the south american mgb version from siqueira et al 2018 as such the basin was discretized using a fixed river length of δx 15 km to provide a balance between computational efficiency and numeric stability with respect to the hydrodynamic routing resulting in 12 466 unit catchments ranging from 20 to 2600 km2 the model was forced with a 0 25 horizontal resolution mswep v1 1 precipitation beck et al 2017 and long term monthly meteorological data from the cru cl 2 0 dataset new et al 2002 in addition the model was calibrated between 1990 and 2010 using daily river discharges and was validated using multiple data sources including water levels in situ and satellite altimetry terrestrial water storage and evapotranspiration estimates further details about model setup and performance can be found in siqueira et al 2018 datasets available at http www gloh2o org for mswep rainfall dataset https crudata uea ac uk cru data hrg tmc for cru climatological dataset and http www snirh gov br hidroweb publico medicoes historicas abas jsf for in situ daily discharge 2 6 2 assimilation parameters and localization approach in this research assimilation parameters were assumed to know hydrological model errors only the precipitation was perturbed in this study considered as the main forcing to the model biancamaria et al 2011 liu et al 2012a paiva et al 2013b the adopted perturbation follows a log normal distribution of errors as proposed by nijssen and lettenmaier 2004 7 p c 1 β e 2 1 e x p l n e 2 1 s p where p c is the perturbed variable precipitation or model state variables p is the non perturbed variable e is relative error β is relative bias here adopted as 0 0 and s is a random variable that follows the time evolution of model error according to evensen 2003 8 s k α s k 1 1 α 2 w k 1 α 1 δ t τ t where the coefficient α 0 1 indicates the influence of temporal correlation on the model errors α 0 indicates a high correlation while α 1 indicates a random field of errors constant in time no temporal correlation w is a stochastic term with mean 0 and variance 1 following a gaussian distribution and τ t is the temporal decorrelation length time units in this study a function of the discharge observation q obs was adopted for the estimation of the matrix covariance of observation errors σ obs 2 clark et al 2008 9 σ obs 2 ε obs q obs 2 where ε obs is the discharge error parameter that could be considered as the uncertainty on river discharge measurement and a value of 10 was adopted in principle based in previous assessments di baldassarre and montanari 2009 clark et al 2008 paiva et al 2013b to afford an adequate representation of the error covariance matrix the enkf methodology needs a sufficient ensemble size to avoid spurious correlations between large rivers with a distant reach in this context to avoid this problem houtekamer and mitchell 2001 proposed ignoring remote observations in the analyzed local point through the use of the covariance localization method a correlation matrix was estimated using a distance dependent correlation function gaspari and cohn 1999 finally the incorporation of a covariance localization matrix sakov and bertino 2011 to the equation referred as a local ensemble kalman filter lenkf houtekamer and mitchell 2001 2005 ott et al 2004 tong 2018 is expressed 10 x a x f ρ p f h t ρ o hp f h t r 1 y h x f where ρ and ρ o are correlation matrices and represents the schur product the correlation matrices were calculated using a fifth order function as determined by gaspari and cohn 1999 and suggested by hamill et al 2001 and houtekamer and mitchell 2001 11 ρ r e 1 1 4 e r 5 1 2 e r 4 5 8 e r 3 5 3 e r 2 0 e r 1 12 e r 5 1 2 e r 4 5 8 e r 3 5 3 e r 2 5 e r 4 2 3 e r 1 r e 2 r 0 e 2 r where e represents the distance along the river network between the observation and the analyzed river reach and r means the radius of influence for this implementation ρ is a n m dimension wherein each column presents the correlations at one observation location unit catchment with all model state variables of all unit catchments and ρ o is an m m dimension wherein each column presents the correlations at one observation with all other observations located in their respective unit catchment in this research enkf and lenkf are related to eqs 5 and 10 respectively 2 6 3 assimilation and validation datasets daily in situ discharge and water level observations from 114 gauges were used in this research divided almost equally for assimilation within the da scheme 57 and for validation purposes 57 fig 2 for assimilation and validation criteria gauges with a coverage greater than a 30 year record and a 15 year record were chosen respectively these datasets were provided by the environmental research observatory so hybam ore hybam http www ore hybam org last access 18 february 2017 and the national water agency ana brazil http www snirh gov br hidroweb last access 09 august 2017 a table with more detailed information about in situ gauges and data quality control used in this research can be found in the supplementary material 2 6 4 experiments for hydrological reanalysis evaluation the following procedures were developed to achieve the hrxx 1 selection of the ensemble members of precipitation from the era 20cm climatic reanalysis based on their performances 2 determination of the optimal radius of influence for the case study region through the lenkf da scheme 3 assessment of the bias removal methods of daily precipitation forcing in comparison with the hop 4 generation of the hrxx through the use of both the optimal radius of influence within lenkf and the best bias corrected precipitation forcing the statistics indexes nash sutcliffe efficiency nse the kling gupta kge the absolute value of stream flow volume error hereafter referred to as bias and the relative reduction in root mean square error δrmse were used to assess performance in daily discharge and water level values produced by the hr the nse is a normalized statistic that determines the relative magnitude of residual variance compared with the observed data variance while the kge offers interesting results in model performance because it uses the most components such as correlation variability and bias terms both nse and kge range between and 1 perfect fit the δrmse compares relatively the performance decreasing errors of the model simulation using the da scheme with respect to the ol free run simulation 12 nse 1 i 1 nt q obs t q sim t 2 i 1 nt q obs t q obs 2 13 kge 1 r 1 2 σ sim μ sim σ obs μ obs 1 2 μ sim μ obs 1 2 14 bias i 1 nt q sim t i 1 nt q obs t i 1 nt q obs t 15 rmse 1 n i 1 nt q obs t q sim t 2 δ r m s e rmse improved rmse open l o o p rmse open l o o p where nt is the number of observations σ is the standard deviation and μ is the mean and rmse improved can be referred to as bias correction or assimilation for precipitation forcing we assessed the 10 ensemble members available from the era 20cm climatic reanalysis to determine the most suitable of them for following analysis the ol simulations were carried out for each member and all discharge gauges 113 were used for validation during the common period from 1980 to 2010 the statistical performance indexes and fewer errors with respect to the mean of the ensembles were considered when choosing the ensemble members for the following analysis it is important to note that the evaluation of the 10 ensemble members can provide an indication of the uncertainty of the precipitation forcing which could be taken into account for the perturbation of forcing within the da scheme a general proxy was developed to estimate the optimal radius of influence for the basin in the study we tested a range of radii between 50 and 5000 km which was selected considering closest values of influenced area in the amazon basin emery et al 2018 the size of 100 members was determined by previous enkf implementation in the amazon basin paiva et al 2013b and for other hydrological studies huang et al 2008 tong et al 2012 nevertheless this could result in a huge computational demand because of 1 the long simulation assimilation window 110 years 2 the large spatial discretization of the study area and 3 several radius of influence scenarios to be assessed therefore for this specific experiment only the ensemble size of 25 members was used to estimate the optimal radius of influence the validation was carried out using a set of 56 in situ discharge gauges described in section 2 6 3 during the period from 1980 to 2010 to assess the bias removal methods of era 20cm precipitation a referenced period from 1990 to 2009 and a validated period from 1980 to 1989 were considered these periods were chosen because observation data availability 1980 2009 from the hop dataset described in section 2 3 the validation performance was assessed for both precipitation and discharge for discharge we carried out two periods of validation 1 from 1980 to 1989 using all discharge gauges 113 and 2 assessing the performance of bias removal methods for past eras during the common period from 1931 to 1948 we also used seven discharge gauges with long records for precipitation validation all unit catchments were assessed from 1980 to 1989 for the hrxx two scenarios of assimilation were considered 1 using all assimilation gauges 57 validated against 56 gauges and 2 using only seven gauges with the longest time records validated against the 106 remaining gauges the second scenario was assessed because we consider validation necessary when just a few gauges seven are used for assimilation purposes which happened the most during the period from 1908 to 1970 of the simulation finally also assessed was the performance of the anomalies in water levels at the longest data record in the amazon basin located in manaus which was not used for assimilation purposes due to manaus records are controlled by solimões river level variability generating a hysteresis effect in the rating curve it was carried out from 1903 to 2010 the methodology developed in this research has the objective of estimating a long and consistent spatio temporal register of hydrological variables mainly discharge and water level through 1 hydrologic hydrodynamic modeling 2 a da method 3 a simple localization approach and 4 bias correction of precipitation forcing to summarize these procedures fig 3 and table 1 show the general framework of the methodology and experiments that were applied in this research 3 results and discussions 3 1 open loop ensemble members performance the ol simulation also known as free run simulation was considered as the background for following tests as we expected the ol simulations using the 10 ensemble members of era 20cm climatic reanalysis showed medium performance in the amazon basin according to the statistical indexes this performance was already noted in previous studies wongchuig et al 2017 the average performances for the median of 10 members of the ensemble were 0 61 0 40 and 20 6 for kge nse and bias respectively there was no clear significant difference among the members performance for daily discharge according to a student s t test at 95 confidence level therefore for the following analyses the members with less rmse in the daily precipitation with respect to the mean of the 10 ensemble members was chosen nevertheless the uncertainty of the 10 ensemble members can also be considered through their ensemble standard deviation for the perturbation of the precipitation within the da scheme 3 2 assessment of the localization approach a general approach to estimating the optimal value for the radius of influence across a river routing network is presented in this section through the use of the polynomic equation developed by gaspari and cohn 1999 the localization experiments were carried out considering a range of radius values closest to previous studies emery et al 2018 the spatial distribution of the correlation values from the 57 assimilation gauges considering several radii of influence is shown in fig 4 for each simulation statistical indexes were applied to find the optimal radius fig 5 shows the boxplots of performance considering the validation and assimilation gauges the lenkf simulations showed more clearly the sensible approach of the use of the localization technique in assimilation fig 5b than in validation fig 5a gauges according to the statistical indexes when the localization technique was applied lenkf the performance increased directly proportional with the radius of influence until a certain value fig 6 shows a general increase in performance when different radii of influence are applied within the localization method in addition better results were found when validation is performed in gauges with large contribution areas 25 000 km2 it is interesting to note that for the δrmse metric enkf showed an increase in errors compared with the ol when all the validated gauges were used which can be explained due to the spurious correlations between the remote locations of assimilation gauges and the updated unit catchments the opposite behavior was observed when validation gauges with large contribution areas were analyzed because these are usually closest to the assimilation gauges used those with long series and therefore located in biggest contribution areas in general the localization technique greatly improved da performance which was already observed by paiva et al 2013b for large basins such as the amazon basin in general the optimal values were found between 500 km and 2000 km which fits close to values found by emery et al 2018 consequently the radius of influence of 1000 km was chosen because of its relatively good performance and greater spatial coverage fig 4 92 of which represents 5 4 106 km2 the following simulations were assessed using 100 ensemble members 3 3 validation of data assimilation scheme localization and bias correction in this section we present the performance of the enkf da scheme in validated gauges when a size of 100 ensemble members and an optimal radius of influence of 1000 km as established in previous section were used lenkf fig 7 shows improvements in performance for all statistical indexes for the assimilation and validation gauges when the localization technique is used for the median of validation gauges the δrmse index improved from 1 to 7 fig 7a considering the comparison between the ol red and lenkf blue the statistics were consistent for the bias nse and kge improving from 19 to 17 from 0 28 to 0 47 and from 0 56 to 0 62 respectively improvements were found for the nse index for 18 of the validation gauges in which values less than 0 50 went to greater than 0 75 and approximately 24 of all gauges with values greater than 0 25 of bias were reduced to 19 the performance of bias correction methods was assessed against precipitation and discharge records during the validation period 1980 1989 and for the longest in situ records of discharge gauges during the oldest period 1931 1948 fig 8 shows the analysis of mean monthly precipitation during the validation period where hop era 20cm raw and era 20cm bias removed were plotted for the northwest region the precipitation was underestimated almost all year for era 20cm reanalysis and mainly during the rainy season in the north region for the western area precipitation was underestimated during the dry period and overestimated during the wet period for the central and southern regions the precipitation was underestimated mainly during the dry season and on average this behavior was also seen for the whole amazon basin the bias correction methods improved monthly precipitation in all regions we can also see the lsc method green lines overestimating values during some dry months which is a problem for this specific method and was described in section 2 4 overall the lsc threshold lsct method has the best performance to correct precipitation on a monthly scale considering the pearson correlation coefficient which improved from 0 97 for the era 20cm raw to 0 99 for the lsct fig 9 shows the bias values for the era 20cm precipitation forcing spatially distributed and aggregated in tri monthly means before and after bias removal the era 20cm shows peculiar behavior in the extreme rainfall regions hotspots as related by wongchuig et al 2017 where the mswep and era interim land rainfall datasets also presented the particular characteristic of overestimation in the eastern flank of the andes while showed underestimation in most hotspots similarly to espinoza et al 2015 using the trmm pr dataset the bias removal method lsct fig 9b which has best performance was effective in constraining bias between the ranges of 5 and 5 for 80 of the amazon basin s area during the span of the referenced and validation periods the daily observed discharge values were also used to assess the bias removal performance fig 10 and table 2 show the statistical index values of daily discharge for the ol simulations before gray and after sky blue each bias removal method we can observe that the best improvement on bias was done by the lsct method during the validation period which was reduced from 20 1 to 14 3 considering the average of all discharge gauge 113 there was also an improvement in the nse and kge indexes using the lsct method from 0 32 to 0 44 and from 0 55 to 0 63 respectively the ol lsc shows the worst performance table 3 even worse than the ol era raw during the validation period the hydrographs of the ol simulation and the ol using precipitation with bias removal are shown in fig 11 the three best and the three worst gauges considering the average bias of all methods were chosen to be plotted during five years for the validation and referenced periods for instance during the validation period fig 11a and b the bias removal methods performed better at the são felipe northern region valparaiso and ipixuna south western region stations in relation to ol era raw dashed red line this improvement is clearly indicated by the reduction of peaks during the rainy season while ol era raw overestimates discharge values this correction is evidently noted at the ipixuna station fig 11a where bias was reduced from 68 to 7 during the validation period further the ji parana and boa esperança south central and eastern regions respectively gauges fig 11b performed the worst for bias it is interesting to note that at the altamira eastern region and boa esperança gauges there is a peak on discharge green line at the end of 1986 when the lsc method was used which explains the decreasing performance when this method was assessed table 2 this problem of overestimation was mentioned in section 2 4 which justifies the application of the threshold on the ratio and what results in a better general performance for the referenced period fig 11c and d the bias of the three stations plotted were improved by all bias correction methods reducing the overestimation on discharge by ol era raw in almost all years for instance in the fazenda passarão gauge northern region where bias was reduced from 34 to 1 on the other hand for the worst gauge stations discharge with bias correction was not much different in comparison with ol era raw as shown mainly at the porto velho and leontino gauges the hydrographs for the seven gauges with longest records are shown in fig 12 and geographical location of each station can be seen at the fig 1s in supplementary material the assessment of bias removal methods in these gauges illustrates their performances during a distant temporal era from the referenced period improvements can be clearly seen at the labrea cruzeiro do sul and óbidos gauges where the peaks were removed for the two first mentioned gauges and enhancements during the recession period for óbidos during the common period from 1931 to 1948 the bias improvement for the average of the seven gauges went from 18 to 9 and achieved the best enhancement at óbidos from 14 to 3 4 which is generally remarkable because the referenced period is temporarily distant these results indicate that the precipitation input dataset has mainly a systematic bias as described in section 2 3 which was acceptably removed by the bias removal methods that mesh with their non stationary assumptions due to statistical performance we have chosen the ol lsct to assess the further experiments for the hr development which means that the final spatio temporal analysis is going to take the best setup of the lenkf scheme when and where observation records were available within an optimal radius of influence in a synergy with the improved bias removed precipitation forcing during the years 1900 to 2010 fig 13 in section 3 4 displays the hydrographs for the assimilation and validation gauges at some stations during a period when observation records are partially available the bias of the ol red line simulations is shown clearly at the serrinha óbidos labrea and cruzeiro do sul gauges while discharge values were improved by lenkf gray and dashed black lines when observations were available which is clearly seen since 1968 it is interesting to see how this improvement spread to the validation gauges most clearly at fazenda borangaba and santos dumont by contrast discharge improvements were not observed well before 1968 for lenkf without bias removal gray line the lenkf scheme was used to improve state variables in spatial and temporal fields using a local assimilation nonetheless this improvement is done when and where observations are available within an area of influence which means that state variables remain biased for several unit catchments before 1970 due to 1 biased precipitation era 20cm forcing 2 limited temporal availability from in situ observation records to be assimilated 3 spatial restriction of state variables updated by localization technique to avoid these constraints and in order to assess the best dataset in as great an area and as much temporal coverage as possible the bias correction was performed to the precipitation forcing from 1900 even though we considered the stationarity assumption of bias correction methods the climatic variability should be represented by in situ observations used in the da scheme afterwards the corrected precipitation and the lenkf scheme will be used to develop the hrxx dataset 3 4 hrxx and multi decadal behavior after validating the performance of the lenkf da scheme and bias correction of the precipitation forcing hrxx in the amazon basin was developed considering the conditions for the optimal radius of influence and best bias correction method hrxx was forced with the bias corrected precipitation since 1900 and the da scheme of in situ discharge records was effectively done by data availability since 1908 1928 and mostly since the end of the 1960s fig 13 illustrates the hydrographs for the assimilation and validation gauges at some stations when observation records are partially available to denote the improvements by both the da scheme and bias correction for serrinha and jusante da cachoeira do caju fig 13a the assimilated observations were available from late 1967 when the improvements to lenkf gray and dashed black lines compared with the ol red line are evidenced by a reduction of peaks in the assimilated gauge which spread to the validation gauge appreciably since the middle of 1982 when observations are available similar behavior occurs at labrea with fazenda bocanegra and at cruzeiro do sul with santos dumont where improvements by da spread when observations were available since 1968 in all these cases we highlight the improvements by bias correction when observations were not available before 1968 thus hrxx dashed black lines shows the correction of overestimated peaks by ol which was not possible to do by lenkf without bias removal gray line improvements were also important at the óbidos gauge where a rapid recession was removed by a da scheme when observations were available since early 1968 and by bias removal before that fig 13b the hrxx performance is shown in fig 14 in which the statistical indexes are spatially assessed the kge and nse indexes showed values above 0 6 for 63 and 34 of validation gauges respectively which represent an improvement of 20 and 18 in the number of validation gauges with respect to the ol for the validation 46 have values of bias index below 10 indicating an improvement in the number of gauges of 25 in comparison with the ol the results of δrmse indicate a reduction of rmse with respect to the ol of more than 25 for almost 34 of validation gauges finally table 3 summarizes the performance of the statistical indexes for the different scenarios experiments assessed in this research from ol to the hrxx final product we can see a consistent improvement in performance in which values could be considered as satisfactory for hrxx even for the experiment in which only the seven gauges with the longest records were used in the da reaching an average of 10 of bias reductions of rmse of 14 and satisfactory values of 0 51 and 0 66 for nse and kge respectively which could be considered in some ways as representative of the oldest periods before 1970 because one objective in this research was to represent acceptable values since the beginning of 1900 and our validation common period was mostly done since 1980 the manaus water level record since 1903 was also used to validate hrxx in this research as described in section 2 6 4 discharge data by manaus gauge was not used for assimilation purposes therefore they are independent fig 15 shows the water level anomalies for two periods from 1901 to 1930 fig 15a and from 1978 to 2009 fig 15b where the observations ol and hrxx were plotted it is clearly seen in the reduction of peaks from ol to hrxx and the enhancements from the rapid recession during the dry period the sky blue vertical lines in the years 1908 and 1928 indicate when observations were available at porto velho madeira river and at óbidos amazon river of which the latter is located downstream of the manaus gauge and therefore influenced by the da scheme the extreme drought in 1926 marengo and espinoza 2016 was not represented by hrxx because discharge observations by óbidos used in da scheme just started in 1928 besides the 1979 81 1982 83 and 1995 drought events as well as the 1989 1999 and 2009 flood events were better represented the performance of the nse and kge indexes improved from 0 44 to 0 86 and from to 0 72 to 0 87 respectively during the period from 1903 to 2010 hrxx shows a good performance even when observations were not available due to improvements by the bias removal of precipitation forcing which is further enhanced by lenkf when observations are accessible as several studies have shown extreme events in the amazon basin have become more frequent and intense during recent decades these events such as floods and droughts are important because of their economic and social impacts some of these extreme events that occurred in the past were assessed in this research corresponding to the two oldest and two most recent floods and droughts cited in marengo and espinoza 2016 which were based mostly on the impact on the water level at the manaus gauge the spatial impact of these drought and flood events are plotted in figs 16a and 17a respectively the intensity of the event in days was estimated based on a simple approach described in wongchuig et al 2017 where the number of days above or below certain discharge or water level thresholds were counted to determine the impact of the flood or drought events respectively the comparison between observation and simulation hrxx was based on daily water level values at the manaus gauge in addition to that it is important to highlight that several flood after 2009 such as 2012 and 2014 years marengo and espinoza 2016 barichivich et al 2018 were not registered by the hrxx due to our simulation window considering the drought events the years 1906 1926 2005 and 2010 were chosen for this analysis the two oldest drought years were mainly registered at the manaus gauge jenkins 2009 marengo and espinoza 2016 being the drought of 1926 perhaps one of the worst on record williams et al 2005 moreover the 2005 and 2010 events were also registered at the óbidos gauge and reported in the literature espinoza et al 2011 marengo et al 2011 through observation records in the madeira and solimões rivers in the southern and western regions as shown in fig 16a fig 16b shows the water level anomalies of minimum annual values for observations ol and hrxx where three drought events 1906 2005 and 2010 are well represented in the vertical red lines for certain drought years for the common period between observation and simulation the pearson correlation coefficient for the water level anomalies of minimum annual values increased from 0 38 for the ol to 0 72 for hrxx in spite of relative well agreement for correlation between hrxx and observations drought events seem to be underestimated by hrxx mainly before 1928 when observations were not available to be assimilated for floods the events in 1909 1976 1999 and 2009 were selected the 1909 event was detected only at the manaus gauge while the last three events were also detected at the óbidos gauge marengo and espinoza 2016 the intensity of the 1909 flood event was represented in the negro river close to the confluence with the amazon river fig 17 a which was less intense in comparison with the 1976 1999 and 2009 events these events were also reported in the literature through observation records at manaus satyamurty et al 2013 madeira and purus rivers most notably during 2009 event marengo et al 2012 pereira and szlafsztein 2016 as shown in fig 17a for these three recent flood events fig 17b shows a clear concordance between observation and hrxx the pearson correlation coefficient for the water level anomalies of maximum annual values increased from 0 18 for the ol to 0 60 for hrxx which indicates a significant improvement in the performance of detecting maximum events according this methodology finally considering the anomalies of the mean annual values of water level at manaus it increased from 0 22 for ol to 0 69 for hrxx 4 conclusions and perspectives this research aimed to develop in a retrospective manner a consistent register of hydrological variables through the use of a large scale hydrologic hydrodynamic model da scheme and bias removal method lenkf was assessed in this research using a primary approximation of a general radius of influence the local implementation showed improvements with respect to the enkf scheme in the amazon basin even using a relatively large size of ensemble members which demonstrates that local consideration regarding the correlation between assimilation and updated points that are separated by a far distance or physically disconnected on a river network should be taken into account for large scale basin studies the optimal radius of influence was reached at 1000 km which when used within the lenkf scheme for improved discharge representation increasing the nse and kge performance by 70 and 9 respectively with respect to the enkf scheme four bias removal techniques were assessed because 1 climatic reanalysis is usually biased and 2 a da scheme only updates state variables when and where observations are available the improvement in absolute values of bias during the period of validation was assessed for monthly precipitation and for daily discharge for the validation period 1980 1989 and during the oldest period 1931 1948 the linear scaling method using a threshold achieved the best performance among other methods tested in this study the bias values for the era 20cm raw dataset range spatially from 50 to 50 which was finally constrained by bias removal from 5 to 5 for 80 of the study area the improvements on bias for daily discharge values was 40 during the validation period and achievements of 0 45 and 0 64 for nse and kge respectively hrxx proposed herein is based in the large scale mgb model forced with the bias removed precipitation and coupled in synergy with a lenkf scheme its performance was assessed for daily discharge observations at 56 validation gauges and for water level anomalies at the manaus gauge negro river during the longest records in amazon basin historic observed flood and drought events were also assessed for hrxx results indicate that improvements were clearly achieved by hrxx which takes advantage of both a da scheme and a bias removal method in which statistical performance could be considered as satisfactory to represent adequate discharge and water levels across the 20th century in this paper we evaluated the hr methodology to generate a consistent record of hydrological variables on a large scale by the use of long temporal records of in situ discharge and climatic precipitation reanalysis datasets that are globally available this new dataset is the first approach of long term data assimilation of in situ data in the amazon basin despite the fact that our methodology presents some simplifications results show adequately for large scale the hrxx could be useful for the spatial and temporal hydrological characterization e g climate change assessment for several past decades once this basin is considered an important large biome with a considerable control on the carbon cycle and global climate other approaches should also be implemented in the future such as complex approximations to estimate the radius of influence in the lenkf scheme considering spatial and temporal variations for each unit catchment or better bias removal methods that consider non stationary series despite this hrxx developed in this study could be used as a methodology in other large basins around the world 1 to evaluate spatially and temporally distributed hydrological variability across the last century 2 to create consistent records of hydrological extreme events such as floods and droughts and 3 to make availability a complementary dataset in regions with sparse hydro meteorological network declaration of interest the authors declare no conflict of interest the funders had no role in the design of the study in the collection analyses or interpretation of data in the writing of the manuscript or in the decision to publish the results acknowledgments the first author is grateful for a grant from the brazilian agency capes and for enkf codes provided by evensen the authors are grateful for the precipitation datasets supplied by ecmwf and the in situ discharge and water level data provided by hybam and ana institutions we also thank two anonymous reviewers for their comments which helped significantly in the improvement of this manuscript the developed hrxx data for the amazon basin that support the findings of this study are available at mendeley data v3 http dx doi org 10 17632 9kjx9d7ycm 3 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 01 025 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 
6737,adequate and accurate hydrological data is necessary to manage water resources which are critical in developing countries where such information is limited in recent years global reanalysis datasets have been developed to provide this information in climatic fields and more recently in hydrologic fields nevertheless these latest efforts have been limited to temporal coverage 30 years and mostly simplified hydraulic scheme routing in rivers which can be inadequate for regional and long term scale objectives in this article a dataset called hydrological reanalysis across the 20th century hrxx in the amazon basin was developed as a case study spanning back to the year 1900 through the use of 1 a large scale hydrologic hydrodynamic model mgb forced by a long term climatic reanalysis of rainfall era 20cm with bias removed and 2 a data assimilation da technique coupled with a localization method lenkf to use several ground observations of daily discharge within a radius of influence several tests were assessed to find the best bias removal method the optimal radius of influence for the localization method and the final hrxx dataset a total of 114 hydrological ground observations of daily information were used for assimilation and validation purposes and several statistics indexes were employed to assess their performance results indicate that both bias correction and the da with localization method greatly improved the simulations overestimations of the peaks in the open loop ol free run simulation mainly in the southern and northern regions of the amazon basin were removed and recession timing in the east central region as seen at the óbidos gauge station were corrected an average performance of 0 6 and 0 7 of the nash sutcliffe and kling gupta indexes was reached even when only a few of the longest ground observations were used which can be representative of the oldest periods since 1930 to assess extreme events the pearson correlation coefficient was used for maximum and minimum annual water level anomaly values reaching 0 6 and 0 7 respectively at the manaus gauge station which is remarkable considering that the analysis covers approximately 110 years considering the results of this case study and the global coverage of rainfall datasets this methodology can be transferred to other regions in order to better estimate and create a hydrological reanalysis that adequately represents the hydrologic and hydraulic spatio temporal fields keywords hydrological reanalysis hydrological hydrodynamic modeling data assimilation local enkf long term dataset amazon basin 1 introduction the requirements of hydrologic records have presented challenges for water management around the world mainly in developing countries where in situ data is temporally and spatially limited and uncertain sivapalan et al 2003 which makes it difficult to characterize past hydrology in a distributed manner some attempts to generate large records have been made in recent years using indirect or proxy data jarrett 1991 that span periods beyond the range of instrumental records moss et al 1988 for example paleoflood hydrology denlinger et al 2002 webb and jarrett 2002 and paleohydrology barber and finney 2000 nunnery 2012 studies have focused on periods that usually range from the last 5000 years to 100 years baker et al 2002 benito and thorndycraft 2005 these attempts aim to reproduce the historical hydrology for periods when records were not kept however they still present some uncertainties for example related to temporal scaling razavi et al 2016 and they are constrained at the gauge of reconstructed sites u s army corps of engineers 2003 where similar spatial restrictions are implied compared with current in situ observations in large basins moreover in the fields of climatology and oceanography data assimilation da techniques have been developed and applied to improve forecast systems and to create a consistent and retrospective record of state of the art climatology variables on a global scale through the optimal combination of models and several observations also widely known as climatic reanalysis e g gibson et al 1997 kistler et al 2001 compo et al 2011 in recent years da techniques have started to be used in the hydrological field sun et al 2016 although their implementation for local vrugt et al 2005 clark et al 2008 xie and zhang 2010 kurtz et al 2017 and large scale applications paiva et al 2013b van dijk et al 2014 lopez et al 2015 liu et al 2012a 2012b 2016 andreadis et al 2017 are still under development some initiatives to develop a coherent register of hydrologic variables in global coverage usually called hydrological reanalysis or water resource reanalysis aim to offer a database of hydrological variables mostly from around the year 1979 such as pcr globwb van beek et al 2011 wanders et al 2014 merra land reichle and liu 2015 era interim land balsamo et al 2015 earth2observe schellekens et al 2017 or era 40 uppala et al 2005 dutra et al 2008 since 1958 the main reason for the lack of many current hydrological reanalyses as global products is the use of simplifications in some procedures such as hydraulic propagation in rivers misrepresenting the hydraulic processes in regions with floodplain extensions for example the large amazon or niger basins which lead to increased uncertainties primarily in the context of a regional outlook recent studies have shown that a large scale hydrologic hydrodynamic model forced by multi decadal precipitation datasets allows for both hydrological variability and extreme events that occurred in the last decades e g wongchuig et al 2017 nkiaka et al 2017 lakew et al 2017 nevertheless one of the limitations of such products also known as hydrological retrospectives is their relatively short temporal extension for the best performing datasets wongchuig et al 2017 which can be extended by using long term climatic reanalysis compo et al 2011 hersbach et al 2013 moreover a long time series of discharges and water levels can be also combined within a da scheme allowing the production of an improved long term hydrological register since the early 1900s from among the diverse da techniques the ensemble kalman filter enkf evensen 2003 has emerged as a popular choice for assimilation into land surface and hydrological models because it enables a simplified implementation moradkhani 2008 in recent years a modified technique called local ensemble kalman filter lenkf has been developed patil et al 2001 ott et al 2002 2004 which implements the impact of local observations within the subset of the model state variables one remarkable advantage is that lenkf can avoid the spurious correlations in the model covariance matrices between the distant state variables of the model zhu et al 2011 where non zero correlations are assigned to variables that are uncorrelated because of a limited number of ensemble members bishop and hodyss 2009 or between two spatially remote locations hamill et al 2001 anderson 2007 because no physical connection for the assimilated state variable exists for sequential da schemes such as enkf a localization method was developed based on a distant dependent covariance localization houtekamer and mitchell 2001 campbell et al 2010 zhu et al 2011 houtekamer and zhang 2016 furthermore this implementation has been demonstrated to be relevant for hydrology studies rasmussen et al 2015 munier et al 2015 zhang et al 2016 long term hydrological simulation requires a consistent set of forcing data which is available in both global and long time scales by climatic reanalysis models numerous studies have demonstrated that raw output from global climate models gcm regional climate models rcm and climate reanalysis have biases mostly due to systematic model errors teutschbein and seibert 2012 ngai et al 2017 berg et al 2003 because of this a bias correction scheme is required for assessing the precipitation forcing as previous research concluded it necessary for long term reanalysis of precipitation decker et al 2012 kim et al 2018 on the other hand if the hydrologic model is simulated with the precipitation forcing biased the use of an observation within the da scheme may result in a synthetic shift in the state variables finally the development of the hydrological reanalysis across the 20th century hrxx is proposed in this research through the use of a da scheme of long temporal in situ discharge records within a large scale hydrologic hydrodynamic model forced by long term precipitation with bias correction understanding the implications of assimilating observations into large scale hydrologic hydrodynamic models for long temporal series is a significant exploration opportunity and may have potential advantages for water resource management van dijk and renzullo 2011 the distinctive benefits of using hrxx data are that their spatially distributed improved variables and long temporal series could be used to understand hydro climatology variability throughout the last century to estimate projected scenarios for hydroelectrical yield companies with less uncertainty to detect hydrological anomalies such as floods and droughts to adequately address these extreme events dottori et al 2016 and to further reduce their future impacts in this context the objectives of this research as a first proxy in the amazon basin are 1 to develop a hydrological reanalysis methodology and product that represents hydrology characteristics across the 20th century 2 to develop a proxy localization within a da scheme lenkf 3 to improve precipitation forcing representation through bias removal methods and 4 to validate hrxx against discharge and water level anomalies from several in situ gauges 2 data and methods 2 1 hydrological reanalysis approach hydrological reanalysis hr can be defined as a consistent and coherent register of spatial temporal fields of hydrologic variables taking as a concept their predecessor in climatology field reanalysis usually extends over several decades and its record is generated through the optimal combination updating of the model forecast with as much as possible observations used within the da scheme considering a global outlook various initiatives mainly based on land surface models forced by climate reanalysis have been developed to create hr datasets with the aim of improving and providing a coherent record of variables that correspond to the water cycle such as gldas houser and rodell 2002 rodell et al 2004 gswp 2 dirmeyer et al 2006 merra land reichle et al 2011 era land balsamoet al 2015 era 20cm r emerton et al 2017 and watch haddeland et al 2011 although these products are not focused to provide a precise record of discharge or water level due to limitations in their hydraulic propagation methods some attempts to evaluate hr were for instance to assess droughts during a relatively long term period van huijgevoort et al 2013 using a large scale based multi model ensemble focused on flood events gründemann et al 2018 these studies call for the importance of a consistent and long temporal dataset for assessment to schematize and summarize the methodology of hrxx proposed in this research fig 1 a shows the different components and processes here used for instance the hydrological hydrodynamic model da technique and bias correction as main processes to develop the hr these processes are explained in more detail in following sections besides the fig 1b schematizes the classic sequential da scheme and shows the time dimension of the long term da of in situ data proposed for this research 2 2 hydrologic hydrodynamic model the mgb model is a large scale semi distributed hydrological model that uses physical and conceptual based equations to simulate the terrestrial phase of the hydrological cycle collischonn et al 2007 the basin is discretized into irregular unit catchments and further into hydrological response units hrus where vertical water and energy budgets are computed individually each unit catchment is also made up of a river reach that encompasses both channel and floodplain units the latter depicted as a simple storage with ineffective flow pontes et al 2017 siqueira et al 2018 the soil is represented as a single layer bucket type model and the evapotranspiration from soil vegetation or open water is calculated using the penman monteith method surface subsurface and groundwater runoff at each unit catchment are produced according to water availability in the soil layer and are routed to a stream network based on a linear reservoir concept in the most recent version flow routing in river channels is computed using the explicit local inertial method bates et al 2010 pontes et al 2017 which is an approximation of the full 1d saint venant equations that neglect only the advective inertial term from the momentum equation i e a hydrodynamic model that is able to represent backwater effects jacon and cudo 1989 meade et al 1991 as it happens in the negro river at manaus due to the stem amazon river influence and floodplain attenuation our reasons for using the mgb model are 1 its satisfactory performance for large scale applications e g paiva et al 2013a pontes et al 2017 siqueira et al 2018 and 2 the past successful attempts with the enkf method e g paiva et al 2013b which demonstrate the potential of this methodology to improve spatio temporal estimates of river discharges 2 3 long term meteorological datasets the 20th century era 20cm climatic reanalysis hersbach et al 2013 was chosen as the input to drive the hydrological model mainly because the era 20cm can still produce statistical estimations despite assimilating no atmospheric observations hersbach et al 2015 which means it is independent of synoptic observations gao et al 2016 resulting in a more homogeneous performance along the temporal coverage 110 years further considering previous assessments of hydrological modeling wongchuig et al 2017 this dataset shows acceptable metric values kge and nse against 27 gauge observations although bias still remains relatively large average of 20 the era 20cm version used here was released in 2014 and it comprises 10 member ensemble predictions forced by the integrated forecast system cy38r1 sea surface temperature sst and sea ice cover sic from the hadsst2 and radiative forcing cmip5 titchner and rayner 2014 the spatial resolution of the final product used herein was 0 25 and the 10 available ensemble members were assessed the dataset is available at https apps ecmwf int datasets data era20cm daily levtype sfc last access 20 march 2016 for bias correction the hybam observed precipitation hop guimberteau et al 2012 dataset was used as referenced observation hop is a gridded daily rainfall data set 1 1 produced by geostatistical interpolation from 752 rain gauges across the amazon basin covering the period from 1980 to 2009 for more details see guimberteau et al 2012 and espinoza et al 2016 the dataset is available at ore hybam http www ore hybam org last access 24 october 2017 2 4 bias correction several methodologies have been developed to remove the bias of precipitation outputs from climatic models therefore three widely used bias adjustment methods were tested in this research the linear scaling lsc approach was often assessed to remove bias of precipitation schmidli et al 2006 lenderink et al 2007 teutschbein and seibert 2012 eisner and voss 2012 chen 2013 lafon et al 2013 n tcha m po et al 2016 because of its simplicity usually a multiplicative correction is used for precipitation instead of an additive to avoid negative corrected values the lsc bias removal was calculated for each unit catchment on a monthly basis the disadvantage of the lsc method is that this value is used equally for extreme events and common events and there is the possibility of overestimating corrected precipitation when 1 the ratio of monthly values between observations and era is large and 2 the daily era value to be corrected is larger than the corresponding observed daily value for the lsc method to perform better a ratio threshold was applied lsct so that when ratio values exceeded this threshold the multiplicative factor became an additive factor and this threshold was established once several values were tested we considered a ratio threshold greater than 1 to avoid negative values in corrected precipitation because lsc is usually used to remove bias in the mean only lenderink et al 2007 teutschbein and seibert 2013 quantile mapping methods were also applied which have already been widely used in hydrological applications to correct mean and variance as well wood et al 2004 teutschbein and seirbet 2012 2013 ngai et al 2017 the empirical quantile mapping eqm and the parametric quantile mapping gamma distribution gqm were assessed the aim was to match the quantile of a referenced precipitation value to the observed value at the same quantile through the construction of cumulative distribution functions cdfs during a referenced calibration period more details regarding the equations used for bias correction are described in the supplementary material in this study we relied on the bias correction as a stationarity assumption where a similar correction method is applied to both the referenced 1990 2009 and past period before 1990 2 5 data assimilation of long term in situ discharge the aim of da techniques is the efficient use of observational information to enhance predictions of model state variables using both model and observation uncertainties madsen and skotner 2005 the enkf method of da used in this research is widely employed in hydrological applications since it enables a simplified implementation of hydrological models where non linear models are predominant enkf defines the model uncertainty as a function of the spread of the model state ensemble using a monte carlo approach implementation of the enkf da scheme in mgb is based on the algorithm developed by evensen 2004 and it can be divided into two steps forecasting and updating as described below for the model the following relation holds 1 x k 1 m x k u k θ q k where the vector x represents model state variables u is the model forcing θ is the model parameters m is the model function that relates state variables at time k with those at time k 1 and qk represents the model uncertainties the observation equation is 2 y k h x k ε k where y is a vector with observations at time k here observed discharge h a function that relates the model state variables x with the correspondent observation y which is a matrix constructed with 1 values where there is a model prediction of the observation and 0 where there is not and ε means the observation uncertainty in the stochastic formulation of enkf the matrix of the forecasted or background ensemble of model states x f is represented as 3 x f x 1 f x 2 f x n ens f where x i f represents each ensemble member of the model states until the total number of defined members n ens the model state matrix x a is updated as the response to the new available observations as follows 4 x a x f k y h x f 5 k p f h t hp f h t r 1 where the x a and x f are the analysis updated and forecasted background model state variable respectively k is the kalman gain p f and r are the covariance matrices of model q and observation ε uncertainties respectively the particularity in the enkf method is that the model error covariance matrix is generated by a set of members from perturbations of the model forcing state variables parameters based on a priori known error this error covariance matrix is estimated from the ensemble anomalies clark et al 2008 as follow 6 p f p e f x f x f x f x f t p a p e a x a x a x a x a t where p e f and p e a are the covariance matrices of the model for the forecast and analysis respectively and t super index means the transpose operator 2 6 experiments and case study 2 6 1 amazon case study and model setup the amazon basin was chosen as a proof of the concept of hrxx because it is the world s largest basin and it drains more than 6 million km2 and discharges 15 of the freshwater that reaches the world s oceans yet its ground observational network is scarce willmott et al 1994 marengo 2005 and its water resources meet many human needs such as fluvial transportation agriculture fisheries and energy production the amazon basin is experiencing a noticeable process of biophysical transition nobre et al 2016 and hydrological extreme events such as floods and droughts have been recorded during the last years with reported increasing of magnitude and frequency due to rainfall intensity marengo et al 2013 2016 espinoza et al 2018 wang et al 2018 barichivich et al 2018 furthermore there is an evident pattern of an upward trend of the frequency of extreme floods in the northern and on the main stem region callède et al 2004 espinoza et al 2009 wongchuig et al 2017 and an upward trend of extreme drought events in southern regions lopes et al 2016 molina carpio et al 2017 herein we applied the same model setup and parameterization used in the south american mgb version from siqueira et al 2018 as such the basin was discretized using a fixed river length of δx 15 km to provide a balance between computational efficiency and numeric stability with respect to the hydrodynamic routing resulting in 12 466 unit catchments ranging from 20 to 2600 km2 the model was forced with a 0 25 horizontal resolution mswep v1 1 precipitation beck et al 2017 and long term monthly meteorological data from the cru cl 2 0 dataset new et al 2002 in addition the model was calibrated between 1990 and 2010 using daily river discharges and was validated using multiple data sources including water levels in situ and satellite altimetry terrestrial water storage and evapotranspiration estimates further details about model setup and performance can be found in siqueira et al 2018 datasets available at http www gloh2o org for mswep rainfall dataset https crudata uea ac uk cru data hrg tmc for cru climatological dataset and http www snirh gov br hidroweb publico medicoes historicas abas jsf for in situ daily discharge 2 6 2 assimilation parameters and localization approach in this research assimilation parameters were assumed to know hydrological model errors only the precipitation was perturbed in this study considered as the main forcing to the model biancamaria et al 2011 liu et al 2012a paiva et al 2013b the adopted perturbation follows a log normal distribution of errors as proposed by nijssen and lettenmaier 2004 7 p c 1 β e 2 1 e x p l n e 2 1 s p where p c is the perturbed variable precipitation or model state variables p is the non perturbed variable e is relative error β is relative bias here adopted as 0 0 and s is a random variable that follows the time evolution of model error according to evensen 2003 8 s k α s k 1 1 α 2 w k 1 α 1 δ t τ t where the coefficient α 0 1 indicates the influence of temporal correlation on the model errors α 0 indicates a high correlation while α 1 indicates a random field of errors constant in time no temporal correlation w is a stochastic term with mean 0 and variance 1 following a gaussian distribution and τ t is the temporal decorrelation length time units in this study a function of the discharge observation q obs was adopted for the estimation of the matrix covariance of observation errors σ obs 2 clark et al 2008 9 σ obs 2 ε obs q obs 2 where ε obs is the discharge error parameter that could be considered as the uncertainty on river discharge measurement and a value of 10 was adopted in principle based in previous assessments di baldassarre and montanari 2009 clark et al 2008 paiva et al 2013b to afford an adequate representation of the error covariance matrix the enkf methodology needs a sufficient ensemble size to avoid spurious correlations between large rivers with a distant reach in this context to avoid this problem houtekamer and mitchell 2001 proposed ignoring remote observations in the analyzed local point through the use of the covariance localization method a correlation matrix was estimated using a distance dependent correlation function gaspari and cohn 1999 finally the incorporation of a covariance localization matrix sakov and bertino 2011 to the equation referred as a local ensemble kalman filter lenkf houtekamer and mitchell 2001 2005 ott et al 2004 tong 2018 is expressed 10 x a x f ρ p f h t ρ o hp f h t r 1 y h x f where ρ and ρ o are correlation matrices and represents the schur product the correlation matrices were calculated using a fifth order function as determined by gaspari and cohn 1999 and suggested by hamill et al 2001 and houtekamer and mitchell 2001 11 ρ r e 1 1 4 e r 5 1 2 e r 4 5 8 e r 3 5 3 e r 2 0 e r 1 12 e r 5 1 2 e r 4 5 8 e r 3 5 3 e r 2 5 e r 4 2 3 e r 1 r e 2 r 0 e 2 r where e represents the distance along the river network between the observation and the analyzed river reach and r means the radius of influence for this implementation ρ is a n m dimension wherein each column presents the correlations at one observation location unit catchment with all model state variables of all unit catchments and ρ o is an m m dimension wherein each column presents the correlations at one observation with all other observations located in their respective unit catchment in this research enkf and lenkf are related to eqs 5 and 10 respectively 2 6 3 assimilation and validation datasets daily in situ discharge and water level observations from 114 gauges were used in this research divided almost equally for assimilation within the da scheme 57 and for validation purposes 57 fig 2 for assimilation and validation criteria gauges with a coverage greater than a 30 year record and a 15 year record were chosen respectively these datasets were provided by the environmental research observatory so hybam ore hybam http www ore hybam org last access 18 february 2017 and the national water agency ana brazil http www snirh gov br hidroweb last access 09 august 2017 a table with more detailed information about in situ gauges and data quality control used in this research can be found in the supplementary material 2 6 4 experiments for hydrological reanalysis evaluation the following procedures were developed to achieve the hrxx 1 selection of the ensemble members of precipitation from the era 20cm climatic reanalysis based on their performances 2 determination of the optimal radius of influence for the case study region through the lenkf da scheme 3 assessment of the bias removal methods of daily precipitation forcing in comparison with the hop 4 generation of the hrxx through the use of both the optimal radius of influence within lenkf and the best bias corrected precipitation forcing the statistics indexes nash sutcliffe efficiency nse the kling gupta kge the absolute value of stream flow volume error hereafter referred to as bias and the relative reduction in root mean square error δrmse were used to assess performance in daily discharge and water level values produced by the hr the nse is a normalized statistic that determines the relative magnitude of residual variance compared with the observed data variance while the kge offers interesting results in model performance because it uses the most components such as correlation variability and bias terms both nse and kge range between and 1 perfect fit the δrmse compares relatively the performance decreasing errors of the model simulation using the da scheme with respect to the ol free run simulation 12 nse 1 i 1 nt q obs t q sim t 2 i 1 nt q obs t q obs 2 13 kge 1 r 1 2 σ sim μ sim σ obs μ obs 1 2 μ sim μ obs 1 2 14 bias i 1 nt q sim t i 1 nt q obs t i 1 nt q obs t 15 rmse 1 n i 1 nt q obs t q sim t 2 δ r m s e rmse improved rmse open l o o p rmse open l o o p where nt is the number of observations σ is the standard deviation and μ is the mean and rmse improved can be referred to as bias correction or assimilation for precipitation forcing we assessed the 10 ensemble members available from the era 20cm climatic reanalysis to determine the most suitable of them for following analysis the ol simulations were carried out for each member and all discharge gauges 113 were used for validation during the common period from 1980 to 2010 the statistical performance indexes and fewer errors with respect to the mean of the ensembles were considered when choosing the ensemble members for the following analysis it is important to note that the evaluation of the 10 ensemble members can provide an indication of the uncertainty of the precipitation forcing which could be taken into account for the perturbation of forcing within the da scheme a general proxy was developed to estimate the optimal radius of influence for the basin in the study we tested a range of radii between 50 and 5000 km which was selected considering closest values of influenced area in the amazon basin emery et al 2018 the size of 100 members was determined by previous enkf implementation in the amazon basin paiva et al 2013b and for other hydrological studies huang et al 2008 tong et al 2012 nevertheless this could result in a huge computational demand because of 1 the long simulation assimilation window 110 years 2 the large spatial discretization of the study area and 3 several radius of influence scenarios to be assessed therefore for this specific experiment only the ensemble size of 25 members was used to estimate the optimal radius of influence the validation was carried out using a set of 56 in situ discharge gauges described in section 2 6 3 during the period from 1980 to 2010 to assess the bias removal methods of era 20cm precipitation a referenced period from 1990 to 2009 and a validated period from 1980 to 1989 were considered these periods were chosen because observation data availability 1980 2009 from the hop dataset described in section 2 3 the validation performance was assessed for both precipitation and discharge for discharge we carried out two periods of validation 1 from 1980 to 1989 using all discharge gauges 113 and 2 assessing the performance of bias removal methods for past eras during the common period from 1931 to 1948 we also used seven discharge gauges with long records for precipitation validation all unit catchments were assessed from 1980 to 1989 for the hrxx two scenarios of assimilation were considered 1 using all assimilation gauges 57 validated against 56 gauges and 2 using only seven gauges with the longest time records validated against the 106 remaining gauges the second scenario was assessed because we consider validation necessary when just a few gauges seven are used for assimilation purposes which happened the most during the period from 1908 to 1970 of the simulation finally also assessed was the performance of the anomalies in water levels at the longest data record in the amazon basin located in manaus which was not used for assimilation purposes due to manaus records are controlled by solimões river level variability generating a hysteresis effect in the rating curve it was carried out from 1903 to 2010 the methodology developed in this research has the objective of estimating a long and consistent spatio temporal register of hydrological variables mainly discharge and water level through 1 hydrologic hydrodynamic modeling 2 a da method 3 a simple localization approach and 4 bias correction of precipitation forcing to summarize these procedures fig 3 and table 1 show the general framework of the methodology and experiments that were applied in this research 3 results and discussions 3 1 open loop ensemble members performance the ol simulation also known as free run simulation was considered as the background for following tests as we expected the ol simulations using the 10 ensemble members of era 20cm climatic reanalysis showed medium performance in the amazon basin according to the statistical indexes this performance was already noted in previous studies wongchuig et al 2017 the average performances for the median of 10 members of the ensemble were 0 61 0 40 and 20 6 for kge nse and bias respectively there was no clear significant difference among the members performance for daily discharge according to a student s t test at 95 confidence level therefore for the following analyses the members with less rmse in the daily precipitation with respect to the mean of the 10 ensemble members was chosen nevertheless the uncertainty of the 10 ensemble members can also be considered through their ensemble standard deviation for the perturbation of the precipitation within the da scheme 3 2 assessment of the localization approach a general approach to estimating the optimal value for the radius of influence across a river routing network is presented in this section through the use of the polynomic equation developed by gaspari and cohn 1999 the localization experiments were carried out considering a range of radius values closest to previous studies emery et al 2018 the spatial distribution of the correlation values from the 57 assimilation gauges considering several radii of influence is shown in fig 4 for each simulation statistical indexes were applied to find the optimal radius fig 5 shows the boxplots of performance considering the validation and assimilation gauges the lenkf simulations showed more clearly the sensible approach of the use of the localization technique in assimilation fig 5b than in validation fig 5a gauges according to the statistical indexes when the localization technique was applied lenkf the performance increased directly proportional with the radius of influence until a certain value fig 6 shows a general increase in performance when different radii of influence are applied within the localization method in addition better results were found when validation is performed in gauges with large contribution areas 25 000 km2 it is interesting to note that for the δrmse metric enkf showed an increase in errors compared with the ol when all the validated gauges were used which can be explained due to the spurious correlations between the remote locations of assimilation gauges and the updated unit catchments the opposite behavior was observed when validation gauges with large contribution areas were analyzed because these are usually closest to the assimilation gauges used those with long series and therefore located in biggest contribution areas in general the localization technique greatly improved da performance which was already observed by paiva et al 2013b for large basins such as the amazon basin in general the optimal values were found between 500 km and 2000 km which fits close to values found by emery et al 2018 consequently the radius of influence of 1000 km was chosen because of its relatively good performance and greater spatial coverage fig 4 92 of which represents 5 4 106 km2 the following simulations were assessed using 100 ensemble members 3 3 validation of data assimilation scheme localization and bias correction in this section we present the performance of the enkf da scheme in validated gauges when a size of 100 ensemble members and an optimal radius of influence of 1000 km as established in previous section were used lenkf fig 7 shows improvements in performance for all statistical indexes for the assimilation and validation gauges when the localization technique is used for the median of validation gauges the δrmse index improved from 1 to 7 fig 7a considering the comparison between the ol red and lenkf blue the statistics were consistent for the bias nse and kge improving from 19 to 17 from 0 28 to 0 47 and from 0 56 to 0 62 respectively improvements were found for the nse index for 18 of the validation gauges in which values less than 0 50 went to greater than 0 75 and approximately 24 of all gauges with values greater than 0 25 of bias were reduced to 19 the performance of bias correction methods was assessed against precipitation and discharge records during the validation period 1980 1989 and for the longest in situ records of discharge gauges during the oldest period 1931 1948 fig 8 shows the analysis of mean monthly precipitation during the validation period where hop era 20cm raw and era 20cm bias removed were plotted for the northwest region the precipitation was underestimated almost all year for era 20cm reanalysis and mainly during the rainy season in the north region for the western area precipitation was underestimated during the dry period and overestimated during the wet period for the central and southern regions the precipitation was underestimated mainly during the dry season and on average this behavior was also seen for the whole amazon basin the bias correction methods improved monthly precipitation in all regions we can also see the lsc method green lines overestimating values during some dry months which is a problem for this specific method and was described in section 2 4 overall the lsc threshold lsct method has the best performance to correct precipitation on a monthly scale considering the pearson correlation coefficient which improved from 0 97 for the era 20cm raw to 0 99 for the lsct fig 9 shows the bias values for the era 20cm precipitation forcing spatially distributed and aggregated in tri monthly means before and after bias removal the era 20cm shows peculiar behavior in the extreme rainfall regions hotspots as related by wongchuig et al 2017 where the mswep and era interim land rainfall datasets also presented the particular characteristic of overestimation in the eastern flank of the andes while showed underestimation in most hotspots similarly to espinoza et al 2015 using the trmm pr dataset the bias removal method lsct fig 9b which has best performance was effective in constraining bias between the ranges of 5 and 5 for 80 of the amazon basin s area during the span of the referenced and validation periods the daily observed discharge values were also used to assess the bias removal performance fig 10 and table 2 show the statistical index values of daily discharge for the ol simulations before gray and after sky blue each bias removal method we can observe that the best improvement on bias was done by the lsct method during the validation period which was reduced from 20 1 to 14 3 considering the average of all discharge gauge 113 there was also an improvement in the nse and kge indexes using the lsct method from 0 32 to 0 44 and from 0 55 to 0 63 respectively the ol lsc shows the worst performance table 3 even worse than the ol era raw during the validation period the hydrographs of the ol simulation and the ol using precipitation with bias removal are shown in fig 11 the three best and the three worst gauges considering the average bias of all methods were chosen to be plotted during five years for the validation and referenced periods for instance during the validation period fig 11a and b the bias removal methods performed better at the são felipe northern region valparaiso and ipixuna south western region stations in relation to ol era raw dashed red line this improvement is clearly indicated by the reduction of peaks during the rainy season while ol era raw overestimates discharge values this correction is evidently noted at the ipixuna station fig 11a where bias was reduced from 68 to 7 during the validation period further the ji parana and boa esperança south central and eastern regions respectively gauges fig 11b performed the worst for bias it is interesting to note that at the altamira eastern region and boa esperança gauges there is a peak on discharge green line at the end of 1986 when the lsc method was used which explains the decreasing performance when this method was assessed table 2 this problem of overestimation was mentioned in section 2 4 which justifies the application of the threshold on the ratio and what results in a better general performance for the referenced period fig 11c and d the bias of the three stations plotted were improved by all bias correction methods reducing the overestimation on discharge by ol era raw in almost all years for instance in the fazenda passarão gauge northern region where bias was reduced from 34 to 1 on the other hand for the worst gauge stations discharge with bias correction was not much different in comparison with ol era raw as shown mainly at the porto velho and leontino gauges the hydrographs for the seven gauges with longest records are shown in fig 12 and geographical location of each station can be seen at the fig 1s in supplementary material the assessment of bias removal methods in these gauges illustrates their performances during a distant temporal era from the referenced period improvements can be clearly seen at the labrea cruzeiro do sul and óbidos gauges where the peaks were removed for the two first mentioned gauges and enhancements during the recession period for óbidos during the common period from 1931 to 1948 the bias improvement for the average of the seven gauges went from 18 to 9 and achieved the best enhancement at óbidos from 14 to 3 4 which is generally remarkable because the referenced period is temporarily distant these results indicate that the precipitation input dataset has mainly a systematic bias as described in section 2 3 which was acceptably removed by the bias removal methods that mesh with their non stationary assumptions due to statistical performance we have chosen the ol lsct to assess the further experiments for the hr development which means that the final spatio temporal analysis is going to take the best setup of the lenkf scheme when and where observation records were available within an optimal radius of influence in a synergy with the improved bias removed precipitation forcing during the years 1900 to 2010 fig 13 in section 3 4 displays the hydrographs for the assimilation and validation gauges at some stations during a period when observation records are partially available the bias of the ol red line simulations is shown clearly at the serrinha óbidos labrea and cruzeiro do sul gauges while discharge values were improved by lenkf gray and dashed black lines when observations were available which is clearly seen since 1968 it is interesting to see how this improvement spread to the validation gauges most clearly at fazenda borangaba and santos dumont by contrast discharge improvements were not observed well before 1968 for lenkf without bias removal gray line the lenkf scheme was used to improve state variables in spatial and temporal fields using a local assimilation nonetheless this improvement is done when and where observations are available within an area of influence which means that state variables remain biased for several unit catchments before 1970 due to 1 biased precipitation era 20cm forcing 2 limited temporal availability from in situ observation records to be assimilated 3 spatial restriction of state variables updated by localization technique to avoid these constraints and in order to assess the best dataset in as great an area and as much temporal coverage as possible the bias correction was performed to the precipitation forcing from 1900 even though we considered the stationarity assumption of bias correction methods the climatic variability should be represented by in situ observations used in the da scheme afterwards the corrected precipitation and the lenkf scheme will be used to develop the hrxx dataset 3 4 hrxx and multi decadal behavior after validating the performance of the lenkf da scheme and bias correction of the precipitation forcing hrxx in the amazon basin was developed considering the conditions for the optimal radius of influence and best bias correction method hrxx was forced with the bias corrected precipitation since 1900 and the da scheme of in situ discharge records was effectively done by data availability since 1908 1928 and mostly since the end of the 1960s fig 13 illustrates the hydrographs for the assimilation and validation gauges at some stations when observation records are partially available to denote the improvements by both the da scheme and bias correction for serrinha and jusante da cachoeira do caju fig 13a the assimilated observations were available from late 1967 when the improvements to lenkf gray and dashed black lines compared with the ol red line are evidenced by a reduction of peaks in the assimilated gauge which spread to the validation gauge appreciably since the middle of 1982 when observations are available similar behavior occurs at labrea with fazenda bocanegra and at cruzeiro do sul with santos dumont where improvements by da spread when observations were available since 1968 in all these cases we highlight the improvements by bias correction when observations were not available before 1968 thus hrxx dashed black lines shows the correction of overestimated peaks by ol which was not possible to do by lenkf without bias removal gray line improvements were also important at the óbidos gauge where a rapid recession was removed by a da scheme when observations were available since early 1968 and by bias removal before that fig 13b the hrxx performance is shown in fig 14 in which the statistical indexes are spatially assessed the kge and nse indexes showed values above 0 6 for 63 and 34 of validation gauges respectively which represent an improvement of 20 and 18 in the number of validation gauges with respect to the ol for the validation 46 have values of bias index below 10 indicating an improvement in the number of gauges of 25 in comparison with the ol the results of δrmse indicate a reduction of rmse with respect to the ol of more than 25 for almost 34 of validation gauges finally table 3 summarizes the performance of the statistical indexes for the different scenarios experiments assessed in this research from ol to the hrxx final product we can see a consistent improvement in performance in which values could be considered as satisfactory for hrxx even for the experiment in which only the seven gauges with the longest records were used in the da reaching an average of 10 of bias reductions of rmse of 14 and satisfactory values of 0 51 and 0 66 for nse and kge respectively which could be considered in some ways as representative of the oldest periods before 1970 because one objective in this research was to represent acceptable values since the beginning of 1900 and our validation common period was mostly done since 1980 the manaus water level record since 1903 was also used to validate hrxx in this research as described in section 2 6 4 discharge data by manaus gauge was not used for assimilation purposes therefore they are independent fig 15 shows the water level anomalies for two periods from 1901 to 1930 fig 15a and from 1978 to 2009 fig 15b where the observations ol and hrxx were plotted it is clearly seen in the reduction of peaks from ol to hrxx and the enhancements from the rapid recession during the dry period the sky blue vertical lines in the years 1908 and 1928 indicate when observations were available at porto velho madeira river and at óbidos amazon river of which the latter is located downstream of the manaus gauge and therefore influenced by the da scheme the extreme drought in 1926 marengo and espinoza 2016 was not represented by hrxx because discharge observations by óbidos used in da scheme just started in 1928 besides the 1979 81 1982 83 and 1995 drought events as well as the 1989 1999 and 2009 flood events were better represented the performance of the nse and kge indexes improved from 0 44 to 0 86 and from to 0 72 to 0 87 respectively during the period from 1903 to 2010 hrxx shows a good performance even when observations were not available due to improvements by the bias removal of precipitation forcing which is further enhanced by lenkf when observations are accessible as several studies have shown extreme events in the amazon basin have become more frequent and intense during recent decades these events such as floods and droughts are important because of their economic and social impacts some of these extreme events that occurred in the past were assessed in this research corresponding to the two oldest and two most recent floods and droughts cited in marengo and espinoza 2016 which were based mostly on the impact on the water level at the manaus gauge the spatial impact of these drought and flood events are plotted in figs 16a and 17a respectively the intensity of the event in days was estimated based on a simple approach described in wongchuig et al 2017 where the number of days above or below certain discharge or water level thresholds were counted to determine the impact of the flood or drought events respectively the comparison between observation and simulation hrxx was based on daily water level values at the manaus gauge in addition to that it is important to highlight that several flood after 2009 such as 2012 and 2014 years marengo and espinoza 2016 barichivich et al 2018 were not registered by the hrxx due to our simulation window considering the drought events the years 1906 1926 2005 and 2010 were chosen for this analysis the two oldest drought years were mainly registered at the manaus gauge jenkins 2009 marengo and espinoza 2016 being the drought of 1926 perhaps one of the worst on record williams et al 2005 moreover the 2005 and 2010 events were also registered at the óbidos gauge and reported in the literature espinoza et al 2011 marengo et al 2011 through observation records in the madeira and solimões rivers in the southern and western regions as shown in fig 16a fig 16b shows the water level anomalies of minimum annual values for observations ol and hrxx where three drought events 1906 2005 and 2010 are well represented in the vertical red lines for certain drought years for the common period between observation and simulation the pearson correlation coefficient for the water level anomalies of minimum annual values increased from 0 38 for the ol to 0 72 for hrxx in spite of relative well agreement for correlation between hrxx and observations drought events seem to be underestimated by hrxx mainly before 1928 when observations were not available to be assimilated for floods the events in 1909 1976 1999 and 2009 were selected the 1909 event was detected only at the manaus gauge while the last three events were also detected at the óbidos gauge marengo and espinoza 2016 the intensity of the 1909 flood event was represented in the negro river close to the confluence with the amazon river fig 17 a which was less intense in comparison with the 1976 1999 and 2009 events these events were also reported in the literature through observation records at manaus satyamurty et al 2013 madeira and purus rivers most notably during 2009 event marengo et al 2012 pereira and szlafsztein 2016 as shown in fig 17a for these three recent flood events fig 17b shows a clear concordance between observation and hrxx the pearson correlation coefficient for the water level anomalies of maximum annual values increased from 0 18 for the ol to 0 60 for hrxx which indicates a significant improvement in the performance of detecting maximum events according this methodology finally considering the anomalies of the mean annual values of water level at manaus it increased from 0 22 for ol to 0 69 for hrxx 4 conclusions and perspectives this research aimed to develop in a retrospective manner a consistent register of hydrological variables through the use of a large scale hydrologic hydrodynamic model da scheme and bias removal method lenkf was assessed in this research using a primary approximation of a general radius of influence the local implementation showed improvements with respect to the enkf scheme in the amazon basin even using a relatively large size of ensemble members which demonstrates that local consideration regarding the correlation between assimilation and updated points that are separated by a far distance or physically disconnected on a river network should be taken into account for large scale basin studies the optimal radius of influence was reached at 1000 km which when used within the lenkf scheme for improved discharge representation increasing the nse and kge performance by 70 and 9 respectively with respect to the enkf scheme four bias removal techniques were assessed because 1 climatic reanalysis is usually biased and 2 a da scheme only updates state variables when and where observations are available the improvement in absolute values of bias during the period of validation was assessed for monthly precipitation and for daily discharge for the validation period 1980 1989 and during the oldest period 1931 1948 the linear scaling method using a threshold achieved the best performance among other methods tested in this study the bias values for the era 20cm raw dataset range spatially from 50 to 50 which was finally constrained by bias removal from 5 to 5 for 80 of the study area the improvements on bias for daily discharge values was 40 during the validation period and achievements of 0 45 and 0 64 for nse and kge respectively hrxx proposed herein is based in the large scale mgb model forced with the bias removed precipitation and coupled in synergy with a lenkf scheme its performance was assessed for daily discharge observations at 56 validation gauges and for water level anomalies at the manaus gauge negro river during the longest records in amazon basin historic observed flood and drought events were also assessed for hrxx results indicate that improvements were clearly achieved by hrxx which takes advantage of both a da scheme and a bias removal method in which statistical performance could be considered as satisfactory to represent adequate discharge and water levels across the 20th century in this paper we evaluated the hr methodology to generate a consistent record of hydrological variables on a large scale by the use of long temporal records of in situ discharge and climatic precipitation reanalysis datasets that are globally available this new dataset is the first approach of long term data assimilation of in situ data in the amazon basin despite the fact that our methodology presents some simplifications results show adequately for large scale the hrxx could be useful for the spatial and temporal hydrological characterization e g climate change assessment for several past decades once this basin is considered an important large biome with a considerable control on the carbon cycle and global climate other approaches should also be implemented in the future such as complex approximations to estimate the radius of influence in the lenkf scheme considering spatial and temporal variations for each unit catchment or better bias removal methods that consider non stationary series despite this hrxx developed in this study could be used as a methodology in other large basins around the world 1 to evaluate spatially and temporally distributed hydrological variability across the last century 2 to create consistent records of hydrological extreme events such as floods and droughts and 3 to make availability a complementary dataset in regions with sparse hydro meteorological network declaration of interest the authors declare no conflict of interest the funders had no role in the design of the study in the collection analyses or interpretation of data in the writing of the manuscript or in the decision to publish the results acknowledgments the first author is grateful for a grant from the brazilian agency capes and for enkf codes provided by evensen the authors are grateful for the precipitation datasets supplied by ecmwf and the in situ discharge and water level data provided by hybam and ana institutions we also thank two anonymous reviewers for their comments which helped significantly in the improvement of this manuscript the developed hrxx data for the amazon basin that support the findings of this study are available at mendeley data v3 http dx doi org 10 17632 9kjx9d7ycm 3 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 01 025 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 
6738,determining the bathymetric properties of a river lake or reservoir is important for many reasons because it identifies location of sections with sedimentation or erosion which indicate the key processes and biophysical habitat status this study used observational data of a 5 km section of the danube river transformed into a reservoir after 1972 to determine the best gis interpolation method and the optimal number of sampling points to get an accurate description of the riverbed nine interpolation methods were used to generate bathymetric maps of the danube course between km 955 and km 950 in the area of iron gates reservoir using a variable number of points n 1943 n 4328 n 17139 obtained by single beam echo sounder six methods of deterministic interpolation have been used inverse distance weighting idw criteria automatically determined cad and manually determined md local polynomial interpolation lpi criteria automatically determined cad and manually determined md radial basis function rbf fully regularized spline crs radial basis function rbf spline with tension swt and three geo statistics methods ordinary kriging ok simple kriging sk universal kriging uk cross validation and bathymetric digital elevation models dem s analysis were used to evaluate the accuracy of the estimated data and maps the two interpolation methods inverse distance weighting idw md and simple kriging sk provide satisfactory results even in the case of a small number of points n 1943 if the number of measured points grows and a section grid perpendicular longitudinal is developed the dem s bathymetric accuracy improves significantly especially in the case of complex morphology even if the positive and negative forms of the bed lead to sudden changes in the measured values the obtained results revealed differences between the interpolation methods used particularly in the case of a small number of points measured per perpendicular trajectories but by the addition of points on longitudinal paths a significant improvement of the bathymetric maps is obtained keywords bathymetric measurements number of points transect location interpolation methods iron gates reservoir 1 introduction many riverines processes such as flood impact assessment di baldassarre et al 2017 romanescu 2013 costache et al 2017 understanding of sediment transport sedimatation rates and the impact of catchment land use changes on the river require solid evidence on the riverbed basin eakins et al 2011 andronache et al 2016 mihu pintilie et al 2016 zelenakova and zvijakova 2016 permanet monitoring of riverbed sections and improvements of detailed maps require a methodological framework to collect the data the relationship between emergent and submergent sediments reflects the physical processes that driven by the shore s geomorphology and the depth of water romanescu et al 2011 gesch et al 2009 notebaert et al 2009 thatcher et al 2016 anderson et al 2017 and are the foundation to the probable impact of the different climate change scenarios on the analyzed areas nicholas 2003 romanescu et al 2011 buxton et al 2013 the accuracy of the bathymetric measurements as well as the interpolation extrapolation methods selected to represent the resulted data allow a good understanding of the river conner and tonina 2014 lakes bottoms of the shoreline areas but can also generate errors when the selected method is not the best aguilar et al 2005 gao 2009 there are many geospatial methods in geoinformatics brown and bara 1994 sui and maggio 1999 wilcox and los huertos 2005 but each of them produces errors whether deterministic interpolation methods are used such as inverse distance weighting idw hu et al 2004 merwade et al 2006 local polynomial interference lpi radial base function rbf or geo statistics ordinary kriging ok simple kriging sk universal kriging uk zhang et al 2015 glenn et al 2016 the rapid evolution of measurement equipment and techniques allows the performance of accurate bathymetric measurements a simple analysis of the evolution of equipment starting from the single beam echosounder lafferty et al 2005 powers et al 2015 bandini et al 2017a multi beam hare et al 1995 ernstsen et al 2006 bird and mullins 2008 brown and blondel 2009 yang et al 2017 lidar uav finkl et al 2004 adam et al 2010 millard et al 2013 radar images vogelzang et al 1992 liebe et al 2005 dost et al 2014 zhao et al 2017 hyperspectral images mckean et al 2009 tamminga et al 2014 hamylton et al 2015 can highlight the advantages and limitations of each of them baban 1993 bagheri et al 1998 2015 hogrefe et al 2008 danielson et al 2016 bandini et al 2017b chen et al 2018 single beam echosounders such as midas surveyor 210 khz and 33 khz simrad cx 33 44 200 khz and 50 khz or cee echo 200 khz and 33 khz are capable of transmitting two wavelengths and the measurement error varies from 0 01 m on the frequency of 210 khz and 0 04 m on the frequency of 33 khz the sounding systems receive sbas corrections but also have the ability to interfere with an external gnss or gps receiver so the north south coordinate probing accuracy is high thanks to rtk l1 l2 dual frequency gps systems urick 2013 some echo sound systems have direct capability to record and display dgps position data in the wgs84 system but also in the local grid allowing the user to set spheroid and projection the effect of waves is eliminated by using echo sounders equipped with inertial correction devices imu especially for large rivers and coastal areas where the waves affect the accuracy of recorded data in the case of small rivers medium sized lakes or reservoirs echosounders can be used without such associated facilities alexe and serban 2014 for submerged surveys in areas without gsm or internet signals the gps measurements for determining the water level quota and the north position of the sampling points can be done with the base rover system that involves mounting a base gps located on a point with known coordinates which transmits radio wave corrections to the mobile gps placed in the same vertical plane as the echosounder the position of the water surface and the emerged field altitudes may be measured with a better than 2 cm precision using a trimble r8 rtk gps or where possible direct reading of the water level using rangers or limnigraphs the measurements are made both at the beginning of the survey flights campaign and at the end of it and where the hydrometer rangers are installed readings will be done in conjunction with the moment of the submersed measurement a good survey plan is one that is based on a survey plan that provides the density of points needed for correct data processing carbonneau et al 2006 as well as cost reduction sánchez carnero et al 2012 thatcher et al 2016 and the duration of the field work uunk et al 2010 in the case of the sections involving long journeys over long distances changing of the weather conditions nebulosity wind rainfall temperature change or of the hydrological conditions change of levels turbidity waves ice floes rodrigues et al 2006 may occur during the measurements which impedes the development of the activity and the accuracy of the data obtained schäppi et al 2010 wessels et al 2015 the previous studies indicate that the accuracy of all interpolation techniques is pending on the sampling density and their distribution aguilar et al 2005 anderson et al 2005 chaplot et al 2006 erdogan 2010 guo et al 2010 they also showed that the sampling density referred either to a percentage of the original measurements aguilar et al 2005 anderson et al 2005 guo et al 2010 or to a number of measurements per region chaplot et al 2006 erdogan 2010 starting with the possible limits imposed by climate hydrologic and navigation conditions the present study aims to assess the advantages and disadvantages of various bathymetric analysis methods by i comparing the accuracy of the interpolation methods generally used in the bathymetric field idw lpi uk sk etc for river sectors ii determine the opportunity of developing cross section profiles combined with longitudinal cross section profiles on the surveyed sector iii determine which are the best results obtained and what method of interpolation was more effective the measurements made in this research may constitute a baseline reference for further measurements in this danube section which will allow the modeling of the dynamics of riverbed processes 2 material and methods 2 1 study area the research was conducted on the lower course of the danube at km 955 and 950 between serbia and romania water flow regime is fluvial watery and is dependent on the tributaries flows and the manner of transiting the iron gates reservoir fig 1 construction of the iron gates i hydro energy and navigation system started in november 1963 and was finalized in may 1972 construction wise it is a weight dam with a retention front 1278 m long formed by a central flow dam on both sides there are symmetric hydroelectric power plants flood gates and non flow dams in terms of energy it is defined by an installed total power of 2100 mw and an installed flow capacity of 4350 m3 s the retention level is at 69 5 m with a median fall of 27 17 m the reservoir created by the construction of the dam has a volume of 2400 mil m3 which led to the flooding of a surface of 10 131 ha including the towns of orsova ada kaleh island small villages as well as communication lines transportation networks etc due to the dam built near the village of gura văii the water level rose upstream along the danube river course flooding the major riverbed and the mouths of its tributaries fig 2 the danube valley between km 955 950 is a river sector with a particular feature the island of ada kaleh formed by alluviums transported by the cerna river the constructions which existed on ada kaleh island were partially transferred to simian island downstream from drobeta turnu severin the new location is not present in the section of the current study the hydrobiological characteristics of iron gates reservoir have suffered substantial changes after the flooding of an important land area the new ecosystems that have developed here combining lotic and lentic conditions brezeanu and cioboiu 2006 if in the first years of the lake s existence the planktonic communities were modified in terms of both quantity and quality systematically this process it was stabilized explosions of algae being registered only in the warm season or because of the eutrophic processes brezeanu and cioboiu 2006 still for example the chlorophyll concentration values registered in these sections in the past few years are lower than upstream and in some years even than downstream baranyi et al 2002 dokulil and donabaum 2014 the investigated section has the following characteristics a iron gates reservoir it is a section of the danube valley flooded by the water which amounts to 2400 million cubic meters formed by obstructing the course of the river and flooding over 10131 ha of land in the period 1971 2005 a quantity of about 393 14 million tons of alluviums entered into iron gates reservoir through the baziaş hydrometric section depositing downstream to the dam a volume of 133 15 million tons respectively a 33 9 rate between 1971 and 1985 the alluvial deposits in iron gates reservoir had an increasing trend when a percentage of about 39 5 was reached these being deposited upstream to the dam bondar 2008 b the water flow rate decrease from speeds of about 1 m s at the entrance of the reservoir to 0 45 0 42 m s in the sector where the measurements were made downstream of orşova city c the water transparency is closely related to the alluvial regime and water temperature low transparency values being recorded near the shore due to the vegetation development because the vertical variation of zooplankton and phytoplankton organisms is not large they do not influence the bathymetric data obtained d the waves are not high 10 cm due to the meandering course with abrupt and tall slopes higher values being recorded in bays and inside large opening sections significant seasonal oscillations of the lake level are recorded during periods of drought or high leakage while normal oscillations are recorded as a result of the water processing for producing electric power the differences between the maximum and minimum water level can also reach to 7 m 2 2 bathymetric investigation methods the international hydrographic organization iho has published over the time a set of standards aimed to establish the minimum conditions for performing bathymetric measurements iho 2005 2008 the study wants to establish measurement conditions in order to obtain comparable and good quality results reduce errors avoid uncertainties and highlight the characteristics of the submersed environment for this study both depth independent errors and errors affecting the depth the uncertainty of depth are determined in 95 of cases with the total vertical uncertainty tvu calculated with the formula eq 1 1 tvu a 2 b d 2 where a is the portion of the uncertainty that does not vary with depth b is a coefficient which represents the portion of the uncertainty that varies with depth d depth expressed in meters and b d the portion of the uncertainty that varies with depth iho 2008 starting with these considerations and possible limits imposed by climate hydrologic and navigation conditions particular to the analyzed area measurements were carried out between december 15 17 2017 during conditions of atmospheric calm air and water temperatures of 4 6 c 86 8 air humidity water transparency of about 1 30 m the water having a light green brown color and small waves 10 cm except the situation when the shipping traffic created waves of 30 40 cm the danube flow ranged between 5550 m3 s 15 december 2017 5930 m3 s 16 december 2017 and 6100 m3 s 17 december 2017 the water level recording oscillations from one day to the next but these have been measured and taken into account during the measurements the level changes were not significant therfore hourly corrections were not necessary due to the fact that the duration of the measurements did not exceed more than 6 7 h day and the change in level of that time was within the accuracy range of the system the development of a new survey plan should consider both the density of points needed for correct data processing as well as improved cost efficiency our workflow to achieve the objectives of this paper is show in fig 3 and we used the following software arcgis 10 2 surfer global mapper 13 0 and hypack the survey bathymetric studies started by consulting the technical and constructive features of the dam and of the reservoir checking previous bathymetric elevations checking the designs settings and results of the previous studies in digital format as well as assessing natural conditions and their possible changes geo morphological changes of banks hydrological regime or vegetation cover that might impact the aquatic unit the next step consists of identification of the triangulation points to be used as the basis for the topo geodesic measurements and acquiring the coordinates for these points field verification of the existence of the contour milestones and topo geodesic landmarks necessary for the measurements and creation of the project for emerged measurements classic topo geodesic or gps in the present study the measurements were made using the single beam type echo sounder simrad type cx 33 44 200 khz and 50 khz with a measurement error rate in ideal conditions that varies between 0 01 m on the 210 khz frequency to 0 04 m on the 33 khz frequency the position of the water surface and the levels of the immerse land was measured with 2 cm precision by using a trimble r8 rtk gps and correlated with direct reading of the water level from the hydrometric station as well as with satellite imagery checking the satellite positioning and scheduling the work days and hours to ensure optimal quality of the gps measurement session and equipment preparation the levels of water are registered at the beginning and at the end of the working session or more often where required subsequently there are performed the on site identification of the transverse profile measuring sections development of the geodesic support network and performed surveys measurements of the cross sections on the shores and in the low depth water areas where the measurements with the echosounder are not possible measurements with the total station gps etc and navigation by boat on the designed routes using gps guidance and profile heads and performed the bathymetric measurements the field stage is followed by an office stage which consists of determining the xyz coordinates in a measuring system stereo 1970 black sea 1975 and making corrections for the acquired immersed survey data elimination of erroneous points and processing of the raw data obtained with the echosounder development of the digital terrain model dtm and of the bathymetric map using arcgis 2 3 interpolation methods using arc gis 10 2 geostatistical analyst extension 9 interpolation methods out of which 6 deterministic interpolation methods were used inverse distance weighting idw criteria automatically determined cad and manually determined md local polynomial interpolation lpi criteria automatically determined cad and manually determined md radial basis function rbf completely regularized spline crs radial basis function rbf spline with tension swt and 3 geo statistics methods were used ordinary kriging ok simple kriging sk universal kriging uk interpolation resulted in bathymetric dem s with grid cell size 9 83 9 83 m the idw represents a deterministic method of interpolation whereby the estimation of values is made based on nearby known locations closer points have a greater impact in estimating the values while the more distant points have a lower impact johnston et al 2001 werner 2001 calculated following eq 2 2 z x o i 1 n x i h ij β i 1 n 1 h ij β where for this study z x0 represents the interpolated value n is the number of points xi is the ith data value hij is the separation distance between interpolated value and the sample data value and ß denotes the weighting power lpi methods are useful because they are capable of producing surfaces that capture the short range variation lpi fits the local polynomial using points only within the specified neighborhood instead of all the data then the neighborhoods can overlap and the surface value at the centre of the neighborhood is estimated as the predicted value wang et al 2014 rbf methods fit dem through the measured sample values while minimizing the total curvature of the surface and may predict values under the minimum of measured value and over the maximum of the measured values which is an advantage as compared to idw but the method is inefficient if sudden changes of the measured values take place johnston et al 2001 unlike the deterministic methods the geo statistic interpolation techniques chen et al 2011 are able to provide better predictions considering the spatial relationships between the measurement points and spatial correlations sanders and chrysikopoulos 2004 legleiter and kyriakidis 2008 merwade 2009 tan and xu 2014 amante and eakins 2016 ordinary kriging uk uses only the points measured in the vicinity to estimate the predicted value of depth and assumes that the mean is constant but unknown focuses on spatial components using the equation eq 3 3 z s μ ε s where for this study s x y is a location z s is the bathymetric depth value µ a constant mean for the data no trend and random errors ε s with spatial dependence johnston et al 2001 the prediction is formed as a weighted sum of the data calculated following eq 4 4 z s 0 i 1 n λ i z s i where for this study z si is the measured value at the ith location λ i is a unknow weight for the measured value s0 is the predicted location and n is the number of points universal kriging uk is useful when the values of the depth record an obvious trend the trend or drift is a continuous spatial variation which is too irregular to be modeled by a simple mathematical function johnston et al 2001 wang et al 2014 3 results and discussions creation of the project regarding submerse measurements was done by using the hypack software environment a process which includes the following steps setting of the geodetic parameters importing the files on the reservoir contours and possible obstacles route planning and drawing of the route lines eventually importing the route from the previous survey study and changing it where necessary setting the parameters for the data transfer from the echosounder to the laptop the results obtained using the hypack software are presented in fig 4 this study compares accuracy and efficiency of obtaining underwater dem s from the danube river resulting from measurements with a single beam equipment on perpendicular and or longitudinal paths and different interpolation methods three sets of data were used a 1943 measured on 4 perpendicular routes b 4328 points measured on 10 perpendicular routes and c 17 139 points measured on 25 perpendicular routes and 5 longitudinal routes fig 5 covering an area of approximately 5 6 km2 because many studies use only profiles perpendicular on the riverbed zhang et al 2016 šiljeg et al 2015 takekawa et al 2010 we tried to analyze the importance of the number of routes and their distribution perpendicular longitudinal in order to determine which is the best solution to get more detailed maps of the aquatic unit increasing the number of points leads to smaller standard errors and standard deviation which results in a lower variance coefficient in order to assess and compare the accuracy of the estimated measurements using different interpolation methods guarneri and weih 2012 errors were measured using eqs 5 9 5 m e a n e r r o r 1 n i 1 n e i 6 r o o t m e a n s q u a r e e r r o r 1 n i 1 n e i 2 7 a v e r a g e s t a n d a r d e r r o r 1 n i 1 n s i 2 8 m e a n s t a n d a r d i z e d e r r o r 1 n i 1 n e i s i 9 r o o t m e a n s q u a r e s t a n d a r d i z e d e r r o r 1 n i 1 n e i s i where for this study ei and si 2 represent the estimated error and variance for xi for xi the estimated error was calculated using the cross validation procedure barton et al 1999 respectively the measured values xi were removed from the data set and in the next stage were estimated using the remaining measurements table 1 the cross validation allows the assessment and comparison of the performances of the interpolation methods by dividing the data set into 2 one set is used for building the model and the other for validating the model castellarin et al 2009 erdogan 2010 bailly et al 2010 scatter plots of the water level depth in danube river section estimated by deterministic method idw cad and md and geo statistical method sk x and y axis units m are presented in fig 6 near the banks due to the smaller number of points obtained through measurements the low water depth and the high slopes of the river bed cause rapid changes in the measured values which generates large errors of the estimated values by running the 9 interpolation methods in the 3 analyzed situations a 1943 points obtained by 4 routes perpendicular to the riverbed with a distance of 1 5 km between them and respectively 4 6 m between the points resulting in a point density of 345 points km2 b 4328 points obtained by 10 perpendicular routes with a maximum distance of 0 842 km between them and minimum distance of 0 158 km between them and 4 6 m between points resulting in a point density of 768 points km2 c 17 139 points obtained by 25 perpendicular routes and 5 longitudinal routes and 4 6 m between points resulting in a point density of 3041 points km2 it is noticed that selecting the manual criteria was based on the obtaining lower values of the standard deviation and of the map improvements obtained using automated criteria even in the situation of use a small number of points for all 3 situations analysed the distance between 2 consecutive measurements was between 4 and 6 m because the speed craft was constant small speed variations generated the variation in the distance between the consecutive points 4 6 m were due to the moments when the craft approached the shores and we changed movement direction or when because of intense shipping traffic we were required to accelerate or decrease speed in order to avoid a collision fig 7 highlights the differences between the interpolations methods used while in the case of using 17 139 points for interpolation the differences are not very obvious but reducing the number of point to 1943 excepting idw md and sk interpolation methods visibly reduced the accuracy of the maps in the case when the number of points increases to 4328 the variants obtained using idw md interpolation methods lpi md ok sk uk are most likely to be used in data processing table 2 showed the statistical results of the analysis of the interpolation both deterministic and geo statistical and in case of the deterministic methods both automatic determination criteria cad and manual determination criteria md were selected the quality of the resulting maps is influenced by the distance between the points both vertically and horizontally but also by the number of neighbors and number of sectors for two of the deterministic interpolation methods idw lpi we used both the automatic option as well as the manual one because the results of idw interpolation depend on power value and the search neighborhood strategy we decided that in the case of the manual method we will use when interpolating a lower number of neighbors and more sectors repeated simulations showed that in case the number of measured points is low and the distance between sections is large for n 1943 points reducing the number of neighbors to those around the predicted value at 4 and using 4 sectors can produce bathymetric maps which are acceptable for analyses while estimated values have higher errors than the case of the automatic method using the interpolation methods which led to the best results idw md and sk longitudinal profiles were drawn in the east west direction for idw md using the simulated results in the three situations and for sk only for n 17 139 points fig 8 with the largest differences being recorded for the situations where the number of points was lower while when idw md and sk are compared for n 17 139 points the differences are low in this study area where the riverbed shows obvious irregularities the results of the two interpolation methods also used previously for the longitudinal profiles idw and respectively sk are also confirmed by the representation of the aquatic field slopes fig 9 the differences in max slope are caused by the use of bathymetric dem s obtained by different interpolation methods idw and sk actually these differences can also be noticed in fig 8 when the profile lines are similar but not identical which generates slope differences on small areas the slope is of major importance in the deviation of echosounder waves generating erroneous values as well as in the sedimentation erosion process that provides different textures to the riverbed by using perpendicular routes valuable information may be obtained regarding the transverse section profile of the riverbed but the addition of the longitudinal profiles allows the streamlining of the interpolation methods and improvement of the final dem s in the case of riverbeds by developing the longitudinal profiles that join the biggest depths obtained based on the perpendicular profiles the bathymetric maps are improved and the errors are reduced and the creation of a tracking grid is an optimal solution particularly for complex sections 4 conclusions the depth of the water in rivers lakes and reservoirs is an important morphometric indicator which controls the physical chemical and biological processes in the case of reservoirs periodic monitoring of the water depth and creation of bathymetric maps allows for estimation of morphometric parameters and the evolution of hydrodynamic processes the usage of single beam eco sounders in bathymetric measurements has both advantages and disadvantages which we need to take into consideration when deciding which equipment to use the main disadvantage of single beam equipment is the fact that we obtain a smaller point number through a single pass compared with multi beam equipment however this situation can be compensated by doing a larger number of passes on several profiles and with a longer duration for the same surface also single beam equipment compensate for these disadvantages with their acquisition price operating costs and staff training costs which are much lower there is also the option to operate them even at low depths the obtained results show that the selected interpolation methods influence the accuracy of the final cartographic products but the most important role is that of choosing the number of sections on which measurements are to be made and their position which ultimately determines the point density both horizontally and vertically the exclusive usage of profiles perpendicular to the riverbed is not efficient in the case of long river sections because it requires a large amount of time for data acquisition increases operating costs and exposes operators to extra risks intense shipping traffic severe meteorological or hydrological conditions development of a grid consisting of perpendicular and longitudinal routes allows a better assessment of the riverbed morphology highlighting the positive and negative forms of the riverbed improves the accuracy of interpolation methods and reduces errors and uncertainties especially in the sections where past turbulence caused complex morphology if the number of points obtained in the measurement campaign is high all the interpolation methods used have proved effective in creating of bathymetric maps including idw md lpi md ok sk or uk the selection of transverse and or longitudinal routes for boat movements during the echo sounder measurements and the displacement speed may lead to erroneous dem in case of an insufficient number of measurements and complex morphology of the river bed even if the statistical errors obtained by the selected interpolation methods are not very large the development of a survey plan should consider both the density of points needed for correct data processing as well as improved cost efficiency this is why if preliminary preexisting information about the morphology of the riverbed about to be analysed are not enough we don t have the time required for making detailed measurements or if there are limitations due to climate hydrological or shipping traffic conditions we may use perpendicular profiles positioned at distances larger than 200 m but which should be complemented by longitudinal profiles parallel to the shores with at least one uniting the points with greatest depth in this situation in which the number of obtained points is small the use of manually adjusted idw may lead to cartographic products that provide preliminary information but they need to be further improved because the results of interpolation using idw depend on the power value and the search neighborhood strategy the reduction of the number of neighbors to those around the predicted value and finding possible directional influences in order to establish the optimum number of sectors can produce acceptable bathymetric maps even if the estimated values will have larger errors than in the case of the automatic method author contributions all authors have equal contribution to the preparation of this scientific paper acknowledgments this research is supported by the project analysis of the submerged evolution of the danube valley between gura văii and dubova no ub 14912 2017 the authors thanks for advice and suggestions offered by dr johan schutten from scottish environment protection agency and for technical advice provided by mr vasile bagrinovschi from centre for environmental research and impact studies university of bucharest conflicts of interest the authors declare that they have no conflict of interest 
6738,determining the bathymetric properties of a river lake or reservoir is important for many reasons because it identifies location of sections with sedimentation or erosion which indicate the key processes and biophysical habitat status this study used observational data of a 5 km section of the danube river transformed into a reservoir after 1972 to determine the best gis interpolation method and the optimal number of sampling points to get an accurate description of the riverbed nine interpolation methods were used to generate bathymetric maps of the danube course between km 955 and km 950 in the area of iron gates reservoir using a variable number of points n 1943 n 4328 n 17139 obtained by single beam echo sounder six methods of deterministic interpolation have been used inverse distance weighting idw criteria automatically determined cad and manually determined md local polynomial interpolation lpi criteria automatically determined cad and manually determined md radial basis function rbf fully regularized spline crs radial basis function rbf spline with tension swt and three geo statistics methods ordinary kriging ok simple kriging sk universal kriging uk cross validation and bathymetric digital elevation models dem s analysis were used to evaluate the accuracy of the estimated data and maps the two interpolation methods inverse distance weighting idw md and simple kriging sk provide satisfactory results even in the case of a small number of points n 1943 if the number of measured points grows and a section grid perpendicular longitudinal is developed the dem s bathymetric accuracy improves significantly especially in the case of complex morphology even if the positive and negative forms of the bed lead to sudden changes in the measured values the obtained results revealed differences between the interpolation methods used particularly in the case of a small number of points measured per perpendicular trajectories but by the addition of points on longitudinal paths a significant improvement of the bathymetric maps is obtained keywords bathymetric measurements number of points transect location interpolation methods iron gates reservoir 1 introduction many riverines processes such as flood impact assessment di baldassarre et al 2017 romanescu 2013 costache et al 2017 understanding of sediment transport sedimatation rates and the impact of catchment land use changes on the river require solid evidence on the riverbed basin eakins et al 2011 andronache et al 2016 mihu pintilie et al 2016 zelenakova and zvijakova 2016 permanet monitoring of riverbed sections and improvements of detailed maps require a methodological framework to collect the data the relationship between emergent and submergent sediments reflects the physical processes that driven by the shore s geomorphology and the depth of water romanescu et al 2011 gesch et al 2009 notebaert et al 2009 thatcher et al 2016 anderson et al 2017 and are the foundation to the probable impact of the different climate change scenarios on the analyzed areas nicholas 2003 romanescu et al 2011 buxton et al 2013 the accuracy of the bathymetric measurements as well as the interpolation extrapolation methods selected to represent the resulted data allow a good understanding of the river conner and tonina 2014 lakes bottoms of the shoreline areas but can also generate errors when the selected method is not the best aguilar et al 2005 gao 2009 there are many geospatial methods in geoinformatics brown and bara 1994 sui and maggio 1999 wilcox and los huertos 2005 but each of them produces errors whether deterministic interpolation methods are used such as inverse distance weighting idw hu et al 2004 merwade et al 2006 local polynomial interference lpi radial base function rbf or geo statistics ordinary kriging ok simple kriging sk universal kriging uk zhang et al 2015 glenn et al 2016 the rapid evolution of measurement equipment and techniques allows the performance of accurate bathymetric measurements a simple analysis of the evolution of equipment starting from the single beam echosounder lafferty et al 2005 powers et al 2015 bandini et al 2017a multi beam hare et al 1995 ernstsen et al 2006 bird and mullins 2008 brown and blondel 2009 yang et al 2017 lidar uav finkl et al 2004 adam et al 2010 millard et al 2013 radar images vogelzang et al 1992 liebe et al 2005 dost et al 2014 zhao et al 2017 hyperspectral images mckean et al 2009 tamminga et al 2014 hamylton et al 2015 can highlight the advantages and limitations of each of them baban 1993 bagheri et al 1998 2015 hogrefe et al 2008 danielson et al 2016 bandini et al 2017b chen et al 2018 single beam echosounders such as midas surveyor 210 khz and 33 khz simrad cx 33 44 200 khz and 50 khz or cee echo 200 khz and 33 khz are capable of transmitting two wavelengths and the measurement error varies from 0 01 m on the frequency of 210 khz and 0 04 m on the frequency of 33 khz the sounding systems receive sbas corrections but also have the ability to interfere with an external gnss or gps receiver so the north south coordinate probing accuracy is high thanks to rtk l1 l2 dual frequency gps systems urick 2013 some echo sound systems have direct capability to record and display dgps position data in the wgs84 system but also in the local grid allowing the user to set spheroid and projection the effect of waves is eliminated by using echo sounders equipped with inertial correction devices imu especially for large rivers and coastal areas where the waves affect the accuracy of recorded data in the case of small rivers medium sized lakes or reservoirs echosounders can be used without such associated facilities alexe and serban 2014 for submerged surveys in areas without gsm or internet signals the gps measurements for determining the water level quota and the north position of the sampling points can be done with the base rover system that involves mounting a base gps located on a point with known coordinates which transmits radio wave corrections to the mobile gps placed in the same vertical plane as the echosounder the position of the water surface and the emerged field altitudes may be measured with a better than 2 cm precision using a trimble r8 rtk gps or where possible direct reading of the water level using rangers or limnigraphs the measurements are made both at the beginning of the survey flights campaign and at the end of it and where the hydrometer rangers are installed readings will be done in conjunction with the moment of the submersed measurement a good survey plan is one that is based on a survey plan that provides the density of points needed for correct data processing carbonneau et al 2006 as well as cost reduction sánchez carnero et al 2012 thatcher et al 2016 and the duration of the field work uunk et al 2010 in the case of the sections involving long journeys over long distances changing of the weather conditions nebulosity wind rainfall temperature change or of the hydrological conditions change of levels turbidity waves ice floes rodrigues et al 2006 may occur during the measurements which impedes the development of the activity and the accuracy of the data obtained schäppi et al 2010 wessels et al 2015 the previous studies indicate that the accuracy of all interpolation techniques is pending on the sampling density and their distribution aguilar et al 2005 anderson et al 2005 chaplot et al 2006 erdogan 2010 guo et al 2010 they also showed that the sampling density referred either to a percentage of the original measurements aguilar et al 2005 anderson et al 2005 guo et al 2010 or to a number of measurements per region chaplot et al 2006 erdogan 2010 starting with the possible limits imposed by climate hydrologic and navigation conditions the present study aims to assess the advantages and disadvantages of various bathymetric analysis methods by i comparing the accuracy of the interpolation methods generally used in the bathymetric field idw lpi uk sk etc for river sectors ii determine the opportunity of developing cross section profiles combined with longitudinal cross section profiles on the surveyed sector iii determine which are the best results obtained and what method of interpolation was more effective the measurements made in this research may constitute a baseline reference for further measurements in this danube section which will allow the modeling of the dynamics of riverbed processes 2 material and methods 2 1 study area the research was conducted on the lower course of the danube at km 955 and 950 between serbia and romania water flow regime is fluvial watery and is dependent on the tributaries flows and the manner of transiting the iron gates reservoir fig 1 construction of the iron gates i hydro energy and navigation system started in november 1963 and was finalized in may 1972 construction wise it is a weight dam with a retention front 1278 m long formed by a central flow dam on both sides there are symmetric hydroelectric power plants flood gates and non flow dams in terms of energy it is defined by an installed total power of 2100 mw and an installed flow capacity of 4350 m3 s the retention level is at 69 5 m with a median fall of 27 17 m the reservoir created by the construction of the dam has a volume of 2400 mil m3 which led to the flooding of a surface of 10 131 ha including the towns of orsova ada kaleh island small villages as well as communication lines transportation networks etc due to the dam built near the village of gura văii the water level rose upstream along the danube river course flooding the major riverbed and the mouths of its tributaries fig 2 the danube valley between km 955 950 is a river sector with a particular feature the island of ada kaleh formed by alluviums transported by the cerna river the constructions which existed on ada kaleh island were partially transferred to simian island downstream from drobeta turnu severin the new location is not present in the section of the current study the hydrobiological characteristics of iron gates reservoir have suffered substantial changes after the flooding of an important land area the new ecosystems that have developed here combining lotic and lentic conditions brezeanu and cioboiu 2006 if in the first years of the lake s existence the planktonic communities were modified in terms of both quantity and quality systematically this process it was stabilized explosions of algae being registered only in the warm season or because of the eutrophic processes brezeanu and cioboiu 2006 still for example the chlorophyll concentration values registered in these sections in the past few years are lower than upstream and in some years even than downstream baranyi et al 2002 dokulil and donabaum 2014 the investigated section has the following characteristics a iron gates reservoir it is a section of the danube valley flooded by the water which amounts to 2400 million cubic meters formed by obstructing the course of the river and flooding over 10131 ha of land in the period 1971 2005 a quantity of about 393 14 million tons of alluviums entered into iron gates reservoir through the baziaş hydrometric section depositing downstream to the dam a volume of 133 15 million tons respectively a 33 9 rate between 1971 and 1985 the alluvial deposits in iron gates reservoir had an increasing trend when a percentage of about 39 5 was reached these being deposited upstream to the dam bondar 2008 b the water flow rate decrease from speeds of about 1 m s at the entrance of the reservoir to 0 45 0 42 m s in the sector where the measurements were made downstream of orşova city c the water transparency is closely related to the alluvial regime and water temperature low transparency values being recorded near the shore due to the vegetation development because the vertical variation of zooplankton and phytoplankton organisms is not large they do not influence the bathymetric data obtained d the waves are not high 10 cm due to the meandering course with abrupt and tall slopes higher values being recorded in bays and inside large opening sections significant seasonal oscillations of the lake level are recorded during periods of drought or high leakage while normal oscillations are recorded as a result of the water processing for producing electric power the differences between the maximum and minimum water level can also reach to 7 m 2 2 bathymetric investigation methods the international hydrographic organization iho has published over the time a set of standards aimed to establish the minimum conditions for performing bathymetric measurements iho 2005 2008 the study wants to establish measurement conditions in order to obtain comparable and good quality results reduce errors avoid uncertainties and highlight the characteristics of the submersed environment for this study both depth independent errors and errors affecting the depth the uncertainty of depth are determined in 95 of cases with the total vertical uncertainty tvu calculated with the formula eq 1 1 tvu a 2 b d 2 where a is the portion of the uncertainty that does not vary with depth b is a coefficient which represents the portion of the uncertainty that varies with depth d depth expressed in meters and b d the portion of the uncertainty that varies with depth iho 2008 starting with these considerations and possible limits imposed by climate hydrologic and navigation conditions particular to the analyzed area measurements were carried out between december 15 17 2017 during conditions of atmospheric calm air and water temperatures of 4 6 c 86 8 air humidity water transparency of about 1 30 m the water having a light green brown color and small waves 10 cm except the situation when the shipping traffic created waves of 30 40 cm the danube flow ranged between 5550 m3 s 15 december 2017 5930 m3 s 16 december 2017 and 6100 m3 s 17 december 2017 the water level recording oscillations from one day to the next but these have been measured and taken into account during the measurements the level changes were not significant therfore hourly corrections were not necessary due to the fact that the duration of the measurements did not exceed more than 6 7 h day and the change in level of that time was within the accuracy range of the system the development of a new survey plan should consider both the density of points needed for correct data processing as well as improved cost efficiency our workflow to achieve the objectives of this paper is show in fig 3 and we used the following software arcgis 10 2 surfer global mapper 13 0 and hypack the survey bathymetric studies started by consulting the technical and constructive features of the dam and of the reservoir checking previous bathymetric elevations checking the designs settings and results of the previous studies in digital format as well as assessing natural conditions and their possible changes geo morphological changes of banks hydrological regime or vegetation cover that might impact the aquatic unit the next step consists of identification of the triangulation points to be used as the basis for the topo geodesic measurements and acquiring the coordinates for these points field verification of the existence of the contour milestones and topo geodesic landmarks necessary for the measurements and creation of the project for emerged measurements classic topo geodesic or gps in the present study the measurements were made using the single beam type echo sounder simrad type cx 33 44 200 khz and 50 khz with a measurement error rate in ideal conditions that varies between 0 01 m on the 210 khz frequency to 0 04 m on the 33 khz frequency the position of the water surface and the levels of the immerse land was measured with 2 cm precision by using a trimble r8 rtk gps and correlated with direct reading of the water level from the hydrometric station as well as with satellite imagery checking the satellite positioning and scheduling the work days and hours to ensure optimal quality of the gps measurement session and equipment preparation the levels of water are registered at the beginning and at the end of the working session or more often where required subsequently there are performed the on site identification of the transverse profile measuring sections development of the geodesic support network and performed surveys measurements of the cross sections on the shores and in the low depth water areas where the measurements with the echosounder are not possible measurements with the total station gps etc and navigation by boat on the designed routes using gps guidance and profile heads and performed the bathymetric measurements the field stage is followed by an office stage which consists of determining the xyz coordinates in a measuring system stereo 1970 black sea 1975 and making corrections for the acquired immersed survey data elimination of erroneous points and processing of the raw data obtained with the echosounder development of the digital terrain model dtm and of the bathymetric map using arcgis 2 3 interpolation methods using arc gis 10 2 geostatistical analyst extension 9 interpolation methods out of which 6 deterministic interpolation methods were used inverse distance weighting idw criteria automatically determined cad and manually determined md local polynomial interpolation lpi criteria automatically determined cad and manually determined md radial basis function rbf completely regularized spline crs radial basis function rbf spline with tension swt and 3 geo statistics methods were used ordinary kriging ok simple kriging sk universal kriging uk interpolation resulted in bathymetric dem s with grid cell size 9 83 9 83 m the idw represents a deterministic method of interpolation whereby the estimation of values is made based on nearby known locations closer points have a greater impact in estimating the values while the more distant points have a lower impact johnston et al 2001 werner 2001 calculated following eq 2 2 z x o i 1 n x i h ij β i 1 n 1 h ij β where for this study z x0 represents the interpolated value n is the number of points xi is the ith data value hij is the separation distance between interpolated value and the sample data value and ß denotes the weighting power lpi methods are useful because they are capable of producing surfaces that capture the short range variation lpi fits the local polynomial using points only within the specified neighborhood instead of all the data then the neighborhoods can overlap and the surface value at the centre of the neighborhood is estimated as the predicted value wang et al 2014 rbf methods fit dem through the measured sample values while minimizing the total curvature of the surface and may predict values under the minimum of measured value and over the maximum of the measured values which is an advantage as compared to idw but the method is inefficient if sudden changes of the measured values take place johnston et al 2001 unlike the deterministic methods the geo statistic interpolation techniques chen et al 2011 are able to provide better predictions considering the spatial relationships between the measurement points and spatial correlations sanders and chrysikopoulos 2004 legleiter and kyriakidis 2008 merwade 2009 tan and xu 2014 amante and eakins 2016 ordinary kriging uk uses only the points measured in the vicinity to estimate the predicted value of depth and assumes that the mean is constant but unknown focuses on spatial components using the equation eq 3 3 z s μ ε s where for this study s x y is a location z s is the bathymetric depth value µ a constant mean for the data no trend and random errors ε s with spatial dependence johnston et al 2001 the prediction is formed as a weighted sum of the data calculated following eq 4 4 z s 0 i 1 n λ i z s i where for this study z si is the measured value at the ith location λ i is a unknow weight for the measured value s0 is the predicted location and n is the number of points universal kriging uk is useful when the values of the depth record an obvious trend the trend or drift is a continuous spatial variation which is too irregular to be modeled by a simple mathematical function johnston et al 2001 wang et al 2014 3 results and discussions creation of the project regarding submerse measurements was done by using the hypack software environment a process which includes the following steps setting of the geodetic parameters importing the files on the reservoir contours and possible obstacles route planning and drawing of the route lines eventually importing the route from the previous survey study and changing it where necessary setting the parameters for the data transfer from the echosounder to the laptop the results obtained using the hypack software are presented in fig 4 this study compares accuracy and efficiency of obtaining underwater dem s from the danube river resulting from measurements with a single beam equipment on perpendicular and or longitudinal paths and different interpolation methods three sets of data were used a 1943 measured on 4 perpendicular routes b 4328 points measured on 10 perpendicular routes and c 17 139 points measured on 25 perpendicular routes and 5 longitudinal routes fig 5 covering an area of approximately 5 6 km2 because many studies use only profiles perpendicular on the riverbed zhang et al 2016 šiljeg et al 2015 takekawa et al 2010 we tried to analyze the importance of the number of routes and their distribution perpendicular longitudinal in order to determine which is the best solution to get more detailed maps of the aquatic unit increasing the number of points leads to smaller standard errors and standard deviation which results in a lower variance coefficient in order to assess and compare the accuracy of the estimated measurements using different interpolation methods guarneri and weih 2012 errors were measured using eqs 5 9 5 m e a n e r r o r 1 n i 1 n e i 6 r o o t m e a n s q u a r e e r r o r 1 n i 1 n e i 2 7 a v e r a g e s t a n d a r d e r r o r 1 n i 1 n s i 2 8 m e a n s t a n d a r d i z e d e r r o r 1 n i 1 n e i s i 9 r o o t m e a n s q u a r e s t a n d a r d i z e d e r r o r 1 n i 1 n e i s i where for this study ei and si 2 represent the estimated error and variance for xi for xi the estimated error was calculated using the cross validation procedure barton et al 1999 respectively the measured values xi were removed from the data set and in the next stage were estimated using the remaining measurements table 1 the cross validation allows the assessment and comparison of the performances of the interpolation methods by dividing the data set into 2 one set is used for building the model and the other for validating the model castellarin et al 2009 erdogan 2010 bailly et al 2010 scatter plots of the water level depth in danube river section estimated by deterministic method idw cad and md and geo statistical method sk x and y axis units m are presented in fig 6 near the banks due to the smaller number of points obtained through measurements the low water depth and the high slopes of the river bed cause rapid changes in the measured values which generates large errors of the estimated values by running the 9 interpolation methods in the 3 analyzed situations a 1943 points obtained by 4 routes perpendicular to the riverbed with a distance of 1 5 km between them and respectively 4 6 m between the points resulting in a point density of 345 points km2 b 4328 points obtained by 10 perpendicular routes with a maximum distance of 0 842 km between them and minimum distance of 0 158 km between them and 4 6 m between points resulting in a point density of 768 points km2 c 17 139 points obtained by 25 perpendicular routes and 5 longitudinal routes and 4 6 m between points resulting in a point density of 3041 points km2 it is noticed that selecting the manual criteria was based on the obtaining lower values of the standard deviation and of the map improvements obtained using automated criteria even in the situation of use a small number of points for all 3 situations analysed the distance between 2 consecutive measurements was between 4 and 6 m because the speed craft was constant small speed variations generated the variation in the distance between the consecutive points 4 6 m were due to the moments when the craft approached the shores and we changed movement direction or when because of intense shipping traffic we were required to accelerate or decrease speed in order to avoid a collision fig 7 highlights the differences between the interpolations methods used while in the case of using 17 139 points for interpolation the differences are not very obvious but reducing the number of point to 1943 excepting idw md and sk interpolation methods visibly reduced the accuracy of the maps in the case when the number of points increases to 4328 the variants obtained using idw md interpolation methods lpi md ok sk uk are most likely to be used in data processing table 2 showed the statistical results of the analysis of the interpolation both deterministic and geo statistical and in case of the deterministic methods both automatic determination criteria cad and manual determination criteria md were selected the quality of the resulting maps is influenced by the distance between the points both vertically and horizontally but also by the number of neighbors and number of sectors for two of the deterministic interpolation methods idw lpi we used both the automatic option as well as the manual one because the results of idw interpolation depend on power value and the search neighborhood strategy we decided that in the case of the manual method we will use when interpolating a lower number of neighbors and more sectors repeated simulations showed that in case the number of measured points is low and the distance between sections is large for n 1943 points reducing the number of neighbors to those around the predicted value at 4 and using 4 sectors can produce bathymetric maps which are acceptable for analyses while estimated values have higher errors than the case of the automatic method using the interpolation methods which led to the best results idw md and sk longitudinal profiles were drawn in the east west direction for idw md using the simulated results in the three situations and for sk only for n 17 139 points fig 8 with the largest differences being recorded for the situations where the number of points was lower while when idw md and sk are compared for n 17 139 points the differences are low in this study area where the riverbed shows obvious irregularities the results of the two interpolation methods also used previously for the longitudinal profiles idw and respectively sk are also confirmed by the representation of the aquatic field slopes fig 9 the differences in max slope are caused by the use of bathymetric dem s obtained by different interpolation methods idw and sk actually these differences can also be noticed in fig 8 when the profile lines are similar but not identical which generates slope differences on small areas the slope is of major importance in the deviation of echosounder waves generating erroneous values as well as in the sedimentation erosion process that provides different textures to the riverbed by using perpendicular routes valuable information may be obtained regarding the transverse section profile of the riverbed but the addition of the longitudinal profiles allows the streamlining of the interpolation methods and improvement of the final dem s in the case of riverbeds by developing the longitudinal profiles that join the biggest depths obtained based on the perpendicular profiles the bathymetric maps are improved and the errors are reduced and the creation of a tracking grid is an optimal solution particularly for complex sections 4 conclusions the depth of the water in rivers lakes and reservoirs is an important morphometric indicator which controls the physical chemical and biological processes in the case of reservoirs periodic monitoring of the water depth and creation of bathymetric maps allows for estimation of morphometric parameters and the evolution of hydrodynamic processes the usage of single beam eco sounders in bathymetric measurements has both advantages and disadvantages which we need to take into consideration when deciding which equipment to use the main disadvantage of single beam equipment is the fact that we obtain a smaller point number through a single pass compared with multi beam equipment however this situation can be compensated by doing a larger number of passes on several profiles and with a longer duration for the same surface also single beam equipment compensate for these disadvantages with their acquisition price operating costs and staff training costs which are much lower there is also the option to operate them even at low depths the obtained results show that the selected interpolation methods influence the accuracy of the final cartographic products but the most important role is that of choosing the number of sections on which measurements are to be made and their position which ultimately determines the point density both horizontally and vertically the exclusive usage of profiles perpendicular to the riverbed is not efficient in the case of long river sections because it requires a large amount of time for data acquisition increases operating costs and exposes operators to extra risks intense shipping traffic severe meteorological or hydrological conditions development of a grid consisting of perpendicular and longitudinal routes allows a better assessment of the riverbed morphology highlighting the positive and negative forms of the riverbed improves the accuracy of interpolation methods and reduces errors and uncertainties especially in the sections where past turbulence caused complex morphology if the number of points obtained in the measurement campaign is high all the interpolation methods used have proved effective in creating of bathymetric maps including idw md lpi md ok sk or uk the selection of transverse and or longitudinal routes for boat movements during the echo sounder measurements and the displacement speed may lead to erroneous dem in case of an insufficient number of measurements and complex morphology of the river bed even if the statistical errors obtained by the selected interpolation methods are not very large the development of a survey plan should consider both the density of points needed for correct data processing as well as improved cost efficiency this is why if preliminary preexisting information about the morphology of the riverbed about to be analysed are not enough we don t have the time required for making detailed measurements or if there are limitations due to climate hydrological or shipping traffic conditions we may use perpendicular profiles positioned at distances larger than 200 m but which should be complemented by longitudinal profiles parallel to the shores with at least one uniting the points with greatest depth in this situation in which the number of obtained points is small the use of manually adjusted idw may lead to cartographic products that provide preliminary information but they need to be further improved because the results of interpolation using idw depend on the power value and the search neighborhood strategy the reduction of the number of neighbors to those around the predicted value and finding possible directional influences in order to establish the optimum number of sectors can produce acceptable bathymetric maps even if the estimated values will have larger errors than in the case of the automatic method author contributions all authors have equal contribution to the preparation of this scientific paper acknowledgments this research is supported by the project analysis of the submerged evolution of the danube valley between gura văii and dubova no ub 14912 2017 the authors thanks for advice and suggestions offered by dr johan schutten from scottish environment protection agency and for technical advice provided by mr vasile bagrinovschi from centre for environmental research and impact studies university of bucharest conflicts of interest the authors declare that they have no conflict of interest 
6739,understanding co2 migration and distribution in fault systems is essential to evaluate long term secure co2 storage and prevent hazardous effects caused by co2 leakage to elucidate the role of the fault system on subsurface co2 migration and leakage processes a two dimensional multi phase transport model was constructed to represent little grand wash lgw and salt wash sw faults where naturally originating co2 is being leaked to the surface according to simulation results buoyant co2 leaked through various pathways including the faults themselves fault offsets and damaged caprock because of both fault systems and caprocks serving as barriers multiple trapped co2 plumes were developed in this region presence of trapped co2 plumes in the subsurface is supported by multiple field observations e g elevated soil co2 fluxes travertines and co2 driven cold water geysers co2 springs adjacent to both lgw and sw faults sensitivity studies were conducted with different permeabilities for faults and caprock various co2 source locations and differing fault parameters e g fault throw and cutoff angle which affected subsurface co2 distribution including size shape and location of trapped co2 plumes finally such trapped co2 plumes have played a key role in the development of co2 driven cold water geysers in these regions keywords fault co2 migration trapped co2 plume co2 driven cold water geyser 1 introduction carbon dioxide co2 emissions from anthropogenic and natural sources to the atmosphere will need to be reduced to varying degrees worldwide for mitigating climate change ipcc 2014 efforts to mitigate environmental impacts from increased atmospheric co2 concentrations over the last several decades have suggested that geologic carbon sequestration gcs can possibly be used to reduce the amount of co2 emitted to the atmosphere ampomah et al 2017 dai et al 2018 li et al 2016 reichle et al 1999 schrag 2009 soltanian et al 2017 to guarantee safe and long term gcs it is essential to find good porosity storage formations capped by low permeability formations kampman et al 2014 pruess et al 2001 because geologically sequestered co2 could potentially encounter unidentified or unwanted pathways e g boreholes fractures within caprocks and fault zones which could serve as co2 leakage pathways directly connecting deep storage formations to shallow potable aquifers or to the atmosphere kirk 2011 pruess 2008 stevens et al 2001 occurrence of such co2 leakage from the storage formation could result in the failure of gcs and also has a detrimental effect on public and environmental health metz et al 2005 price et al 2007 for example as a result of co2 leakage from a gcs reservoir a bank of highly concentrated methane could migrate to upper shallow aquifers where unexpected contamination of potable groundwater occurred hosseini et al 2013 soltanian et al 2018 furthermore previous studies assessed that co2 leakage into shallow aquifers could contaminate potable groundwater resources by decreasing the ph and consequently enhancing the mobility of toxic metals preserved in the aquifer media keating et al 2013 kim et al 2018 zheng et al 2015 it is thus essential to gain an understanding of subsurface co2 migration or leakage through unidentified pathways when evaluating long term secure co2 storage to prevent potential disasters relating to co2 leakage baxter et al 1989 burnside et al 2013 with respect to unidentified pathways fault zones within the upper crustal system have an important role in fluid flow bense et al 2013 faulkner et al 2010 according to caine et al 1996 fault zones comprise distinct structural and hydrogeologic features that include a fault core and damage zone the fault core consisting of gouge cataclasite and mylonite is characterized as being a low permeability zone the damage zone surrounding the fault core is composed of various geologic features e g fractures veins and folds and is typically highlighted to be an enhanced permeability zone from a hydrogeological perspective these two units can thus be a low permeability fault core and high permeability fractured damage zone respectively bense et al 2013 these structural and hydrogeologic features within a fault zone characterize an along fault or vertical conduit and an across fault or horizontal barrier due to such an opposite role of the fault zone to fluid flow many previous hydrogeologic studies investigated the role of fault zones as a conduit barrier on fluid flow for example the role of fault zones as conduits has been investigated in relation to observing the cementation mineralization processes in faults boles et al 2004 garven et al 1999 treiman 2008 and studying geothermal anomalies fernàndez and banda 1990 mamadou et al 2016 mckenna and blackwell 2004 and co2 leakage along the fault zones jung et al 2014 lee et al 2016 sciarra et al 2018 in contrast studies focusing on fault zones as barriers have focused on the development of subsurface regions characterized as either abnormal hydraulic gradient or overpressures bense et al 2013 or the development of natural co2 reservoirs jung et al 2015 kampman et al 2014 shipton et al 2004 as complex fault zones can be essential pathways for co2 leakage previous studies have aimed to understand natural co2 reservoirs where co2 is released naturally via regional faults bickle et al 2013 lewicki et al 2007 one of these natural analogue sites is located within the paradox basin in eastern utah jung et al 2014 where naturally originating co2 is being leaked through both little grand wash lgw and salt wash sw faults that are located near the city of green river at the surface of fault traces allis et al 2005 conducted diffusive soil co2 flux surveys and observed a high co2 fluxes 100 g d a y m 2 later jung et al 2014 conducted more extensive co2 flux surveys in this region and observed co2 flux anomalies along fault traces and also at the northern footwall of both faults in addition to field oriented studies jung et al 2015 used numerical simulations to establish regional scale numerical models to elucidate the co2 distribution within the lgw fault system advancing the study by jung et al 2015 we extended previous understandings of subsurface co2 migration and distribution by developing both regional scale lgw and sw fault models and evaluated how the fault structures affected subsurface co2 distribution and the characteristics of trapped co2 plumes specifically the effect of the lgw fault zone serving as either a barrier or a conduit was assessed and the role of caprock integrity on trapped co2 plumes was evaluated then for the first time subsurface co2 migration within the sw fault system was predicted as the geologic features of the sw fault have not yet been characterized in detail sensitivity studies on trapped co2 plumes were conducted by varying the magnitude of fault throw and the cutoff angle between the sw fault and regional formations in addition the locations for co2 sources were evaluated by assuming that co2 originated from either recharge of dissolved co2 brine in jurassic aquifers or separate phase co2 leaking through the sw fault from deep subsurface mississippian carbonate rock finally the eruption mechanisms for co2 driven cold water geysers such as crystal and tenmile geysers located in these regions were numerically evaluated 2 site description 2 1 little grand wash lgw and salt wash sw faults the colorado plateau extending in parts of the utah colorado arizona and new mexico is an elevated tectonic platform caused by cenozoic tectonic events parsons and mccarthy 1995 fig 1 a in the colorado plateau multiple sequences of sedimentary formations horizontally extend with a gentle dip angle table 1 nevertheless some strata are folded or cross cut by monoclines and faults with north or northwest strikes stewart et al 1972 three basins including uinta piceance and paradox basins are formed in the upper and central parts of the colorado plateau among these three basins the study area is located within paradox basin fig 1a the paradox basin is primarily composed of paleozoic and early mesozoic strata especially the shallow strata system is hydrostratigraphically classified into two categories 1 permian jurassic aquifers permian white rim sandstone lower jurassic wingate navajo sandstones and middle jurassic entrada curtis sandstones and 2 interbedded confining layers triassic moenkopi chinle formations jurassic kayenta carmel formations the shale rich lower part of entrada sandstone and middle jurassic summerville table 1 kampman et al 2014 shipton et al 2004 in the paradox basin structural isotopic and noble gas studies suggested that meteoric groundwater recharging at san rafael swell migrates to the southeast via jurassic sandstone aquifers navajo and entrada sandstones and discharges into the green river fig 1b baer and rigby 1978 hood and patterson 1984 kampman et al 2014 wilkinson et al 2009 additionally within and at the margin of the paradox basin there exist co2 reservoirs where numerous amounts of co2 are stored naturally the estimated amount was 2 8 1010 2 8 1013 m3 allis et al 2001 most of these co2 natural reservoirs including gordon creek farnham dome woodside escalante lisbon and mcelmo dome are currently developed with the aim of using them commercially in the process of co2 enhanced oil recovery and dry ice production fig 1a allis et al 2001 cappa and rice 1995 morgan and chidsey 1991 pearce et al 1996 little grand wash lgw and salt wash sw faults are located to the south of the city of green river fig 1c the lgw fault intersecting the north to northwest plunging green river anticline extends 30 km with a west east strike the lgw fault having a dip of 70 80 to the south is a normal fault with the maximum throw of 260 290 m dockrill and shipton 2010 mcknight 1940 shipton et al 2005 to 6 km further south from the lgw fault the sw fault characterizing two sub parallel normal faults extends approximately 23 km west east with the strike of 290 the northern and southern sw faults have dips of 78 and 87 to the south and north respectively which form the salt wash graben between the two faults doelling 2002 the maximum offsets of the northern and southern faults are 366 m and 210 m respectively evans et al 2004 williams 2004 2 2 evidences of co2 and brine leakage geysers springs travertines and diffusive co2 flux both co2 and brine have been leaked in the form of co2 driven cold water geysers and springs along the traces of both lgw and sw faults and adjacent areas han et al 2013 shipton et al 2005 for example the largest co2 driven cold water geyser crystal geyser is located 45 m north of the lgw fault fig 2 a and a relatively small geyser tenmile geyser is located 100 m south of the northern trace of the sw fault fig 2b the drilling history penetration depth and lithologic information of crystal geyser has been characterized well for example han et al 2013 shipton et al 2005 and watson et al 2014 revealed that eruption intervals of crystal geyser was extended while its intensity was decreased in contrast to crystal geyser the characteristics for tenmile geyser were not identified well but a recent study by watson et al 2014 indicated that the eruption pattern was regular with the intervals of 8 5 2 6 h in addition to these geysers co2 driven cold water springs such as small bubbling big bubbling pseudo tenmile and torrey s springs are located in this region interestingly all these springs are densely distributed on the northern footwall of the sw faults fig 2b adjacent to these geysers and springs active and inactive or ancient travertine deposits are developed burnside et al 2013 han et al 2013 shipton et al 2004 the presence of both active and inactive travertine deposits supports the occurrence of long term co2 and brine leakages in this region over the geologic time period and also confirms that both lgw and sw faults act as active pathways for subsurface fluids baer and rigby 1978 burnside 2010 burnside et al 2013 recently the spatial patterns of diffusive co2 fluxes were measured along both lgw and sw fault traces allis et al 2001 jung et al 2014 measured co2 flux anomalies were found to be concentrated at the northern footwalls of both the lgw and sw faults and intersected fault traces fig 2a and b in addition followed by jung et al 2014 the magnitude of the co2 flux was decreased from the lgw north to sw south faults maximum co2 flux anomalies were 36 259 g m 2 d 1 and 1428 g m 2 d 1 in the lgw and sw fault zones respectively 2 3 origins of leaking co2 assuming that the value of δ 13 c originated from marine carbonate is 0 and dissolved carbon in groundwater primarily originated from soil and carbonate minerals the range of δ 13 c at crystal geyser effluent expected to be 13 0 to 7 5 mayo et al 1991 however measured δ 13 c in geyser effluents water 1 2 and gas 1 9 were found to be positively skewed relative to the expected values implying that additional co2 sources such as thermal decomposition of carbonate rocks could contribute the enrichment of δ 13 c in the crystal geyser effluent mayo et al 1991 the co2 originated from thermal decomposition was supported by shipton et al 2004 who suggested that the high temperature thermal decomposition of carbonate was caused by the adjacent contact aureoles of tertiary intrusions e g the la sal and henry mountains recently heath et al 2009 reported that helium isotopic ratios r ra are 0 302 crystal geyser and 0 310 big bubbling spring respectively here r and ra represent 3he 4he of a sample and atmospheric air respectively these r ra ratios measured from crystal geyser and big bubbling spring were closer to the values of crust originated sources typically 0 02 than mantle derived ones 7 to 21 clark and fritz 1997 which suggested that the co2 from geysers and springs was presumably originated from crustal sources such as clay carbonate reactions and the thermal degradation of carbonates heath et al 2009 furthermore wilkinson et al 2009 analyzed co2 3he from these geysers and springs tumbleweed geyser torrey s spring crystal geyser chaffin ranch geyser small bubbling big bubbling pseudo tenmile geyser and tenmile geyser as shown fig 1b and also supported that co2 primarily originated from crustal sources with the rest of co2 1 20 from a mantle driven source 2 4 regional water chemistry a total of 97 water chemistry data were obtained from various sources han et al 2017 kampman et al 2014 kharaka et al 1997 spangler 1992 and the chemical characteristics and origins of fluids in this region were investigated fig 3 these compiled water chemistry data were categorized into four groups where group i represents fluid samples collected from shallow jurassic aquifers during a scientific drilling hole project kampman et al 2014 co2w55 well was drilled approximately 285 m to the west of crystal geyser and here a total of 6 fluid samples were collected from entrada sandstone 98 m carmel formation 188 m and navajo sandstone 206 224 276 and 322 m group ii included a total of 5 fluid samples originating from deep paleozoic aquifers such as paradox brine which were gathered in adjacent hydrocarbon fields kharaka et al 1997 spangler 1992 and group iii included 71 effluent samples that were collected during the eruption of crystal geyser han et al 2017 kampman et al 2014 finally a total of 15 samples group iv were collected at salt wash springs and tenmile geyser which are located adjacent to the northern footwall of the sw faults han et al 2017 kampman et al 2014 group i representing fluid chemistry in the shallow jurassic aquifers such as entrada carmel and navajo sandstone evolved from na hco3 to na cl typed groundwater as the formation depth increased fig 3a for example the fluid chemistry at shallow entrada sandstone 98 mbs na k 39 9 and cl 24 9 transited to be saline at navajo sandstone 322 mbs na k 63 6 and cl 44 7 additionally ph and tds of group i was low 5 13 to 6 3 and diluted 7677 11 980 mg l relative to other samples groups ii iii and iv in this region which implies that formation fluids in the shallow jurassic aquifers were mixed with meteorically originated shallow groundwater group ii representing paradox brine was characterized to be high tds from 158 721 to 255 030 mg l which was strongly enriched with na k cl average na k of 93 4 and cl of 97 4 group iii and iv represented the fluid chemistry of crystal geyser and salt wash springs respectively the chemistry of these groups were plotted between groups i and ii which implies that groups iii and iv are a mixture of both groups i and ii in detail the salinity of group iii crystal geyser revealed average and standard deviation tds of 15 203 mg l average na k 70 57 and cl 47 98 and 1241 mg l respectively while group iv salt wash springs showed average and standard deviation tds of 19 154 mg l average of na k 77 6 and cl 58 5 and 2004 mg l here p value between group iii and iv was 1 66 10 6 assuming that groups i and ii represent end members of the mixture groups iii and iv the mixing ratio of paradox brine group ii in groups iii and iv are calculated to be 2 3 and 4 1 respectively this observation supported the fact that effluents from both crystal geyser and salt wash springs having a tds of 11 000 to 14 000 mg l characterized to be a mixture of both meteoric groundwater and brine baer and rigby 1978 rush et al 1984 waltham 2001 wilkinson et al 2009 recent studies revealed that the geochemistry of crystal geyser effluent dynamically evolved during its eruption the eruption of crystal geyser was classified into four stages a minor eruption period major eruption period aftershock eruption and recharge during the transitions between dynamic geyser eruptions effluent chemistry was also changed han et al 2017 according to han et al 2017 the recharge period was characterized by a gradual increase in electrical conductivity from 18 to 19 ms cm after transiting to the minor eruption period the electrical conductivity of the effluents increased to 21 3 ms cm and then maintained flat until the initiation of the major eruption period which was characterized to be an instantaneous drop in electrical conductivity from 21 3 to 19 3 ms cm similarly probst et al 2018 observed the evolution of effluent chemistry during different eruption periods 3 model description lgw and sw faults and geysers to simulate the distribution and migration of co2 in shallow jurassic aquifers at lgw and sw faults a numerical simulator tough2 mp eco2n was utilized the tough2 mp is a massive parallel version of tough2 which is capable of simulating non isothermal multiphase and multicomponent flow processes in porous fractured media pruess et al 1999 zhang et al 2008 the eco2n is the equation of state module that can predict thermodynamic properties for co2 h2o and nacl within a range of 10 c t 110 c and p 47 6 mpa pruess 2005 the lgw fault model is a 2 d model that cross cuts both lgw fault and crystal geyser from north to south fig 4 a this model was horizontally extended by 700 m from a a figs 1c and 2a and vertically penetrated 600 m from cretaceous and jurassic formations table 1 to simulate co2 migration accurately in the region of crystal geyser and lgw fault the sizes of grid blocks were varied in the x direction e g δ x 0 25 1 5 and 10 m dependent on the distance from crystal geyser and lgw fault however the size of the grid blocks in the z direction δ z 10 m were uniformly assigned therefore the number of grid blocks was 329 and 60 to the x and z direction respectively the sw fault model consisting of three fault lines as well as tenmile geyser is a 2 d model that cuts perpendicular to sw fault b b in figs 1c 2b and 4b the size of model was 2 130 m width and 600 m height similar to the lgw fault model the sizes of the grid blocks in the x direction were varied depending on the location of fault lines and the geyser but the grid block size in the z direction was uniform δ z 10 m as a result the number of grid blocks were 9 840 x direction 164 and z direction 60 finally the thickness of fault lines for both lgw and sw faults were assigned to be 5 m followed by dockrill and shipton 2010 for both lgw and sw fault models the hydrostatic pressure gradient of 0 01 mpa m was assigned similar to that of jung et al 2015 while the top and bottom boundaries were fixed at 0 1 mpa surface and 6 1 mpa 600 m depth respectively following the study of heath et al 2009 the geothermal gradient was assigned as 0 0212 c m with the surface temperature of 25 c in addition a 0 011 nacl mass fraction which was calculated from the chemistry of crystal geyser effluents kampman et al 2014 was uniformly assigned the top boundary was assigned as the fixed boundary condition to represent the atmospheric condition whereas the bottom boundary was set as a no flow boundary condition due to the presence of the low permeable formation such as chinle formation in addition the fixed boundary condition was assigned to lateral boundaries where both co2 and brine were allowed to flow in and out especially hood and patterson 1984 suggested that co2 dissolved brine in both navajo and entrada sandstones was fed from san rafael swell which is located on the left boundary of the model fig 1b to simulate recharge of co2 dissolved brine the pressure of navajo and entrada sandstones on the left boundary was set to be 0 025 mpa higher than those in adjacent grid blocks the lgw fault model consists of cretaceous and jurassic formations while the sw fault model includes cretaceous jurassic as well as triassic formations geologic formations of both lgw and sw fault models were assumed to be homogeneous and anisotropic kv kh 10 table 2 allis et al 2001 burnside 2010 hansley 1995 hood and patterson 1984 jung et al 2015 white et al 2005 the regional dip of the formations in the lgw and sw faults models was uniform at 4 and 6 11 to the north respectively dockrill and shipton 2010 frery et al 2015 williams 2004 after calibrating the numerical lgw fault model with field measured co2 flux jung et al 2015 suggested that the lgw fault acts vertically as a conduit 5 10 16 m2 kv 1 10 15 m2 and horizontally as a barrier 1 10 17 m2 kh 1 10 16 m2 therefore following the study of jung et al 2015 kv and kh of the lgw fault were assigned as 5 10 16 m2 and 10 17 m2 respectively in addition it was assumed that the sw fault acted in a similar way to the lgw fault and the following k kv kh 1 10 15 m2 5 10 16 m2 was assigned the buoyant migration of gaseous co2 through both lgw and sw faults was simulated by assigning 0 6 co2 saturation at the bottom most grid blocks of the faults red arrows in fig 4a and b in addition co2 dissolved brine fed from the left boundaries of the two models through both navajo and wingate sandstones was simulated by setting 0 05 mass fraction of co2 dissolved brine blue arrows in fig 4a and b finally for multiphase transports of brine and gaseous co2 the relative permeability and capillary pressure were modeled using corey s curves corey 1954 and van genuchten function van genuchten 1980 in both lgw and sw fault models the detailed mathematical expressions and input parameters are shown in table 3 one of localized characteristics in the lgw and sw faults is the presence of co2 driven cold water geysers such as crystal and tenmile geysers respectively glennon and pfaff 2004 kampman et al 2014 previously a few researchers such as han et al 2013 and watson et al 2014 collected in situ datasets of pressure temperature electrical conductivity and ph and conceptually identified the eruption mechanisms of these cold water geysers based on the conceptual framework characterized by previous studies the eruption mechanism was evaluated in this study by using regional scale numerical models fig 4a and b which included realistic sedimentary stratigraphy fault configuration and subsurface co2 distribution both crystal and tenmile geysers have diameters of 0 5 m surrounded by a less permeable matrix 0 25 m here the permeability of conduit and surrounding matrix was set as 10 11 m2 and 10 19 m2 respectively following the study of jung et al 2015 the matrix surrounding the geyser conduit constrains the influx of both co2 and brine from aquifers to the conduit while co2 and brine can flow quickly through the geyser conduit however due to limitations associated with the continuum or porous media approach applied in this study for example the velocity of fluids within geysers is too fast to simulate with darcy s law the geyser model cannot predict the periodic eruption patterns exactly as observed at these geysers in addition the continuum approach cannot simulate co2 bubble generation and coalescence within the wellbore as well as the exact thermal alterations caused by frictional loss the goal of the geyser model was therefore not to reproduce the exact periodic eruption pattern observed in the field rather we attempted to evaluate whether the co2 distribution or traps predicted from the regional scale model was capable of developing co2 driven cold water geysers in addition to identifying the role of subsurface co2 traps on geyser eruption 4 simulation results 4 1 lgw fault model 4 1 1 subsurface co2 migration and distribution in lgw fault case 1 fig 5 shows the evolution of gaseous co2 migration in the lgw fault system at 77 3 222 6 398 9 and 1 314 7 years after co2 is released subsurface co2 migration reached the steady state condition approximately at 1 314 7 years the normal lgw fault consists of two parallel fault lines which are approximately 50 m apart each other dockrill and shipton 2010 separated by the two fault lines the footwall and hanging wall are located to the north and south respectively and stacked regional formations subside toward the south for example compared to the entrada formation in the footwall the entrada formation within two faults lines subsided by 70 m and the fault throw at the hanging wall ranged between 70 m and 160 m as described the interbedded formations e g caprocks and aquifers and the cross cutting lgw faults have developed complex geologic configurations which potentially alter the buoyant movement of co2 plumes through offsets between the formations after co2 was released from the bottom most of the lgw fault lines the co2 was accumulated in the wingate sandstone wi which is positioned beneath the regional caprock of the kayenta formation ka fig 5a when accumulated co2 saturation within the wingate sandstone became large enough some co2 began to disperse directly to the upper low k kayenta formation i in fig 5a at pore scale this indicates that built up co2 pressure exceeded the capillary entry pressure of kayenta formation other co2 horizontally passed through the lgw fault which served as a horizontal barrier kh 1 10 17 m2 and migrated to the wingate sandstone in the footwall ii in fig 5a once co2 entered the wingate sandstone it migrated upward following the dip of the northern lgw fault until its movement was hampered by the kayenta formation the remaining co2 migrated south toward the navajo sandstone na in the hanging wall iii in fig 5a once the co2 entered the navajo sandstone in the hanging wall co2 migrated upward to the camel formation ca and moved further south following the regional dip to the right lateral boundary finally while co2 dissolved brine fed from the san rafael swell migrated through the dipping navajo sandstone in the footwall gaseous co2 was exsolved from co2 dissolved brine due to the pressure reduction caused by the regional dip of the navajo sandstone iv in fig 5a the exsolved gaseous co2 then migrated south toward the lgw fault until its movement was prevented by the lgw fault after 222 6 years a trapped co2 plume developed in the wingate sandstone capped by both kayanta formation and the lgw fault fig 5b even if some co2 escaped to the fault offset which was connected to the navajo sandstone located between two lgw fault lines the size of the trapped co2 plume continuously grew within the wingate sandstone this suggests that the role of the lgw fault serving as a horizontal barrier is important to the development of the trapped co2 plume in the footwall after co2 passed horizontally through the northern lgw fault and entered the navajo sandstone which was located between two lgw fault lines co2 migrated upward and accumulated beneath the camel formation then through the fault offset in the southern lgw fault line co2 escaped to the entrada formation en in the hanging wall finally an additional trapped co2 plume which was fed from the san rafael swell gradually developed in the navajo sandstone at the footwall where the co2 plume was capped by both the carmel formation and the northern lgw fault in 398 9 years and 1 314 7 years the role of the lgw fault on co2 migration becomes distinct fig 5c and d in the end multiple trapped co2 plumes were developed in the jurassic wingate navajo and entrada sandstones trapped co2 plumes were particularly concentrated in the footwall and between the two lgw fault lines however co2 that migrated to the hanging wall was not able to accumulate due to the absence of a horizontal barrier the development of trapped co2 plumes only in the footwall was also supported by field observed co2 fluxes jung et al 2014 where high co2 fluxes were dominantly measured on the footwall of the lgw fault fig 2a in summary the lgw fault model revealed that co2 migrated buoyantly through various pathways the offsets developed by fault displacement were the primary pathway for buoyant co2 these offsets served as connected pathways to other regional aquifers where co2 migrated vertically to regional caprocks some of the co2 was able to escape directly following through the dip of the lgw fault kv 5 10 16 m2 but this amount was relatively small finally the kayenta formation which has relatively high permeability compared to other confining layers also served as leakage pathways where co2 migrated dispersively fig 5d and table 2 4 1 2 sensitivity study for kh in lgw fault case 1 2 1 and 2 2 from the previous study by jung et al 2015 the permeability range of the lgw fault was characterized to be 1 10 17 m2 kh 1 10 16 m2 and 5 10 16 m2 kv 1 10 15 m2 after calibrating numerical prediction to field measured co2 flux in case 1 the selected permeabilities of the lgw fault was kh 10 17 m2 and kv 5 10 16 m2 assuming that the lgw fault served as a horizontal barrier one of the objectives in this study was to evaluate the role of the lgw fault on subsurface co2 migration and distribution therefore additional sensitivity studies were conducted using an increase in kh of the lgw fault table 4 simulated co2 distribution in each case is shown in fig 6 a 6b and 6c the vertical profile green dotted line was selected where the crystal geyser was currently located here co2 saturation temperature and solubility were predicted fig 6d co2 solubility was calculated using the equation of state developed by duan and sun 2003 relative to the co2 distribution in case 1 a one order increase in kh case 2 1 accelerated co2 leakage through multiple fault offsets fig 6a and b consequently the size or thickness of the trapped co2 plume located in the entrada sandstone of the footwall grew for example the thickness of the trapped co2 plume in the entrada sandstone increased from 67 m case 1 to 85 m case 2 1 fig 6d additionally in case 1 the trapped co2 plume was not developed in the hanging wall but after increasing kh the small size of the trapped co2 plume began to develop in the entrada sandstone of the hanging wall when kh of the lgw fault was further increased case 2 2 co2 trapped in both the wingate and navajo sandstones at the footwall leaked more to the shallow entrada sandstone fig 6c therefore the size or thickness of the trapped co2 plume in the entrada sandstone became even larger 115 m in case 2 2 due to the co2 accumulation in the entrada sandstone formation pressure was elevated and consequently the calculated solubility was also enhanced fig 6d in addition more co2 migrated to the hanging wall via fault offsets and thus the size of the trapped co2 plume in the hanging wall was also increased however despite the development of trapped co2 plumes in the hanging wall field observations did not support the presence of subsurface co2 reservoirs in the hanging wall for example in the field active co2 geysers such as crystal geyser and active inactive travertines were located at the footwall and even anomalous co2 flux measurements were mostly detected at the footwall fig 2a burnside 2010 jung et al 2014 the presence of local geologic signatures on the footwall implies that accumulated co2 plumes only exist in the footwall therefore based on field and simulated observations it is concluded that the regional permeability of the lgw fault is presumably low less than 10 16 m2 and thus the lgw fault currently serves as a barrier for subsurface fluid flow 4 1 3 regional caprock kayenta formation case 1 3 1 and 3 2 less information is available for the characteristics of regional caprocks in this region for example the permeabilities kh 10 15 m2 and kv 10 16 m2 of the kayenta formation were assigned based on the previous study by white et al 2005 however the simulation results shown in fig 5d suggest that the presence of highly permeable pathways within caprocks could be important to the development of trapped co2 plumes likewise through an investigation of the lithologic cores acquired from the drill hole co2w55 kampman et al 2014 suggested that preferential pathways may exist in these regional caprocks therefore additional sensitivity studies were conducted by varying the permeability of the kayenta formation cases 1 3 1 and 3 2 in table 4 again co2 distributions are shown in fig 7 a d represents co2 saturation temperature and solubility at a chosen profile when the kayenta formation was assumed to be a seal with good integrity kh 10 16 m2 and kv 10 17 m2 case 3 1 it prevented the upward migration of co2 from wingate sandstone fig 7a in response to less co2 migration the size of trapped co2 plume in the navajo sandstone was remarkably reduced this result suggests that a co2 supply only from the san rafael swell is not enough to develop a trapped co2 plume in the navajo sandstone in order to develop sufficient size of the trapped co2 plume in the navajo sandstone co2 leakage through either the lgw fault or regional caprocks could be important when the permeability of the kayenta formation was increased by one order case 1 co2 began to leak through the kayenta formation fig 7b which resulted in the development of sufficient size of the trapped co2 plume in the navajo sandstone maximum co2 saturation in case 1 was 0 67 which was greater than one 0 2 in case 3 1 fig 7d even if the co2 stored in wingate sandstone leaked to the upper navajo sandstone the size of the trapped co2 plume in wingate sandstone was still large which implies that the co2 supply from the lgw fault was greater than the amount of co2 leaking through the kayenta formation however when the permeability of kayenta formation was increased further kh 10 14 m2 and kv 10 15 m2 in case 3 2 the trapped co2 plume disappeared within the wingate sandstone fig 7c due to this reason co2 saturation was hardly observed at the vertical profile in the wingate sandstone fig 7d here the kayenta formation with high permeability can thus be considered as fractured or damaged caprock based on the sensitivity study of caprock permeability it can be concluded that the development of trapped co2 plumes and their sizes within upper regional aquifers are highly variable dependent on the presence of fractured or unidentified pathways in the caprock 4 2 sw fault model 4 2 1 subsurface co2 migration and distribution in sw fault case 4 the sw fault system represents more complex geologic configurations than the lgw fault for example the sw fault consists of three fault lines characterizing the same strike but the opposite direction of dip fig 4b frery et al 2015 williams 2004 similar to the lgw fault model two co2 sources were assumed in the sw fault model in the model thermogenically originated co2 from mississippian limestone directly leaked through the sw fault red arrows in fig 4b and as shown in fig 5 the co2 accumulated in the hanging wall of the lgw fault laterally migrated through regional dipping aquifers until it reached the sw fault blue arrows in fig 4b fig 8 a c shows the evolution of gaseous co2 migration in the sw fault system at time periods of 95 1 634 2 and 3171 0 years after co2 is released after 95 1 years co2 fed from the lgw fault through both wingate and navajo sandstones reached the northern sw fault fig 8a once co2 reached the northern sw fault which served as a horizontal barrier its migration was hampered therefore trapped co2 plumes became developed while a certain amount of co2 leaked through the fault offsets between zone i and ii additional co2 was released directly from the bottoms of both the northern and southern sw faults however the co2 released from the bottom of the northern sw fault migrated underneath the regional dipping caprock e g camel formation within sw graben until it reaching at the southern sw fault when co2 arrived at the southern sw fault additional trapped co2 plumes developed in the navajo sandstone zone ii and iii finally co2 released directly from the bottom of the southern sw faults mostly migrated toward the south zone iv where additional co2 geysers tumble weed and chaffin ranch geysers were located fig 1b and c after 634 2 years co2 leaked via both the northern and southern sw faults reached the surface fig 8b the leaked co2 fluxes were localized at fault traces without co2 leakage occurring between the northern and southern sw faults e g sw graben which indicates that the summerville formation served as a seal with good integrity at 3171 0 years the co2 influx from these sources and the outflux to the atmosphere reached the steady state and thus the sizes of the trapped co2 plumes were stabilized fig 8c as seen the largest trapped co2 plume developed in the navajo sandstone of the footwall due to co2 supply from multiple sources laterally migrated co2 from the lgw fault dispersively leaked co2 via the kayenta formation and directly migrated co2 from the bottom of the northern sw fault the occurrence of the largest trapped co2 plume in the shallow navajo sandstone of the footwall is supported by multiple field observations such as those relating to concentrated co2 flux anomalies jung et al 2014 ancient active travertines on the northern side of sw fault burnside 2010 and co2 springs and geyser small bubbling big bubbling pseudo tenmile and tenmile geyser in fig 2b han et al 2013 4 2 2 identification of co2 sources in sw fault case 4 5 1 and 5 2 there has been effort to characterize the co2 sources in this region after investigating the isotopic signatures of gaseous dissolved co2 and helium heath et al 2009 and wilkinson et al 2009 suggested that the co2 released from both lgw and sw faults had a shared origin however although the origin of co2 was characterized well less information was available for identifying locations of the co2 sources in the sw fault in case 4 two co2 sources representing laterally migrated co2 through the regional dipping aquifers e g navajo and wingate sandstones and directly leaked co2 from the bottom of the sw fault were assigned in addition two scenarios were developed by excluding co2 released from lateral boundary case 5 1 and excluding co2 released from the bottom of the sw fault case 5 2 table 4 then degree of contribution on each co2 source was evaluated for the sw fault case 4 releasing co2 from two sources was served as the base case fig 9 a a detailed description of case 4 was provided in section 4 2 1 relative to case 4 it was assumed in case 5 1 that co2 only migrated from the hanging wall of the lgw fault without considering co2 release from the bottom of the sw fault similar to case 4 in case 5 1 the large trapped co2 plume was developed in the navajo sandstone fig 9b nevertheless only a small amount of co2 migrated through the sw graben and reached the southern sw fault almost no co2 flux was predicted at the southern sw fault as co2 did not accumulate at the southern sw fault no co2 migrated further south indicating that case 5 1 was not able to explain the presence of the multiple co2 driven cold water geysers e g tumble weed and chaffin ranch geysers located further south of the sw fault fig 1b and c when co2 was leaked only from the sw fault case 5 2 in fig 9c the subsurface co2 distribution within the sw fault was almost equivalent to that of case 4 fig 9a where co2 was released from two sources the only difference between case 4 and 5 2 was the co2 distribution in the wingate sandstone and kayenta formation of the footwall at the northern sw fault this minor discrepancy in the distribution of subsurface co2 presumably does not cause any significant differences in field observed co2 leakage patterns and the locations of geysers springs and travertines therefore this result indicates that a majority of the co2 in the sw fault originates either solely from the bottom of the sw fault or from both the lgw and sw faults without co2 releasing from the bottom of the sw fault currently predicted subsurface co2 distribution and surface co2 flux anomalies cannot be explained 4 2 3 sensitivity study for fault configurations including fault throw case 4 6 1 and 6 2 and cutoff angle case 4 7 1 and 7 2 in the sw fault model additional uncertainties involve in the fault configurations such as the fault throw and cutoff angle frery et al 2015 and williams 2004 developed a 2 d geologic stratigraphy for the sw fault after analyzing surface outcrops and using well correlations however their stratigraphy models were developed based only on a few wells therefore the sw fault structures still include some uncertainties and additional sensitivity studies were thus conducted to evaluate the role of fault throw and the cutoff angle of the sw fault on subsurface co2 distribution in case 4 the fault throw between the northern footwall zone i and sw graben zone ii was 60 m fig 10 b to evaluate the effect of fault throw on the subsurface co2 distribution the elevation of the sw graben was varied while other footwall and hanging wall zones i iii and iv were fixed for example the sw fault throw was assigned to be 30 m case 6 1 60 m case 4 and 90 m case 6 2 respectively table 4 in this sensitivity study there were only slight changes in the co2 distribution and migration patterns in zone i even with an increase in the sw fault throw fig 10a c there was no distinctive change in the size of trapped co2 plume in the navajo sandstone the invariant size of the trapped co2 plume indicates that the horizontal permeability kh 5 10 16 m2 assigned to the sw fault was sufficiently small enough to prevent horizontal migration of the co2 plume to the sw graben zone ii therefore it can be concluded that the size of the trapped co2 plume is dominantly controlled by fault permeability rather than the magnitude of fault throw in the sw fault as described in section 4 2 1 case 4 less dense co2 migrated buoyantly against gravity until it reached either caprocks or the sw fault when co2 migration was hampered by these types of barriers co2 accumulated beneath caprocks or faults thereby causing the development of trapped co2 plumes in this study the shape of the trapped co2 plumes and the amount of stored co2 mass were assessed by varying the cross cutting angle between the carmel formation and the southern sw fault 80 in case 7 1 70 in case 4 and 60 in case 7 2 when the cutoff angle was 80 the trapped co2 plume was almost flat parallel to the gentle dip of caprock and the calculated co2 mass under the caprock was 3 33 10 4 k g fig 10d after decreasing the cutoff angle to 70 the shape of the trapped co2 plume changed from a flat shape to a wedge shape fig 10e co2 saturation was elevated at the end of the wedge but the total mass of co2 decreased to 2 54 10 4 k g which implies that more co2 escaped to the southern sw fault finally when the cutoff angle was decreased further to 60 more co2 was concentrated at the end of the wedge and the smallest mass of co2 was stored 1 44 10 4 k g fig 10f 4 3 crystal geyser and tenmile geyser models one of the interesting geologic features in this region was the presence of co2 driven cold water geysers fig 11 a and d show photo images of crystal and tenmile geysers when they are erupting as it is evident that the development of these geysers is related to both subsurface co2 distribution or trapped co2 plumes and the configuration of both the lgw and sw fault systems the regional scale lgw and sw fault models developed in this study were utilized to evaluate the eruption mechanisms of co2 driven cold water geysers e g crystal and tenmile geysers in fact there has been effort to characterize the eruption patterns and intervals of these geysers by inserting in situ sensors han et al 2013 watson et al 2014 from a series of field observations it was identified that the eruption characteristics were dynamically evolved with time and were often unpredictable due to complexity involved in eruption characteristics of these geysers it was difficult to reproduce the periodic eruption patterns observed in the field exactly by applying the regional scale models the accurate prediction of the eruption patterns of these geysers via numerical simulations requires the sophisticated wellbore geysering model lu et al 2005 piao et al 2018 pruess 2008 therefore the following simulations were developed to evaluate whether the co2 distribution or trapped co2 plume predicted from regional scale models was capable of developing co2 driven cold water geysers after both lgw and sw fault models reached the steady state condition indicating that the size of trapped co2 plumes became stable and the magnitude of co2 flux did not vary crystal and tenmile geysers were activated in the footwall and graben of lgw and sw fault models respectively fig 4 in fig 11 brine and co2 flow rates gaseous co2 saturation dissolved co2 mass fraction and pressure were simulated at 15 m below the surface where fig 11b c and 11e f represent the eruption characteristics for the crystal and tenmile geysers respectively four eruption stages such as pre eruption eruption recharge and spring or bubbling were identified based on the evolutionary features of both pressure and gaseous co2 flow rates from the geysers specific to crystal geyser shown in fig 11b c during the pre eruption stage yellow bar co2 dissolved brine flowed with a rate fluctuating from 2 0 10 5 to 1 0 10 6 g day m2 green line in fig 11b and the dissolved co2 mass fraction increased xco2 purple line in fig 11c when the brine was not able to hold any more dissolved co2 due to reaching at its solubility limit e g 0 77 of dissolved co2 mass fraction the eruption stage red bar began at t 1 66 10 5 s gaseous co2 exsolved sco2 red line in fig 11c and gaseous co2 flow rate was elevated pink line in fig 11b different from the pre eruption stage the eruption stage was characterized by the presence of two phase fluids including brine and gaseous co2 as the eruption progressed the intensity of the eruption degraded due to both the emission of gaseous co2 to the surface and a decrease in the amount of exsolved co2 from co2 dissolved brine therefore both the gas flow rate and the corresponding co2 saturation also decreased in the middle of the eruption stage brine flow was inverted from an upward to a downward direction green line in fig 11b for example after gaseous co2 had been released to the surface the brine migrated downward to fill void spaces in the wellbore when both co2 saturation and the gaseous co2 flow rate fell to zero the recharge stage blue bar began t 6 10 10 5 s during the recharge stage the co2 dissolved brine migrated upward and gradually filled the wellbore while exsolving a small amount of gaseous co2 due to increase in brine flow within the wellbore the hydrostatic pressure was also elevated navy dotted line in fig 11c at the end of the recharge period t 1 10 10 6 s the brine flow rate reached 8 51 10 5 g day m2 green line in fig 11b and the co2 mass fraction xco2 once again reached its maximum 0 77 and thus gaseous co2 sco2 began to exsolve with increasing in gaseous co2 saturation a subsequent large scale eruption began and continued until all the gaseous co2 has been released to the atmosphere after the large eruption stopped at t 1 23 10 7 s the recharge period began again thereafter the geyser did not show the periodic trend anymore rather both co2 and brine fluxes reached their steady state rates of 1 67 10 3 and 1 43 10 3 g day m2 respectively which implies that the geyser behaved in a similar way to a spring or bubbling well in the previous regional scale lgw fault model trapped co2 plumes were developed in entrada navajo and wingate sandstones as shown in fig 5d indicating that co2 could be supplied from all these formations when the crystal geyser was activated likewise after investigating the eruption profiles of crystal geyser as shown in fig 11b c it can be identified that gaseous co2 entered crystal geyser only from these surrounding formations not from deep co2 sources directly migrated through the lgw fault gaseous co2 entered crystal geyser and then migrated upward to the surface while dissolving into co2 undersaturated brine interestingly during the pre eruption stage yellow bar co2 saturation was zero at the monitored depth i e 15 m within the geyser fig 11c which implies that most of the gaseous co2 entered the geyser dissolved to ambient co2 undersaturated brine while they migrated upward within the geyser therefore co2 presented as co2 dissolved brine within the geyser until gaseous co2 was exsolved due to perturbation of pressure and temperature essentially the geyser eruption was driven by co2 dissolved brine which caused co2 exsolution when the solubility limit was achieved therefore it can be concluded that the cyclicity of co2 dissolution and exsolution from co2 dissolved brine induced the periodic eruptions of the geyser the simulated behavior of tenmile geyser was similar to that of crystal geyser fig 11e and f tenmile geyser also showed the same eruption stages of pre eruption eruption recharge and spring however different from the crystal geyser a large gaseous co2 flux was predicted during the pre eruption stage pink line in fig 11e which was due to widely spread gaseous co2 within shallow formations such as the cedar mountain ce and morrison formations mo fig 8c immediately after activating tenmile geyser pre existing gaseous co2 within these shallow formations was instantaneously emitted after the emission of pre existing gaseous co2 a major eruption began at t 8 95 10 5 s with an increase in the dissolved co2 mass fraction to 0 46 xco2 purple line in fig 11f during the eruption stage red bar the simulated gaseous co2 flow rate and pressure at tenmile geyser were smaller than those at the crystal geyser even in the spring stage green bar the gaseous co2 flow rate at tenmile geyser 6 80 10 2 g day per m2 was still smaller compared to crystal geyser 1 67 10 3 g day per m2 the difference in the eruption scales of these two geysers was caused by the distribution of subsurface co2 including the size and number of trapped co2 plumes intersected by geysers for example in the lgw fault model three large trapped co2 plumes located at the footwall supplied both gaseous co2 and co2 dissolved brine to crystal geyser figs 4a and 5d in contrast even if a large trapped co2 plume exist in the northern footwall of sw fault the tenmile geyser drilled in the sw graben did not intersect this trapped co2 plume figs 4b and 8c therefore only a small amount of co2 is fed to tenmile geyser which presumably resulted in the small scale eruption and co2 flux even after the geyser has transited to a spring or bubbling well 5 conclusion this study used regional scale models of both lgw and sw faults in western utah to identify co2 migration and distribution within the areas where multiple evidences of co2 leakage appeared at the surface travertine deposits co2 rich geyser and springs soil co2 flux anomalies and an oil seep to evaluate subsurface co2 migration and distribution in these complex fault systems two models representing the lgw and sw fault systems were developed in the lgw fault model co2 migrated buoyantly through various flow pathways such as the fault itself fault offsets and damaged caprocks in additional to the direct leakage pathway through the lgw fault both fault offsets developed by fault displacement and relatively high permeable caprocks e g kayenta formation were found to serve as secondary pathways for co2 while co2 migrated through these pathways multiple trapped co2 plumes developed in regional jurassic aquifers e g entrada navajo and wingate sandstones were localized at the northern footwall and between the two lgw fault traces the occurrence of these trapped co2 plumes in these specific locations was related to the structural configuration of both faults and the regional caprocks the lgw fault served as a horizontal barrier and the regional caprocks e g carmel summerville and kayenta formations were intersected with each other sensitivity studies for the lgw fault model subsequently revealed the relationship between the kh of the lgw fault and the size of trapped co2 plumes when the kh of the lgw fault was sufficiently small less than 10 16 m2 trapped co2 plumes were almost equally developed within entrada navajo and wingate sandstones however with an increase in the kh of the lgw fault co2 escaped to the hanging wall of the lgw fault in another sensitivity study when the kayenta formation was assumed to be a good integrity caprock kh 10 16 m2 and kv 10 17 m2 the trapped co2 plume did not develop in upper navajo sandstone which indicated that the degree of fracturing or damage within the caprock would be an important factor governing the development of trapped co2 plumes within aquifers in the lgw fault system in the regional scale sw fault model a large trapped co2 plume appeared within the navajo sandstone at the northern footwall the presence of trapped co2 plumes at the northern footwall provides good support for previous field observations ancient travertine deposits and co2 springs were localized at the northern footwall in addition concentrated co2 flux anomalies were also monitored at the northern trace of the sw fault sensitivity studies with varying co2 sources indicated that the scenario with co2 originating from the bottom of the sw fault only explained the presence of multiple co2 driven cold water geysers e g tumble weed and chaffin ranch geysers which are located further south of the sw fault finally we evaluated whether subsurface co2 distributions or trapped co2 plumes predicted from regional scale models were capable of developing co2 driven cold water geysers although the periodic geyser eruption could not be reproduced exactly by the regional scale model the physical process of the eruption mechanism for the co2 driven geyser eruption was elucidated in this simulation the cyclicity of the geyser eruption was found to be primarily driven by gaseous co2 exsolution from co2 dissolved brine acknowledgements this research was supported by basic science research program through the national research foundation of korea funded by the ministry of education project number 2016r1d1a1b01008715 the korea environmental industry and technology institute keiti project numbers 2018002440003 2018001810004 kue young kim received funding through the basic research project of the korea institute of geoscience and mineral resources kigam funded by the ministry of science and ict 
6739,understanding co2 migration and distribution in fault systems is essential to evaluate long term secure co2 storage and prevent hazardous effects caused by co2 leakage to elucidate the role of the fault system on subsurface co2 migration and leakage processes a two dimensional multi phase transport model was constructed to represent little grand wash lgw and salt wash sw faults where naturally originating co2 is being leaked to the surface according to simulation results buoyant co2 leaked through various pathways including the faults themselves fault offsets and damaged caprock because of both fault systems and caprocks serving as barriers multiple trapped co2 plumes were developed in this region presence of trapped co2 plumes in the subsurface is supported by multiple field observations e g elevated soil co2 fluxes travertines and co2 driven cold water geysers co2 springs adjacent to both lgw and sw faults sensitivity studies were conducted with different permeabilities for faults and caprock various co2 source locations and differing fault parameters e g fault throw and cutoff angle which affected subsurface co2 distribution including size shape and location of trapped co2 plumes finally such trapped co2 plumes have played a key role in the development of co2 driven cold water geysers in these regions keywords fault co2 migration trapped co2 plume co2 driven cold water geyser 1 introduction carbon dioxide co2 emissions from anthropogenic and natural sources to the atmosphere will need to be reduced to varying degrees worldwide for mitigating climate change ipcc 2014 efforts to mitigate environmental impacts from increased atmospheric co2 concentrations over the last several decades have suggested that geologic carbon sequestration gcs can possibly be used to reduce the amount of co2 emitted to the atmosphere ampomah et al 2017 dai et al 2018 li et al 2016 reichle et al 1999 schrag 2009 soltanian et al 2017 to guarantee safe and long term gcs it is essential to find good porosity storage formations capped by low permeability formations kampman et al 2014 pruess et al 2001 because geologically sequestered co2 could potentially encounter unidentified or unwanted pathways e g boreholes fractures within caprocks and fault zones which could serve as co2 leakage pathways directly connecting deep storage formations to shallow potable aquifers or to the atmosphere kirk 2011 pruess 2008 stevens et al 2001 occurrence of such co2 leakage from the storage formation could result in the failure of gcs and also has a detrimental effect on public and environmental health metz et al 2005 price et al 2007 for example as a result of co2 leakage from a gcs reservoir a bank of highly concentrated methane could migrate to upper shallow aquifers where unexpected contamination of potable groundwater occurred hosseini et al 2013 soltanian et al 2018 furthermore previous studies assessed that co2 leakage into shallow aquifers could contaminate potable groundwater resources by decreasing the ph and consequently enhancing the mobility of toxic metals preserved in the aquifer media keating et al 2013 kim et al 2018 zheng et al 2015 it is thus essential to gain an understanding of subsurface co2 migration or leakage through unidentified pathways when evaluating long term secure co2 storage to prevent potential disasters relating to co2 leakage baxter et al 1989 burnside et al 2013 with respect to unidentified pathways fault zones within the upper crustal system have an important role in fluid flow bense et al 2013 faulkner et al 2010 according to caine et al 1996 fault zones comprise distinct structural and hydrogeologic features that include a fault core and damage zone the fault core consisting of gouge cataclasite and mylonite is characterized as being a low permeability zone the damage zone surrounding the fault core is composed of various geologic features e g fractures veins and folds and is typically highlighted to be an enhanced permeability zone from a hydrogeological perspective these two units can thus be a low permeability fault core and high permeability fractured damage zone respectively bense et al 2013 these structural and hydrogeologic features within a fault zone characterize an along fault or vertical conduit and an across fault or horizontal barrier due to such an opposite role of the fault zone to fluid flow many previous hydrogeologic studies investigated the role of fault zones as a conduit barrier on fluid flow for example the role of fault zones as conduits has been investigated in relation to observing the cementation mineralization processes in faults boles et al 2004 garven et al 1999 treiman 2008 and studying geothermal anomalies fernàndez and banda 1990 mamadou et al 2016 mckenna and blackwell 2004 and co2 leakage along the fault zones jung et al 2014 lee et al 2016 sciarra et al 2018 in contrast studies focusing on fault zones as barriers have focused on the development of subsurface regions characterized as either abnormal hydraulic gradient or overpressures bense et al 2013 or the development of natural co2 reservoirs jung et al 2015 kampman et al 2014 shipton et al 2004 as complex fault zones can be essential pathways for co2 leakage previous studies have aimed to understand natural co2 reservoirs where co2 is released naturally via regional faults bickle et al 2013 lewicki et al 2007 one of these natural analogue sites is located within the paradox basin in eastern utah jung et al 2014 where naturally originating co2 is being leaked through both little grand wash lgw and salt wash sw faults that are located near the city of green river at the surface of fault traces allis et al 2005 conducted diffusive soil co2 flux surveys and observed a high co2 fluxes 100 g d a y m 2 later jung et al 2014 conducted more extensive co2 flux surveys in this region and observed co2 flux anomalies along fault traces and also at the northern footwall of both faults in addition to field oriented studies jung et al 2015 used numerical simulations to establish regional scale numerical models to elucidate the co2 distribution within the lgw fault system advancing the study by jung et al 2015 we extended previous understandings of subsurface co2 migration and distribution by developing both regional scale lgw and sw fault models and evaluated how the fault structures affected subsurface co2 distribution and the characteristics of trapped co2 plumes specifically the effect of the lgw fault zone serving as either a barrier or a conduit was assessed and the role of caprock integrity on trapped co2 plumes was evaluated then for the first time subsurface co2 migration within the sw fault system was predicted as the geologic features of the sw fault have not yet been characterized in detail sensitivity studies on trapped co2 plumes were conducted by varying the magnitude of fault throw and the cutoff angle between the sw fault and regional formations in addition the locations for co2 sources were evaluated by assuming that co2 originated from either recharge of dissolved co2 brine in jurassic aquifers or separate phase co2 leaking through the sw fault from deep subsurface mississippian carbonate rock finally the eruption mechanisms for co2 driven cold water geysers such as crystal and tenmile geysers located in these regions were numerically evaluated 2 site description 2 1 little grand wash lgw and salt wash sw faults the colorado plateau extending in parts of the utah colorado arizona and new mexico is an elevated tectonic platform caused by cenozoic tectonic events parsons and mccarthy 1995 fig 1 a in the colorado plateau multiple sequences of sedimentary formations horizontally extend with a gentle dip angle table 1 nevertheless some strata are folded or cross cut by monoclines and faults with north or northwest strikes stewart et al 1972 three basins including uinta piceance and paradox basins are formed in the upper and central parts of the colorado plateau among these three basins the study area is located within paradox basin fig 1a the paradox basin is primarily composed of paleozoic and early mesozoic strata especially the shallow strata system is hydrostratigraphically classified into two categories 1 permian jurassic aquifers permian white rim sandstone lower jurassic wingate navajo sandstones and middle jurassic entrada curtis sandstones and 2 interbedded confining layers triassic moenkopi chinle formations jurassic kayenta carmel formations the shale rich lower part of entrada sandstone and middle jurassic summerville table 1 kampman et al 2014 shipton et al 2004 in the paradox basin structural isotopic and noble gas studies suggested that meteoric groundwater recharging at san rafael swell migrates to the southeast via jurassic sandstone aquifers navajo and entrada sandstones and discharges into the green river fig 1b baer and rigby 1978 hood and patterson 1984 kampman et al 2014 wilkinson et al 2009 additionally within and at the margin of the paradox basin there exist co2 reservoirs where numerous amounts of co2 are stored naturally the estimated amount was 2 8 1010 2 8 1013 m3 allis et al 2001 most of these co2 natural reservoirs including gordon creek farnham dome woodside escalante lisbon and mcelmo dome are currently developed with the aim of using them commercially in the process of co2 enhanced oil recovery and dry ice production fig 1a allis et al 2001 cappa and rice 1995 morgan and chidsey 1991 pearce et al 1996 little grand wash lgw and salt wash sw faults are located to the south of the city of green river fig 1c the lgw fault intersecting the north to northwest plunging green river anticline extends 30 km with a west east strike the lgw fault having a dip of 70 80 to the south is a normal fault with the maximum throw of 260 290 m dockrill and shipton 2010 mcknight 1940 shipton et al 2005 to 6 km further south from the lgw fault the sw fault characterizing two sub parallel normal faults extends approximately 23 km west east with the strike of 290 the northern and southern sw faults have dips of 78 and 87 to the south and north respectively which form the salt wash graben between the two faults doelling 2002 the maximum offsets of the northern and southern faults are 366 m and 210 m respectively evans et al 2004 williams 2004 2 2 evidences of co2 and brine leakage geysers springs travertines and diffusive co2 flux both co2 and brine have been leaked in the form of co2 driven cold water geysers and springs along the traces of both lgw and sw faults and adjacent areas han et al 2013 shipton et al 2005 for example the largest co2 driven cold water geyser crystal geyser is located 45 m north of the lgw fault fig 2 a and a relatively small geyser tenmile geyser is located 100 m south of the northern trace of the sw fault fig 2b the drilling history penetration depth and lithologic information of crystal geyser has been characterized well for example han et al 2013 shipton et al 2005 and watson et al 2014 revealed that eruption intervals of crystal geyser was extended while its intensity was decreased in contrast to crystal geyser the characteristics for tenmile geyser were not identified well but a recent study by watson et al 2014 indicated that the eruption pattern was regular with the intervals of 8 5 2 6 h in addition to these geysers co2 driven cold water springs such as small bubbling big bubbling pseudo tenmile and torrey s springs are located in this region interestingly all these springs are densely distributed on the northern footwall of the sw faults fig 2b adjacent to these geysers and springs active and inactive or ancient travertine deposits are developed burnside et al 2013 han et al 2013 shipton et al 2004 the presence of both active and inactive travertine deposits supports the occurrence of long term co2 and brine leakages in this region over the geologic time period and also confirms that both lgw and sw faults act as active pathways for subsurface fluids baer and rigby 1978 burnside 2010 burnside et al 2013 recently the spatial patterns of diffusive co2 fluxes were measured along both lgw and sw fault traces allis et al 2001 jung et al 2014 measured co2 flux anomalies were found to be concentrated at the northern footwalls of both the lgw and sw faults and intersected fault traces fig 2a and b in addition followed by jung et al 2014 the magnitude of the co2 flux was decreased from the lgw north to sw south faults maximum co2 flux anomalies were 36 259 g m 2 d 1 and 1428 g m 2 d 1 in the lgw and sw fault zones respectively 2 3 origins of leaking co2 assuming that the value of δ 13 c originated from marine carbonate is 0 and dissolved carbon in groundwater primarily originated from soil and carbonate minerals the range of δ 13 c at crystal geyser effluent expected to be 13 0 to 7 5 mayo et al 1991 however measured δ 13 c in geyser effluents water 1 2 and gas 1 9 were found to be positively skewed relative to the expected values implying that additional co2 sources such as thermal decomposition of carbonate rocks could contribute the enrichment of δ 13 c in the crystal geyser effluent mayo et al 1991 the co2 originated from thermal decomposition was supported by shipton et al 2004 who suggested that the high temperature thermal decomposition of carbonate was caused by the adjacent contact aureoles of tertiary intrusions e g the la sal and henry mountains recently heath et al 2009 reported that helium isotopic ratios r ra are 0 302 crystal geyser and 0 310 big bubbling spring respectively here r and ra represent 3he 4he of a sample and atmospheric air respectively these r ra ratios measured from crystal geyser and big bubbling spring were closer to the values of crust originated sources typically 0 02 than mantle derived ones 7 to 21 clark and fritz 1997 which suggested that the co2 from geysers and springs was presumably originated from crustal sources such as clay carbonate reactions and the thermal degradation of carbonates heath et al 2009 furthermore wilkinson et al 2009 analyzed co2 3he from these geysers and springs tumbleweed geyser torrey s spring crystal geyser chaffin ranch geyser small bubbling big bubbling pseudo tenmile geyser and tenmile geyser as shown fig 1b and also supported that co2 primarily originated from crustal sources with the rest of co2 1 20 from a mantle driven source 2 4 regional water chemistry a total of 97 water chemistry data were obtained from various sources han et al 2017 kampman et al 2014 kharaka et al 1997 spangler 1992 and the chemical characteristics and origins of fluids in this region were investigated fig 3 these compiled water chemistry data were categorized into four groups where group i represents fluid samples collected from shallow jurassic aquifers during a scientific drilling hole project kampman et al 2014 co2w55 well was drilled approximately 285 m to the west of crystal geyser and here a total of 6 fluid samples were collected from entrada sandstone 98 m carmel formation 188 m and navajo sandstone 206 224 276 and 322 m group ii included a total of 5 fluid samples originating from deep paleozoic aquifers such as paradox brine which were gathered in adjacent hydrocarbon fields kharaka et al 1997 spangler 1992 and group iii included 71 effluent samples that were collected during the eruption of crystal geyser han et al 2017 kampman et al 2014 finally a total of 15 samples group iv were collected at salt wash springs and tenmile geyser which are located adjacent to the northern footwall of the sw faults han et al 2017 kampman et al 2014 group i representing fluid chemistry in the shallow jurassic aquifers such as entrada carmel and navajo sandstone evolved from na hco3 to na cl typed groundwater as the formation depth increased fig 3a for example the fluid chemistry at shallow entrada sandstone 98 mbs na k 39 9 and cl 24 9 transited to be saline at navajo sandstone 322 mbs na k 63 6 and cl 44 7 additionally ph and tds of group i was low 5 13 to 6 3 and diluted 7677 11 980 mg l relative to other samples groups ii iii and iv in this region which implies that formation fluids in the shallow jurassic aquifers were mixed with meteorically originated shallow groundwater group ii representing paradox brine was characterized to be high tds from 158 721 to 255 030 mg l which was strongly enriched with na k cl average na k of 93 4 and cl of 97 4 group iii and iv represented the fluid chemistry of crystal geyser and salt wash springs respectively the chemistry of these groups were plotted between groups i and ii which implies that groups iii and iv are a mixture of both groups i and ii in detail the salinity of group iii crystal geyser revealed average and standard deviation tds of 15 203 mg l average na k 70 57 and cl 47 98 and 1241 mg l respectively while group iv salt wash springs showed average and standard deviation tds of 19 154 mg l average of na k 77 6 and cl 58 5 and 2004 mg l here p value between group iii and iv was 1 66 10 6 assuming that groups i and ii represent end members of the mixture groups iii and iv the mixing ratio of paradox brine group ii in groups iii and iv are calculated to be 2 3 and 4 1 respectively this observation supported the fact that effluents from both crystal geyser and salt wash springs having a tds of 11 000 to 14 000 mg l characterized to be a mixture of both meteoric groundwater and brine baer and rigby 1978 rush et al 1984 waltham 2001 wilkinson et al 2009 recent studies revealed that the geochemistry of crystal geyser effluent dynamically evolved during its eruption the eruption of crystal geyser was classified into four stages a minor eruption period major eruption period aftershock eruption and recharge during the transitions between dynamic geyser eruptions effluent chemistry was also changed han et al 2017 according to han et al 2017 the recharge period was characterized by a gradual increase in electrical conductivity from 18 to 19 ms cm after transiting to the minor eruption period the electrical conductivity of the effluents increased to 21 3 ms cm and then maintained flat until the initiation of the major eruption period which was characterized to be an instantaneous drop in electrical conductivity from 21 3 to 19 3 ms cm similarly probst et al 2018 observed the evolution of effluent chemistry during different eruption periods 3 model description lgw and sw faults and geysers to simulate the distribution and migration of co2 in shallow jurassic aquifers at lgw and sw faults a numerical simulator tough2 mp eco2n was utilized the tough2 mp is a massive parallel version of tough2 which is capable of simulating non isothermal multiphase and multicomponent flow processes in porous fractured media pruess et al 1999 zhang et al 2008 the eco2n is the equation of state module that can predict thermodynamic properties for co2 h2o and nacl within a range of 10 c t 110 c and p 47 6 mpa pruess 2005 the lgw fault model is a 2 d model that cross cuts both lgw fault and crystal geyser from north to south fig 4 a this model was horizontally extended by 700 m from a a figs 1c and 2a and vertically penetrated 600 m from cretaceous and jurassic formations table 1 to simulate co2 migration accurately in the region of crystal geyser and lgw fault the sizes of grid blocks were varied in the x direction e g δ x 0 25 1 5 and 10 m dependent on the distance from crystal geyser and lgw fault however the size of the grid blocks in the z direction δ z 10 m were uniformly assigned therefore the number of grid blocks was 329 and 60 to the x and z direction respectively the sw fault model consisting of three fault lines as well as tenmile geyser is a 2 d model that cuts perpendicular to sw fault b b in figs 1c 2b and 4b the size of model was 2 130 m width and 600 m height similar to the lgw fault model the sizes of the grid blocks in the x direction were varied depending on the location of fault lines and the geyser but the grid block size in the z direction was uniform δ z 10 m as a result the number of grid blocks were 9 840 x direction 164 and z direction 60 finally the thickness of fault lines for both lgw and sw faults were assigned to be 5 m followed by dockrill and shipton 2010 for both lgw and sw fault models the hydrostatic pressure gradient of 0 01 mpa m was assigned similar to that of jung et al 2015 while the top and bottom boundaries were fixed at 0 1 mpa surface and 6 1 mpa 600 m depth respectively following the study of heath et al 2009 the geothermal gradient was assigned as 0 0212 c m with the surface temperature of 25 c in addition a 0 011 nacl mass fraction which was calculated from the chemistry of crystal geyser effluents kampman et al 2014 was uniformly assigned the top boundary was assigned as the fixed boundary condition to represent the atmospheric condition whereas the bottom boundary was set as a no flow boundary condition due to the presence of the low permeable formation such as chinle formation in addition the fixed boundary condition was assigned to lateral boundaries where both co2 and brine were allowed to flow in and out especially hood and patterson 1984 suggested that co2 dissolved brine in both navajo and entrada sandstones was fed from san rafael swell which is located on the left boundary of the model fig 1b to simulate recharge of co2 dissolved brine the pressure of navajo and entrada sandstones on the left boundary was set to be 0 025 mpa higher than those in adjacent grid blocks the lgw fault model consists of cretaceous and jurassic formations while the sw fault model includes cretaceous jurassic as well as triassic formations geologic formations of both lgw and sw fault models were assumed to be homogeneous and anisotropic kv kh 10 table 2 allis et al 2001 burnside 2010 hansley 1995 hood and patterson 1984 jung et al 2015 white et al 2005 the regional dip of the formations in the lgw and sw faults models was uniform at 4 and 6 11 to the north respectively dockrill and shipton 2010 frery et al 2015 williams 2004 after calibrating the numerical lgw fault model with field measured co2 flux jung et al 2015 suggested that the lgw fault acts vertically as a conduit 5 10 16 m2 kv 1 10 15 m2 and horizontally as a barrier 1 10 17 m2 kh 1 10 16 m2 therefore following the study of jung et al 2015 kv and kh of the lgw fault were assigned as 5 10 16 m2 and 10 17 m2 respectively in addition it was assumed that the sw fault acted in a similar way to the lgw fault and the following k kv kh 1 10 15 m2 5 10 16 m2 was assigned the buoyant migration of gaseous co2 through both lgw and sw faults was simulated by assigning 0 6 co2 saturation at the bottom most grid blocks of the faults red arrows in fig 4a and b in addition co2 dissolved brine fed from the left boundaries of the two models through both navajo and wingate sandstones was simulated by setting 0 05 mass fraction of co2 dissolved brine blue arrows in fig 4a and b finally for multiphase transports of brine and gaseous co2 the relative permeability and capillary pressure were modeled using corey s curves corey 1954 and van genuchten function van genuchten 1980 in both lgw and sw fault models the detailed mathematical expressions and input parameters are shown in table 3 one of localized characteristics in the lgw and sw faults is the presence of co2 driven cold water geysers such as crystal and tenmile geysers respectively glennon and pfaff 2004 kampman et al 2014 previously a few researchers such as han et al 2013 and watson et al 2014 collected in situ datasets of pressure temperature electrical conductivity and ph and conceptually identified the eruption mechanisms of these cold water geysers based on the conceptual framework characterized by previous studies the eruption mechanism was evaluated in this study by using regional scale numerical models fig 4a and b which included realistic sedimentary stratigraphy fault configuration and subsurface co2 distribution both crystal and tenmile geysers have diameters of 0 5 m surrounded by a less permeable matrix 0 25 m here the permeability of conduit and surrounding matrix was set as 10 11 m2 and 10 19 m2 respectively following the study of jung et al 2015 the matrix surrounding the geyser conduit constrains the influx of both co2 and brine from aquifers to the conduit while co2 and brine can flow quickly through the geyser conduit however due to limitations associated with the continuum or porous media approach applied in this study for example the velocity of fluids within geysers is too fast to simulate with darcy s law the geyser model cannot predict the periodic eruption patterns exactly as observed at these geysers in addition the continuum approach cannot simulate co2 bubble generation and coalescence within the wellbore as well as the exact thermal alterations caused by frictional loss the goal of the geyser model was therefore not to reproduce the exact periodic eruption pattern observed in the field rather we attempted to evaluate whether the co2 distribution or traps predicted from the regional scale model was capable of developing co2 driven cold water geysers in addition to identifying the role of subsurface co2 traps on geyser eruption 4 simulation results 4 1 lgw fault model 4 1 1 subsurface co2 migration and distribution in lgw fault case 1 fig 5 shows the evolution of gaseous co2 migration in the lgw fault system at 77 3 222 6 398 9 and 1 314 7 years after co2 is released subsurface co2 migration reached the steady state condition approximately at 1 314 7 years the normal lgw fault consists of two parallel fault lines which are approximately 50 m apart each other dockrill and shipton 2010 separated by the two fault lines the footwall and hanging wall are located to the north and south respectively and stacked regional formations subside toward the south for example compared to the entrada formation in the footwall the entrada formation within two faults lines subsided by 70 m and the fault throw at the hanging wall ranged between 70 m and 160 m as described the interbedded formations e g caprocks and aquifers and the cross cutting lgw faults have developed complex geologic configurations which potentially alter the buoyant movement of co2 plumes through offsets between the formations after co2 was released from the bottom most of the lgw fault lines the co2 was accumulated in the wingate sandstone wi which is positioned beneath the regional caprock of the kayenta formation ka fig 5a when accumulated co2 saturation within the wingate sandstone became large enough some co2 began to disperse directly to the upper low k kayenta formation i in fig 5a at pore scale this indicates that built up co2 pressure exceeded the capillary entry pressure of kayenta formation other co2 horizontally passed through the lgw fault which served as a horizontal barrier kh 1 10 17 m2 and migrated to the wingate sandstone in the footwall ii in fig 5a once co2 entered the wingate sandstone it migrated upward following the dip of the northern lgw fault until its movement was hampered by the kayenta formation the remaining co2 migrated south toward the navajo sandstone na in the hanging wall iii in fig 5a once the co2 entered the navajo sandstone in the hanging wall co2 migrated upward to the camel formation ca and moved further south following the regional dip to the right lateral boundary finally while co2 dissolved brine fed from the san rafael swell migrated through the dipping navajo sandstone in the footwall gaseous co2 was exsolved from co2 dissolved brine due to the pressure reduction caused by the regional dip of the navajo sandstone iv in fig 5a the exsolved gaseous co2 then migrated south toward the lgw fault until its movement was prevented by the lgw fault after 222 6 years a trapped co2 plume developed in the wingate sandstone capped by both kayanta formation and the lgw fault fig 5b even if some co2 escaped to the fault offset which was connected to the navajo sandstone located between two lgw fault lines the size of the trapped co2 plume continuously grew within the wingate sandstone this suggests that the role of the lgw fault serving as a horizontal barrier is important to the development of the trapped co2 plume in the footwall after co2 passed horizontally through the northern lgw fault and entered the navajo sandstone which was located between two lgw fault lines co2 migrated upward and accumulated beneath the camel formation then through the fault offset in the southern lgw fault line co2 escaped to the entrada formation en in the hanging wall finally an additional trapped co2 plume which was fed from the san rafael swell gradually developed in the navajo sandstone at the footwall where the co2 plume was capped by both the carmel formation and the northern lgw fault in 398 9 years and 1 314 7 years the role of the lgw fault on co2 migration becomes distinct fig 5c and d in the end multiple trapped co2 plumes were developed in the jurassic wingate navajo and entrada sandstones trapped co2 plumes were particularly concentrated in the footwall and between the two lgw fault lines however co2 that migrated to the hanging wall was not able to accumulate due to the absence of a horizontal barrier the development of trapped co2 plumes only in the footwall was also supported by field observed co2 fluxes jung et al 2014 where high co2 fluxes were dominantly measured on the footwall of the lgw fault fig 2a in summary the lgw fault model revealed that co2 migrated buoyantly through various pathways the offsets developed by fault displacement were the primary pathway for buoyant co2 these offsets served as connected pathways to other regional aquifers where co2 migrated vertically to regional caprocks some of the co2 was able to escape directly following through the dip of the lgw fault kv 5 10 16 m2 but this amount was relatively small finally the kayenta formation which has relatively high permeability compared to other confining layers also served as leakage pathways where co2 migrated dispersively fig 5d and table 2 4 1 2 sensitivity study for kh in lgw fault case 1 2 1 and 2 2 from the previous study by jung et al 2015 the permeability range of the lgw fault was characterized to be 1 10 17 m2 kh 1 10 16 m2 and 5 10 16 m2 kv 1 10 15 m2 after calibrating numerical prediction to field measured co2 flux in case 1 the selected permeabilities of the lgw fault was kh 10 17 m2 and kv 5 10 16 m2 assuming that the lgw fault served as a horizontal barrier one of the objectives in this study was to evaluate the role of the lgw fault on subsurface co2 migration and distribution therefore additional sensitivity studies were conducted using an increase in kh of the lgw fault table 4 simulated co2 distribution in each case is shown in fig 6 a 6b and 6c the vertical profile green dotted line was selected where the crystal geyser was currently located here co2 saturation temperature and solubility were predicted fig 6d co2 solubility was calculated using the equation of state developed by duan and sun 2003 relative to the co2 distribution in case 1 a one order increase in kh case 2 1 accelerated co2 leakage through multiple fault offsets fig 6a and b consequently the size or thickness of the trapped co2 plume located in the entrada sandstone of the footwall grew for example the thickness of the trapped co2 plume in the entrada sandstone increased from 67 m case 1 to 85 m case 2 1 fig 6d additionally in case 1 the trapped co2 plume was not developed in the hanging wall but after increasing kh the small size of the trapped co2 plume began to develop in the entrada sandstone of the hanging wall when kh of the lgw fault was further increased case 2 2 co2 trapped in both the wingate and navajo sandstones at the footwall leaked more to the shallow entrada sandstone fig 6c therefore the size or thickness of the trapped co2 plume in the entrada sandstone became even larger 115 m in case 2 2 due to the co2 accumulation in the entrada sandstone formation pressure was elevated and consequently the calculated solubility was also enhanced fig 6d in addition more co2 migrated to the hanging wall via fault offsets and thus the size of the trapped co2 plume in the hanging wall was also increased however despite the development of trapped co2 plumes in the hanging wall field observations did not support the presence of subsurface co2 reservoirs in the hanging wall for example in the field active co2 geysers such as crystal geyser and active inactive travertines were located at the footwall and even anomalous co2 flux measurements were mostly detected at the footwall fig 2a burnside 2010 jung et al 2014 the presence of local geologic signatures on the footwall implies that accumulated co2 plumes only exist in the footwall therefore based on field and simulated observations it is concluded that the regional permeability of the lgw fault is presumably low less than 10 16 m2 and thus the lgw fault currently serves as a barrier for subsurface fluid flow 4 1 3 regional caprock kayenta formation case 1 3 1 and 3 2 less information is available for the characteristics of regional caprocks in this region for example the permeabilities kh 10 15 m2 and kv 10 16 m2 of the kayenta formation were assigned based on the previous study by white et al 2005 however the simulation results shown in fig 5d suggest that the presence of highly permeable pathways within caprocks could be important to the development of trapped co2 plumes likewise through an investigation of the lithologic cores acquired from the drill hole co2w55 kampman et al 2014 suggested that preferential pathways may exist in these regional caprocks therefore additional sensitivity studies were conducted by varying the permeability of the kayenta formation cases 1 3 1 and 3 2 in table 4 again co2 distributions are shown in fig 7 a d represents co2 saturation temperature and solubility at a chosen profile when the kayenta formation was assumed to be a seal with good integrity kh 10 16 m2 and kv 10 17 m2 case 3 1 it prevented the upward migration of co2 from wingate sandstone fig 7a in response to less co2 migration the size of trapped co2 plume in the navajo sandstone was remarkably reduced this result suggests that a co2 supply only from the san rafael swell is not enough to develop a trapped co2 plume in the navajo sandstone in order to develop sufficient size of the trapped co2 plume in the navajo sandstone co2 leakage through either the lgw fault or regional caprocks could be important when the permeability of the kayenta formation was increased by one order case 1 co2 began to leak through the kayenta formation fig 7b which resulted in the development of sufficient size of the trapped co2 plume in the navajo sandstone maximum co2 saturation in case 1 was 0 67 which was greater than one 0 2 in case 3 1 fig 7d even if the co2 stored in wingate sandstone leaked to the upper navajo sandstone the size of the trapped co2 plume in wingate sandstone was still large which implies that the co2 supply from the lgw fault was greater than the amount of co2 leaking through the kayenta formation however when the permeability of kayenta formation was increased further kh 10 14 m2 and kv 10 15 m2 in case 3 2 the trapped co2 plume disappeared within the wingate sandstone fig 7c due to this reason co2 saturation was hardly observed at the vertical profile in the wingate sandstone fig 7d here the kayenta formation with high permeability can thus be considered as fractured or damaged caprock based on the sensitivity study of caprock permeability it can be concluded that the development of trapped co2 plumes and their sizes within upper regional aquifers are highly variable dependent on the presence of fractured or unidentified pathways in the caprock 4 2 sw fault model 4 2 1 subsurface co2 migration and distribution in sw fault case 4 the sw fault system represents more complex geologic configurations than the lgw fault for example the sw fault consists of three fault lines characterizing the same strike but the opposite direction of dip fig 4b frery et al 2015 williams 2004 similar to the lgw fault model two co2 sources were assumed in the sw fault model in the model thermogenically originated co2 from mississippian limestone directly leaked through the sw fault red arrows in fig 4b and as shown in fig 5 the co2 accumulated in the hanging wall of the lgw fault laterally migrated through regional dipping aquifers until it reached the sw fault blue arrows in fig 4b fig 8 a c shows the evolution of gaseous co2 migration in the sw fault system at time periods of 95 1 634 2 and 3171 0 years after co2 is released after 95 1 years co2 fed from the lgw fault through both wingate and navajo sandstones reached the northern sw fault fig 8a once co2 reached the northern sw fault which served as a horizontal barrier its migration was hampered therefore trapped co2 plumes became developed while a certain amount of co2 leaked through the fault offsets between zone i and ii additional co2 was released directly from the bottoms of both the northern and southern sw faults however the co2 released from the bottom of the northern sw fault migrated underneath the regional dipping caprock e g camel formation within sw graben until it reaching at the southern sw fault when co2 arrived at the southern sw fault additional trapped co2 plumes developed in the navajo sandstone zone ii and iii finally co2 released directly from the bottom of the southern sw faults mostly migrated toward the south zone iv where additional co2 geysers tumble weed and chaffin ranch geysers were located fig 1b and c after 634 2 years co2 leaked via both the northern and southern sw faults reached the surface fig 8b the leaked co2 fluxes were localized at fault traces without co2 leakage occurring between the northern and southern sw faults e g sw graben which indicates that the summerville formation served as a seal with good integrity at 3171 0 years the co2 influx from these sources and the outflux to the atmosphere reached the steady state and thus the sizes of the trapped co2 plumes were stabilized fig 8c as seen the largest trapped co2 plume developed in the navajo sandstone of the footwall due to co2 supply from multiple sources laterally migrated co2 from the lgw fault dispersively leaked co2 via the kayenta formation and directly migrated co2 from the bottom of the northern sw fault the occurrence of the largest trapped co2 plume in the shallow navajo sandstone of the footwall is supported by multiple field observations such as those relating to concentrated co2 flux anomalies jung et al 2014 ancient active travertines on the northern side of sw fault burnside 2010 and co2 springs and geyser small bubbling big bubbling pseudo tenmile and tenmile geyser in fig 2b han et al 2013 4 2 2 identification of co2 sources in sw fault case 4 5 1 and 5 2 there has been effort to characterize the co2 sources in this region after investigating the isotopic signatures of gaseous dissolved co2 and helium heath et al 2009 and wilkinson et al 2009 suggested that the co2 released from both lgw and sw faults had a shared origin however although the origin of co2 was characterized well less information was available for identifying locations of the co2 sources in the sw fault in case 4 two co2 sources representing laterally migrated co2 through the regional dipping aquifers e g navajo and wingate sandstones and directly leaked co2 from the bottom of the sw fault were assigned in addition two scenarios were developed by excluding co2 released from lateral boundary case 5 1 and excluding co2 released from the bottom of the sw fault case 5 2 table 4 then degree of contribution on each co2 source was evaluated for the sw fault case 4 releasing co2 from two sources was served as the base case fig 9 a a detailed description of case 4 was provided in section 4 2 1 relative to case 4 it was assumed in case 5 1 that co2 only migrated from the hanging wall of the lgw fault without considering co2 release from the bottom of the sw fault similar to case 4 in case 5 1 the large trapped co2 plume was developed in the navajo sandstone fig 9b nevertheless only a small amount of co2 migrated through the sw graben and reached the southern sw fault almost no co2 flux was predicted at the southern sw fault as co2 did not accumulate at the southern sw fault no co2 migrated further south indicating that case 5 1 was not able to explain the presence of the multiple co2 driven cold water geysers e g tumble weed and chaffin ranch geysers located further south of the sw fault fig 1b and c when co2 was leaked only from the sw fault case 5 2 in fig 9c the subsurface co2 distribution within the sw fault was almost equivalent to that of case 4 fig 9a where co2 was released from two sources the only difference between case 4 and 5 2 was the co2 distribution in the wingate sandstone and kayenta formation of the footwall at the northern sw fault this minor discrepancy in the distribution of subsurface co2 presumably does not cause any significant differences in field observed co2 leakage patterns and the locations of geysers springs and travertines therefore this result indicates that a majority of the co2 in the sw fault originates either solely from the bottom of the sw fault or from both the lgw and sw faults without co2 releasing from the bottom of the sw fault currently predicted subsurface co2 distribution and surface co2 flux anomalies cannot be explained 4 2 3 sensitivity study for fault configurations including fault throw case 4 6 1 and 6 2 and cutoff angle case 4 7 1 and 7 2 in the sw fault model additional uncertainties involve in the fault configurations such as the fault throw and cutoff angle frery et al 2015 and williams 2004 developed a 2 d geologic stratigraphy for the sw fault after analyzing surface outcrops and using well correlations however their stratigraphy models were developed based only on a few wells therefore the sw fault structures still include some uncertainties and additional sensitivity studies were thus conducted to evaluate the role of fault throw and the cutoff angle of the sw fault on subsurface co2 distribution in case 4 the fault throw between the northern footwall zone i and sw graben zone ii was 60 m fig 10 b to evaluate the effect of fault throw on the subsurface co2 distribution the elevation of the sw graben was varied while other footwall and hanging wall zones i iii and iv were fixed for example the sw fault throw was assigned to be 30 m case 6 1 60 m case 4 and 90 m case 6 2 respectively table 4 in this sensitivity study there were only slight changes in the co2 distribution and migration patterns in zone i even with an increase in the sw fault throw fig 10a c there was no distinctive change in the size of trapped co2 plume in the navajo sandstone the invariant size of the trapped co2 plume indicates that the horizontal permeability kh 5 10 16 m2 assigned to the sw fault was sufficiently small enough to prevent horizontal migration of the co2 plume to the sw graben zone ii therefore it can be concluded that the size of the trapped co2 plume is dominantly controlled by fault permeability rather than the magnitude of fault throw in the sw fault as described in section 4 2 1 case 4 less dense co2 migrated buoyantly against gravity until it reached either caprocks or the sw fault when co2 migration was hampered by these types of barriers co2 accumulated beneath caprocks or faults thereby causing the development of trapped co2 plumes in this study the shape of the trapped co2 plumes and the amount of stored co2 mass were assessed by varying the cross cutting angle between the carmel formation and the southern sw fault 80 in case 7 1 70 in case 4 and 60 in case 7 2 when the cutoff angle was 80 the trapped co2 plume was almost flat parallel to the gentle dip of caprock and the calculated co2 mass under the caprock was 3 33 10 4 k g fig 10d after decreasing the cutoff angle to 70 the shape of the trapped co2 plume changed from a flat shape to a wedge shape fig 10e co2 saturation was elevated at the end of the wedge but the total mass of co2 decreased to 2 54 10 4 k g which implies that more co2 escaped to the southern sw fault finally when the cutoff angle was decreased further to 60 more co2 was concentrated at the end of the wedge and the smallest mass of co2 was stored 1 44 10 4 k g fig 10f 4 3 crystal geyser and tenmile geyser models one of the interesting geologic features in this region was the presence of co2 driven cold water geysers fig 11 a and d show photo images of crystal and tenmile geysers when they are erupting as it is evident that the development of these geysers is related to both subsurface co2 distribution or trapped co2 plumes and the configuration of both the lgw and sw fault systems the regional scale lgw and sw fault models developed in this study were utilized to evaluate the eruption mechanisms of co2 driven cold water geysers e g crystal and tenmile geysers in fact there has been effort to characterize the eruption patterns and intervals of these geysers by inserting in situ sensors han et al 2013 watson et al 2014 from a series of field observations it was identified that the eruption characteristics were dynamically evolved with time and were often unpredictable due to complexity involved in eruption characteristics of these geysers it was difficult to reproduce the periodic eruption patterns observed in the field exactly by applying the regional scale models the accurate prediction of the eruption patterns of these geysers via numerical simulations requires the sophisticated wellbore geysering model lu et al 2005 piao et al 2018 pruess 2008 therefore the following simulations were developed to evaluate whether the co2 distribution or trapped co2 plume predicted from regional scale models was capable of developing co2 driven cold water geysers after both lgw and sw fault models reached the steady state condition indicating that the size of trapped co2 plumes became stable and the magnitude of co2 flux did not vary crystal and tenmile geysers were activated in the footwall and graben of lgw and sw fault models respectively fig 4 in fig 11 brine and co2 flow rates gaseous co2 saturation dissolved co2 mass fraction and pressure were simulated at 15 m below the surface where fig 11b c and 11e f represent the eruption characteristics for the crystal and tenmile geysers respectively four eruption stages such as pre eruption eruption recharge and spring or bubbling were identified based on the evolutionary features of both pressure and gaseous co2 flow rates from the geysers specific to crystal geyser shown in fig 11b c during the pre eruption stage yellow bar co2 dissolved brine flowed with a rate fluctuating from 2 0 10 5 to 1 0 10 6 g day m2 green line in fig 11b and the dissolved co2 mass fraction increased xco2 purple line in fig 11c when the brine was not able to hold any more dissolved co2 due to reaching at its solubility limit e g 0 77 of dissolved co2 mass fraction the eruption stage red bar began at t 1 66 10 5 s gaseous co2 exsolved sco2 red line in fig 11c and gaseous co2 flow rate was elevated pink line in fig 11b different from the pre eruption stage the eruption stage was characterized by the presence of two phase fluids including brine and gaseous co2 as the eruption progressed the intensity of the eruption degraded due to both the emission of gaseous co2 to the surface and a decrease in the amount of exsolved co2 from co2 dissolved brine therefore both the gas flow rate and the corresponding co2 saturation also decreased in the middle of the eruption stage brine flow was inverted from an upward to a downward direction green line in fig 11b for example after gaseous co2 had been released to the surface the brine migrated downward to fill void spaces in the wellbore when both co2 saturation and the gaseous co2 flow rate fell to zero the recharge stage blue bar began t 6 10 10 5 s during the recharge stage the co2 dissolved brine migrated upward and gradually filled the wellbore while exsolving a small amount of gaseous co2 due to increase in brine flow within the wellbore the hydrostatic pressure was also elevated navy dotted line in fig 11c at the end of the recharge period t 1 10 10 6 s the brine flow rate reached 8 51 10 5 g day m2 green line in fig 11b and the co2 mass fraction xco2 once again reached its maximum 0 77 and thus gaseous co2 sco2 began to exsolve with increasing in gaseous co2 saturation a subsequent large scale eruption began and continued until all the gaseous co2 has been released to the atmosphere after the large eruption stopped at t 1 23 10 7 s the recharge period began again thereafter the geyser did not show the periodic trend anymore rather both co2 and brine fluxes reached their steady state rates of 1 67 10 3 and 1 43 10 3 g day m2 respectively which implies that the geyser behaved in a similar way to a spring or bubbling well in the previous regional scale lgw fault model trapped co2 plumes were developed in entrada navajo and wingate sandstones as shown in fig 5d indicating that co2 could be supplied from all these formations when the crystal geyser was activated likewise after investigating the eruption profiles of crystal geyser as shown in fig 11b c it can be identified that gaseous co2 entered crystal geyser only from these surrounding formations not from deep co2 sources directly migrated through the lgw fault gaseous co2 entered crystal geyser and then migrated upward to the surface while dissolving into co2 undersaturated brine interestingly during the pre eruption stage yellow bar co2 saturation was zero at the monitored depth i e 15 m within the geyser fig 11c which implies that most of the gaseous co2 entered the geyser dissolved to ambient co2 undersaturated brine while they migrated upward within the geyser therefore co2 presented as co2 dissolved brine within the geyser until gaseous co2 was exsolved due to perturbation of pressure and temperature essentially the geyser eruption was driven by co2 dissolved brine which caused co2 exsolution when the solubility limit was achieved therefore it can be concluded that the cyclicity of co2 dissolution and exsolution from co2 dissolved brine induced the periodic eruptions of the geyser the simulated behavior of tenmile geyser was similar to that of crystal geyser fig 11e and f tenmile geyser also showed the same eruption stages of pre eruption eruption recharge and spring however different from the crystal geyser a large gaseous co2 flux was predicted during the pre eruption stage pink line in fig 11e which was due to widely spread gaseous co2 within shallow formations such as the cedar mountain ce and morrison formations mo fig 8c immediately after activating tenmile geyser pre existing gaseous co2 within these shallow formations was instantaneously emitted after the emission of pre existing gaseous co2 a major eruption began at t 8 95 10 5 s with an increase in the dissolved co2 mass fraction to 0 46 xco2 purple line in fig 11f during the eruption stage red bar the simulated gaseous co2 flow rate and pressure at tenmile geyser were smaller than those at the crystal geyser even in the spring stage green bar the gaseous co2 flow rate at tenmile geyser 6 80 10 2 g day per m2 was still smaller compared to crystal geyser 1 67 10 3 g day per m2 the difference in the eruption scales of these two geysers was caused by the distribution of subsurface co2 including the size and number of trapped co2 plumes intersected by geysers for example in the lgw fault model three large trapped co2 plumes located at the footwall supplied both gaseous co2 and co2 dissolved brine to crystal geyser figs 4a and 5d in contrast even if a large trapped co2 plume exist in the northern footwall of sw fault the tenmile geyser drilled in the sw graben did not intersect this trapped co2 plume figs 4b and 8c therefore only a small amount of co2 is fed to tenmile geyser which presumably resulted in the small scale eruption and co2 flux even after the geyser has transited to a spring or bubbling well 5 conclusion this study used regional scale models of both lgw and sw faults in western utah to identify co2 migration and distribution within the areas where multiple evidences of co2 leakage appeared at the surface travertine deposits co2 rich geyser and springs soil co2 flux anomalies and an oil seep to evaluate subsurface co2 migration and distribution in these complex fault systems two models representing the lgw and sw fault systems were developed in the lgw fault model co2 migrated buoyantly through various flow pathways such as the fault itself fault offsets and damaged caprocks in additional to the direct leakage pathway through the lgw fault both fault offsets developed by fault displacement and relatively high permeable caprocks e g kayenta formation were found to serve as secondary pathways for co2 while co2 migrated through these pathways multiple trapped co2 plumes developed in regional jurassic aquifers e g entrada navajo and wingate sandstones were localized at the northern footwall and between the two lgw fault traces the occurrence of these trapped co2 plumes in these specific locations was related to the structural configuration of both faults and the regional caprocks the lgw fault served as a horizontal barrier and the regional caprocks e g carmel summerville and kayenta formations were intersected with each other sensitivity studies for the lgw fault model subsequently revealed the relationship between the kh of the lgw fault and the size of trapped co2 plumes when the kh of the lgw fault was sufficiently small less than 10 16 m2 trapped co2 plumes were almost equally developed within entrada navajo and wingate sandstones however with an increase in the kh of the lgw fault co2 escaped to the hanging wall of the lgw fault in another sensitivity study when the kayenta formation was assumed to be a good integrity caprock kh 10 16 m2 and kv 10 17 m2 the trapped co2 plume did not develop in upper navajo sandstone which indicated that the degree of fracturing or damage within the caprock would be an important factor governing the development of trapped co2 plumes within aquifers in the lgw fault system in the regional scale sw fault model a large trapped co2 plume appeared within the navajo sandstone at the northern footwall the presence of trapped co2 plumes at the northern footwall provides good support for previous field observations ancient travertine deposits and co2 springs were localized at the northern footwall in addition concentrated co2 flux anomalies were also monitored at the northern trace of the sw fault sensitivity studies with varying co2 sources indicated that the scenario with co2 originating from the bottom of the sw fault only explained the presence of multiple co2 driven cold water geysers e g tumble weed and chaffin ranch geysers which are located further south of the sw fault finally we evaluated whether subsurface co2 distributions or trapped co2 plumes predicted from regional scale models were capable of developing co2 driven cold water geysers although the periodic geyser eruption could not be reproduced exactly by the regional scale model the physical process of the eruption mechanism for the co2 driven geyser eruption was elucidated in this simulation the cyclicity of the geyser eruption was found to be primarily driven by gaseous co2 exsolution from co2 dissolved brine acknowledgements this research was supported by basic science research program through the national research foundation of korea funded by the ministry of education project number 2016r1d1a1b01008715 the korea environmental industry and technology institute keiti project numbers 2018002440003 2018001810004 kue young kim received funding through the basic research project of the korea institute of geoscience and mineral resources kigam funded by the ministry of science and ict 
